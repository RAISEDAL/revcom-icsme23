Bit of redundancy: this sets `input` twice (here and in the next few lines).
Then you wouldn't be able to easily serialize it.
Yeah but most (if not all) layers are not placeholder, right? Beside Input, I don't know any layer which could be placeholder.
Need to fill in this section
0.05 is a better interval. 50ms is definitely perceptible.
You can use parentheses to structure code into several lines.
You shouldn't need to pop these args here. Rather, you should remove them from kwargs before calling the layer (which is fine since they are transferred to the input list)
This should be max.
Make this method private and add a docstring explaining its purpose.
You could standardize the weights in `input_validation`, return a dict, then turn the dict into a list afterwards. That way you still have the dict around for `evaluate`, but weight standardization is being done in just one place.
Please explain the need for this new method
When a mask is provided, it means that the input has time steps. However the input might not necessarily be `(samples, timesteps, dims)`, it should more generally be considered to be `(samples, timesteps, **)` (e.g. sequences of pictures).
"on how masking is handled by the wrapped layer"
Why not turn this into a warning? Seems preferable, if only to avoid breaking existing code that might do this.
Make this method private and add a docstring explaining its purpose.
This won't do anything (need to be a global)
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Incorrect / confusing. Please fix.
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
This should definitely be a function, taking two arguments.
No `+` needed for string concatenation at the end
num_train_samples != steps_per_epoch, though. A step is a batch, not a single sample.
Reshaping is appropriate in this case, but only in this case.
does this assume all the images have the same shape? If so, varying image dimensions should be handled, and some kind of target dimensions could be utilized to apply padding to the images so they are all the same size. reference code: https://github.com/aurora95/Keras-FCN/blob/370eb767df86f364d93eff9068a3edb0b194a18b/utils/SegDataGenerator.py#L221 https://github.com/nicolov/segmentation_keras/blob/master/utils/image_reader.py#L79
That sounds good. There may be confusion with the concept of `op` in TF though (e.g. a dot product). But maybe not a big deal.
Only the `tf.eye` supports the non-square. Currently, all the three `K.eye`s don't support that, thus I proposed #12534.
Throughout this file, `"` is mixed up with `'`. Only use `'`, for consistency.
This is the TF backend, so don't rely on `_keras_shape`, instead use `tuple(kernel.get_shape().as_list())` (always available).
`new_shape_temp` will be deleted automatically after the return statement. There is no need to delete it explicitly.
`predict` and `evaluate` with data tensors should have unit tests as well.
This is a significant regression which breaks a lot of my code too.
This is a new layer so no API conversion decorator is necessary.
`predict` and `evaluate` with data tensors should have unit tests as well.
As a user, what can I do, knowing that I can now feed a Layer to the `metrics` arguments? Can I feed any Layer? (No, but some will try)
The CNTK errors on Travis CI seem to come from this line. `self.bias[0]` results in a `(1, 3 * self.units)` 2-D tensor in CNTK.
Add imports to make the script compatible with py2/3: ```python from __future__ import absolute_import from __future__ import division from __future__ import print_function ```
Fix indent. Use `pylint` as linter.
You should not be importing `keras` here. You can use `K.placeholder` to create a placeholder.
```suggestion if k == KC: ```
Yes, it would make better sense in `build`.
To show how to handle the output shape, let's not add keepdims
@tiferet the API change in `sparse_categorical_crossentropy` is not something we can merge, sorry. Such an argument should be called `axis` and should default to `-1` (`K.image_data_format()` is a layer-level configuration argument and should not affect the default behavior of backend methods).
Break into `if/else` blocks, for readability
No need for final space
Also I think the line does too much, breaking it into several lines would be preferable.
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
The ValueError should be listed in the docstring. The error message should specify what was passed, and the list of values expected instead.
Why not just pass the target directory? This is all your need to perform this task.
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
Link on a single line, otherwise it won't work (we don't enforce line length)
The `bn%d` looks unnecessary.
This default value will break loading old model files.
Please rename to `preprocessing_function`. Please improve the docstring by specifying: "The function should take one argument: a batch of images (Numpy tensor with rank 4), and should output a Numpy tensor with the same shape."
`if unknown is not None`
No return section in such cases.
Typo: output. It should be clarified that it needs to be a valid Theano expression.
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
There could be multiple model outputs
Incorrect / confusing. Please fix.
Incorrect / confusing. Please fix.
Should we rely have to rely on `np.dot`? Besides the fact that it's expensive, it's also a black box. The logic should be inferable from reading the code.
I don't get why you are introducing this unused argument.
PEP8 error. Use a PEP8 linter.
Move to the line below in order to keep each line under 80 char.
Indeed, or you can just increment the input seed for each new process.
"This allows for"
grammar "Please consider using"
Previous version was more readable imo.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
You could do that with Matplotlib, to avoid a new dependency
Oups, sorry, my bad. You are right! Please proceed with the temporary variable.
Actually, what we do right now is, when running travis, we compare: * theano against numpy * tensorflow against numpy * cntk against numpy those are three different jobs. If one backend is wrong, the corresponding job will fail. If the numpy backend is wrong, the three jobs will fail. Running some kind of correctness computation is really difficult to do right, because you would need to use random input values to ensure correctness in a majority of cases. But then if you take random values as input, it's very likely that you won't use a paper and a pencil to compute the expected output. You'll likely use numpy. So I think this is our best bet to avoid shallow tests. After all this, I didn't dig much into the rnn implementation in the numpy backend, so I can't guarantee that it supports your use case. And if it does not, it would surely fall outside the scope of this PR, and we're better off with your implementation of the tests for sure. After a bit of digging into the git blame, I found that the numpy RNN implemtation was done there: #9557 Maybe @taehoonlee can tell us more about it? Otherwise I'm fine with the tests that you made if it means changing a lot of code to adapt it to my request. I don't intend to make you do too much extra work since you're already helping a lot with your frequent PRs and discussions :)
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
For theano, `ratio` needs to be `integer`. ```python ratio = height_factor // width_factor ```
Replace with ``` if len(mask.get_shape()) > ndim: raise ValueError(...) ```
Would it be possible to simplify by doing ```python if axis is not None: axis = tuple(axis) ```
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Prefer using `if isinstance(...):` / etc: it makes lines shorter and more readable, and it will be extensible to more types in the future.
It should be clarified in the docstring what "compilation" entails.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
Nit: please shorten lines (here and above).
Per the failing docstring test, this docstring needs a `Raises` section mentioning the ValueError: https://travis-ci.org/fchollet/keras/jobs/282558708
Please fix the identations issues in the file. I'll review the PR in the next few days. Thanks for updating it!
Also around `=`
I'd rather use `Deconvolution2D` (and an alias `Deconv2D`), to better match the TensorFlow API.
Yes, that works
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
Default values should be 0 (i.e. if argument isn't specified then no padding occurs on that side).
Also style: use `target_height` / `target_width`, no point in removing two characters.
We could add a backend method to do it, with custom implementations in each backend...
Likewise, please format docstring
Looks great to me. :)
Insert line break above
`weights` are part of the base layer kwargs, so it doesn't need to be included in the test. `name` is only included in order to get the test to pass (otherwise the different names would make the configs different). You can remove it, especially since this is not be the proper syntax for this argument (needs a list).
should be self.forward.
There's no reason to not make these both extend `MaskedLayer` instead of `Layer` and thereby also be supported in masked scenarios.
Please do not include html markup in the docstrings. Two line breaks should be sufficient (or use markdown list formatting).
it's less pythonic but more in line with the style of how things are computed at some other places in the code base.
```suggestion if k == KC: ```
No need for final space
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
this is discussed in https://github.com/fchollet/keras/pull/7113
This is way too ad-hoc. The choice of having exactly 2 input and 2 outputs and having the input data / target data be just a repetition of the same array is something that happens to work in some of the existing unit tests, but it wouldn't work in the general case.
No need for such abbreviations, they just make code harder to read.
Please fix the identations issues in the file. I'll review the PR in the next few days. Thanks for updating it!
Use bullet points
enumerate is not needed here. i is not used
Please add a note saying that the learning_phase should be added by `fit_generator`, otherwise it's a little confusing.
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
Please add a docstring describing the overall strategy used to compute the mask.
I think this check would be better as if inputs.shape[1] is not None and sum(self.cropping) >= inputs.shape[1]: You could still construct a tensor with size 0 and shape (None, None) that would cause this to crash.
This is not the same argument. The proper behavior here would be: - if `forget_bias_init` is set to `"one"`, set `unit_forget_bias` to True - else ignore the argument, and in this case, raise a warning specifying the argument was ignored. You will need custom code to do this.
The base layer should raise an error actually or None. Depend if we want everyone to provide this service. Every layer in keras' repo should provide this
Should this be part of the public API? It sounds like it should be an internal method.
You are later multiplying with a float. This has no effect on the output
I vote for option number two. That seems the most consistent with other parts of the Keras API.
I think we should add the arguments "file_format" and "**kwargs" (passed to `Image.save()`) https://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.save "format" needs to be renamed "file_format" to avoid confusion with "data_format".
I think `if self.dropout > 0 or self.recurrent_dropout > 0` is more clear.
Please update the docstrings as well.
this value error is good but do in other places
You can just append: ``` To install TensorFlow: `pip3 install tensorflow` ``` to the previous message.
No need for final space
The number of batches in the Sequence
Please use PEP8 conventions: one space after `,`
`weights` are part of the base layer kwargs, so it doesn't need to be included in the test. `name` is only included in order to get the test to pass (otherwise the different names would make the configs different). You can remove it, especially since this is not be the proper syntax for this argument (needs a list).
add the type to be consistent send_as_json: Boolean, ...
There are added empty lines. Please remove them.
Respect PEP8 conventions.
In the future, I'll just remove this use case. I suspect having `workers > 1 and use_multiprocessing == False` doesn't gives any real speedup. I'll do some profiling and post my findings here. Also, we should try to mimic the Ordered Enqueuer so this class will get heavily refactored anytime soon anyway. (By the end of August)
whoops! Thanks for the fix. I'd lean towards yes, but I don't know the details of how locally declared python classes work between calls.
var is a reserved keyword, use `v` or something like that.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Better to check whether the layer's call method accepts the `training` and `mask` arguments.
Use spaces around `-` operator (PEP8).
In that case the first seed can be used to generate separate seeds for each sub process before the fork
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
This mechanism will only work for a few layers, and will fail in the general case. The proper behavior when batch size matters is to slice the input mask and run slices through `self.layer.compute_mask`, then concatenate. No reshaping.
This is way too ad-hoc. The choice of having exactly 2 input and 2 outputs and having the input data / target data be just a repetition of the same array is something that happens to work in some of the existing unit tests, but it wouldn't work in the general case.
Line too long
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
Syntax error here (`}`)
not sure you need to wrap this in a method it looks clean this way though.
Docstring contains a few typos, please fix / rephrase
This default value will break loading old model files.
Insert link to callbacks page
I don't quite understand this message. Do we expect users to be familiar with the concept of "dynamic axis" here? Doesn't seem standard
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Can we have a better API than `padding=(1, 1, 1, 1)`? Maybe `padding=((1, 1), (1, 1))` (but that one is not very good either). Please think of something. Maybe multiple arguments.
Callbacks are processed sequentially, future is more vague than next IMO.
In all of these cases, we refer to the `Variable` class.
in the tests k.backend() == `cntk` might want to lower case here
Please print a message for this action (like we do in `on_train_end`): "Restoring model to its state at the end of the best epoch."
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
Add a `# Arguments` section to the docstring.
If the default is 0.5, then I would suggest to put `def __init__(self, threshold=0.5):`
Please add a check that all kwargs match a list of expected Theano arguments, with helpful error message otherwise. This is necessary to avoid confusion in case of typo.
I think it would make the operation clearer.
Simply `batch_size` would suffice.
Please rename to `preprocessing_function`. Please improve the docstring by specifying: "The function should take one argument: a batch of images (Numpy tensor with rank 4), and should output a Numpy tensor with the same shape."
Also rewrite this description assuming an integer axis.
Capitalize start of argument descriptions ("String or...")
Please add spaces after commas.
So I think we should: - move the function inside the parent function, since no one else will use it - keep the list comprehension, since we won't in-line the function after all... Thanks!
As I said, using img_to_array would be nicer. The API of `save_img` should reflect the one of img_to_array
Does CNTK support a softmax axis? If not, we can also go with manual softmax in CNTK.
Let's add a TODO for this one
Insert a line break after the docstring
This is unsafe, because it would be reused across different unrelated calls to `layers_from_config`. I would suggest using a custom object scope inside `layers_from_config`: ```python with custom_objects_scope(custom_objects): layer = ... ``` Or something like that.
It seems that all pep8 tests failures are ignored by travis. I'll make a PR to fix it.
The indices of the axes depend on the dim ordering. Just say "width and height"
Incorrect / confusing. Please fix.
This is correct.
We have this warning in several places, please fix it everywhere
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
`mathews_correlation` or `matthews_correlation_coefficient`
Needs the same docstring as the TF one
Also style: use `target_height` / `target_width`, no point in removing two characters.
Can we have a better API than `padding=(1, 1, 1, 1)`? Maybe `padding=((1, 1), (1, 1))` (but that one is not very good either). Please think of something. Maybe multiple arguments.
Personnaly, I would use Theano flags :) I don't know if it should be added directly in Theano. Do tensorflow support this? If it is added in keras, I would do: ``` mode = None if _DEBUG_MODE == 'detect_nan': mode = 'NanGuardMode' ``` Can you open an issue on Theano, Using the Theano flag should not enable the GPU. I don't have this behavior on the lstm example.
Suggest to put operator in next line and remove redundant parentheses. ```python (K.backend() != 'tensorflow' or not K.tensorflow_backend._get_available_gpus()), ```
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
`data_utils` is no longer meant as a public namespace, use `utils`
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
There's no reason to not make these both extend `MaskedLayer` instead of `Layer` and thereby also be supported in masked scenarios.
Specify an epoch number
That last sentence will be very difficult to understand for people who don't have further context.
You shouldn't need to pop these args here. Rather, you should remove them from kwargs before calling the layer (which is fine since they are transferred to the input list)
in the tests k.backend() == `cntk` might want to lower case here
In general throughout this PR, we should follow PEP8 and avoid camel case. Let's use snake case instead (this is Python after all).
Please add a check and raise `ValueError` if appropriate. Reshape may not be possible.
In this case the better solution would to check `dtype(x)`.
LeCun proposed this scheme way back (see ref in `lecun_uniform` docstring). Our initializers are named `*_normal` and `*_uniform`. We already have the `lecun_uniform` initializer, and this initializer is simply the normal version of it. I don't even know why we didn't already have it, it's a significant inconsistency.
Could you try benchmarking this against the use of `transpose + softmax + transpose`? It may be that transposing is faster (but impossible to know in advance).
The indent is meant to match to upper logical line, not the semantics of np arrays
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
Yes, unless we expect users to access it and set it (we don't), it should be private.
This won't work, since the shape of the mask won't match the shape of the input.
Respect PEP8 conventions.
Please add a docstring.
The error messages in `generate_legacy_interface` are layer-specific. Don't use it for model methods.
Since `dtype` is an argument name and not a string variable, quotes are not necessary.
Just for reference for newbies, in windows, the cache folder is at C:\Users\USERNAME_HERE\.keras\datasets. I usually download the files manually and place them because sometimes it does fail downloading in my computer.
cropping, not padding
Fix indent. Use `pylint` as linter.
The example currently works fine with `data_augmentation=False`...
Flaky test is fixed just so you know.
Better mention that the cropping happens along the time dimension here (axis 1)
Add space after `#`
Transposing the weights is always the right thing to do regardless of original backend.
You could do that with Matplotlib, to avoid a new dependency
Yes, that works
Please format the docstring like the others, with an `# Arguments` and `# Returns` section
Looks like you got it, I just wanted to make sure this PR wasn't going to get stuck for another couple of releases.
Bit of redundancy: this sets `input` twice (here and in the next few lines).
Here is the generic version that will work for any ndim: return T.TensorType(dtype, (False,)*ndim)(name) So this whole if/elif/.../else will disapear.
Don't use needed abbreviations that make code harder to read in order so save 4 characters.
These quantities are not relevant here.
I would definitely exclude `loss_weights` from the `Sequential` API. There is no use case for it, and it is likely to confuse some people.
> tf.ragged.constant does not accept tf.Tensor inputs gracefully It's really strange that it works with numpy arrays but not tf.Tensors. That's an inconsistency in the ragged API that we should address...
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Capitalize start of argument descriptions ("String or...")
That should be `inputs`, not None (same below).
Can be replicated in all backends
The CNTK errors on Travis CI seem to come from this line. `self.bias[0]` results in a `(1, 3 * self.units)` 2-D tensor in CNTK.
Add these 3 classes to `utils/__init__.py` so they can be imported from `utils` by users (internally it doesn't matter)
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Please revert this change.
In order to avoid this `for` loop, I think it would be better to have the test for `logsumexp` be a separate function, with a parameterization decorator over axes and shapes.
`)` after `]`
this is discussed in https://github.com/fchollet/keras/pull/7113
No need for final space
Incorrect / confusing. Please fix.
Is there a way to eliminate the underlying cause of this warning & the other similar ones without requiring the user to inherit from Dataset? I've only used pickling once or twice so I'll defer to others on all such code.
We could add a backend method to do it, with custom implementations in each backend...
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
+1. Use case would be validating on more data than fits in GPU memory. So the generator has to return small-ish minibatches, but I want to validate on more than one minibatch.
Add space after `#`
Blank line required before the next section
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
Space (" ") instead of period(" ")
Link on a single line, otherwise it won't work (we don't enforce line length)
Link on a single line, otherwise it won't work (we don't enforce line length)
@tiferet the API change in `sparse_categorical_crossentropy` is not something we can merge, sorry. Such an argument should be called `axis` and should default to `-1` (`K.image_data_format()` is a layer-level configuration argument and should not affect the default behavior of backend methods).
var is a reserved keyword, use `v` or something like that.
Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
You can replace the next lines with `return - dice_coef_loss(y_true, y_pred)`
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
No `+` needed for string concatenation at the end
@farizrahman4u this is still not fixed.
Should we rely have to rely on `np.dot`? Besides the fact that it's expensive, it's also a black box. The logic should be inferable from reading the code.
This is not the same argument. The proper behavior here would be: - if `forget_bias_init` is set to `"one"`, set `unit_forget_bias` to True - else ignore the argument, and in this case, raise a warning specifying the argument was ignored. You will need custom code to do this.
Yes, that's right
Fix indent here and below
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
This is a significant regression which breaks a lot of my code too.
Introduce an `if` block to avoid a very long line.
@briannemsick Sorry, I wasn't clear about my main point! 1. The tqdm API UX is worth considering for inspiration when designing stateful metrics, which must be updated at every batch and displayed to the user. 2. I'm suggesting stateful metrics should be a callback call and not a special init variable that gets passed around to every class in keras. Rather than actually including tqdm (which is just a convenient option), the point is the excellent API UX style of tqdm for the stateful task of iterating through batches and counting them.
Are you sure about this? Justify.
In this case the better solution would to check `dtype(x)`.
This default value will not work with Windows. Use None instead, and set it in the function code.
Looks good to me now.
Singe the names are expected to match across models, "in the current model" does not make sense here.
Is there a reason why there is not a `SpatialAlphaDropout` like there is a `SpatialDropout`? In the paper they are not explicitly doing it, but they do have an argument `noise_shape` on their Github. When they release the code for more advanced datasets, we'll know for sure I guess.
Code markers around `validation_split`
Please use one import per line from now on.
The targets / predictions are assumed to be in the [0, 1] interval but that is not enforced. It should be.
An optimizer instance is not serializable (it's a Python object). The previous 4 lines were serializing it. Revert this
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
Let's add a TODO for this one
This is the TF backend, so don't rely on `_keras_shape`, instead use `tuple(kernel.get_shape().as_list())` (always available).
Reformat this in a way that avoids the use of `\`
Use backticks around codde keywords
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
I'm glad I could help :)
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
Would it be possible to simplify by doing ```python if axis is not None: axis = tuple(axis) ```
Replace with ``` if len(mask.get_shape()) > ndim: raise ValueError(...) ```
This will break if `layer` is a container.
`if not {expression} != {expression}:` is quite a strange structure. Did you mean: ```python dtype = getattr(x, 'dtype', None) if dtype != K.floatx(): x = np.asarray(x, dtype=K.floatx()) ```
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
Awesome : ) But now you'll need to remove the outdated exception as well ; )
Please make this method private.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Optimizers have a `get_config` method precisely for this purpose.
No `+` needed for string concatenation at the end
Nit: ` around code keywords
@tiferet the API change in `sparse_categorical_crossentropy` is not something we can merge, sorry. Such an argument should be called `axis` and should default to `-1` (`K.image_data_format()` is a layer-level configuration argument and should not affect the default behavior of backend methods).
Do not use backslashes to break lines.
I believe you should be able to remove a lot of redundant code by subclassing `RNN`. There are lots of shared methods.
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
Introduce an `if` block to avoid a very long line.
I don't quite understand this message. Do we expect users to be familiar with the concept of "dynamic axis" here? Doesn't seem standard
Please use backticks around code keywords.
This function does not have a properly formatted dosctring (see other dosctrings for reference)
It's "depth, height and width" in this order (was previously incorrect)
It's all very confusing, and `Convolution2D` wasn't doing great on that front either. Here I think we should refer to the kernel dimensions as `kernel_dim*` and to the target tensor dimensions as `conv_dim*`.
`# Returns `
Space between "take" and "place"
You can replace these lines with `outputs.set_shape((inputs.get_shape()[0], None, None))`
Here is the generic version that will work for any ndim: return T.TensorType(dtype, (False,)*ndim)(name) So this whole if/elif/.../else will disapear.
This still seems hackey. Maybe a better or more clear solution could be something like: ``` python from keras import backend as K if K._BACKEND == 'tensorflow': logic else: other_logic ```
`K.eye` should already follow this same behavior (at least it does in TF). So no padding necessary.
Can we have a better API than `padding=(1, 1, 1, 1)`? Maybe `padding=((1, 1), (1, 1))` (but that one is not very good either). Please think of something. Maybe multiple arguments.
Please put "`" around code keywords.
Needs a space after {}
What if the layer does not have a name, though? There should be an exception or a fallback (preferably an exception, for maximum explicitness).
`K.floatx()` is the preferred way to access this.
Need spaces at the end of every line in this message (this is also true of a few other messages)
replace `with` with `to`
"on how masking is handled by the wrapped layer"
No need for final space
At this point it would be fine to have `np_kernel = kernel.eval()`
Set the default value to `0.0` rather than None, for consistency with `fit`
@farizrahman4u this is still not fixed.
Docstring contains a few typos, please fix / rephrase
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Actually, maybe it would be higher performance to have a switch: `if eta > 3600` / `if eta > 60` So that we only compute what we need.
Reduce indent (should be 4 spaces)
please shorten the line by using temporary variables, it will be easier to read.
Clarify the error message; a "Keras tensor" is the output of a Keras layer
Prefer importing `layers` then using e.g. `layers.Conv2D`
For an unimplemented method to be useful, it should have a docstring describing its specs.
Parens not necessary here
I think we should make this function private, as well as `is_current_explicit_device`, and `get_available_gpus`.
`try` with an `assert` is not the way to test inequality between two integers...
`nb_val_worker` should be described in the docstring.
Should this be part of the public API? It sounds like it should be an internal method.
Typo: output. It should be clarified that it needs to be a valid Theano expression.
This statement should come afterwards
Break up long line
`mathews_correlation` or `matthews_correlation_coefficient`
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
`if self.depth_multiplier != 1` Additionally: please put this exception in the Theano function, in the backend, since it is Theano-specific.
Please include a non abbreviated explanation of what erf is.
You can define the set on the same line, to avoid a named variable
Not sure this is the behavior we actually want. Seems like a lot of hard-coded assumptions.
It seems like the `weights` argument for `preprocess_weights_for_loading` is not really a list of numpy arrays. It's a list of `HDF5 dataset`. When I call `print(weights)` on my machine, I saw something like: ``` [<HDF5 dataset "kernel:0": shape (100, 96), type "<f4">, <HDF5 dataset "recurrent_kernel:0": shape (32, 96), type "<f4">, <HDF5 dataset "bias:0": shape (192,), type "<f4">] ``` Hence there would be some metadata attached to the weights. Specifically, with `print([x.name for x in weights])`, the output is: ``` ['/model_weights/cu_dnngru_1/cu_dnngru_1/kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/recurrent_kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/bias:0'] ``` However, I'm really not sure if this is a behavior that we could rely on (i.e., is it a consistent behavior for different versions of h5py, different versions of Keras, python, OS, ...). Also, it might not pass some existing tests since the tests are written under the assumption that the input is a list of arrays.
I see, it's to be able to compare it with the other backends with `==` later on. Nevermind.
This is a significant regression which breaks a lot of my code too.
This is a significant regression which breaks a lot of my code too.
Missing a space between "argument" and "has". Also tell users to use the `unit_forget_bias` argument instead.
It makes it much easier to keep track of parts of the code that are backend-specific.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
Prefer using `if isinstance(...):` / etc: it makes lines shorter and more readable, and it will be extensible to more types in the future.
Please use instead `K.epsilon()`, so that the user can globally set all fuzz factors throughout the codebase.
Yes, all private methods in the Keras codebase use a single leading underscore. Thanks!
In general we can use the default implementation if `axis == 1 or axis == x.ndim - 1`
Looks like you got it, I just wanted to make sure this PR wasn't going to get stuck for another couple of releases.
In which case this wouldn't be necessary anymore.
The entries in `config` should match the arguments in `__init__`.
"not currently supported with CNTK".
No point in calling super here
Use `'` for strings for consistency with the rest of the file.
Prefer more explicit variable names.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Also style: use `target_height` / `target_width`, no point in removing two characters.
It's a hack, but changing to something like ``` return K.mean(y_pred, axis=-1) + (0 * y_true) ``` may suppress the Theano warning that you're currently throwing. (NB: Not sure the dimensions here are correct in all situations, but something along these lines would work.)
As a user, what can I do, knowing that I can now feed a Layer to the `metrics` arguments? Can I feed any Layer? (No, but some will try)
It doesn't really make sense to me, because random transformations are important to have at test time as well (because they modify the statistics of the data). Best evals are from multiple random transforms, with results merged via power averaging.
Bit of redundancy: this sets `input` twice (here and in the next few lines).
Let's add a TODO for this one
The ValueError should be reported in the docstring
"When using `steps_per_epoch`, ..."
Looks good to me now.
Default axis to -1
No need for final space
Space (" ") instead of period(" ")
Code delimiters ` would be more appropriate than string quotes here, for `x`.
In which cases would this be needed? It may be better to defined a proper private function than a very long named lambda. e.g. ``` python def _expand_if_needed(input, mask): ... ```
List or tuple. Iterables implement `__iter__()` and thus may not necessarily be indexable (requires `__getitem__()`).
Parens not necessary here
The class docstring should explain the meaning of the arguments.
`for/else` is not idiomatic Python. Please don't use this pattern.
Please use more informative descriptions, not just types
I don't understand why; `tf.nn.separable_conv2d` does support strides.
The class docstring should explain the meaning of the arguments.
Same remark as before regarding `output_shape`.
No `+` needed for string concatenation at the end
I don't think the line needs to be broken.
What about failure cases? Example: #6928 it is possible only x, only y, neither x nor y, or a tuple of some other unexpected size gets returned. At a minimum, check the tuple size and throw an exception if it doesn't match expectations. There are probably other cases like this in this pull request, it might be worth double checking.
We could add a backend method to do it, with custom implementations in each backend...
Space after #
These should be `ValueError`
The ValueError should be reported in the docstring
No point in calling super here
`)` after `]`
It's good to have an explicit example. Put it in an `# Example` section. I don't understand the message "It therefore has to be part of the computational graph,". Please remove, the example is self-explanatory.
Not sure this is the behavior we actually want. Seems like a lot of hard-coded assumptions.
No, that's a fine style as well. Anything that's PEP8 works. And line length is not strictly enforced (prefer readability over correct line length).
replace the word hack with workaround
Nit: first line of docstring (one-line summary) should fit in one line and end with a period.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
In line with naming conventions in this API, this should be `_num_constants`.
For papers that are closer to the heart of VAEs: Might be useful to cite Kingma's [IAF paper](https://arxiv.org/abs/1606.04934) (the encoder is more complicated though) Larsen's [vae-gan paper](https://arxiv.org/abs/1512.09300) is good as well.
About this test: - please use the same docstring format as elsewhere in the codebase - use `'` as quote character for consistency - use lines that are <= 80 char
I'm afraid "Container" is not a term that can be readily understood by most users. Please say "list, tuple, or set"
These should be `ValueError`
This function does not have a properly formatted dosctring (see other dosctrings for reference)
No need for final space
Use a variable with a complete name, not `l`.
Fix link (should be explicit link)
This and everything that uses it is too tf specific for this file. See how I handled these same issues in #6928
Use `'` as quote char for consistency
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
We could add a backend method to do it, with custom implementations in each backend...
The number of batches in the Sequence
Use the same docstring as the TF version.
I think these layers would benefit from having more transparent names.
var is a reserved keyword, use `v` or something like that.
The indices of the axes depend on the dim ordering. Just say "width and height"
may be use a local variable here and in the cases below to avoid code duplication? ``` ndim = len(self.output_shape[i]) if ... else ... weight = ... ```
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
> The current progbar is fine. We're not changing the existing API, we just extend it in a really simple way to support a new use case. Fair enough, but rather than a different progbar please allow me to suggest a **different, composable stateful metric design**, unrelated to progbars, which uses the tqdm API for inspiration. In other words, consider a stateful metric which is a decorated iterator implementing `next()`, `def __iter__(self):`, `update()`, `clear()`, ` def __len__(self):`, etc.
Line too long (and several other lines in this file as well)
Please use readable variable names such as `array`
I see you are a Theano user. This wouldn't work with TF.
This would be very inefficient and would cause EOM errors even for smallish datasets. Please use instead the approach of `predict()` (preallocating entire arrays as soon as their shape is known, then assigning values inside the preallocated arrays). This is doable because the number of samples that are expected is known (`val_samples`).
Please use standard formatting for the docstrings, e.g. ``` # Arguments ```
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
No `+` needed for string concatenation at the end
One import per line. Also import `models` so as to avoid `tf.keras` calls in the code. This *is* the Keras codebase! It should import internal modules, not `tf.keras`.
For now, after adding `axis` in the crossentropy losses, you will have to use a different loss function when doing pixelwise classification (image segmentation) in NCHW: ```python if K.data_format() == 'channels_first': loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(y_true, y_pred, axis=1) else: loss = K.sparse_categorical_crossentropy model.compile(optimizer=optimizer, loss=loss) ```
Then you wouldn't be able to easily serialize it.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
Nit: use backquotes around code keywords
I think this is out of scope, the goal of the PR is to support stateful metrics. A complete rewrite of progbar (if that's the route taken) should be a follow on PR.
It looks like you undid my work in a merge conflict here.
Line too long
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
Line too long
It seems there is four spaces missing (unrelated to your changes).
Should we rely have to rely on `np.dot`? Besides the fact that it's expensive, it's also a black box. The logic should be inferable from reading the code.
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
Nit: please shorten lines (here and above).
No warning should occur with default settings. It is safe to remove this.
Prefer making multiple statements, it will be easier to read than breaking the statements into multiple lines. Breaking lines should only be done if necessary. ```python slices = [] for i in range(x.ndim): .... ```
Simply `batch_size` would suffice.
Format your docstrings like other docstrings in the codebase
This is too broad an exception, it should be `ImportError` (otherwise something inside the module could fail and you wouldn't know why).
I think we should either not mention the details of choosing the reduction methods, or explain why it's chosen this way (for which, I'm afraid there's not an easy way to describe in docs as it really depends on tf.distribute strategies' implementation). So, I would probably just say the library would choose the best reduction method based on the training environment, for 2).
I think we should make this function private, as well as `is_current_explicit_device`, and `get_available_gpus`.
This would benefit from a bit more explanation on how to use TensorBoard, at least a link to https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
Please rename to `preprocessing_function`. Please improve the docstring by specifying: "The function should take one argument: a batch of images (Numpy tensor with rank 4), and should output a Numpy tensor with the same shape."
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
One import per line. Also import `models` so as to avoid `tf.keras` calls in the code. This *is* the Keras codebase! It should import internal modules, not `tf.keras`.
It looks like you undid my work in a merge conflict here.
Also I think the line does too much, breaking it into several lines would be preferable.
In that case shouldn't it be `if x.ndim == 4`? Also this line is becoming too long, I'd suggest creating a `use_cudnn` intermediate variable.
Just say "either md5 or sha256".
Use `'` as string delimiter
In general this test is more like an integration test than a unit test. You don't need half of this stuff: - the model should be minimal (this one has a bunch of extra layers) - you don't need data with a statistical structures, `np.random` will work just fine - etc.
That's a good point, since we didn't require it be named `epoch` before, we should probably make the first argument positional and only make the second (new one) a keyword arg.
I don't think so, adding @KeDengMS from cntk team to confirm
I'm glad I could help :)
An optimizer instance is not serializable (it's a Python object). The previous 4 lines were serializing it. Revert this
`raise NotImplementedError` may be more appropriate.
Need to fill in this section
Not a fan of this. It is neither simple nor elegant.
Need to fill in this section
replace `with` with `to`
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
Use `'` as string delimiter for consistency
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
PEP8: spaces around operators. We don't do strict PEP8, but such guidelines make the code more readable and should be respected.
Right. My mistake.
```suggestion if k == KC: ```
The three lines above can be removed.
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Bit of redundancy: this sets `input` twice (here and in the next few lines).
"Name-based weight loading (instead of topological weight loading)"
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
You're right. Never mind then.
The Keras API does not require `compile` before calling `predict`, because `compile` merely configures training and is not related to inference. If MXNet requires it, that's a bug and it should be fixed.
This will be more readable with code markers around `epochs`.
Seems a bit specific. Since this is the last `if` clause, it would be okay to cast it to list: ``` else: key = list(key) ```
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
You could do that with Matplotlib, to avoid a new dependency
isn't is always \n anyway? POSIX uses \n as default. So we could remove the if.
I think this check would be better as if inputs.shape[1] is not None and sum(self.cropping) >= inputs.shape[1]: You could still construct a tensor with size 0 and shape (None, None) that would cause this to crash.
No need for final space
This should be private. Also, since this function is only called once (in a loop), please consider if you could in-line it in the parent function.
The ValueError should be listed in the docstring. The error message should specify what was passed, and the list of values expected instead.
Line too long
Please add a docstring.
Please log the `axes` argument in the error message. It should be clear to the user upon reading the message what happened and why it happened (likewise for other backends).
These few lines break PEP8 conventions.
Better mention that the cropping happens along the time dimension here (axis 1)
pg 6 of the [paper](https://arxiv.org/pdf/1706.02515.pdf) says: > Therefore, we propose alpha dropout, that randomly sets inputs to 
Better to use keyword arguments (same below). API change looks ok to me.
Better to use `_keras_history`
Are there cases where `any` would not return `bool`? If so, better to fix it in the corresponding backend.
"`x` can be" (better be explicit)
No need for final space
`+ K.epsilon()` in the denominator.
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
Please make multiple statements instead of breaking the line, it will improve readability. ```python if _LEARNING_PHASE ....: return .... else: return .... ```
There are added empty lines. Please remove them.
Nit: first line of docstring (one-line summary) should fit in one line and end with a period.
I think this is probably needed as well, otherwise the follow up model.eval() will accumulate the metric result from this train/test_on_batch.
Style: code markers around `Sequence`
Please rename `sparse_top_k_categorical_accuracy` for consistency with other metrics names
This line should be right after `"""`. Put "`" around function names.
The point of these conversion interfaces is that old code should still work. So in this case we should figure out a better solution. Please leave out this layer.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Yes please, rewrite those lines.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
"the input name to a Numpy array" (singular in this case, for `Sequential`)
Better to put the activation as the `activation` keyword of the layer below
Awesome : ) But now you'll need to remove the outdated exception as well ; )
Remove leading space
No need to capitalize Input or Tensor
"Name-based weight loading (instead of topological weight loading)"
