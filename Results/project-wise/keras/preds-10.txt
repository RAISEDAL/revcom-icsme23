Bit of redundancy: this sets `input` twice (here and in the next few lines).
This should be tensor3 instead of matrix.
`input_spec` contains constraints that future inputs should respect. This statement would set the length of the first input as a length constraint, but unless the network is unrolled there should be no constraint on length. This is in part what the previous TODO was referring to.
The CNTK errors on Travis CI seem to come from this line. `self.bias[0]` results in a `(1, 3 * self.units)` 2-D tensor in CNTK.
cropping, not padding
We could add a backend method to do it, with custom implementations in each backend...
Same: don't mention specific axes
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Line too long, and not PEP8 compliant. Break it down into a few lines.
This is Theano syntax and breaks with TF. Use `K` instead.
Then you wouldn't be able to easily serialize it.
Please put the new parameters on a new line
You are setting this to True but don't seem to be using the learning phase in the code.
Just import `utils`
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
> `T.sqrt(self.p/(1-self.p))` Something should be done to avoid division by zero in case p = 1... maybe clipping p to [epsilon, 1-epsilon]? In terms of coding style, please use spaces around operators and use floats in float operations.
`# Returns `
Yeah but most (if not all) layers are not placeholder, right? Beside Input, I don't know any layer which could be placeholder.
Why would something without '_is_placeholder' is a placeholder? (The except part)
No `+` needed for string concatenation at the end
No need for `+` at the end. But needs a space after `.`.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
Need to fill in this section
Use list markers
Shapes mentioned in the docstring are generally 2D; should be 3D
This is a new layer so no API conversion decorator is necessary.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Blank line required before the next section
unused variable `input_length`
Blank line required before the next section
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Use bullet points
0.05 is a better interval. 50ms is definitely perceptible.
Docstring should have a `Returns` section and a `Raises` section.
Using code markers around code keywords (.e.g `_predict_loop`).
> The current progbar is fine. We're not changing the existing API, we just extend it in a really simple way to support a new use case. Fair enough, but rather than a different progbar please allow me to suggest a **different, composable stateful metric design**, unrelated to progbars, which uses the tqdm API for inspiration. In other words, consider a stateful metric which is a decorated iterator implementing `next()`, `def __iter__(self):`, `update()`, `clear()`, ` def __len__(self):`, etc.
@briannemsick Sorry, I wasn't clear about my main point! 1. The tqdm API UX is worth considering for inspiration when designing stateful metrics, which must be updated at every batch and displayed to the user. 2. I'm suggesting stateful metrics should be a callback call and not a special init variable that gets passed around to every class in keras. Rather than actually including tqdm (which is just a convenient option), the point is the excellent API UX style of tqdm for the stateful task of iterating through batches and counting them.
I think this is out of scope, the goal of the PR is to support stateful metrics. A complete rewrite of progbar (if that's the route taken) should be a follow on PR.
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
this is discussed in https://github.com/fchollet/keras/pull/7113
Insert link to callbacks page
Set default `batch_size` to None, like in `fit`.
You can use parentheses to structure code into several lines.
Actually, maybe it would be higher performance to have a switch: `if eta > 3600` / `if eta > 60` So that we only compute what we need.
Don't format a string two lines, do it in one pass. Also, there is seemingly no need for the `% 7`...
0.05 is a better interval. 50ms is definitely perceptible.
Please raise a `NotIplementedError` when the use case is not supported yet.
@briannemsick Sorry, I wasn't clear about my main point! 1. The tqdm API UX is worth considering for inspiration when designing stateful metrics, which must be updated at every batch and displayed to the user. 2. I'm suggesting stateful metrics should be a callback call and not a special init variable that gets passed around to every class in keras. Rather than actually including tqdm (which is just a convenient option), the point is the excellent API UX style of tqdm for the stateful task of iterating through batches and counting them.
> The current progbar is fine. We're not changing the existing API, we just extend it in a really simple way to support a new use case. Fair enough, but rather than a different progbar please allow me to suggest a **different, composable stateful metric design**, unrelated to progbars, which uses the tqdm API for inspiration. In other words, consider a stateful metric which is a decorated iterator implementing `next()`, `def __iter__(self):`, `update()`, `clear()`, ` def __len__(self):`, etc.
I think this is out of scope, the goal of the PR is to support stateful metrics. A complete rewrite of progbar (if that's the route taken) should be a follow on PR.
Invalid Python 3 syntax.
Please add `s` for seconds.
You shouldn't need to pop these args here. Rather, you should remove them from kwargs before calling the layer (which is fine since they are transferred to the input list)
Clarify the error message; a "Keras tensor" is the output of a Keras layer
Nit: first line of docstring (one-line summary) should fit in one line and end with a period.
In line with naming conventions in this API, this should be `_num_constants`.
and -> or
All of this should be delegated to the parent's `__call__`.
Unnecessary blank line
There is no longer any check that the initial states are Keras tensors, which will cause the model construction to fail when using non-Keras tensors.
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
This should be max.
Same: don't mention specific axes
cropping, not padding
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
Yes, that would make sense.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Make this method private and add a docstring explaining its purpose.
Typo: space after `uuid,`
This should be tensor3 instead of matrix.
remove unused keyword `args`
This should be a private method, I believe
Yes, all private methods in the Keras codebase use a single leading underscore. Thanks!
Sleeping with a lock held seems bad. Shouldn't it be sufficient to guard this line with the lock: ``` generator_output = next(self._generator) ```
Ok, I had overlooked that. I think this should be enforced via an exception. Knowing from the start what you did wrong is better than a failure at training time due to shape incompatibilities.
This divides the input into halves of size output_dim/2 that are then concatenated. The size of the output might not be output_dim anymore (eg: python(13/2) = 6; 6+6=12).
With not mask, how do you handle a batch with different sequence lengths? Said a batch of 2, with first input have lenght 2 and the 2nd has a lenght 4. Then you would do a right padding on the 1st sequence to make it have length 4. In you implementation without mask, for the 1st input, the **true** energy should be `b_start + x1' y1 + x2' y2 + y1' U y2 + b_end` but in your implementation, there isn't a `b_end`, but with an additional `x3' y3' + x4' y4 + y2' U y3 + y3' U y4`, where `y3 = y4 = 0`. The consequence is, the above two formulations are not equivalent, at least when you take derivative with respect to `U_00` (top-left element in matrix `U`), the derivative isn't the same. Right? (also, `U_00` and `U_11` are not `exchangable`, but why we treat label 0 and label 1 differently?) Also when you compute the normalization constance (free energy in your code), you have to integrate over `y3, y4` (which are paddings). I guess that's what you mean by "padding elements act as a virtual end label". However, if when you think about taking derivative with respect to `U` or `b_end`, your approach is not equivalent to a real CRF. One very obvious observation is, `y3, y4`, the padding, affects the derivative with respect to `U`, and therefore, the paddings plays a role on the final outcome. The more paddings you have, the more impact the paddings affects the outcome. This is unexpected from my point of view. Lastly, another simple observation, a model with and without the end energy (`b_end`), the numbers of trainable parameters are not the same. So the two models are not the same.
You could standardize the weights in `input_validation`, return a dict, then turn the dict into a list afterwards. That way you still have the dict around for `evaluate`, but weight standardization is being done in just one place.
Put `int):` on the same line for readability.
PEP8: quote character should be `'` for consistency. Add spaces after `,`. Replace `weights` with `sample_weights` for explicitness.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Please add a note saying that the learning_phase should be added by `fit_generator`, otherwise it's a little confusing.
This is the non-generator path. 0 is added to val_data here : https://github.com/keras-team/keras/pull/9796/files/86e5448ff06d30bebfdf8a4781562ad6abaabd1c#diff-b25d82c3f751f73f6e62b8455547ac73R124
Code markers around tuple
Use `'` everywhere for consistency. Do not break lines with `\`
This would be very inefficient and would cause EOM errors even for smallish datasets. Please use instead the approach of `predict()` (preallocating entire arrays as soon as their shape is known, then assigning values inside the preallocated arrays). This is doable because the number of samples that are expected is known (`val_samples`).
`all_outs` is meant to be a list of arrays (potentially with 1 element), not a Numpy array, because we need to support multi-output models (the present code wouldn't). Same for `outs`. So I would recommend following the pattern from `evaluate_generator`: converting the output of `self.predict_on_batch` to a list if necessary, etc.
Please explain the need for this new method
Is there a reason why `training` defaults to `False`? If this is primarily meant to be called by the training library, having no default value and forcing the caller to be explicit seems preferred.
Default to False, not None
Here rather than using __call__ (which we deliberately disable with non-TF backends), we should use a new internal method
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
Code markers around tuple
this is discussed in https://github.com/fchollet/keras/pull/7113
Code markers around `validation_split`
Use `'` everywhere for consistency. Do not break lines with `\`
When a mask is provided, it means that the input has time steps. However the input might not necessarily be `(samples, timesteps, dims)`, it should more generally be considered to be `(samples, timesteps, **)` (e.g. sequences of pictures).
I don't know enough keras, but what is the dtype of the mask? int64? If the mask is of type int8, there won't be upcast. I think I would use a mask of the same dtype as the input, so floatX when it is created. This could lower transfer depending of the rest of the models.
float32 + int32 will upcast following c casting rules. This is normal. not all int32 fit exactly in a float32. So not doing the upcast have problems in some corner case. Theano casting rules is very close to c casting rules. int8 and int16 won't cause this upcast. The current GPU back-end only support float32, so this can cause is some corner case extra transfer. Making the mask int16 would be better then int32, as the upcast could happen elsewhere where that int32 mask is used. On Thu, Jan 7, 2016 at 3:24 PM, Ozan ÃaÄlayan notifications@github.com wrote: > In keras/models.py > https://github.com/fchollet/keras/pull/1419#discussion_r49121301: > > > @@ -81,6 +81,8 @@ def weighted(y_true, y_pred, weights, mask=None): > > # score_array has ndim >= 2 > > score_array = fn(y_true, y_pred) > > if mask is not None: > > - # Cast the mask to floatX to avoid float64 upcasting in theano > > - mask = K.cast(mask, K.floatx()) > > Well I'm not an expert of keras nor theano. I also sent an email to > theano-users list today but didn't receive anything yet: On my system a > multiplication of float32 and int32 in theano results in creation of a > float64 tensor. Here the mask is int32 and the score_array is float32. > > Are casts causing transfer between host and device? > > â > Reply to this email directly or view it on GitHub > https://github.com/fchollet/keras/pull/1419/files#r49121301.
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Specify an epoch number
Format your docstrings like other docstrings in the codebase
If we were to use a epsilon here... it should be abstracted as a globally configured epsilon. Also, I think this value is too low and would cause issues with GPUs (float32). But anyway: we shouldn't. If the sum of the weights is zero, then the problem is ill-defined and a loss cannot be computed. We should throw an exception in that case.
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
Don't use this pattern. No try/except block here.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
"on how masking is handled by the wrapped layer"
Need at least rank 3
I am cool with such a docstring style, it's neat and informative. But then it would need to be matched everywhere else in the repo.
Use a space after `,`
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
Change to 0. Also please format code elements in docstring with "`" (tuples. dicts).
The indices of the axes depend on the dim ordering. Just say "width and height"
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Same: don't mention specific axes
Why not turn this into a warning? Seems preferable, if only to avoid breaking existing code that might do this.
This is already validated in the constructor, no need.
It doesn't really make sense to me, because random transformations are important to have at test time as well (because they modify the statistics of the data). Best evals are from multiple random transforms, with results merged via power averaging.
Set default `batch_size` to None, like in `fit`.
Introduce an `if` block to avoid a very long line.
Please make this method private (unless there is a rationale for making it part of the public API).
I don't understand why; `tf.nn.separable_conv2d` does support strides.
Please make this method private.
Please introduce line breaks in the docstring to avoid very long lines.
I believe you don't need this method, the inherited one should work fine.
Make this method private and add a docstring explaining its purpose.
Typo: space after `uuid,`
Space after #
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
Use code markers around `put()`
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Remove leading space
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
This won't do anything (need to be a global)
Let's add a TODO for this one
Per the failing docstring test, this docstring needs a `Raises` section mentioning the ValueError: https://travis-ci.org/fchollet/keras/jobs/282558708
Please make this method private (unless there is a rationale for making it part of the public API).
Please make this method private.
Let's add a TODO for this one
Let's add a TODO for this one
Let's add a TODO for this one
Let's add a TODO for this one
Should not be public
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
At this point it would be fine to have `np_kernel = kernel.eval()`
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Most of this stuff is included in the config of `super` and thus does not need to figure here.
Same: don't mention specific axes
cropping, not padding
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
This should be max.
Incorrect / confusing. Please fix.
No return section in such cases.
This is somewhat problematic because this will be ignored in most Keras functions. But that's a separate problem I suppose, which we will fix in a different PR.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
No `+` needed for string concatenation at the end
"samples drawn from"
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
@Dref360 I can throw a specific exception for the case a data element should be just skipped.
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
Use code markers around `put()`
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Remove leading space
This should definitely be a function, taking two arguments.
This won't do anything (need to be a global)
CTC decode isn't finished yet. Let's add it to the docs only when finished.
Let's add a TODO for this one
Let's add a TODO for this one
Let's add a TODO for this one
Let's add a TODO for this one
Should not be public
Let's add a TODO for this one
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
No `+` needed for string concatenation at the end
No need for `+` at the end. But needs a space after `.`.
Better to use `_keras_history`
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
Yes, that was changed some time ago. The doc should be updated.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
num_train_samples != steps_per_epoch, though. A step is a batch, not a single sample.
Prefer `if steps_per_epoch is not None`
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
"When using `steps_per_epoch`, ..."
Docstring should have a `Returns` section and a `Raises` section.
Set default `batch_size` to None, like in `fit`.
You don't need a lambda here. Also, don't break lines with `\`.
Use `'` everywhere for consistency. Do not break lines with `\`
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Code markers around tuple
Reshaping is appropriate in this case, but only in this case.
Better to check whether the layer's call method accepts the `training` and `mask` arguments.
This mechanism will only work for a few layers, and will fail in the general case. The proper behavior when batch size matters is to slice the input mask and run slices through `self.layer.compute_mask`, then concatenate. No reshaping.
This won't work, since the shape of the mask won't match the shape of the input.
`K.int_shape(inputs)` will not always be available.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
No, this should always be entered if `input_shape[0]`.
This should be a `ValueError` (never raise `Exception`).
Should be `inputs` and `mask`.
No reference to `_keras_shape`, that's an implementation detail. Call it "static shape"
does this assume all the images have the same shape? If so, varying image dimensions should be handled, and some kind of target dimensions could be utilized to apply padding to the images so they are all the same size. reference code: https://github.com/aurora95/Keras-FCN/blob/370eb767df86f364d93eff9068a3edb0b194a18b/utils/SegDataGenerator.py#L221 https://github.com/nicolov/segmentation_keras/blob/master/utils/image_reader.py#L79
enumerate is not needed here. i is not used
Do not need the enumerate here. i is not used.
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
This should be max.
Line too long, and not PEP8 compliant. Break it down into a few lines.
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
That sounds good. There may be confusion with the concept of `op` in TF though (e.g. a dot product). But maybe not a big deal.
I also don't think the confusion with TF ops is a big deal. As long as the docstring makes it very clear what is being counted. One more note: I don't think op counting is a common enough use case that it should be displayed in `model.summary()`.
I vote `count_ops` since it is more consistent with `count_params`
Some of your lines are too long. We don't strictly enforce line length, but please do your best to follow PEP8.
So you always return None in mode `channels_first`? Why? That's not the expected behavior.
This formula is wrong for most convolution layer configs because it doesn't take into account padding and strides
The formula is wrong because `np.prod(self.output_shape[1:-1])` is not the number of positions where the kernel is applied, it is the maximum number of positions.
@fchollet Does the output shape include padding? That may be the problem you're referring to. I tried to think of any other way the output shape would not be equal to the number of positions the kernel is applied, but as far as I can tell input stride and input padding are already taken into account by this. A specific counter example would be greatly appreciated.
This seems strangely ad-hoc
The base layer should raise an error actually or None. Depend if we want everyone to provide this service. Every layer in keras' repo should provide this
Only the `tf.eye` supports the non-square. Currently, all the three `K.eye`s don't support that, thus I proposed #12534.
`K.eye` should already follow this same behavior (at least it does in TF). So no padding necessary.
I think we could refactor this to call `K.eye` instead. The advantage of `K.eye` is that for TF it will not store the numpy array returned by `np.eye` in the TF graph (so the graph will be smaller).
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
"samples drawn from"
Same: don't mention specific axes
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
cropping, not padding
Line too long, and not PEP8 compliant. Break it down into a few lines.
@ns3284 Squash function has to be applied according to paper.
Throughout this file, `"` is mixed up with `'`. Only use `'`, for consistency.
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
Better to put the activation as the `activation` keyword of the layer below
Remove blank line
Prefer importing `layers` then using e.g. `layers.Conv2D`
That's something we should fix in the Keras backend.
Explain what the difference is and what motivates it
Format your docstrings like other docstrings in the codebase
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
This is the TF backend, so don't rely on `_keras_shape`, instead use `tuple(kernel.get_shape().as_list())` (always available).
These should be `ValueError`
I don't understand why; `tf.nn.separable_conv2d` does support strides.
At this point it would be fine to do the dimshuffle without the call the `_postprocess_conv2d_output`
At this point it would be fine to have `np_kernel = kernel.eval()`
Use `'` for strings for consistency with the rest of the file.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
Processing of `np_kernel` should be removed from this function
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
`new_shape_temp` will be deleted automatically after the return statement. There is no need to delete it explicitly.
Oups, sorry, my bad. You are right! Please proceed with the temporary variable.
Can you make multiple statements for this one too? Thanks!
Looks great to me. :)
Parens not necessary here
No, this should always be entered if `input_shape[0]`.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
Please add a docstring.
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
These should be `ValueError`
`predict` and `evaluate` with data tensors should have unit tests as well.
Use `train_dataset` and `val_dataset` as the names
Specify an epoch number
Please use lowercase variable names.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Good catch! yeah there should be a warning.
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
"the input name to a Numpy array" (singular in this case, for `Sequential`)
This is already validated in the constructor, no need.
This is a significant regression which breaks a lot of my code too.
I feel like it would actually be clearer and more economical to separate the two cases entirely: one input vs. multiple inputs.
I fear this is a brittle mechanism. It will work in simple cases but will fail in advanced cases.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
Please introduce line breaks in the docstring to avoid very long lines.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
Prefer more explicit variable names.
PEP8: space after comma
This is a new layer so no API conversion decorator is necessary.
Use `'` for strings for consistency with the rest of the file.
Blank line required before the next section
Blank line required before the next section
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Use list markers
Need to fill in this section
unused variable `input_length`
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
`predict` and `evaluate` with data tensors should have unit tests as well.
No need to capitalize Input or Tensor
num_train_samples != steps_per_epoch, though. A step is a batch, not a single sample.
I verified. Looks great!
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
this is discussed in https://github.com/fchollet/keras/pull/7113
Insert link to callbacks page
"When using `steps_per_epoch`, ..."
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
Prefer `if steps_per_epoch is not None`
As a user, what can I do, knowing that I can now feed a Layer to the `metrics` arguments? Can I feed any Layer? (No, but some will try)
There is a problem here. `_feed_input_names` is the list of model *inputs*, but `ins` refers to list of the Keras function input placeholders. Typically, ins = model_inputs + model_outputs + sample_weights. Your setup will still work, but the conversion doesn't get applied to targets.
How is there any difference between this and `on_epoch_end`? In practice, both are called in succession, with nothing in between.
You can remove this part. If training from symbolic tensors, there is no need to convert input arrays because there are no input arrays (and `indices_for_conversion_to_dense` will always be empty).
In which cases would this be needed? It may be better to defined a proper private function than a very long named lambda. e.g. ``` python def _expand_if_needed(input, mask): ... ```
No, do not do this
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
I vote for option number two. That seems the most consistent with other parts of the Keras API.
Just `# Arguments` to be consistent
If the default is 0.5, then I would suggest to put `def __init__(self, threshold=0.5):`
The CNTK errors on Travis CI seem to come from this line. `self.bias[0]` results in a `(1, 3 * self.units)` 2-D tensor in CNTK.
I understand your points. Thank you for the explanation.
Nitpick, but the line would be more readable if `padding` was a list instead of a tuple (many parens here).
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
Use `'` for strings for consistency with the rest of the file.
Better to add `rank` here
Most of this stuff is included in the config of `super` and thus does not need to figure here.
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
This is Theano syntax and breaks with TF. Use `K` instead.
unused variable `input_length`
Add imports to make the script compatible with py2/3: ```python from __future__ import absolute_import from __future__ import division from __future__ import print_function ```
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
You don't need BN for such a shallow network, `Conv2DTranspose` with relu activation and strides should suffice
You don't need this, `Conv2DTranspose` with strides should work better
Better to put the activation as the `activation` keyword of the layer below
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
Better to put the activation as the `activation` keyword of the layer below
filters //= 2
Good catch! yeah there should be a warning.
Fix indent. Use `pylint` as linter.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
Just import `utils`
One import per line. Also import `models` so as to avoid `tf.keras` calls in the code. This *is* the Keras codebase! It should import internal modules, not `tf.keras`.
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
I mean `RuntimeError`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
You should not be importing `keras` here. You can use `K.placeholder` to create a placeholder.
You should provide empty shape like you did in next line. You can find the reason in the cntk backend code: ```python def placeholder( # ... if not shape: if ndim: shape = tuple([None for _ in range(ndim)]) # shape is None and not iterable. cntk_shape = [dynamic_dimension if s is None else s for s in shape] ```
In addition to type, I think you should also check the value after clipping by placeholder variable.
No `+` needed for string concatenation at the end
var is a reserved keyword, use `v` or something like that.
Good catch! yeah there should be a warning.
Not a useful example. Instead please have examples dealing with larger input shapes (e.g. 3D, 4D).
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
Line too long (and several other lines in this file as well)
```suggestion if k == KC: ```
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
Please keep the random tests where they were. Unit tests should be small and target as few things as possible for better error reporting and debugging.
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
Good catch! yeah there should be a warning.
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
Past few lines too long
Still relevant? If so, explain the diff
Line too long
Yes, it would make better sense in `build`.
I think `if self.dropout > 0 or self.recurrent_dropout > 0` is more clear.
`input_spec` contains constraints that future inputs should respect. This statement would set the length of the first input as a length constraint, but unless the network is unrolled there should be no constraint on length. This is in part what the previous TODO was referring to.
This one is fine
You don't need `+` to do string concatenation across two consecutive lines
Nitpick, but the line would be more readable if `padding` was a list instead of a tuple (many parens here).
Please shorten line (break after `(`)
The indices of the axes depend on the dim ordering. Just say "width and height"
Yes, that would make sense.
This reshape will fail for some shapes (all inputs X where X.shape[1] is odd) because the number of elements in the tensor will not be conserved. Additionally it appears that the maxout is done only of the 1st tensor dimension (indexing from 0). This would be time in case of a temporal input, of channels for a picture input. I don't thinking that's how it should work in these cases (it should be respectively the 2nd and 2nd-3rd dimensions).
To show how to handle the output shape, let's not add keepdims
` x1 = Dense(32)(input_1)` is enough for an example.
It should be return [tuple(shape1), tuple(shape2[:-1])]
I suggest x_hadamard, x_sum instead of x, _
Not a useful example. Instead please have examples dealing with larger input shapes (e.g. 3D, 4D).
Use a space after `,`
> tf.ragged.constant does not accept tf.Tensor inputs gracefully It's really strange that it works with numpy arrays but not tf.Tensors. That's an inconsistency in the ragged API that we should address...
Theano -> Theano/TensorFlow
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
@tiferet the API change in `sparse_categorical_crossentropy` is not something we can merge, sorry. Such an argument should be called `axis` and should default to `-1` (`K.image_data_format()` is a layer-level configuration argument and should not affect the default behavior of backend methods).
For now, after adding `axis` in the crossentropy losses, you will have to use a different loss function when doing pixelwise classification (image segmentation) in NCHW: ```python if K.data_format() == 'channels_first': loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(y_true, y_pred, axis=1) else: loss = K.sparse_categorical_crossentropy model.compile(optimizer=optimizer, loss=loss) ```
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
About this test: - please use the same docstring format as elsewhere in the codebase - use `'` as quote character for consistency - use lines that are <= 80 char
This is a significant regression which breaks a lot of my code too.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
This is correct.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Break into `if/else` blocks, for readability
This is just `{0}`
`_check_array_lengths` was arguably a better name
`_set_keras_shape_for_reduction` would arguably be a better name. This can be reused for any reduction op (sum, etc).
Why not return `None` instead? Wouldn't it be more efficient (one less element-wise multiplication in the objective function).
Forgot a space ```suggestion ' If your inputs are not batched,' ```
This is already validated in the constructor, no need.
add space after `(w[1])`
@ns3284 Squash function has to be applied according to paper.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
No need for final space
No need for final space
Spaces at the end of lines
No need for final space
No need for final space
No need for final space
Please provide a more detailed error message, including a suggestion of what the user should do to fix the issue. The current message would not be immediately understandable by users.
Parens not necessary here
Need spaces at the end of every line in this message (this is also true of a few other messages)
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Also I think the line does too much, breaking it into several lines would be preferable.
Not a useful example. Instead please have examples dealing with larger input shapes (e.g. 3D, 4D).
The notation seems unusual (`y`, `_y`, `__y`). Please find something more descriptive and conventional
Prefer making multiple statements, it will be easier to read than breaking the statements into multiple lines. Breaking lines should only be done if necessary. ```python slices = [] for i in range(x.ndim): .... ```
I wonder if this whole loop could be simplified somehow? It has a clear recursive structure. The same code should be generalizable to 1D/2D/3D/etc without having to manually unroll the loop.
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
Please introduce line breaks in the docstring to avoid very long lines.
This doesn't seem to take into account the case `NCH`? Only `NCHW` and `NCDHW`
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
Still relevant? If so, explain the diff
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
To be clear, the idea (to my understanding) is that `OrderedEnqueuer` will be the class that knows about `batch_size`. The generator that `fit_generator` receives is constructed in `DatasetEnqueuer.get()`. This generator pops `batch_size` items from the queue and then calls `self.dataset.create_batch(lst_items)` to obtain the actual batch.
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
I like this!
I just realized that I missed something important. These `indexes` are not the indexes of individual samples. These are indexes of batches. It means that forever you will have the same samples in the same batch, even if you shuffle the indexes. It takes the edge out of some important operations (i.e. batch-normalization). I find this a bit confusing. What I would expect is that the Dataset will store samples, not batches, and that `getitem` would return a single sample. I don't think that a Dataset should know about the `batch_size`. It makes more sense to me that the packaging of the samples into batches would happen on the fly, in the `DatasetEnqueuer.get()` method. If the `batch_size` is 32, then Enqueuer should pop out 32 elements from the queue (or less if there is a StopIteration), and call a `batcher` function (perhaps it can be provided by `Dataset`) that turns a list of samples into a batch.
@Dref360 yes I think it is best to keep the same behavior as before.
In any case, this PR is a great addition for Keras, thank you!
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
The ValueError should be listed in the docstring. The error message should specify what was passed, and the list of values expected instead.
Also style: use `target_height` / `target_width`, no point in removing two characters.
Use `'` as quote char for consistency
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
Spaces around operators
I think these layers would benefit from having more transparent names.
Forgot a space ```suggestion ' If your inputs are not batched,' ```
Please introduce line breaks in the docstring to avoid very long lines.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Why not just pass the target directory? This is all your need to perform this task.
Use `directory` for consistency
This will warns a tremendous amount times, isn't it? I would just do a check before returning.
`start`/`stop` is flexible since it means `_count/list_valid_files_in_directory` will be agnostic to the validation/training story, and only needs the `split` argument. But it doesn't make a big difference.
You can make the whole PR a lot simpler by using: `for fname in sorted(files)[start : stop]` Remember: this feature should only total a few lines of change. The only "logic" required by this PR is the computation of `start` and `stop` above given the `validation_split` passed by the user (if any).
`split` can be reserved for internal methods, as it isn't very user-friendly. For user-facing APIs, we can go with your original proposal: ```python generator = image.ImageDataGenerator(validation_split=0.5) train_iterator = generator.flow_from_directory(image_dir, subset='training') val_iterator = generator.flow_from_directory(image_dir, subset='validation') # This should also be possible train_iterator = generator.flow(x, y, subset='training') val_iterator = generator.flow(x, y, subset='validation') ```
Sorting is actually important.
Ok then. The message is missing a space for the period, please fix
IMO yes or we shouldn't accept tiff at all. We'll get complaints that some .tiff are not handled correctly.
Link on a single line, otherwise it won't work (we don't enforce line length)
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
Processing of `np_kernel` should be removed from this function
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
At this point it would be fine to have `np_kernel = kernel.eval()`
At this point it would be fine to do the dimshuffle without the call the `_postprocess_conv2d_output`
Change to "pooling over conv_dim2 and conv_dim1"
Blank line required before the next section
This should be refactored to eliminate code redundancy. The conditional flow should affect the reshape ops.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Link on a single line, otherwise it won't work (we don't enforce line length)
In general your docstrings have an indentation problem, the lines after the first one should be indented by 1 level (4 spaces).
I don't understand why we would want to deprecate md5, or have a preference for one algo or another. It's cool to support more than one hash function, but md5 works just fine for this purpose. We're just building a basic cache invalidation mechanism.
Just say "either md5 or sha256".
This default value will not work with Windows. Use None instead, and set it in the function code.
Just for reference for newbies, in windows, the cache folder is at C:\Users\USERNAME_HERE\.keras\datasets. I usually download the files manually and place them because sometimes it does fail downloading in my computer.
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Newline before this line
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
The `bn%d` looks unnecessary.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
I mean `RuntimeError`.
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
Please remove new line (`"""Instantiates`).
`)` after `]`
Looks good to me now.
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
You don't need to specify this field if there is no return output
`# Returns `
This default value will break loading old model files.
Space between arguments (PEP8).
Please put the new parameters on a new line
The `output_dim` / `initial_output` business should definitely be eliminated by all means necessary.
I see no need to add a `constants` argument to the `rnn` API. It can be made part of the states (and the whole logic will be handled at the level of the `step` function of the RNN layers, as it should be...).
"not currently supported with CNTK".
You are setting this to True but don't seem to be using the learning phase in the code.
There is already a variable named `initial_weights`. To avoid confusion, please use `reset_weights`.
I mean, it's a pretty serious inconsistency.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Please rename to `preprocessing_function`. Please improve the docstring by specifying: "The function should take one argument: a batch of images (Numpy tensor with rank 4), and should output a Numpy tensor with the same shape."
This function does not have a properly formatted dosctring (see other dosctrings for reference)
Make this method private and add a docstring explaining its purpose.
This one is fine
Should be named `apply_brightness_shift`
Good catch! yeah there should be a warning.
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
`if unknown is not None`
Since this function is only called once, consider in-lining it (not saying you *should* do it, but consider whether it would improve the code if you did it -- maybe it would).
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
Better to add `rank` here
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
No point in calling super here
Looks good to me now.
No return section in such cases.
This should be "Returns", not "Return" (same for every occurrence in this file).
This is somewhat problematic because this will be ignored in most Keras functions. But that's a separate problem I suppose, which we will fix in a different PR.
Incorrect / confusing. Please fix.
This is primarily meant for tensor casting, not variable casting. Albeit you could cast a variable (thus returning a tensor).
"samples drawn from"
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Typo: output. It should be clarified that it needs to be a valid Theano expression.
Same remark as before regarding `output_shape`.
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
cropping, not padding
Same: don't mention specific axes
cropping, not padding
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
The indices of the axes depend on the dim ordering. Just say "width and height"
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
Processing of `np_kernel` should be removed from this function
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
At this point it would be fine to have `np_kernel = kernel.eval()`
At this point it would be fine to do the dimshuffle without the call the `_postprocess_conv2d_output`
Change to "pooling over conv_dim2 and conv_dim1"
Blank line required before the next section
This should be refactored to eliminate code redundancy. The conditional flow should affect the reshape ops.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
There could be multiple model outputs
"output names to Numpy arrays"; "`y` can be"
Same, can be a list
"input names to Numpy arrays"
this is discussed in https://github.com/fchollet/keras/pull/7113
This will be more readable with code markers around `epochs`.
Code markers around tuple
Code markers around `validation_split`
Code markers around code keywords (`)
"the parameter" is redundant, you can simply say `epochs`
Incorrect / confusing. Please fix.
This is somewhat problematic because this will be ignored in most Keras functions. But that's a separate problem I suppose, which we will fix in a different PR.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
var is a reserved keyword, use `v` or something like that.
Better to use `_keras_history`
No need for `+` at the end. But needs a space after `.`.
Better to use `_keras_history`
No `+` needed for string concatenation at the end
"samples drawn from"
Incorrect / confusing. Please fix.
Better to use `_keras_history`
No `+` needed for string concatenation at the end
No need for blank line
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for `+` at the end. But needs a space after `.`.
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
"samples drawn from"
Should we rely have to rely on `np.dot`? Besides the fact that it's expensive, it's also a black box. The logic should be inferable from reading the code.
`_set_keras_shape_for_reduction` would arguably be a better name. This can be reused for any reduction op (sum, etc).
@farizrahman4u Undefined variable `K`
@farizrahman4u Isn't `ndim` always going to be 1 for `n`, I think you meant the equivalent of `len(n)`
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
Also I think the line does too much, breaking it into several lines would be preferable.
Forgot a space ```suggestion ' If your inputs are not batched,' ```
PEP8: space after comma
I don't get why you are introducing this unused argument.
Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.
`compile=True` is a more user-friendly API.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
No warning should occur with default settings. It is safe to remove this.
Break up line
`nb_val_worker` should be described in the docstring.
Introduce line return after `(` to reduce line length
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
Should be on the same line as the argument.
PEP8 error. Use a PEP8 linter.
Should we rely have to rely on `np.dot`? Besides the fact that it's expensive, it's also a black box. The logic should be inferable from reading the code.
This should be max.
The notation seems unusual (`y`, `_y`, `__y`). Please find something more descriptive and conventional
Past few lines too long
This doesn't seem to take into account the case `NCH`? Only `NCHW` and `NCDHW`
Line too long (and several other lines in this file as well)
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Still relevant? If so, explain the diff
Line too long
Move to the line below in order to keep each line under 80 char.
Use `train_dataset` and `val_dataset` as the names
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Blank line required before the next section
Break up long line
Need to fill in this section
Use list markers
Use bullet points
You can use `K.is_keras_tensor`
Indeed, or you can just increment the input seed for each new process.
In that case the first seed can be used to generate separate seeds for each sub process before the fork
add param to provide a seed at init time
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
@Dref360 I can throw a specific exception for the case a data element should be just skipped.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
@Dref360 yes I think it is best to keep the same behavior as before.
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
In any case, this PR is a great addition for Keras, thank you!
"This allows for"
"Number of epochs to wait for before..."
`try` with an `assert` is not the way to test inequality between two integers...
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
I really don't see how incrementing `self.wait` at the end of each epoch is the correct behavior. You have access to the epoch counter `epoch`, if you just want to skip the first epoch you can? E.g. if it's the first epoch, then set the best score / weights and continue.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Insert link to callbacks page
this is discussed in https://github.com/fchollet/keras/pull/7113
Code markers around `validation_split`
Code markers around tuple
grammar "Please consider using"
`data_utils` is no longer meant as a public namespace, use `utils`
`data_utils` is no longer meant as a public namespace, use `utils`
That last sentence will be very difficult to understand for people who don't have further context.
What about failure cases? Example: #6928 it is possible only x, only y, neither x nor y, or a tuple of some other unexpected size gets returned. At a minimum, check the tuple size and throw an exception if it doesn't match expectations. There are probably other cases like this in this pull request, it might be worth double checking.
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Use code markers around `put()`
Remove leading space
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
In that case the first seed can be used to generate separate seeds for each sub process before the fork
Previous version was more readable imo.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
`# Returns `
You don't need to specify this field if there is no return output
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
Better to put the activation as the `activation` keyword of the layer below
Better to put the activation as the `activation` keyword of the layer below
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
filters //= 2
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
In that case, I think this error and the corresponding test should be kept.
`batch_size` parameter needs to be deprecated too.
Please remove these changes so that this callback has the same behavior as the other callbacks. It could be discussed in another issue/PR.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
PEP8 issues (space around operators)
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Please raise a `NotIplementedError` when the use case is not supported yet.
You could do that with Matplotlib, to avoid a new dependency
Add these 3 classes to `utils/__init__.py` so they can be imported from `utils` by users (internally it doesn't matter)
This should be kept (for namespace consistency: you want to be able to import `inception_v3.decode_predictions`).
There are added empty lines. Please remove them.
Throughout this file, `"` is mixed up with `'`. Only use `'`, for consistency.
Surely this should be `.name`
Then the serializer should be updated, and metrics classes should have a `get_config`/`from_config` method
Let's not include that.
Prefer importing `layers` then using e.g. `layers.Conv2D`
I believe you should be able to remove a lot of redundant code by subclassing `RNN`. There are lots of shared methods.
Oups, sorry, my bad. You are right! Please proceed with the temporary variable.
Can you make multiple statements for this one too? Thanks!
`new_shape_temp` will be deleted automatically after the return statement. There is no need to delete it explicitly.
I think it would be good to assert than the input tensor is at least 3D (to avoid a more obscure error message later).
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
Just `# Arguments` to be consistent
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
If the default is 0.5, then I would suggest to put `def __init__(self, threshold=0.5):`
Actually, what we do right now is, when running travis, we compare: * theano against numpy * tensorflow against numpy * cntk against numpy those are three different jobs. If one backend is wrong, the corresponding job will fail. If the numpy backend is wrong, the three jobs will fail. Running some kind of correctness computation is really difficult to do right, because you would need to use random input values to ensure correctness in a majority of cases. But then if you take random values as input, it's very likely that you won't use a paper and a pencil to compute the expected output. You'll likely use numpy. So I think this is our best bet to avoid shallow tests. After all this, I didn't dig much into the rnn implementation in the numpy backend, so I can't guarantee that it supports your use case. And if it does not, it would surely fall outside the scope of this PR, and we're better off with your implementation of the tests for sure. After a bit of digging into the git blame, I found that the numpy RNN implemtation was done there: #9557 Maybe @taehoonlee can tell us more about it? Otherwise I'm fine with the tests that you made if it means changing a lot of code to adapt it to my request. I don't intend to make you do too much extra work since you're already helping a lot with your frequent PRs and discussions :)
Nit: use `num_` for counters, for consistency
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
Should be `inputs` and `mask`.
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
Clarify the error message; a "Keras tensor" is the output of a Keras layer
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
I believe you don't need this method, the inherited one should work fine.
You can use `K.is_keras_tensor`
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
Should probably be int in both case. We don't want separate cases to handle.
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
I vote for option number two. That seems the most consistent with other parts of the Keras API.
Should be `inputs` and `mask`.
In which cases would this be needed? It may be better to defined a proper private function than a very long named lambda. e.g. ``` python def _expand_if_needed(input, mask): ... ```
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
@farizrahman4u this is still not fixed.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
For theano, `ratio` needs to be `integer`. ```python ratio = height_factor // width_factor ```
I am also wondering whether it is necessary to specify the original height and width as part of the arguments (this information is part of the tensor X).
It is looking like `height_factor` and `width_factor` can only be positive integers. This should be specified in the docstring. The API makes it sound like `*_factor` could be a float (e.g. 0.75 for an output image with 75% of the original height).
maybe tell the user the valid data_formats
in the tests k.backend() == `cntk` might want to lower case here
It seems like the rest of this file generally adheres to an 80-character limit per line.
"all three factors"
Line too long (and several other lines in this file as well)
this value error is good but do in other places
Suggest to make `data_format` as argument of `_helper_bilinear`. Then parameterize `test_resize_images_bilinear` with `data_format`. Otherwise, you may not be able to test both `data_format` with `pytest.raises`.
Replace with ``` if len(mask.get_shape()) > ndim: raise ValueError(...) ```
Spaces around `=` please.
Nit: use `'` as the quote character, for consistency
Nit: use backquotes around code keywords
In which cases would this be needed? It may be better to defined a proper private function than a very long named lambda. e.g. ``` python def _expand_if_needed(input, mask): ... ```
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
I vote for option number two. That seems the most consistent with other parts of the Keras API.
Should be `inputs` and `mask`.
No, this should always be entered if `input_shape[0]`.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
Would it be possible to simplify by doing ```python if axis is not None: axis = tuple(axis) ```
You are right. My bad. I dont think it's necessary to use an intermediate variable though: ```python if isinstance(axis, list): axis = tuple(axis) ```
For numerical stability, you have to do T.exp(x - x.max())
Could you try benchmarking this against the use of `transpose + softmax + transpose`? It may be that transposing is faster (but impossible to know in advance).
The exact transposition depends on the `axis` value and `x.ndim`. But we'd only need to benchmark it for one configuration. For `axis=2` and `x.ndim=4` your code looks right to me.
I am not seeing much reusability for these 5 functions at this point. Maybe it would be better to only change the Matthews correlation implementation without adding new functions to the backend.
Also rewrite this description assuming an integer axis.
`_set_keras_shape_for_reduction` would arguably be a better name. This can be reused for any reduction op (sum, etc).
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
Shapes mentioned in the docstring are generally 2D; should be 3D
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
> Train a model and store every bit of it, including optimizers, in case you want to pick it up later for further training etc. In this case it makes sense to have the compiled version at hand. At least I would like to have the option to have a compiled version. Sounds very useful, but there are further problems with implementing this: for instance, how do you save the state of the optimizer for further training? That state is contained in shared Theano variables. I have no strong opinion either way, the main argument I see for skipping compilation is the use of custom objectives (custom optimizers are relatively unlikely, much like custom regularizers and constraints, however custom objectives are fairly common).
It's the same hack, but the big difference is that `get` is only used in small files where the set of names you want to be able to "get" is identical (or close enough) to the entire namespace. Which makes it safe. The reason this hack is potentially dangerous in the first place is the likelihood of namespace collisions, and they are highly likely in a file as busy as `models.py`. So I'd rather import each module separately, then use `getattr` on the appropriate module name. Then we limit the use of the namespace to the name of modules, which is fine.
You can change line 263-269 like this: ``` ndim = len(self.output_shape[i]) if ... else ... weight = ... ``` and you can do the same in other such places.
may be use a local variable here and in the cases below to avoid code duplication? ``` ndim = len(self.output_shape[i]) if ... else ... weight = ... ```
Using if/else here definitely improves readability. In the previous discussion I had request to de-dup the code for creating placeholder which you have done already.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
Use `'` everywhere for consistency. Do not break lines with `\`
Prefer using `if isinstance(...):` / etc: it makes lines shorter and more readable, and it will be extensible to more types in the future.
This probably won't help with your actual problem, but the following PR was very helpful when I needed to fix feed dict issues: https://github.com/fchollet/keras/pull/7064
The paragraph above can be replaced with `layer.weights`, which is always implemented.
If write batch performance is false self.seen should probably be equal to the epoch so the current behavior remains unchanged.
`_merged_summaries` is added to fetches when the callable is created for the first time. That means the summaries are computed at every call, even when `_merged_summaries` is None (but only added to the writer when `_merged_summaries` is not None). Also it means that if `_merged_summaries` is None when the callable is created, `_merged_summaries` will always be ignored henceforth. You need to store `_merged_summaries` as a Function attribute and refresh the callable when it has changed (like we do for input tensors now).
BTW, if this issue isn't being detected in tests then I suspect there isn't sufficient test coverage.
PEP8 issues (space around operators)
The class docstring should explain the meaning of the arguments.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
It should be clarified in the docstring what "compilation" entails.
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
This will break if `layer` is a container.
Optimizers have a `get_config` method precisely for this purpose.
`compile=True` is a more user-friendly API.
An optimizer instance is not serializable (it's a Python object). The previous 4 lines were serializing it. Revert this
should be self.forward.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
Style: break long lines in the test
Is this try/except necessary? It's a test
No need for this line
@ns3284 Squash function has to be applied according to paper.
PEP8: spaces around operators
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
Use `'` everywhere for consistency. Do not break lines with `\`
Nit: please shorten lines (here and above).
No need for the extra space at the end of the lines.
Nit: please shorten lines here to 80 char or less (also in `initializers.py`)
I see you are a Theano user. This wouldn't work with TF.
I'm a bit confused here. If T is the training set, T_i is the single i-th sample (image) from the training set (with a dim of 784) and t_j is the j-th pixel then when we consider p(x_i | z_i,l) (expr. 10), do we assume that x_i is a t_j (pixel) or T_i (image)? But I could well be wrong, as I'm no expert in this field, I've started to look into VAE just recently.
You don't need to specify this field if there is no return output
Previous version was more readable imo.
`# Returns `
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Per the failing docstring test, this docstring needs a `Raises` section mentioning the ValueError: https://travis-ci.org/fchollet/keras/jobs/282558708
Please make this method private (unless there is a rationale for making it part of the public API).
Please make this method private.
I think we should make this function private, as well as `is_current_explicit_device`, and `get_available_gpus`.
Use code markers around `put()`
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Please add a docstring.
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
Any way to completely abstract this away in the Theano backend? We should not adjust the backend-agnostic part of the codebase to adjust for Theano-specific issues.
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
Please fix the identations issues in the file. I'll review the PR in the next few days. Thanks for updating it!
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
For consistency with layers, this should probably be set as `self.add_update`. Also: how much layer functionality can be shared with layers? Should metrics be a layer subclass? (one with `self.stateful = True`) This would enable weight management, serialization, etc. for free.
Format your docstrings like other docstrings in the codebase
Let's not include that.
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
`# Returns `
This should be `activations.get(activation)` where `activations` is `from keras import activations`
No point in calling super here
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Also around `=`
Spaces around `<`
Awesome : ) But now you'll need to remove the outdated exception as well ; )
`if n.__class__.__name__ == ...`
I vote for option number two. That seems the most consistent with other parts of the Keras API.
Forgot a space ```suggestion ' If your inputs are not batched,' ```
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
Should probably be int in both case. We don't want separate cases to handle.
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
PEP8: space after comma
I'd rather use `Deconvolution2D` (and an alias `Deconv2D`), to better match the TensorFlow API.
Use a variable with a complete name, not `l`.
We might need a more standard way to merge dictionaries (with the latter dict taking precedence). Like a `config` decorator. Or maybe that would introduce too much implicitness.
pg 6 of the [paper](https://arxiv.org/pdf/1706.02515.pdf) says: > Therefore, we propose âalpha dropoutâ, that randomly sets inputs to Î±
Is there a reason why there is not a `SpatialAlphaDropout` like there is a `SpatialDropout`? In the paper they are not explicitly doing it, but they do have an argument `noise_shape` on their Github. When they release the code for more advanced datasets, we'll know for sure I guess.
Use ` around code keywords everywhere in docstrings..
If this base layer does not have a `call` method, it should implement `call` and raise `NotImplementedError` there.
Complete name `ParametricSoftExponential` would be better, even if long.
Better mention that the cropping happens along the time dimension here (axis 1)
cropping, not padding
Yes, that works
Hence why we should use `endswith`. To ignore any prefix.
prefer `or self.monitor == 'auc'` to avoid potential collisions
Then use `endswith`. Otherwise unrelated metrics that have the substring "auc" will get caught.
For metric name yes. But for reporting is gets a prefix. E. g., trainig_acc, validation_accuracy, etc.
I would say '_acc' and '_auc' to further reduce chances of accidental name clash.
my point was to use `endswith('_acc')` rather than `endswith('acc')`
Make sure the line in under 80 chars, e.g. ``` if (self.monitor.endswith('acc') or self.monitor.endswith('accuracy') or self.monitor.endswith('auc')): ```
Add two spaces.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
In general we should avoid explicit types when the expect type is a custom class, like in the above case. It creates significant tech debt and maintenance burden going forward.
No warning should occur with default settings. It is safe to remove this.
Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.
Should be on the same line as the argument.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
What case does this cover? Also, here we have twice an unchecked assumptions that we are dealing with a list; all we know is that it isn't a float. Not all non-floats are lists.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Not sure this is the behavior we actually want. Seems like a lot of hard-coded assumptions.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Default values should be 0 (i.e. if argument isn't specified then no padding occurs on that side).
Same here, I think we should have a polymorphic padding argument that could be `int`, tuple of size 2, or dictionary.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Should be Tensor3.
The indices of the axes depend on the dim ordering. Just say "width and height"
Change to 0. Also please format code elements in docstring with "`" (tuples. dicts).
You don't need `+` to do string concatenation across two consecutive lines
Use `'` for strings for consistency with the rest of the file.
Please shorten line (break after `(`)
Change to 0. Also please format code elements in docstring with "`" (tuples. dicts).
Also style: use `target_height` / `target_width`, no point in removing two characters.
The ValueError should be listed in the docstring. The error message should specify what was passed, and the list of values expected instead.
Use `'` as quote char for consistency
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
Spaces around operators
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
Forgot a space ```suggestion ' If your inputs are not batched,' ```
I think these layers would benefit from having more transparent names.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
We could add a backend method to do it, with custom implementations in each backend...
The entries in `config` should match the arguments in `__init__`.
cropping, not padding
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
cropping, not padding
Same: don't mention specific axes
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Likewise, please format docstring
Please format the docstring like the others, with an `# Arguments` and `# Returns` section
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
You're right. Never mind then.
Please add a check and raise `ValueError` if appropriate. Reshape may not be possible.
What if we're loading a `GRU` layer with `reset_after=True`? It will have 6 biases also. I think we shouldn't transpose the kernels in this case.
It seems like the `weights` argument for `preprocess_weights_for_loading` is not really a list of numpy arrays. It's a list of `HDF5 dataset`. When I call `print(weights)` on my machine, I saw something like: ``` [<HDF5 dataset "kernel:0": shape (100, 96), type "<f4">, <HDF5 dataset "recurrent_kernel:0": shape (32, 96), type "<f4">, <HDF5 dataset "bias:0": shape (192,), type "<f4">] ``` Hence there would be some metadata attached to the weights. Specifically, with `print([x.name for x in weights])`, the output is: ``` ['/model_weights/cu_dnngru_1/cu_dnngru_1/kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/recurrent_kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/bias:0'] ``` However, I'm really not sure if this is a behavior that we could rely on (i.e., is it a consistent behavior for different versions of h5py, different versions of Keras, python, OS, ...). Also, it might not pass some existing tests since the tests are written under the assumption that the input is a list of arrays.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
@farizrahman4u this is still not fixed.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
Looks great to me. :)
No need for final space
No need for final space
Please make multiple statements instead of breaking the line, it will improve readability. ```python if _LEARNING_PHASE ....: return .... else: return .... ```
Meaning of error message is vague, please clarify. Also note that you're missing a space before `(` Also please shorten your lines to 80 chars.
Please do not break lines with `\`
Flaky test is fixed just so you know.
I think that would be better indeed. It's not a big deal if the internal implementations differ as long as the external interface is the same.
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
Please keep the random tests where they were. Unit tests should be small and target as few things as possible for better error reporting and debugging.
Insert line break above
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
We don't want to do N dictionary lookups in this loop. Much better to change the `depth_keys` list to match the list of expected keys...
`if n.__class__.__name__ == ...`
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
Don't use `\` for breaking lines, prefer using parentheses
Use code markers around `put()`
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Style nit: avoid strange line breaking ```python node_key = self._node_key(layer, original_node_index) if node_key in self.container_nodes: ``` Also applicable in several other places in this PR. Please fix.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
`weights` are part of the base layer kwargs, so it doesn't need to be included in the test. `name` is only included in order to get the test to pass (otherwise the different names would make the configs different). You can remove it, especially since this is not be the proper syntax for this argument (needs a list).
You should use a PEP8 linter to avoid style issues. https://pypi.python.org/pypi/pep8
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
Style: break long lines in the test
Better to put the activation as the `activation` keyword of the layer below
Line too long (and several other lines in this file as well)
Use `'` everywhere for consistency. Do not break lines with `\`
filters //= 2
should be self.forward.
@farizrahman4u this is still not fixed.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
Should be `inputs` and `mask`.
I think it would make the operation clearer.
There's no reason for these three branches to be inside the `else` of line 773, rather that else should be removed should all be `elif`s up one layer, i.e. ``` if self.consume_less == 'gpu': ... elif self.consume_less == 'cpu': ... elif self.consume_less == 'mem': ... else: raise Exception('Unknown `consume_less` mode.') ```
oops yeah I can't read apparently. Disregard!
@ns3284 Squash function has to be applied according to paper.
There's no reason to not make these both extend `MaskedLayer` instead of `Layer` and thereby also be supported in masked scenarios.
> `T.sqrt(self.p/(1-self.p))` Something should be done to avoid division by zero in case p = 1... maybe clipping p to [epsilon, 1-epsilon]? In terms of coding style, please use spaces around operators and use floats in float operations.
This reshape will fail for some shapes (all inputs X where X.shape[1] is odd) because the number of elements in the tensor will not be conserved. Additionally it appears that the maxout is done only of the 1st tensor dimension (indexing from 0). This would be time in case of a temporal input, of channels for a picture input. I don't thinking that's how it should work in these cases (it should be respectively the 2nd and 2nd-3rd dimensions).
Yes, that would make sense.
Syntax error here (`}`)
Typo: output. It should be clarified that it needs to be a valid Theano expression.
We might need a more standard way to merge dictionaries (with the latter dict taking precedence). Like a `config` decorator. Or maybe that would introduce too much implicitness.
Same remark as before regarding `output_shape`.
Same: don't mention specific axes
PEP8: space after comma
Please do not include html markup in the docstrings. Two line breaks should be sufficient (or use markdown list formatting).
Need to fill in this section
No, that's a fine style as well. Anything that's PEP8 works. And line length is not strictly enforced (prefer readability over correct line length).
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Please introduce line breaks in the docstring to avoid very long lines.
Use bullet points
Break up long line
This is a new layer so no API conversion decorator is necessary.
I believe you don't need this method, the inherited one should work fine.
it's less pythonic but more in line with the style of how things are computed at some other places in the code base.
Please remove these changes so that this callback has the same behavior as the other callbacks. It could be discussed in another issue/PR.
Just checking for `Wrapper` will not work in the general case. The only `Wrapper` that could work with an `Embedding` currently is `TimeDistributed` (but even that sounds overly niche). Please remove this statement
Use ` around code keywords
Yes please, rewrite those lines.
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
Use bullet points
Code markers around `validation_split`
Code markers around tuple
Looks good to me now.
```suggestion if k == KC: ```
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
I wonder if this whole loop could be simplified somehow? It has a clear recursive structure. The same code should be generalizable to 1D/2D/3D/etc without having to manually unroll the loop.
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
Past few lines too long
I will note in passing that doing one conv per channel is not an efficient way to implement depthwise conv (too much overhead). Preferable to do a single conv with a diagonal kernel.
Still relevant? If so, explain the diff
Line too long
No need for final space
This is already validated in the constructor, no need.
Better to use `_keras_history`
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
No need for `+` at the end. But needs a space after `.`.
We want to print the full shapes for clarity. Creating a new array in the exception is not an issue: we're interrupting execution anyway, so we don't care about resources consumption.
Please make this method private (unless there is a rationale for making it part of the public API).
Please make this method private.
Please provide a more detailed error message, including a suggestion of what the user should do to fix the issue. The current message would not be immediately understandable by users.
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
@Dref360 I can throw a specific exception for the case a data element should be just skipped.
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
To be clear, the idea (to my understanding) is that `OrderedEnqueuer` will be the class that knows about `batch_size`. The generator that `fit_generator` receives is constructed in `DatasetEnqueuer.get()`. This generator pops `batch_size` items from the queue and then calls `self.dataset.create_batch(lst_items)` to obtain the actual batch.
I like this!
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
There are added empty lines. Please remove them.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
We generally call it "KTF"
That's something we should fix in the Keras backend.
Format your docstrings like other docstrings in the codebase
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
`# Returns `
You don't need to specify this field if there is no return output
this is discussed in https://github.com/fchollet/keras/pull/7113
Insert link to callbacks page
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
"the input name to a Numpy array" (singular in this case, for `Sequential`)
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
This will be more readable with code markers around `epochs`.
Code markers around code keywords (`)
"the parameter" is redundant, you can simply say `epochs`
Code markers around tuple
Code markers around `validation_split`
This is way too ad-hoc. The choice of having exactly 2 input and 2 outputs and having the input data / target data be just a repetition of the same array is something that happens to work in some of the existing unit tests, but it wouldn't work in the general case.
In general this test is more like an integration test than a unit test. You don't need half of this stuff: - the model should be minimal (this one has a bunch of extra layers) - you don't need data with a statistical structures, `np.random` will work just fine - etc.
This test would be very expensive to run. It's an integration test, not a unit test. Please boil it down to essential components.
No need for this line
Is this try/except necessary? It's a test
`cnn` sounds like a model instance, but it's a tensor. Call it `x`
These quantities are not relevant here.
Typo: perfermace -> performance
It is a good idea to implement your loss outside of compile so that your code is readable.
@ns3284 Squash function has to be applied according to paper.
No need for such abbreviations, they just make code harder to read.
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
Optimizers have a `get_config` method precisely for this purpose.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
Singe the names are expected to match across models, "in the current model" does not make sense here.
"The weight file you are trying to load is in a legacy format that does not support name-based weight loading".
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
Bit of redundancy: this sets `input` twice (here and in the next few lines).
```python if isinstance(v, np.ndarray): send[k] = v.item() else: send[k] = v ````
Please fix the identations issues in the file. I'll review the PR in the next few days. Thanks for updating it!
There are added empty lines. Please remove them.
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
Prefer importing `layers` then using e.g. `layers.Conv2D`
`# Returns `
Still relevant? If so, explain the diff
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
Should this be part of the public API? It sounds like it should be an internal method.
You don't need to specify this field if there is no return output
Use bullet points
Break up long line
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Shapes mentioned in the docstring are generally 2D; should be 3D
Need to fill in this section
Use list markers
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
This is a new layer so no API conversion decorator is necessary.
enumerate is not needed here. i is not used
Use `'` as quote character
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
It doesn't really make sense to me, because random transformations are important to have at test time as well (because they modify the statistics of the data). Best evals are from multiple random transforms, with results merged via power averaging.
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
I think we should not expect only a list, but also allow for tuples. In which case this comparison won't work; better to compare each member: `zoom_range[0] == 1 and zoom_range[1] == 1` . Also, since we make the assumption that `zoom_range` is going to be a 2-element list/tuple, better check first and raise a helpful error message if it's not the case.
array_to_img need argument scale to decide if it is needed to scale to uint8. And the previous code assume X is always within 0 and 1. We may need to fix it.
Got it! Let me check if other codes make such guarantee.
Spaces around `/`
Please add a note saying that the learning_phase should be added by `fit_generator`, otherwise it's a little confusing.
This is the non-generator path. 0 is added to val_data here : https://github.com/keras-team/keras/pull/9796/files/86e5448ff06d30bebfdf8a4781562ad6abaabd1c#diff-b25d82c3f751f73f6e62b8455547ac73R124
No, do not do this
Prefer `if steps_per_epoch is not None`
`all_outs` is meant to be a list of arrays (potentially with 1 element), not a Numpy array, because we need to support multi-output models (the present code wouldn't). Same for `outs`. So I would recommend following the pattern from `evaluate_generator`: converting the output of `self.predict_on_batch` to a list if necessary, etc.
This would be very inefficient and would cause EOM errors even for smallish datasets. Please use instead the approach of `predict()` (preallocating entire arrays as soon as their shape is known, then assigning values inside the preallocated arrays). This is doable because the number of samples that are expected is known (`val_samples`).
"When using `steps_per_epoch`, ..."
How is there any difference between this and `on_epoch_end`? In practice, both are called in succession, with nothing in between.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
Should be `inputs` and `mask`.
Break up long line
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
You can replace these lines with `outputs.set_shape((inputs.get_shape()[0], None, None))`
Please add a docstring describing the overall strategy used to compute the mask.
Should be `inputs` and `mask`.
This is incorrect in the general case: just because `call` takes a `training` argument doesn't mean the learning phase is being used. Instead, you should look at whether `_uses_learning_phase` is set on any if the output tensors of the child layer.
Put `int):` on the same line for readability.
No reference to `_keras_shape`, that's an implementation detail. Call it "static shape"
Please add a note saying that the learning_phase should be added by `fit_generator`, otherwise it's a little confusing.
This is the non-generator path. 0 is added to val_data here : https://github.com/keras-team/keras/pull/9796/files/86e5448ff06d30bebfdf8a4781562ad6abaabd1c#diff-b25d82c3f751f73f6e62b8455547ac73R124
Meaning of error message is vague, please clarify. Also note that you're missing a space before `(` Also please shorten your lines to 80 chars.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
This probably won't help with your actual problem, but the following PR was very helpful when I needed to fix feed dict issues: https://github.com/fchollet/keras/pull/7064
I think this check would be better as if inputs.shape[1] is not None and sum(self.cropping) >= inputs.shape[1]: You could still construct a tensor with size 0 and shape (None, None) that would cause this to crash.
The ValueError needs to be tested with a test that uses `assertRaisesRegex`
This would read clearer with format strings, and we are trying to gravitate towards more uniform error messages in keras. f'`cropping` parameter of Cropping layer must be greater than the input shape. ' f'Recieved: inputs.shape={inputs.shape}, and cropping={self.cropping}'
Fix indent here and below
cropping, not padding
Same: don't mention specific axes
Line too long, and not PEP8 compliant. Break it down into a few lines.
The indices of the axes depend on the dim ordering. Just say "width and height"
cropping, not padding
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
This is not the same argument. The proper behavior here would be: - if `forget_bias_init` is set to `"one"`, set `unit_forget_bias` to True - else ignore the argument, and in this case, raise a warning specifying the argument was ignored. You will need custom code to do this.
Missing a space between "argument" and "has". Also tell users to use the `unit_forget_bias` argument instead.
You can make this a dict instead of a list of tuples, that would be more natural. In this case, the order of the values does no matter.
Should `args[1:]` here (the first entry in `args` is `self`).
In case `padding` is a positional argument, quote characters will be required around it here (since it's a string). E.g. don't print `MaxPooling1D(3, valid)`, instead print `MaxPooling1D(3, "valid")`.
Actually, you can just use the `convert_legacy_kwargs` utility function I just added.
You're right. In that case we should make sure the user does not pass more than 1 positional argument.
`pool_size` would be commonly used as positional argument.
'p' is already removed when, kwargs.pop('p')
For simplicity, I would simply disallow `data_format` as a positional arg. It would be bad practice to pass it as positional anyway.
The base layer should raise an error actually or None. Depend if we want everyone to provide this service. Every layer in keras' repo should provide this
Use `'` for strings for consistency with the rest of the file.
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Better to add `rank` here
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Break up long line
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
Should this be part of the public API? It sounds like it should be an internal method.
This should be a `ValueError`.
This is too broad an exception, it should be `ImportError` (otherwise something inside the module could fail and you wouldn't know why).
There are added empty lines. Please remove them.
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
You don't need to specify this field if there is no return output
`# Returns `
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
Better to put the activation as the `activation` keyword of the layer below
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
You are later multiplying with a float. This has no effect on the output
This seems strangely ad-hoc
Additionally this will give the wrong number for RNN layers
@fchollet Does the output shape include padding? That may be the problem you're referring to. I tried to think of any other way the output shape would not be equal to the number of positions the kernel is applied, but as far as I can tell input stride and input padding are already taken into account by this. A specific counter example would be greatly appreciated.
The formula is wrong because `np.prod(self.output_shape[1:-1])` is not the number of positions where the kernel is applied, it is the maximum number of positions.
This formula is wrong for most convolution layer configs because it doesn't take into account padding and strides
Yes, which will be defined at least for the built-in layers
You should not rely on private property `_keras_shape` which may not be set
So you always return None in mode `channels_first`? Why? That's not the expected behavior.
The base layer should raise an error actually or None. Depend if we want everyone to provide this service. Every layer in keras' repo should provide this
I vote for option number two. That seems the most consistent with other parts of the Keras API.
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
Should probably be int in both case. We don't want separate cases to handle.
No, this should always be entered if `input_shape[0]`.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
This should be a `ValueError` (never raise `Exception`).
Should be `inputs` and `mask`.
In which cases would this be needed? It may be better to defined a proper private function than a very long named lambda. e.g. ``` python def _expand_if_needed(input, mask): ... ```
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
I think we should add the arguments "file_format" and "**kwargs" (passed to `Image.save()`) https://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.save "format" needs to be renamed "file_format" to avoid confusion with "data_format".
Explicitly mention that this is 'channels_first'/'channels_last' (since it may be confusing vs. image file format).
Parens not necessary here
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
Format your docstrings like other docstrings in the codebase
Since Python is a compiled language you are recomputing `2 ** 31` at every iteration here. Prefer instead using e.g. 1e9 or something. 1e7 would be enough I guess. But really I'm not sure this is a good idea since it makes the file names less readable.
enumerate is not needed here. i is not used
I wonder if this whole loop could be simplified somehow? It has a clear recursive structure. The same code should be generalizable to 1D/2D/3D/etc without having to manually unroll the loop.
That is not 100% guarantee and it will result in different intensity for different image.
For example, given 20% intensity shift, an image with pixel value [50, 100] will have larger shift than an image with pixel value in [70, 80].
I think `if self.dropout > 0 or self.recurrent_dropout > 0` is more clear.
`try / except` is not the proper thing to do here. You could do a type check instead.
This is correct.
Insert line break above
This function does not have a properly formatted dosctring (see other dosctrings for reference)
Does CNTK support a softmax axis? If not, we can also go with manual softmax in CNTK.
Could you try benchmarking this against the use of `transpose + softmax + transpose`? It may be that transposing is faster (but impossible to know in advance).
Flaky test is fixed just so you know.
Code delimiters ` would be more appropriate than string quotes here, for `x` and `increment`.
Good catch! yeah there should be a warning.
Please update the docstrings as well.
this line is over 80 characters.
This only applies when save_best_only is true correct? We should call that out. Something like... ``` Initial "best" value of the metric to be monitored. Only applies if `save_best_value=True`. If set, the checkpoint will only be saved if the model metric value is better than this value. ```
In general we should avoid explicit types when the expect type is a custom class, like in the above case. It creates significant tech debt and maintenance burden going forward.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
Please use backticks around code keywords.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
Please put "`" around code keywords.
Looks good to me now.
this value error is good but do in other places
It is looking like `height_factor` and `width_factor` can only be positive integers. This should be specified in the docstring. The API makes it sound like `*_factor` could be a float (e.g. 0.75 for an output image with 75% of the original height).
I am also wondering whether it is necessary to specify the original height and width as part of the arguments (this information is part of the tensor X).
Suggest to make `data_format` as argument of `_helper_bilinear`. Then parameterize `test_resize_images_bilinear` with `data_format`. Otherwise, you may not be able to test both `data_format` with `pytest.raises`.
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
For theano, `ratio` needs to be `integer`. ```python ratio = height_factor // width_factor ```
in the tests k.backend() == `cntk` might want to lower case here
maybe tell the user the valid data_formats
Line too long (and several other lines in this file as well)
Please introduce line breaks in the docstring to avoid very long lines.
You can just append: ``` To install TensorFlow: `pip3 install tensorflow` ``` to the previous message.
we could just use a dict instead of doing an eval. Would be cleaner.
This should be a `ValueError`.
I don't think the warning message ends up being very clear... Better to raise specific warnings below, one at a time
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Don't do this, prefer explicit checks
Don't do this, prefer explicit checks
We generally call it "KTF"
Why rename this test? If it isn't prefixed by "test", it will not be run by pytest.
Should this be part of the public API? It sounds like it should be an internal method.
No need for final space
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
Better to use `_keras_history`
"of a symbolic tensor" (it doesn't have to be a keras one)
Break up long line
Use bullet points
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
The number of batches in the Sequence
Space after #
Use code markers around `put()`
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Remove leading space
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
In any case, this PR is a great addition for Keras, thank you!
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Please use PEP8 conventions: one space after `,`
There's no reason for these three branches to be inside the `else` of line 773, rather that else should be removed should all be `elif`s up one layer, i.e. ``` if self.consume_less == 'gpu': ... elif self.consume_less == 'cpu': ... elif self.consume_less == 'mem': ... else: raise Exception('Unknown `consume_less` mode.') ```
oops yeah I can't read apparently. Disregard!
With not mask, how do you handle a batch with different sequence lengths? Said a batch of 2, with first input have lenght 2 and the 2nd has a lenght 4. Then you would do a right padding on the 1st sequence to make it have length 4. In you implementation without mask, for the 1st input, the **true** energy should be `b_start + x1' y1 + x2' y2 + y1' U y2 + b_end` but in your implementation, there isn't a `b_end`, but with an additional `x3' y3' + x4' y4 + y2' U y3 + y3' U y4`, where `y3 = y4 = 0`. The consequence is, the above two formulations are not equivalent, at least when you take derivative with respect to `U_00` (top-left element in matrix `U`), the derivative isn't the same. Right? (also, `U_00` and `U_11` are not `exchangable`, but why we treat label 0 and label 1 differently?) Also when you compute the normalization constance (free energy in your code), you have to integrate over `y3, y4` (which are paddings). I guess that's what you mean by "padding elements act as a virtual end label". However, if when you think about taking derivative with respect to `U` or `b_end`, your approach is not equivalent to a real CRF. One very obvious observation is, `y3, y4`, the padding, affects the derivative with respect to `U`, and therefore, the paddings plays a role on the final outcome. The more paddings you have, the more impact the paddings affects the outcome. This is unexpected from my point of view. Lastly, another simple observation, a model with and without the end energy (`b_end`), the numbers of trainable parameters are not the same. So the two models are not the same.
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
You don't need to specify this field if there is no return output
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
Previous version was more readable imo.
This is Theano syntax and breaks with TF. Use `K` instead.
`weights` are part of the base layer kwargs, so it doesn't need to be included in the test. `name` is only included in order to get the test to pass (otherwise the different names would make the configs different). You can remove it, especially since this is not be the proper syntax for this argument (needs a list).
You should use a PEP8 linter to avoid style issues. https://pypi.python.org/pypi/pep8
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
filters //= 2
Style: break long lines in the test
Line too long (and several other lines in this file as well)
Better to put the activation as the `activation` keyword of the layer below
Use `'` everywhere for consistency. Do not break lines with `\`
add the type to be consistent send_as_json: Boolean, ...
It seems there is four spaces missing (unrelated to your changes).
It's also inconsistent with line 593
Link on a single line, otherwise it won't work (we don't enforce line length)
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
There are added empty lines. Please remove them.
One import per line. Also import `models` so as to avoid `tf.keras` calls in the code. This *is* the Keras codebase! It should import internal modules, not `tf.keras`.
Just import `utils`
We generally call it "KTF"
What is your TF version? Here you are taking a slice, which as far as I can tell breaks shape inference and causes the following code to fail. A workaround is to manually set the shape of the slice. This may not be the case with the latest TF version. Unclear
Please fix the identations issues in the file. I'll review the PR in the next few days. Thanks for updating it!
I will note in passing that doing one conv per channel is not an efficient way to implement depthwise conv (too much overhead). Preferable to do a single conv with a diagonal kernel.
Please remove new line (`"""Instantiates`).
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
I mean `RuntimeError`.
Respect PEP8 conventions.
Capital variable names is not appropriate for scalar variables
`+ K.epsilon()` in the denominator.
It's a hack, but changing to something like ``` return K.mean(y_pred, axis=-1) + (0 * y_true) ``` may suppress the Theano warning that you're currently throwing. (NB: Not sure the dimensions here are correct in all situations, but something along these lines would work.)
The targets / predictions are assumed to be in the [0, 1] interval but that is not enforced. It should be.
Please rename `sparse_top_k_categorical_accuracy` for consistency with other metrics names
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Format your docstrings like other docstrings in the codebase
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
In the future, I'll just remove this use case. I suspect having `workers > 1 and use_multiprocessing == False` doesn't gives any real speedup. I'll do some profiling and post my findings here. Also, we should try to mimic the Ordered Enqueuer so this class will get heavily refactored anytime soon anyway. (By the end of August)
Sleeping with a lock held seems bad. Shouldn't it be sufficient to guard this line with the lock: ``` generator_output = next(self._generator) ```
Please draft a PR. I think we should keep a UX-friendly way of handling python generators. (ie. a good clear message stating that they should set workers=1)
Quick test with heavy I/O ``` from keras.utils import GeneratorEnqueuer import numpy as np import cv2 from itertools import cycle import time # Create fake datas for i in range(10): cv2.imwrite('/tmp/{}.png'.format(i), np.zeros([1024, 1024, 3], np.uint8)) def gen(): for i in cycle(range(10)): yield cv2.resize(cv2.imread('/tmp/{}.png'.format(i)), (600, 600)) enq = GeneratorEnqueuer(gen(), use_multiprocessing=False) enq.start(3,10) g = enq.get() s = time.time() for _ in range(1000): next(g) end = time.time() print("Took :", end - s) ``` Both `workers = 1` and `workers = 3` take 28 seconds to do 1000 iterations. I propose that we just remove all of this and force workers to be 1 when using multithreading. The GIL removes all improvments anyway. @fchollet I would like your input on that.
Sounds good. I'll put something together in the weekend and I'll tag you to get your feedback.
This should be a private method, I believe
Yes, all private methods in the Keras codebase use a single leading underscore. Thanks!
In that case the first seed can be used to generate separate seeds for each sub process before the fork
Indeed, or you can just increment the input seed for each new process.
remove unused keyword `args`
whoops! Thanks for the fix. I'd lean towards yes, but I don't know the details of how locally declared python classes work between calls.
Change applied in #6670 in addition to a second bugfix that occurs when servers don't provide a Content-Length header.
just wasn't sure if "probar" -> "enclosed" goes from a local to a global variable. NVM about threads, that's out of scope. Thanks.
To avoid spilling on the left side, use string concatenation like this: ``` reference_str = ('Model: "model_2"' '_________________________________________________________________' ' Layer (type) Output Shape Param # ' ... ) ```
Newline before this line
Remove leading space
Add line break above
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
The number of batches in the Sequence
I don't understand why we would want to deprecate md5, or have a preference for one algo or another. It's cool to support more than one hash function, but md5 works just fine for this purpose. We're just building a basic cache invalidation mechanism.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
No `+` needed for string concatenation at the end
Better to use `_keras_history`
No need for blank line
No need for `+` at the end. But needs a space after `.`.
"of a symbolic tensor" (it doesn't have to be a keras one)
Better to use `_keras_history`
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Shapes mentioned in the docstring are generally 2D; should be 3D
This is a new layer so no API conversion decorator is necessary.
unused variable `input_length`
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Blank line required before the next section
Blank line required before the next section
Please introduce line breaks in the docstring to avoid very long lines.
Use list markers
Need to fill in this section
Better to check whether the layer's call method accepts the `training` and `mask` arguments.
`if n.__class__.__name__ == ...`
Please use string formatting: 'Unrecognized value for argument `merge_mode`: %s' % (self.merge_mode,)
should be self.forward.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
@farizrahman4u this is still not fixed.
PEP8: space after comma
Use spaces around `-` operator (PEP8).
cropping, not padding
The indices of the axes depend on the dim ordering. Just say "width and height"
We could add a backend method to do it, with custom implementations in each backend...
This should be `activations.get(activation)` where `activations` is `from keras import activations`
No point in calling super here
Same remark as before regarding `output_shape`.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
cropping, not padding
Same: don't mention specific axes
In that case the first seed can be used to generate separate seeds for each sub process before the fork
add param to provide a seed at init time
Indeed, or you can just increment the input seed for each new process.
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
@Dref360 I can throw a specific exception for the case a data element should be just skipped.
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
In any case, this PR is a great addition for Keras, thank you!
@Dref360 yes I think it is best to keep the same behavior as before.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
Fix indent. Use `pylint` as linter.
One import per line. Also import `models` so as to avoid `tf.keras` calls in the code. This *is* the Keras codebase! It should import internal modules, not `tf.keras`.
Just import `utils`
I mean `RuntimeError`.
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
This mechanism will only work for a few layers, and will fail in the general case. The proper behavior when batch size matters is to slice the input mask and run slices through `self.layer.compute_mask`, then concatenate. No reshaping.
`K.int_shape(inputs)` will not always be available.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
No, this should always be entered if `input_shape[0]`.
This should be a `ValueError` (never raise `Exception`).
Should be `inputs` and `mask`.
Reshaping is appropriate in this case, but only in this case.
I vote for option number two. That seems the most consistent with other parts of the Keras API.
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
No reference to `_keras_shape`, that's an implementation detail. Call it "static shape"
This is way too ad-hoc. The choice of having exactly 2 input and 2 outputs and having the input data / target data be just a repetition of the same array is something that happens to work in some of the existing unit tests, but it wouldn't work in the general case.
In general this test is more like an integration test than a unit test. You don't need half of this stuff: - the model should be minimal (this one has a bunch of extra layers) - you don't need data with a statistical structures, `np.random` will work just fine - etc.
This test would be very expensive to run. It's an integration test, not a unit test. Please boil it down to essential components.
Is this try/except necessary? It's a test
No need for this line
PEP8: spaces around operators
Also, you don't actually need these error messages after `assert` since this is a unit test
Use `'` as the quote character for consistency with the rest of the file
@ns3284 Squash function has to be applied according to paper.
These quantities are not relevant here.
Line too long
Still relevant? If so, explain the diff
Past few lines too long
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
Style: if you're going to break a signature or a call like this, prefer stacking the arguments for better readability, like ```python def assert_list_pairwise(z_list, shape=True, allclose=True): ``` This is applicable in several places in this PR
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
Line too long (and several other lines in this file as well)
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
```suggestion if k == KC: ```
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
"the input name to a Numpy array" (singular in this case, for `Sequential`)
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
Insert link to callbacks page
this is discussed in https://github.com/fchollet/keras/pull/7113
Code markers around code keywords (`)
"the parameter" is redundant, you can simply say `epochs`
"output names to Numpy arrays"; "`y` can be"
This will be more readable with code markers around `epochs`.
Code markers around `validation_split`
Syntax error here (`}`)
We might need a more standard way to merge dictionaries (with the latter dict taking precedence). Like a `config` decorator. Or maybe that would introduce too much implicitness.
I think it would make the operation clearer.
PEP8: space after comma
> `T.sqrt(self.p/(1-self.p))` Something should be done to avoid division by zero in case p = 1... maybe clipping p to [epsilon, 1-epsilon]? In terms of coding style, please use spaces around operators and use floats in float operations.
Yes, that would make sense.
This reshape will fail for some shapes (all inputs X where X.shape[1] is odd) because the number of elements in the tensor will not be conserved. Additionally it appears that the maxout is done only of the 1st tensor dimension (indexing from 0). This would be time in case of a temporal input, of channels for a picture input. I don't thinking that's how it should work in these cases (it should be respectively the 2nd and 2nd-3rd dimensions).
Same remark as before regarding `output_shape`.
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
not sure you need to wrap this in a method it looks clean this way though.
Yes please, rewrite those lines.
It's possible to write this one liner in several more readable lines of code. It will also solve your pep8 problems.
Same here, not sure if the dict comprehension is readable.
Please remove these changes so that this callback has the same behavior as the other callbacks. It could be discussed in another issue/PR.
In that case, I think this error and the corresponding test should be kept.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
We generally call it "KTF"
The paragraph above can be replaced with `layer.weights`, which is always implemented.
it's less pythonic but more in line with the style of how things are computed at some other places in the code base.
Docstring contains a few typos, please fix / rephrase
Use markdown format for links
"samples drawn from"
Fix indent. Use `pylint` as linter.
I will note in passing that doing one conv per channel is not an efficient way to implement depthwise conv (too much overhead). Preferable to do a single conv with a diagonal kernel.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Use bullet points
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
This default value will break loading old model files.
Space between arguments (PEP8).
Please put the new parameters on a new line
The `output_dim` / `initial_output` business should definitely be eliminated by all means necessary.
I see no need to add a `constants` argument to the `rnn` API. It can be made part of the states (and the whole logic will be handled at the level of the `step` function of the RNN layers, as it should be...).
"not currently supported with CNTK".
You are setting this to True but don't seem to be using the learning phase in the code.
There is already a variable named `initial_weights`. To avoid confusion, please use `reset_weights`.
I mean, it's a pretty serious inconsistency.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Insert link to callbacks page
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
"the input name to a Numpy array" (singular in this case, for `Sequential`)
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
This will be more readable with code markers around `epochs`.
Code markers around `validation_split`
this is discussed in https://github.com/fchollet/keras/pull/7113
Code markers around tuple
"the parameter" is redundant, you can simply say `epochs`
Code markers around code keywords (`)
I don't quite understand this message. Do we expect users to be familiar with the concept of "dynamic axis" here? Doesn't seem standard
No need for final space
No need for final space
Need spaces at the end of every line in this message (this is also true of a few other messages)
Need at least rank 3
Line too long
```suggestion if k == KC: ```
Use f-strings for string formatting (or otherwise `format()`). The error message should include what the input shape was and what the output shape would have been. "check the input shape" is not actionable.
Space (" ") instead of period(" ")
Introduce an `if` block to avoid a very long line.
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
I feel like it would actually be clearer and more economical to separate the two cases entirely: one input vs. multiple inputs.
"the parameter" is redundant, you can simply say `epochs`
Insert link to callbacks page
> tf.ragged.constant does not accept tf.Tensor inputs gracefully It's really strange that it works with numpy arrays but not tf.Tensors. That's an inconsistency in the ragged API that we should address...
this is discussed in https://github.com/fchollet/keras/pull/7113
Code markers around `validation_split`
Code markers around tuple
I fear this is a brittle mechanism. It will work in simple cases but will fail in advanced cases.
I don't think that `0` is a valid shape dimension.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
It's the same hack, but the big difference is that `get` is only used in small files where the set of names you want to be able to "get" is identical (or close enough) to the entire namespace. Which makes it safe. The reason this hack is potentially dangerous in the first place is the likelihood of namespace collisions, and they are highly likely in a file as busy as `models.py`. So I'd rather import each module separately, then use `getattr` on the appropriate module name. Then we limit the use of the namespace to the name of modules, which is fine.
> Train a model and store every bit of it, including optimizers, in case you want to pick it up later for further training etc. In this case it makes sense to have the compiled version at hand. At least I would like to have the option to have a compiled version. Sounds very useful, but there are further problems with implementing this: for instance, how do you save the state of the optimizer for further training? That state is contained in shared Theano variables. I have no strong opinion either way, the main argument I see for skipping compilation is the use of custom objectives (custom optimizers are relatively unlikely, much like custom regularizers and constraints, however custom objectives are fairly common).
You can change line 263-269 like this: ``` ndim = len(self.output_shape[i]) if ... else ... weight = ... ``` and you can do the same in other such places.
may be use a local variable here and in the cases below to avoid code duplication? ``` ndim = len(self.output_shape[i]) if ... else ... weight = ... ```
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Using if/else here definitely improves readability. In the previous discussion I had request to de-dup the code for creating placeholder which you have done already.
Use `'` everywhere for consistency. Do not break lines with `\`
Can we have a better API than `padding=(1, 1, 1, 1)`? Maybe `padding=((1, 1), (1, 1))` (but that one is not very good either). Please think of something. Maybe multiple arguments.
Change to "pooling over conv_dim2 and conv_dim1"
Change to "pooling over conv_dim3"
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
cropping, not padding
Same: don't mention specific axes
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
This should be max.
Callbacks are processed sequentially, future is more vague than next IMO.
I don't think the grammar is right as-is with "next". Alternate: "make value available to each of the following callbacks"
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
`try` with an `assert` is not the way to test inequality between two integers...
While print the batch index with so many leading zeros? Just use `%d`
Optimizers have a `get_config` method precisely for this purpose.
Insert a line break after the docstring
Bit of redundancy: this sets `input` twice (here and in the next few lines).
```python if isinstance(v, np.ndarray): send[k] = v.item() else: send[k] = v ````
Invalid Python 3 syntax.
In all of these cases, we refer to the `Variable` class.
Code delimiters ` would be more appropriate than string quotes here, for `x`.
Code delimiters ` would be more appropriate than string quotes here, for `x`.
Code delimiters ` would be more appropriate than string quotes here, for `x`.
Code delimiters ` would be more appropriate than string quotes here, for `x` and `increment`.
No need for `+` at the end. But needs a space after `.`.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
Also rewrite this description assuming an integer axis.
in the tests k.backend() == `cntk` might want to lower case here
maybe tell the user the valid data_formats
Suggest to make `data_format` as argument of `_helper_bilinear`. Then parameterize `test_resize_images_bilinear` with `data_format`. Otherwise, you may not be able to test both `data_format` with `pytest.raises`.
It is looking like `height_factor` and `width_factor` can only be positive integers. This should be specified in the docstring. The API makes it sound like `*_factor` could be a float (e.g. 0.75 for an output image with 75% of the original height).
I am also wondering whether it is necessary to specify the original height and width as part of the arguments (this information is part of the tensor X).
"all three factors"
It seems like the rest of this file generally adheres to an 80-character limit per line.
The `:` is good to have
this value error is good but do in other places
For theano, `ratio` needs to be `integer`. ```python ratio = height_factor // width_factor ```
Please print a message for this action (like we do in `on_train_end`): "Restoring model to its state at the end of the best epoch."
`try` with an `assert` is not the way to test inequality between two integers...
I really don't see how incrementing `self.wait` at the end of each epoch is the correct behavior. You have access to the epoch counter `epoch`, if you just want to skip the first epoch you can? E.g. if it's the first epoch, then set the best score / weights and continue.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Yes, it would make better sense in `build`.
The class docstring should explain the meaning of the arguments.
Good catch! yeah there should be a warning.
"eror" -> "error"
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Pretty cool that it's checking for its own performance impact!
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
This default value will not work with Windows. Use None instead, and set it in the function code.
Just for reference for newbies, in windows, the cache folder is at C:\Users\USERNAME_HERE\.keras\datasets. I usually download the files manually and place them because sometimes it does fail downloading in my computer.
In general your docstrings have an indentation problem, the lines after the first one should be indented by 1 level (4 spaces).
Just say "either md5 or sha256".
I don't understand why we would want to deprecate md5, or have a preference for one algo or another. It's cool to support more than one hash function, but md5 works just fine for this purpose. We're just building a basic cache invalidation mechanism.
Link on a single line, otherwise it won't work (we don't enforce line length)
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Newline before this line
Add a `# Arguments` section to the docstring.
Add a `# Arguments` section to the docstring.
Remove leading space
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Use code markers around `put()`
Add a `# Arguments` section to the docstring.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
add param to provide a seed at init time
In that case the first seed can be used to generate separate seeds for each sub process before the fork
Indeed, or you can just increment the input seed for each new process.
If the default is 0.5, then I would suggest to put `def __init__(self, threshold=0.5):`
Just `# Arguments` to be consistent
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
unused variable `input_length`
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
Looks good to me now.
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
What you call `one_hot` is referred to as `categorical` everywhere else in the codebase (e.g. categorical_crossentropy, cateorical_accuracy, to_categorical). But think we don't need this argument, when it comes to single-label classification, because you can automatically infer it from the shape of the predictions (if the last axis is size 1, it's binary, else categorical).
But we would need this argument in case we want to support *multi-label* binary classification, where you have multiple dimensions on the last axis, and each one of them encodes a binary class prediction. So I think we should have the argument. And we should add support for: - multi-class, single-label categorical classification - multi-class, multi-label binary classification
Please add a check that all kwargs match a list of expected Theano arguments, with helpful error message otherwise. This is necessary to avoid confusion in case of typo.
Yes, unless we expect users to access it and set it (we don't), it should be private.
self.current_feed_dict = {} if self.feed_dict is None else self.feed_dict Clearer
We have a "NanGuardMode" (you can just use that string) that is done for this: http://deeplearning.net/software/theano/tutorial/nan_tutorial.html http://deeplearning.net/software/theano/library/compile/nanguardmode.html I think it would be better to use that then what you propose. We are making it skip some False positive error from time to time: https://github.com/Theano/Theano/pull/3768
Personnaly, I would use Theano flags :) I don't know if it should be added directly in Theano. Do tensorflow support this? If it is added in keras, I would do: ``` mode = None if _DEBUG_MODE == 'detect_nan': mode = 'NanGuardMode' ``` Can you open an issue on Theano, Using the Theano flag should not enable the GPU. I don't have this behavior on the lstm example.
I don't think that `0` is a valid shape dimension.
That should be `inputs`, not None (same below).
You added a `name` argument but it isn't used downstream.
This one should follow the same logic as above, as well.
"Passed to `tf.Session.run`", with ` around code
I think it would make the operation clearer.
This won't work, since the shape of the mask won't match the shape of the input.
This should be tensor3 instead of matrix.
Ok, I had overlooked that. I think this should be enforced via an exception. Knowing from the start what you did wrong is better than a failure at training time due to shape incompatibilities.
This divides the input into halves of size output_dim/2 that are then concatenated. The size of the output might not be output_dim anymore (eg: python(13/2) = 6; 6+6=12).
Yes, that would make sense.
This reshape will fail for some shapes (all inputs X where X.shape[1] is odd) because the number of elements in the tensor will not be conserved. Additionally it appears that the maxout is done only of the 1st tensor dimension (indexing from 0). This would be time in case of a temporal input, of channels for a picture input. I don't thinking that's how it should work in these cases (it should be respectively the 2nd and 2nd-3rd dimensions).
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
@farizrahman4u this is still not fixed.
PEP8: space after comma
Simply `batch_size` would suffice.
Can we change this parameter to be `write_step` with the options `'epoch'` and `'batch'`, and improve the description? I think `write_step` might be more clear, and doesn't break the true/false setting in the future if there is another setting worth adding.
Please use a smaller batch size in order to fully test the iteration code (here is only a single batch).
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
It's better use a flag to control write epoch-level summary or batch-level summary. The batch-level summary will be overwrite in your implementation.
We generally call it "KTF"
Use ` around code keywords
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
Please rename to `preprocessing_function`. Please improve the docstring by specifying: "The function should take one argument: a batch of images (Numpy tensor with rank 4), and should output a Numpy tensor with the same shape."
This function does not have a properly formatted dosctring (see other dosctrings for reference)
Make this method private and add a docstring explaining its purpose.
This one is fine
Should be named `apply_brightness_shift`
Good catch! yeah there should be a warning.
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Also rewrite this description assuming an integer axis.
var is a reserved keyword, use `v` or something like that.
`_set_keras_shape_for_reduction` would arguably be a better name. This can be reused for any reduction op (sum, etc).
var is a reserved keyword, use `v` or something like that.
Format your docstrings like other docstrings in the codebase
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
Parens are unnecessary: `if tf_data_format == 'NHWC' or tf_data_format == 'NCHW' and _has_nchw_support():`
I vote for option number two. That seems the most consistent with other parts of the Keras API.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
This should be max.
Capitalize start of argument descriptions ("String or...")
Please make this method private.
I don't understand why; `tf.nn.separable_conv2d` does support strides.
Please introduce line breaks in the docstring to avoid very long lines.
This one is fine too
Need to fill in this section
This is a new layer so no API conversion decorator is necessary.
Use bullet points
Break up long line
You can use `K.is_keras_tensor`
Please add spaces after commas.
The general term used throughout Keras is "loss" (as well as "objective" for the objective functions); I think we should keep it that way and replace "cost" with "loss" in the variables.
Definitely a nice way to implement regularization. We'll have to think about a unified system for integrating regularization as part of the loss.
Yes, that would be a good idea. We would need to monitor accuracy and speed along the way. Incorporating regularization in the loss should result in higher accuracy but _might_ cause performance issues.
What if the layer does not have a name, though? There should be an exception or a fallback (preferably an exception, for maximum explicitness).
We don't want to do N dictionary lookups in this loop. Much better to change the `depth_keys` list to match the list of expected keys...
> `T.sqrt(self.p/(1-self.p))` Something should be done to avoid division by zero in case p = 1... maybe clipping p to [epsilon, 1-epsilon]? In terms of coding style, please use spaces around operators and use floats in float operations.
We might need a more standard way to merge dictionaries (with the latter dict taking precedence). Like a `config` decorator. Or maybe that would introduce too much implicitness.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
Same remark as before regarding `output_shape`.
So I think we should: - move the function inside the parent function, since no one else will use it - keep the list comprehension, since we won't in-line the function after all... Thanks!
This should be private. Also, since this function is only called once (in a loop), please consider if you could in-line it in the parent function.
Actually it can. The first two are positional (input_dim, output_dim).
Use ` around **kwargs
Please add `# Arguments` and `# Returns` sections.
You're right. In that case we should make sure the user does not pass more than 1 positional argument.
Actually, you can just use the `convert_legacy_kwargs` utility function I just added.
`pool_size` would be commonly used as positional argument.
In case `padding` is a positional argument, quote characters will be required around it here (since it's a string). E.g. don't print `MaxPooling1D(3, valid)`, instead print `MaxPooling1D(3, "valid")`.
Same remark as before regarding `output_shape`.
As I said, using img_to_array would be nicer. The API of `save_img` should reflect the one of img_to_array
I think we should add the arguments "file_format" and "**kwargs" (passed to `Image.save()`) https://pillow.readthedocs.io/en/3.1.x/reference/Image.html#PIL.Image.Image.save "format" needs to be renamed "file_format" to avoid confusion with "data_format".
Explicitly mention that this is 'channels_first'/'channels_last' (since it may be confusing vs. image file format).
Use `'` as quote char for consistency
The ValueError should be listed in the docstring. The error message should specify what was passed, and the list of values expected instead.
Is the copy absolutely necessary? Wondering.
Also style: use `target_height` / `target_width`, no point in removing two characters.
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
Since Python is a compiled language you are recomputing `2 ** 31` at every iteration here. Prefer instead using e.g. 1e9 or something. 1e7 would be enough I guess. But really I'm not sure this is a good idea since it makes the file names less readable.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Does CNTK support a softmax axis? If not, we can also go with manual softmax in CNTK.
In general we can use the default implementation if `axis == 1 or axis == x.ndim - 1`
Could you try benchmarking this against the use of `transpose + softmax + transpose`? It may be that transposing is faster (but impossible to know in advance).
For numerical stability, you have to do T.exp(x - x.max())
The exact transposition depends on the `axis` value and `x.ndim`. But we'd only need to benchmark it for one configuration. For `axis=2` and `x.ndim=4` your code looks right to me.
`try / except` is not the proper thing to do here. You could do a type check instead.
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Format your docstrings like other docstrings in the codebase
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
Let's add a TODO for this one
If all you do with `ReverseGradient` is call it, why should it be a class? Everything in the backend is a function.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
Let's add a TODO for this one
Let's add a TODO for this one
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
Let's add a TODO for this one
Let's add a TODO for this one
Should not be public
With not mask, how do you handle a batch with different sequence lengths? Said a batch of 2, with first input have lenght 2 and the 2nd has a lenght 4. Then you would do a right padding on the 1st sequence to make it have length 4. In you implementation without mask, for the 1st input, the **true** energy should be `b_start + x1' y1 + x2' y2 + y1' U y2 + b_end` but in your implementation, there isn't a `b_end`, but with an additional `x3' y3' + x4' y4 + y2' U y3 + y3' U y4`, where `y3 = y4 = 0`. The consequence is, the above two formulations are not equivalent, at least when you take derivative with respect to `U_00` (top-left element in matrix `U`), the derivative isn't the same. Right? (also, `U_00` and `U_11` are not `exchangable`, but why we treat label 0 and label 1 differently?) Also when you compute the normalization constance (free energy in your code), you have to integrate over `y3, y4` (which are paddings). I guess that's what you mean by "padding elements act as a virtual end label". However, if when you think about taking derivative with respect to `U` or `b_end`, your approach is not equivalent to a real CRF. One very obvious observation is, `y3, y4`, the padding, affects the derivative with respect to `U`, and therefore, the paddings plays a role on the final outcome. The more paddings you have, the more impact the paddings affects the outcome. This is unexpected from my point of view. Lastly, another simple observation, a model with and without the end energy (`b_end`), the numbers of trainable parameters are not the same. So the two models are not the same.
Insert a line break after the docstring
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
`try` with an `assert` is not the way to test inequality between two integers...
While print the batch index with so many leading zeros? Just use `%d`
The class docstring should explain the meaning of the arguments.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
Callbacks are processed sequentially, future is more vague than next IMO.
I don't think the grammar is right as-is with "next". Alternate: "make value available to each of the following callbacks"
Space after `,`.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
This is unsafe, because it would be reused across different unrelated calls to `layers_from_config`. I would suggest using a custom object scope inside `layers_from_config`: ```python with custom_objects_scope(custom_objects): layer = ... ``` Or something like that.
Please add a docstring explaining the behavior and giving a usage example.
This line should be right after `"""`. Put "`" around function names.
Also add a `# Arguments` section for `*args`
What happens if I pass in a harmful string like `"(injection=__import__('os').listdir('.'))"`? Perhaps the identifier string should just be parsed for k,v pairs, using `set` or `setattr`.
You should not be modifying `get_from_module`. Instead you should be merging the `custom_layers` dict with the layer dict from `globals`.
This will break if `layer` is a container.
Two line breaks after the first sentence.
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
I mean `RuntimeError`.
It seems that all pep8 tests failures are ignored by travis. I'll make a PR to fix it.
The notation seems unusual (`y`, `_y`, `__y`). Please find something more descriptive and conventional
These should be `ValueError`
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
Past few lines too long
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
Line too long (and several other lines in this file as well)
Suggest to make `data_format` as argument of `_helper_bilinear`. Then parameterize `test_resize_images_bilinear` with `data_format`. Otherwise, you may not be able to test both `data_format` with `pytest.raises`.
Use `'` everywhere for consistency. Do not break lines with `\`
The indices of the axes depend on the dim ordering. Just say "width and height"
cropping, not padding
cropping, not padding
Same: don't mention specific axes
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Line too long, and not PEP8 compliant. Break it down into a few lines.
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
This should be max.
Incorrect / confusing. Please fix.
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
At this point it would be fine to have `np_kernel = kernel.eval()`
This should be max.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Processing of `np_kernel` should be removed from this function
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
This is correct.
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
For now, after adding `axis` in the crossentropy losses, you will have to use a different loss function when doing pixelwise classification (image segmentation) in NCHW: ```python if K.data_format() == 'channels_first': loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(y_true, y_pred, axis=1) else: loss = K.sparse_categorical_crossentropy model.compile(optimizer=optimizer, loss=loss) ```
@tiferet the API change in `sparse_categorical_crossentropy` is not something we can merge, sorry. Such an argument should be called `axis` and should default to `-1` (`K.image_data_format()` is a layer-level configuration argument and should not affect the default behavior of backend methods).
`any` seems it doesn't belong here. You'll want this to return an array. Additionally, I would prefer not casting to `float32` and use the native TF `bool` type instead (i.e. this function should be a thin wrapper over `tf.nn.in_top_k`). The fact that Theano does not have a bool type has to be dealt with in the Theano backend and should not affect the TensorFlow backend.
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
Still relevant? If so, explain the diff
We have this warning in several places, please fix it everywhere
Add a `# Arguments` section to the docstring.
Quick test with heavy I/O ``` from keras.utils import GeneratorEnqueuer import numpy as np import cv2 from itertools import cycle import time # Create fake datas for i in range(10): cv2.imwrite('/tmp/{}.png'.format(i), np.zeros([1024, 1024, 3], np.uint8)) def gen(): for i in cycle(range(10)): yield cv2.resize(cv2.imread('/tmp/{}.png'.format(i)), (600, 600)) enq = GeneratorEnqueuer(gen(), use_multiprocessing=False) enq.start(3,10) g = enq.get() s = time.time() for _ in range(1000): next(g) end = time.time() print("Took :", end - s) ``` Both `workers = 1` and `workers = 3` take 28 seconds to do 1000 iterations. I propose that we just remove all of this and force workers to be 1 when using multithreading. The GIL removes all improvments anyway. @fchollet I would like your input on that.
Please draft a PR. I think we should keep a UX-friendly way of handling python generators. (ie. a good clear message stating that they should set workers=1)
Sounds good. I'll put something together in the weekend and I'll tag you to get your feedback.
In the future, I'll just remove this use case. I suspect having `workers > 1 and use_multiprocessing == False` doesn't gives any real speedup. I'll do some profiling and post my findings here. Also, we should try to mimic the Ordered Enqueuer so this class will get heavily refactored anytime soon anyway. (By the end of August)
Sleeping with a lock held seems bad. Shouldn't it be sufficient to guard this line with the lock: ``` generator_output = next(self._generator) ```
This should be a private method, I believe
Yes, all private methods in the Keras codebase use a single leading underscore. Thanks!
Add a `# Arguments` section to the docstring.
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
"The weight file you are trying to load is in a legacy format that does not support name-based weight loading".
Singe the names are expected to match across models, "in the current model" does not make sense here.
"Name-based weight loading (instead of topological weight loading)"
It is be preferable to confine changes to this loop instead of introducing a new layer method. Here, we just need a loop that builds the `weight_values` list and flips convolution kernels if `layer` is an instance of a convolution layer.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
It should be clarified in the docstring what "compilation" entails.
`mathews_correlation` or `matthews_correlation_coefficient`
The targets / predictions are assumed to be in the [0, 1] interval but that is not enforced. It should be.
Capital variable names is not appropriate for scalar variables
`+ K.epsilon()` in the denominator.
It's a hack, but changing to something like ``` return K.mean(y_pred, axis=-1) + (0 * y_true) ``` may suppress the Theano warning that you're currently throwing. (NB: Not sure the dimensions here are correct in all situations, but something along these lines would work.)
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
Since you are taking a global mean instead of the mean on the last axis, this will fail for loss weighting.
Please rename `sparse_top_k_categorical_accuracy` for consistency with other metrics names
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Respect PEP8 conventions.
Needs the same docstring as the TF one
K.zeros returns a variable, which is not necessary here, hence the use of `constant`.
`try / except` is not the proper thing to do here. You could do a type check instead.
No `+` needed for string concatenation at the end
Better to use `_keras_history`
No need for `+` at the end. But needs a space after `.`.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
> tf.ragged.constant does not accept tf.Tensor inputs gracefully It's really strange that it works with numpy arrays but not tf.Tensors. That's an inconsistency in the ragged API that we should address...
Better to use `_keras_history`
Also style: use `target_height` / `target_width`, no point in removing two characters.
Use `'` as quote char for consistency
The ValueError should be listed in the docstring. The error message should specify what was passed, and the list of values expected instead.
I think these layers would benefit from having more transparent names.
Spaces around operators
Use `'` as string delimiter for consistency
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
Break up long line
Use bullet points
Can we have a better API than `padding=(1, 1, 1, 1)`? Maybe `padding=((1, 1), (1, 1))` (but that one is not very good either). Please think of something. Maybe multiple arguments.
Default values should be 0 (i.e. if argument isn't specified then no padding occurs on that side).
Same here, I think we should have a polymorphic padding argument that could be `int`, tuple of size 2, or dictionary.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Either this mode should be removed (not supported by the tf backend) or code redundancy with 'max' should be eliminated. I'd recommend removing the mode.
Processing of `np_kernel` should be removed from this function
Change to 0. Also please format code elements in docstring with "`" (tuples. dicts).
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
Change to 0. Also please format code elements in docstring with "`" (tuples. dicts).
Personnaly, I would use Theano flags :) I don't know if it should be added directly in Theano. Do tensorflow support this? If it is added in keras, I would do: ``` mode = None if _DEBUG_MODE == 'detect_nan': mode = 'NanGuardMode' ``` Can you open an issue on Theano, Using the Theano flag should not enable the GPU. I don't have this behavior on the lstm example.
We have a "NanGuardMode" (you can just use that string) that is done for this: http://deeplearning.net/software/theano/tutorial/nan_tutorial.html http://deeplearning.net/software/theano/library/compile/nanguardmode.html I think it would be better to use that then what you propose. We are making it skip some False positive error from time to time: https://github.com/Theano/Theano/pull/3768
Use `'` as quote character for intra-file consistency
`args` is the list of positional arguments passed by the user. It could have any length.
Actually it can. The first two are positional (input_dim, output_dim).
Unclear what purpose this line serves.
Use ` around **kwargs
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
This could simple read "converted"
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Suggest to put operator in next line and remove redundant parentheses. ```python (K.backend() != 'tensorflow' or not K.tensorflow_backend._get_available_gpus()), ```
You can use `random.choice` instead
You should not be importing `keras` here. You can use `K.placeholder` to create a placeholder.
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
About this test: - please use the same docstring format as elsewhere in the codebase - use `'` as quote character for consistency - use lines that are <= 80 char
Space (" ") instead of period(" ")
`npt` and `x_start` are always the same, they can be declared in the test function itself (like you did before). They don't need to be in the parameters of `parametrize`.
Why rename this test? If it isn't prefixed by "test", it will not be run by pytest.
"non-static". Use single quotes for the string delimiters, for consistency.
In addition to type, I think you should also check the value after clipping by placeholder variable.
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
I think it would be good to assert than the input tensor is at least 3D (to avoid a more obscure error message later).
Nit: use backquotes around code keywords
Nit: use `'` as the quote character, for consistency
Replace with ``` if len(mask.get_shape()) > ndim: raise ValueError(...) ```
Spaces around `=` please.
Should be `inputs` and `mask`.
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
`data_utils` is no longer meant as a public namespace, use `utils`
Use `'` as string delimiter
Is there a way to eliminate the underlying cause of this warning & the other similar ones without requiring the user to inherit from Dataset? I've only used pickling once or twice so I'll defer to others on all such code.
`data_utils` is no longer meant as a public namespace, use `utils`
What about failure cases? Example: #6928 it is possible only x, only y, neither x nor y, or a tuple of some other unexpected size gets returned. At a minimum, check the tuple size and throw an exception if it doesn't match expectations. There are probably other cases like this in this pull request, it might be worth double checking.
grammar "Please consider using"
Add a `# Arguments` section to the docstring.
Add a `# Arguments` section to the docstring.
Add a `# Arguments` section to the docstring.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Theano -> Theano/TensorFlow
Blank line required before the next section
Blank line required before the next section
This should be max.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
@ns3284 Squash function has to be applied according to paper.
There's no reason to not make these both extend `MaskedLayer` instead of `Layer` and thereby also be supported in masked scenarios.
I think it would make the operation clearer.
The entries in `config` should match the arguments in `__init__`.
Syntax error here (`}`)
> `T.sqrt(self.p/(1-self.p))` Something should be done to avoid division by zero in case p = 1... maybe clipping p to [epsilon, 1-epsilon]? In terms of coding style, please use spaces around operators and use floats in float operations.
should be self.forward.
We might need a more standard way to merge dictionaries (with the latter dict taking precedence). Like a `config` decorator. Or maybe that would introduce too much implicitness.
@farizrahman4u this is still not fixed.
PEP8: space after comma
Same remark as before regarding `output_shape`.
Specify an epoch number
`predict` and `evaluate` with data tensors should have unit tests as well.
Don't use this pattern. No try/except block here.
Use `'` everywhere for consistency. Do not break lines with `\`
Use `'` as string delimiter for consistency
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
Style: break long lines in the test
That last sentence will be very difficult to understand for people who don't have further context.
The inserted ```order of``` is less precise than the original. It is the batches that are shuffled, not their order. The order is randomised.
Only for Sequence. No effect for Generators
Use code markers around code keywords (`)
Code markers around `validation_split`
Remove leading space
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Use code markers around `put()`
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Code markers around tuple
You shouldn't need to pop these args here. Rather, you should remove them from kwargs before calling the layer (which is fine since they are transferred to the input list)
Could you please split this method to a standalone utility function in `recurrent.py` (named `def _standardize_args`)? The only instance attribute it needs is `_num_constants`, which can be passed as a function argument (`num_constants`). That way we don't need to duplicate this code, you can just import it from `recurrent.py`.
In line with naming conventions in this API, this should be `_num_constants`.
Clarify the error message; a "Keras tensor" is the output of a Keras layer
and -> or
Use bullet points
Break up long line
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
in the tests k.backend() == `cntk` might want to lower case here
maybe tell the user the valid data_formats
It is looking like `height_factor` and `width_factor` can only be positive integers. This should be specified in the docstring. The API makes it sound like `*_factor` could be a float (e.g. 0.75 for an output image with 75% of the original height).
I am also wondering whether it is necessary to specify the original height and width as part of the arguments (this information is part of the tensor X).
this value error is good but do in other places
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
Line too long (and several other lines in this file as well)
Please introduce line breaks in the docstring to avoid very long lines.
For theano, `ratio` needs to be `integer`. ```python ratio = height_factor // width_factor ```
Suggest to make `data_format` as argument of `_helper_bilinear`. Then parameterize `test_resize_images_bilinear` with `data_format`. Otherwise, you may not be able to test both `data_format` with `pytest.raises`.
In general throughout this PR, we should follow PEP8 and avoid camel case. Let's use snake case instead (this is Python after all).
It's the same hack, but the big difference is that `get` is only used in small files where the set of names you want to be able to "get" is identical (or close enough) to the entire namespace. Which makes it safe. The reason this hack is potentially dangerous in the first place is the likelihood of namespace collisions, and they are highly likely in a file as busy as `models.py`. So I'd rather import each module separately, then use `getattr` on the appropriate module name. Then we limit the use of the namespace to the name of modules, which is fine.
> Train a model and store every bit of it, including optimizers, in case you want to pick it up later for further training etc. In this case it makes sense to have the compiled version at hand. At least I would like to have the option to have a compiled version. Sounds very useful, but there are further problems with implementing this: for instance, how do you save the state of the optimizer for further training? That state is contained in shared Theano variables. I have no strong opinion either way, the main argument I see for skipping compilation is the use of custom objectives (custom optimizers are relatively unlikely, much like custom regularizers and constraints, however custom objectives are fairly common).
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
Optimizers have a `get_config` method precisely for this purpose.
should be self.forward.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
PEP8: space after comma
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
Please add a check and raise `ValueError` if appropriate. Reshape may not be possible.
However in some cases there will be no weights. This assert is a bug...
This is a bug, please remove
Please format the docstring like the others, with an `# Arguments` and `# Returns` section
Likewise, please format docstring
You're right. Never mind then.
These two entries (if Bidirectional, if TimeDistributed) should be added in the big `if` switch without affecting the rest of the code. Currently we have 150 lines changed for should be a ~15 lines change...
Transposing the weights is always the right thing to do regardless of original backend.
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
At this point it would be fine to have `np_kernel = kernel.eval()`
In this case the better solution would to check `dtype(x)`.
In this case the better solution would to check `dtype(x)`.
In this case the better solution would to check `dtype(x)`.
Use `'` not `"`, as in the rest of the file
At this point it would be fine to have `np_kernel = kernel.eval()`
At this point it would be fine to do the dimshuffle without the call the `_postprocess_conv2d_output`
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
Processing of `np_kernel` should be removed from this function
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
LeCun proposed this scheme way back (see ref in `lecun_uniform` docstring). Our initializers are named `*_normal` and `*_uniform`. We already have the `lecun_uniform` initializer, and this initializer is simply the normal version of it. I don't even know why we didn't already have it, it's a significant inconsistency.
"samples drawn from"
The meaning of `seed` in the API is to make the dropout *node* in the graph deterministic, but not constant. In this implementation the op would be constant if passed a seed argument. Not super important for just debugging use cases, but easy to fix. I suggest you simply remove the `np.random.seed(seed)` statement, this would be closer to the intended behavior.
No need for the extra space at the end of the lines.
Nit: please shorten lines here to 80 char or less (also in `initializers.py`)
Please use readable variable names such as `array`
Please use PEP8 conventions: spaces around operators (.e.g `*`)
More elegant would be to shuffle an array of indices once, then use the array to index X and y (yes, unlike the current code in this module, but like the code in `models.py`).
Nit: please shorten lines (here and above).
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
Could you try benchmarking this against the use of `transpose + softmax + transpose`? It may be that transposing is faster (but impossible to know in advance).
For numerical stability, you have to do T.exp(x - x.max())
The exact transposition depends on the `axis` value and `x.ndim`. But we'd only need to benchmark it for one configuration. For `axis=2` and `x.ndim=4` your code looks right to me.
Does CNTK support a softmax axis? If not, we can also go with manual softmax in CNTK.
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
`_set_keras_shape_for_reduction` would arguably be a better name. This can be reused for any reduction op (sum, etc).
Format your docstrings like other docstrings in the codebase
No point in calling super here
This should be `activations.get(activation)` where `activations` is `from keras import activations`
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
The indent is meant to match to upper logical line, not the semantics of np arrays
It's also inconsistent with line 593
We have a "NanGuardMode" (you can just use that string) that is done for this: http://deeplearning.net/software/theano/tutorial/nan_tutorial.html http://deeplearning.net/software/theano/library/compile/nanguardmode.html I think it would be better to use that then what you propose. We are making it skip some False positive error from time to time: https://github.com/Theano/Theano/pull/3768
Personnaly, I would use Theano flags :) I don't know if it should be added directly in Theano. Do tensorflow support this? If it is added in keras, I would do: ``` mode = None if _DEBUG_MODE == 'detect_nan': mode = 'NanGuardMode' ``` Can you open an issue on Theano, Using the Theano flag should not enable the GPU. I don't have this behavior on the lstm example.
enumerate is not needed here. i is not used
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
I vote for option number two. That seems the most consistent with other parts of the Keras API.
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
Space after #
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
@Dref360 I can throw a specific exception for the case a data element should be just skipped.
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
Use code markers around `put()`
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Remove leading space
Yes, unless we expect users to access it and set it (we don't), it should be private.
self.current_feed_dict = {} if self.feed_dict is None else self.feed_dict Clearer
Please add a check that all kwargs match a list of expected Theano arguments, with helpful error message otherwise. This is necessary to avoid confusion in case of typo.
You added a `name` argument but it isn't used downstream.
"Passed to `tf.Session.run`", with ` around code
This raises an error for me, but replacing it for `self._merged_summaries.name` fixes the issue.
This one should follow the same logic as above, as well.
That should be `inputs`, not None (same below).
We have a "NanGuardMode" (you can just use that string) that is done for this: http://deeplearning.net/software/theano/tutorial/nan_tutorial.html http://deeplearning.net/software/theano/library/compile/nanguardmode.html I think it would be better to use that then what you propose. We are making it skip some False positive error from time to time: https://github.com/Theano/Theano/pull/3768
Personnaly, I would use Theano flags :) I don't know if it should be added directly in Theano. Do tensorflow support this? If it is added in keras, I would do: ``` mode = None if _DEBUG_MODE == 'detect_nan': mode = 'NanGuardMode' ``` Can you open an issue on Theano, Using the Theano flag should not enable the GPU. I don't have this behavior on the lstm example.
This won't work, since the shape of the mask won't match the shape of the input.
Should be `inputs` and `mask`.
Reshaping is appropriate in this case, but only in this case.
No, this should always be entered if `input_shape[0]`.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
Yes, that would make sense.
This reshape will fail for some shapes (all inputs X where X.shape[1] is odd) because the number of elements in the tensor will not be conserved. Additionally it appears that the maxout is done only of the 1st tensor dimension (indexing from 0). This would be time in case of a temporal input, of channels for a picture input. I don't thinking that's how it should work in these cases (it should be respectively the 2nd and 2nd-3rd dimensions).
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Respect PEP8 conventions.
Capital variable names is not appropriate for scalar variables
Since you are taking a global mean instead of the mean on the last axis, this will fail for loss weighting.
`+ K.epsilon()` in the denominator.
It's a hack, but changing to something like ``` return K.mean(y_pred, axis=-1) + (0 * y_true) ``` may suppress the Theano warning that you're currently throwing. (NB: Not sure the dimensions here are correct in all situations, but something along these lines would work.)
Format your docstrings like other docstrings in the codebase
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
The targets / predictions are assumed to be in the [0, 1] interval but that is not enforced. It should be.
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Please rename `sparse_top_k_categorical_accuracy` for consistency with other metrics names
Please add a docstring.
Using code markers around code keywords (.e.g `_predict_loop`).
Docstring should have a `Returns` section and a `Raises` section.
Set default `batch_size` to None, like in `fit`.
num_train_samples != steps_per_epoch, though. A step is a batch, not a single sample.
"When using `steps_per_epoch`, ..."
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Prefer `if steps_per_epoch is not None`
@ns3284 Squash function has to be applied according to paper.
The error messages in `generate_legacy_interface` are layer-specific. Don't use it for model methods.
For simplicity, I would simply disallow `data_format` as a positional arg. It would be bad practice to pass it as positional anyway.
This is not the same argument. The proper behavior here would be: - if `forget_bias_init` is set to `"one"`, set `unit_forget_bias` to True - else ignore the argument, and in this case, raise a warning specifying the argument was ignored. You will need custom code to do this.
Missing a space between "argument" and "has". Also tell users to use the `unit_forget_bias` argument instead.
You can make this a dict instead of a list of tuples, that would be more natural. In this case, the order of the values does no matter.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
Should `args[1:]` here (the first entry in `args` is `self`).
If providing code examples in a docstring, it should use the MarkDown syntax for code snippets (as used elsewhere in docstring code snippets in the codebase) and the code should follow PEP8 syntax. Alternatively, you could simply remove the code example, remove the mention of "lazy evaluated arrays", and simply state that the data should be picklable.
`pool_size` would be commonly used as positional argument.
Don't use this pattern. No try/except block here.
Since `dtype` is an argument name and not a string variable, quotes are not necessary.
No `+` needed for string concatenation at the end
Better to use `_keras_history`
No need for `+` at the end. But needs a space after `.`.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
This is primarily meant for tensor casting, not variable casting. Albeit you could cast a variable (thus returning a tensor).
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
Just for reference for newbies, in windows, the cache folder is at C:\Users\USERNAME_HERE\.keras\datasets. I usually download the files manually and place them because sometimes it does fail downloading in my computer.
This default value will not work with Windows. Use None instead, and set it in the function code.
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
In general your docstrings have an indentation problem, the lines after the first one should be indented by 1 level (4 spaces).
Just say "either md5 or sha256".
I don't understand why we would want to deprecate md5, or have a preference for one algo or another. It's cool to support more than one hash function, but md5 works just fine for this purpose. We're just building a basic cache invalidation mechanism.
Link on a single line, otherwise it won't work (we don't enforce line length)
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Newline before this line
cropping, not padding
The indices of the axes depend on the dim ordering. Just say "width and height"
cropping, not padding
Same: don't mention specific axes
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Better to add `rank` here
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
Fix indent. Use `pylint` as linter.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
Just import `utils`
I mean `RuntimeError`.
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
The `bn%d` looks unnecessary.
The example currently works fine with `data_augmentation=False`...
That's a bug indeed, but of a different kind. Test/evaluation shouldn't be run with data augmentation. Instead we should be using the Numpy array data + `predict`/`evaluate`.
Please revert this change.
Test is not redundant. Please fix.
You don't need a lambda here. Also, don't break lines with `\`.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Good catch! yeah there should be a warning.
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
Also, you don't actually need these error messages after `assert` since this is a unit test
Use `'` as the quote character for consistency with the rest of the file
Flaky test is fixed just so you know.
Not sure this is needed.
"Name-based weight loading (instead of topological weight loading)"
"The weight file you are trying to load is in a legacy format that does not support name-based weight loading".
Singe the names are expected to match across models, "in the current model" does not make sense here.
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
No need for `+` at the end. But needs a space after `.`.
Better mention that the cropping happens along the time dimension here (axis 1)
cropping, not padding
The indices of the axes depend on the dim ordering. Just say "width and height"
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
cropping, not padding
Same: don't mention specific axes
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
Line too long, and not PEP8 compliant. Break it down into a few lines.
Add space after `#`
Add imports to make the script compatible with py2/3: ```python from __future__ import absolute_import from __future__ import division from __future__ import print_function ```
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
Better to put the activation as the `activation` keyword of the layer below
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
You don't need BN for such a shallow network, `Conv2DTranspose` with relu activation and strides should suffice
You don't need this, `Conv2DTranspose` with strides should work better
Better to put the activation as the `activation` keyword of the layer below
filters //= 2
Transposing the weights is always the right thing to do regardless of original backend.
Are you sure about this? Justify.
Please format the docstring like the others, with an `# Arguments` and `# Returns` section
Likewise, please format docstring
You're right. Never mind then.
Please add a check and raise `ValueError` if appropriate. Reshape may not be possible.
These two entries (if Bidirectional, if TimeDistributed) should be added in the big `if` switch without affecting the rest of the code. Currently we have 150 lines changed for should be a ~15 lines change...
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
Why do you need two methods? You should only need one...
Please introduce line breaks in the docstring to avoid very long lines.
You could do that with Matplotlib, to avoid a new dependency
Add these 3 classes to `utils/__init__.py` so they can be imported from `utils` by users (internally it doesn't matter)
I'm not 100% sure on whether Keras enforces a standard ordering, but the usual order adopted by most projects that I've worked on that do enforce an ordering is `__future__, builtin, pip-installed, local`. And I'm a believer in going above and beyond for readability :)
One import per line
Let's avoid `*` imports, even if the import list is very long. The namespace in `models` is very busy, and we need what is free and what isn't.
Please use one import per line from now on.
Please avoid reordering imports. Let's keep the git diff small.
Let's not include that.
There are added empty lines. Please remove them.
Style nitpick, but please insert spaces around operators (`*`, `+`, etc).
Yes, that works
Hence why we should use `endswith`. To ignore any prefix.
prefer `or self.monitor == 'auc'` to avoid potential collisions
Then use `endswith`. Otherwise unrelated metrics that have the substring "auc" will get caught.
For metric name yes. But for reporting is gets a prefix. E. g., trainig_acc, validation_accuracy, etc.
I would say '_acc' and '_auc' to further reduce chances of accidental name clash.
my point was to use `endswith('_acc')` rather than `endswith('acc')`
Add two spaces.
Make sure the line in under 80 chars, e.g. ``` if (self.monitor.endswith('acc') or self.monitor.endswith('accuracy') or self.monitor.endswith('auc')): ```
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Please format the docstring like the others, with an `# Arguments` and `# Returns` section
Likewise, please format docstring
You're right. Never mind then.
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
Please add a check and raise `ValueError` if appropriate. Reshape may not be possible.
Why do you need two methods? You should only need one...
should be self.forward.
What if we're loading a `GRU` layer with `reset_after=True`? It will have 6 biases also. I think we shouldn't transpose the kernels in this case.
It seems like the `weights` argument for `preprocess_weights_for_loading` is not really a list of numpy arrays. It's a list of `HDF5 dataset`. When I call `print(weights)` on my machine, I saw something like: ``` [<HDF5 dataset "kernel:0": shape (100, 96), type "<f4">, <HDF5 dataset "recurrent_kernel:0": shape (32, 96), type "<f4">, <HDF5 dataset "bias:0": shape (192,), type "<f4">] ``` Hence there would be some metadata attached to the weights. Specifically, with `print([x.name for x in weights])`, the output is: ``` ['/model_weights/cu_dnngru_1/cu_dnngru_1/kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/recurrent_kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/bias:0'] ``` However, I'm really not sure if this is a behavior that we could rely on (i.e., is it a consistent behavior for different versions of h5py, different versions of Keras, python, OS, ...). Also, it might not pass some existing tests since the tests are written under the assumption that the input is a list of arrays.
Transposing the weights is always the right thing to do regardless of original backend.
Looks like you got it, I just wanted to make sure this PR wasn't going to get stuck for another couple of releases.
Using code markers around code keywords (.e.g `_predict_loop`).
Docstring should have a `Returns` section and a `Raises` section.
`data_utils` is no longer meant as a public namespace, use `utils`
Break down the message into two lines (line too long)
Is there a way to eliminate the underlying cause of this warning & the other similar ones without requiring the user to inherit from Dataset? I've only used pickling once or twice so I'll defer to others on all such code.
What about failure cases? Example: #6928 it is possible only x, only y, neither x nor y, or a tuple of some other unexpected size gets returned. At a minimum, check the tuple size and throw an exception if it doesn't match expectations. There are probably other cases like this in this pull request, it might be worth double checking.
You don't need a lambda here. Also, don't break lines with `\`.
Add a `# Arguments` section to the docstring.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Bit of redundancy: this sets `input` twice (here and in the next few lines).
`if n.__class__.__name__ == ...`
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
PEP8: space after comma
I vote for option number two. That seems the most consistent with other parts of the Keras API.
should be self.forward.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
@farizrahman4u this is still not fixed.
Please add a docstring detailing the meaning of each argument. It is non-obvious.
Here is the generic version that will work for any ndim: return T.TensorType(dtype, (False,)*ndim)(name) So this whole if/elif/.../else will disapear.
Then you should apply the same modifications in the TensorFlow backend, for consistency.
But about the `broadcastable` bool tuple: is it required to build the graph? Could we have a tensor that can accept data of _variable_ ndim (like `tf.placeholder()`, which is ndim-agnostic)? I'm asking because occasionally the ndim of certain inputs isn't known at compilation time, which is difficult to work around.
Please use PEP8 conventions: spaces around operators (.e.g `*`)
var is a reserved keyword, use `v` or something like that.
Bit of redundancy: this sets `input` twice (here and in the next few lines).
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
var is a reserved keyword, use `v` or something like that.
Nit: please shorten lines here to 80 char or less (also in `initializers.py`)
Please use `'` as quote character for consistency.
Don't use needed abbreviations that make code harder to read in order so save 4 characters.
Better to use keyword arguments (same below). API change looks ok to me.
That's a good point, since we didn't require it be named `epoch` before, we should probably make the first argument positional and only make the second (new one) a keyword arg.
This would benefit from a bit more explanation on how to use TensorBoard, at least a link to https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
`batch_size` parameter needs to be deprecated too.
We generally call it "KTF"
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
These quantities are not relevant here.
In general this test is more like an integration test than a unit test. You don't need half of this stuff: - the model should be minimal (this one has a bunch of extra layers) - you don't need data with a statistical structures, `np.random` will work just fine - etc.
This test would be very expensive to run. It's an integration test, not a unit test. Please boil it down to essential components.
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
Use `'` as the quote character for consistency with the rest of the file
Also, you don't actually need these error messages after `assert` since this is a unit test
Good catch! yeah there should be a warning.
No need for this line
Is this try/except necessary? It's a test
PEP8: spaces around operators
I would definitely exclude `loss_weights` from the `Sequential` API. There is no use case for it, and it is likely to confuse some people.
We should consider naming it `target_tensor` since it will always be a single tensor.
Ok for this change.
I don't get why you are introducing this unused argument.
Since this is ad-hoc and specific to a single method it shouldn't be a class method but rather a function defined on the fly in `compile`.
This is a private method, for safety, better not pass a default value for `include_optimizer`. Users shouldn't be using it, and when working on Keras itself it is easy to forget to pass it.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
Should be on the same line as the argument.
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
Use `'` everywhere for consistency. Do not break lines with `\`
> tf.ragged.constant does not accept tf.Tensor inputs gracefully It's really strange that it works with numpy arrays but not tf.Tensors. That's an inconsistency in the ragged API that we should address...
Ok, we can keep the current behavior for the time being. Thanks for checking!
Shorten one-line description (further detail can be provided in the docstring), add `Args:` section and `Returns:` section
Better to use `_keras_history`
No need for `+` at the end. But needs a space after `.`.
"of a symbolic tensor" (it doesn't have to be a keras one)
Better to use `_keras_history`
No `+` needed for string concatenation at the end
No reference to `_keras_shape`, that's an implementation detail. Call it "static shape"
and -> or
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Indeed, or you can just increment the input seed for each new process.
add param to provide a seed at init time
In that case the first seed can be used to generate separate seeds for each sub process before the fork
Remove leading space
Use code markers around `put()`
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
@Dref360 I can throw a specific exception for the case a data element should be just skipped.
Capitalize start of argument descriptions ("String or...")
I don't understand why; `tf.nn.separable_conv2d` does support strides.
I think that would be better indeed. It's not a big deal if the internal implementations differ as long as the external interface is the same.
Parens are unnecessary: `if tf_data_format == 'NHWC' or tf_data_format == 'NCHW' and _has_nchw_support():`
For simplicity, I would simply disallow `data_format` as a positional arg. It would be bad practice to pass it as positional anyway.
Introduce an `if` block to avoid a very long line.
Please introduce line breaks in the docstring to avoid very long lines.
This one is fine too
Need to fill in this section
Use bullet points
That should be `inputs`, not None (same below).
The entries in `config` should match the arguments in `__init__`.
This one should follow the same logic as above, as well.
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
There is already a variable named `initial_weights`. To avoid confusion, please use `reset_weights`.
Personnaly, I would use Theano flags :) I don't know if it should be added directly in Theano. Do tensorflow support this? If it is added in keras, I would do: ``` mode = None if _DEBUG_MODE == 'detect_nan': mode = 'NanGuardMode' ``` Can you open an issue on Theano, Using the Theano flag should not enable the GPU. I don't have this behavior on the lstm example.
We have a "NanGuardMode" (you can just use that string) that is done for this: http://deeplearning.net/software/theano/tutorial/nan_tutorial.html http://deeplearning.net/software/theano/library/compile/nanguardmode.html I think it would be better to use that then what you propose. We are making it skip some False positive error from time to time: https://github.com/Theano/Theano/pull/3768
Same remark as before regarding `output_shape`.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
Can be replicated in all backends
Let's add a TODO for this one
Can be replicated in all backends
Let's add a TODO for this one
Can be replicated in all backends (it's `-=`)
Let's add a TODO for this one
Let's add a TODO for this one
Let's add a TODO for this one
This is also TF-specific.
Should not be public
The CNTK errors on Travis CI seem to come from this line. `self.bias[0]` results in a `(1, 3 * self.units)` 2-D tensor in CNTK.
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
For efficiency reasons I believe it is preferable to keep the default regularizers to `None`. This is also important because using `None` in the class constructor is part of the standard API and the class should be able to deal with it. This is absolutely not an issue in `get_config`: you can simply use, e.g.: ``` python "W_constraint":self.W_constraint.get_config() if self.W_constraint else None, ``` After setting `self.W_constraint` to the value given to the constructor in `__init__`.
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
should be `wrong_size`
Singe the names are expected to match across models, "in the current model" does not make sense here.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Most of this stuff is included in the config of `super` and thus does not need to figure here.
unused variable `input_length`
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
Add these 3 classes to `utils/__init__.py` so they can be imported from `utils` by users (internally it doesn't matter)
Remove blank line
One import per line
Please fix the identations issues in the file. I'll review the PR in the next few days. Thanks for updating it!
Explain what the difference is and what motivates it
That's something we should fix in the Keras backend.
There are added empty lines. Please remove them.
Format your docstrings like other docstrings in the codebase
Prefer importing `layers` then using e.g. `layers.Conv2D`
Please remove new line (`"""Instantiates`).
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
This ignores additional keyword arguments possibly passed by the user.
Should `args[1:]` here (the first entry in `args` is `self`).
'p' is already removed when, kwargs.pop('p')
The point of these conversion interfaces is that old code should still work. So in this case we should figure out a better solution. Please leave out this layer.
This should be literally what the function call should look like. So the user can just copy and paste it.
You're right. In that case we should make sure the user does not pass more than 1 positional argument.
Actually, you can just use the `convert_legacy_kwargs` utility function I just added.
`pool_size` would be commonly used as positional argument.
In case `padding` is a positional argument, quote characters will be required around it here (since it's a string). E.g. don't print `MaxPooling1D(3, valid)`, instead print `MaxPooling1D(3, "valid")`.
Please revert this change.
That's a bug indeed, but of a different kind. Test/evaluation shouldn't be run with data augmentation. Instead we should be using the Numpy array data + `predict`/`evaluate`.
The example currently works fine with `data_augmentation=False`...
Could you wrap `float(batch_size))),` to new line.
why twice? both are not returned
You don't need a lambda here. Also, don't break lines with `\`.
Good catch! yeah there should be a warning.
Test is not redundant. Please fix.
Please use `np.ceil` instead
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
In order to avoid this `for` loop, I think it would be better to have the test for `logsumexp` be a separate function, with a parameterization decorator over axes and shapes.
It seems that all pep8 tests failures are ignored by travis. I'll make a PR to fix it.
Please keep the random tests where they were. Unit tests should be small and target as few things as possible for better error reporting and debugging.
Past few lines too long
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
Line too long (and several other lines in this file as well)
@farizrahman4u Undefined variable `K`
@farizrahman4u Isn't `ndim` always going to be 1 for `n`, I think you meant the equivalent of `len(n)`
Line too long
Still relevant? If so, explain the diff
`)` after `]`
Please remove new line (`"""Instantiates`).
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
I mean `RuntimeError`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
The `bn%d` looks unnecessary.
You don't need to specify this field if there is no return output
Please raise a `NotIplementedError` when the use case is not supported yet.
This function does not have a properly formatted dosctring (see other dosctrings for reference)
`# Returns `
this is discussed in https://github.com/fchollet/keras/pull/7113
Insert link to callbacks page
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
"the input name to a Numpy array" (singular in this case, for `Sequential`)
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
This will be more readable with code markers around `epochs`.
Code markers around code keywords (`)
"the parameter" is redundant, you can simply say `epochs`
Code markers around tuple
Code markers around `validation_split`
No need for final space
No need for final space
No need for final space
Please provide a more detailed error message, including a suggestion of what the user should do to fix the issue. The current message would not be immediately understandable by users.
We want to print the full shapes for clarity. Creating a new array in the exception is not an issue: we're interrupting execution anyway, so we don't care about resources consumption.
Parens not necessary here
No need for `+` at the end. But needs a space after `.`.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
Incorrect / confusing. Please fix.
No return section in such cases.
This is somewhat problematic because this will be ignored in most Keras functions. But that's a separate problem I suppose, which we will fix in a different PR.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
No `+` needed for string concatenation at the end
"samples drawn from"
Is there a way to eliminate the underlying cause of this warning & the other similar ones without requiring the user to inherit from Dataset? I've only used pickling once or twice so I'll defer to others on all such code.
What about failure cases? Example: #6928 it is possible only x, only y, neither x nor y, or a tuple of some other unexpected size gets returned. At a minimum, check the tuple size and throw an exception if it doesn't match expectations. There are probably other cases like this in this pull request, it might be worth double checking.
`all_outs` is meant to be a list of arrays (potentially with 1 element), not a Numpy array, because we need to support multi-output models (the present code wouldn't). Same for `outs`. So I would recommend following the pattern from `evaluate_generator`: converting the output of `self.predict_on_batch` to a list if necessary, etc.
This would be very inefficient and would cause EOM errors even for smallish datasets. Please use instead the approach of `predict()` (preallocating entire arrays as soon as their shape is known, then assigning values inside the preallocated arrays). This is doable because the number of samples that are expected is known (`val_samples`).
Please use `np.ceil` instead
This breaks the general philosophy of `keras-team/keras`, which is to have a shared codebase across different backends (which is possible as long as each backend implements the Keras backend API). Why do you think this is necessary? We've managed to do it across Theano and TF without much issues, even though they work quite differently (e.g. sessions, graphs, etc). Surely you can manage any custom functionality you need at the level of `K.Function()`.
No, do not do this
`data_utils` is no longer meant as a public namespace, use `utils`
Add a `# Arguments` section to the docstring.
Should be on the same line as the argument.
We could add a backend method to do it, with custom implementations in each backend...
cropping, not padding
should be self.forward.
cropping, not padding
Same: don't mention specific axes
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
@farizrahman4u this is still not fixed.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
PEP8: space after comma
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
We generally call it "KTF"
This would benefit from a bit more explanation on how to use TensorBoard, at least a link to https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
should be self.forward.
The entries in `config` should match the arguments in `__init__`.
The paragraph above can be replaced with `layer.weights`, which is always implemented.
Not convinced. Names should already be sensible by construction. What about just `weight.name`.
If some weights are incorrectly named, we better fix it at the level where the weights are created.
Please remove these changes so that this callback has the same behavior as the other callbacks. It could be discussed in another issue/PR.
@ns3284 Squash function has to be applied according to paper.
+1. Use case would be validating on more data than fits in GPU memory. So the generator has to return small-ish minibatches, but I want to validate on more than one minibatch.
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
Insert link to callbacks page
this is discussed in https://github.com/fchollet/keras/pull/7113
This will be more readable with code markers around `epochs`.
Code markers around `validation_split`
"the input name to a Numpy array" (singular in this case, for `Sequential`)
Code markers around tuple
Put the imports at the top of the file.
Use `'` everywhere for consistency. Do not break lines with `\`
Add space after `#`
`# Returns `
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
You don't need to specify this field if there is no return output
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Better to put the activation as the `activation` keyword of the layer below
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
Add imports to make the script compatible with py2/3: ```python from __future__ import absolute_import from __future__ import division from __future__ import print_function ```
filters //= 2
Better to put the activation as the `activation` keyword of the layer below
Blank line required before the next section
Blank line required before the next section
Theano -> Theano/TensorFlow
Most of this stuff is included in the config of `super` and thus does not need to figure here.
Need to fill in this section
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Use list markers
This is a new layer so no API conversion decorator is necessary.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
Let's not include that.
Previous version was more readable imo.
Format your docstrings like other docstrings in the codebase
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
This should be `activations.get(activation)` where `activations` is `from keras import activations`
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
`# Returns `
You don't need to specify this field if there is no return output
Space (" ") instead of period(" ")
Past few lines too long
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
Line too long
Still relevant? If so, explain the diff
```suggestion if k == KC: ```
What you call `one_hot` is referred to as `categorical` everywhere else in the codebase (e.g. categorical_crossentropy, cateorical_accuracy, to_categorical). But think we don't need this argument, when it comes to single-label classification, because you can automatically infer it from the shape of the predictions (if the last axis is size 1, it's binary, else categorical).
Link on a single line, otherwise it won't work (we don't enforce line length)
In general your docstrings have an indentation problem, the lines after the first one should be indented by 1 level (4 spaces).
Just say "either md5 or sha256".
I don't understand why we would want to deprecate md5, or have a preference for one algo or another. It's cool to support more than one hash function, but md5 works just fine for this purpose. We're just building a basic cache invalidation mechanism.
This default value will not work with Windows. Use None instead, and set it in the function code.
Just for reference for newbies, in windows, the cache folder is at C:\Users\USERNAME_HERE\.keras\datasets. I usually download the files manually and place them because sometimes it does fail downloading in my computer.
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Newline before this line
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Link on a single line, otherwise it won't work (we don't enforce line length)
In general your docstrings have an indentation problem, the lines after the first one should be indented by 1 level (4 spaces).
I don't understand why we would want to deprecate md5, or have a preference for one algo or another. It's cool to support more than one hash function, but md5 works just fine for this purpose. We're just building a basic cache invalidation mechanism.
Just say "either md5 or sha256".
This default value will not work with Windows. Use None instead, and set it in the function code.
Just for reference for newbies, in windows, the cache folder is at C:\Users\USERNAME_HERE\.keras\datasets. I usually download the files manually and place them because sometimes it does fail downloading in my computer.
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Newline before this line
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
@tiferet the API change in `sparse_categorical_crossentropy` is not something we can merge, sorry. Such an argument should be called `axis` and should default to `-1` (`K.image_data_format()` is a layer-level configuration argument and should not affect the default behavior of backend methods).
For now, after adding `axis` in the crossentropy losses, you will have to use a different loss function when doing pixelwise classification (image segmentation) in NCHW: ```python if K.data_format() == 'channels_first': loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(y_true, y_pred, axis=1) else: loss = K.sparse_categorical_crossentropy model.compile(optimizer=optimizer, loss=loss) ```
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
About this test: - please use the same docstring format as elsewhere in the codebase - use `'` as quote character for consistency - use lines that are <= 80 char
This is a significant regression which breaks a lot of my code too.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
This is correct.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
No `+` needed for string concatenation at the end
Better to use `_keras_history`
Better to use `_keras_history`
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
No need for `+` at the end. But needs a space after `.`.
var is a reserved keyword, use `v` or something like that.
Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.
"Name-based weight loading (instead of topological weight loading)"
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
Should be on the same line as the argument.
Introduce line return after `(` to reduce line length
"The weight file you are trying to load is in a legacy format that does not support name-based weight loading".
Singe the names are expected to match across models, "in the current model" does not make sense here.
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
It is be preferable to confine changes to this loop instead of introducing a new layer method. Here, we just need a loop that builds the `weight_values` list and flips convolution kernels if `layer` is an instance of a convolution layer.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Blank line required before the next section
Blank line required before the next section
Maybe "strides". I had been considering deprecating `subsample` in favor of `strides` in Conv2d, too.
Theano -> Theano/TensorFlow
Most of this stuff is included in the config of `super` and thus does not need to figure here.
Need to fill in this section
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
This is a new layer so no API conversion decorator is necessary.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
You can replace the next lines with `return - dice_coef_loss(y_true, y_pred)`
The targets / predictions are assumed to be in the [0, 1] interval but that is not enforced. It should be.
Capital variable names is not appropriate for scalar variables
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
`+ K.epsilon()` in the denominator.
Prefer more explicit variable names.
Please rename `sparse_top_k_categorical_accuracy` for consistency with other metrics names
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
What you call `one_hot` is referred to as `categorical` everywhere else in the codebase (e.g. categorical_crossentropy, cateorical_accuracy, to_categorical). But think we don't need this argument, when it comes to single-label classification, because you can automatically infer it from the shape of the predictions (if the last axis is size 1, it's binary, else categorical).
But we would need this argument in case we want to support *multi-label* binary classification, where you have multiple dimensions on the last axis, and each one of them encodes a binary class prediction. So I think we should have the argument. And we should add support for: - multi-class, single-label categorical classification - multi-class, multi-label binary classification
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
"weights incident to each hidden unit" is not clear in this context. A "hidden unit" is generally understood as a coefficient in the layer weight tensor.
Theano -> Theano/TensorFlow
Blank line required before the next section
Blank line required before the next section
This should be max.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Please introduce line breaks in the docstring to avoid very long lines.
This one is fine too
No `+` needed for string concatenation at the end
No need for `+` at the end. But needs a space after `.`.
Better to use `_keras_history`
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
Yes, that was changed some time ago. The doc should be updated.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
@farizrahman4u this is still not fixed.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
Should be `inputs` and `mask`.
@ns3284 Squash function has to be applied according to paper.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
Could you use `output = Dense(2, name='dense_B')(c1)` instead? Using a temporary variable make the reader believe that you are going to reuse this layer in the test or in the network.
cropping, not padding
Should we rely have to rely on `np.dot`? Besides the fact that it's expensive, it's also a black box. The logic should be inferable from reading the code.
For theano, `ratio` needs to be `integer`. ```python ratio = height_factor // width_factor ```
Format your docstrings like other docstrings in the codebase
I am also wondering whether it is necessary to specify the original height and width as part of the arguments (this information is part of the tensor X).
It is looking like `height_factor` and `width_factor` can only be positive integers. This should be specified in the docstring. The API makes it sound like `*_factor` could be a float (e.g. 0.75 for an output image with 75% of the original height).
in the tests k.backend() == `cntk` might want to lower case here
maybe tell the user the valid data_formats
`_set_keras_shape_for_reduction` would arguably be a better name. This can be reused for any reduction op (sum, etc).
No point in calling super here
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
This is not the same argument. The proper behavior here would be: - if `forget_bias_init` is set to `"one"`, set `unit_forget_bias` to True - else ignore the argument, and in this case, raise a warning specifying the argument was ignored. You will need custom code to do this.
You can make this a dict instead of a list of tuples, that would be more natural. In this case, the order of the values does no matter.
Missing a space between "argument" and "has". Also tell users to use the `unit_forget_bias` argument instead.
This should be literally what the function call should look like. So the user can just copy and paste it.
'p' is already removed when, kwargs.pop('p')
In case `padding` is a positional argument, quote characters will be required around it here (since it's a string). E.g. don't print `MaxPooling1D(3, valid)`, instead print `MaxPooling1D(3, "valid")`.
`pool_size` would be commonly used as positional argument.
Actually, you can just use the `convert_legacy_kwargs` utility function I just added.
You're right. In that case we should make sure the user does not pass more than 1 positional argument.
For simplicity, I would simply disallow `data_format` as a positional arg. It would be bad practice to pass it as positional anyway.
Yes, that's right
These should be `ValueError`
I don't understand why; `tf.nn.separable_conv2d` does support strides.
At this point it would be fine to do the dimshuffle without the call the `_postprocess_conv2d_output`
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
At this point it would be fine to have `np_kernel = kernel.eval()`
I will note in passing that doing one conv per channel is not an efficient way to implement depthwise conv (too much overhead). Preferable to do a single conv with a diagonal kernel.
conv3d2d does use the new version `nnet.conv2d` so it should be fine https://github.com/Theano/Theano/blob/master/theano/tensor/nnet/conv3d2d.py#L244
`conv3d2d` that is being used in this function uses `tensor.nnet.conv2d` for the convolutions. [This page](http://deeplearning.net/software/theano/library/tensor/nnet/conv.html) mentions that `nnet.conv2d` uses cuDNN by default if available, so I think that this function will indeed take advantage of cuDNN 2d convolution operation if available. This makes me wonder why the conv2d function in this same file uses `dnn.dnn_conv` instead of `tensor.nnet.conv2d` when cuDNN is detected, instead of simply using `nnet.conv2d`.
Fix indent here and below
Better to add `rank` here
This would read clearer with format strings, and we are trying to gravitate towards more uniform error messages in keras. f'`cropping` parameter of Cropping layer must be greater than the input shape. ' f'Recieved: inputs.shape={inputs.shape}, and cropping={self.cropping}'
Same: don't mention specific axes
cropping, not padding
Line too long, and not PEP8 compliant. Break it down into a few lines.
The indices of the axes depend on the dim ordering. Just say "width and height"
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
No warning should occur with default settings. It is safe to remove this.
Please print a message for this action (like we do in `on_train_end`): "Restoring model to its state at the end of the best epoch."
I really don't see how incrementing `self.wait` at the end of each epoch is the correct behavior. You have access to the epoch counter `epoch`, if you just want to skip the first epoch you can? E.g. if it's the first epoch, then set the best score / weights and continue.
You don't have to return from the function. If the current epoch was best and `restore_best_weights= True` then the weights wont ever be restored which is done in the code following this line.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
`try` with an `assert` is not the way to test inequality between two integers...
What case does this cover? Also, here we have twice an unchecked assumptions that we are dealing with a list; all we know is that it isn't a float. Not all non-floats are lists.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
"eror" -> "error"
This is a significant regression which breaks a lot of my code too.
The right way to check if a class attribute is a property is: ```python is_property = isinstance(type(obj).attribute, property) ``` So here it would be: ```python if not isinstance(type(self).losses, property): self.losses += losses ```
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
I fear this is a brittle mechanism. It will work in simple cases but will fail in advanced cases.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
Prefer more explicit variable names.
Introduce an `if` block to avoid a very long line.
Why not return `None` instead? Wouldn't it be more efficient (one less element-wise multiplication in the objective function).
No, do not do this
@farizrahman4u Isn't `ndim` always going to be 1 for `n`, I think you meant the equivalent of `len(n)`
@farizrahman4u Undefined variable `K`
Is this try/except necessary? It's a test
No need for this line
PEP8: spaces around operators
No reference to `_keras_shape`, that's an implementation detail. Call it "static shape"
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
@briannemsick Sorry, I wasn't clear about my main point! 1. The tqdm API UX is worth considering for inspiration when designing stateful metrics, which must be updated at every batch and displayed to the user. 2. I'm suggesting stateful metrics should be a callback call and not a special init variable that gets passed around to every class in keras. Rather than actually including tqdm (which is just a convenient option), the point is the excellent API UX style of tqdm for the stateful task of iterating through batches and counting them.
I think this is out of scope, the goal of the PR is to support stateful metrics. A complete rewrite of progbar (if that's the route taken) should be a follow on PR.
> The current progbar is fine. We're not changing the existing API, we just extend it in a really simple way to support a new use case. Fair enough, but rather than a different progbar please allow me to suggest a **different, composable stateful metric design**, unrelated to progbars, which uses the tqdm API for inspiration. In other words, consider a stateful metric which is a decorated iterator implementing `next()`, `def __iter__(self):`, `update()`, `clear()`, ` def __len__(self):`, etc.
0.05 is a better interval. 50ms is definitely perceptible.
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
You can use parentheses to structure code into several lines.
Insert link to callbacks page
this is discussed in https://github.com/fchollet/keras/pull/7113
Code markers around `validation_split`
Invalid Python 3 syntax.
Are you sure about this? Justify.
Order arguments vertically to avoid an overly long line.
Why do you need two methods? You should only need one...
Likewise, please format docstring
This is a bug, please remove
However in some cases there will be no weights. This assert is a bug...
Please add a check and raise `ValueError` if appropriate. Reshape may not be possible.
Transposing the weights is always the right thing to do regardless of original backend.
This is a bit confusing. Maybe simpler: ``` if skip_mismatch: if K.int_shape(symbolic_weights[i]) != weight_values[i].shape: warnings.warn(...) continue weight_value_tuples.append(...)
These two entries (if Bidirectional, if TimeDistributed) should be added in the big `if` switch without affecting the rest of the code. Currently we have 150 lines changed for should be a ~15 lines change...
In this case the better solution would to check `dtype(x)`.
This is the TF backend, so don't rely on `_keras_shape`, instead use `tuple(kernel.get_shape().as_list())` (always available).
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
Processing of `np_kernel` should be removed from this function
At this point it would be fine to have `np_kernel = kernel.eval()`
I don't understand why; `tf.nn.separable_conv2d` does support strides.
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
Change to "pooling over conv_dim2 and conv_dim1"
Change to "pooling over conv_dim3"
This default value will not work with Windows. Use None instead, and set it in the function code.
Just for reference for newbies, in windows, the cache folder is at C:\Users\USERNAME_HERE\.keras\datasets. I usually download the files manually and place them because sometimes it does fail downloading in my computer.
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
In general your docstrings have an indentation problem, the lines after the first one should be indented by 1 level (4 spaces).
I don't understand why we would want to deprecate md5, or have a preference for one algo or another. It's cool to support more than one hash function, but md5 works just fine for this purpose. We're just building a basic cache invalidation mechanism.
Just say "either md5 or sha256".
Link on a single line, otherwise it won't work (we don't enforce line length)
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Newline before this line
Looks good to me now.
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Fix indent. Use `pylint` as linter.
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
I mean `RuntimeError`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
The `bn%d` looks unnecessary.
@ns3284 Squash function has to be applied according to paper.
Singe the names are expected to match across models, "in the current model" does not make sense here.
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
"The weight file you are trying to load is in a legacy format that does not support name-based weight loading".
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
It is be preferable to confine changes to this loop instead of introducing a new layer method. Here, we just need a loop that builds the `weight_values` list and flips convolution kernels if `layer` is an instance of a convolution layer.
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
It makes it much easier to keep track of parts of the code that are backend-specific.
It should be clarified in the docstring what "compilation" entails.
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
Is there a reason why there is not a `SpatialAlphaDropout` like there is a `SpatialDropout`? In the paper they are not explicitly doing it, but they do have an argument `noise_shape` on their Github. When they release the code for more advanced datasets, we'll know for sure I guess.
pg 6 of the [paper](https://arxiv.org/pdf/1706.02515.pdf) says: > Therefore, we propose âalpha dropoutâ, that randomly sets inputs to Î±
Use a variable with a complete name, not `l`.
cropping, not padding
Use ` around code keywords everywhere in docstrings..
The entries in `config` should match the arguments in `__init__`.
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
The indices of the axes depend on the dim ordering. Just say "width and height"
Code markers around `validation_split`
Code markers around tuple
This will be more readable with code markers around `epochs`.
"the parameter" is redundant, you can simply say `epochs`
Code markers around code keywords (`)
"output names to Numpy arrays"; "`y` can be"
There could be multiple model outputs
Same, can be a list
Insert link to callbacks page
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
Please use one import per line from now on.
can tf.logging be hooked into this? that may be the best course of action https://www.tensorflow.org/api_docs/python/tf/logging
`K.floatx()` is the preferred way to access this.
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
There are added empty lines. Please remove them.
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
Better to put the activation as the `activation` keyword of the layer below
Better to put the activation as the `activation` keyword of the layer below
Should this be part of the public API? It sounds like it should be an internal method.
The targets / predictions are assumed to be in the [0, 1] interval but that is not enforced. It should be.
Capital variable names is not appropriate for scalar variables
`mathews_correlation` or `matthews_correlation_coefficient`
`+ K.epsilon()` in the denominator.
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
You can replace the next lines with `return - dice_coef_loss(y_true, y_pred)`
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
When a mask is provided, it means that the input has time steps. However the input might not necessarily be `(samples, timesteps, dims)`, it should more generally be considered to be `(samples, timesteps, **)` (e.g. sequences of pictures).
Respect PEP8 conventions.
An optimizer instance is not serializable (it's a Python object). The previous 4 lines were serializing it. Revert this
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
This is a private method, for safety, better not pass a default value for `include_optimizer`. Users shouldn't be using it, and when working on Keras itself it is easy to forget to pass it.
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
It should be clarified in the docstring what "compilation" entails.
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
Singe the names are expected to match across models, "in the current model" does not make sense here.
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
No need for such abbreviations, they just make code harder to read.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
No need for this line
Is this try/except necessary? It's a test
PEP8: spaces around operators
Use `'` as the quote character for consistency with the rest of the file
Also, you don't actually need these error messages after `assert` since this is a unit test
Let's add a TODO for this one
Let's add a TODO for this one
Can be replicated in all backends
Let's add a TODO for this one
Can be replicated in all backends
Let's add a TODO for this one
Let's add a TODO for this one
Can be replicated in all backends (it's `-=`)
Should not be public
This is also TF-specific.
This is the TF backend, so don't rely on `_keras_shape`, instead use `tuple(kernel.get_shape().as_list())` (always available).
These should be `ValueError`
I don't understand why; `tf.nn.separable_conv2d` does support strides.
At this point it would be fine to do the dimshuffle without the call the `_postprocess_conv2d_output`
At this point it would be fine to have `np_kernel = kernel.eval()`
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
Processing of `np_kernel` should be removed from this function
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
Change to "pooling over conv_dim3"
Reformat this in a way that avoids the use of `\`
PEP8 issues (space around operators)
This probably won't help with your actual problem, but the following PR was very helpful when I needed to fix feed dict issues: https://github.com/fchollet/keras/pull/7064
This is the non-generator path. 0 is added to val_data here : https://github.com/keras-team/keras/pull/9796/files/86e5448ff06d30bebfdf8a4781562ad6abaabd1c#diff-b25d82c3f751f73f6e62b8455547ac73R124
Please add a note saying that the learning_phase should be added by `fit_generator`, otherwise it's a little confusing.
Meaning of error message is vague, please clarify. Also note that you're missing a space before `(` Also please shorten your lines to 80 chars.
`batch_size` parameter needs to be deprecated too.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
In that case, I think this error and the corresponding test should be kept.
Use backticks around codde keywords
Please format the link (`as described [here](...)`)
Also say "may be slightly inconsistent" since 1) it is not necessarily the case depending on various parameters, 2) the difference is minor and generally unimportant
This sentence is important and should be kept
Shapes mentioned in the docstring are generally 2D; should be 3D
Use list markers
Need to fill in this section
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Use bullet points
This is a new layer so no API conversion decorator is necessary.
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
"When using `steps_per_epoch`, ..."
Prefer `if steps_per_epoch is not None`
Style: code markers around `Sequence`
this is discussed in https://github.com/fchollet/keras/pull/7113
No need to capitalize Input or Tensor
Insert link to callbacks page
Code markers around `validation_split`
Code markers around tuple
Set default `batch_size` to None, like in `fit`.
I'm glad I could help :)
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
No warning should occur with default settings. It is safe to remove this.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
In that case, I think this error and the corresponding test should be kept.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
`batch_size` parameter needs to be deprecated too.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
Break up line
Singe the names are expected to match across models, "in the current model" does not make sense here.
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
"Name-based weight loading (instead of topological weight loading)"
"The weight file you are trying to load is in a legacy format that does not support name-based weight loading".
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
It is be preferable to confine changes to this loop instead of introducing a new layer method. Here, we just need a loop that builds the `weight_values` list and flips convolution kernels if `layer` is an instance of a convolution layer.
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
It should be clarified in the docstring what "compilation" entails.
Would it be possible to simplify by doing ```python if axis is not None: axis = tuple(axis) ```
You are right. My bad. I dont think it's necessary to use an intermediate variable though: ```python if isinstance(axis, list): axis = tuple(axis) ```
Could you try benchmarking this against the use of `transpose + softmax + transpose`? It may be that transposing is faster (but impossible to know in advance).
For numerical stability, you have to do T.exp(x - x.max())
The exact transposition depends on the `axis` value and `x.ndim`. But we'd only need to benchmark it for one configuration. For `axis=2` and `x.ndim=4` your code looks right to me.
Would the type be consistent with the Theano backend? I don't think so... Types should be consistent.
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
Format your docstrings like other docstrings in the codebase
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
`_set_keras_shape_for_reduction` would arguably be a better name. This can be reused for any reduction op (sum, etc).
Replace with ``` if len(mask.get_shape()) > ndim: raise ValueError(...) ```
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
You can replace these lines with `outputs.set_shape((inputs.get_shape()[0], None, None))`
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
Should be `inputs` and `mask`.
Also I think the line does too much, breaking it into several lines would be preferable.
Better to add `rank` here
Please introduce line breaks in the docstring to avoid very long lines.
This one is fine too
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
This will break if `layer` is a container.
Two line breaks after the first sentence.
It should be clarified in the docstring what "compilation" entails.
Better to use `_keras_history`
Thinking about it, I think `conv_dim*` like in the code would be the clearest here. Otherwise we should explicitly mention that these are the dimensions the convolution will operate on.
Sections in docstring should be separated with a line break. I don't think the `len_` prefix everywhere is necessary, just `input_dim*` seems clear enough.
It's all very confusing, and `Convolution2D` wasn't doing great on that front either. Here I think we should refer to the kernel dimensions as `kernel_dim*` and to the target tensor dimensions as `conv_dim*`.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
`if not {expression} != {expression}:` is quite a strange structure. Did you mean: ```python dtype = getattr(x, 'dtype', None) if dtype != K.floatx(): x = np.asarray(x, dtype=K.floatx()) ```
In this case the better solution would to check `dtype(x)`.
Then remove the test case. I assume what's being raised is a TypeError and that's why it would fail. It doesn't make sense to have this check for this function and nowhere else.
You can remove this check. The error will be raised downstream anyway.
In this case the better solution would to check `dtype(x)`.
In this case the better solution would to check `dtype(x)`.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
These should be `ValueError`
Line too long (and several other lines in this file as well)
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Remove leading space
Use code markers around `put()`
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
I like this!
To be clear, the idea (to my understanding) is that `OrderedEnqueuer` will be the class that knows about `batch_size`. The generator that `fit_generator` receives is constructed in `DatasetEnqueuer.get()`. This generator pops `batch_size` items from the queue and then calls `self.dataset.create_batch(lst_items)` to obtain the actual batch.
I just realized that I missed something important. These `indexes` are not the indexes of individual samples. These are indexes of batches. It means that forever you will have the same samples in the same batch, even if you shuffle the indexes. It takes the edge out of some important operations (i.e. batch-normalization). I find this a bit confusing. What I would expect is that the Dataset will store samples, not batches, and that `getitem` would return a single sample. I don't think that a Dataset should know about the `batch_size`. It makes more sense to me that the packaging of the samples into batches would happen on the fly, in the `DatasetEnqueuer.get()` method. If the `batch_size` is 32, then Enqueuer should pop out 32 elements from the queue (or less if there is a StopIteration), and call a `batcher` function (perhaps it can be provided by `Dataset`) that turns a list of samples into a batch.
@Dref360 yes I think it is best to keep the same behavior as before.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
should be self.forward.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
@farizrahman4u this is still not fixed.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Line too long, and not PEP8 compliant. Break it down into a few lines.
PEP8: space after comma
Awesome : ) But now you'll need to remove the outdated exception as well ; )
Also around `=`
Spaces around `<`
`if n.__class__.__name__ == ...`
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
should be self.forward.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
PEP8: space after comma
Please make this method private.
"Passed to `tf.Session.run`", with ` around code
self.current_feed_dict = {} if self.feed_dict is None else self.feed_dict Clearer
You added a `name` argument but it isn't used downstream.
var is a reserved keyword, use `v` or something like that.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Please make this method private (unless there is a rationale for making it part of the public API).
The paragraph above can be replaced with `layer.weights`, which is always implemented.
Per the failing docstring test, this docstring needs a `Raises` section mentioning the ValueError: https://travis-ci.org/fchollet/keras/jobs/282558708
I don't think that `0` is a valid shape dimension.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Remove leading space
Use code markers around `put()`
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
@Dref360 yes I think it is best to keep the same behavior as before.
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
In any case, this PR is a great addition for Keras, thank you!
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
I just realized that I missed something important. These `indexes` are not the indexes of individual samples. These are indexes of batches. It means that forever you will have the same samples in the same batch, even if you shuffle the indexes. It takes the edge out of some important operations (i.e. batch-normalization). I find this a bit confusing. What I would expect is that the Dataset will store samples, not batches, and that `getitem` would return a single sample. I don't think that a Dataset should know about the `batch_size`. It makes more sense to me that the packaging of the samples into batches would happen on the fly, in the `DatasetEnqueuer.get()` method. If the `batch_size` is 32, then Enqueuer should pop out 32 elements from the queue (or less if there is a StopIteration), and call a `batcher` function (perhaps it can be provided by `Dataset`) that turns a list of samples into a batch.
I like this!
Optimizers have a `get_config` method precisely for this purpose.
`compile=True` is a more user-friendly API.
Also add a `# Arguments` section for `*args`
This line should be right after `"""`. Put "`" around function names.
It makes it much easier to keep track of parts of the code that are backend-specific.
This warning does not seem necessary
Two line breaks after the first sentence.
It should be clarified in the docstring what "compilation" entails.
Don't do this, prefer explicit checks
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
No `+` needed for string concatenation at the end
Better to use `_keras_history`
No need for `+` at the end. But needs a space after `.`.
Yes, that was changed some time ago. The doc should be updated.
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
Nit: ` around code keywords
Please make this method private (underscore) and make the docstring style-compliant.
Since this is ad-hoc and specific to a single method it shouldn't be a class method but rather a function defined on the fly in `compile`.
Better to leave this part of the code unchanged and implement a property setter on the wrapper.
That's a good point. Just fix the indentation in that part of the code, then.
It seems you are indenting with 8 spaces. It should be 4.
The paragraph above can be replaced with `layer.weights`, which is always implemented.
Not convinced. Names should already be sensible by construction. What about just `weight.name`.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
We could add a backend method to do it, with custom implementations in each backend...
@tiferet the API change in `sparse_categorical_crossentropy` is not something we can merge, sorry. Such an argument should be called `axis` and should default to `-1` (`K.image_data_format()` is a layer-level configuration argument and should not affect the default behavior of backend methods).
For now, after adding `axis` in the crossentropy losses, you will have to use a different loss function when doing pixelwise classification (image segmentation) in NCHW: ```python if K.data_format() == 'channels_first': loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(y_true, y_pred, axis=1) else: loss = K.sparse_categorical_crossentropy model.compile(optimizer=optimizer, loss=loss) ```
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
About this test: - please use the same docstring format as elsewhere in the codebase - use `'` as quote character for consistency - use lines that are <= 80 char
This is a significant regression which breaks a lot of my code too.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
This is correct.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Do not use backslashes to break lines.
Better to use a more explicit variable name, like `key`
This warning does not seem necessary
Optimizers have a `get_config` method precisely for this purpose.
The indices of the axes depend on the dim ordering. Just say "width and height"
cropping, not padding
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
It should be clarified in the docstring what "compilation" entails.
Same: don't mention specific axes
cropping, not padding
I believe you should be able to remove a lot of redundant code by subclassing `RNN`. There are lots of shared methods.
Use bullet points
Break up long line
Format your docstrings like other docstrings in the codebase
`K.floatx()` is the preferred way to access this.
Please remove new line (`"""Instantiates`).
You don't need to specify this field if there is no return output
`# Returns `
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
```suggestion if k == KC: ```
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
Style: break long lines in the test
Line too long (and several other lines in this file as well)
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
Use `'` everywhere for consistency. Do not break lines with `\`
Still relevant? If so, explain the diff
Line too long
Introduce an `if` block to avoid a very long line.
The same concern exists for Theano with `data_format='channels_first'`. I do not know the extent of the performance hit. My guess is that it is small. I note that [native TF ops](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) use the same kernel shape for both data formats, which indicates that performance optimization can probably be handled at the backend level.
Whatever the backend uses internally, the kernel shape is standardized to `self.kernel_size + (input_dim, self.filters)`, to allow portability across models. Revert this change. Note: we used to have 2 different possible shapes for kernels, in Keras 1.0. It was a nightmare. That's why it is now standardized.
Line too long, and not PEP8 compliant. Break it down into a few lines.
Same: don't mention specific axes
cropping, not padding
This should be max.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
I will note in passing that doing one conv per channel is not an efficient way to implement depthwise conv (too much overhead). Preferable to do a single conv with a diagonal kernel.
I don't quite understand this message. Do we expect users to be familiar with the concept of "dynamic axis" here? Doesn't seem standard
No need for final space
No need for final space
No need for final space
This is already validated in the constructor, no need.
We want to print the full shapes for clarity. Creating a new array in the exception is not an issue: we're interrupting execution anyway, so we don't care about resources consumption.
Use f-strings for string formatting (or otherwise `format()`). The error message should include what the input shape was and what the output shape would have been. "check the input shape" is not actionable.
Introduce an `if` block to avoid a very long line.
Please make this method private.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
Please use backticks around code keywords.
The `(` should be next to the `]` in order for the markdown to render properly.
Please make sure the link fits on a single line
This only applies when save_best_only is true correct? We should call that out. Something like... ``` Initial "best" value of the metric to be monitored. Only applies if `save_best_value=True`. If set, the checkpoint will only be saved if the model metric value is better than this value. ```
Please update the docstrings as well.
this line is over 80 characters.
Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
Looks good to me now.
This function does not have a properly formatted dosctring (see other dosctrings for reference)
At this point it would be fine to have `np_kernel = kernel.eval()`
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
cropping, not padding
This should be max.
Line too long, and not PEP8 compliant. Break it down into a few lines.
Same: don't mention specific axes
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
It's "depth, height and width" in this order (was previously incorrect)
Style: break long lines in the test
and -> or
Shapes mentioned in the docstring are generally 2D; should be 3D
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
You don't need to specify this field if there is no return output
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
var is a reserved keyword, use `v` or something like that.
Looks good to me now.
It's all very confusing, and `Convolution2D` wasn't doing great on that front either. Here I think we should refer to the kernel dimensions as `kernel_dim*` and to the target tensor dimensions as `conv_dim*`.
Thinking about it, I think `conv_dim*` like in the code would be the clearest here. Otherwise we should explicitly mention that these are the dimensions the convolution will operate on.
Sections in docstring should be separated with a line break. I don't think the `len_` prefix everywhere is necessary, just `input_dim*` seems clear enough.
Specify that this would be for 128x128x128 volumes with 3 channels
Shapes mentioned in the docstring are generally 2D; should be 3D
Theano -> Theano/TensorFlow
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Blank line required before the next section
Blank line required before the next section
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
`# Returns `
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
Use `'` as the quote character for consistency with the rest of the file
Also, you don't actually need these error messages after `assert` since this is a unit test
You don't need to specify this field if there is no return output
No need for this line
Is this try/except necessary? It's a test
PEP8: spaces around operators
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
Space between "take" and "place"
I'd say we can remove both warnings.
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
No need for final space
Introduce an `if` block to avoid a very long line.
Nit: ` around code keywords
Line too long
Better to put the activation as the `activation` keyword of the layer below
`any` seems it doesn't belong here. You'll want this to return an array. Additionally, I would prefer not casting to `float32` and use the native TF `bool` type instead (i.e. this function should be a thin wrapper over `tf.nn.in_top_k`). The fact that Theano does not have a bool type has to be dealt with in the Theano backend and should not affect the TensorFlow backend.
Use `'` as string delimiter for consistency
You can replace these lines with `outputs.set_shape((inputs.get_shape()[0], None, None))`
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
Clarify the error message; a "Keras tensor" is the output of a Keras layer
With not mask, how do you handle a batch with different sequence lengths? Said a batch of 2, with first input have lenght 2 and the 2nd has a lenght 4. Then you would do a right padding on the 1st sequence to make it have length 4. In you implementation without mask, for the 1st input, the **true** energy should be `b_start + x1' y1 + x2' y2 + y1' U y2 + b_end` but in your implementation, there isn't a `b_end`, but with an additional `x3' y3' + x4' y4 + y2' U y3 + y3' U y4`, where `y3 = y4 = 0`. The consequence is, the above two formulations are not equivalent, at least when you take derivative with respect to `U_00` (top-left element in matrix `U`), the derivative isn't the same. Right? (also, `U_00` and `U_11` are not `exchangable`, but why we treat label 0 and label 1 differently?) Also when you compute the normalization constance (free energy in your code), you have to integrate over `y3, y4` (which are paddings). I guess that's what you mean by "padding elements act as a virtual end label". However, if when you think about taking derivative with respect to `U` or `b_end`, your approach is not equivalent to a real CRF. One very obvious observation is, `y3, y4`, the padding, affects the derivative with respect to `U`, and therefore, the paddings plays a role on the final outcome. The more paddings you have, the more impact the paddings affects the outcome. This is unexpected from my point of view. Lastly, another simple observation, a model with and without the end energy (`b_end`), the numbers of trainable parameters are not the same. So the two models are not the same.
I think it would be good to assert than the input tensor is at least 3D (to avoid a more obscure error message later).
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
I believe you don't need this method, the inherited one should work fine.
You can use `K.is_keras_tensor`
Here is the generic version that will work for any ndim: return T.TensorType(dtype, (False,)*ndim)(name) So this whole if/elif/.../else will disapear.
Then you should apply the same modifications in the TensorFlow backend, for consistency.
But about the `broadcastable` bool tuple: is it required to build the graph? Could we have a tensor that can accept data of _variable_ ndim (like `tf.placeholder()`, which is ndim-agnostic)? I'm asking because occasionally the ndim of certain inputs isn't known at compilation time, which is difficult to work around.
Please use PEP8 conventions: spaces around operators (.e.g `*`)
var is a reserved keyword, use `v` or something like that.
Bit of redundancy: this sets `input` twice (here and in the next few lines).
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
var is a reserved keyword, use `v` or something like that.
Nit: please shorten lines here to 80 char or less (also in `initializers.py`)
Please use `'` as quote character for consistency.
This still seems hackey. Maybe a better or more clear solution could be something like: ``` python from keras import backend as K if K._BACKEND == 'tensorflow': logic else: other_logic ```
Actually we don't; what matters is that the weights are in a deterministic order. In _what_ order they are is not very important. We could simply sort by `auto_name`.
Since this is about dealing with a Theano-specific behavior, the syntax should be: if Theano: else:
The weights should be sorted. Simply catching the exception is not the right fix...
The paragraph above can be replaced with `layer.weights`, which is always implemented.
Likewise, please format docstring
Please format the docstring like the others, with an `# Arguments` and `# Returns` section
We could add a backend method to do it, with custom implementations in each backend...
Not convinced. Names should already be sensible by construction. What about just `weight.name`.
If some weights are incorrectly named, we better fix it at the level where the weights are created.
`K.eye` should already follow this same behavior (at least it does in TF). So no padding necessary.
Only the `tf.eye` supports the non-square. Currently, all the three `K.eye`s don't support that, thus I proposed #12534.
I think we could refactor this to call `K.eye` instead. The advantage of `K.eye` is that for TF it will not store the numpy array returned by `np.eye` in the TF graph (so the graph will be smaller).
You are requesting a potentially-breaking behavior change in both Keras and TensorFlow. It's possible, but you will have to get the approval of a number of stakeholders. I suggest you start by opening a well-argued issue on the TensorFlow repo.
Inserting this line changes the initial weight values of some models, and it may sometimes be the difference between a model starting to train or not. Besides that, Keras optimizers should be consistent with TF optimizers (in `tf.init_ops`). So, please revert this line.
`if unknown is not None`
Do not need the enumerate here. i is not used.
"samples drawn from"
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
Style: spaces around `**`
Can we have a better API than `padding=(1, 1, 1, 1)`? Maybe `padding=((1, 1), (1, 1))` (but that one is not very good either). Please think of something. Maybe multiple arguments.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Change to 0. Also please format code elements in docstring with "`" (tuples. dicts).
Change to "pooling over conv_dim2 and conv_dim1"
Change to "pooling over conv_dim3"
This should be max.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
cropping, not padding
Same: don't mention specific axes
Please put "`" around code keywords.
More elegant would be to shuffle an array of indices once, then use the array to index X and y (yes, unlike the current code in this module, but like the code in `models.py`).
This seems to make `reset()` in `flow()` superfluous. If so I think it would be cleaner and still safe to just remove the `reset()` from flow and have the index_array generator handle resetting all its counters.
Please use readable variable names such as `array`
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
Docs should be clarified: the output is `(x, y)` unless `sample_weight` is specified.
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
this is discussed in https://github.com/fchollet/keras/pull/7113
This is already validated in the constructor, no need.
Please use `np.ceil` instead
Needs a space after {}
That's a good warning to have. Reformat: `"` should be `'`. "`output_shape` argument not specified for layer {} and cannot be automatically inferred with the Theano backend. Defaulting to output shape {} (same as input shape). If the expected output shape is different, specify it via the `output_shape` argument. "
Theano -> Theano/TensorFlow
Blank line required before the next section
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Looks good to me now.
You can use `K.is_keras_tensor`
What if the layer does not have a name, though? There should be an exception or a fallback (preferably an exception, for maximum explicitness).
Yes, that would make sense.
This reshape will fail for some shapes (all inputs X where X.shape[1] is odd) because the number of elements in the tensor will not be conserved. Additionally it appears that the maxout is done only of the 1st tensor dimension (indexing from 0). This would be time in case of a temporal input, of channels for a picture input. I don't thinking that's how it should work in these cases (it should be respectively the 2nd and 2nd-3rd dimensions).
> `T.sqrt(self.p/(1-self.p))` Something should be done to avoid division by zero in case p = 1... maybe clipping p to [epsilon, 1-epsilon]? In terms of coding style, please use spaces around operators and use floats in float operations.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
`if n.__class__.__name__ == ...`
should be self.forward.
PEP8: space after comma
@farizrahman4u this is still not fixed.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
`K.floatx()` is the preferred way to access this.
I believe you should be able to remove a lot of redundant code by subclassing `RNN`. There are lots of shared methods.
Explain what the difference is and what motivates it
Please fix the identations issues in the file. I'll review the PR in the next few days. Thanks for updating it!
add space after `(w[1])`
`# Returns `
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
You don't need to specify this field if there is no return output
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
Need spaces at the end of every line in this message (this is also true of a few other messages)
I don't quite understand this message. Do we expect users to be familiar with the concept of "dynamic axis" here? Doesn't seem standard
Need at least rank 3
The error message seems unclear. Please update it to something like: "`go_backards` is not support with variable-length sequences. Please specify a static-length for your sequences"
No need for final space
No need for final space
"has only rank %d."
Got it. Since the error is specific to Theano, it seems fine.
Is this error actually necessary? Couldn't we allow input_length=1 and unroll=True? (loop over 1 element).
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
replace `with` with `to`
`CNTK` (to have consistent capitalization with other messages) `when constructing the trainer`
Period after `inputs`
Spaces at the end of lines
No need for final space, use ` around train_function
Spaces at the end of lines
No need for final space
No need for final space
No need for final space
and -> or
"on how masking is handled by the wrapped layer"
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
The indices of the axes depend on the dim ordering. Just say "width and height"
Change to 0. Also please format code elements in docstring with "`" (tuples. dicts).
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
I vote for option number two. That seems the most consistent with other parts of the Keras API.
This should be max.
Should be `inputs` and `mask`.
cropping, not padding
Same: don't mention specific axes
No need for final space
No need for final space
I don't quite understand this message. Do we expect users to be familiar with the concept of "dynamic axis" here? Doesn't seem standard
Need spaces at the end of every line in this message (this is also true of a few other messages)
in the tests k.backend() == `cntk` might want to lower case here
maybe tell the user the valid data_formats
Past few lines too long
Clarify or remove.
`cnn` sounds like a model instance, but it's a tensor. Call it `x`
@ns3284 Squash function has to be applied according to paper.
At this point it would be fine to have `np_kernel = kernel.eval()`
Processing of `np_kernel` should be removed from this function
Please raise a `RuntimeError` instead of using `assert`.
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
conv3d2d does use the new version `nnet.conv2d` so it should be fine https://github.com/Theano/Theano/blob/master/theano/tensor/nnet/conv3d2d.py#L244
`conv3d2d` that is being used in this function uses `tensor.nnet.conv2d` for the convolutions. [This page](http://deeplearning.net/software/theano/library/tensor/nnet/conv.html) mentions that `nnet.conv2d` uses cuDNN by default if available, so I think that this function will indeed take advantage of cuDNN 2d convolution operation if available. This makes me wonder why the conv2d function in this same file uses `dnn.dnn_conv` instead of `tensor.nnet.conv2d` when cuDNN is detected, instead of simply using `nnet.conv2d`.
Most of this stuff is included in the config of `super` and thus does not need to figure here.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Set the default value to `0.0` rather than None, for consistency with `fit`
This function does not have a properly formatted dosctring (see other dosctrings for reference)
This should default to `None`, not to a boolean
Please use readable variable names such as `array`
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
It doesn't really make sense to me, because random transformations are important to have at test time as well (because they modify the statistics of the data). Best evals are from multiple random transforms, with results merged via power averaging.
We generally call it "KTF"
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
Please use `np.ceil` instead
Same remark as before regarding `output_shape`.
@farizrahman4u this is still not fixed.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
should be self.forward.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
PEP8: space after comma
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
Docstring contains a few typos, please fix / rephrase
One-line docstring description should end with a period.
Use markdown format for links
One-line docstring description should be one line and end with a period.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Newline before this line
Link on a single line, otherwise it won't work (we don't enforce line length)
Blank line required before the next section
Blank line required before the next section
Theano -> Theano/TensorFlow
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
cropping, not padding
Same: don't mention specific axes
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
This should be max.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Actually, maybe it would be higher performance to have a switch: `if eta > 3600` / `if eta > 60` So that we only compute what we need.
Please add `s` for seconds.
Don't format a string two lines, do it in one pass. Also, there is seemingly no need for the `% 7`...
While print the batch index with so many leading zeros? Just use `%d`
You can use parentheses to structure code into several lines.
Invalid Python 3 syntax.
`try` with an `assert` is not the way to test inequality between two integers...
@hermansje it may need to be that in `fit` methods `on_batch_{begin|end}` is only called during the training loop and not the validation loops, otherwise yes I think user Callbacks would be broken and some of the built-in Callbacks would need refactoring as well Edit: actually that would be difficult since the `test_loop` methods are shared b/t val and eval. If we switch all built-in Callbacks to `on_train_batch_{begin | end}` they should be ok, but user Callbacks may still be broken. I think we might want to go with `on_batch_{begin | end}` being aliases for `on_batch_train_{begin | end}`, I'll check back with Francois
@hermansje Let's have `on_batch_{ begin | end }` be aliases for `on_train_batch_{begin | end}` like in your original code
With the addition of `on_fit_batch_begin`, it might seem to users that `on_batch_begin` will run in all modes (fit/eval/predict). Same for `on_batch_end`. I'm not sure if there's a great way around that since we want to maintain backwards compatibility. Maybe we can just have `on_batch_begin` / `on_validation_batch_begin` (same for `end`)? Do we have use cases where users would want Callbacks in the public `evaluate` and `predict` methods? I'm picturing users mostly using the extra hooks for their validation data (especially with the TensorBoard callback)
Reduce indent (should be 4 spaces)
Right, better to use `then_expression` etc.
Wrap `then` and `else` with ` to make the sentence easier to parse.
Line too long
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
Line too long
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
I find this difficult to understand and rather special-case. Couldn't we do without adding this to the backend? Also if you don't have the same function for Theano, then it doesn't belong in the backend. You could put it in the `rnn` scope, or get rid of it altogether.
Style nitpick: the lines below should be indented at the level of the parens (same with the modifications above).
Introduce an `if` block to avoid a very long line.
please shorten the line by using temporary variables, it will be easier to read.
please shorten the line by using temporary variables, it will be easier to read. ```python indices = tf.to_int64(indices) ... ```
Use `train_dataset` and `val_dataset` as the names
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Sure, but for the sake of semantics and possible future extensibility, please use `-1` to refer to the last axis.
If feel like this should be handled more elegantly in the above loop. This line is not very readable.
Also I think the line does too much, breaking it into several lines would be preferable.
You don't need a lambda here. Also, don't break lines with `\`.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
What is your TF version? Here you are taking a slice, which as far as I can tell breaks shape inference and causes the following code to fail. A workaround is to manually set the shape of the slice. This may not be the case with the latest TF version. Unclear
Clarify the error message; a "Keras tensor" is the output of a Keras layer
All of this should be delegated to the parent's `__call__`.
In line with naming conventions in this API, this should be `_num_constants`.
Unnecessary blank line
and -> or
There is no longer any check that the initial states are Keras tensors, which will cause the model construction to fail when using non-Keras tensors.
We're not making an exception, RNN layers will behave like every other layer. We're just building an API. The API is that `RNN(inputs, initial_state=x)` should work as a way to set initial state tensors, independently of the value of `x` (Keras tensor or not). It's actually very simple to set up, via a switch between inputs and layer keyword arguments.
Break up long line
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
Prefer importing `layers` then using e.g. `layers.Conv2D`
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
You don't need BN for such a shallow network, `Conv2DTranspose` with relu activation and strides should suffice
You don't need this, `Conv2DTranspose` with strides should work better
Previous version was more readable imo.
`# Returns `
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
You don't need to specify this field if there is no return output
For an unimplemented method to be useful, it should have a docstring describing its specs.
Two line breaks after the first sentence.
Actually it can. The first two are positional (input_dim, output_dim).
`args` is the list of positional arguments passed by the user. It could have any length.
This layer is commonly used with a positional argument, e.g. `PReLU(0.4)`. This should still work.
Sorry, I was confusing it with `LeakyReLU`. You're right.
In case `padding` is a positional argument, quote characters will be required around it here (since it's a string). E.g. don't print `MaxPooling1D(3, valid)`, instead print `MaxPooling1D(3, "valid")`.
`pool_size` would be commonly used as positional argument.
Actually, you can just use the `convert_legacy_kwargs` utility function I just added.
You're right. In that case we should make sure the user does not pass more than 1 positional argument.
Parens not necessary here
filters //= 2
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Use `'` as string delimiter for consistency
Looks good to me now.
You don't need BN for such a shallow network, `Conv2DTranspose` with relu activation and strides should suffice
Better to put the activation as the `activation` keyword of the layer below
You don't need this, `Conv2DTranspose` with strides should work better
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
The `bn%d` looks unnecessary.
I think we should make this function private, as well as `is_current_explicit_device`, and `get_available_gpus`.
Per the failing docstring test, this docstring needs a `Raises` section mentioning the ValueError: https://travis-ci.org/fchollet/keras/jobs/282558708
Please make this method private (unless there is a rationale for making it part of the public API).
Please make this method private.
In that case shouldn't it be `if x.ndim == 4`? Also this line is becoming too long, I'd suggest creating a `use_cudnn` intermediate variable.
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
@Dref360 I can throw a specific exception for the case a data element should be just skipped.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
Please add a docstring.
Any way to completely abstract this away in the Theano backend? We should not adjust the backend-agnostic part of the codebase to adjust for Theano-specific issues.
`try` with an `assert` is not the way to test inequality between two integers...
While print the batch index with so many leading zeros? Just use `%d`
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
Insert a line break after the docstring
The class docstring should explain the meaning of the arguments.
"eror" -> "error"
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
I really don't see how incrementing `self.wait` at the end of each epoch is the correct behavior. You have access to the epoch counter `epoch`, if you just want to skip the first epoch you can? E.g. if it's the first epoch, then set the best score / weights and continue.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
`nb_val_worker` should be described in the docstring.
`maxproc` should be `nb_worker`, for consistency.
Please add this to the docstring, with mention that it only applies to the validation data.
Add a `# Arguments` section to the docstring.
this is discussed in https://github.com/fchollet/keras/pull/7113
If providing code examples in a docstring, it should use the MarkDown syntax for code snippets (as used elsewhere in docstring code snippets in the codebase) and the code should follow PEP8 syntax. Alternatively, you could simply remove the code example, remove the mention of "lazy evaluated arrays", and simply state that the data should be picklable.
Add a `# Arguments` section to the docstring.
Don't use this pattern. No try/except block here.
Add a `# Arguments` section to the docstring.
Use `'` everywhere for consistency. Do not break lines with `\`
Should this be part of the public API? It sounds like it should be an internal method.
This should be a `ValueError`.
This is too broad an exception, it should be `ImportError` (otherwise something inside the module could fail and you wouldn't know why).
There are added empty lines. Please remove them.
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
You don't need to specify this field if there is no return output
`# Returns `
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
Better to put the activation as the `activation` keyword of the layer below
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
Typo: output. It should be clarified that it needs to be a valid Theano expression.
Same remark as before regarding `output_shape`.
cropping, not padding
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
The indices of the axes depend on the dim ordering. Just say "width and height"
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
cropping, not padding
Same: don't mention specific axes
Line too long, and not PEP8 compliant. Break it down into a few lines.
This statement should come afterwards
The ValueError should be reported in the docstring
Please break up this line into several
Bit of redundancy: this sets `input` twice (here and in the next few lines).
Just checking for `Wrapper` will not work in the general case. The only `Wrapper` that could work with an `Embedding` currently is `TimeDistributed` (but even that sounds overly niche). Please remove this statement
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
it's less pythonic but more in line with the style of how things are computed at some other places in the code base.
`if n.__class__.__name__ == ...`
Should be `inputs` and `mask`.
Please remove these changes so that this callback has the same behavior as the other callbacks. It could be discussed in another issue/PR.
Break up long line
You can use `K.is_keras_tensor`
Use bullet points
I believe you don't need this method, the inherited one should work fine.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Shapes mentioned in the docstring are generally 2D; should be 3D
Need to fill in this section
Blank line required before the next section
Please introduce line breaks in the docstring to avoid very long lines.
`mathews_correlation` or `matthews_correlation_coefficient`
The targets / predictions are assumed to be in the [0, 1] interval but that is not enforced. It should be.
Capital variable names is not appropriate for scalar variables
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
`+ K.epsilon()` in the denominator.
It's a hack, but changing to something like ``` return K.mean(y_pred, axis=-1) + (0 * y_true) ``` may suppress the Theano warning that you're currently throwing. (NB: Not sure the dimensions here are correct in all situations, but something along these lines would work.)
Since you are taking a global mean instead of the mean on the last axis, this will fail for loss weighting.
Please rename `sparse_top_k_categorical_accuracy` for consistency with other metrics names
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Respect PEP8 conventions.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
We generally call it "KTF"
This would benefit from a bit more explanation on how to use TensorBoard, at least a link to https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
should be self.forward.
The entries in `config` should match the arguments in `__init__`.
The paragraph above can be replaced with `layer.weights`, which is always implemented.
If some weights are incorrectly named, we better fix it at the level where the weights are created.
Not convinced. Names should already be sensible by construction. What about just `weight.name`.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Please remove these changes so that this callback has the same behavior as the other callbacks. It could be discussed in another issue/PR.
`if self.depth_multiplier != 1` Additionally: please put this exception in the Theano function, in the backend, since it is Theano-specific.
Whatever the backend uses internally, the kernel shape is standardized to `self.kernel_size + (input_dim, self.filters)`, to allow portability across models. Revert this change. Note: we used to have 2 different possible shapes for kernels, in Keras 1.0. It was a nightmare. That's why it is now standardized.
The same concern exists for Theano with `data_format='channels_first'`. I do not know the extent of the performance hit. My guess is that it is small. I note that [native TF ops](https://www.tensorflow.org/api_docs/python/tf/nn/conv2d) use the same kernel shape for both data formats, which indicates that performance optimization can probably be handled at the backend level.
Processing of `np_kernel` should be removed from this function
Line too long, and not PEP8 compliant. Break it down into a few lines.
I will note in passing that doing one conv per channel is not an efficient way to implement depthwise conv (too much overhead). Preferable to do a single conv with a diagonal kernel.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
cropping, not padding
Same: don't mention specific axes
Please include a non abbreviated explanation of what erf is.
Add a docstring.
Code delimiters ` would be more appropriate than string quotes here, for `x` and `increment`.
I think we should not expect only a list, but also allow for tuples. In which case this comparison won't work; better to compare each member: `zoom_range[0] == 1 and zoom_range[1] == 1` . Also, since we make the assumption that `zoom_range` is going to be a 2-element list/tuple, better check first and raise a helpful error message if it's not the case.
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
For example, given 20% intensity shift, an image with pixel value [50, 100] will have larger shift than an image with pixel value in [70, 80].
That is not 100% guarantee and it will result in different intensity for different image.
Spaces around `/`
array_to_img need argument scale to decide if it is needed to scale to uint8. And the previous code assume X is always within 0 and 1. We may need to fix it.
Got it! Let me check if other codes make such guarantee.
You can define the set on the same line, to avoid a named variable
Bit of redundancy: this sets `input` twice (here and in the next few lines).
Personnaly, I would use Theano flags :) I don't know if it should be added directly in Theano. Do tensorflow support this? If it is added in keras, I would do: ``` mode = None if _DEBUG_MODE == 'detect_nan': mode = 'NanGuardMode' ``` Can you open an issue on Theano, Using the Theano flag should not enable the GPU. I don't have this behavior on the lstm example.
We have a "NanGuardMode" (you can just use that string) that is done for this: http://deeplearning.net/software/theano/tutorial/nan_tutorial.html http://deeplearning.net/software/theano/library/compile/nanguardmode.html I think it would be better to use that then what you propose. We are making it skip some False positive error from time to time: https://github.com/Theano/Theano/pull/3768
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
should be self.forward.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
`if n.__class__.__name__ == ...`
We generally call it "KTF"
Not sure this is the behavior we actually want. Seems like a lot of hard-coded assumptions.
What case does this cover? Also, here we have twice an unchecked assumptions that we are dealing with a list; all we know is that it isn't a float. Not all non-floats are lists.
You don't have to return from the function. If the current epoch was best and `restore_best_weights= True` then the weights wont ever be restored which is done in the code following this line.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
Please print a message for this action (like we do in `on_train_end`): "Restoring model to its state at the end of the best epoch."
No warning should occur with default settings. It is safe to remove this.
I really don't see how incrementing `self.wait` at the end of each epoch is the correct behavior. You have access to the epoch counter `epoch`, if you just want to skip the first epoch you can? E.g. if it's the first epoch, then set the best score / weights and continue.
"eror" -> "error"
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
It seems like the `weights` argument for `preprocess_weights_for_loading` is not really a list of numpy arrays. It's a list of `HDF5 dataset`. When I call `print(weights)` on my machine, I saw something like: ``` [<HDF5 dataset "kernel:0": shape (100, 96), type "<f4">, <HDF5 dataset "recurrent_kernel:0": shape (32, 96), type "<f4">, <HDF5 dataset "bias:0": shape (192,), type "<f4">] ``` Hence there would be some metadata attached to the weights. Specifically, with `print([x.name for x in weights])`, the output is: ``` ['/model_weights/cu_dnngru_1/cu_dnngru_1/kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/recurrent_kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/bias:0'] ``` However, I'm really not sure if this is a behavior that we could rely on (i.e., is it a consistent behavior for different versions of h5py, different versions of Keras, python, OS, ...). Also, it might not pass some existing tests since the tests are written under the assumption that the input is a list of arrays.
What if we're loading a `GRU` layer with `reset_after=True`? It will have 6 biases also. I think we shouldn't transpose the kernels in this case.
You're right. Never mind then.
Start the keyword arguments on the next line, indented with 4 spaces, to avoid overly long lines
This is a bug, please remove
However in some cases there will be no weights. This assert is a bug...
Please format the docstring like the others, with an `# Arguments` and `# Returns` section
Likewise, please format docstring
The CNTK errors on Travis CI seem to come from this line. `self.bias[0]` results in a `(1, 3 * self.units)` 2-D tensor in CNTK.
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
I see, it's to be able to compare it with the other backends with `==` later on. Nevermind.
"not currently supported with CNTK".
I don't quite understand this message. Do we expect users to be familiar with the concept of "dynamic axis" here? Doesn't seem standard
No need for final space
Need spaces at the end of every line in this message (this is also true of a few other messages)
There are added empty lines. Please remove them.
No need for final space
Past few lines too long
Line too long
Still relevant? If so, explain the diff
This is a significant regression which breaks a lot of my code too.
I feel like it would actually be clearer and more economical to separate the two cases entirely: one input vs. multiple inputs.
I fear this is a brittle mechanism. It will work in simple cases but will fail in advanced cases.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
Please introduce line breaks in the docstring to avoid very long lines.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
Prefer more explicit variable names.
This is a significant regression which breaks a lot of my code too.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
This should be a `ValueError` (never raise `Exception`).
Should be `inputs` and `mask`.
I vote for option number two. That seems the most consistent with other parts of the Keras API.
No reference to `_keras_shape`, that's an implementation detail. Call it "static shape"
I fear this is a brittle mechanism. It will work in simple cases but will fail in advanced cases.
Should probably be int in both case. We don't want separate cases to handle.
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
Missing a space between "argument" and "has". Also tell users to use the `unit_forget_bias` argument instead.
You can make this a dict instead of a list of tuples, that would be more natural. In this case, the order of the values does no matter.
This ignores additional keyword arguments possibly passed by the user.
'p' is already removed when, kwargs.pop('p')
You're right. In that case we should make sure the user does not pass more than 1 positional argument.
`pool_size` would be commonly used as positional argument.
Actually, you can just use the `convert_legacy_kwargs` utility function I just added.
In case `padding` is a positional argument, quote characters will be required around it here (since it's a string). E.g. don't print `MaxPooling1D(3, valid)`, instead print `MaxPooling1D(3, "valid")`.
This should be literally what the function call should look like. So the user can just copy and paste it.
This is not the same argument. The proper behavior here would be: - if `forget_bias_init` is set to `"one"`, set `unit_forget_bias` to True - else ignore the argument, and in this case, raise a warning specifying the argument was ignored. You will need custom code to do this.
It makes it much easier to keep track of parts of the code that are backend-specific.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
Singe the names are expected to match across models, "in the current model" does not make sense here.
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
This is a bit confusing. Maybe simpler: ``` if skip_mismatch: if K.int_shape(symbolic_weights[i]) != weight_values[i].shape: warnings.warn(...) continue weight_value_tuples.append(...)
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
It is be preferable to confine changes to this loop instead of introducing a new layer method. Here, we just need a loop that builds the `weight_values` list and flips convolution kernels if `layer` is an instance of a convolution layer.
add space after `(w[1])`
Use `'` everywhere for consistency. Do not break lines with `\`
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
"Number of epochs to wait for before..."
Please update the docstrings as well.
We generally call it "KTF"
"This allows for"
Don't use needed abbreviations that make code harder to read in order so save 4 characters.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Insert link to callbacks page
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
If the default is 0.5, then I would suggest to put `def __init__(self, threshold=0.5):`
Prefer using `if isinstance(...):` / etc: it makes lines shorter and more readable, and it will be extensible to more types in the future.
This probably won't help with your actual problem, but the following PR was very helpful when I needed to fix feed dict issues: https://github.com/fchollet/keras/pull/7064
Please remove these changes so that this callback has the same behavior as the other callbacks. It could be discussed in another issue/PR.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
If write batch performance is false self.seen should probably be equal to the epoch so the current behavior remains unchanged.
PEP8 issues (space around operators)
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
The class docstring should explain the meaning of the arguments.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Please use instead `K.epsilon()`, so that the user can globally set all fuzz factors throughout the codebase.
An Example section would be welcome here.
Please log the `axes` argument in the error message. It should be clear to the user upon reading the message what happened and why it happened (likewise for other backends).
Please add a docstring detailing the meaning of each argument. It is non-obvious.
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
`if n.__class__.__name__ == ...`
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
Forgot a space ```suggestion ' If your inputs are not batched,' ```
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
PEP8: space after comma
Yes, all private methods in the Keras codebase use a single leading underscore. Thanks!
This should be a private method, I believe
Sounds good. I'll put something together in the weekend and I'll tag you to get your feedback.
In the future, I'll just remove this use case. I suspect having `workers > 1 and use_multiprocessing == False` doesn't gives any real speedup. I'll do some profiling and post my findings here. Also, we should try to mimic the Ordered Enqueuer so this class will get heavily refactored anytime soon anyway. (By the end of August)
Quick test with heavy I/O ``` from keras.utils import GeneratorEnqueuer import numpy as np import cv2 from itertools import cycle import time # Create fake datas for i in range(10): cv2.imwrite('/tmp/{}.png'.format(i), np.zeros([1024, 1024, 3], np.uint8)) def gen(): for i in cycle(range(10)): yield cv2.resize(cv2.imread('/tmp/{}.png'.format(i)), (600, 600)) enq = GeneratorEnqueuer(gen(), use_multiprocessing=False) enq.start(3,10) g = enq.get() s = time.time() for _ in range(1000): next(g) end = time.time() print("Took :", end - s) ``` Both `workers = 1` and `workers = 3` take 28 seconds to do 1000 iterations. I propose that we just remove all of this and force workers to be 1 when using multithreading. The GIL removes all improvments anyway. @fchollet I would like your input on that.
Sleeping with a lock held seems bad. Shouldn't it be sufficient to guard this line with the lock: ``` generator_output = next(self._generator) ```
Please draft a PR. I think we should keep a UX-friendly way of handling python generators. (ie. a good clear message stating that they should set workers=1)
Indeed, or you can just increment the input seed for each new process.
In that case the first seed can be used to generate separate seeds for each sub process before the fork
remove unused keyword `args`
In general we can use the default implementation if `axis == 1 or axis == x.ndim - 1`
Flaky test is fixed just so you know.
I think `if self.dropout > 0 or self.recurrent_dropout > 0` is more clear.
`try / except` is not the proper thing to do here. You could do a type check instead.
No need for final space
The class docstring should explain the meaning of the arguments.
Good catch! yeah there should be a warning.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Nit: please shorten lines (here and above).
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Looks like you got it, I just wanted to make sure this PR wasn't going to get stuck for another couple of releases.
Using code markers around code keywords (.e.g `_predict_loop`).
Docstring should have a `Returns` section and a `Raises` section.
`data_utils` is no longer meant as a public namespace, use `utils`
Break down the message into two lines (line too long)
Is there a way to eliminate the underlying cause of this warning & the other similar ones without requiring the user to inherit from Dataset? I've only used pickling once or twice so I'll defer to others on all such code.
What about failure cases? Example: #6928 it is possible only x, only y, neither x nor y, or a tuple of some other unexpected size gets returned. At a minimum, check the tuple size and throw an exception if it doesn't match expectations. There are probably other cases like this in this pull request, it might be worth double checking.
You don't need a lambda here. Also, don't break lines with `\`.
Add a `# Arguments` section to the docstring.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
In which case this wouldn't be necessary anymore.
Please add this to the docstring, with mention that it only applies to the validation data.
Good catch! yeah there should be a warning.
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
Also, you don't actually need these error messages after `assert` since this is a unit test
Use `'` as the quote character for consistency with the rest of the file
Add a `# Arguments` section to the docstring.
No need for this line
Is this try/except necessary? It's a test
PEP8: spaces around operators
The entries in `config` should match the arguments in `__init__`.
Use a variable with a complete name, not `l`.
If all you do with `ReverseGradient` is call it, why should it be a class? Everything in the backend is a function.
The indices of the axes depend on the dim ordering. Just say "width and height"
cropping, not padding
We could add a backend method to do it, with custom implementations in each backend...
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
cropping, not padding
Same: don't mention specific axes
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
"not currently supported with CNTK".
You are setting this to True but don't seem to be using the learning phase in the code.
In line with naming conventions in this API, this should be `_num_constants`.
Please put the new parameters on a new line
`if n.__class__.__name__ == ...`
and -> or
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Break up long line
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
No point in calling super here
This should be `activations.get(activation)` where `activations` is `from keras import activations`
Format your docstrings like other docstrings in the codebase
`cnn` sounds like a model instance, but it's a tensor. Call it `x`
That's something we should fix in the Keras backend.
@ns3284 Squash function has to be applied according to paper.
Clarify or remove.
It is a good idea to implement your loss outside of compile so that your code is readable.
Typo: perfermace -> performance
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
Use `'` for strings for consistency with the rest of the file.
Nitpick, but the line would be more readable if `padding` was a list instead of a tuple (many parens here).
The indices of the axes depend on the dim ordering. Just say "width and height"
cropping, not padding
cropping, not padding
Same: don't mention specific axes
Line too long, and not PEP8 compliant. Break it down into a few lines.
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Prefer more explicit variable names.
Good catch! yeah there should be a warning.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
Use `train_dataset` and `val_dataset` as the names
Use `'` everywhere for consistency. Do not break lines with `\`
It should be clarified in the docstring what "compilation" entails.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
We generally call it "KTF"
This would benefit from a bit more explanation on how to use TensorBoard, at least a link to https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
should be self.forward.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
If some weights are incorrectly named, we better fix it at the level where the weights are created.
Not convinced. Names should already be sensible by construction. What about just `weight.name`.
@ns3284 Squash function has to be applied according to paper.
The paragraph above can be replaced with `layer.weights`, which is always implemented.
Looks good to me now.
Also style: use `target_height` / `target_width`, no point in removing two characters.
Use `'` as quote char for consistency
@briannemsick Sorry, I wasn't clear about my main point! 1. The tqdm API UX is worth considering for inspiration when designing stateful metrics, which must be updated at every batch and displayed to the user. 2. I'm suggesting stateful metrics should be a callback call and not a special init variable that gets passed around to every class in keras. Rather than actually including tqdm (which is just a convenient option), the point is the excellent API UX style of tqdm for the stateful task of iterating through batches and counting them.
> The current progbar is fine. We're not changing the existing API, we just extend it in a really simple way to support a new use case. Fair enough, but rather than a different progbar please allow me to suggest a **different, composable stateful metric design**, unrelated to progbars, which uses the tqdm API for inspiration. In other words, consider a stateful metric which is a decorated iterator implementing `next()`, `def __iter__(self):`, `update()`, `clear()`, ` def __len__(self):`, etc.
I think this is out of scope, the goal of the PR is to support stateful metrics. A complete rewrite of progbar (if that's the route taken) should be a follow on PR.
The ValueError should be listed in the docstring. The error message should specify what was passed, and the list of values expected instead.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
Spaces around operators
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
It's a hack, but changing to something like ``` return K.mean(y_pred, axis=-1) + (0 * y_true) ``` may suppress the Theano warning that you're currently throwing. (NB: Not sure the dimensions here are correct in all situations, but something along these lines would work.)
Since you are taking a global mean instead of the mean on the last axis, this will fail for loss weighting.
You can replace the next lines with `return - dice_coef_loss(y_true, y_pred)`
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
Respect PEP8 conventions.
Please rename `sparse_top_k_categorical_accuracy` for consistency with other metrics names
What you call `one_hot` is referred to as `categorical` everywhere else in the codebase (e.g. categorical_crossentropy, cateorical_accuracy, to_categorical). But think we don't need this argument, when it comes to single-label classification, because you can automatically infer it from the shape of the predictions (if the last axis is size 1, it's binary, else categorical).
But we would need this argument in case we want to support *multi-label* binary classification, where you have multiple dimensions on the last axis, and each one of them encodes a binary class prediction. So I think we should have the argument. And we should add support for: - multi-class, single-label categorical classification - multi-class, multi-label binary classification
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
As a user, what can I do, knowing that I can now feed a Layer to the `metrics` arguments? Can I feed any Layer? (No, but some will try)
There is a problem here. `_feed_input_names` is the list of model *inputs*, but `ins` refers to list of the Keras function input placeholders. Typically, ins = model_inputs + model_outputs + sample_weights. Your setup will still work, but the conversion doesn't get applied to targets.
How is there any difference between this and `on_epoch_end`? In practice, both are called in succession, with nothing in between.
You can remove this part. If training from symbolic tensors, there is no need to convert input arrays because there are no input arrays (and `indices_for_conversion_to_dense` will always be empty).
In which cases would this be needed? It may be better to defined a proper private function than a very long named lambda. e.g. ``` python def _expand_if_needed(input, mask): ... ```
No, do not do this
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
I vote for option number two. That seems the most consistent with other parts of the Keras API.
Just `# Arguments` to be consistent
If the default is 0.5, then I would suggest to put `def __init__(self, threshold=0.5):`
It doesn't really make sense to me, because random transformations are important to have at test time as well (because they modify the statistics of the data). Best evals are from multiple random transforms, with results merged via power averaging.
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
This should be tensor3 instead of matrix.
Functions names should be defined in snake case.
oops yeah I can't read apparently. Disregard!
There's no reason for these three branches to be inside the `else` of line 773, rather that else should be removed should all be `elif`s up one layer, i.e. ``` if self.consume_less == 'gpu': ... elif self.consume_less == 'cpu': ... elif self.consume_less == 'mem': ... else: raise Exception('Unknown `consume_less` mode.') ```
This is Theano syntax and breaks with TF. Use `K` instead.
With not mask, how do you handle a batch with different sequence lengths? Said a batch of 2, with first input have lenght 2 and the 2nd has a lenght 4. Then you would do a right padding on the 1st sequence to make it have length 4. In you implementation without mask, for the 1st input, the **true** energy should be `b_start + x1' y1 + x2' y2 + y1' U y2 + b_end` but in your implementation, there isn't a `b_end`, but with an additional `x3' y3' + x4' y4 + y2' U y3 + y3' U y4`, where `y3 = y4 = 0`. The consequence is, the above two formulations are not equivalent, at least when you take derivative with respect to `U_00` (top-left element in matrix `U`), the derivative isn't the same. Right? (also, `U_00` and `U_11` are not `exchangable`, but why we treat label 0 and label 1 differently?) Also when you compute the normalization constance (free energy in your code), you have to integrate over `y3, y4` (which are paddings). I guess that's what you mean by "padding elements act as a virtual end label". However, if when you think about taking derivative with respect to `U` or `b_end`, your approach is not equivalent to a real CRF. One very obvious observation is, `y3, y4`, the padding, affects the derivative with respect to `U`, and therefore, the paddings plays a role on the final outcome. The more paddings you have, the more impact the paddings affects the outcome. This is unexpected from my point of view. Lastly, another simple observation, a model with and without the end energy (`b_end`), the numbers of trainable parameters are not the same. So the two models are not the same.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
`cnn` sounds like a model instance, but it's a tensor. Call it `x`
Bit of redundancy: this sets `input` twice (here and in the next few lines).
This should be tensor3 instead of matrix.
`input_spec` contains constraints that future inputs should respect. This statement would set the length of the first input as a length constraint, but unless the network is unrolled there should be no constraint on length. This is in part what the previous TODO was referring to.
The CNTK errors on Travis CI seem to come from this line. `self.bias[0]` results in a `(1, 3 * self.units)` 2-D tensor in CNTK.
cropping, not padding
We could add a backend method to do it, with custom implementations in each backend...
Same: don't mention specific axes
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Line too long, and not PEP8 compliant. Break it down into a few lines.
This is Theano syntax and breaks with TF. Use `K` instead.
Let's add a TODO for this one
Let's add a TODO for this one
Let's add a TODO for this one
Right. My mistake.
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Use code markers around `put()`
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Remove leading space
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
The ValueError should be reported in the docstring
Please break up this line into several
Bit of redundancy: this sets `input` twice (here and in the next few lines).
Just checking for `Wrapper` will not work in the general case. The only `Wrapper` that could work with an `Embedding` currently is `TimeDistributed` (but even that sounds overly niche). Please remove this statement
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
it's less pythonic but more in line with the style of how things are computed at some other places in the code base.
`if n.__class__.__name__ == ...`
Should be `inputs` and `mask`.
Still relevant? If so, explain the diff
PEP8: space after comma
"When using `steps_per_epoch`, ..."
Insert link to callbacks page
Prefer `if steps_per_epoch is not None`
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
Set default `batch_size` to None, like in `fit`.
Use `'` everywhere for consistency. Do not break lines with `\`
+1. Use case would be validating on more data than fits in GPU memory. So the generator has to return small-ish minibatches, but I want to validate on more than one minibatch.
Code markers around `validation_split`
Code markers around tuple
this is discussed in https://github.com/fchollet/keras/pull/7113
Looks good to me now.
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Fix indent. Use `pylint` as linter.
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
I mean `RuntimeError`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
The `bn%d` looks unnecessary.
@ns3284 Squash function has to be applied according to paper.
Default axis to -1
I think we should rename this to `batch_normalization` in order to follow the TF API. API consistency matters, and Keras is aligning on TF rather than Theano.
Default axis to -1
NCHW should be supported on GPU since it offers better performance. For conv ops we have a test checking whether we run on GPU or not, check it out
If beta/gamma are None, we should create `ones` vectors for them so we can use fused ops anyway.
This is incorrect. What data format to use depends on what `axis` argument was passed to the BN layer.
Parens are unnecessary: `if tf_data_format == 'NHWC' or tf_data_format == 'NCHW' and _has_nchw_support():`
In that case shouldn't it be `if x.ndim == 4`? Also this line is becoming too long, I'd suggest creating a `use_cudnn` intermediate variable.
Only call `squeeze` if `mean` / `var` have more than 1 axes.
Just 4 spaces for indent
No need for final space
No need for final space
`new_shape_temp` will be deleted automatically after the return statement. There is no need to delete it explicitly.
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
No need for such abbreviations, they just make code harder to read.
The formula is wrong because `np.prod(self.output_shape[1:-1])` is not the number of positions where the kernel is applied, it is the maximum number of positions.
This formula is wrong for most convolution layer configs because it doesn't take into account padding and strides
@fchollet Does the output shape include padding? That may be the problem you're referring to. I tried to think of any other way the output shape would not be equal to the number of positions the kernel is applied, but as far as I can tell input stride and input padding are already taken into account by this. A specific counter example would be greatly appreciated.
Additionally this will give the wrong number for RNN layers
This seems strangely ad-hoc
Space (" ") instead of period(" ")
Past few lines too long
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
Line too long
```suggestion if k == KC: ```
Still relevant? If so, explain the diff
But we would need this argument in case we want to support *multi-label* binary classification, where you have multiple dimensions on the last axis, and each one of them encodes a binary class prediction. So I think we should have the argument. And we should add support for: - multi-class, single-label categorical classification - multi-class, multi-label binary classification
Code delimiters ` would be more appropriate than string quotes here, for `x`.
Code delimiters ` would be more appropriate than string quotes here, for `x` and `increment`.
Code delimiters ` would be more appropriate than string quotes here, for `x`.
Code delimiters ` would be more appropriate than string quotes here, for `x`.
Code delimiters ` would be more appropriate than string quotes here, for `x` and `new_x`.
No need for `+` at the end. But needs a space after `.`.
No need for blank line
"of a symbolic tensor" (it doesn't have to be a keras one)
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
In which cases would this be needed? It may be better to defined a proper private function than a very long named lambda. e.g. ``` python def _expand_if_needed(input, mask): ... ```
This should be decorated with `@keras_test`
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
This is already validated in the constructor, no need.
Please use `np.ceil` instead
This should be `activations.get(activation)` where `activations` is `from keras import activations`
Use `train_dataset` and `val_dataset` as the names
No point in calling super here
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
`cnn` sounds like a model instance, but it's a tensor. Call it `x`
List or tuple. Iterables implement `__iter__()` and thus may not necessarily be indexable (requires `__getitem__()`).
It is not clear from the name "first_or_list" what the function does. A list or set with a single element is a singleton. Maybe a better name would be `unpack_singleton`.
Shapes mentioned in the docstring are generally 2D; should be 3D
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
It's all very confusing, and `Convolution2D` wasn't doing great on that front either. Here I think we should refer to the kernel dimensions as `kernel_dim*` and to the target tensor dimensions as `conv_dim*`.
Thinking about it, I think `conv_dim*` like in the code would be the clearest here. Otherwise we should explicitly mention that these are the dimensions the convolution will operate on.
Sections in docstring should be separated with a line break. I don't think the `len_` prefix everywhere is necessary, just `input_dim*` seems clear enough.
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Parens not necessary here
I don't understand why; `tf.nn.separable_conv2d` does support strides.
At this point it would be fine to do the dimshuffle without the call the `_postprocess_conv2d_output`
It seems that all pep8 tests failures are ignored by travis. I'll make a PR to fix it.
Please introduce line breaks in the docstring to avoid very long lines.
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
in the tests k.backend() == `cntk` might want to lower case here
maybe tell the user the valid data_formats
This one is fine too
The class docstring should explain the meaning of the arguments.
If write batch performance is false self.seen should probably be equal to the epoch so the current behavior remains unchanged.
This would benefit from a bit more explanation on how to use TensorBoard, at least a link to https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Don't use needed abbreviations that make code harder to read in order so save 4 characters.
In that case, I think this error and the corresponding test should be kept.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
`try` with an `assert` is not the way to test inequality between two integers...
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
`for/else` is not idiomatic Python. Please don't use this pattern.
apologies if I gave a poor suggestion...
If some weights are incorrectly named, we better fix it at the level where the weights are created.
Not convinced. Names should already be sensible by construction. What about just `weight.name`.
Bit of redundancy: this sets `input` twice (here and in the next few lines).
The paragraph above can be replaced with `layer.weights`, which is always implemented.
`if n.__class__.__name__ == ...`
Style nit: avoid strange line breaking ```python node_key = self._node_key(layer, original_node_index) if node_key in self.container_nodes: ``` Also applicable in several other places in this PR. Please fix.
Don't use `\` for breaking lines, prefer using parentheses
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
Please use more informative descriptions, not just types
Wrap `then` and `else` with ` to make the sentence easier to parse.
Right, better to use `then_expression` etc.
Style nitpick: the lines below should be indented at the level of the parens (same with the modifications above).
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
Make the cast conditional on `condition` being the wrong dtype
I find this difficult to understand and rather special-case. Couldn't we do without adding this to the backend? Also if you don't have the same function for Theano, then it doesn't belong in the backend. You could put it in the `rnn` scope, or get rid of it altogether.
Reduce indent (should be 4 spaces)
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
This should be max.
I don't understand why; `tf.nn.separable_conv2d` does support strides.
These should be `ValueError`
This one is fine too
Please introduce line breaks in the docstring to avoid very long lines.
Shapes mentioned in the docstring are generally 2D; should be 3D
This is the TF backend, so don't rely on `_keras_shape`, instead use `tuple(kernel.get_shape().as_list())` (always available).
Use list markers
Need to fill in this section
This is a new layer so no API conversion decorator is necessary.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
The class docstring should explain the meaning of the arguments.
Good catch! yeah there should be a warning.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
No warning should occur with default settings. It is safe to remove this.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Better to use keyword arguments (same below). API change looks ok to me.
That's a good point, since we didn't require it be named `epoch` before, we should probably make the first argument positional and only make the second (new one) a keyword arg.
Please raise a `NotIplementedError` when the use case is not supported yet.
"eror" -> "error"
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Same remark as before regarding `output_shape`.
Typo: output. It should be clarified that it needs to be a valid Theano expression.
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Same: don't mention specific axes
cropping, not padding
cropping, not padding
The indices of the axes depend on the dim ordering. Just say "width and height"
No `+` needed for string concatenation at the end
`try / except` is not the proper thing to do here. You could do a type check instead.
This one is fine too
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Good catch! yeah there should be a warning.
Also rewrite this description assuming an integer axis.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
I don't think the line needs to be broken.
In validation or test, there is no concept of epoch, so that seems OK to me.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
@Dref360 I can throw a specific exception for the case a data element should be just skipped.
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Use code markers around `put()`
Remove leading space
What about failure cases? Example: #6928 it is possible only x, only y, neither x nor y, or a tuple of some other unexpected size gets returned. At a minimum, check the tuple size and throw an exception if it doesn't match expectations. There are probably other cases like this in this pull request, it might be worth double checking.
Add a `# Arguments` section to the docstring.
In the future, I'll just remove this use case. I suspect having `workers > 1 and use_multiprocessing == False` doesn't gives any real speedup. I'll do some profiling and post my findings here. Also, we should try to mimic the Ordered Enqueuer so this class will get heavily refactored anytime soon anyway. (By the end of August)
Sounds good. I'll put something together in the weekend and I'll tag you to get your feedback.
Please draft a PR. I think we should keep a UX-friendly way of handling python generators. (ie. a good clear message stating that they should set workers=1)
Quick test with heavy I/O ``` from keras.utils import GeneratorEnqueuer import numpy as np import cv2 from itertools import cycle import time # Create fake datas for i in range(10): cv2.imwrite('/tmp/{}.png'.format(i), np.zeros([1024, 1024, 3], np.uint8)) def gen(): for i in cycle(range(10)): yield cv2.resize(cv2.imread('/tmp/{}.png'.format(i)), (600, 600)) enq = GeneratorEnqueuer(gen(), use_multiprocessing=False) enq.start(3,10) g = enq.get() s = time.time() for _ in range(1000): next(g) end = time.time() print("Took :", end - s) ``` Both `workers = 1` and `workers = 3` take 28 seconds to do 1000 iterations. I propose that we just remove all of this and force workers to be 1 when using multithreading. The GIL removes all improvments anyway. @fchollet I would like your input on that.
Indeed, or you can just increment the input seed for each new process.
add param to provide a seed at init time
In that case the first seed can be used to generate separate seeds for each sub process before the fork
Add a `# Arguments` section to the docstring.
We could add a backend method to do it, with custom implementations in each backend...
The entries in `config` should match the arguments in `__init__`.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
This is only relevant for Theano and should not be in the public API. The conditional `if K.backend() == 'theano':` is acceptable in this case.
The `bn%d` looks unnecessary.
cropping, not padding
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Space after #
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Use code markers around `put()`
Remove leading space
To be clear, the idea (to my understanding) is that `OrderedEnqueuer` will be the class that knows about `batch_size`. The generator that `fit_generator` receives is constructed in `DatasetEnqueuer.get()`. This generator pops `batch_size` items from the queue and then calls `self.dataset.create_batch(lst_items)` to obtain the actual batch.
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
I just realized that I missed something important. These `indexes` are not the indexes of individual samples. These are indexes of batches. It means that forever you will have the same samples in the same batch, even if you shuffle the indexes. It takes the edge out of some important operations (i.e. batch-normalization). I find this a bit confusing. What I would expect is that the Dataset will store samples, not batches, and that `getitem` would return a single sample. I don't think that a Dataset should know about the `batch_size`. It makes more sense to me that the packaging of the samples into batches would happen on the fly, in the `DatasetEnqueuer.get()` method. If the `batch_size` is 32, then Enqueuer should pop out 32 elements from the queue (or less if there is a StopIteration), and call a `batcher` function (perhaps it can be provided by `Dataset`) that turns a list of samples into a batch.
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
I like this!
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
These should be `ValueError`
If using a tuple as the `kernel_size` argument, better to use a tuple for `strides` as well, for consistency.
Spaces around operators
filters //= 2
I think these layers would benefit from having more transparent names.
Better to put the activation as the `activation` keyword of the layer below
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Looks good to me now.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
The `bn%d` looks unnecessary.
The ValueError should be reported in the docstring
Please break up this line into several
Bit of redundancy: this sets `input` twice (here and in the next few lines).
Just checking for `Wrapper` will not work in the general case. The only `Wrapper` that could work with an `Embedding` currently is `TimeDistributed` (but even that sounds overly niche). Please remove this statement
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
it's less pythonic but more in line with the style of how things are computed at some other places in the code base.
`if n.__class__.__name__ == ...`
Should be `inputs` and `mask`.
Still relevant? If so, explain the diff
PEP8: space after comma
No point in calling super here
This should be `activations.get(activation)` where `activations` is `from keras import activations`
`cnn` sounds like a model instance, but it's a tensor. Call it `x`
Format your docstrings like other docstrings in the codebase
That's something we should fix in the Keras backend.
Clarify or remove.
@ns3284 Squash function has to be applied according to paper.
It is a good idea to implement your loss outside of compile so that your code is readable.
Typo: perfermace -> performance
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
`)` after `]`
Please remove new line (`"""Instantiates`).
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
I mean `RuntimeError`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
The `bn%d` looks unnecessary.
You don't need to specify this field if there is no return output
Please raise a `NotIplementedError` when the use case is not supported yet.
This function does not have a properly formatted dosctring (see other dosctrings for reference)
`# Returns `
It's good to have an explicit example. Put it in an `# Example` section. I don't understand the message "It therefore has to be part of the computational graph,". Please remove, the example is self-explanatory.
No `+` needed for string concatenation at the end
Better to use `_keras_history`
No need for `+` at the end. But needs a space after `.`.
Better to use `_keras_history`
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
var is a reserved keyword, use `v` or something like that.
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
Not sure this is the behavior we actually want. Seems like a lot of hard-coded assumptions.
What case does this cover? Also, here we have twice an unchecked assumptions that we are dealing with a list; all we know is that it isn't a float. Not all non-floats are lists.
You don't have to return from the function. If the current epoch was best and `restore_best_weights= True` then the weights wont ever be restored which is done in the code following this line.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
Please print a message for this action (like we do in `on_train_end`): "Restoring model to its state at the end of the best epoch."
No warning should occur with default settings. It is safe to remove this.
I really don't see how incrementing `self.wait` at the end of each epoch is the correct behavior. You have access to the epoch counter `epoch`, if you just want to skip the first epoch you can? E.g. if it's the first epoch, then set the best score / weights and continue.
"eror" -> "error"
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
No, that's a fine style as well. Anything that's PEP8 works. And line length is not strictly enforced (prefer readability over correct line length).
For efficiency reasons I believe it is preferable to keep the default regularizers to `None`. This is also important because using `None` in the class constructor is part of the standard API and the class should be able to deal with it. This is absolutely not an issue in `get_config`: you can simply use, e.g.: ``` python "W_constraint":self.W_constraint.get_config() if self.W_constraint else None, ``` After setting `self.W_constraint` to the value given to the constructor in `__init__`.
Most of this stuff is included in the config of `super` and thus does not need to figure here.
Maybe "strides". I had been considering deprecating `subsample` in favor of `strides` in Conv2d, too.
Need to fill in this section
Use list markers
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
unused variable `input_length`
This is a new layer so no API conversion decorator is necessary.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
replace the word hack with workaround
This should be a `ValueError` (never raise `Exception`).
This mechanism will only work for a few layers, and will fail in the general case. The proper behavior when batch size matters is to slice the input mask and run slices through `self.layer.compute_mask`, then concatenate. No reshaping.
`K.int_shape(inputs)` will not always be available.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
No, this should always be entered if `input_shape[0]`.
Should be `inputs` and `mask`.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
I believe you don't need this method, the inherited one should work fine.
No reference to `_keras_shape`, that's an implementation detail. Call it "static shape"
Nit: first line of docstring (one-line summary) should fit in one line and end with a period.
Could you please split this method to a standalone utility function in `recurrent.py` (named `def _standardize_args`)? The only instance attribute it needs is `_num_constants`, which can be passed as a function argument (`num_constants`). That way we don't need to duplicate this code, you can just import it from `recurrent.py`.
You shouldn't need to pop these args here. Rather, you should remove them from kwargs before calling the layer (which is fine since they are transferred to the input list)
In line with naming conventions in this API, this should be `_num_constants`.
Clarify the error message; a "Keras tensor" is the output of a Keras layer
and -> or
Unnecessary blank line
Break up long line
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
should be self.forward.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
@farizrahman4u this is still not fixed.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Line too long, and not PEP8 compliant. Break it down into a few lines.
PEP8: space after comma
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.
Singe the names are expected to match across models, "in the current model" does not make sense here.
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
It is be preferable to confine changes to this loop instead of introducing a new layer method. Here, we just need a loop that builds the `weight_values` list and flips convolution kernels if `layer` is an instance of a convolution layer.
"The weight file you are trying to load is in a legacy format that does not support name-based weight loading".
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
It should be clarified in the docstring what "compilation" entails.
In line with naming conventions in this API, this should be `_num_constants`.
and -> or
All of this should be delegated to the parent's `__call__`.
Clarify the error message; a "Keras tensor" is the output of a Keras layer
Unnecessary blank line
There is no longer any check that the initial states are Keras tensors, which will cause the model construction to fail when using non-Keras tensors.
We're not making an exception, RNN layers will behave like every other layer. We're just building an API. The API is that `RNN(inputs, initial_state=x)` should work as a way to set initial state tensors, independently of the value of `x` (Keras tensor or not). It's actually very simple to set up, via a switch between inputs and layer keyword arguments.
Could you please split this method to a standalone utility function in `recurrent.py` (named `def _standardize_args`)? The only instance attribute it needs is `_num_constants`, which can be passed as a function argument (`num_constants`). That way we don't need to duplicate this code, you can just import it from `recurrent.py`.
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
For papers that are closer to the heart of VAEs: Might be useful to cite Kingma's [IAF paper](https://arxiv.org/abs/1606.04934) (the encoder is more complicated though) Larsen's [vae-gan paper](https://arxiv.org/abs/1512.09300) is good as well.
Are we sure about this removal of the multiplication by the original_dim? @RuiShu added this multiplication in #3220, and he had some arguments to do it. Initial implementation was without this multiplication.
I can't see the relation to Normalising Flows (IAF paper) or VAE-GANs. If you're looking for VAE papers that make use of convolutional architectures then there are dozens of papers. I'm not sure if the ref needs to be changed as the adaptation is minor (using convolutions for image data instead of inner product layers).
@RuiShu Now I see the point, thank you. And the multiplication makes sense then, cool.
I'm a bit confused here. If T is the training set, T_i is the single i-th sample (image) from the training set (with a dim of 784) and t_j is the j-th pixel then when we consider p(x_i | z_i,l) (expr. 10), do we assume that x_i is a t_j (pixel) or T_i (image)? But I could well be wrong, as I'm no expert in this field, I've started to look into VAE just recently.
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
`# Returns `
About this test: - please use the same docstring format as elsewhere in the codebase - use `'` as quote character for consistency - use lines that are <= 80 char
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
Style: no need for the space after `3,`
This is a significant regression which breaks a lot of my code too.
Style: break long lines in the test
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
Please introduce line breaks in the docstring to avoid very long lines.
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
Use `'` everywhere for consistency. Do not break lines with `\`
I'm afraid "Container" is not a term that can be readily understood by most users. Please say "list, tuple, or set"
I will note in passing that doing one conv per channel is not an efficient way to implement depthwise conv (too much overhead). Preferable to do a single conv with a diagonal kernel.
Use bullet points
Prefer `if steps_per_epoch is not None`
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Break up long line
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
To be clear, the idea (to my understanding) is that `OrderedEnqueuer` will be the class that knows about `batch_size`. The generator that `fit_generator` receives is constructed in `DatasetEnqueuer.get()`. This generator pops `batch_size` items from the queue and then calls `self.dataset.create_batch(lst_items)` to obtain the actual batch.
You can use `K.is_keras_tensor`
Looks good to me now.
These should be `ValueError`
For efficiency reasons I believe it is preferable to keep the default regularizers to `None`. This is also important because using `None` in the class constructor is part of the standard API and the class should be able to deal with it. This is absolutely not an issue in `get_config`: you can simply use, e.g.: ``` python "W_constraint":self.W_constraint.get_config() if self.W_constraint else None, ``` After setting `self.W_constraint` to the value given to the constructor in `__init__`.
Use `'` for strings for consistency with the rest of the file.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Most of this stuff is included in the config of `super` and thus does not need to figure here.
Use list markers
Maybe "strides". I had been considering deprecating `subsample` in favor of `strides` in Conv2d, too.
Need to fill in this section
unused variable `input_length`
This is a new layer so no API conversion decorator is necessary.
This function does not have a properly formatted dosctring (see other dosctrings for reference)
I think we should not expect only a list, but also allow for tuples. In which case this comparison won't work; better to compare each member: `zoom_range[0] == 1 and zoom_range[1] == 1` . Also, since we make the assumption that `zoom_range` is going to be a 2-element list/tuple, better check first and raise a helpful error message if it's not the case.
Better to put the activation as the `activation` keyword of the layer below
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
filters //= 2
Better to put the activation as the `activation` keyword of the layer below
Spaces around `/`
Got it! Let me check if other codes make such guarantee.
array_to_img need argument scale to decide if it is needed to scale to uint8. And the previous code assume X is always within 0 and 1. We may need to fix it.
For example, given 20% intensity shift, an image with pixel value [50, 100] will have larger shift than an image with pixel value in [70, 80].
No need for final space
No need for final space
`new_shape_temp` will be deleted automatically after the return statement. There is no need to delete it explicitly.
@fchollet Does the output shape include padding? That may be the problem you're referring to. I tried to think of any other way the output shape would not be equal to the number of positions the kernel is applied, but as far as I can tell input stride and input padding are already taken into account by this. A specific counter example would be greatly appreciated.
The formula is wrong because `np.prod(self.output_shape[1:-1])` is not the number of positions where the kernel is applied, it is the maximum number of positions.
This formula is wrong for most convolution layer configs because it doesn't take into account padding and strides
You are later multiplying with a float. This has no effect on the output
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
This seems strangely ad-hoc
Additionally this will give the wrong number for RNN layers
Use a variable with a complete name, not `l`.
Is there a reason why there is not a `SpatialAlphaDropout` like there is a `SpatialDropout`? In the paper they are not explicitly doing it, but they do have an argument `noise_shape` on their Github. When they release the code for more advanced datasets, we'll know for sure I guess.
pg 6 of the [paper](https://arxiv.org/pdf/1706.02515.pdf) says: > Therefore, we propose âalpha dropoutâ, that randomly sets inputs to Î±
If all you do with `ReverseGradient` is call it, why should it be a class? Everything in the backend is a function.
Use ` around code keywords everywhere in docstrings..
The entries in `config` should match the arguments in `__init__`.
Better mention that the cropping happens along the time dimension here (axis 1)
cropping, not padding
cropping, not padding
The indices of the axes depend on the dim ordering. Just say "width and height"
Fix link (should be explicit link)
This is a private method, for safety, better not pass a default value for `include_optimizer`. Users shouldn't be using it, and when working on Keras itself it is easy to forget to pass it.
Code markers around `validation_split`
Code markers around tuple
This will be more readable with code markers around `epochs`.
Insert link to callbacks page
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
I mean `RuntimeError`.
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
This and everything that uses it is too tf specific for this file. See how I handled these same issues in #6928
You can just append: ``` To install TensorFlow: `pip3 install tensorflow` ``` to the previous message.
Excessive line breaks. The lines 202-213 do not exceed a length 85.
It's also inconsistent with line 593
There are added empty lines. Please remove them.
If beta/gamma are None, we should create `ones` vectors for them so we can use fused ops anyway.
Typo: two spaces after NOT
You can remove `activation` and `return_sequences` since they take the default values.
Please use lowercase variable names.
Put the imports at the top of the file.
Use `'` as quote char for consistency
Explicitly mention that this is 'channels_first'/'channels_last' (since it may be confusing vs. image file format).
As I said, using img_to_array would be nicer. The API of `save_img` should reflect the one of img_to_array
The ValueError should be listed in the docstring. The error message should specify what was passed, and the list of values expected instead.
This line needs to be placed before the assertions. If an assertion fails in `clean_run`, the image data format will not be reset back to 'channel_last', and all following tests will also fail (because shapes like `(None, None, None, dim)` assumes 'channel_last' format).
Also style: use `target_height` / `target_width`, no point in removing two characters.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Looks good to me now.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
The `bn%d` looks unnecessary.
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
While print the batch index with so many leading zeros? Just use `%d`
I don't think the grammar is right as-is with "next". Alternate: "make value available to each of the following callbacks"
Callbacks are processed sequentially, future is more vague than next IMO.
Use `'` as quote character for intra-file consistency
```suggestion if k == KC: ```
`try` with an `assert` is not the way to test inequality between two integers...
```python if isinstance(v, np.ndarray): send[k] = v.item() else: send[k] = v ````
What case does this cover? Also, here we have twice an unchecked assumptions that we are dealing with a list; all we know is that it isn't a float. Not all non-floats are lists.
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
We could add a backend method to do it, with custom implementations in each backend...
cropping, not padding
The indices of the axes depend on the dim ordering. Just say "width and height"
cropping, not padding
Same: don't mention specific axes
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Line too long, and not PEP8 compliant. Break it down into a few lines.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
The number of batches in the Sequence
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
Space after #
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
I like this!
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
In any case, this PR is a great addition for Keras, thank you!
To be clear, the idea (to my understanding) is that `OrderedEnqueuer` will be the class that knows about `batch_size`. The generator that `fit_generator` receives is constructed in `DatasetEnqueuer.get()`. This generator pops `batch_size` items from the queue and then calls `self.dataset.create_batch(lst_items)` to obtain the actual batch.
I just realized that I missed something important. These `indexes` are not the indexes of individual samples. These are indexes of batches. It means that forever you will have the same samples in the same batch, even if you shuffle the indexes. It takes the edge out of some important operations (i.e. batch-normalization). I find this a bit confusing. What I would expect is that the Dataset will store samples, not batches, and that `getitem` would return a single sample. I don't think that a Dataset should know about the `batch_size`. It makes more sense to me that the packaging of the samples into batches would happen on the fly, in the `DatasetEnqueuer.get()` method. If the `batch_size` is 32, then Enqueuer should pop out 32 elements from the queue (or less if there is a StopIteration), and call a `batcher` function (perhaps it can be provided by `Dataset`) that turns a list of samples into a batch.
Use the same docstring as the TF version.
Does this create a copy of the tensor? I suspect it does. We need to just copy the pointer without touching the data in memory.
If I remember correctly, we use `to_categorical` for this one. Since the imports are not added in the docs, users will wonder what `to_categorical` is. Let's remove {{np_implementation}} it until we find another way to display it nicely.
No need for `+` at the end. But needs a space after `.`.
No `+` needed for string concatenation at the end
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
"samples drawn from"
I think these layers would benefit from having more transparent names.
Spaces around operators
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
I'm a bit confused here. If T is the training set, T_i is the single i-th sample (image) from the training set (with a dim of 784) and t_j is the j-th pixel then when we consider p(x_i | z_i,l) (expr. 10), do we assume that x_i is a t_j (pixel) or T_i (image)? But I could well be wrong, as I'm no expert in this field, I've started to look into VAE just recently.
@RuiShu Now I see the point, thank you. And the multiplication makes sense then, cool.
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
You don't need to specify this field if there is no return output
If using a tuple as the `kernel_size` argument, better to use a tuple for `strides` as well, for consistency.
Use `'` as string delimiter for consistency
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
No `+` needed for string concatenation at the end
No need for blank line
"of a symbolic tensor" (it doesn't have to be a keras one)
Better to use `_keras_history`
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
"samples drawn from"
The indices of the axes depend on the dim ordering. Just say "width and height"
cropping, not padding
cropping, not padding
Same: don't mention specific axes
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Better to add `rank` here
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
may be use a local variable here and in the cases below to avoid code duplication? ``` ndim = len(self.output_shape[i]) if ... else ... weight = ... ```
You can change line 263-269 like this: ``` ndim = len(self.output_shape[i]) if ... else ... weight = ... ``` and you can do the same in other such places.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Using if/else here definitely improves readability. In the previous discussion I had request to de-dup the code for creating placeholder which you have done already.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Avoid avoid many logical statements on a single line, which harms readability. Instead, use a if/else block.
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
Use `'` everywhere for consistency. Do not break lines with `\`
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
Looks good to me now.
Fix indent. Use `pylint` as linter.
Just import `utils`
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
I mean `RuntimeError`.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
The `bn%d` looks unnecessary.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Use `train_dataset` and `val_dataset` as the names
In any case, this PR is a great addition for Keras, thank you!
I like this!
@Dref360 yes I think it is best to keep the same behavior as before.
No need for this line
Is this try/except necessary? It's a test
PEP8: spaces around operators
Also, you don't actually need these error messages after `assert` since this is a unit test
Use `'` as the quote character for consistency with the rest of the file
> The current progbar is fine. We're not changing the existing API, we just extend it in a really simple way to support a new use case. Fair enough, but rather than a different progbar please allow me to suggest a **different, composable stateful metric design**, unrelated to progbars, which uses the tqdm API for inspiration. In other words, consider a stateful metric which is a decorated iterator implementing `next()`, `def __iter__(self):`, `update()`, `clear()`, ` def __len__(self):`, etc.
I think this is out of scope, the goal of the PR is to support stateful metrics. A complete rewrite of progbar (if that's the route taken) should be a follow on PR.
@briannemsick Sorry, I wasn't clear about my main point! 1. The tqdm API UX is worth considering for inspiration when designing stateful metrics, which must be updated at every batch and displayed to the user. 2. I'm suggesting stateful metrics should be a callback call and not a special init variable that gets passed around to every class in keras. Rather than actually including tqdm (which is just a convenient option), the point is the excellent API UX style of tqdm for the stateful task of iterating through batches and counting them.
You can use parentheses to structure code into several lines.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
0.05 is a better interval. 50ms is definitely perceptible.
No warning should occur with default settings. It is safe to remove this.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Invalid Python 3 syntax.
Line too long (and several other lines in this file as well)
Still relevant? If so, explain the diff
Line too long
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
Past few lines too long
Suggest to make `data_format` as argument of `_helper_bilinear`. Then parameterize `test_resize_images_bilinear` with `data_format`. Otherwise, you may not be able to test both `data_format` with `pytest.raises`.
I wonder if this whole loop could be simplified somehow? It has a clear recursive structure. The same code should be generalizable to 1D/2D/3D/etc without having to manually unroll the loop.
This is the failing line, failing with `"ValueError: Error when checking model target: expected no data, but got: [array, array]"`. The model has been compiled with 2 target tensors, hence it should not expect any feed data. It seems you are proposing a scheme where one could pass placeholders as target tensors, then have them replace the placeholders created by `compile`, thus expecting feed data. That's a different API from what I had in mind; not sure what the use case would be? The point of the current API is to be able to use data tensors.
Ok, that makes sense. I added support for custom placeholders. Unfortunately, in the case of Theano and CNTK, there is no easy way to check whether something is a placeholder. This leads to a loss of generality, but that's not important since Theano and CNTK are secondary to this feature.
Use `'` everywhere for consistency. Do not break lines with `\`
Please use readable variable names such as `array`
Should be named `apply_brightness_shift`
You'd save quite a bit of code by simply not passing the `axis` argument, which is equivalent to what you are doing (normalize each sample globally). The change you are proposing matches with the docstring description, but it may not necessarily be the most useful thing to. We could also normalize per channel (`axis=(row_axis, col_axis)`). In any case the current code does not look good to me, so we should fix it indeed.
Please use `np.ceil` instead
I think we should not expect only a list, but also allow for tuples. In which case this comparison won't work; better to compare each member: `zoom_range[0] == 1 and zoom_range[1] == 1` . Also, since we make the assumption that `zoom_range` is going to be a 2-element list/tuple, better check first and raise a helpful error message if it's not the case.
For example, given 20% intensity shift, an image with pixel value [50, 100] will have larger shift than an image with pixel value in [70, 80].
That is not 100% guarantee and it will result in different intensity for different image.
Got it! Let me check if other codes make such guarantee.
array_to_img need argument scale to decide if it is needed to scale to uint8. And the previous code assume X is always within 0 and 1. We may need to fix it.
Spaces around `/`
I see you are a Theano user. This wouldn't work with TF.
How about: epsilon = K.random_normal(shape=K.shape(z_mean), mean=0., this works on Tensorflow CPU.
This might work in both tf and th, please help to check ```python epsilon = K.random_normal(shape=(K.int_shape(z_mean)[0], K.int_shape(z_mean)[1]), mean=0., ```
@RuiShu Now I see the point, thank you. And the multiplication makes sense then, cool.
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
Previous version was more readable imo.
You don't need to specify this field if there is no return output
`# Returns `
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
This would be very inefficient and would cause EOM errors even for smallish datasets. Please use instead the approach of `predict()` (preallocating entire arrays as soon as their shape is known, then assigning values inside the preallocated arrays). This is doable because the number of samples that are expected is known (`val_samples`).
`all_outs` is meant to be a list of arrays (potentially with 1 element), not a Numpy array, because we need to support multi-output models (the present code wouldn't). Same for `outs`. So I would recommend following the pattern from `evaluate_generator`: converting the output of `self.predict_on_batch` to a list if necessary, etc.
In that case the first seed can be used to generate separate seeds for each sub process before the fork
Code markers around tuple
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
this is discussed in https://github.com/fchollet/keras/pull/7113
Code markers around `validation_split`
Insert link to callbacks page
Use `'` everywhere for consistency. Do not break lines with `\`
If providing code examples in a docstring, it should use the MarkDown syntax for code snippets (as used elsewhere in docstring code snippets in the codebase) and the code should follow PEP8 syntax. Alternatively, you could simply remove the code example, remove the mention of "lazy evaluated arrays", and simply state that the data should be picklable.
Please use standard formatting for the docstrings, e.g. ``` # Arguments ```
I don't see how it makes the behavior any different. You are still feeding the *_generator functions with a generator that creates batches. The decomposition of the batch preparation process to (1) items drawn from a sequence and (2) a batch creation from a list of items, is a stronger abstraction, because: (a) It allows the user to do stronger shuffling (instead of using fixed batches throughout the training), also making layers like BatchNormalization more effective. (b) It allows the user to handle dataset elements that are not suitable for training by simply skipping over them. (c) It completely contains the current approach (of having the Dataset items be fixed batches), since in that case just set the `create_batch` function be the identity function.
To be clear, the idea (to my understanding) is that `OrderedEnqueuer` will be the class that knows about `batch_size`. The generator that `fit_generator` receives is constructed in `DatasetEnqueuer.get()`. This generator pops `batch_size` items from the queue and then calls `self.dataset.create_batch(lst_items)` to obtain the actual batch.
In any case, this PR is a great addition for Keras, thank you!
Items should be extracted by batch, removing them individually will have poor performance. I wouldn't be surprised if it turned out to empirically be a factor of 100 slower. fit_generator already generates batches now and it works, plus batch_size is not a parameter so I advise sticking to that. As for `Dataset`, that should be reserved for a class that manages Datasets properly, so `DataSequence` would be a more appropriate name. However, with what I mentioned above Dataset should still be removed.
I just realized that I missed something important. These `indexes` are not the indexes of individual samples. These are indexes of batches. It means that forever you will have the same samples in the same batch, even if you shuffle the indexes. It takes the edge out of some important operations (i.e. batch-normalization). I find this a bit confusing. What I would expect is that the Dataset will store samples, not batches, and that `getitem` would return a single sample. I don't think that a Dataset should know about the `batch_size`. It makes more sense to me that the packaging of the samples into batches would happen on the fly, in the `DatasetEnqueuer.get()` method. If the `batch_size` is 32, then Enqueuer should pop out 32 elements from the queue (or less if there is a StopIteration), and call a `batcher` function (perhaps it can be provided by `Dataset`) that turns a list of samples into a batch.
@Dref360 yes I think it is best to keep the same behavior as before.
First of all, to be honest I'm not sure I've understood each point of view correctly. However, from what I've read, I'm also in favor of having the Dataset (or whatever it ends up being called) be as transparent as possible and build everything from the point of view of each sample. The separation of the "batcher" from the actual sample generation is important for the reasons @jonilaserson mentioned and also combining the samples into a batch is pretty much straightforward enough to only be implemented once (with the added option to be overriden as a method if need be). Are there any cases which might be complicated by this separation? If so, we should discuss it a little bit more, otherwise I really think it's best to keep each building block as simple as possible and not mix together what are essentially two different operations, effectively crippling the API.
Use bullet points
Break up long line
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
Better to put the activation as the `activation` keyword of the layer below
Better to put the activation as the `activation` keyword of the layer below
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
filters //= 2
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
You don't need BN for such a shallow network, `Conv2DTranspose` with relu activation and strides should suffice
You don't need this, `Conv2DTranspose` with strides should work better
`# Returns `
You don't need to specify this field if there is no return output
No `+` needed for string concatenation at the end
`try / except` is not the proper thing to do here. You could do a type check instead.
This one is fine too
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Good catch! yeah there should be a warning.
Also rewrite this description assuming an integer axis.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
One import per line. Also import `models` so as to avoid `tf.keras` calls in the code. This *is* the Keras codebase! It should import internal modules, not `tf.keras`.
Just import `utils`
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
Fix indent. Use `pylint` as linter.
`# Returns `
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
You don't need to specify this field if there is no return output
For now, after adding `axis` in the crossentropy losses, you will have to use a different loss function when doing pixelwise classification (image segmentation) in NCHW: ```python if K.data_format() == 'channels_first': loss = lambda y_true, y_pred: K.sparse_categorical_crossentropy(y_true, y_pred, axis=1) else: loss = K.sparse_categorical_crossentropy model.compile(optimizer=optimizer, loss=loss) ```
@tiferet the API change in `sparse_categorical_crossentropy` is not something we can merge, sorry. Such an argument should be called `axis` and should default to `-1` (`K.image_data_format()` is a layer-level configuration argument and should not affect the default behavior of backend methods).
I don't understand why; `tf.nn.separable_conv2d` does support strides.
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
For theano, `ratio` needs to be `integer`. ```python ratio = height_factor // width_factor ```
in the tests k.backend() == `cntk` might want to lower case here
`T.nnet.softmax` creates less ops and will be more efficient (also simpler).
Please introduce line breaks in the docstring to avoid very long lines.
This is correct.
Then you wouldn't be able to easily serialize it.
add space after `(w[1])`
No point in calling super here
This should be `activations.get(activation)` where `activations` is `from keras import activations`
If you remove this, `get_config` defaults to method of the parent class, which is incorrect in this case.
`# Returns `
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
No warning should occur with default settings. It is safe to remove this.
What case does this cover? Also, here we have twice an unchecked assumptions that we are dealing with a list; all we know is that it isn't a float. Not all non-floats are lists.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
In that case, I think this error and the corresponding test should be kept.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
`batch_size` parameter needs to be deprecated too.
Not sure this is the behavior we actually want. Seems like a lot of hard-coded assumptions.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
Nit: use backquotes around code keywords
Nit: use `'` as the quote character, for consistency
Spaces around `=` please.
Replace with ``` if len(mask.get_shape()) > ndim: raise ValueError(...) ```
In which cases would this be needed? It may be better to defined a proper private function than a very long named lambda. e.g. ``` python def _expand_if_needed(input, mask): ... ```
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
That crazy process was used for compatibility with TensorFlow. With Theano you could simply call `tensor.shape`, which is itself a symbolic tensor.
I vote for option number two. That seems the most consistent with other parts of the Keras API.
Should probably be int in both case. We don't want separate cases to handle.
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
I think this is out of scope, the goal of the PR is to support stateful metrics. A complete rewrite of progbar (if that's the route taken) should be a follow on PR.
@briannemsick Sorry, I wasn't clear about my main point! 1. The tqdm API UX is worth considering for inspiration when designing stateful metrics, which must be updated at every batch and displayed to the user. 2. I'm suggesting stateful metrics should be a callback call and not a special init variable that gets passed around to every class in keras. Rather than actually including tqdm (which is just a convenient option), the point is the excellent API UX style of tqdm for the stateful task of iterating through batches and counting them.
> The current progbar is fine. We're not changing the existing API, we just extend it in a really simple way to support a new use case. Fair enough, but rather than a different progbar please allow me to suggest a **different, composable stateful metric design**, unrelated to progbars, which uses the tqdm API for inspiration. In other words, consider a stateful metric which is a decorated iterator implementing `next()`, `def __iter__(self):`, `update()`, `clear()`, ` def __len__(self):`, etc.
As a user, what can I do, knowing that I can now feed a Layer to the `metrics` arguments? Can I feed any Layer? (No, but some will try)
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
Callbacks are processed sequentially, future is more vague than next IMO.
I don't think the grammar is right as-is with "next". Alternate: "make value available to each of the following callbacks"
You should batch these calls (see what we do for weight loading, for instance)
Prefer more explicit variable names.
Update this docstring.
It looks like you undid my work in a merge conflict here.
I meant "if someone de decides to catch the exception you don't want the trackback printed at all" . I should 't do this from my phone apparantly...
remove unused keyword `args`
Yes, all private methods in the Keras codebase use a single leading underscore. Thanks!
This should be a private method, I believe
Sounds good. I'll put something together in the weekend and I'll tag you to get your feedback.
You can remove `activation` and `return_sequences` since they take the default values.
Put the imports at the top of the file.
Please use lowercase variable names.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Line too long
Line too long
Line too long
Line too long
Line too long
I don't understand why; `tf.nn.separable_conv2d` does support strides.
Please introduce line breaks in the docstring to avoid very long lines.
Need to fill in this section
in the tests k.backend() == `cntk` might want to lower case here
Introduce an `if` block to avoid a very long line.
The `merge_mode` argument is never validated. Additionally, we should consider a `None` mode that just makes the layer return `(forward, backward)`
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
should be self.forward.
The output below still seems wrong to me, because you also have to shift the output to make the alignment right. Yes, that is why I said bidirectional is really ugly with padding in the first place. [[[ 0. 6.] [ 1. 5.] [ 3. 3.] [ 6. 0.]] [[ 0. 3.] [ 0. 2.] [ 1. 0.] [ 3. 0.]]]
@farizrahman4u this is still not fixed.
When weights=None, you cannot pass a list weights[:nw/2], should be just None.
But it cannot be a list of None, should be just None. weights [:nw/2]=None, because you use : , the result is a list.
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
For the record, you cannot set this as a `property` because `core.Layer` will attempt to set it as a class attribute.
PEP8: space after comma
Line too long
Still relevant? If so, explain the diff
Past few lines too long
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
Style: if you're going to break a signature or a call like this, prefer stacking the arguments for better readability, like ```python def assert_list_pairwise(z_list, shape=True, allclose=True): ``` This is applicable in several places in this PR
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
Line too long (and several other lines in this file as well)
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
```suggestion if k == KC: ```
It seems there is four spaces missing (unrelated to your changes).
Move to the line below in order to keep each line under 80 char.
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
Link on a single line, otherwise it won't work (we don't enforce line length)
Use bullet points
Use `train_dataset` and `val_dataset` as the names
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
Looks good to me now.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
Break up long line
Should we rely have to rely on `np.dot`? Besides the fact that it's expensive, it's also a black box. The logic should be inferable from reading the code.
var is a reserved keyword, use `v` or something like that.
This is correct.
Sure this should take a single tensor as input for API consistency. Using `[K.to_dense(x) for x in tensors]` is also not a big overhead for the batch version.
var is a reserved keyword, use `v` or something like that.
Space (" ") instead of period(" ")
Better to use `_keras_history`
Better to use `_keras_history`
No `+` needed for string concatenation at the end
No need for `+` at the end. But needs a space after `.`.
`self.dtype = dtype or K.floatx()` is equivalent and simpler.
I mean `RuntimeError`.
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
unused variable `input_length`
You should fetch the mask in the `sparse_loss` function as well, the same way you do in `loss` function. Also, all the loss should be the mean loss per batch, right now you are simply doing the sum of the losses. This makes the losses for different batch sizes to be of different scales.
For enabling on Theano, please modify `epsilon=1.01e-5` (simple trick).
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Looks good to me now.
Nit: please shorten lines (here and above).
No need for the extra space at the end of the lines.
Nit: please shorten lines here to 80 char or less (also in `initializers.py`)
I see you are a Theano user. This wouldn't work with TF.
I'm a bit confused here. If T is the training set, T_i is the single i-th sample (image) from the training set (with a dim of 784) and t_j is the j-th pixel then when we consider p(x_i | z_i,l) (expr. 10), do we assume that x_i is a t_j (pixel) or T_i (image)? But I could well be wrong, as I'm no expert in this field, I've started to look into VAE just recently.
You don't need to specify this field if there is no return output
Previous version was more readable imo.
`# Returns `
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
No warning should occur with default settings. It is safe to remove this.
Please print a message for this action (like we do in `on_train_end`): "Restoring model to its state at the end of the best epoch."
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
I really don't see how incrementing `self.wait` at the end of each epoch is the correct behavior. You have access to the epoch counter `epoch`, if you just want to skip the first epoch you can? E.g. if it's the first epoch, then set the best score / weights and continue.
nit, you can use formatted string like: print(f'Restoring model weights from the end of the best epoch: {self.best_epoch + 1}')
What case does this cover? Also, here we have twice an unchecked assumptions that we are dealing with a list; all we know is that it isn't a float. Not all non-floats are lists.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
"eror" -> "error"
Not sure this is the behavior we actually want. Seems like a lot of hard-coded assumptions.
Prefer making multiple statements, it will be easier to read than breaking the statements into multiple lines. Breaking lines should only be done if necessary. ```python slices = [] for i in range(x.ndim): .... ```
enumerate is not needed here. i is not used
@farizrahman4u Isn't `ndim` always going to be 1 for `n`, I think you meant the equivalent of `len(n)`
@farizrahman4u Undefined variable `K`
Also I think the line does too much, breaking it into several lines would be preferable.
I fear this is a brittle mechanism. It will work in simple cases but will fail in advanced cases.
I don't think that `0` is a valid shape dimension.
This one is fine too
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
PEP8: spaces around operators
Simply `batch_size` would suffice.
Can we change this parameter to be `write_step` with the options `'epoch'` and `'batch'`, and improve the description? I think `write_step` might be more clear, and doesn't break the true/false setting in the future if there is another setting worth adding.
Please use a smaller batch size in order to fully test the iteration code (here is only a single batch).
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
It's better use a flag to control write epoch-level summary or batch-level summary. The batch-level summary will be overwrite in your implementation.
We generally call it "KTF"
Use ` around code keywords
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
Format your docstrings like other docstrings in the codebase
`if n.__class__.__name__ == ...`
What you call `one_hot` is referred to as `categorical` everywhere else in the codebase (e.g. categorical_crossentropy, cateorical_accuracy, to_categorical). But think we don't need this argument, when it comes to single-label classification, because you can automatically infer it from the shape of the predictions (if the last axis is size 1, it's binary, else categorical).
But we would need this argument in case we want to support *multi-label* binary classification, where you have multiple dimensions on the last axis, and each one of them encodes a binary class prediction. So I think we should have the argument. And we should add support for: - multi-class, single-label categorical classification - multi-class, multi-label binary classification
Update this docstring.
Prefer more explicit variable names.
You should batch these calls (see what we do for weight loading, for instance)
Just `# Arguments` to be consistent
If the default is 0.5, then I would suggest to put `def __init__(self, threshold=0.5):`
`cnn` sounds like a model instance, but it's a tensor. Call it `x`
This is too broad an exception, it should be `ImportError` (otherwise something inside the module could fail and you wouldn't know why).
This should be a `ValueError`.
Since this is about dealing with a Theano-specific behavior, the syntax should be: if Theano: else:
It is be preferable to confine changes to this loop instead of introducing a new layer method. Here, we just need a loop that builds the `weight_values` list and flips convolution kernels if `layer` is an instance of a convolution layer.
There are added empty lines. Please remove them.
We generally call it "KTF"
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
`# Returns `
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
Should this be part of the public API? It sounds like it should be an internal method.
I think we should either not mention the details of choosing the reduction methods, or explain why it's chosen this way (for which, I'm afraid there's not an easy way to describe in docs as it really depends on tf.distribute strategies' implementation). So, I would probably just say the library would choose the best reduction method based on the training environment, for 2).
"first", "concat", or "sum".
Suggest: all cases to be replaced by "general use cases"
suggestion: "This is used" to be replaced by "This may be used"
Set the default axis to be 0, for explicitness (same with the other one).
> tf.ragged.constant does not accept tf.Tensor inputs gracefully It's really strange that it works with numpy arrays but not tf.Tensors. That's an inconsistency in the ragged API that we should address...
Add a `# Arguments` section to the docstring.
`_set_keras_shape_for_reduction` would arguably be a better name. This can be reused for any reduction op (sum, etc).
Add a `# Arguments` section to the docstring.
It looks to me that we don't have specific implementation for "In case of a `tf.distribute.MirroredStrategy` it boils down to `"sum"` to account for the case of custom training loops.", so I would omit this to avoid confusions. Otherwise looks good. Thank you!
I think we should make this function private, as well as `is_current_explicit_device`, and `get_available_gpus`.
Per the failing docstring test, this docstring needs a `Raises` section mentioning the ValueError: https://travis-ci.org/fchollet/keras/jobs/282558708
Please make this method private (unless there is a rationale for making it part of the public API).
Please make this method private.
Please add a docstring.
Remove leading space
Should there be a timeout option? It might be wise to also have `proportion_full_before_start` parameter so the queue isn't kept empty. This can help improve throughput.
Then people's results won't be valid and they won't have a way to know! Imagine if you're trying to train on very small datasets and you skip one.... I think raising an Exception is the correct behavior.
@Dref360 I can throw a specific exception for the case a data element should be just skipped.
Sometimes you'll have entries in your Dataset that you won't want to process in your model (a class that you can't handle, an image that is too big etc.) and in some other cases your pre-processor might simply fail (bad communication, missing file, invalid labels, etc.). The user can handle those cases by having `Dataset.__getitem__` return an exception, and when that happens simply don't add the index into the queue. Otherwise the user has to pre-preemptively remove from the Dataset every object that might "break". This is not always possible to know in advance.
This would benefit from a bit more explanation on how to use TensorBoard, at least a link to https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
That's a good point, since we didn't require it be named `epoch` before, we should probably make the first argument positional and only make the second (new one) a keyword arg.
Better to use keyword arguments (same below). API change looks ok to me.
Don't use needed abbreviations that make code harder to read in order so save 4 characters.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Good catch! yeah there should be a warning.
We generally call it "KTF"
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
The class docstring should explain the meaning of the arguments.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Please rename to `preprocessing_function`. Please improve the docstring by specifying: "The function should take one argument: a batch of images (Numpy tensor with rank 4), and should output a Numpy tensor with the same shape."
It doesn't really make sense to me, because random transformations are important to have at test time as well (because they modify the statistics of the data). Best evals are from multiple random transforms, with results merged via power averaging.
This is incorrect
Set the default value to `0.0` rather than None, for consistency with `fit`
Code markers around tuple
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
This is a new layer so no API conversion decorator is necessary.
Need to fill in this section
Use list markers
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
Past few lines too long
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
What you call `one_hot` is referred to as `categorical` everywhere else in the codebase (e.g. categorical_crossentropy, cateorical_accuracy, to_categorical). But think we don't need this argument, when it comes to single-label classification, because you can automatically infer it from the shape of the predictions (if the last axis is size 1, it's binary, else categorical).
But we would need this argument in case we want to support *multi-label* binary classification, where you have multiple dimensions on the last axis, and each one of them encodes a binary class prediction. So I think we should have the argument. And we should add support for: - multi-class, single-label categorical classification - multi-class, multi-label binary classification
```suggestion if k == KC: ```
Still relevant? If so, explain the diff
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
Line too long
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
Past few lines too long
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
Still relevant? If so, explain the diff
Good catch! yeah there should be a warning.
Use `'` everywhere for consistency. Do not break lines with `\`
Not a useful example. Instead please have examples dealing with larger input shapes (e.g. 3D, 4D).
`cnn` sounds like a model instance, but it's a tensor. Call it `x`
Line too long
@ns3284 Squash function has to be applied according to paper.
One import per line. Also import `models` so as to avoid `tf.keras` calls in the code. This *is* the Keras codebase! It should import internal modules, not `tf.keras`.
Just import `utils`
Also prefer using more detailed names -- e.g. `ConvNeXtBlock`.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Fix indent. Use `pylint` as linter.
Looks good to me now.
`# Returns `
You don't need to specify this field if there is no return output
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
It looks like you undid my work in a merge conflict here.
I meant "if someone de decides to catch the exception you don't want the trackback printed at all" . I should 't do this from my phone apparantly...
remove unused keyword `args`
Yes, all private methods in the Keras codebase use a single leading underscore. Thanks!
This should be a private method, I believe
Sounds good. I'll put something together in the weekend and I'll tag you to get your feedback.
You can remove `activation` and `return_sequences` since they take the default values.
Put the imports at the top of the file.
Please use lowercase variable names.
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Also I think the line does too much, breaking it into several lines would be preferable.
Not a useful example. Instead please have examples dealing with larger input shapes (e.g. 3D, 4D).
Should be `inputs` and `mask`.
Forgot a space ```suggestion ' If your inputs are not batched,' ```
I wonder if this whole loop could be simplified somehow? It has a clear recursive structure. The same code should be generalizable to 1D/2D/3D/etc without having to manually unroll the loop.
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
This doesn't seem to take into account the case `NCH`? Only `NCHW` and `NCDHW`
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
@ns3284 Squash function has to be applied according to paper.
Still relevant? If so, explain the diff
In that case shouldn't it be `if x.ndim == 4`? Also this line is becoming too long, I'd suggest creating a `use_cudnn` intermediate variable.
Default axis to -1
this is not good I think with the new back-end. I think it should be: use_cudnn = ndim(x) < 5 and reduction_axes == [0, 2, 3] if dev.startswith('gpu') and theano.sandbox.cuda.dnn_available(): pass elsif dev.startswith('cuda') and theano.gpuarray.dnn.dnn_available(dev): pass else: use_cudnn = False This can be refactored, but I think it show more clearly the logic to use.
Default axis to -1
This is incorrect. What data format to use depends on what `axis` argument was passed to the BN layer.
Parens are unnecessary: `if tf_data_format == 'NHWC' or tf_data_format == 'NCHW' and _has_nchw_support():`
If beta/gamma are None, we should create `ones` vectors for them so we can use fused ops anyway.
Just 4 spaces for indent
Only call `squeeze` if `mean` / `var` have more than 1 axes.
With not mask, how do you handle a batch with different sequence lengths? Said a batch of 2, with first input have lenght 2 and the 2nd has a lenght 4. Then you would do a right padding on the 1st sequence to make it have length 4. In you implementation without mask, for the 1st input, the **true** energy should be `b_start + x1' y1 + x2' y2 + y1' U y2 + b_end` but in your implementation, there isn't a `b_end`, but with an additional `x3' y3' + x4' y4 + y2' U y3 + y3' U y4`, where `y3 = y4 = 0`. The consequence is, the above two formulations are not equivalent, at least when you take derivative with respect to `U_00` (top-left element in matrix `U`), the derivative isn't the same. Right? (also, `U_00` and `U_11` are not `exchangable`, but why we treat label 0 and label 1 differently?) Also when you compute the normalization constance (free energy in your code), you have to integrate over `y3, y4` (which are paddings). I guess that's what you mean by "padding elements act as a virtual end label". However, if when you think about taking derivative with respect to `U` or `b_end`, your approach is not equivalent to a real CRF. One very obvious observation is, `y3, y4`, the padding, affects the derivative with respect to `U`, and therefore, the paddings plays a role on the final outcome. The more paddings you have, the more impact the paddings affects the outcome. This is unexpected from my point of view. Lastly, another simple observation, a model with and without the end energy (`b_end`), the numbers of trainable parameters are not the same. So the two models are not the same.
Just say "either md5 or sha256".
I don't understand why we would want to deprecate md5, or have a preference for one algo or another. It's cool to support more than one hash function, but md5 works just fine for this purpose. We're just building a basic cache invalidation mechanism.
In general your docstrings have an indentation problem, the lines after the first one should be indented by 1 level (4 spaces).
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
Just for reference for newbies, in windows, the cache folder is at C:\Users\USERNAME_HERE\.keras\datasets. I usually download the files manually and place them because sometimes it does fail downloading in my computer.
This default value will not work with Windows. Use None instead, and set it in the function code.
Link on a single line, otherwise it won't work (we don't enforce line length)
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
Newline before this line
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Use `'` as string delimiter
`data_utils` is no longer meant as a public namespace, use `utils`
We have this warning in several places, please fix it everywhere
You can remove this part. If training from symbolic tensors, there is no need to convert input arrays because there are no input arrays (and `indices_for_conversion_to_dense` will always be empty).
Put `int):` on the same line for readability.
There is a problem here. `_feed_input_names` is the list of model *inputs*, but `ins` refers to list of the Keras function input placeholders. Typically, ins = model_inputs + model_outputs + sample_weights. Your setup will still work, but the conversion doesn't get applied to targets.
You could standardize the weights in `input_validation`, return a dict, then turn the dict into a list afterwards. That way you still have the dict around for `evaluate`, but weight standardization is being done in just one place.
Good catch! yeah there should be a warning.
It seems the `if shuffle` block is repeated twice, you can move it out of the conditional block
No, do not do this
In general this test is more like an integration test than a unit test. You don't need half of this stuff: - the model should be minimal (this one has a bunch of extra layers) - you don't need data with a statistical structures, `np.random` will work just fine - etc.
This test would be very expensive to run. It's an integration test, not a unit test. Please boil it down to essential components.
Also, you don't actually need these error messages after `assert` since this is a unit test
Use `'` as the quote character for consistency with the rest of the file
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
Good catch! yeah there should be a warning.
No need for this line
These quantities are not relevant here.
Is this try/except necessary? It's a test
PEP8: spaces around operators
That's a good point, since we didn't require it be named `epoch` before, we should probably make the first argument positional and only make the second (new one) a keyword arg.
Better to use keyword arguments (same below). API change looks ok to me.
Don't use needed abbreviations that make code harder to read in order so save 4 characters.
This would benefit from a bit more explanation on how to use TensorBoard, at least a link to https://www.tensorflow.org/versions/master/how_tos/summaries_and_tensorboard/index.html
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Good catch! yeah there should be a warning.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
We generally call it "KTF"
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
I don't think so, adding @KeDengMS from cntk team to confirm
You may use [element_select](https://cntk.ai/pythondocs/cntk.ops.html#cntk.ops.element_select)
Don't indent. Don't use \ (this is not code)
Please use more informative descriptions, not just types
Make the cast conditional on `condition` being the wrong dtype
Also, you don't actually need these error messages after `assert` since this is a unit test
Use `'` as the quote character for consistency with the rest of the file
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
Wrap `then` and `else` with ` to make the sentence easier to parse.
Right, better to use `then_expression` etc.
I'm glad I could help :)
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
No warning should occur with default settings. It is safe to remove this.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
In that case, I think this error and the corresponding test should be kept.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
`batch_size` parameter needs to be deprecated too.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
An optimizer instance is not serializable (it's a Python object). The previous 4 lines were serializing it. Revert this
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
This is a private method, for safety, better not pass a default value for `include_optimizer`. Users shouldn't be using it, and when working on Keras itself it is easy to forget to pass it.
I know this was in the original code, but `_make_train_function` is actually not necessary. If you are going to train further, it will be called automatically anyway. If you only need the forward pass, this step is very slow, specially with Theano. (In my local copy I have patched it out, but never got around to make a PR)
It should be clarified in the docstring what "compilation" entails.
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
Singe the names are expected to match across models, "in the current model" does not make sense here.
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
`raise NotImplementedError` may be more appropriate.
Don't use needed abbreviations that make code harder to read in order so save 4 characters.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
In that case, I think this error and the corresponding test should be kept.
`batch_size` parameter needs to be deprecated too.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
We generally call it "KTF"
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
Need to fill in this section
Use list markers
Shapes mentioned in the docstring are generally 2D; should be 3D
This is a new layer so no API conversion decorator is necessary.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Blank line required before the next section
Use bullet points
Blank line required before the next section
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
unused variable `input_length`
Not a fan of this. It is neither simple nor elegant.
Be more specific with the test name
I don't think this is required, please remove mmh3-related code.
As I said, using img_to_array would be nicer. The API of `save_img` should reflect the one of img_to_array
Since `dtype` is an argument name and not a string variable, quotes are not necessary.
Should be on the same line as the argument.
You are right. My bad. I dont think it's necessary to use an intermediate variable though: ```python if isinstance(axis, list): axis = tuple(axis) ```
Would it be possible to simplify by doing ```python if axis is not None: axis = tuple(axis) ```
Specify an epoch number
Syntax error here (`}`)
Need to fill in this section
Use list markers
Shapes mentioned in the docstring are generally 2D; should be 3D
This is a new layer so no API conversion decorator is necessary.
Depth should come before rows and cols (this might need to be fixed elsewhere as well)
Blank line required before the next section
Use bullet points
Blank line required before the next section
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
unused variable `input_length`
replace `with` with `to`
`CNTK` (to have consistent capitalization with other messages) `when constructing the trainer`
Spaces at the end of lines
Period after `inputs`
Spaces at the end of lines
No need for final space, use ` around train_function
I don't quite understand this message. Do we expect users to be familiar with the concept of "dynamic axis" here? Doesn't seem standard
No need for final space
No need for final space
Spaces at the end of lines
There are no 1D layers that use this dim ordering. I would recommend removing support for it entirely for 'th' dim ordering here (see e.g. Conv1D).
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
cropping, not padding
Same: don't mention specific axes
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Line too long, and not PEP8 compliant. Break it down into a few lines.
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
This should be max.
Blank line required before the next section
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
Use `'` as string delimiter for consistency
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
Better to put the activation as the `activation` keyword of the layer below
filters //= 2
Better to put the activation as the `activation` keyword of the layer below
You don't need this, `Conv2DTranspose` with strides should work better
You don't need BN for such a shallow network, `Conv2DTranspose` with relu activation and strides should suffice
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
The error message should mention the rank of the condition that was passed and the rank of the then/else expressions
Right, better to use `then_expression` etc.
Wrap `then` and `else` with ` to make the sentence easier to parse.
Style nitpick: the lines below should be indented at the level of the parens (same with the modifications above).
I find this difficult to understand and rather special-case. Couldn't we do without adding this to the backend? Also if you don't have the same function for Theano, then it doesn't belong in the backend. You could put it in the `rnn` scope, or get rid of it altogether.
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
This should be max.
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
Reduce indent (should be 4 spaces)
suggestion: "This is used" to be replaced by "This may be used"
PEP8: spaces around operators. We don't do strict PEP8, but such guidelines make the code more readable and should be respected.
I don't get why you are introducing this unused argument.
It appeared to do so. I altered the `append` line above to: `trained_encoders.append((ae.layers[0].encoder, ae.layers[0].encoder.get_weights()))` and this line to: ``` model.add(encoder) model.layers[-1].set_weights(weights) ``` This seems to be working pretty well.
Good catch! yeah there should be a warning.
No need for this line
Is this try/except necessary? It's a test
Use `'` as the quote character for consistency with the rest of the file
Also, you don't actually need these error messages after `assert` since this is a unit test
PEP8: spaces around operators
@farizrahman4u this is still not fixed.
Right. My mistake.
@farizrahman4u Undefined variable `K`
@farizrahman4u Isn't `ndim` always going to be 1 for `n`, I think you meant the equivalent of `len(n)`
Better to use `_keras_history`
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
"samples drawn from"
Docstring contains a few typos, please fix / rephrase
Use markdown format for links
```suggestion if k == KC: ```
Just noticed that this line doesnt test anything if backend is CNTK. So one last nit pick.. Put the backend check outside the loop so that it makes more sense: ```python def test_stack(self): tensor_list = [np.random.randn(5, 4, 6, 10) for _ in range(5)] stack_axis = 3 results = [] if K.backend() == 'cntk': check_two_tensor_operation('stack', (5, 4, 6, 10), (5, 4, 6, 10), WITH_NP, axis=stack_axis, concat_args=True) else: for k in WITH_NP: tensor_list_var = [k.variable(tensor) for tensor in tensor_list] out = k.eval(k.stack(tensor_list_var, axis=stack_axis)) results.append(out) assert_list_pairwise(results) ```
Please keep the random tests where they were. Unit tests should be small and target as few things as possible for better error reporting and debugging.
I think it's fine to test for KNP. As you said in our previous discussions, we can make certain assumptions regarding the numpy backend when the function is simple (K.expand_dims for example). In this case, I believe it is simple to check that `unroll` is not used in KNP.rnn because * `unroll` can have no meaning in the numpy implementation of RNNs. * With a decent text editor with python pluging / IDE, the variable `unroll` is marked as `unused variable` so it's fairly easy to notice an error. To be clear: * I believe that the numpy backend should get tested for complex functions * KNP.rnn should get tested for correctness * It is safe to assume that KNP.rnn doesn't use `unroll`
I thought about it last time, and I don't think we need those checks, because you already did everything needed in the numpy implementation. KNP.rnn is garanteed to give the same result for `unroll=True` and `unroll=False` because you don't use the variable `unroll` in the implementation. You already compare against KNP.rnn, so you're good to go. This should simplify this function quite a bit. Do you see what I mean? Maybe I'm not clear.
Good catch! yeah there should be a warning.
Does it really have to be this complex? This is just a unit test. why not: ```python def rnn_fn(x, h): return x, [x, K.concatenate([x, x], axis=-1)] ```
Past few lines too long
Still relevant? If so, explain the diff
Line too long
The three lines above can be removed.
Use f-strings for string formatting (or otherwise `format()`). The error message should include what the input shape was and what the output shape would have been. "check the input shape" is not actionable.
Use `'` for strings for consistency with the rest of the file.
This seems strangely ad-hoc
Additionally this will give the wrong number for RNN layers
The entries in `config` should match the arguments in `__init__`.
Please make this method private (unless there is a rationale for making it part of the public API).
Please make this method private.
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
I believe this is incorrect implementation. In the original paper `a` and `b` are defined as follows: ```tex a = (q + {\alpha'}^2 q (1 - q))^{-1/2} b = -a ((1 - q) \alpha') ``` where `q` is keep probability. But here drop probability `rate` is used instead.
Keeping `rate` does not make the expressions below more complicated; it makes them more readable: ```python a = (1 - rate) * (1 + rate * alpha_p ** 2) ** (-0.5) b = -a * (alpha_p * rate) ```
Some parentheses missed, and some aren't required. I would propose: ```python a = ((1 - rate) * (1 + rate * alpha_p ** 2)) ** -0.5 b = -a * alpha_p * rate ```
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
@ns3284 Squash function has to be applied according to paper.
It would be more in line with the keras style guide to remove these abbreviations: dw_conv_1 -> depthwise_conv_1
You don't need to specify this field if there is no return output
So, these are initialized based on imagenet: this is required for use with the pretrained weights. Is there a way we can allow users to configure this for custom datasets? @fchollet
Fix indent. Use `pylint` as linter.
Looks good to me now.
Bit of redundancy: this sets `input` twice (here and in the next few lines).
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
Callbacks are processed sequentially, future is more vague than next IMO.
I don't think the grammar is right as-is with "next". Alternate: "make value available to each of the following callbacks"
```python if isinstance(v, np.ndarray): send[k] = v.item() else: send[k] = v ````
```suggestion if k == KC: ```
Insert a line break after the docstring
While print the batch index with so many leading zeros? Just use `%d`
`try` with an `assert` is not the way to test inequality between two integers...
Invalid Python 3 syntax.
"Name-based weight loading (instead of topological weight loading)"
"The weight file you are trying to load is in a legacy format that does not support name-based weight loading".
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
Singe the names are expected to match across models, "in the current model" does not make sense here.
It is be preferable to confine changes to this loop instead of introducing a new layer method. Here, we just need a loop that builds the `weight_values` list and flips convolution kernels if `layer` is an instance of a convolution layer.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
Break up line
Not sure this is needed.
From reading this, we would use autogenerated names `param_n` all the time when using TF or Theano. That's not what we want...
This should be: ```python logs = logs or {} loss = logs.get('loss') if loss is not None: if np.isnan(loss) or np.isinf(loss): ```
While print the batch index with so many leading zeros? Just use `%d`
It's also inconsistent with line 593
Make this method private and add a docstring explaining its purpose.
We might need a more standard way to merge dictionaries (with the latter dict taking precedence). Like a `config` decorator. Or maybe that would introduce too much implicitness.
In validation or test, there is no concept of epoch, so that seems OK to me.
`pickle_safe` is generally not a good API argument, it is not very descriptive and is Python-specific (the Keras API should generally avoid being Python-specific). This is an opportunity to get rid of it. I would use `use_multiprocessing` (or `multiprocessing`, but then we have to handle to name collision with the module name) in the new code, and deprecate the `pickle_safe` argument in the generator methods at a later date.
add param to provide a seed at init time
Indeed, or you can just increment the input seed for each new process.
In that case the first seed can be used to generate separate seeds for each sub process before the fork
You're right. Never mind then.
Please format the docstring like the others, with an `# Arguments` and `# Returns` section
Likewise, please format docstring
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
Start the keyword arguments on the next line, indented with 4 spaces, to avoid overly long lines
Please add a check and raise `ValueError` if appropriate. Reshape may not be possible.
The CNTK errors on Travis CI seem to come from this line. `self.bias[0]` results in a `(1, 3 * self.units)` 2-D tensor in CNTK.
These two entries (if Bidirectional, if TimeDistributed) should be added in the big `if` switch without affecting the rest of the code. Currently we have 150 lines changed for should be a ~15 lines change...
It seems like the `weights` argument for `preprocess_weights_for_loading` is not really a list of numpy arrays. It's a list of `HDF5 dataset`. When I call `print(weights)` on my machine, I saw something like: ``` [<HDF5 dataset "kernel:0": shape (100, 96), type "<f4">, <HDF5 dataset "recurrent_kernel:0": shape (32, 96), type "<f4">, <HDF5 dataset "bias:0": shape (192,), type "<f4">] ``` Hence there would be some metadata attached to the weights. Specifically, with `print([x.name for x in weights])`, the output is: ``` ['/model_weights/cu_dnngru_1/cu_dnngru_1/kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/recurrent_kernel:0', '/model_weights/cu_dnngru_1/cu_dnngru_1/bias:0'] ``` However, I'm really not sure if this is a behavior that we could rely on (i.e., is it a consistent behavior for different versions of h5py, different versions of Keras, python, OS, ...). Also, it might not pass some existing tests since the tests are written under the assumption that the input is a list of arrays.
What if we're loading a `GRU` layer with `reset_after=True`? It will have 6 biases also. I think we shouldn't transpose the kernels in this case.
The Keras API does not require `compile` before calling `predict`, because `compile` merely configures training and is not related to inference. If MXNet requires it, that's a bug and it should be fixed.
Transposing the weights is always the right thing to do regardless of original backend.
We could add a backend method to do it, with custom implementations in each backend...
should be self.forward.
The indices of the axes depend on the dim ordering. Just say "width and height"
cropping, not padding
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
Better to add `rank` here
cropping, not padding
This overriding mechanism seems complicated. Especially since in the code you refer to the `cropping` argument in `Cropping1D` as `normalized_cropping `, although `self._normalized_cropping` returns a *different* value... Why would you need more than a single `cropping` argument? Make the base class normalize the cropping argument to be a tuple of tuples of 2 ints, of the same length as the rank.
This will be more readable with code markers around `epochs`.
"the parameter" is redundant, you can simply say `epochs`
Code markers around code keywords (`)
"output names to Numpy arrays"; "`y` can be"
There could be multiple model outputs
Code markers around `validation_split`
Same, can be a list
"`x` can be" (better be explicit)
Code markers around tuple
Insert link to callbacks page
Seems a bit specific. Since this is the last `if` clause, it would be okay to cast it to list: ``` else: key = list(key) ```
Simply as `(self.end - self.start,) + self.data.shape[1:]`
The weights should be sorted. Simply catching the exception is not the right fix...
This still seems hackey. Maybe a better or more clear solution could be something like: ``` python from keras import backend as K if K._BACKEND == 'tensorflow': logic else: other_logic ```
Since this is about dealing with a Theano-specific behavior, the syntax should be: if Theano: else:
Actually we don't; what matters is that the weights are in a deterministic order. In _what_ order they are is not very important. We could simply sort by `auto_name`.
This warning does not seem necessary
Style nit: avoid strange line breaking ```python node_key = self._node_key(layer, original_node_index) if node_key in self.container_nodes: ``` Also applicable in several other places in this PR. Please fix.
`start`/`stop` is flexible since it means `_count/list_valid_files_in_directory` will be agnostic to the validation/training story, and only needs the `split` argument. But it doesn't make a big difference.
Don't use `\` for breaking lines, prefer using parentheses
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Newline before this line
This description makes it sounds like it is required to pass a hash in order to skip download. But if not hash is passed and a local file is found, we should skip download, too. The hash is just a way to invalidate old files on people's computers after they have been updated on the Keras side.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
In general your docstrings have an indentation problem, the lines after the first one should be indented by 1 level (4 spaces).
Just say "either md5 or sha256".
I don't understand why we would want to deprecate md5, or have a preference for one algo or another. It's cool to support more than one hash function, but md5 works just fine for this purpose. We're just building a basic cache invalidation mechanism.
Just for reference for newbies, in windows, the cache folder is at C:\Users\USERNAME_HERE\.keras\datasets. I usually download the files manually and place them because sometimes it does fail downloading in my computer.
This default value will not work with Windows. Use None instead, and set it in the function code.
Link on a single line, otherwise it won't work (we don't enforce line length)
You could do that with Matplotlib, to avoid a new dependency
Same, please add more info. Maybe a concrete example would help.
Previous version was more readable imo.
`# Returns `
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
Better to put the activation as the `activation` keyword of the layer below
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
You don't need to specify this field if there is no return output
isn't is always \n anyway? POSIX uses \n as default. So we could remove the if.
This argument is only accepted in Python 3, it would not work with Python 2.
B is added in the constructor if we remove the NT check.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
In that case, I think this error and the corresponding test should be kept.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
`batch_size` parameter needs to be deprecated too.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
I think this check would be better as if inputs.shape[1] is not None and sum(self.cropping) >= inputs.shape[1]: You could still construct a tensor with size 0 and shape (None, None) that would cause this to crash.
This would read clearer with format strings, and we are trying to gravitate towards more uniform error messages in keras. f'`cropping` parameter of Cropping layer must be greater than the input shape. ' f'Recieved: inputs.shape={inputs.shape}, and cropping={self.cropping}'
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
No, this should always be entered if `input_shape[0]`.
Fix indent here and below
Use `'` for strings for consistency with the rest of the file.
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
Should be `inputs` and `mask`.
Should probably be int in both case. We don't want separate cases to handle.
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
No need for final space
No need for final space
I don't quite understand this message. Do we expect users to be familiar with the concept of "dynamic axis" here? Doesn't seem standard
I would consider using a function signature like: ``` python def conv2d(x, kernel, strides=(1, 1), border_mode='valid', dim_ordering='th', image_shape=None, filter_shape=None, output_shape=None, transpose=False, atrous=False, atrous_rate=1): ```
I would consider abstracting `conv2d` into a single interface that could use `conv`, `deconv`, `atrous_conv`. Otherwise there is a lot of redundancy across these 3.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
cropping, not padding
cropping, not padding
Same: don't mention specific axes
The indices of the axes depend on the dim ordering. Just say "width and height"
This should be private. Also, since this function is only called once (in a loop), please consider if you could in-line it in the parent function.
So I think we should: - move the function inside the parent function, since no one else will use it - keep the list comprehension, since we won't in-line the function after all... Thanks!
Please add `# Arguments` and `# Returns` sections.
Use ` around **kwargs
Please format the docstring to follow Keras conventions (see other docstrings).
Please use PEP8 conventions: spaces around operators (.e.g `*`)
What is your TF version? Here you are taking a slice, which as far as I can tell breaks shape inference and causes the following code to fail. A workaround is to manually set the shape of the slice. This may not be the case with the latest TF version. Unclear
Same remark as before regarding `output_shape`.
Also, you don't actually need these error messages after `assert` since this is a unit test
Use `'` as the quote character for consistency with the rest of the file
The ValueError should be listed in the docstring. The error message should specify what was passed, and the list of values expected instead.
this value error is good but do in other places
This is already validated in the constructor, no need.
This should be max.
Use `'` as string delimiter for consistency
Processing of `np_kernel` should be removed from this function
Theano -> Theano/TensorFlow
Blank line required before the next section
`_postprocess_border_mode` should be part of `_postprocess_conv2d_output`, it doesn't need to be its own function.
Blank line required before the next section
Line too long
Line too long
Line too long
Line too long
Line too long
What is the justification for this new argument? `bias_add(x, bias)` seems unambiguous...
How about the following? ``` mean, var, beta, gamma = [np.random.random(other_shape).astype(np.float32) for _ in range(4)] ```
Using comma here does not work as expected (unlike `print`). Also, I think "Invalid" may be more precise here (since the bias shape is known).
Need to fill in this section
Introduce an `if` block to avoid a very long line.
Please add a docstring.
Using code markers around code keywords (.e.g `_predict_loop`).
Docstring should have a `Returns` section and a `Raises` section.
Set default `batch_size` to None, like in `fit`.
num_train_samples != steps_per_epoch, though. A step is a batch, not a single sample.
"When using `steps_per_epoch`, ..."
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Prefer `if steps_per_epoch is not None`
@ns3284 Squash function has to be applied according to paper.
Please log the `axes` argument in the error message. It should be clear to the user upon reading the message what happened and why it happened (likewise for other backends).
An Example section would be welcome here.
Introduce an `if` block to avoid a very long line.
Isn't it equivalent to this? ```python def int_shape(x): return x.shape ```
We don't need to follow tensorflow's code. The most important things are simplicity, readability and correctness. The tests are here for the correctness.
Make the cast conditional on `condition` being the wrong dtype
Forgot a space ```suggestion ' If your inputs are not batched,' ```
This one is fine
Also I think the line does too much, breaking it into several lines would be preferable.
This one is fine too
These few lines break PEP8 conventions.
You don't need a lambda here. Also, don't break lines with `\`.
Don't put logic on an `if` line, introduce a line break. In general, I suggest rewriting the part of the code that prints evaluation results to make it simpler, easier to read, and more user friendly. A big goal of these example scripts is to be as user friendly as possible while introducing best practices.
Didn't notice this earlier, but why save both the entire model and its weights, separately? The saved models already contains the weights. I suggest removing `save_weights`.
Throughout this file, `"` is mixed up with `'`. Only use `'`, for consistency.
We generally call it "KTF"
This is already validated in the constructor, no need.
I think this is a good solution for now. In the future when we have a layer naming system, we'll use that instead.
I don't think this is useful in this example. Please remove.
@ns3284 Squash function has to be applied according to paper.
Better mention that the cropping happens along the time dimension here (axis 1)
cropping, not padding
The indices of the axes depend on the dim ordering. Just say "width and height"
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
cropping, not padding
Same: don't mention specific axes
Line too long, and not PEP8 compliant. Break it down into a few lines.
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Should be Tensor3.
pg 6 of the [paper](https://arxiv.org/pdf/1706.02515.pdf) says: > Therefore, we propose âalpha dropoutâ, that randomly sets inputs to Î±
Is there a reason why there is not a `SpatialAlphaDropout` like there is a `SpatialDropout`? In the paper they are not explicitly doing it, but they do have an argument `noise_shape` on their Github. When they release the code for more advanced datasets, we'll know for sure I guess.
We might need a more standard way to merge dictionaries (with the latter dict taking precedence). Like a `config` decorator. Or maybe that would introduce too much implicitness.
Use `'` for strings for consistency with the rest of the file.
Use a variable with a complete name, not `l`.
Use list markers
Need to fill in this section
Syntax error here (`}`)
cropping, not padding
Specify that this would be for 128x128x128 volumes with 3 channels
Better to use keyword arguments (same below). API change looks ok to me.
That's a good point, since we didn't require it be named `epoch` before, we should probably make the first argument positional and only make the second (new one) a keyword arg.
Please initially check that `mode` in is `{'auto', 'min', 'max'}`.
No warning should occur with default settings. It is safe to remove this.
Can you factorize this over `test_EarlyBaselineStopping_baseline_met`? The codes look a little redundant.
Code below this line should be on same indentation as if self.wait >= self.patience Otherwise, if verbosity is turned off, the current implementation doesn't do the actual learning rate scheduling.
Please raise a `NotIplementedError` when the use case is not supported yet.
Good catch! yeah there should be a warning.
Any reason why you are using `keys_` instead of `keys`? In any case, the standard naming convention for private variables would be `_keys`.
Thank you for the PR, @giuscri. Why is `epochs_trained` 3? The accuracy has been already reached in the second epoch.
Better to use `_keras_history`
No `+` needed for string concatenation at the end
"of a symbolic tensor" (it doesn't have to be a keras one)
No need for blank line
Better to use `_keras_history`
No need for `+` at the end. But needs a space after `.`.
var is a reserved keyword, use `v` or something like that.
"samples drawn from"
var is a reserved keyword, use `v` or something like that.
var is a reserved keyword, use `v` or something like that.
Are there cases where `any` would not return `bool`? If so, better to fix it in the corresponding backend.
This mechanism will only work for a few layers, and will fail in the general case. The proper behavior when batch size matters is to slice the input mask and run slices through `self.layer.compute_mask`, then concatenate. No reshaping.
No, this should always be entered if `input_shape[0]`.
Some layers may only be able to process a batches of a fixed size. A built-in Keras example are stateful RNN layers. Other examples include custom layers that share information across samples in a batch (one case I've come across is to have batches of size 2 and take the distance between the two samples). Again: if the batch size is specified, then it is meaningful, and you should not arbitrarily change it.
You should use a broadcast rather than a repeat, for performance reasons
I vote for option number two. That seems the most consistent with other parts of the Keras API.
Should probably be int in both case. We don't want separate cases to handle.
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
No reference to `_keras_shape`, that's an implementation detail. Call it "static shape"
"`x` can be" (better be explicit)
"input names to Numpy arrays"
Same, can be a list
There could be multiple model outputs
"output names to Numpy arrays"; "`y` can be"
Code markers around code keywords (`)
"the parameter" is redundant, you can simply say `epochs`
This will be more readable with code markers around `epochs`.
Code markers around `validation_split`
Code markers around tuple
No need for final space
No need for final space
You should be able to get this list without relying on `nb_params`. Then you can get rid of all code related to it.
You are later multiplying with a float. This has no effect on the output
The formula is wrong because `np.prod(self.output_shape[1:-1])` is not the number of positions where the kernel is applied, it is the maximum number of positions.
@fchollet Does the output shape include padding? That may be the problem you're referring to. I tried to think of any other way the output shape would not be equal to the number of positions the kernel is applied, but as far as I can tell input stride and input padding are already taken into account by this. A specific counter example would be greatly appreciated.
This formula is wrong for most convolution layer configs because it doesn't take into account padding and strides
You should not rely on private property `_keras_shape` which may not be set
This seems strangely ad-hoc
Additionally this will give the wrong number for RNN layers
`+ K.epsilon()` in the denominator.
Capital variable names is not appropriate for scalar variables
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
The targets / predictions are assumed to be in the [0, 1] interval but that is not enforced. It should be.
`mathews_correlation` or `matthews_correlation_coefficient`
This is fixed. Please do not submit PRs that are incorrect or unfinished, post a Github issue instead.
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
Format your docstrings like other docstrings in the codebase
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
Respect PEP8 conventions.
The best would be to add an `axis` argument in these loss functions. If you don't want to do that, you can use a different loss function, like `mse`.
You don't appear to be doing any correctness checking. A simpler test would be: - call `predict` with the first model, store results in y1 - switch the data format, call `predict` on the same input array, store results in y2 - check that y1 == y2
About this test: - please use the same docstring format as elsewhere in the codebase - use `'` as quote character for consistency - use lines that are <= 80 char
Line too long
Line too long
Line too long
Please introduce line breaks in the docstring to avoid very long lines.
This one is fine too
Line too long (and several other lines in this file as well)
Style: break long lines in the test
Please make multiple statements instead of breaking the line, it will improve readability. ```python if _LEARNING_PHASE ....: return .... else: return .... ```
The same fix should be applied to `get_updates_for`.
Incorrect / confusing. Please fix.
`dtype in str(var.dtype)` like in CNTK would seem like a better check. Dtypes in TF are weird, and both `float32_ref` and `float32` are possible values for the `name` attribute of a float32 variable.
You can use `random.choice` instead
In validation or test, there is no concept of epoch, so that seems OK to me.
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
Please make this method private.
Please make this method private (unless there is a rationale for making it part of the public API).
Good catch! yeah there should be a warning.
There are added empty lines. Please remove them.
One import per line. Also import `models` so as to avoid `tf.keras` calls in the code. This *is* the Keras codebase! It should import internal modules, not `tf.keras`.
Just import `utils`
We generally call it "KTF"
What is your TF version? Here you are taking a slice, which as far as I can tell breaks shape inference and causes the following code to fail. A workaround is to manually set the shape of the slice. This may not be the case with the latest TF version. Unclear
Please fix the identations issues in the file. I'll review the PR in the next few days. Thanks for updating it!
I will note in passing that doing one conv per channel is not an efficient way to implement depthwise conv (too much overhead). Preferable to do a single conv with a diagonal kernel.
Please remove new line (`"""Instantiates`).
or invalid depth_multiplier, alpha, rows when `weights='imagenet'`.
I mean `RuntimeError`.
Nit: first line of docstring (one-line summary) should fit in one line and end with a period.
Could you please split this method to a standalone utility function in `recurrent.py` (named `def _standardize_args`)? The only instance attribute it needs is `_num_constants`, which can be passed as a function argument (`num_constants`). That way we don't need to duplicate this code, you can just import it from `recurrent.py`.
In line with naming conventions in this API, this should be `_num_constants`.
Clarify the error message; a "Keras tensor" is the output of a Keras layer
and -> or
Use bullet points
Break up long line
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
You can use `K.is_keras_tensor`
I believe you don't need this method, the inherited one should work fine.
I think this is probably needed as well, otherwise the follow up model.eval() will accumulate the metric result from this train/test_on_batch.
Description not consistent with actual behavior...
`raise NotImplementedError` may be more appropriate.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
This message needs to be removed, as `validation_data` is no longer passed to the callback.
I thought since `callbacks.Tensorboard` didn't need `validation_data` anymore (and no other callback seems to use it), we could safely remove it; but I guess this would break users' custom callbacks. +1 for keeping it, then.
`batch_size` parameter needs to be deprecated too.
In that case, I think this error and the corresponding test should be kept.
Syntax error here (`}`)
Please raise a `NotIplementedError` when the use case is not supported yet.
Style: code markers around `Sequence`
I'm afraid "Container" is not a term that can be readily understood by most users. Please say "list, tuple, or set"
This method is new, so it has never had a `verbose` argument. This check was for backwards compatibility. Here it isn't required. You can just remove `kwargs` management altogether.
"When using `steps_per_epoch`, ..."
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
Prefer `if steps_per_epoch is not None`
Docstring should have a `Returns` section and a `Raises` section.
+1. Use case would be validating on more data than fits in GPU memory. So the generator has to return small-ish minibatches, but I want to validate on more than one minibatch.
this is discussed in https://github.com/fchollet/keras/pull/7113
Set default `batch_size` to None, like in `fit`.
Please rename `sparse_top_k_categorical_accuracy` for consistency with other metrics names
You can replace the next lines with `return - dice_coef_loss(y_true, y_pred)`
PEP8 specifies that there should be spaces around operators. Also this is a very long line, so you might want to break it up into two lines.
Format your docstrings like other docstrings in the codebase
Please standardize the docstrings formatting to be the same as other docstrings in the codebase.
Taking the mean makes this quantity a scalar, I believe. It should be a vector (different value for each sample).
No point in calling super here
But we would need this argument in case we want to support *multi-label* binary classification, where you have multiple dimensions on the last axis, and each one of them encodes a binary class prediction. So I think we should have the argument. And we should add support for: - multi-class, single-label categorical classification - multi-class, multi-label binary classification
What you call `one_hot` is referred to as `categorical` everywhere else in the codebase (e.g. categorical_crossentropy, cateorical_accuracy, to_categorical). But think we don't need this argument, when it comes to single-label classification, because you can automatically infer it from the shape of the predictions (if the last axis is size 1, it's binary, else categorical).
This should be `activations.get(activation)` where `activations` is `from keras import activations`
This line should be right after `"""`. Put "`" around function names.
Also add a `# Arguments` section for `*args`
Please make this method private (unless there is a rationale for making it part of the public API).
> `T.sqrt(self.p/(1-self.p))` Something should be done to avoid division by zero in case p = 1... maybe clipping p to [epsilon, 1-epsilon]? In terms of coding style, please use spaces around operators and use floats in float operations.
Per the failing docstring test, this docstring needs a `Raises` section mentioning the ValueError: https://travis-ci.org/fchollet/keras/jobs/282558708
Please make this method private.
Two line breaks after the first sentence.
Are these various classes necessary? Could we simply use an `if` switch? Classes and inheritance is meant to modularize code for the purpose of reuse and abstraction. If these classes are used in only one place and we do not use them to achieve a higher level of abstraction, we would be better off with `if` rules.
`cnn` sounds like a model instance, but it's a tensor. Call it `x`
@ns3284 Squash function has to be applied according to paper.
The point of these conversion interfaces is that old code should still work. So in this case we should figure out a better solution. Please leave out this layer.
This could simple read "converted"
Unclear what purpose this line serves.
Sorry, I was confusing it with `LeakyReLU`. You're right.
This layer is commonly used with a positional argument, e.g. `PReLU(0.4)`. This should still work.
Additionally, the old `Embedding` supported a `dropout` argument that we no longer support. Since calls using the old API should still work, the dropout argument needs to be handled. Just remove it from kwargs if present, and raise a warning saying that the argument no longer exists that people should use instead a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.
'p' is already removed when, kwargs.pop('p')
Actually it can. The first two are positional (input_dim, output_dim).
`args` is the list of positional arguments passed by the user. It could have any length.
Should `args[1:]` here (the first entry in `args` is `self`).
Additionally, raise a `ValueError` with a helpful message in case an unexpected key is found in the dict. This is important because people may have typos in their dict argument and they would never notice.
It would be more concise to make the named keyword args part of the function call, rather than storing them in the `kwargs` dict.
At this point a check should be done that the cropping argument is a tuple of length 2 of tuples of length 2
cropping, not padding
Same: don't mention specific axes
At this point a check should be done that the `cropping` argument is a tuple of length 3 of tuples of length 2
Should be `[InputSpec(ndim=5)]` not 4 for `Cropping3D`
Line too long, and not PEP8 compliant. Break it down into a few lines.
This should be max.
Yesterday I added support for nD tensors in TF dynamic RNNs. So now it should be possible to remove this exception (and `if tf then unroll` branching), as far as I can tell it will just work.
Yes please, rewrite those lines.
it's less pythonic but more in line with the style of how things are computed at some other places in the code base.
It's possible to write this one liner in several more readable lines of code. It will also solve your pep8 problems.
Same here, not sure if the dict comprehension is readable.
`validation_data` is still available in callbacks: It is set [here](https://github.com/keras-team/keras/blob/58fd1f0589d33aeb33c4129cfedfb7737495efc0/keras/engine/training_generator.py#L124).
In that case, I think this error and the corresponding test should be kept.
This message needs to be removed, as `validation_data` is no longer passed to the callback.
not sure you need to wrap this in a method it looks clean this way though.
Just checking for `Wrapper` will not work in the general case. The only `Wrapper` that could work with an `Embedding` currently is `TimeDistributed` (but even that sounds overly niche). Please remove this statement
Please remove these changes so that this callback has the same behavior as the other callbacks. It could be discussed in another issue/PR.
If you're using the default RMSprop parameters, you might as well pass it as a string to `compile()`.
Previous version was more readable imo.
`# Returns `
You don't need to specify this field if there is no return output
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
I think these layers would benefit from having more transparent names.
@RuiShu Now I see the point, thank you. And the multiplication makes sense then, cool.
Spaces around operators
I see you are a Theano user. This wouldn't work with TF.
If you don't need to create a loss dependent on model outputs, you can use `loss=None`. In that case only the loss you added with `add_loss` earlier will be used.
"the input name to a Numpy array" (singular in this case, for `Sequential`)
"or 1-element list of Numpy arrays" does not need to be specified, since this is not how we want people to use `fit` on `Sequential`.
Insert link to callbacks page
Same, can be a list
this is discussed in https://github.com/fchollet/keras/pull/7113
"output names to Numpy arrays"; "`y` can be"
There could be multiple model outputs
This will be more readable with code markers around `epochs`.
Code markers around `validation_split`
Code markers around tuple
Better to put the activation as the `activation` keyword of the layer below
You are manually encoding the hyperparameters in both cases (number of layers and size of each layer).
Better to put the activation as the `activation` keyword of the layer below
filters //= 2
You don't need BN for such a shallow network, `Conv2D` and `MaxPooling2D` should suffice
This is TensorFlow specific. Instead you can use `K.int_shape(x)`
You don't need BN for such a shallow network, `Conv2DTranspose` with relu activation and strides should suffice
You don't need this, `Conv2DTranspose` with strides should work better
You don't need to specify this field if there is no return output
Please format all docstrings in this CL like other docstrings in the codebase: ```python """One-line summary ending in a period. # Arguments argument_1: Description (may include type if relevant). argument_2: Description. # Returns Description of the output. """ ```
Awesome : ) But now you'll need to remove the outdated exception as well ; )
Also around `=`
Spaces around `<`
`if n.__class__.__name__ == ...`
We can either make everything `int`, or make the two different behaviors possible without backend-specific code, for instance by casting to `K.dtype(mask)`.
Should probably be int in both case. We don't want separate cases to handle.
If concatenation is not on the time axis, then masks have to be AND-merged on the time axis.
I vote for option number two. That seems the most consistent with other parts of the Keras API.
This will break with TF, and it would be more efficient to use `go_backwards` since it avoid the back and forth with `permute_dimensions`.
PEP8: space after comma
Remove leading space
Add line break above
The number of batches in the Sequence
Space after #
It isn't a queue of data? I didn't mean 100 threads. Perhaps I'm not understanding something
I think we should use `max_queue_size` for consistency with other API keywords, which are full words, as a general rule
Use code markers around `put()`
Remove leading space
Is this backwards compatible with what we had previously? We have datasets and applications relying on the previous system.
Newline before this line
No need to capitalize Input or Tensor
num_train_samples != steps_per_epoch, though. A step is a batch, not a single sample.
this is discussed in https://github.com/fchollet/keras/pull/7113
The requirement for `validation_steps` should be based on the type of `validation_data`. We should allow Numpy validation data even if fitting from data tensors (e.g. same way that `fit_generator` allows both Numpy validation data and generator validation data).
Insert link to callbacks page
You can remove this part. If training from symbolic tensors, there is no need to convert input arrays because there are no input arrays (and `indices_for_conversion_to_dense` will always be empty).
"When using `steps_per_epoch`, ..."
Code markers around `validation_split`
Prefer `if steps_per_epoch is not None`
Code markers around tuple
"Name-based weight loading (instead of topological weight loading)"
Please clarify the docstring: "in case of mismatch between the number or shapes of the weights of a layer in your model, and the corresponding weights in the savefile".
"The weight file you are trying to load is in a legacy format that does not support name-based weight loading".
Break up line
Note that layers that don't have weights are not taken into account in the topological ordering, so adding or removing layers is fine as long as they don't have weights.
Importantly, these are not all model weights, just the model's top-level weights (assigned to the model instance directly, not via layers). We should pick a group name that reflects this, e.g. `top_level_weight_names`
You don't need to compute a list of filtered layers in this setup. You can build the index in one go.
Singe the names are expected to match across models, "in the current model" does not make sense here.
By definition `name` and `layer.name` will be the same. The error message should be modified to reflect this.
Introduce line return after `(` to reduce line length
