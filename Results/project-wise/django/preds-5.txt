Looking at the code changes below in the middleware, I also see no clear reason for not returning a new token here to stay a little bit more compatible to with what we had before.
Why would you need to sanitize something that's already in your session? Seems a bit late...
Chop " we"
I personally generate the NONCE's on the client side using javascript (so I don't need the token in the response body). It would be nice to continue long term to accept the raw cookie value as a valid csrf token.
Is this branch a candidate for removal in some future release? Either way, would be helpful to elaborate on how the backwards-compatibility case arises. I think it's upgrading Django in the presence of existing token set by older versions of Django, but would like t to confirm.
Yes, but I have to ask why? I get that there is a side effect, but how much of a problem is this? I can potentially see the problem if you do the following: ```python def view(request): ... wrapped_view = no_append_slash(wrapped_view) # Now both ``view`` and ``wrapped_view`` have ``should_append_slash`` set which # means using ``view`` might not do what you expect. ``` But typically you're going to do the following: ```python @no_append_slash def view(request): ... ``` Which would be no different to assigning the attribute directly after the function is created if not using a wrapper function: ```python def view(request): ... view.should_append_slash = False ``` I was concerned that there may be an issue if you wanted to do something like the following, but it turns out that `functools.wraps()` also copies attributes other than `__name__` and `__doc__` so this works fine: ```python @csrf_exempt @no_append_slash def view(request): ... ``` But it also effectively translates to having to call three functions, the outer two which have no benefit other than to have copies of all of the attributes of the functions within them. This has some call overhead and, if there are many decorated functions, excess memory use to store all these additional function objects and extra attributes as they bubble up.
IMO supporting a typical usage is not enough in this case, because `no_append_slash` should be used to avoid enumerations, so it's security-related, like `csrf_exempt`. It must be bulletproof, without any side effects.
Note that there are similar decorators that add attributes to functions in the works [here](https://github.com/django/django/pull/13483/files#diff-3fd16120fca44bdc94983057b9c28e7e815ed56a44f74fee21c2ddfac5cee2acR115-R139) and [here](https://github.com/django/django/pull/13532/files#diff-fd2291d1e25086ffa9e332f7bb4d16800501b7944a3659b1e5eb0a34e6ac924cR1-R60) that are not using this approach.
Ok, I see. Makes it useful for the rare case you want the function both decorated and un-decorated.
```suggestion path = '%s/' % request.path ``` :thinking:
Arf, this is also not optimal either. `pre_save` can have side-effects, like `django.db.models.fields.files.FileField.pre_save` does 😕 We probably don't want to trigger those here. I mean, serendipitously it would work for the `FileField` because even if the returned value is still the same (so we don't add the `field.name` to `updated_fields`), we actually triggered the side-effect committing the file 😂 However, that seems pretty brittle 😅 I'm not sure what the cleanest/Djangoest approach would be here 🤔 We could add an attribute on the Field class, like `Field.has_pre_save: bool`, but that creates a precedent and users/libs must update their code accordingly. But at least, we would know _for sure_ which fields need to be added and which don't. Any other suggestion is very welcome!
Perhaps the following to avoid constructing a new set unnecessarily: ```suggestion if fnames.issuperset(defaults): ```
I think this should include non-concrete local field as well since `select_for_update` will lock at tables involved in MTI and `Model.save` handles it just fine.
> And yes it feels wasteful, but what are the options? I guess `Options` could have a private `cached_property(_concrete_field_names -> frozenset)`. It seems niche enough to be kept private but worth it given this set is computed on every `Model.save(update_fields)` call and on every `QuerySet.update_or_create` call after this PR.
You'd need to either include both `f.name` and `f.attname` or use `self.model._meta.get_field(name)` for each `defaults` which I think supports both form e.g. ```python get_field = self.model._meta.get_field update_defaults = True for default in defaults: try: field = get_field(default) except FieldError: break if not field.concrete: break else: update_defaults = False ```
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
This exception message is different from that in `related.py` though the logic/intention surrounding it seems to be the same. Is this intentional? (FWIW, I find the message in `related.py` to be clearer)
Same as below, you should be able to call `self.using()` directly.
Welcome to the wonderful world of `contenttypes` where clearing a GFK (even an optional one) actually deletes the objects.
I'd rather find out why we are getting the failure first. User can opt in for `self` to be a custom manager with the `__call__` syntax, doing `self.model._default_manager` bypasses it.
@felixxm that's a tricky one for sure. We could adjust MySQL's `allows_group_by_pk` feature to be based of `not ONLY_FULL_GROUP_BY` but that would likely incur a large performance hit which is definitely not suitable for a backport. I guess we could always skip the test on MySQL for now.
I should have been clearer but `firstname` and `lastname` can be omited as they'll default to `''` if missing.
You can drop all the `firstname`, `lastname` above and default to `''`. Also could create a single `Employee` and use `cnt__gt=0` below.
About Josh's suggestion, we've considered try/except/fail an antipattern because it hides the original exception and thus makes fixing a failure more difficult. There's no problem with a test erroring rather than failing.
how about: ``` try: query_that_shouldnt_fail = ... except ..ProgrammingError: self.fail('Appropriate Error Message') ```
"nonexistent" would be the word
I believe you can simplify all this stuff to lines like: ``` assertFieldType('pos_big_int_field', 'models.%s() % connection.features.introspected_field_types['PositiveBigIntegerField']) ``` I don't think the if statements are needed anymore (similar elsewhere in this file).
Ahh, yes, sorry :facepalm: Good catch :dart:
You want to avoid altering `self` here as subsequent calls will reuse this attribute even if this branch's conditions don't match.
``` @mock.patch('django.contrib.contenttypes.management.update_contenttypes') def test_remove_contenttypes(self, mocked_update_func): management.remove_contenttypes(self.app_config.name) self.assertEqual(mocked_update_func.call_count, 1) ```
Nitpick but `dict.get` default value for a missing key is already `None`.
You're calling `model_name.lower()` twice in most cases
Yes, this should be taken care of before.
It looks like you can actually do `fields = self.models[model_key].fields` (similar to further down) since you're only using `model_state.fields` below.
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
The other option is to wrap the file with something like: ``` from django.core.files import File class ChunkedFile(File): DEFAULT_CHUNK_SIZE = 4096 def __iter__(self): return self.chunks() return StreamingResponse(ChunkedFile(open(fullpath, 'rb'))) ``` I considered using this wrapper for FileResponse.
Your solution honestly isn't _that_ much more complex, so I'm not saying we shouldn't do it, I was just curious how you ended up here! I think the resulting patch is pretty nice - I will need to take more time to properly review it but I like it on first glance.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
`aiter` is new in Python 3.10. https://docs.python.org/3.10/library/functions.html#aiter Django 4.2 will support Python 3.8, and 3.9 too.
line saver? ``` format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' extra_context['format_string'] = format_string ```
Ideally this would be passed as a parameter instead of being baked into the SQL. Maybe adding a `%%s` placeholder and inserting the format string at `params[0]` would work? ```python template = "strftime(%%s, %(expressions)s)" sql, params = self.as_sql(compiler, connection, template=template, **extra_context) format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' params.insert(0, format_string) return sql, params ```
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
Since we used the `::%(db_type)s` for PostgreSQL solely for readability purposes and this now requires two parentheses wrapping `((expr)::type)` I think we should consider removing that `as_postgresql` override entirely as `CAST(expr AS type)` seems more readable to me at this point.
Don't sqlite have the same issue as illustrated by `test_field_database_defaults_sqlite`? Once solution might be to use `STRFTIME('%Y-%m-%d %H:%M:%f', 'NOW')` on sqlite but it appears like it only supports 3 digits when the expected precision is 6.
We do this twice, so I'd move `joined_column_names` above the first `index_name` creation.
In most of cases names won't contain multibyte chars, so it should be worth avoiding multiple encoding and slicing, e.g.: ```python if len(table_name.encode()) == len(table_name): table_name = table_name[:other_length] else: # Shorten table name accounting for multibyte characters. while len(table_name.encode()) > other_length: table_name = table_name[:-1] ```
I added a small hook for this.
`'utf-8'` is the default. We can remove it.
Ok, I don't think it needs to be skipped on sqlite (since it passes). A note in the docstring that it's only a problem on certain databases would be helpful.
This can just be `pass` since the functionality doesn't matter.
use of one the styles in 04de4369325097472d7ad036dac262555002ba88
Do we need to change `related_name` here? We could add `note` with `related_name='owner'` instead.
Please add a trailing comma.
This test name mentions multi-table inheritance but the body of the test has nothing to do with it.
These check should respect `required_db_features`, so we need to omit checking conditions for `UniqueConstraint`\`s if `connection.features.supports_partial_indexes or 'supports_partial_indexes' in cls._meta.required_db_features`.
This duplicates logic from `_check_local_fields()` and added unnecessary error `models.E042` which is already covered by `models.E012` in `_check_local_fields()`. I think we should pass fields from `references` to the `_check_local_fields()` and remove redundant logic, e.g. ```python for field_name, *lookups in references: fields.add(field_name) if not lookups: # If it has no lookups it cannot result in a JOIN. continue try: field = cls._meta.get_field(field_name) if not field.is_relation or field.many_to_many or field.one_to_many: continue except FieldDoesNotExist: continue # JOIN must happen at the first lookup. first_lookup = lookups[0] if field.get_transform(first_lookup) is None and field.get_lookup(first_lookup) is None: errors.append( checks.Error( "'constraints' refers to '%s' which results a JOIN attempt, " "JOIN is not permitted in 'constraints'." % LOOKUP_SEP.join([field_name] + lookups), obj=cls, id='models.E042', ) ) errors.extend(cls._check_local_fields(fields, 'constraints')) ```
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
Thanks for these tests, they look great!
This warning ID was not updated after copy-pasting it.
Since you don't actually need the instances of all those models, can you use `WindowTestModel.objects.bulk_create()` please.
Or split the args over two lines if it passes 119 chars.
We usually avoid hanging indents, and prefer this: ``` WindowTestModel.objects.create( name='Jones', salary=45000, department='Accounting', hiredate=datetime.datetime(2005, 11, 1) ) ```
I think this can be single lined, and since the filter clause doesn't matter we can use sth shorter, e.g.: ```python WindowTestModel.objects.annotate(dense_rank=Window(expression=DenseRank())).filter(dense_rank=1) ```
I've opened a separate [ticket](https://code.djangoproject.com/ticket/28560) for that.
Looks like Windows isn't happy with the dots. I think something like 'nonexistent' should work.
suggestion: "commands that don't need settings succeed if settings file doesn't exist"
move this to the previous line (we favor longer lines over non-hanging indent)
Maybe we could test that `name_color_uniq` is also in the message? ```suggestion with self.assertRaisesMessage(ValidationError, 'name_color_uniq'): ```
I would move test for conflict with an existing Python module to a separate test e.g. `test_importable_target_name`
This is never executed.
@felixxm Uf, now that we changed it I noticed that we might have a problem here. Shouldn't the `_legacy_hash` keep a hardcoded `key_salt = 'django.contrib.messages'` -- it never had a different salt…
use a msg variable
I'm a little concerned about the loss of `constant_time_compare()` here which sounds like it was added as a potential mitigation against timing attacks.
Shouldn't that second test be against `request.session[SESSION_HASH_KEY]`? Because now, the value must be equal to both the users pk and their session auth hash, or the session is flushed.
``` Superuser creation skipped due to not running in a TTY. You can run `manage.py createsuperuser` in your project to create one manually. ```
I would add `OK`: ```suggestion executor.recorder.delete(app, name) self.stdout.write(self.style.SUCCESS(' OK')) ```
`--prune` is ignored when `--plan` is used. Maybe we should raise an error that they're mutually exclusive.
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
no restructured text (:class:) in docstrings please
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Use single quotes consistently.
Cannot this information solely be extracted from the model itself? ie `.model._meta.app_label`.
It seems this URL doesn't work anymore.
don't add this blank line.
please alphabetize with the rest of the django imports
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
This doesn't seem correct as `SimplePoFileTests` no longer has any tests in it so now this subclass doesn't do anything.
I would add quotes: ```suggestion violation_error_message = _("Constraint '{name}' is violated.") ```
Could you please keep the cross-app reference that we had before.
I think for the benefit of Python 3 users at least we should set `__cause__` on this new exception to the original `KeyError`.
I think "by" in this sentence should be replaced by "with": normally we'd say "tried to replace X _with_ Y"
I don't know if this is an overkill, but we could log the exception.
Unnecessary `.keys` call ```suggestion return list(unique_items) ```
Use `setUpTestData` now that two models will be used by two methods.
In cases like this, we prefer to include a trailing comma so if more items are later added, we don't need to modify this line again.
could we inspect `query.order_by` instead? Maybe it's fine as-is, but that seems a bit less fragile.
Need to test that result is as expected, not only calling it.
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
I think that you could move the slicing inside `DebugLexer._tag_re_split()` and then `DebugLexer.tokenize()` will be even closer to `Lexer.tokenize()`: ```suggestion for bit, position in self._tag_re_split(): ``` Maybe with these changes it makes sense to rename `DebugLexer._tag_re_split()` to something like `.split()` and add the same method to `Lexer` with something like: ```python def split(): yield from ((bit, None) for bit in tag_re.split(self.template_string)) ``` Then you should be able to ditch `DebugLexer.tokenize()` entirely and inherit it.
We don't need to call `len()`, `slice()` will work the same with `None`.
Passing the last argument as a keyword argument (`in_tag=False`) would make the code easier to follow. This is almost always better for boolean arguments, except when they're the only argument of the function.
It's hard to assess the correctness of this change through visual inspection. I'll trust you (and the test suite) on this.
Yup. It's completely irrelevant to the module it's in with this change.
Both `with` should fit on the same line, `with self.subTest(value=value), self.assertRaisesMessage(ValidationError, "'Enter a number.'"):`
This error message is confusing. A `Car` instance doesn't have a `car` field. Should it refer to the `make` field instead? The `CarDriver` through table has a `car` foreign key with `to_field='make'`.
I don't see much need for the class attributes.
Should we also have a pointer here of the form ```suggestion with self.assertRaisesMessage(FieldError, "Cannot distinct on 'other_rating' alias. Use annotate to promote it"): ```
I think we should raise a more descriptive error, maybe the same as in `add()` and `set()`.
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
Ah yes. It no doubt will. (That's too much DRF that is. 🙂) We need to handle this. 👍
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
Could switch to single quotes as long as this is being modified.
Yes, just be careful not to mess up the `else:` case below
Is there any reason you are not using `request.get_port` like above? I also do not like the duplication, can you set `good_referer` before like: ``` good_referer = settings.SESSION_COOKIE_DOMAIN if settings.USE_CSRF_SESSIONS else settings.CSRF_COOKIE_DOMAIN ``` and then simply check on ``` if good_referer is not None and … ```
Here we need ``` python elif settings.CSRF_COOKIE_DOMAIN is not None and settings.CSRF_USE_SESSIONS: raise ImproperlyConfigured("When CSRF uses sessions, use SESSION_COOKIE_DOMAIN instead of CSRF_COOKIE_DOMAIN") ``` This, to make sure people don't just forget such settings, which probably express some security assumptions about their deployment.
Use single quotes to stay consistent with the code above.
Merge with the line below since you are not using `session_token` later on. Is it actually needed to sanitize the session token? After all the user cannot change it.
I think you could use `self.assertSequenceEqual` rather than this.
Please add a trailing comma.
Collapse this decorator into a single line.
First we should verify this passes before we toggle `is_active` to False.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
```suggestion self.assertEqual(a.headline, 'Default headline') ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
minor improvement ```suggestion now = datetime.now() a = DBArticle.objects.create() ```
```suggestion now = datetime.utcnow() a = DBArticle.objects.create() ```
Yeah, this is a good point, reuse an ordering if possible (maybe even force it)
Slow or not, it is kinda pointless to do since we do not need the data -- so yeah, we should not count here
You are leaking information about whether somebody has access or something doesn't exist.
Raising a 404 with the same message as in the previous check would mask the issue. Then again I think we already leak a lot like that in other admin pages, will have to double check.
Both `has_perm()` and `has_change_permission()` take an optional `obj=None` argument for object-level permission checks as implemented by e.g. django-guardian. I think we should provide this here as well.
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
This should only be performed if the `relations` registry is already computed; `if 'relations' in self.__dict__`
> Would that be fine? Or is there something I am missing? `else` is not necessary, there is no need to resolve relations at this point.
The same amount of caching would be happening in the approach I'm suggesting. It's just that you would be calling `self.resolve_fields_and_relations() / self.all_relations = ...` (e.g. in a method) instead of accessing a cached property. It just seems like the usage in the PR doesn't really match `@cached_property`'s use case. In addition to what I mentioned above, the calls to `self.all_relations` in the PR aren't using the return value, it's just doing that for the caching side effect, which you could do more simply / explicitly.
If `django.__file__` contains non-ASCII characters, this will raise an exception. `is_ascii(force_text(django.__file__))` or catching the encoding exception in the is_ascii function would be safer approach. (This would be incorrect if `django.__file__` is a relative path, of course.)
to make it simpler: ``` py skipIfNonASCIIPath = unittest.skipIf(...) ```
You don't need to mock, it will return `False` for a bad file descriptor.
We should `try` yielding and `finally` restoring `old_cwd`.
This could become a class attribute so it needn't be repeated.
Since `separate_logs` seems like a higher-level mode that does multiple things, maybe you can make it so the mode doesn't need to be stored as an attribute. For example, the following line could write to a `self.output_stream` that defaults to `os.devnull`. When running in script mode, it could be set to `self.stdout`. It would also eliminate the need for an `if` statement.
`# Write the migrations file to the disk.` and something like `# Alternatively, makemigrations --dry-run --verbosity 3 will output the merge migrations file to stdout rather than saving the file to the disk.`
I noticed that all logs and prompts have `ERROR` style when using `--scriptable`, e.g.: ![image](https://user-images.githubusercontent.com/2865885/148344507-ada0d115-4a48-4001-81a2-b62c919c5e45.png) ![image](https://user-images.githubusercontent.com/2865885/148344684-e00db0d8-c25f-45fc-ba54-9dfef13eac7c.png) We could create a copy of `stderr` without the `ERROR` style and use it where appropriate :thinking: ```diff diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py index cdb200f22e..096702814c 100644 --- a/django/core/management/commands/makemigrations.py +++ b/django/core/management/commands/makemigrations.py @@ -6,7 +6,7 @@ from itertools import takewhile from django.apps import apps from django.conf import settings from django.core.management.base import ( - BaseCommand, CommandError, no_translations, + BaseCommand, CommandError, no_translations, OutputWrapper ) from django.db import DEFAULT_DB_ALIAS, OperationalError, connections, router from django.db.migrations import Migration @@ -62,9 +62,17 @@ class Command(BaseCommand): help='Output only created migration filepaths to stdout; divert logging and prompts to stderr.', ) + def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False): + super().__init__(stdout, stderr, no_color, force_color) + if no_color: + self.stderr_log = self.stderr + else: + # stderr without the ERROR style. + self.stderr_log = OutputWrapper(stderr or sys.stderr) + ```
_"f-strings should use only plain variable and property access"_ This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
We could add this hook in a separate commit/PR.
These could be alphabetized.
I believe the name should be `CITextField` for Case Insensitive Text Field.
(It's kinda hilarious to recommend a case change on a name that's literally case insensitive.)
For consistency, use a tuple instead of a list.
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
I'm torn whether or not this copy is necessary. When we resolve the expression we do a copy of the subquery anyway. Even if the queryset was cached and evaluated, the resolving will copy a new queryset anyway. ```python qs = Model.objects.whatever() sq = SubQuery(qs) list(qs) # this evaluates the queryset that subquery is holding onto OtherModel.objects.annotate(subq=sq) # queryset is copied here anyway, previous eval doesn't matter ``` Let me know if you can poke holes in my reasoning (it is new years day after all...).
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
Yeah that's what I suspected too. Stupid SQL.
This is not only about constraints but also about noop `ALTER FIELD` operations. Field alteration can cause many DDL changes. > We could just compare the old and new field. That's exactly what we're doing here, we compare fields but without attributes that don't impact schema changes.
I don't think this is the best way to address this issue. We will always have to keep this list of fields updated. Instead we could change `_alter_field` field to do nothing when the constraint hasn't changed. We could just compare the old and new field. This is the `if` that drops the constraint. https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L590 and the one that adds it back https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L810
I guess `name` would be another one.
I think we missed some attributes e.g. `related_query_name`, `limit_choices_to`, or `validators`.
Maybe? ```suggestion def _field_non_database_attrs(self): ```
chop "Check that"
Shouldn't that second test be against `request.session[SESSION_HASH_KEY]`? Because now, the value must be equal to both the users pk and their session auth hash, or the session is flushed.
This one is fine as `auth.load_backend()` is used in `clean_username()` above. ```suggestion request.session.get(auth.BACKEND_SESSION_KEY, ''), ```
If we want to change the default we can add a separate ticket and change it in Django 4.0. There is no need to use `VERSION`.
So, I've been hemming and hawing on whether to mention it, because it conceptually works when in the error message, but it still seems slightly _'off'_ to me that the warning would say `SECRET_KEY_FALLBACK` when the setting is `SECRET_KEY_FALLBACKS` (plural). I guess if we're not going to say _which_ one errored (which _we could_, using hints) I think it'd make more sense to say `One of your SECRET_KEY_FALLBACKS has less ...`
I'm afraid isort insists on the backslash version
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
We should run these tests only on SQLite: ```python @unittest.skipUnless(connection.vendor == 'sqlite', 'SQLite tests') ```
would be helpful to explain what the issue is (e.g. how must the polygon orientation be fixed)
I'd move the entire `geoadmin` folder to the `geoadmin_depracated`.
`fields` is always specified by callers, no need to have a default value
This is required only for indexes defined in `Meta.indexes`. Should we pass list of pure fields names in `remove_index()` instead? For example: ```python def remove_index(self, model, index): self._create_missing_fk_index( model, fields=[field_name for field_name, _ in index.fields_orders], expressions=index.expressions, ) super().remove_index(model, index) ```
What about indexes and constraints based on `expressions`? For example: ```python Index(F('author'), F('title'), name='author_title_index') ```
Not a blocker or anything but `concurrently` seems more appropriate than `concurrent` for the kwarg name to me. e.g. `add_index(model, index, concurrently=True)`
This formatting change is not related with a bug fix, please revert.
I'd use hanging indent as we do for Python code: ``` WHEN EXISTS ( SELECT 1 FROM user_indexes WHERE user_indexes.index_name = user_constraints.index_name AND user_indexes.uniqueness = 'UNIQUE' ) ```
Oh, and you should expect even more fun with long names of automatically generated m2m tables. They have a slightly different shortening.
Assuming `tables` here comes from the apps, this will have a problem with long (>30 chars) table names. The Oracle metadata tables will hold the shortened names.
I think we can remove `unqote_name` and always add `token.value[1:-1]`.
If you're slicing `[1:-1]` just to remove backticks (`` ` ``) around column names, I think you need to find some other way. While working on https://github.com/django/django/pull/11452, I tried this function to get the `JSON_VALID` constraint for introspection. After some debugging, I found out that it gets sliced into `son_vali`. Perhaps using ``.strip('`')`` is enough, but I'm not really sure...
Here too -- I'd prefer to see `raw_converter` replace `e` in the exception message
And basically that's how it works even now, because `msg` for `KeyError` contains a nonexistent key. We can use `raw_converter`.
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
This check is also redundant.
I'd change this to: `If the database should be kept, ignore "database already exists".`
"or in UTC."
Languages are ordered by `code`, so this should be above `'tr'`.
Please keep this list in alphabetical order, i.e. place this after `SECURE_CONTENT_TYPE_NOSNIFF`
I'm wondering if this should be within the `DATABASES` setting
Yeah, screw that :D in the worst case make it an attribute on the CSRF class, so a user can override it if we go down the route with an extra class.
Use `if isinstance(d, list)` to handle subclasses which are likely to be unhashable as well.
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
I would keep the previous name for a class attribute: ``` self.ignorenonexistent = ignorenonexistent ```
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
I think the `= true` is a byproduct of filter requiring a left and right hand side. This can be fixed when that restriction is removed via filter/expressions.
Include a trailing comma so that if more items are added later, so we don't need to modify this line again.
You can use `self.assertRaisesMessage(ValueError, 'error string')` rather than inspecting the exception args.
Perhaps I misunderstood Anssi's original intent somehow, but the fact that your filter expression uses INNER joins seems like you're maintaining the status quo at the minimum. @charettes I've just pinged you on IRC but if you've got some thoughts on this I'd like to hear them.
Is there a reason to use `len()` instead of checking the objects? `len()` may take more effort to debug in the event of a failure.
`assertTrue(value)` will pass for `bool(value) is True` which is different than checking for `True`.
I think at least the latter is worth it - it's confusing to submit two files and be told "the" file is empty.
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
You don't need to mock, it will return `False` for a bad file descriptor.
chop "should" (just state the behavior)
Please wrap at 79 chars.
Please wrap at 79 chars.
Please wrap at 79 chars.
Please wrap at 79 chars.
Please start a docstring from a new line ``` """ alternate... ... """ ```
"foreign key id" may not be the best wording. For example, this also applies to subclasses like OneToOneField.
It looks like should use `f.get_attname()` instead of rebuilding that here.
This can just be `pass` since the functionality doesn't matter.
remove "or None"
I think the error message that @akaariai provided is a bit better: "Autogenerated column name too long for field [field_name]. Maximum length is [xx] for database alias [somealias]."
These check should respect `required_db_features`, so we need to omit checking conditions for `UniqueConstraint`\`s if `connection.features.supports_partial_indexes or 'supports_partial_indexes' in cls._meta.required_db_features`.
This duplicates logic from `_check_local_fields()` and added unnecessary error `models.E042` which is already covered by `models.E012` in `_check_local_fields()`. I think we should pass fields from `references` to the `_check_local_fields()` and remove redundant logic, e.g. ```python for field_name, *lookups in references: fields.add(field_name) if not lookups: # If it has no lookups it cannot result in a JOIN. continue try: field = cls._meta.get_field(field_name) if not field.is_relation or field.many_to_many or field.one_to_many: continue except FieldDoesNotExist: continue # JOIN must happen at the first lookup. first_lookup = lookups[0] if field.get_transform(first_lookup) is None and field.get_lookup(first_lookup) is None: errors.append( checks.Error( "'constraints' refers to '%s' which results a JOIN attempt, " "JOIN is not permitted in 'constraints'." % LOOKUP_SEP.join([field_name] + lookups), obj=cls, id='models.E042', ) ) errors.extend(cls._check_local_fields(fields, 'constraints')) ```
You can use `connection.display_name` to get the database's name.
come on, no need to pick on MySQL... "Check constraints are not supported on your database backend"
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
yeah, i don't think instance patching requires cleanup, that instance goes away at the end of the test
You also needs to "unmock" this method in a try/finally block. Maybe we can first decide on a resolution about using mock (#23289) so we don't have to add more of this cruft though.
`HTTPS` is not necessary, so I removed this line.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
this can be a single line (we prefer longer lines when it improves readability)
This works without the patch and should be moved to a separate commit. I'd also move it to a separate test method: ```python def test_defer_only_clear(self): self.assert_delayed(qs.only('name').defer('name')[0], 0) self.assert_delayed(qs.defer('name').only('name')[0], 0) ```
I _think_ this one will fail on Postgres at least since `->>` returns text natively. ```suggestion char_value=KeyTextTransform(1, KeyTransform("bar", "value")), ```
NVM, I forgot that `KeyTransform` aggregated instances of `KeyTransform` independently of their actual types https://github.com/django/django/blob/aed60aee38215e293d6ec2f3c96ec55bb9a62fc2/django/db/models/fields/json.py#L321-L323
The extra queries could be generated in this line (199), as this is where the instancies are created, so so you should check the number of queries is one.
This won't work on all backends, we need to use `connection.ops.quote_name()` for identifiers.
I suggest renaming the variable to `validators`.
I think a trailing underscore rather than a leading one might be a more common convention in Django for this case.
I suggest you use the `for`/`else` construct here. ``` python for validator in validators: if isinstance(validator, validators.MinValueValidator) and validator.limit_value <= min_value: break else: validators.append(validators.MinValueValidator(min_value)) ```
Ditto about the `for`/`else` construct.
Simply return `validators`.
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
Ahh right, I forgot about it. Thanks!
@pope1ni no, it's heavily cached as it's using `ContentType.objects.get_for_model`.
Current implementation of `get_prefetch_queryset()` assumes that all instances have the same content type (there is an issue), but the fix is not optimal IMO because object IDs can be the same in different content types, e.g. we have two related objects: - object ID 1 with content type ID 1, - object ID 2 with content type ID 2, this query will return also: - object ID 2 with content type ID 1, - object ID 1 with content type ID 2, which is not correct. I know that we are matching them below but still I think we can limit the no. of objects only to actually needed.
Could use `reduce` here. ```python reduce(operator.or_, content_type_queries) ```
We can also import `include()` from `django.urls` instead of `django.conf.urls`.
```suggestion request.FILES # Trigger file parsing. ```
consolidate this a bit: ``` file1.seek(0) response = self.client.post('/unicode_name/', {'file_unicode': file1}) self.assertEqual(response.status_code, 200) ```
+1 to a public method on the handler
Is there a reason to use `isfile()` instead of `exists()`.
`VACUUM INTO` was [added in 3.27.0](https://sqlite.org/releaselog/3_27_0.html). This would bump requirements in `databases.txt` and `check_sqlite_version()` check in `django/db/backends/sqlite3/base.py`
To keep the diff a bit cleaner, I wouldn't make this unrelated whitespace change.
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
I think I would compose the string before the condition ```python exc_msg = 'database %s already exists' % parameters['dbname'] if exc_msg not in str(e): ... ```
I'd chop this blank line since the } on its own line is providing whitespace.
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
They can only be decoded if these bytes were previously encoded in this encoding.
I would have been interested in something closer to werkezeug's. That takes encoding as a parameter, etc. **Edit**: TL;DR skip to https://github.com/django/django/pull/2932/files#r15440287
The latin1 encoding mess is a WSGI thing, Django wasn't always a WSGI framework, and who knows what will be the next best thing in the future. When these things were contained in the WSGIHandler that made sense, but if we extract a reusable function it shouldn't be tied to such specifics.
We cannot make serial pk assumption: ```diff diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py index 8b54611010..ea68a105d6 100644 --- a/tests/model_forms/tests.py +++ b/tests/model_forms/tests.py @@ -1765,10 +1765,12 @@ class ModelMultipleChoiceFieldTests(TestCase): f.clean([c6.id]) def test_model_multiple_choice_field_validate_choices_called_properly(self): + c1 = self.c1 + class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField, TestCase): def validate_choices(self, queryset, field_name, selected_choices): self.assertIsInstance(queryset, models.QuerySet) - self.assertQuerysetEqual(queryset.order_by('id'), [1], lambda a: a.id) + self.assertSequenceEqual(queryset, [c1]) self.assertIsInstance(field_name, str) self.assertEqual(field_name, 'pk') self.assertIsInstance(selected_choices, frozenset) ```
Maybe you can use `subTest` here, e.g.: ```python for model, pk_pos in ( (Book, -1), # Unmanaged origin model. (Author, 0), # Unmanaged related model. ): with self.subTest(model=model, pk_pos=pk_pos): with mock.patch.object(model._meta, 'managed', False): _, _, grouping = queryset.query.get_compiler(using='default').pre_sql_setup() self.assertEqual(len(grouping), len(model._meta.fields) + 1) self.assertIn(Author._meta.pk.name, grouping[pk_pos][0]) for index, field in enumerate(model._meta.fields): self.assertIn(field.name, grouping[index + pk_pos + 1][0]) assert_queryset_results(queryset) ``` but I'm not convinced that it isn't less readable.
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
I'm not sure if there are lookups where it's not the case, but comparisons such as `Choice.objects.filter(votes__gte='2')` seem to work fine with the value as a string so the "transform" stuff seems unnecessary, at this for the first version of this.
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
missing some trailing commas
I think connection is a bad name to use because of database connections `django.db.connection`.
I would deindent these ] and also include a trailing comma in case more items are added later
assertTrue -> assertIn
removing unnecessary multilines like this will make it nicer.
The test data should be defined so it isn't necessary to call `strip()`.
I would move it right before the `with self.assertRaisesMessage(ValidationError, msg):`
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
Okay, I'll drop that point, however, it seems odd to me to reject an empty scheme even if someone specifies `schemes=['']` (which seems unlikely anyway). I don't know that rejecting this case is important.
Is there a need to hardcode pks? This is generally to be avoided, I think.
While longer, this avoids creating the extra list, string building and "complex" range calculations: ```suggestion i = None try: while i := lang_code.rindex('-', 0, i): possible_lang_codes.append(lang_code[:i]) except ValueError: pass ``` I know it also uses the walrus operator, but Django 4.0 is targeting Python 3.8+, so it is available to us. It seems much more readable to me. (If this isn't a performance critical path then `contextlib.suppress()` could be used to shave off two lines.)
Thanks both :+1: I pushed edits.
That docstring doesn't add much info. It isn't useful to paraphrase a function's signature!
unclear if this is `'name' not in lang_info` or `not ('name' in lang_info ...` (I think the first) would be helpful to restructure or adds parens so it's easily readible
This is also wrong, `LANGUAGE_COOKIE_NAME` is the name of the cookie, not the name used in the session.
We'd likely want to accept `renderer=None` here and default to `get_default_renderer()`.
You can use the new `self._bound_items()` here, which is now in `main`.
We can drop the backticks, improve indentation, etc. ```suggestion warnings.warn( 'django.forms.BaseForm._html_output() is deprecated. ' 'Please use .render() and .get_context() instead.', RemovedInDjango50Warning, ) ```
Although this was changed to use `self._bound_items()`, it is still doing `self[name]` and `field` is unused. ```suggestion fields = [] hidden_fields = [] top_errors = self.non_field_errors().copy() for name, bf in self._bound_items(): bf_errors = self.error_class(bf.errors) if bf.is_hidden: if bf_errors: top_errors.extend( [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ) hidden_fields.append(bf) else: fields.append((bf, mark_safe(str(bf_errors)))) return { 'form': self, 'fields': fields, 'hidden_fields': hidden_fields, 'errors': top_errors, } ```
You could skip these, but I thought that the rewording read better. I guess if you go for the proposed `Renderable` then they'd be moved anyway and then it doesn't hurt to update them. (Also note that the docstring for `BaseFormSet.as_ul()` neglected to mention that it isn't wrapped in `<ul>`.) 🤷🏻‍♂️
We can add a control assertion to confirm that a `house` is cached for the `room`: ```suggestion self.assertIs(Room.house.is_cached(self.room), True) with self.assertNumQueries(0): ```
I think verifying the results wouldn't hurt, e.g. `self.assertSequenceEqual(groups2.filter(id__gte=0), [g])`
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
@timgraham already pointed the code formatting of the tests. Please don't make newlines at dots, `tests/annotations/tests.py` has good examples of the style.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
I'm not sure this is needed since class doesn't have a custom `__repr__()`, we're just testing the base class.
The blank lines in this method aren't needed.
If a custom `__eq__()` method isn't necesary, then it seems like these tests aren't needed.
Since you don't actually need the instances of all those models, can you use `WindowTestModel.objects.bulk_create()` please.
We usually avoid hanging indents, and prefer this: ``` WindowTestModel.objects.create( name='Jones', salary=45000, department='Accounting', hiredate=datetime.datetime(2005, 11, 1) ) ```
I'm reluctant to pass a `Template` to the `Engine` because that creates a circular relation between the two classes. If you keep this design, you must at least rename `compile_string`, because it no longer accepts a string in argument. In fact I would add a new method and deprecate `compile_string`.
Did you intentionally keep the unused `TemplateEncodingError` for backwards compatibility? I think it could be removed.
explain why it needs to be copied
This is mainly to avoid edge cases. Here's an example: Imagine a 3rd-party node sets a value with key `include.html` in `context.render_context`. It's not probable, but perfectly possible. Later `IncludeNode` runs and happens to also use `include.html` as a key. It will pull whatever is already in `render_context` from that previous node when it shouldn't. Using a custom key won't eliminate the edge case completely, but it does reduce the probability of edge cases. The `ExtendsNode` uses a key value of `extends_context`. `IncludeNode` could do something similar.
This is better. I didn't think about the problem with variables that can change values. I have one concern, though. The same `render_context` instance is shared across nodes in the `Template.render()` call, so `template_name` isn't a very safe key to use. The potential arises to clash with other nodes. Maybe we could adjust the approach a bit? My thought is to create a cache dict in the `render_context` using `self` as a key. For example: ``` cache = context.render_context.setdefault(self, {}) template = cache.get(template_name) cache[template_name] = template ``` Alternatively, you could use a unique, uncommon key rather than `self`. The benefit here is that multiple `IncludeNode` instances could share the same cache. That means a template like below would only parse `template.html` once: ``` {% include "template.html" %} {% include "template.html" %} {% include "template.html" %} ``` That seems appropriate in this case.
You can remove the `keys()` call as `iter(dict.keys())` yields the same results as `iter(dict)`. That is `update(base.__dict__)`.
Just out of interest, `dict.keys()` is a **set-like** object providing a **view** on a dictionary's keys in Python 3. So the cast to `set` was only needed for Python 2 where `dict.keys()` returns a list. Thus the options here are changing to use `set.update()` and passing the dictionary as-is - as has already been committed, or to just drop the cast to `set` as it already is set-like which might look a bit less magic. No strong opinion on this however.
I guess this needs to be something like `inherited_attributes |= set(base.__dict__.keys())` to work on Python 2.
> I've noticed that these "internal" names leak into migrations. Making this change will cause migrations to be generated when users upgrade. Are you sure? I didn't notice this in a sample project.
> Perhaps when creating migrations we should ensure the value of `related_name` is forced to `'+'` if it ends with `'+'`? We could edit the following in `RelatedField.deconstruct()` to undo the changes made in `ManyToManyField.contribute_to_class()`: https://github.com/django/django/blob/74fd233b1433da8c68de636172ee1c9c6d1c08c9/django/db/models/fields/related.py#L324-L325 Or handle it specially in `ManyToManyField.deconstruct()`.
I guess `mark_safe()` is needed because the empty string is considered "unsafe"? In that case, it might be easier to understand the intention with: `mark_safe('').join(...)`
Ideally, `stream()` wouldn't have this deprecation code.
I would organize these methods else (inside of in the middle of the views) and prefix them with an underscore to indicate that they're helpers, not public APIs.
chop blank line
As `BaseFormSet` is inheriting from `Renderable` we can ditch this as the definition is the same: ```suggestion ``` You can also remove `.as_table()`, `.as_p()`, and `.as_ul()`.
`DatabaseFailureError` is not declared, it should be a subclass of `AssertionError`.
perhaps more generally, "Database queries aren't allowed in SimpleTestCase." (since queries can be executed in ways other than just the oRM)
We might want to avoid doing this if `self.localize is True` since `DECIMAL_SEPARATOR` and `THOUSAND_SEPARATOR` should be taken into account in this case.
Any idea what the "cost" of this is? ie: because all template output runs through `render_value_in_context` -> `localize` which then dispatches to any of `number_format` / `date_format` / `time_format` each of which _may_ call `settings.USE_L10N` depending on if the `context.use_l10n` value (and I confess I can't remember when/where the details of _that_), each of those values (decimals/ints/floats/datetime.*) is unavoidably going to be slower (if/when `use_l10n` is `None`), and I wonder by how much? And is it avoidable? (eg: `cached_property` or what-have-you)
This must also take the sign into account. What about: ``` python max_length = self.max_digits + 1 # for the sign if self.decimal_places is None or self.decimal_places > 0: max_length += 1 # for the dot ``` We could also make the sign check conditional based on `min_value` and `max_value` but it would be a mess.
You'll want to branch off `< 3.6`.
Might make sense to check explicitly set name too, because '__name' obviously will not work.
``` class A: __print = cached_property(print, '__print') ``` This will not work and we can easily detect it too.
I also still don't understand why it's useful to allow writing code that doesn't work.
I think silently failing to cache the property should be considered not working.
``` python # the following time is equivalent to UTC 2014-03-13 05:34:23.24000 ```
``` python # but in UTC, the __date only matches one of them ```
Use single quotes consistently.
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
I'd be to test `is_dst=True` as well!
I added warning to docs.
Good idea, I will implement it :+1:
We try to avoid altering expressions during the compilation phase as it can lead to hard to diagnose issues what about ```suggestion self.collation = collation def as_sql(self, compiler, connection, **extra_context): extra_context.setdefault('collation', connection.ops.quote_name(self.collation) ```
line saver? ``` format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' extra_context['format_string'] = format_string ```
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
Any reason not to do the following? ```python return ( clean_lookup in valid_lookups or LOOKUP_SEP.join(relation_parts + [part]) in valid_lookups ) ``` A better approach would be to make `valid_lookups` a `set()` in the first place (using `add` instead of `append` above) and do: ```python clean_lookups = {LOOKUP_SEP.join(relation_parts), LOOKUP_SEP.join(relation_parts + [part])} return clean_lookups & valid_lookups ```
Make this and new_lookups sets.
No need to change this now... but would base_path = 'foo__bar', prefetch_through = '__baz' and prefetch_to_attr = '__baz_list' clarify things here? You could then append base_path and either prefetch_through or prefetch_to_attr together as needed.
I think what Anssi is asking you to do is prove that the following produces LEFT OUTER joins rather than INNER JOINs. ``` class Timestamp(models.Model): at_time = models.DateTimeField() class Event(models.Model): start = models.ForeignKey(Timestamp, null=True) end = models.ForeignKey(Timestamp, null=True) actual = models.DateTimeField() start_datetime = datetime.datetime(2016, 6, 2) end_datetime = datetime.datetime(2016, 6, 4) actual = datetime.datetime(2016, 6, 3) t1 = Timestamp.objects.create(at_time=start_datetime) t2 = Timestamp.objects.create(at_time=end_datetime) Event.objects.create(start=t1, end=t2, actual=actual) Event.objects.create(start=t1, end=None, actual=actual) Event.objects.create(start=None, end=t2, actual=actual) Event.objects.create(start=None, end=None, actual=actual) # this should produce LEFT OUTER JOINS, not INNER JOIN Event.objects.filter(actual__range=[F('start__at_time'), F('end__at_time')]) ``` I'm not sure what those results will be, but the joins should be LEFT OUTER.
I believe this to be broken. It shouldn't be possible for one of the rhs values to produce a new lookup which others didn't produce.
The layout should be something along those lines ``` python for enclosure in item.get("enclosures") or []: handler.addQuickElement("link", "", { "rel": "enclosure", "href": enclosure.url, "length": enclosure.length, "type": enclosure.mime_type }) ```
add trailing ,
chop blank line
Seems these classes need something like `feed_type = feedgenerator.Atom1Feed` if you want them to be atom feeds.
please use `assertRaisesMessage` to verify it's the `ValueError` we expect (also makes the test easier to read and debug).
`CURRENT_DIR` is already a `Path` object, so we could join this with the `/` operator. ```suggestion html_template_path = CURRENT_DIR / 'templates' / 'technical_500.html' ```
I moved this to the `test()` method to avoid code duplication.
This is minor, but I'm curious -- any reason to use `[::-1]` over `reversed(settings.MIDDLEWARE)`? I think the latter is clearer, and if micro-optimization is a concern (shouldn't be here), I think it is better, as it just creates an iterator over the original list.
Given the concerns raised on the ML I've removed the option of returning `None` from the latest draft of the spec.
I wonder if it would be better to include `.send()` in the new method and call it `send_mail()`. That gives some additional flexibility if the user doesn't want to actually send an email for some reason.
Please move [standard library imports](http://www.python.org/dev/peps/pep-0008/#imports) with the [other ones](https://github.com/ezequielsz/django/blob/90a9140051aeeb84ab9d46c6209f42c5c3820908/tests/regressiontests/mail/tests.py#L4-L11).
```suggestion try: from aiosmtpd.controller import Controller except ImportError: HAS_AIOSMTPD = False else: HAS_AIOSMTPD = True ```
I don't think this needs to live here - it could just live under the definition of `GeometryField` - the `ready` method would be perfect if we were adding this to something which lives outside of `contrib.gis`.
Use `gettext` instead of `ugettext`
It used to be that way (in Python 2 era). Now gettext is an alias to ugettext and the latter will be deprecated in the future.
The last parenthesis should be moved to the next line due to hanging indentation.
The last parenthesis should be moved to the next line due to hanging indentation.
I don't think we need to check all rows, probably sth like this: ```python self.assertEqual(list(qs.values_list('lead_default', flat=True).distinct()), [60000]) ``` will be sufficient. We have a similar situation in the `test_nth_returns_null`.
It's weird, because Oracle interprets empty strings as nulls.
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
`not statement` is used several times above, so need to be consistent in code style.
@MarkusH - that looks good to me.
@akulakov `passed_check` is to check if list is not empty. if it is not empty, method will return no error, otherwise error will be returned (`[] if passed_check else [W020]`).
@coldmind With the current code, `passed_check` will be `True` if `settings.ALLOWED_HOSTS` IS empty. That is backwards. `passed_check` should be `True` if `settings.ALLOWED_HOSTS` is NOT empty.
`str` -> `six.string_types` for compatibility with Python 2.
Sounds good. Feel free to submit that as a separate pull request. We can probably merge that first and then rebase this.
Okay, feel free to update this PR or send a new one.
If there is no danger of a circular import error, I'd move this to the top of the file.
Or in some cases (e.g. CSRF) it's because we want to log the response under a particular non-default logger. But even in those cases, we never want to double-log a response.
I'm omit the intermediate extra variable in favor of: ``` getattr(logger, level)( message, *args, extra={...}, exc_info=exc_info, ) ```
Add a trailing comma so if more items are added later we don't have to modify this line again.
prefer hanging indent: ``` self.assertEqual( len(calls), 1, "..." ) ```
You don't need to wrap a connection, you should be able to use `CaptureQueriesContext()` with `commit()` and `rollback()` and test captured queries.
Do we need these changes? :thinking: `Path.absolute()` raises `FileNotFoundError`, so why not catch it in `watch_for_translation_changes()`, e.g. ```python for path in directories: try: absolute_path = path.absolute() sender.watch_dir(absolute_path, '**/*.mo') except FileNotFoundError: logger.debug('Skipping watching file %s as it cannot be resolved.', path, exc_info=True) ```
Great, thanks! I will merge #11590 and rebase this PR :+1:
I'd omit the blank line since the ) on its own line provides space.
The current idiom might be required because some backends (perhaps third-party ones) choke on empty `params`. I'd keep it.
Rather than implementing a special CursorWrapper for Oracle to do this, it is better to include the change in the general CursorWrapper. This has two immediate advantages over doing it in the Oracle backend: 1) The new feature can be shared with any other backend which supports it (3rd party backends included) 2) The new feature is automatically included in CursorDebugWrapper (which your version of make_cursor disables) The disadvantage -- exposing the interface to backends which do not support it -- is a small price to pay in comparison.
the `reversed` call isn't free, it's slightly more optimal to put the wrappers in the list in the way you want to iterate them
btw `reversed(x)` doesn't actually iterate the whole list in reverse in python 3, you just get a `list_reverseiterator`... ``` In [1]: reversed([1]) Out[1]: <list_reverseiterator at 0x105098b70> ``` :)
Move the exists assertions to another test.
please use single quotes for consistency
Following the existing docstring pattern of wording like "Hook for..." seems useful.
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
Where is it taken care of that a `Ref` will already exist in the inner query? Might be nice to have that information here.
I would remove this sentence and let the person who changes this code in the future decide of the way to implement it.
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
It's not actually a comprehension - this could just use a tuple literal.
"Considre case" > "Consider the case".
The rest of Django's test use `@mock.patch` so I think we should use that.
Same here, not following order `(value, expected)`
Same here, not following order `(value, expected)`
Perhaps this could mock `random.choice('?.')` to test both scenarios.
Docstring shouldn't have a trailing space. Docstring sentences should end with a period.
In cases like this, we prefer to include a trailing comma so if more items are later added, we don't need to modify this line again.
Use `setUpTestData` now that two models will be used by two methods.
Need to test that result is as expected, not only calling it.
IMO, these tests would be less verbose with assertRaises. what do you think? edit: actually I'd use six.assertRaisesRegex to verify the message 'Good' (maybe change it to something better) so you're sure you didn't trigger an AttributeError some other way in the test.
checking the results of the query would be useful. ``` self.assertEqual( Pet.objects.prefetch_related('fleas_hosted').values_list('id', flat=True), [...], ) ```
The reason for this is that your for loop is running on both dbs, at first `allow_migrate()` returns `True` for the first db (`default`) thus setting `connection`, `allowed_len`, `db_alias` accordingly, but you are not terminating the loop, making it try `other` db with `allow_migrate()`, returning `True` and setting the variables again.
Same note goes here.
The blank space for the string usually goes at the end of the line instead of the start of the next line.
think we should say 'for database "%s".'
use `and` and parenthesis rather than nesting if statements
@MarkusH Cleaning up all the tests like this makes sense of course, but since this particular test is not yet committed and the change is rather trivial - it can be done before commit as well (and serve as an example of a good test later). Besides, cleanup may happen but it might not as well for a plenty of reasons (no resources, unexpected difficulties, etc), so imo it's better to do this now with this particular test. Why should one commit something that already needs cleanup? Hope this makes sense.
I don't think try/except/fail is a good pattern. See 071801ccff970682a799ce754431a3c3ce3d6902 for the reasoning.
Ah I think you could use `assertTrue` without issues as both `1` and `True` are truthy. ```suggestion self.assertTrue(field.null_ok) ```
missing trailing comma
Chop the ticket number `(#25253)`.
Not sure these asserts bring value ... they seem to test that `override_settings` works.
or just `# CSS files shouldn't be touched...`
This is the failing assertion on Windows. I think it might have to do with the file being written with Windows vs. Unix line endings. If you remove the assertion, the rest of the test passes.
This can probably also be cleaned in existing cases but `BaseCollectionTestCase` inherits `BaseStaticFilesTestCase` so it looks like it's redundant here.
single line would be fine here
Return (chop 's')
I don't know if this is a "must", it might not be the case that all cache backends out there can sensibly support it
Remove the blank line here.
Remove blank line (and below).
Use a single line (we allow up to 119 chars when it helps readability) or we use hanging indent.
You may change the others if you like, but please make it a separate commit.
I don't think such a regression is likely and we don't have similar checking elsewhere so I think it's fine to remove. Yes, please squash commits.
is this to ensure that `bulk_create()` didn't create any objections even though it raised an error? I don't think that's really needed. Otherwise, this patch looks good.
Can we use custom `date_friended`? and check is it set properly on an intermediary object.
I have some nitpicks to these tests but I can push them later after the final review.
Trailing zeros are unnecessary. Also, it'd be more readable to keep MySQL and MariaDB in separate branches, e.g.: ```python if self.connection.mysql_is_mariadb: return self.connection.mysql_version >= (10, 8) return self.connection.mysql_version >= (8, 0, 1) ```
Nit-pick: I think Django generally favors the syntax with parens instead of the `\` continuation char.
For MySQL >= 8.0.13, `default` was not fully supported as other backends, for example: Alter a field with default value: ✅ `ALTER TABLE foo MODIFY COLUMN bar LONGTEXT DEFAULT("");` ❌ `ALTER TABLE foo ALTER COLUMN bar SET DEFAULT ('');` So unless we could tell what kind of action of this SQL is taken, otherwise we should always return `False` for safe.
This test fails: `(1235, "This version of MySQL doesn't yet support 'FORMAT=JSON with EXPLAIN ANALYZE'")`.
This hook is unnecessary you can reuse `has_native_uuid_field`, e.g. ```python class DatabaseFeatures(BaseDatabaseFeatures): ... @cached_property def has_native_uuid_field(self): return self.connection.mysql_is_mariadb and self.connection.mysql_version >= (10, 7) ``` ```python class DatabaseWrapper(BaseDatabaseWrapper): ... @cached_property def data_types(self): return { ..., "UUIDField": "uuid" if self.features.has_native_uuid_field else "char(32)", } ```
I wonder, maybe in future we should introduce a `django.conf` setting for this regexp
This will completely obscure `HTTP_COOKIE` but I don't think it's a big deal since individual items are still retrievable from `request_COOKIES_items`.
Do we need to be so restrictive? There are many language tags in the [IANA](http://www.iana.org/assignments/language-subtag-registry/language-subtag-registry) registry that don't match this regex, e.g. `i-mingo`, `de-CH-1996`, `de-1996`, or `kl-tunumiit`.
Indeed, we do not need to be so specific. The downside I see when being permissive is a bit more computation by going more often in `get_supported_language_variant` and possible `get_supported_language_variant` lru cache exhaustion. But I don't see a nice alternative.
TIL that character classes also work inside `[]` :D
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
We prefer hanging indent style like this: ``` self.assertEqual( res.context_data["form"].errors["__all__"], ['You must confirm the delete.']) ) ``` Also please drop the u prefix on strings.
this can be a single line (we prefer longer lines when it improves readability)
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
I don't like the idea of reading from stdin; that's unlike how any other management command works. Let's take this part out, I think it's YAGNI.
_"f-strings should use only plain variable and property access"_ This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
IMHO specifically this change worsen readability. Something like this might look better: ``` if app_labels: if len(app_labels) == 1: ... else: ... else: ... ```
I would not recommend any alternatives: ```suggestion f"Cannot update applied migration {migration}." ```
can you call `sort` on the invalid_apps before joining them, please.
longer lines here are okay, we try to avoid non-multiple of 4 indents
I think a list comprehension would be more readable.
This is inconsistent but I think the patch can land as is and the test be modified later on based on the direction of [#24082](https://code.djangoproject.com/ticket/24082).
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
I think we'd want more details about why this hack is needed.
These notes are unnecessary.
```suggestion class TaggedItemWithUUID(models.Model): ```
I would omit the parenthesis in these messages (I know it's done elsewhere, but "I am at war" with that style unless you like it).
```suggestion class Integration(models.Model): ```
This seems unnecessary.
You can use `@modify_settings`, e.g. ```suggestion @modify_settings(MIDDLEWARE={ 'prepend': 'test_client.tests.urlconf_override_middleware', }) def test_resolver_match_when_urlconf_modified_by_middleware(self): response = self.client.get('/') ```
I would assert against `url_name`, e.g. ```suggestion self.assertEqual(response.resolver_match.url_name, 'overridden_urlconf_view') ```
Is this possible? If so, it will be good to cover this scenario with tests.
by convention - 'handle_' as a prefix is used for methods that actually handle an exception condition. This is more of a utility around sending the signal, so while I don't want to bikeshed the naming of it, I'll just say that starting with handle_ is probably not a good choice.
This is minor, but I'm curious -- any reason to use `[::-1]` over `reversed(settings.MIDDLEWARE)`? I think the latter is clearer, and if micro-optimization is a concern (shouldn't be here), I think it is better, as it just creates an iterator over the original list.
Missing `cls.cls_atomics` argument.
Can we move this conditional out of the loop? (I see it was copied from `_fixture_setup`.
We don't need these two lines, or the starting `try:` line.
I don't understand why we have methods with a double underscores prefix which are copies from `SessionBase`, e.g. `__hash()`, `__legacy_encode()`, `__legacy_decode()` :thinking:
Rather than have the `_test_marker` as an instance variable that ripples through all the methods, we could have it as a class-level variable that defaults to `False` and override it here on the instance. Also I think a better name would be `_from_testcase` or similar - the word "marker" doesn't really convey much meaning. ```suggestion atomic = transaction.atomic(using=db_name) atomic._from_testcase = True atomics[db_name] = atomic ```
Can you include latin-1, non-ASCII characters? `café` is one of the few English words matching this requirement. `Just latin-1 :)` will encode identically in ASCII, latin-1 and utf-8, making the tests much less interesting.
This isn't Django's default charset (unless I'm mistaken).
This is the default charset in Django, I wouldn't call it unusual :)
I would assert against `url_name`, e.g. ```suggestion self.assertEqual(response.resolver_match.url_name, 'overridden_urlconf_view') ```
One empty line above, please.
Silenced the output. The `create_default_site` method deserves a more basic test, but there's more to it than the output, could be another ticket I guess (this one is pretty convolved as is). Here's a [sketch of a test](https://github.com/wrwrwr/django/commit/8927a52a4271ab8208783ce4c2af31814314a6c8).
These checks aren't quite independent. When this one is first it fails. But I guess it's OK.
No problem. I think it’s OK as is. (Adjusting it would be done separately anyway)
I'd be great to assert the permission and content types were appropriately created as well!
it's a separate item, but I wonder if we could patch override_settings to handle DATABASE_ROUTERS like is done below
```suggestion if not isinstance(perm_list, (list, tuple)): ValueError('perm_list must be a list or tuple.') ```
my preferred style is: "#17903 -- Inactive users shouldn't have permissions..."
I believe save() isn't required after adding permissions (M2M change)
as noted in other PR, think we can omit a newline before a single assert
I don't think it's terribly important as both checks use the same code path (although this could obviously be refactored later at which point that argument would fail...).
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
Chop the ticket number `(#25253)`.
Chop the ticket number `(#25253)`.
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
Use single quotes consistently (could be done above and below also).
No need for `keys()` here.
You can remove the whole `else:` branch as `None` will be returned by the function implicitly.
This would probably be better in the docstring. Maybe you want to say something about ducktyping instead of just "let's hope it has .get()" (guess you might want to add "filter()" too)
Only `OneToOneField` can be `parent_link` so this can be reduced to the following at least. ```python parents = set(self.query.get_meta().get_parent_list()) return [ c[0] for c in self.select if c[0].target.related_model in parents and c[0].target.remote_field.parent_link ] ```
I think there's a constant for `'self'` as well somewhere in `django.db`.
remove "should", e.g. "debug() bubbles up exceptions before cleanup."
Remove extra spaces around docstring.
Any disadvantage to making it a separate test method instead? I guess the signal connecting might be better is `setUpClass` at that point.
avoid _we_ usage as well ``` SystemCheckError is surfaced when run_checks raises SystemCheckError and teardown databases raises ValueError
I would also consider turning that into an instance method called something like `get_runner()` and starting each test method with `runner = self.get_runner()`. The reason is that instantiating a runner is "cheap." You also don't have to think / worry about whether the runner has state that you might unwittingly be carrying from one test to the other (e.g. attributes set when a method is executed).
Please use 4 space hanging indent style as seen elsewhere in this file such as `cls.superuser = ...`
We should have both versions covered by tests, so I moved test methods with `opclasses` to the new class `ExclusionConstraintOpclassesDepracationTests`.
TBH, I don't think we need this test. I will chop it.
Use `assertEqual()`, e.g. ```python self.assertEqual( conf_url(r'^regex/(?P<pk>[0-9]+)/$', empty_view, name='regex'), re_path(r'^regex/(?P<pk>[0-9]+)/$', empty_view, name='regex'), ) ```
`# Prevent the RuntimeWarning subclass from appearing as an exception due to the warnings.simplefilter() in runtests.py.`
`# Check that ...`
You can define an `as_sqlite` method for this case.
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Similarly, I don't see much advantage to creating indirection with a method.
Need to test how many times `update_contenttypes` was called and test arguments which passed to it.
assertEqual -- the version with "s" is a deprecated alias.
I'd be great to assert the permission and content types were appropriately created as well!
I'd chop every other empty line and group the `auto_now` and `auto_now_add`, but that's just cosmetics.
couldn't -> can't
True, but they test the behavior of the respective operations. It's true that `test_state.py` has a few tests that check for the correct `state_forwards()` behavior, though those tests are focused on the bigger picture of how `ProjectState` and `ModelState` work. Whereas `test_operations.py` tests for the particular implementations of the different migration operations, and as such should hold (regression) tests that focus on a particular implementation of such an migration operation. Thus, `test_operations.py` sounds like the right choice to me.
I think so -- all code changes should be tested unless it's infeasible to do so.
Yeah, looking at those test modules, I think they deserve some cleanup.
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
We can drop meta ordering and add it to the queryset: ``` self.assert_pickles(c.concrete_events.order_by('event)) ```
We can chop `FK`.
Pass models.CASCADE as a positional argument for consistency with the rest of the test models.
It'd be great we if we could avoid creating 5 new tables to reproduce the issue. Existing ones should be reusable somehow.
Do we expect users to use strings like `&&` and `&` directly anywhere else? It seems like we're exposing an implementation detail we'd usually hide.
You can remove parentheses.
```suggestion sql_params = (*lhs_params, *rhs_params) ```
I guess we could remove the mention of Oracle and just say "for databases which limit..."
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Looking at this, this one picks first source as self.source. Above self.col is picked from last target. Should we just throw an error for multicolumn expressions? I bet they don't work currently in any sane way, so lets not pretend they work.
Please test for all of the extra registered range types - you should be able to make use of `self.subTest()`.
You might want to write some tests to prove that the new query search subclasses combine correctly with SearchQuery.
I'm not sure this should be committed.
Usually we camel case assertions to match the unittest style. Maybe assertFieldsInModel (considering field_outputs is a list).
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
And this can be reverted.
```python kwargs['max_value'] = min(value, kwargs.get('max_value', value)) ```
I suggest you use the `for`/`else` construct here. ``` python for validator in validators: if isinstance(validator, validators.MinValueValidator) and validator.limit_value <= min_value: break else: validators.append(validators.MinValueValidator(min_value)) ```
Ditto about the `for`/`else` construct.
Simply return `validators`.
Makes sense, let's stick with `raise e`.
Thanks for investigating, so simply raising `exc_info[1]` seems the way to go, unless some test can demonstrate the opposite.
This makes makes it not obvious at all that the contents of the `try/except IntegrityError` are properly wrapped in a transaction. This is necessary to prevent errors on databases which actually enforce transactional integrity on errors like PostgreSQL.
This is not used only by `get_or_create`.
create -> creates
Use `self.assertIs(cache.touch('something'), True)` since `assertTrue()` passes if `bool(value) is True`.
I'm not convinced this deserves a separate test. Consolidating the `test_forever_timeout` test might be enough.
I see your point and can't think of anything sensible either. Assertion-less tests just seem pointless other than to put a tick in the coverage box.
please insert tests on line 1029, after the `setUp`/`tearDown` helpers `create_table` and `drop_table`
I don't think that `BaseSerializer` is necessary. I only want to avoid defining the same class in different places so moving `PickleSerializer` (as described in https://github.com/django/django/pull/14437#discussion_r696343672) is enough.
spelling / typo: parentheses
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
I _think_ that `Ref` will also need to return True, since it is a named reference to an existing `Col`.
F() expressions aren't the only ones that can refer to other columns in the query. How about Q(other_field__isnull=True). Also, expressions are free to resolve columns of the query without using F-expressions. We need some other way to know if the expression refers to columns of the query. Maybe we could first resolve the expression, the check for Col references? That might be better. The check should be done in the expression, so that the expression tells Django if it is referring to any columns. Making the compiler guess this is the wrong way in my opinion.
I would move it to `_init__()`: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ... self.index_type = index_type or `GIST` self.condition = condition super().__init__(name=name) ``` and skip the default in `deconstruct()` and `__str__()`: ```python def deconstruct(self): ... if self.index_type != 'GIST': kwargs['index_type'] = self.index_type ```
comma after tuple
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Oh, I just meant to suggest the `value` to `values` (plural) renaming, not more...
It may not be possible without a database roundtrip. I'm just asking.
The main question is what to do with these tests? We should analyze them one by one and prepare alternative versions only with `unique_together` (if necessary). I'm afraid that we cannot simply remove them when deprecation ends because we will end with many not covered scenarios. For example: ```python diff --git a/tests/migrations/test_autodetector.py b/tests/migrations/test_autodetector.py index 547e0b32c5..4c19a34d7f 100644 --- a/tests/migrations/test_autodetector.py +++ b/tests/migrations/test_autodetector.py @@ -2441,10 +2441,10 @@ class AutodetectorTests(TestCase): self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterField"]) + # RemovedInDjango51Warning: When deprecation ends rename to + # test_empty_unique_together(). + @ignore_warnings(category=RemovedInDjango51Warning) def test_empty_foo_together(self): - """ - #23452 - Empty unique/index_together shouldn't generate a migration. - """ # Explicitly testing for not specified, since this is the case after # a CreateModel operation w/o any definition on the original model model_state_not_specified = ModelState( @@ -2457,7 +2457,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": None, + "index_together": None, # RemovedInDjango51Warning "unique_together": None, }, ) @@ -2468,7 +2468,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": set(), + "index_together": set(), # RemovedInDjango51Warning "unique_together": set(), }, ) ```
We should mark all tests and model states that use `index_together` in `tests/migrations/test_autodetector.py` for removal. We can also move them to a common class for easier remove when deprecation ends.
A note in `docs/internals/deprecation.txt` is missing.
`codename %= ...`
`cls.__name__.lower()` is the same as `self.model_name`. I guess `model_name` would probably be a better placeholder name.
I'd say omitting `__class__.__name__` is more useful as it'll include the `app_label`. I would just omit `'.ModelAdmin'` if the string ends with that, since that's probably `register()` without a `ModelAdmin` subclass. So in case 1, the error would look like: The model %s is already registered with app 'admin_registration'. In case 2: The model %s is already registered with 'admin_registration.PersonAdmin'.
In the case of `admin.site.register(Model)` (without a `ModelAdmin` subclass, this shows something like `polls.ModelAdmin`. which could be confusing.
The wording doesn't seem quite right: "<model> for <registered admin>" seems like it should be "Cannot register <model> because <model> is already registered with <registered admin>."
use the context manager version: `with self.assertRaisesMessage(...):`
I'd use `rstrip('.ModelAdmin')` rather than a regex.
This docstring is unnecessary ```suggestion ```
IMO checking how `empty_form` is rendered is not necessary. It's enough to check `empty_permitted`, e.g. ```suggestion self.assertIs(formset.empty_form.empty_permitted, True) ```
Please use hanging indentation: ```python GenericFormFormset = formset_factory( form=GenericForm, can_delete=True, extra=2, ) ```
```suggestion f'<li>Title: <input type="text" name="form-0-title"></li>' f'<li>Pub date: <input type="text" name="form-0-pub_date">' f'{delete_form}</li>' ```
I renamed the test and removed the docstring.
To prevent unexpected `FieldDoesNotExist` exceptions raised in `if field.attname == field_name:` to be silennced. It's generally good practice to restrict the `try` body to the only parts expected to raise the exception.
ideally this bit would be in the `else:` branch of the try/except.
Indentation can do a lot for legibility here: ``` fields.update( (field, (field.name, field.attname)) for field in self.local_fields if include_non_concrete or field.column is not None ) ```
True about the ML. Regarding the naming for `related_objects/related_m2m` vs `reverse_rel/reverse_m2m`, that's a new API so there isn't historical names to preserve (unlike `many_to_many` vs `m2m`), we just need to pick the best names to represent the relations.
if include_parents is False, this line generates a result that isn't used. Move it inside the if for a minor performance boost.
This can be single-lined.
This also can be simplify: ```python call_command( 'createsuperuser', interactive=False, username='test_superuser', email='joe@somewhere.org', stdout=StringIO(), ) user = User.objects.get(username='test_superuser') self.assertEqual(user.email, 'joe@somewhere.org') self.assertFalse(user.has_usable_password()) ```
I don't think that this test is required.
``` # Environment variables are ignored in non-interactive mode, if provided. ```
Chop blank line.
This now raises a warning, so I adjusted to use a view.
Please use a hanging indentation: ``` python self.assertEqual( set(...), {...}, ) ```
Combining this commit with the next one seems fine. It works the same as override_settings, but you can use `with self.settings`.
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
When fixing the implementation of `RedisCacheClient.get()` to support `default`, this should work fine. ```suggestion ```
AdminSelect used to take the related model. It now takes the field.
Would `tag='label'` be simpler? Also perhaps the docstring could be updated with the new param, since it's not always `<label>` now.
I would prefer `tag=None` because we will be able to pass `None` to get the default value.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
It seems this URL doesn't work anymore.
move ) to next line for consistency
since the brackets on their own lines add whitespace, I think you could omit the blank line between queries/assertions in most cases to make this file a bit shorter.
This test should include updating a decimal field that includes decimal points: ``` Value(Decimal("1.1")) ```
I'm not sure why these tests raises a `ProgrammingError` :thinking:
```suggestion with self.assertRaises((OperationalError, ProgrammingError)): ```
I find `assertEqual` preferable since `asserTrue` checks `bool(expr) is True` which could pass for a result we don't want here. Well, I guess what we actually want is `assertIs(expr, True)` as described in the Python docs.
``` py self.assertFalse(r.closed) ```
I think you can safely remove this.
Also please keep it as HttpResponseNotFound as bug only occurs when that view throws 404.
use snake case, please: `test_login_required()`
```suggestion msg = f"Cannot use 'default_bounds' with {field_class_name}." with self.assertRaisesMessage(TypeError, msg): ```
`CANONICAL_RANGE_BOUNDS` is unnecessary: ```suggestion def __init__(self, *args, default_bounds='[)', **kwargs): ```
`related_manager_name` not `related_model_name`
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
`items = value.split(self.delimiter) if value else []` is slightly faster.
😮 I see that we have a similar condition here `django.db.models.expressions.Exists.as_sql`: ``` features = compiler.connection.features if not features.supports_boolean_expr_in_select_clause: return "1=1", () return compiler.compile(Value(True)) ``` Would it make sense to somehow move them to the same piece of logic? We could either have `compile(Value(True))` determine if it should generate a `1=1`, but it have other side-effects I think 😕
That's what I thought. Thanks for the clarification 👍 The patch is fine to me 🚀
Please check test coverage carefully. I didn't spot a test for this change.
Shouldn't be part of this PR, but it looks like redundancy in `__repr__()` methods would be a good candidate for a refactor.
I think that you can add `filter` to `kwargs` in `__init__` method and remove redundant `__repr__` (see #8759).
Reading below, I see that Flask has an "any" converter that does something more complicated. Creating a converter with the same name but a different behavior doesn't sound good.
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
(same pattern as above, if you change it)
Use single quotes consistently.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Only this parameter is unnecessary, rest of them is necessary to hide std outputs.
`'bar'` is already in `out` from the first execution of `call_command()`. You should reinstantiate or use `out.truncate(0)` before the second call.
This can be single-lined.
I'd combine w/previous line for better readability
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
Please use the same order as in `--help` output, i.e. `--version`, `--verbosity`, `--settings`, `--pythonpath`, `--traceback`, `--no-color`, and `--force-color`.
I would move it to the `ManageRunserver` class.
Please wrap at 79 chars.
Wrap at 79 chars.
It's not obvious to me that the template approach is the best solution for readability as opposed to just creating another test settings file.
can import go at top of file? also, `test_utils` seems like an odd place for these tests. Generally that module is for testing `django.utils`.
re: location of tests -- oops, I confused `test_utils` with `utils_tests`.
You can use `@modify_settings`, e.g. ```suggestion @modify_settings(MIDDLEWARE={ 'prepend': 'test_client.tests.urlconf_override_middleware', }) def test_resolver_match_when_urlconf_modified_by_middleware(self): response = self.client.get('/') ```
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
Use `self.assertIs` and `self.assertIsNot` as these boolean expressions are noop.
Surely you want all of the password hashes in the list of available ones so that people can log in with them? Of course argon2 is unlikely to be out there in the wild, but if someone tried it and then decided to switch back they wouldn't be able to do so by deleting the settings, they'd have to copy/paste the default and re-add it. There's little harm in including it by default afaik. You might not want to have something other than PBKDF2 to be the default though, people might accidently have bcrypt or argon2 installed and not realize it and end up unable to log in if they deploy. Not sure if that's a big worry or not though.
Our code currently requires the first hasher to be usable, putting it as first and not installing the extension will break (look at `get_hasher('default')`)
I think the best argument is "There's little harm in including it by default afaik.". If someone tried using argon2 they can as well adjust their settings, after all they are testing against an unreleased version.
From a security stand point, argon2 is better than PBKDF2 because it's memory hard as well as CPU hard. Security wise argon2 > scrypt > PBKDF2 ~= bcrypt.
Presumably at some point this change will be released.
`value` or `return_value`? or maybe we should swap these lines: ```python if ( not timezone._is_pytz_zone(current_timezone) and timezone._datetime_ambiguous_or_imaginary(value, current_timezone) ): raise ValueError('Ambiguous or non-existent time.') return timezone.make_aware(value, current_timezone) ``` :thinking:
I wouldn't have reflowed this line since you didn't make any other changes and it would simplify the diff.
I don't understand why this is here? Also why not `value.total_seconds()`? Or am I missing something? ```python >>> from datetime import timedelta >>> delta = timedelta(microseconds=90000000123) >>> delta datetime.timedelta(days=1, seconds=3600, microseconds=123) >>> delta.microseconds 123 >>> delta.total_seconds() 90000.000123 ```
I'd use `assertRaisesMessage()` with `msg = 'backend does not support timezone-aware datetimes when USE_TZ is False.'`. There's a small chance that messages from third-party backends might not match the `connection.vendor` convention and I don't think it's a critical part of the assertion.
Not sure if changes to these check methods are required -- was there a discussion somewhere about it? At least tests are missing for these changes.
You don't need the trailing \ here. EDIT: I see you just moved that code, that's fine.
``` is_multipart = context['adminform'].form.is_multipart() or any( admin_formset.formset.form().is_multipart() for admin_formset in context['inline_admin_formsets'] ) ```
This one as well
Move `has_view_permission` above `has_add_permission` for consistency.
If you want to use a new name, that's okay with me, but I think `'has_file_field'` should remain for backwards compatibility.
It's fine to manually substituting parameters here.
Remove the blank line.
It is more usual to use `i` or `idx` than `inx`. With `i` this may fit nicely in one line. Some sort of string formatting is preferable too.
I'm not sure there is any benefit assigning this local variable here when it is only used once.
It's safe IMO.
Can't this case be handled by calling related model's meta.get_field(link_field_name)? If that is the case, then the `for field in self.through._meta.fields` loop would be much simplified.
I'm usually fairly conscious of higher level abstractions accessing very detailed properties or methods from lower down the stack. I would prefer a method within the `sql/query.py` Query object so that other implementations that may or may not yet exist have access to override this behaviour. I'd consider pushing everything from retrieving the inner query into a method and returning on that. ``` return obj.query.as_subquery_filter(obj) ``` Method name and args probably need work but that's the kind of thing I'm considering.
The style I prefer is ``` options = { 'include_parents': include_parents, .... } ``` It's somewhat of a pain to indent additional items if your editor doesn't do it automatically with the other style.
Just because you _can_ cram this all on one line, doesn't mean you have to. This would be a lot easier to read as: ``` field_list = tree[self] if self.proxy: field_list += tree[self.concrete_model._meta] for f in field_list: ... ```
Wording of this error is awkward. I'd suggest: "(old api) is an unofficial API that has been deprecated. Usage of (old API) may be able to be replaced with a call to (new API)"
I wonder if it would be simpler and more efficient to filter out all empty querysets. from self and other_qs, then use `qs[0].self._combinator_query('union', qs[1:], all=all)`, accounting for the case where qs might have zero or one elements.
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
We can fix this condition without nested parentheses, i.e. ```python if not compiler.query.values_select and not compiler.query.annotations and self.query.values_select: ```
Ahh nvm, the function accepts an iterable and not `*args` 🤦‍♂️
I'd omit the blank lines.
No need to multiline statements like this which will fit on a single line.
This should _never_ be the case. `ModelState` should have a default `indexes = []`
Does the ordering of indexes on a database matter? I'm not talking about the order of fields an index applies to, but the indexes itself.
Although using only the name might cause usability issues in the case of an auto-generated name. The user will have to inspect the database or something in order to determine the index name if they're writing the migration by hand.
Why does `DropIndex` take name, but `CreateIndex` takes an `Index`? That seems a little counterintuitive.
isort rewrites this to `convert_exception_to_response, get_exception_response,`
I thought about this. It's a much bigger change, just for a deprecation. Inserting a deprecation is one thing. Adjusting method calls is something else: `MiddlewareMixin.__init__()` calls `super()` so there's a potential logic change. Don't know where exactly, but I didn't want to risk a regression just to save the extra lines here implementing this deprecation.
please alphabetize with the rest of the django imports
Do we need this mapping? We could redirect to a `HttpResponse` with the `status_code`, e.g. `HttpResponse(status_code=r.redirect_type)`.
Can you sort those attributes please
This can be moved outside of `try...except...`.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Do we need an inner import? `from . import urls` should work fine.
Use single quotes.
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
I wonder if this might be bit more readable: `model = type('A' * 101, (models.Model,), {'__module__': self.__module__})`
``` 'BinaryField default cannot be a string, use bytes content ' 'instead.' ```
Might be worth testing for the actual type.
the quotes around verylong... aren't present in the error message so the test isn't passing
`long_field_name` replaces the existing fields
chop blank line
What about keeping the old logic and just changing the message to `raise CommandError("Couldn't import the %s interface." % shell)`. The error should only be trigger when specifying a specific shell anyway.
``` Superuser creation skipped due to not running in a TTY. You can run `manage.py createsuperuser` in your project to create one manually. ```
I'm in favor of re-raising `subprocess.CalledProcessError` as a `CommandError`, e.g. ```python def handle(self, **options): connection = connections[options['database']] try: connection.client.runshell(options['parameters']) except OSError: # Note that we're assuming OSError means that the client program # isn't installed. There's a possibility OSError would be raised # for some other reason, in which case this error message would be # inaccurate. Still, this message catches the common case. raise CommandError( 'You appear not to have the %r program installed or on your path.' % connection.client.executable_name ) except subprocess.CalledProcessError as e: raise CommandError( '"%s" returned non-zero exit status %s.' % ( ' '.join(e.cmd), e.returncode), ) ``` which will end with: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: "psql -U djangoticket -h localhost -p 5432 djangoticket --asdasdad" returned non-zero exit status 1. ```
I wonder if we should suppress `subprocess.CalledProcessError` when arguments are not correct, to get e.g. ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. ``` instead of ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. Traceback (most recent call last): File "manage.py", line 22, in <module> main() File "manage.py", line 18, in main execute_from_command_line(sys.argv) File "django/django/core/management/__init__.py", line 401, in execute_from_command_line utility.execute() File "django/core/management/__init__.py", line 395, in execute self.fetch_command(subcommand).run_from_argv(self.argv) File "django/django/core/management/base.py", line 328, in run_from_argv self.execute(*args, **cmd_options) File "django/django/core/management/base.py", line 369, in execute output = self.handle(*args, **options) File "django/django/core/management/commands/dbshell.py", line 25, in handle connection.client.runshell(options['parameters']) File "django/django/db/backends/postgresql/client.py", line 55, in runshell self.runshell_db(self.connection.get_connection_params(), parameters) File "django/django/db/backends/postgresql/client.py", line 49, in runshell_db subprocess.run(args, check=True, env=subprocess_env) File "/usr/lib/python3.6/subprocess.py", line 438, in run output=stdout, stderr=stderr) subprocess.CalledProcessError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ``` We can also re-raise it as a `CommandError`: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ```
Can you please rename it to `ModelManagerSerializer`. I think you just missed it.
Can you please rename this one to `ModelManagerSerializer` and let it inherit from `DeconstructableSerializer`.
I think you mean `ByteType`
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
This would be better as a set rather than a list.
`clean` is not only for validation, but also for data modification in a form.
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
drop the new line please
The form class is configuration too, is it not? You can group class attributes using a blank line, but this attribute is inherited from `BaseModelAdmin` where it is not separated. It just seemed odd.
It would be nice to be consistent about the ordering in `assertEqual` using it's `(variable, 'expected value')` but here and a couple other places it's opposite.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
GZipMiddleware doesn't modify a weak ETag.
`aiter` is new in Python 3.10. https://docs.python.org/3.10/library/functions.html#aiter Django 4.2 will support Python 3.8, and 3.9 too.
Your solution honestly isn't _that_ much more complex, so I'm not saying we shouldn't do it, I was just curious how you ended up here! I think the resulting patch is pretty nice - I will need to take more time to properly review it but I like it on first glance.
There is not need for an extra variable (`expected_repr_response`), also, we should call `__repr__` directly: ```suggestion self.assertEqual(repr(r), '<StreamingHttpResponse status_code=200>') ```
Historic moment! I don't see a reason why we shouldn't use them.
Is it too late to move the conversion of `auto` to an integer to a post-processing step (e.g. your `get_num_test_processes()` function)? I feel like the `parallel_type` function's job here should only be to check that the value equals `auto` if the value is a string, but not to apply the environment-dependent business logic to convert `auto` to a number. (I also see that `get_num_test_processes()` is already calling `multiprocessing.cpu_count()`, so there may be some duplication of logic with the way things are currently structured.)
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
I think it's okay to use the variable, IMO, especially since it's used twice further down.
Just to be clear, I meant `processes` variable. But if you want to go with the other suggestion, I won't object.
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
I guess this needs to be something like `inherited_attributes |= set(base.__dict__.keys())` to work on Python 2.
As discussed on IRC: no.
add trailing comma
In `_handle_m2m_field()` and `_handle_foreign_key_field()` we can avoid of temporary variables (`value`) and return directly, e.g. ```python def _handle_foreign_key_field(self, field, field_value): return base.deserialize_fk_value(field, field_value, self.using, self.handle_forward_references) ```
I think we also need to exclude [conditional constraints](https://docs.djangoproject.com/en/3.0/ref/models/constraints/#condition) here.
This formatting change is not related with a bug fix, please revert.
Maybe we could test that `name_color_uniq` is also in the message? ```suggestion with self.assertRaisesMessage(ValidationError, 'name_color_uniq'): ```
Here we also should call `super` and not copy-paste code
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
You should be able to pass `is_active=False` to `create_user()`.
prefer including a trailing comma in kwargs so if more items are added in the future we don't have to modify this line again
These two permissions are never used. Please remove them. `cls.permissionuser` is only used in `test_simple_inline_permissions`. Create it inline there rather than on the class.
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
You can move it to the top, because we have an alias.
`serial` columns in PostgreSQL have a `NOT NULL` constraint. You may want to force `null` to be `False`
Use unpacking generalisations and remove arguments to `super()`: ```python super().__init__(*args, **{ 'editable': False, **kwargs, 'blank': True, 'default': Default(), 'unique': True, }) ```
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
Python2 does not support `super()`.
`clean` is not only for validation, but also for data modification in a form.
me too :+1:
I don't think extending `Subquery.__init__` to allow any `QuerySet` some method (e.g. `filter`, `order_by`, ...) is desirable.
You can rebase your branch and target it for Django 2.0. Since master no longer supports Python 2, you can make a few updates such as using `super().`.
This could be a bare `super()`.
This should be set only for values.
Blank lines aren't needed.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
No need to try/except/fali... just test that the method works properly for each choice value.
This file is mostly for unit testing the `LogEntry` model, so I would limit the tests to `LogEntryManager.log_action()`. Similarly, could you try to unit test the `ModelAdmin` methods rather than having complete request/response tests? Maybe in `tests/modeladmin`. p.s. when sending or updating a pull request, please also update the ticket as I just did.
`str(self.band)` doesn't seem like a realistic value for the message.
I would rename it to `kwargs` ```suggestion kwargs = {} ```
Do we need to check a `current_mask`? This code is reachable only when `umask` is set. ```suggestion kwargs['umask'] = umask ```
In the suggested command list, `'python'` should be `sys.executable` to ensure the same Python that is running the tests is used in the subprocess.
```suggestion content = app_path.joinpath("apps.py").read_text() ```
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
This usage looks a bit magic to me, but I think it can stay as it is. The module level deprecation warnings in https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01 are different than this, so stacklevel=2 can be removed in the following locations: - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-9e264d0b47bfdd60be1698bca9bae281R19 - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-68395a4996a48dd1b3cd34ddd9efe762R12
Doesn't matter, but I think if this appears in `__all__`, `NOQA` isn't needed.
This needs an entry in `deprecation.txt`
I thought about this. It's a much bigger change, just for a deprecation. Inserting a deprecation is one thing. Adjusting method calls is something else: `MiddlewareMixin.__init__()` calls `super()` so there's a potential logic change. Don't know where exactly, but I didn't want to risk a regression just to save the extra lines here implementing this deprecation.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
indent style: ``` self.assertEqual( rendered, '...' '...' ) ```
please use hanging indent to make better use of space, e.g. `context = Context({'content': '<b>"Escaped" content to try \'force_escape\ argument & check for errors.</b>'})` might be good here
could you limit line length to 120 characters so horizontal scrolling isn't required in GitHub? missing whitespace for: `{% autoescape on%}`
I think the test is more readable with `type(s)` -> `SafeData`, but I'll leave the choice to you.
Wrap docstrings at 79 characters. Try to avoid "we... " (often this results in simpler language).
A None check would be required here (and not just look for truthiness of self._secret_fallbacks). I.e. using `SECRET_KEY_FALLBACKS = ['a']` and setting `generator.secret_fallbacks = []` would make the getter `generator.secret_fallbacks` return `['a']` and not `[]`.
```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
For all these tests, I'd move `tk1 = p1.make_token(user)` up before instantiating `p2`, so that `p1` drops out of scope. I suspect @felixxm would like you to remove (or at least reduce) the whitespace.
```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
> Just checking - this doesn't account for accidentally passing in a _str_ by say, omitting the comma of a _tuple_. Is an error suitably raised earlier/later by it being a `tuple_settings`? Yes exactly, `tuple_settings` protects from passing a string.
Small nitpick, I would use `bulk_create` here. ``` python Article.objects.bulk_create( Article(pub_date=pub_datetime.date(), pub_datetime=pub_datetime) for pub_datetime in pub_datetimes ) ```
I'd use `Article.objects.create()` instead of `.save()`
"Test checks MySQL query syntax"
Do we need the `tzinfo` bit for the test? I'm worried relying on `get_current_timezone` could make the test flaky.
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
I think we should add this to the opclasses as well then.
I'd suggest defaulting to True so databases have to opt-out rather than opt-in. It would be good to mention this in "Database backend API" under "Backwards incompatible changes in 3.2" like other new features are.
I think this can be single lined: ```python # Does the backed support window expressions (aggregate OVER (expression))? ```
Shouldn't this be named? ```suggestion collate_as_index_expression = False ```
How about making these two flags `False` by default, thus making the feature not causing backwards incompatible changes.
It might be smarter to validate the token first and only modify the session + redirect if it's valid. Otherwise it makes it really easy to create a session just by GET'ing a url (possible DoS vector). It also means you can't pass `accounts/password_reset` as the token and take advantage of our `request.path.replace()` code. It probably means validating the token twice, which is slightly slower. Seems fine to me if an invalid token gets leaked.
@romgar If you find the time that would be great!
immediatelly -> immediately
yeah, `request.session.get` would return none for the token and this wouldn't pass the comparision (which would be perfectly fine)
This throws a 500 if the token is not set!
you can just `del` it instead, it will then fall back to the class level attribute, and save space on pickled state objects
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Ah ofcourse, my bad, you're right. Looks good to me.
Correct, but if me change `ModelState` at some point, this will work automatically or fail, telling us we did something wrong ;)
Can you use `ModelState.from_model()` here, please, as this is what the migration framework will use internally.
Note that I didn't plea for keeping the functionality. I just said that if we remove that, it should be done properly (backwards incompatibility note, separate commit).
I'm in the habit of including an trailing , for all QuerySet filter kwargs.
These might be sorted somewhere above `gis_operators` for similarity with the ordering in `spatialite/operations.py`.
I tried to use a generated condition the `WHERE` clause and it works fine, so IMO we can safely assume that it's an Oracle caveat :smile:
Add an exception message similar to the other methods.
IMO we should check options against PostreSQL names.
So do we need to generate SQL with the same config in the `ts_headline` and an inline `tsquery`? (that's my main question) ```sql ts_headline('french'::regconfig, ..., tsquery(..., 'french'::regconfig), ...) ``` If not then I would prefer to leave config only in `tsquery` and don't duplicate its logic in `SearchHeadline`.
Is there any reason to take `config` from a `query`? This should be rather a separate `config` as far as I'm concerned :thinking:
@hannseman Thanks :+1: > I prefer it over the mixin approach. Yes me too :+1: . We can move `Value()` wrapping to the `__init__()` and simplify it a bit, e.g.: ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) if not (config and hasattr(config, 'resolve_expression')): config = Value(config) self.config = config def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save) resolved.config = self.config.resolve_expression(query, allow_joins, reuse, summarize, for_save) return resolved def as_sql(self, compiler, connection): sql, params = compiler.compile(self.config) return '%s::regconfig' % sql, params ``` Please move introducing a `SearchConfig` expression to the separate commit, or even PR.
I would prefer to wrap value with `Value()` and compile `options` separately.
Don't sqlite have the same issue as illustrated by `test_field_database_defaults_sqlite`? Once solution might be to use `STRFTIME('%Y-%m-%d %H:%M:%f', 'NOW')` on sqlite but it appears like it only supports 3 digits when the expected precision is 6.
`%`-formatting is called anyway: https://github.com/django/django/blob/f71b0cf769d9ac582ee3d1a8c33d73dad3a770da/django/db/models/expressions.py#L965 Do you think an extra value can cause a performance regression? :thinking: I was thinking about readability.
Since we used the `::%(db_type)s` for PostgreSQL solely for readability purposes and this now requires two parentheses wrapping `((expr)::type)` I think we should consider removing that `as_postgresql` override entirely as `CAST(expr AS type)` seems more readable to me at this point.
I added warning to docs.
No, they are not supported, because `BOOLEAN` datatype is available only in PL/SQL on Oracle, so `SELECT` clause cannot return it.
Can you use `['indexes']` here? If not, the list comprehensions in the next lines have a `not in None` and will fail.
This is inconsistent but I think the patch can land as is and the test be modified later on based on the direction of [#24082](https://code.djangoproject.com/ticket/24082).
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
`# Store ... warning message.`
Well the thing is that what StreamingResponse returns isn't guaranteed to be single bytes - if I remember right, it can be chunks of any size - so the queue size isn't going to directly dictate the number of bytes stored in memory. 5 would be a good first start, but I wonder if there's a way to cap the number of _bytes_ too here, along with the sentinel value idea.
Hm, yes, I forgot this is an async queue so `put()` won't just sleep synchronously. I think catching QueueFull and sleeping would accomplish the same thing, though, and give you a queue with one sync "end" and one async "end",
It won't necessarily - the queue means it'll be unloaded as it's loaded - but I do wonder if giving the queue an explicit length and using normal `put()`, or some similar way of _limiting_ the amount of memory used, would be sensible.
`aiter` is new in Python 3.10. https://docs.python.org/3.10/library/functions.html#aiter Django 4.2 will support Python 3.8, and 3.9 too.
It's not a good practice to manually assign primary keys like this. It can cause problems with database sequences.
`str(self.band)` doesn't seem like a realistic value for the message.
It would probably be better to check `cl.queryset.query.distinct`
This should use hanging indent style: ``` python supporting_bands = models.ManyToManyField( Band, related_name='events_supporting_band_at', ..., ) ```
``` help_text='Supporting Bands.', ) ```
This is compliant with the PEP8 rules that we care about, let's not make the diff bigger than needed.
Might be worth renaming this to `self.root_queryset`.
Should this be `r.field.name` so the error in the example of the ticket is: ``` myapp.specialdetail: Accessor for field 'parent' clashes with accessor for field 'SpecialDetail.target'. Add a related_name argument to the definition for 'parent'. ``` instead of: ``` myapp.specialdetail: Accessor for field 'parent' clashes with accessor for field 'SpecialDetail.myapp:specialdetail'. Add a related_name argument to the definition for 'parent'. ```
You turned the arguments into keyword arguments in one other place. Could you also do this here and below? I don't know if it makes sense to also do this in the tests.
I overlook this myself, but hanging indent, please.
The import should be conditional and the test skipped if enum isn't installed.
Put `import warnings` before `from collections import deque`.
alphabetize g before o also I would combine with the "from" imports below
Leave an empty line between stdlib imports and project ones.
built-in imports like unittest should go above django imports, separate by a newline. e.g. ``` from __future__ import unicode_literals import unittest from django ... ```
Also, I don't think we should collect this in `to_report`. We can fail immediately with `self.fail('Form is valid')`.
Ahh, yes sorry wrong ticket. It should be ticket-28507.
I think we should build an `ErrorDict` of expected errors and use `assertEqual()` to compare it with `form.error`. This way we will avoid building a custom message. See also ticket-24782 that should be fixed in advance.
`FormNotValid failed. ` seems unnecessary for me.
I wasn't familiar with `assertFormError` actually. Guess the main difference is that `assertFormError` is a single field. Happy to leave that though, the nicer `assertFormValid` is useful in itself.
Should we also have a pointer here of the form ```suggestion with self.assertRaisesMessage(FieldError, "Cannot distinct on 'other_rating' alias. Use annotate to promote it"): ```
Use `self.assertSequenceEqual(lengths, [3, 7, 8])`.
Running `test_incorrect_field_expression_in_join()` without a fix, doesn't behave like it's described in the ticket on the PostgreSQL database. It raises: _"django.db.utils.ProgrammingError: operator does not exist: character varying = integer"_ IMO using `ceo__pk` instead of `ceo_firstname` should fix this issue.
using `Lower` seems more readable
This assertion is not necessary.
This should just be `template_params = kwargs`. The `extra` in the signature that was removed is acting like a `kwargs` anyway.
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
put the closing parenthesis on the next line
Yeah that's what I suspected too. Stupid SQL.
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
I think leave the original `widget = widget or self.field.widget` here. Then do the `isinstance()` check, so that we're no repeating ourselves in the `else` block. `widgets` might then be clearer as `subwidgets`. (Or such.)
We need to factor this differently, as it's an exact duplicate of the added block above.
* We're still preferring single quotes, please use those throughout, unless there's a nested single quote. * This change is unrelated, please revert.
I find it problematic we’d make it possible to override the `aria-describedby` for two reasons: - If the `help_text` is used, then I don’t think it would be appropriate for its content to be missing from the input’s description as computed from `aria-describedby`. - Assuming we implement the other fix for #32819 by adding the field’s error(s) in `aria-describedby`, it would also be inappropriate for that to be missing because of a customization. In both cases I guess this would be ok if the customization included the ids for the help text and error message when needed, but that doesn’t seem very convenient. --- So we could make it possible to customize `aria-describedby`, but if we did in my opinion it should be in addition to Django automatically populating it for `help_text` and field errors: ```suggestion if self.field.help_text and id_for_label: helptext_id = '%s_helptext' % id_for_label if 'aria-describedby' in widget.attrs: attrs['aria-describedby'] = f"{helptext_id} {attrs['aria-describedby']}" else: attrs['aria-describedby'] = helptext_id ``` I’m not too sold on this either because then we’re having to assume the order of the different descriptions. It gets more problematic if we had errors in there too: ```python attrs['aria-describedby'] = f"{helptext_id} {errors_id} {attrs['aria-describedby']}" ```
Please try to stay near 80 char per line…
Add a blank line. ```suggestion base_table_class = BaseTable ```
`MultiJoin` is an exception class. I don't think you need to customize it.
IMO checking how `empty_form` is rendered is not necessary. It's enough to check `empty_permitted`, e.g. ```suggestion self.assertIs(formset.empty_form.empty_permitted, True) ```
Are there situations in which this can happen other than "too many subqueries"? If not, I'd suggest an error message that might be more helpful to the end user would be "Maximum recursion depth exceeded: too many subqueries."
I guess it would be easier to understand, if you'd name the separate boolean expression first before combining them, eg: ```python is_join = isinstance(table, Join) is_base_table = isinstance(table, BaseTable) clone.external_aliases[alias] = is_join and not is_base_table ``` Something along those lines.
You can reuse `resolve_model_field_relations()`.
Oh, when I was reading before, I thought the function ended there. It could still help readability to do the `if self._relations is None:` case first, since there are less "nots" to look at.
This would be cleaner if you did the following before handling the `self._relations is not None` case: ```python if self._relations is None: fields[name] = field return ``` Then you don't need to indent after.
Are you sure this branch is ever skipped? AFAIK `auto_created` models are not part `ProjectState.models` entries.
The 4 lines above look identical to the `remote_model_key` lines a few lines before, except with `through` instead of `remote_field.model`. Maybe that can be a helper method accepting that argument.
`'Big serial'` (`BigIntegerField` has `'Big (8 byte) integer'`, but I think we can keep this description simple.)
Python2 does not support `super()`.
Use unpacking generalisations and remove arguments to `super()`: ```python super().__init__(*args, **{ 'editable': False, **kwargs, 'blank': True, 'default': Default(), 'unique': True, }) ```
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
I saw that you're now handling this at the database level. It makes more sense to me.
It'd be great we if we could avoid creating 5 new tables to reproduce the issue. Existing ones should be reusable somehow.
(inadvertence revert here too)
I would omit the parenthesis in these messages (I know it's done elsewhere, but "I am at war" with that style unless you like it).
no parenthesis needed / prefer single quotes
Unnecessary -> ```suggestion def __str__(self): ```
Move the exists assertions to another test.
The fact only a single result is returned is a strong enough assertion here. Some database backend could translate `__isnull` to some different SQL.
Might want to only test for `JOIN` presence as this wouldn't fail if `LEFT JOIN` was used.
Ditto, I'd remove.
Oh I realize that asserting against the results is problematic given all the engines we're testing against support foreign keys. In this case yes, using the same `JOIN` check against `captured_query` should do!
then you should be able to remove [0] from django/contrib/gis/db/backends/oracle/operations.py too (just so we stay consistent) (same for spatiallite)
I wonder if we should suppress `subprocess.CalledProcessError` when arguments are not correct, to get e.g. ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. ``` instead of ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. Traceback (most recent call last): File "manage.py", line 22, in <module> main() File "manage.py", line 18, in main execute_from_command_line(sys.argv) File "django/django/core/management/__init__.py", line 401, in execute_from_command_line utility.execute() File "django/core/management/__init__.py", line 395, in execute self.fetch_command(subcommand).run_from_argv(self.argv) File "django/django/core/management/base.py", line 328, in run_from_argv self.execute(*args, **cmd_options) File "django/django/core/management/base.py", line 369, in execute output = self.handle(*args, **options) File "django/django/core/management/commands/dbshell.py", line 25, in handle connection.client.runshell(options['parameters']) File "django/django/db/backends/postgresql/client.py", line 55, in runshell self.runshell_db(self.connection.get_connection_params(), parameters) File "django/django/db/backends/postgresql/client.py", line 49, in runshell_db subprocess.run(args, check=True, env=subprocess_env) File "/usr/lib/python3.6/subprocess.py", line 438, in run output=stdout, stderr=stderr) subprocess.CalledProcessError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ``` We can also re-raise it as a `CommandError`: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ```
I'm in favor of re-raising `subprocess.CalledProcessError` as a `CommandError`, e.g. ```python def handle(self, **options): connection = connections[options['database']] try: connection.client.runshell(options['parameters']) except OSError: # Note that we're assuming OSError means that the client program # isn't installed. There's a possibility OSError would be raised # for some other reason, in which case this error message would be # inaccurate. Still, this message catches the common case. raise CommandError( 'You appear not to have the %r program installed or on your path.' % connection.client.executable_name ) except subprocess.CalledProcessError as e: raise CommandError( '"%s" returned non-zero exit status %s.' % ( ' '.join(e.cmd), e.returncode), ) ``` which will end with: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: "psql -U djangoticket -h localhost -p 5432 djangoticket --asdasdad" returned non-zero exit status 1. ```
Trailing space in string not required.
Trailing space in string not required.
only need 'coding' if there are non-ascii chars in the file
We usually only include this if there are non-ASCII characters in the file.
no need for this import
remove extra newline
I'm not too keen on beginning each warning with "In your url patterns, ..". How about "Your url patterns .." ? "Your url patterns have used `include` with a regex containing a '$'. " .. "Your url patterns have a regex beginning with a '/'." .. "Your url patterns have a pattern with a name containing a ':'." ..
There is no need to mix these tests with `.extra()` we can use existing columns, e.g. ```python values = Number.objects.values_list('num', 'other_num', named=True).get() ```
These two could be `and`ed.
no ticket reference needed
But it's already covered by the first assertions. Moreover `assertEqual()` uses `assertTupleEqual()` internally.
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
Please add trailing comma.
This cleanup is not related with a patch please move it to a separate commit/PR.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
Chop blank line.
Use hanging indentation: ```python raise TypeError( 'Transform only accepts SpatialReference, string, and integer ' 'objects.' ) ```
`ExpressionList.__repr__()` can be removed because `Func.__repr__()` works in the same way.
How about this ```python def __str__(self): return self.arg_joiner.join(str(arg) for arg in self.source_expressions) ``` I don't see a need for a `.format()` call.
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Is this check correct? A `Coalesce` can still result in a null value (if all of its arguments are null), so even if the expression is already a `Coalesce` ISTM it needs to be wrapped again (or have `Value('')` added to the end of its `source_expressions`, but just wrapping in another `Coalesce` seems cleaner).
Ah! Of course, sorry I missed that.
```suggestion def _select_on_conflict(self, ignore_conflicts, update_conflicts, update_fields, unique_fields): ```
You can move the line above to an `else` clause below.
```suggestion 'ignore_conflicts and update_conflicts are mutually exclusive' ```
We try to avoid accessing the database connections when not necessary, so I'd move `db_features`: ```suggestion if ignore_conflicts and update_conflicts: raise ValueError( 'ignore_conflicts and update_conflicts are mutually exclusive.' ) db_features = connections[self.db].features ```
```suggestion raise NotSupportedError( 'This database backend does not support ignoring conflicts.' ) ```
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
To avoid the interesting indentation: ``` msg = "<class 'admin_views.models.Question'> is not registered in the admin." with self.assertRaisesMessage(Http404, msg): ```
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
`.get(self.live_server_url + reverse('admin:admin_views_question_add'))`
use `reverse()` rather than a hard coded URL.
It won't necessarily - the queue means it'll be unloaded as it's loaded - but I do wonder if giving the queue an explicit length and using normal `put()`, or some similar way of _limiting_ the amount of memory used, would be sensible.
Hm, yes, I forgot this is an async queue so `put()` won't just sleep synchronously. I think catching QueueFull and sleeping would accomplish the same thing, though, and give you a queue with one sync "end" and one async "end",
Well the thing is that what StreamingResponse returns isn't guaranteed to be single bytes - if I remember right, it can be chunks of any size - so the queue size isn't going to directly dictate the number of bytes stored in memory. 5 would be a good first start, but I wonder if there's a way to cap the number of _bytes_ too here, along with the sentinel value idea.
> We'll want to do something with regards to the newly added support for iterator's prefetch_related here. That looks like a _moderate_ task in itself (to implement) — `islice`, `prefetch_related_objects`, ... — it might be that adjusting the PR here match the new interface, but emitting a warning if prefetches are set would let us get this in, to work on async prefetches later. (Would be equivalent to the sync behaviour before edbf930287cb72e9afab1f7208c24b1146b0c4ec — of _either prefetch or iterator_.) 🤔
```python async with contextlib.aclosing(aiter(self._iterable_class(...))) as agen: async for item in agen: yield item ``` You should explicitly aclose your async generators when you create them: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators
We shouldn't use the same chain on `replace()` in multiple places, use `quote_value()` instead.
`str()` call is unnecessary: ```suggestion yield self.connection.ops.tablespace_sql(tablespace, inline=True) ```
Maybe: ```suggestion column_db_type = db_params['type'] ```
The fact you have to special case `DefaultNow` makes it look like a code smell to me, this logic should be completely abstracted by whatever is allowed to be passed to `db_default`.
Feels like this should be handled at the database backend level.
but its standard too have a doc string
Please remove blank line.
Django doesn't currently use f-strings, but 3.0 will certainly be capable of doing so. @felixxm, @carltongibson - are we happy to start allowing use of f-strings, or do we want to hold off? Perhaps this could be: ```python except ValueError as e: raise e.__class__(...) from e ```
This reassignment is pointless as `source_value` is not reused later. Perhaps: ```python value = classdict[key] if isinstance(value, (list, tuple)): try: value, display = value except ValueError as e: ... else: display = ...
Please use single quotes.
Lets also test that `values_list()` throws the same error. You can do it in the same test method.
This should use a variant on the `check_isseq` used elsewhere in the file. At present this does restrict you to a list or a tuple, but we may as well keep this consistent.
I don't think adding this line has anything to contribute to the commit. I'd just stick with the first line of the docstring. If you want to include the issue number I usually go with preceding it to the docstring: `#25252 - Running select_related() ...`
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
`if it encounter` => `if it encounters`
I meant changing the signature of `apply_converters()` to: ``` @staticmethod def apply_converters(self, connection, rows, converters): ``` I guess that change doesn't make much sense given `apply_converters()` is called in some other places.
I'm not a fan of aliasing builtin names.
In this case, I think a ternary is more complicated to read than: ``` if srid == -1: srid = None ```
Perhaps this could be a docstring? You might elaborate a bit more -- as someone not familiar with MySQL, it's not clear to me what "improved" means.
Add an exception message similar to the other methods.
I don't see much value in this docstring.
I don't see much value in this docstring.
Why would you need to sanitize something that's already in your session? Seems a bit late...
Use single quotes to stay consistent with the code above.
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
I don't see much value in this docstring, please remove it.
Chop blank line.
```suggestion form = PartiallyRequiredForm({'f_0': '', 'f_1': ''}) ```
I'm not sure we need to test implementation details of `MultiValueDict`. It seems like the following test should be enough ```python def test_empty_data_files_multivalue_dict(self): form = Person() self.assertIsInstance(form.data, MultiValueDict) self.assertIsInstance(form.files, MultiValueDict)
@smithdc1 it does thanks!
return directly, no need for `path` variable.
And there: ``` work_file = os.path.join(self.dirpath, '%s.c' % self.file) ```
And use `work_file` here.
this could use the indent style of the previous `CommandError`.
no `u''` prefixes on strings please
`as defined by the arguments` is not really telling me anything. I would either add a longer more descriptive doc string or none.
IMHO I would simply use `_` not `,` and always replace. Reduces complexity and a replacement isn't too slow. In fact, it's probably faster than the if clause. If clauses can significantly slow down code execution, since your processor doesn't know which instructions to preload until you reached that particular instruction and decided where to go from there.
Or you can still use f-strings for this too: ```python number = f'{number:_.{decimal_pos}f}' ```
Why don't you do the decimal precision as part of the format expression? Something like: ```python number = ("{:_.%sf}" % decimal_pos).format(number) ```
Besides, this change doesn't improve speed. From experience, any change will slow down reviews and hinder this from being merged ;)
@felixxm that's a tricky one for sure. We could adjust MySQL's `allows_group_by_pk` feature to be based of `not ONLY_FULL_GROUP_BY` but that would likely incur a large performance hit which is definitely not suitable for a backport. I guess we could always skip the test on MySQL for now.
Per new code guidelines, can we use `assertIs`? :)
@timgraham is ordering by the result of an aggregate allowed without subqueries? If ordering by count does not error, then it should be safe to use that ordering. If not, introducing a different field into the orderby will affect the grouping (not that you suggested that), so we'll need to look at comparing the queryset out of order if there's another assert method available that does that. I'm not able to check either of these things at the moment, but I can take a look in about 8 hours if it's not resolved.
```suggestion self.assertEqual([book.rating_count for book in qs], [1]) ```
This assertion is not necessary.
Pretty sure we can't drop the `order_by` based on 779e615e362108862f1681f965ee9e4f1d0ae6d2 which explicitly deals with this `annotate` / `FieldError` issue.
```suggestion # Inline annotations in order_by, if possible. ```
```suggestion if annotation := query.annotations.get(col): ```
`by` :thinking: ```suggestion f"Cannot update when ordering by an aggregate: " ```
```suggestion new_order_by.append(annotation) ```
Are you sure? Should this not be consistent with `SHORT_DATETIME_FORMAT`, i.e. `SHORT_DATE_FORMAT = 'j N Y'`.
@sdil Thanks for checking :+1:
My pleasure :)
@sdil Can you take a look? Thanks!
In fact, unless you have a special sequence like \n, \r, \t, the raw prefix is not strictly necessary. But for consistency, it's better to always add it to indicate that none of the escaped letters have to be interpreted as special-meaning sequences.
You could, just seemed easier not to have nested if statements.
It's this part that I think needs to be changed (line 24): > 'func' is a function at the time it is passed to _dec There's no longer an argument called `func` that gets passed to `_dec`.
use single quotes
Would `functools.partial` work here? ```python from functools import partial bound_method = partial(method.__get__(self, type(self))) ```
I don't think both tests are required.
Use [PEP 257](https://www.python.org/dev/peps/pep-0257/) verb style: "Update..."
I think we want to avoid altering `self.extra` here and pass `db_type` as a kwag to `super().as_sql()`.
Then it's settled, I think. Thanks :)
Why the `CombinedExpression` and not `Expression`? IMO it's misleading, I know that `CombinedExpression` has the concept of right-hand and left-hand sides but for other purposes.
I'd use `*args, **kwargs` for arguments that are simply passed-on without being accessed or modified, to reduce the number of places that a change in signature would need to be reflected, and to avoid having to repeat the same default values. We've had issues in the past in Django (in forms/formsets, IIRC) where the default value for some parameter to a superclass method changed, or a new optional argument was added, but nobody remembered to update subclass method signatures accordingly, causing bugs.
I was thinking about the same, but without any static list we cannot perform a proper validation. A wildcard approach is fine IMO, we can add a small warning in the docs, e.g. ``` .. warning: Rasters with names starting with `/vsi*/` will be treated as rasters from the GDAL virtual filesystems. Django doesn't perform any extra validation. ```
prefer hanging indent style: ``` GDAL_TO_CTYPES = [ None, ... .... ] ```
, keeping a reference to the cyptes object so that the vsimem file...
While my tests suggest that iterating a set is ~8% slower in this case, it is a negligible difference once you look at the whole `_expire_cache` function.
So, I've been hemming and hawing on whether to mention it, because it conceptually works when in the error message, but it still seems slightly _'off'_ to me that the warning would say `SECRET_KEY_FALLBACK` when the setting is `SECRET_KEY_FALLBACKS` (plural). I guess if we're not going to say _which_ one errored (which _we could_, using hints) I think it'd make more sense to say `One of your SECRET_KEY_FALLBACKS has less ...`
According to [Wolfram Alpha](http://bit.ly/29bAENj) that's the same as this and slightly more understandable? ``` python (not old_field.db_index and not old_field.unique and new_field.db_index) or (not old_field.unique and new_field.unique) ```
Oh are we creating the `_like` indexes even when `unique=True`? I wasn't expecting that.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
"cannot" is one word. add period.
Ahh, right, so :wink: : ```python for error in _search_form.errors.values(): ```
It would probably be better to check `cl.queryset.query.distinct`
And this to `self.queryset`.
For consistency with the rest of the code, I think you can omit the comma at the end.
Please revert the whitespace addition.
Please order alphabetically.
is `str()` needed? I assume `%s` takes care of that.
Chop blank line.
@timgraham wilco. As new contributors, it's difficult to know which direction so I appreciate the explanation.
`extra` filed is assigned by user. for example: ```python class ChoiceInline(admin.StackedInline): model = Choice extra = 3 ``` ref: https://docs.djangoproject.com/en/3.1/intro/tutorial07/#writing-your-first-django-app-part-7 I'am sorry that I think `EXTRA_FORM_COUNT = TOTAL_FORM_COUNT - max(INITIAL_FORM_COUNT, MIN_NUM_FORM_COUNT)` is incorrect.
Sorry for my mistabke, you are right.
If initial_forms=3 and min_num=4 and extra=3 I'd expect total_forms to be 6 and not 7 EDIT:// oh, I see below that this would probably be a change in backwards compat; in that case never mind ;)
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
I'll take the time to write one later today but we could use a `@property`: ``` python @property def widget(self): if self.localize: return TextInput else: return NumberInput ``` One of the con here is that `NumberField.widget` will be an instance of `property`. We could also write a descriptor to maintain backward compatibilty: ``` python class WidgetDescriptor(object): def __init__(self, widget, localized_widget): self.widget = widget self.localized_widget = localized_widget def __get__(self, instance, owner): if instance and instance.localize: return self.localized_widget return self.widget class IntegerField(Field): widget = WidgetDescriptor(NumberInput, TextInput) ``` Maybe I'm just over-complicating this whole thing.
I thought you wanted to remove `return`. Nevertheless I'd also leave the `else` as it increases readability.
I prefer the following one rather than the above one ```py def greet(): condition = False if condition: return "Hi" return "Hello" ``` Feel free whether follow the things I point out.
That's not true, `return` is to avoid setting new migrations.
```suggestion sys.exit(1) ```
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
This class is unnecessary.
This can be single-lined.
This test should verify the correct results of the Filter rather than just checking that an exception isn't raised.
This can be single-lined.
Chop blank line.
I think using a semantic name would help here, e.g. `lookup_kwarg_null`
Please use single quotes.
For new code, we're using single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
Inner import is not necessary: ```python from django.core.mail import ( DNS_NAME, EmailMessage, EmailMultiAlternatives, mail_admins, mail_managers, send_mail, send_mass_mail, ) ```
I don't see much value in this docstring, please remove it.
You can mock return value in a decorator, e.g. ```python @mock.patch('socket.getfqdn', return_value='漢字') ```
chop blank lines
might as well use `setdefault` in the test as well
chop extra space after period, chop "we".
chop "we" 2x
I won't require it if you don't like it, but the style I prefer is ``` raise RuntimeError( "Error..." ) ``` (allows longer lines of text and less need to break the string up)
@charettes Thanks :+1: I removed unnecessary connector, see #15511. As far as I'm aware we now prefer non-kwargs constructions for internal usage, see 9662193aea2ee982bc8e553c62499aca5e606755 and #14699,
Minor but this could have likely be simplified by using `reduce` to avoid the private `_connector` usage ```python condition = reduce( (Q(app_label=app_label, model__in=models) for app_label, models in needed_models) , operator.or_) ``` In all cases `Q(("app_label", app_label), ("model__in", models), _connector=Q.AND)` can be simplified to `Q(app_label=app_label, model__in=models)` since `_connector` defaults to `Q.AND`.
Do we need to call `str()` on `contraint_sql`? ```suggestion if contraint_sql: schema_editor.execute(constraint_sql + ' NOT VALID') ```
You can use `super()`: ```suggestion return super().migration_name_fragment + '_not_valid' ```
Chop blank line.
I would chop _" on all existing rows"_.
Maybe: ```'Create not valid constraint %s on model %s'```
```suggestion # Reversal. ```
@atombrella Do we need inner imports here? Imports at the top works fine for me.
should be `first_state`, not `project_state`, I suspect.
This docstring is unnecessary.
Do we need to delete these models? I don't think that below tests are required,
I'd suggest to check `response.context[REDIRECT_FIELD_NAME]` instead.
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
We prefer hanging indent style like this: ``` self.assertEqual( res.context_data["form"].errors["__all__"], ['You must confirm the delete.']) ) ``` Also please drop the u prefix on strings.
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
I wasn't familiar with `assertFormError` actually. Guess the main difference is that `assertFormError` is a single field. Happy to leave that though, the nicer `assertFormValid` is useful in itself.
Yes, exactly. However, if the value is truthy but not `True`, I think the current message could be confusing. So perhaps some alternate failure message should be used when the method doesn't return a `bool`. Same idea should be applied to `assertFormNotValid`.
I think it would be nice if these methods verified the value is identical to either `True` or `False` and not some other truthy/falsey value. This would align with recommendation in the [coding style guildelines](https://docs.djangoproject.com/en/3.0/internals/contributing/writing-code/coding-style/): > Use assertIs(…, True/False) for testing boolean values, rather than assertTrue() and assertFalse(), so you can check the actual boolean value, not the truthiness of the expression. As well as stdlib [unittest](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertTrue): > Note that this is equivalent to bool(expr) is True and not to expr is True (use assertIs(expr, True) for the latter).
Also, I don't think we should collect this in `to_report`. We can fail immediately with `self.fail('Form is valid')`.
I think we should build an `ErrorDict` of expected errors and use `assertEqual()` to compare it with `form.error`. This way we will avoid building a custom message. See also ticket-24782 that should be fixed in advance.
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
+1 (in separate patch)
Wouldn't be required if you subclasses `IntegerField`.
Oh, no, OK, the nextval will always return a different value. It's just that we might have gaps if one value is not saved.
`Also include shadowed fields of the parent class.` (can move to previous line I think)
I think this docstring should also explain the meaning of the three possible values of `include_parents`
I'd simplified this test: ```suggestion def test_reverse_inherited_m2m_with_through_fields_list_hashable(self): reverse_m2m = Person._meta.get_field('events_invited') self.assertEqual(reverse_m2m.through_fields, ['event', 'invitee']) inherited_reverse_m2m = PersonChild._meta.get_field('events_invited') self.assertEqual(inherited_reverse_m2m.through_fields, ['event', 'invitee']) self.assertEqual(hash(reverse_m2m), hash(inherited_reverse_m2m)) ```
don't think "or None" should be needed (None or None) is None
remove "or None"
That shouldn't be an issue (see a workaround for `|`).
Ahh right :disappointed: I'm fine with raising exception on Oracle: ```python raise NotSupportedError('Bit-wise xor is not supported in Oracle.') ```
You're right. I prepared separate PR #7787.
I think that I found complex solution for all binary operators in `MySQL` that return an unsigned 64-bit integer. We can simple convert return value to `SIGNED` integer. I don't know why, but it doesn't work for right shift operator. ```diff --- a/django/db/backends/mysql/operations.py +++ b/django/db/backends/mysql/operations.py @@ -202,8 +202,14 @@ class DatabaseOperations(BaseDatabaseOperations): + lhs, rhs = sub_expressions if connector == '^': return 'POW(%s)' % ','.join(sub_expressions) + # MySQL's binary operators return an unsigned 64-bit integer. + elif connector in ['<<', '|', '&']: + return 'CONVERT(%s, SIGNED)' % connector.join(sub_expressions) + elif connector == '>>': + return 'FLOOR(%(lhs)s / POW(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs} return super(DatabaseOperations, self).combine_expression(connector, sub_expressions) ```
use a tuple as it's faster to construct
Do we need to call `list(fields)` here? :thinking:
This will not work for `OuterRef()` :disappointed: because we don't resolve it properly, so it generates: ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING(U0."name", 3, 1)) LIMIT 1 ) ``` instead of ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING("expressions_company"."name", 3, 1)) LIMIT 1 ) ``` see `test_slicing_of_outerref`.
I'd move this line to the top of `__init__()` so it isn't lost below all the conditional logic.
`target` is only available for `Col`, so it crashes for expressions, see `test_slicing_of_f_expression_with_annotated_expression`.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Please make this `IntegerField` instead of `PositiveIntegerField`. Similar to `AutoField`, which uses `serial`, although the field usually increments from `1`, it is not forbidden to store zero or negative values. Indeed, this is sometimes useful.
Not necessary if you subclass `IntegerField`.
I don't think this needs to live here - it could just live under the definition of `GeometryField` - the `ready` method would be perfect if we were adding this to something which lives outside of `contrib.gis`.
You could remove `record=True` here too.
I think you can safely remove this.
I guess this needs to be something like `inherited_attributes |= set(base.__dict__.keys())` to work on Python 2.
I don't think that we need this check. I would rather remove from docs [note](https://github.com/django/django/blob/77d335e5abec889b15323975187a8d5b10bfcb0f/docs/topics/db/queries.txt#L965-L979) about setting `id` to `None`. That is outdated after this patch. \cc @spookylukey
> I was under the impression that only `AutoField`'s were to be made `None`. You can also set `pk` that is an `AutoField` to a string value, in all such cases Django raises `ValueError`, so I don't see any issue in it. Moreover we can have a primary key that is not an `AutoField` but has a default value, e.g. `UUIDField(default=uuid.uuid4)` and this should also work.
I think this test is sufficient, no need for the other one. Can you rename it to `test_delete_keep_parents()` though.
Are you using PROXY_PARENTS as some type of flag? We already went through the "flags" path throughout the Meta API refactor and ended by removing it because it required imports. Even though this is an internal function, I would advise to find a better solution because, personally, I don't think it's good practice to have one argument that can be of different types (in this case, boolean or object) as it increases the risk of bugs, and it also can be confusing to other people. But that's just me.
Right so I think the skip condition in order to avoid false failures should be: `@unittest.skipIf(connection.ops.max_name_length() > 74` but it would be better if we could keep the skip condition as it is so the test is run on all databases and automatically generate a model that has a field name with length `connection.ops.max_name_length() + 1` If you're still unsure about this, let's sync up on IRC.
I think the skip condition needs to be amended as this test won't pass on DB backends if `connection.ops.max_name_length() >= 74` (the length of the model field), right? It would also be helpful to be a bit more descriptive to say _why_ the test is not required for this database.
more descriptive names would be enhance readability of the test, e.g. "ModelWithLongField", "ModelWithDBColumn"
`long_field_name = 'a' * (allowed_len + 1)`
supports long field names. -> doesn't have a column name length limit.
``` # If the database returns a Decimal, convert it to a float as expected # by the Python geometric objects. ```
The docs say, "For performance reasons, `from_db_value` is not implemented as a no-op on fields which do not require it (all Django fields)."
According to Django docs: > If present for the field subclass, from_db_value() will be called in all circumstances when the data is loaded from the database, including in aggregates and values() calls. > to_python() is called by deserialization and during the clean() method used from forms. https://docs.djangoproject.com/en/1.8/howto/custom-model-fields/#converting-values-to-python-objects [Here](https://github.com/django/django/blob/8047e3666b0b50bb04e6f16c2a4fb21ddfd5713f/django/contrib/gis/db/models/sql/conversion.py) you can look at from_db_value implementation
Why do you fallback to `to_python` method? It's kind of unexpected, since normally `to_python` isn't called from `from_db_value`
I added warning to docs.
might as well use `setdefault` in the test as well
this line should be: `def __init__(self, *args, **kwargs):`
`assertEqual` (the version you have now is a deprecated alias)
Both `response` vars are unused.
The commas aren't necessary in the docstring sentences.
This is better. I didn't think about the problem with variables that can change values. I have one concern, though. The same `render_context` instance is shared across nodes in the `Template.render()` call, so `template_name` isn't a very safe key to use. The potential arises to clash with other nodes. Maybe we could adjust the approach a bit? My thought is to create a cache dict in the `render_context` using `self` as a key. For example: ``` cache = context.render_context.setdefault(self, {}) template = cache.get(template_name) cache[template_name] = template ``` Alternatively, you could use a unique, uncommon key rather than `self`. The benefit here is that multiple `IncludeNode` instances could share the same cache. That means a template like below would only parse `template.html` once: ``` {% include "template.html" %} {% include "template.html" %} {% include "template.html" %} ``` That seems appropriate in this case.
`ContextMixin` doesn't use it but is very explicit about what it's trying to achieve. I guess `SingleObjectMixin` could be updated (in another commit) to use `setdefault` and avoid an extraneous `dict` creation and update.
This looks like a good candidate for `kwargs.setdefault('form', self.get_form())`
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
No, they are not supported, because `BOOLEAN` datatype is available only in PL/SQL on Oracle, so `SELECT` clause cannot return it.
Here's what I came up with https://github.com/django/django/pull/11641.
And a another alternative in #11642
You should use `1` instead of `True`, sorry for misleading. If you will use `True` as a param than it will be automatically converted into `1`.
😮 I see that we have a similar condition here `django.db.models.expressions.Exists.as_sql`: ``` features = compiler.connection.features if not features.supports_boolean_expr_in_select_clause: return "1=1", () return compiler.compile(Value(True)) ``` Would it make sense to somehow move them to the same piece of logic? We could either have `compile(Value(True))` determine if it should generate a `1=1`, but it have other side-effects I think 😕
No, I was thinking about `'input'` an `'widget'` strings, e.g. - `MultipleHiddenInput` -> `multiplehidden`, - `SplitHiddenDateTimeWidget` -> `splithiddendatetime`, - `PasswordInput` -> `password`. Does it make sense? :thinking:
We can strip `input` and `widget` (as Claude suggested).
I find it problematic we’d make it possible to override the `aria-describedby` for two reasons: - If the `help_text` is used, then I don’t think it would be appropriate for its content to be missing from the input’s description as computed from `aria-describedby`. - Assuming we implement the other fix for #32819 by adding the field’s error(s) in `aria-describedby`, it would also be inappropriate for that to be missing because of a customization. In both cases I guess this would be ok if the customization included the ids for the help text and error message when needed, but that doesn’t seem very convenient. --- So we could make it possible to customize `aria-describedby`, but if we did in my opinion it should be in addition to Django automatically populating it for `help_text` and field errors: ```suggestion if self.field.help_text and id_for_label: helptext_id = '%s_helptext' % id_for_label if 'aria-describedby' in widget.attrs: attrs['aria-describedby'] = f"{helptext_id} {attrs['aria-describedby']}" else: attrs['aria-describedby'] = helptext_id ``` I’m not too sold on this either because then we’re having to assume the order of the different descriptions. It gets more problematic if we had errors in there too: ```python attrs['aria-describedby'] = f"{helptext_id} {errors_id} {attrs['aria-describedby']}" ```
* We're still preferring single quotes, please use those throughout, unless there's a nested single quote. * This change is unrelated, please revert.
Likewise, it seems odd to keep `'point'` here: ```suggestion context = widget.get_context('geometry', None, None) ```
This test data seems wrong to me. For example, you have verbosity `1` leading to level `DEBUG`, which means that logging at a level of `DEBUG` should result in output per the logic below (since `logging_level >= level` appends `output = True`). That isn't right though, since verbosity `1` shouldn't show `DEBUG`. The test would be a lot easier to understand and update if it was simply a hard-coded, sorted list of tuples, e.g. ```python cases = [ (0, None, False), (0, logging.DEBUG, False), (0, logging.INFO, False), (0, logging.WARNING, False), ... ] ``` Including `level=None` will serve to check the default case. Also, you don't need to check `level=logging.NOTSET` since that's not a level that anyone would ever pass when logging a message. That level is more for when reading what level is set on a configured logger. Having the correct test should help with getting your logic correct in the `log()` method above.
You can just say `expected`. (It's clear from the next line.)
No problem, happy to help. Thanks for keeping at it.
Add a trailing comma so if more items are added later we don't have to modify this line again.
I noticed that all logs and prompts have `ERROR` style when using `--scriptable`, e.g.: ![image](https://user-images.githubusercontent.com/2865885/148344507-ada0d115-4a48-4001-81a2-b62c919c5e45.png) ![image](https://user-images.githubusercontent.com/2865885/148344684-e00db0d8-c25f-45fc-ba54-9dfef13eac7c.png) We could create a copy of `stderr` without the `ERROR` style and use it where appropriate :thinking: ```diff diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py index cdb200f22e..096702814c 100644 --- a/django/core/management/commands/makemigrations.py +++ b/django/core/management/commands/makemigrations.py @@ -6,7 +6,7 @@ from itertools import takewhile from django.apps import apps from django.conf import settings from django.core.management.base import ( - BaseCommand, CommandError, no_translations, + BaseCommand, CommandError, no_translations, OutputWrapper ) from django.db import DEFAULT_DB_ALIAS, OperationalError, connections, router from django.db.migrations import Migration @@ -62,9 +62,17 @@ class Command(BaseCommand): help='Output only created migration filepaths to stdout; divert logging and prompts to stderr.', ) + def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False): + super().__init__(stdout, stderr, no_color, force_color) + if no_color: + self.stderr_log = self.stderr + else: + # stderr without the ERROR style. + self.stderr_log = OutputWrapper(stderr or sys.stderr) + ```
Moved fail_on_restricted to the next line and use hanging indentation.
Try to avoid two branches and lots of code duplication here. You should be able to handle both cases in single path.
Do we need to use `self.restricted_objects` multiple times? I would simplify this, e.g. ```python for model, fields in self.restricted_objects.items(): for field, objs in fields.items(): for obj in objs: raise RestrictedError( "Cannot delete some instances of model '%s' " "because they are referenced through a restricted " "foreign key: '%s.%s'" % ( model.__name__, obj.__class__.__name__, field.name, ), objs, ) ```
if _not_ keep_parents :)
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
please use periods
seems to be missing a placeholder at the end
setUp/tearDown should go at the top of the class.
include trailing comma
chop "should" (just state the behavior)
In general, I think the `get` / `set` style APIs are familiar enough that we don't need to use keyword arguments with every call. But I don't feel strongly about it.
Fine by me. I think we could probably omit the keywords in a lot of places and include them only where it's potentially confusing, but probably that's already what you're doing.
try to avoid "we", e.g. "Because it's a parent link, all the data is available in the instance, ...
I think we should raise a more descriptive error, maybe the same as in `add()` and `set()`.
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
Quick link: https://github.com/django/django/pull/8714/files
Please add trailing comma.
Can you call this function `django_datetime_cast_date` for consistency? Everything else has cast_date / extract / trunc.
the tests pass for me on Oracle using `'TRUNC(%s)'`
Minor but the `'%%Y-%%m-01 00:00:00'` could likely by appended to params as well.
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Good catch, I will remove it before final squash.
Trailing comma: ```suggestion migrations.RunPython.noop, ```
```suggestion 'INSERT INTO test_runsql_pony (pink, weight) VALUES (1, 1)\n', ```
It would be a bit more clear like: ``` {field_name: (field_name_other_table, other_table) for field_name, other_table, field_name_other_table in self.get_key_columns(cursor, table_name)} ```
```suggestion row = cursor.execute(""" SELECT sql FROM sqlite_master WHERE type = 'table' AND name = %s """, [table_name]).fetchone() if not row: return {} sql = row[0] ```
```suggestion Return a list of primary key columns for the given table. ```
Please remove the unnecessary trailing comma and space.
Maybe `_` instead of `seq`, because it's unused.
Chop "Helper function that" "Return ..." (use PEP 257 verb style)
UnqiueConstraint is suggested instead of unique_togather in newer versions [2.2+]
Please add trailing comma.
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
`"""Return the index at which the ordering expressions start."""`
No need for `keys()` here.
I think there's a constant for `'self'` as well somewhere in `django.db`.
I guess `self` probably can't be used as a field name very well, e.g. ``` >>> MyObject.objects.create(data='bar', self=my1) TypeError: manager_method() got multiple values for argument 'self' ```
Dot is missing: `'Choices are: %s.'`.
This is compliant with the PEP8 rules that we care about, let's not make the diff bigger than needed.
I made a few edits and squashed commits but before I push those updates I wanted to ask if this test is really needed. None of the changes seem related to verbosity so this test seems unnecessary to me.
Why's that? It's non-obvious at first glance.
non existing -> nonexistent
Copy / paste? I would have expected the ordering to change for the `duth1` and `duth2` arguments.
You could use single quotes in all strings for consistency (don't worry about existing tests).
Maybe `# If the expression can be used in a WHERE-clause.`.
Right, so let's move it above the `# aggregate specific fields`.
We should move it out of the "aggregate specific fields" section. Maybe: ```suggestion # Func() specific fields. empty_result_set_value = NotImplemented ```
`for_save` is True for inserts and updates, so you can remove this and put the fielderror into the resolve_expressions that make sense.
Do we need a new flag? IMO it's unnecessary. It should be feasible to detect this automatically in the system check, e.g. with `_get_expr_references(expression)`.
I'd do: ``` kwargs['separators'] = kwargs.get('separators', (',', ':')) ``` On Wed, Aug 21, 2013 at 8:06 PM, Tim Graham notifications@github.comwrote: > In django/contrib/messages/storage/session.py: > > > ``` > > else: > > self.request.session.pop(self.session_key, None) > > return [] > > ``` > > > > + > > - def serialize_messages(self, messages): > > - encoder = MessageEncoder(separators=(',', ':')) > > look ok? https://gist.github.com/timgraham/dc1cc1abe202d3830eab > > — > Reply to this email directly or view it on GitHubhttps://github.com/django/django/pull/1488/files#r5903355 > .
I'd move the `separators=(',', ':')` into `__init__` of `MessageEncoder`, so we always get "efficient" (having '__json_message' as key doesn't look to efficient ;)) json without having to specify it everywhere. But we can do this in a 1.6 cleanup commit after committing this.
If we went with `get_model_class()` above, this could simply be `model`.
To verify this is the expected import error, I'd do something like: `self.assertRaisesMessage(ImportError, 'nonexistent')`
Positional arguments cannot follow keyword arguments.
I think the idea is `sortable_by = None` is the default case of all fields sortable and `sortable_by = ()` means no fields are sortable.
I'll suggest `sortable_by` as a possible alternative name to `orderable_by`. I think the use case Ramiro suggested would be good to support.
Remove this blank line.
You should be able to skip that line
Ah, you're right. makes sense, then.
Is this check only applicable to the `if request is None` branch? I'm not sure.
else isn't needed
Can you put this block in a helper? ``` context_kwargs = _adams_helper_with_a_good_name(...) ```
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
revert this change since you ended up removing has_permission here
It allows many new schemes that weren't allowed before.
I don't think we should go so deep into validation, we opt out from numbers but at the same time we allow the whole unicode range. Unicode numbers like `๑` would happily validate therefore it's an uphill battle. I'd opt for a vastly simplified regex to validate FQDN: `'(?:[a-z0-9\u00a1-\uffff-]+\.?)+'`. Sure it'll let some invalid segments go through (e.g. leading/trailing hyphens) but at least it doesn't pretend of being exhaustive. Proper validation requires a parser anyway.
I think we should include `*args, **kwargs` and pass them to the super `__init__`
`localhost` or rather `localhost.` is a FQDN, that shouldn't require a special case.
Forgot to mention earlier, but on first look I found `[a-z-' + ul` a little confusing because of the dash between two ranges that actually serves as a dash and not a range separator. I think it would be more readable as `[a-z' + ul + r'-]` (similar to how it is in `domain_re` above).
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
Tests for this method seem missing. It seems like we need a better way to build these reprs that's not so complicated and repetitive for each index.
It looks like there will be a SQL syntax error due to a trailing comma if gin_pending_list_limit is used without fastupdate. Maybe `with_params` should be a list and joined with `', '`.
This needs an update following 831358f23d545b8dba017c6b26bd295ba9f6c17d.
You can't assume the presence of `self.name` here
You need to make the changes.
That must be `connection.features.can_rollback_ddl` and doesn't have to rely on a default value ```suggestion self.output_transaction = migration.atomic and connection.features.can_rollback_ddl ```
This small optimization is not related with fix. Merged in e12fea24f06f8911ddc2af1d6cbfb1adb529c1f2.
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
This must use `mock.patch` else it will leak between tests as the connection. Also it should be `connection.features.can_rollback_ddl` and not `connection.can_rollback_ddl`.
I think it's okay to use the variable, IMO, especially since it's used twice further down.
Just to be clear, I meant `processes` variable. But if you want to go with the other suggestion, I won't object.
I can have a look after lunch @adamchainz — thanks for your work! 🏅
```suggestion with self.time_keeper.timed('Total database setup'): ```
Historic moment! I don't see a reason why we shouldn't use them.
I'm in the habit of including an trailing , for all QuerySet filter kwargs.
Since the existence of instance lookups will be rare I suggest we avoid an unncessary dict creation when `instance_lookups` is missing ```suggestion if not (instance_lookups := self.__dict__.get("instance_lookups"): return class_lookups return {**class_lookups, **instance_lookups} ```
This could have been `clone._prefetch_related_lookups += lookups`.
Use `self.assertCountEqual()` when ordering is not specified and we have more than one expected result.
Please use a single quote.
Do we need to call `render()`? It looks unnecessary.
```suggestion self.assertEqual(response.headers['x-foo'], 'foo') ```
Do we need to call `render()`? It looks unnecessary.
Maybe test whether `r.headers['x-foo']` is set or something? (`CaseInsensitiveMapping` itself is probably thoroughly tested but it may be useful to verify the case insensitivity here too)
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
Or even go so far as to split them into three tests - one assertion per test. Then if one fails it won't prevent the other two from passing, etc.
Looks good, on a cosmetic level, I wouldn't group the queryset declarations at the top but declare them before each assertion.
How about changing `second` to args/kwargs like `cols, primary_key=False, 'unique=False, ...` and then the assertion becomes `assertDetails(constraint, ['up_votes'], check=True)`. No need to repeat all the other values.
Hi, this name should be assert_foreign_key_exists
Could you please follow the previous indentation style :)
A list comprehension is preferable here as `str.join()` converts to list internally anyway. ```suggestion ', '.join([ f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields) ]), ```
Spaces around `=` and PostgreSQL docs have `EXCLUDED`. ```suggestion ', '.join(f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields or ())), ```
As far as I'm aware `unique_fields` should be required when `supports_update_conflicts_with_target` is `True`, so there is no need to use `unique_fields or ()`. Moreover, we should raise an exception when it's not provided.
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
Chop blank line.
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
We should also test for `events = Event.objects.filter(group__in=groups.query)` to test both `isinstance(self.rhs, QuerySet)` branches.
URL patterns may change over time, so we can restore the different match :thinking:
Wrap lines closer to 79 characters and use () when referring to a function. ``` # get_current_site() will lookup a Site object, so these must match the # domains in the MockSite model. ```
We should have a more generic solution and deep-copy all non-picklable attributes, e.g. ```python for attr in self.non_picklable_attrs: if hasattr(self, attr): setattr(obj, attr, copy.deepcopy(getattr(self, attr), memo)) ```
Replace "items" with "values"
Can you use `self.assertNumberMigrations()`, `self.assertOperationTypes()` and `self.assertOperationAttributes()` instead of things like `self.assertEqual(first_action.__class__.__name__, "AlterUniqueTogether")`, please. Have a look through at the top of the test case on which arguments they expect and how they work. They are also heavily used all over the place in the autodetector tests. (A overall cleanup is in #3564.)
Please use the helper methods `self.assertOperationType()` et. al.
Can you add a `call_count` check, please: https://github.com/django/django/pull/4901/files#diff-c11e6432df7086eda3dfb9ab8e5b2839R1491
use the same style as before: ``` self.get_changes([ [...], [...], ) ```
`for (app_label, model_name), through in sorted(self.new_through_models.items()):` saves you the next line and is still readable.
I am not sure what the "rem" prefix means
please try to make this line fit in 119 chars
Nitpick but `dict.get` default value for a missing key is already `None`.
Are you sure this branch is ever skipped? AFAIK `auto_created` models are not part `ProjectState.models` entries.
I don't see a need for the `ingredients` variable.
I'm not sure if there are lookups where it's not the case, but comparisons such as `Choice.objects.filter(votes__gte='2')` seem to work fine with the value as a string so the "transform" stuff seems unnecessary, at this for the first version of this.
This test should catch `IntegrityError`, e.g. ```python def test_order_by_update_on_unique_constraint_annotation(self): # order_by() with annotate references are ignored. with self.assertRaises(IntegrityError): UniqueNumber.objects.annotate( number_inverse=F('number').desc(), ).order_by('number_inverse').update( number=F('number') + 2, ) ```
Need to test that result is as expected, not only calling it.
You could use `self.subTest()`, e.g. ```python def test_order_by_update_on_unique_constraint(self): tests = [ ('-number', 'id'), (F('number').desc(), 'id'), (F('number') * -1,), ] for ordering in tests: with self.subTest(ordering=ordering): updated_count = UniqueNumber.objects.order_by(*ordering).update( number=F('number') + 1, ) self.assertEqual(updated_count, 2) ```
Don't use `.items()` if you don't need the values. ```suggestion # Set timeout for each key individually as .mset() doesn't support # setting the timeout for all keys at the same time. for key in data: if timeout is None: client.persist(key) else: client.expire(key, timeout) ```
Ah, yes. Good observation. 🙂
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
I think that we should unpack `self._options` here and make them arguments of `RedisCacheClient.__init__()`. ```suggestion return self._class(self._servers, **self._options) ``` This is how we approach this for all of the memcached backends using client classes implemented in third-party packages.
Please move `add()` above `get()` to keep the order consistent with the definition in `BaseCache` and other backends. (It's probably worth ordering the methods in `RedisCacheClient` in the same way.)
Since this is only being used in one test case class, I would put it right before that test case class. If it turns out to be useful for other tests, it could always be moved to a more central location and modified as needed, etc.
`SELECT * FROM (SELECT "_SUB".*, ROWNUM AS "_RN" FROM (%s) "_SUB" %s) WHERE` ... (`ROWNUM AS "_RN"` should be part of the SELECT clause, not FROM clause).
if no app*
For the sake of clarity with the bug report, can you check for `'b"' not in output` :)
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
We can remove the `elif`s and `else here: ```suggestion if lookup_type == 'week_day': return (dt.isoweekday() % 7) + 1 if lookup_type == 'iso_week_day': return dt.isoweekday() if lookup_type == 'week': return dt.isocalendar()[1] if lookup_type == 'quarter': return ceil(dt.month / 3) if lookup_type == 'iso_year': return dt.isocalendar()[0] return getattr(dt, lookup_type) ``` We'll have to wait until we're Python 3.9+ only to use `.week` and `.year` on the result of `dt.isocalendar()`.
This could be simplified to match the implementation in `_sqlite_datetime_extract()`: ```suggestion month_in_quarter = ceil(dt.month / 3) ```
Ah, sorry. Misread these. One gets the quarter number, the other gets the first month of the quarter. Ignore me.
Sure, perhaps `ValueError` is better. I think PostgreSQL does the nice thing here - silently returning the value unchanged is ugly. Given this is our own implementation, having a third way - returning `NULL` - isn't great. We should align to one of the other two behaviours, and raising an error seems best.
Error is raised only on PostreSQL. On Oracle and MySQL we simply return the same date. Even if we want to raise an exception on SQLite, `NotImplementedError` is probably not the best choice. It's not sth that will or may be implemented in the feature. I'd use `ValueError` as we do in similar cases.
`str` -> `six.string_types` for compatibility with Python 2.
@MarkusH - that looks good to me.
@coldmind With the current code, `passed_check` will be `True` if `settings.ALLOWED_HOSTS` IS empty. That is backwards. `passed_check` should be `True` if `settings.ALLOWED_HOSTS` is NOT empty.
@akulakov `passed_check` is to check if list is not empty. if it is not empty, method will return no error, otherwise error will be returned (`[] if passed_check else [W020]`).
`not statement` is used several times above, so need to be consistent in code style.
Please wrap at 79 chars.
Wrap strings at 79: ``` 'You have provided values in the LANGUAGES_BIDI setting that are not in ' 'the LANGUAGES setting.', ```
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
I would keep `if not ...` in the same line.
What about m2m and reverse relationships? Something like `Q(cities=3)` will also produce the join.
If it's an expression its source expression tree should be walked (recursive `get_source_expressions`) and when the expression `isinstance(expr, str)` then you'd need to use split it using `LOOKUP_SEP`. The first part should be used to retrieve the field (`_meta.get_field(parts[0])`). If it's a related field (`field.remote_field is not None`) then you are trying to `JOIN` and it's disallowed.
Looks like we just need to use `_meta._get_fields(reverse=False)`.
I think the function can be simplified to ```python @classmethod def _get_expr_fields(cls, expr): fields = set() if isinstance(expr, Q): for child in expr.children: if isinstance(child, tuple): lookup, value = child fields.add(lookup.split(LOOKUP_SEP)[0]) fields.add(cls._get_expr_fields(value)) else: fields.update(cls._get_expr_fields(child[1])) elif isinstance(expr, F): fields.add(field.name) elif hasattr(expr, 'get_source_expressions'): for src_expr in expr.get_source_expression(): if isinstance(src_expr, str): fields.add(src_expr.split(LOOKUP_SEP)[0]) else: fields.update(cls._get_expr_fields(src_expr)) return fields ``` And you call it directly with `constraint.condition` and `constraint.check`. An alternative would be to create a `sql.Query` object and try to add the where object while disallowing joins https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/constraints.py#L101-L102 https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1361-L1362 This will raise a `FieldError` if there's an attempt at joining https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1660-L1684 But the message won't include the name of the culprit which be a blocker here if we want to provide adequate hints.
Something like ```python elif hasattr(child[1], 'get_source_expressions'): for expr in child[1].get_source_expressions(): if isinstance(expr, str): fields.add(expr.split(LOOKUP_SEP)[0]) else: fields.update(self._get_check_or_condition_fields(expr) ```
We can move the test that involves `login()` to the other pull request.
As `clean()` can also raise `ValidationError` if overridden I would avoid calling it here and stick to calling `normalize_username()`.
I'd only use mock as a last resort and instead pass some email that will be affected by the normalization.
What about using the global user model's `normalize_username` method while returning an instance of `self.model`? ```python GlobalUserModel = apps.get_model(self.model._meta.app_label, self.model._meta.object_name) username = GlobalUserModel.normalize_username(username) password = GlobalUserModel.hash_password(password) user = UserModel(username=username, email=email, **extra_fields) user.password = password user.save(using=self._db) return user ```
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
This crashes: ``` Complete output from command python setup.py egg_info: Traceback (most recent call last): File "<string>", line 1, in <module> File "/tmp/pip-K04os1-build/setup.py", line 36, in <module> """.format('.'.join(REQUIRED_PYTHON), '.'.join(HAS_PYTHON))) TypeError: sequence item 0: expected string, int found ```
Such an extensive docstring is not necessary, IMO.
The setuptools version is (in practice) not an issue: In the rare case that someone force a source-install (by using the `--no-binary`) flag, then pip will get the sdist, try to build it, which will fail on too-old setuptools. This is/was more of an issue for project like numpy, that do not have universal wheels, and thus for most linux users where pip would get the sdist (by default of not finding a compatible wheel). Now that there is the manylinux1, it not really an issue. And anyway django have an universal wheel. Python version check also happen before setuptools version matters, so users that have old setuptools may not even see that. So IMHO the setuptools is unnecessary. The only potential help is the correlation between setuptools version and python version, so Python 2 users are more likely to have an old setuptools. I can't judge how frequent this may be in the Django community.
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
``` # Environment variables are ignored in non-interactive mode, if provided. ```
This also can be simplify: ```python call_command( 'createsuperuser', interactive=False, username='test_superuser', email='joe@somewhere.org', stdout=StringIO(), ) user = User.objects.get(username='test_superuser') self.assertEqual(user.email, 'joe@somewhere.org') self.assertFalse(user.has_usable_password()) ```
This can be single-lined.
I don't think that this test is required.
Ahh, I see! Thank you for the quick reply! Learning a lot from these PRs! :)
Can we move this function up by `get_traceback_highlighter`. (That way we keep the two related helper functions next to each other.)
This is only used once. Can we move it back to the `color` module? (That way `termcolors` is still only ever used by `color`)
Something is wrong with the indentation here, you might want to use `flake8` from the top directory to spot warnings.
I think we can drop the empty line here.
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
```suggestion f"App '{app_label}' does not have migrations." ```
There is no need to resolve replaced/applied migrations so I would pass `None` instead of the default connection: ```suggestion loader = MigrationLoader(None) ```
I would use f-strings for these messages.
```suggestion # Validate app_label. ```
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
use: `any(name for app, name ... )`
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
"tables or columns it would create"
"CreateModel and AddField"
I think we need to ignore models with `managed=False` or `proxy=True` here as they never receive any database level operations anyways.
Do we need this mapping? We could redirect to a `HttpResponse` with the `status_code`, e.g. `HttpResponse(status_code=r.redirect_type)`.
This should use longer lines (up to 119 characters) or hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
As above, since `process_request()` returns a response, the second test isn't needed (see 434d309ef6dbecbfd2b322d3a1da78aa5cb05fa8).
This is minor, but I'm curious -- any reason to use `[::-1]` over `reversed(settings.MIDDLEWARE)`? I think the latter is clearer, and if micro-optimization is a concern (shouldn't be here), I think it is better, as it just creates an iterator over the original list.
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
`CANONICAL_RANGE_BOUNDS` is unnecessary: ```suggestion def __init__(self, *args, default_bounds='[)', **kwargs): ```
I saw that you're now handling this at the database level. It makes more sense to me.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
Do we need this check? All tests pass without it.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
I'd reverse the ordering and say "use list instead of []"
no dash in "email"
its so that, for example, a ...
Since the list is in order of most common use, the code detects incorrect passwords slightly faster if you preserve the order. :bikeshed:
Oh I missed that. Sorry!
No need to construct a new `dict` and call `dict.update()` here. Also the key ought to exist in the map or something has gone drastically wrong, so no need to use `dict.get()`. ```python return_dict[key_map[key]] = value ```
Use literals please - `[]` for `list()` and `{}` for `dict()`. Also, something like `result` would be a better name than `return_dict`.
Please add a trailing comma to this line.
Please add a trailing comma to this line.
This is fine as-is. It is well known that iterating over a dictionary iterates over the keys. Also this is explicitly returning a `list` and not an iterator (as is the case with Python 3). Try out `type({}.keys())` to see the difference.
The existing text looks correct to me. If validation is skipped (skip_validation=True), the calling code should call validate_consistency() to do that instead of having this method do it.
Could you please keep the cross-app reference that we had before.
Style: Can you move that `add_child()` above `add_parent()`.
When you keep sets for `parent_keys` and `children_keys` on a `Node` you don't need a lambda here. Not sure if that's worth it though.
Well, I guess we should take the node instances then.
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
Maybe `By default, return the django.contrib.admin.utils.get_deleted_objects.` instead of `By default this just returns django.contrib.admin.utils.get_deleted_objects.`.
" allowed to be deleted permissions" seems like a typo.
Following the existing docstring pattern of wording like "Hook for..." seems useful.
This can be single lined.
I think that's fine.
If you could add `# for allow_tags deprecation` besides this line and the others `@ignore_warnings` in this file, that's helpful when removing deprecated features. Thanks!
No, it would be admin specific so it doesn't belong there. Just a private API mixin for the Django tests is that I was thinking. It might live in this file, for example.
It's ugly either way, but this way might make it slightly easier to debug if the test fails at some later point. ``` python plot_details_field = list(list(list(response.context['adminform'])[0])[3])[0] self.assertEqual(plot_details_field.field['name'], 'plotdetails') self.assertTrue(plot_details_field.is_readonly) self.assertEqual(plot_details_field.contents(), 'Brand New Plot') ``` I guess it we used the pattern more widely, it might be worth some helper functions to make it easy to extract fields without using magic numbers in the indexing.
Actually `assertContains` checks the `status_code` too, so the other assertion is redundant.
I think wrapping in `Point()` is causing the test crash.
```suggestion functions.FromWKT(Value(g.wkt)), ```
I'm in the habit of including an trailing , for all QuerySet filter kwargs.
Why? IMO using regexp is less readable. This is not a really complicated comparison, I can imagine only one case when this can be broken in the future i.e. when Oracle unify their implementation with other dbs. Honestly I would like to catch this.
I was close to restore a regexp :wink:, but let's leave it as it is. Thanks :+1:
We don't need this skip.
Could we check if we actually need this `with` statement again? Maybe the one above is just fine? :man_shrugging:
I added a small hook for this.
In most of cases names won't contain multibyte chars, so it should be worth avoiding multiple encoding and slicing, e.g.: ```python if len(table_name.encode()) == len(table_name): table_name = table_name[:other_length] else: # Shorten table name accounting for multibyte characters. while len(table_name.encode()) > other_length: table_name = table_name[:-1] ```
It sounds like maybe index_type could be used as the suffix and this method doesn't need that argument. I guess the question is whether index_type should be limited to 3 characters or if truncating the first 3 characters of "index_type" as the suffix is okay.
If I can bring a little bit of nuance to my position. Yes, Python supports aware time. However, the majority opinion in Django contributions (AFAIK) is that using this feature is likely to result in worse design than not using it. Many users aren't experts able to delineate narrow sets of circumstances under which code manipulating aware times is more likely to be correct (e.g. "my code will never be used outside HK and HK will never introduce DST [alternative: I will write a unit test that fails if HK ever introduces DST]"). The recommendation would be to manage the time and the timezone in separate objects. There are other cases where Django diverges from Python's standard behavior. For example, I have found the transaction behavior mandated by PEP 249 less than helpful for most users and I have decided to default to autocommit in Django instead.
, -> and
At first sight it could be simplified to: ``` [option not in [None, False] for option in mutually_exclusive_options].count(True) ``` But I have a feeling even more simplification might be possible. Note that we can't simply cast default to bool, which would make this even simpler, as some valid dates evaluate to false: https://mail.python.org/pipermail/python-ideas/2014-March/026446.html
I see the idea, but for me if a function is called only once and only contains some simple lines, the function call overhead is not worth it. You can let this for now and wait for the Django fellows opinion.
Ideally this would be passed as a parameter instead of being baked into the SQL. Maybe adding a `%%s` placeholder and inserting the format string at `params[0]` would work? ```python template = "strftime(%%s, %(expressions)s)" sql, params = self.as_sql(compiler, connection, template=template, **extra_context) format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' params.insert(0, format_string) return sql, params ```
You can pass `verbosity=0` instead to completely silence the command instead of creating an unused `StringIO` container.
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
```python mo_file_en.with_suffix('.po').touch() ```
Given these methods are all wrapped in `assertTrue` calls they should probably be converted to `assert_all_exists` and `assert_none_exists` that perform the assertion themselves. e.g. ```python def assert_all_exists(self, dir, langs): self.assertTrue(all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ))
Ditto ```suggestion return all( not os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
Move that below the `csrf_processing_done` -- we do not need to do extra work in that case.
Again single quotes
Use single quotes to stay consistent with the code above.
add trailing comma
`getattr` raises an exception when the attribute doesn't exist and no default is given
suggested format: #19820 - Deserializer should give a helpful error message ....
To avoid creating an extra table, it seems you could use a local test model without any trouble. `s.serialize([ScoreDecimal(score=decimal.Decimal(1.0))], cls=CustomJSONEncoder)`
The current development version of Django support Python 3.8+, so this note and workaround are unnecessary.
I didn't get a deserialization error with this test_string: ``` test_string = """[{ "pk": 1, "model": "serializers.article", "fields": { "author": 1, "headline": "Unknown many to many", "pub_date": "2014-09-15T10:35:00", "meta_data": [ ["author", "meta1"] ] } }, { "pk": 1, "model": "serializers.author", "fields": { "name": "Agnes" } }, { "pk": 1, "model": "serializers.categorymetadata", "fields": { "kind": "author", "name": "meta1", "value": "Agnes" } }]""" ```
Instead of simply `list(....)`, use this: ``` with self.assertRaisesMessage(serializers.base.DeserializationError, expected): objects = serializers.deserialize('json', test_string) for obj in objects: obj.save() ``` You could also just omit the `CategoryMetaData` object from the fixture and create it with the ORM.
Please move it above `'tr'`.
Obviously this is unwanted changes.
Yep. Looks good @felixxm
You can drop this line.
prefer if you use hanging indent style for this assertion to match the other tests
In Thailand it’s customary to use the [Thai solar calendar](https://en.wikipedia.org/wiki/Thai_solar_calendar) system (as it’s the official legal calendar in Thailand). Dates and months are the same as the common Gregorian Calendar, but years are in Buddhist Era instead of the Christian/Common Era. Just add 543 to the year number when displaying, and subtract 543 from the year number when parsing.
Is it possible to convert year type? (e.g. 2006 &rarr; 2549)
OK then, thanks for the references.
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
Are you sure? Should this not be consistent with `SHORT_DATETIME_FORMAT`, i.e. `SHORT_DATE_FORMAT = 'j N Y'`.
Use `self.assertIs` and `self.assertIsNot` as these boolean expressions are noop.
Bad conflict resolution -- urls attribute is deprected in favor of `@override_settings(ROOT_URLCONF='view_tests.urls')`
I think the name could be a bit more specific like `include_with_dollar` to prevent clashes with possible future checks that involve include, slash, or name. Maybe a `views.py` for the dummy view so we don't need to define it in every urls file would be an improvement as well (or even something like `lambda x: x` in place of an actual view might work).
I see the old tests do this, but (AFAICS) there's no reason to to store `post_data` on `self`. (It's not accessed outside this test case.)
prefer assertRaisesMessage to verify the message contents as well
a single line is fine here (up to 119 chars is okay if it helps readability)
chop "Make sure" in favor of simply stating the expected behavior. The ticket reference isn't really needed -- we reserve that for obscure issues.
use single quotes
chop ticket number
chop blank lines here and below
`str(self.band)` doesn't seem like a realistic value for the message.
Single line here is fine (as the style guide says, we allow up to 119 characters if it improve readability).
This test belongs with the tests for the delete action in `tests/admin_views/test_actions.py`.
put this tuple on a single line
Blank line not needed.
I guess this should be more specific like `CheckTemplateSettingsAppDirsTests`
Add a trailing comma.
Please use 4 space indent as done in other `self.assertEqual` assertions in the file I mentioned.
Please use 4 space indent: ``` templates = [{ 'BACKEND': ... }] ```
I see, thanks for your answer. I really don't want to hold the template based widget stuff from landing any longer. I suppose this is something we could refactor later on.
This -> These
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
move this to an else block in (try/except/else)
They can only be decoded if these bytes were previously encoded in this encoding.
simpler: "must be a string"
Yes, I think Django would be obviously broken in such a configuration anyway.
I don't think there's a use case for `settings.AUTHENTICATION_BACKENDS` without any backends that have a `get_user()` method.
I'd suggest something like: ``` 'You have multiple authentication backends configured; ' 'you must provide the `backend` argument or set the `backend` ' 'attribute on the user.' ``` You can omit the plus sign.
I'd revert this as I don't think it is better and it isn't making this more consistent with code elsewhere. ```suggestion if isinstance(stored_backend, RemoteUserBackend): ```
`print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-'))`
@hramezani I think you removed `setattr(options, opt_name, os.path.normpath(opt_val))` by mistake. My proposition was to remove only `else`, i.e. ```python if '.' in opt_val: print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-')) sys.exit(1) setattr(options, opt_name, os.path.normpath(opt_val)) ```
IMO `else`is unnecessary i.e. ```python if '.' in opt_val: ... setattr(options, opt_name, os.path.normpath(opt_val)) ```
Please add trailing comma.
We should support `--shuffle` with `--bisect` and `--pair`, i.e. handle it in `get_subprocess_args()`.
You are leaking information about whether somebody has access or something doesn't exist.
Raising a 404 with the same message as in the previous check would mask the issue. Then again I think we already leak a lot like that in other admin pages, will have to double check.
Slow or not, it is kinda pointless to do since we do not need the data -- so yeah, we should not count here
Yeah, this is a good point, reuse an ordering if possible (maybe even force it)
Add a message please.
This seems like an odd place to put this... between the logging of test database creation and the actual creation. Actually, it might be possible to call `connection.creation.mark_expected_failures_and_skips()` in `runtests.py`. That would be cleaner and eliminate the need for the environment variable.
An error the database
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
`BaseDatabaseCreation` shouldn't contain branches for specific backends.
param -> params
An optimized `__bool__` definitely makes sense. On the other hand (as mentioned in the ticket), the queryset is (now, since 1.11) only shared per form instance, and not per form class. Given that, an alternative approach would be to remove the `.all()` in `__iter__`, and indeed reuse the queryset for the lifetime of the form-instance.
Since we don't use the results `.count()` is definitely more appropriate here.
In which cases does `__len__` gets called by the form layer? I'm asking because if it's only to allow third party to do `if field.choices` we better be implementing an optimized `__bool__` as well because `.count()` can perform bad on large resultsets. ```python def __bool__(self): return self.field.empty_label is not None or self.queryset.exists() ```
@tchaumeny reverted fa534b9 here.
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
Actually removing the trailing parentheses (e.g. `CURRENT_TIMESTAMP`) should work on all backends including SQLite.
This will require an `as_oracle()` with `self.template = 'CURRENT_TIMESTAMP'` on the other end.
> Paolo, Can you take a look? (\cc @pauloxnet) point_up Sorry, I totally missed the notification of this. I'll take a look
Do we need to swap arguments? IMO we want to keep the same order as in `SIMILARITY()` calls. ```suggestion class TrigramWordSimilarity(TrigramBase): function = 'WORD_SIMILARITY' ``` e.g. - `TrigramWordSimilarity('Cat sat on mat.', 'cat')` should be equal to `0.30769232` instead of `1` - `TrigramWordDistance('Cat sat on mat.', 'cat')` should be equal to `0.6923077` instead of `0`
I would use the same order as the previous two classes (`TrigramSimilarity` and `TrigramDistance`): ```suggestion class TrigramWordSimilarity(TrigramWordBase): function = 'WORD_SIMILARITY' class TrigramWordDistance(TrigramWordBase): function = '' arg_joiner = ' <<-> ' ```
Interesting. I just tried it. This returns 2. ``` def func(): try: return 1 finally: return 2 ```
Anyway, good practices include: - keeping the try clause as small as possible - avoiding multiple returns Hence the correct idiom is: ``` try: import autopep8 except ImportError: pass else: prepared_migration_statement = autopep8.fix_code(prepared_migration_statement, ...) return prepared_migration_statement ```
please move this to `except` and return `autopep8` result in `try`
Can you use hanging indents here: ``` python a = b( c, d=e, ) ```
Remove the parentheses, please.
`assertRaisesMessage()` (this test is broken) as it doesn't pass` on_conflict='ignore'`.
Use single quotes please.
`field` variable is unnecessary: ```suggestion msg = "TwoFields has no field named 'nonexistent'" with self.assertRaisesMessage(FieldDoesNotExist, msg): TwoFields.objects.bulk_create(self.data, update_conflicts=True, update_fields=['nonexistent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ```suggestion msg = ( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ```
Ah ofcourse, my bad, you're right. Looks good to me.
could move this to the previous line while you're here
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
same issue as with obj_refs_aggregate
Patch LGTM. Do you think it might be worth removing the code duplication for the `negated` case while were around? It looks we're simply reusing the same logic wrapped in `'(NOT %s)'`.
Constructing the entire string within the as_sql method departs from how other functions work. Is it possible to do something like: ``` class BaseCaseExpression(Func): function = None template = 'CASE %(simple)s %(conditions)s ELSE %(default)s END' ``` Then build up the dict required to fill in that template, and construct/return at the end? It may flow nicer, and allow 3rd party backends to modify the template without overriding the entire method.
We shouldn't silently change passed parameters. IMO it better to raise an exception like we do now: ``` $ export DJANGO_SETTINGS_MODULE=test_oracle $ ./runtests.py queries --parallel=2 Testing against Django installed in '/django/django' with up to 2 processes Found 416 test(s). Creating test database for alias 'default'... Creating test user... Cloning test database for alias 'default'... Traceback (most recent call last): File "./runtests.py", line 659, in <module> failures = django_tests( File "./runtests.py", line 385, in django_tests failures = test_runner.run_tests(test_labels) File "/django/django/test/runner.py", line 881, in run_tests old_config = self.setup_databases( File "/django/django/test/runner.py", line 787, in setup_databases return _setup_databases( File "/django/django/test/utils.py", line 217, in setup_databases connection.creation.clone_test_db( File "/django/django/db/backends/base/creation.py", line 239, in clone_test_db self._clone_test_db(suffix, verbosity, keepdb) File "/django/django/db/backends/base/creation.py", line 255, in _clone_test_db raise NotImplementedError( NotImplementedError: The database backend doesn't support cloning databases. Disable the option to run tests in parallel processes. ```
Would it be better to move this log message to after where `parallel` is done being computed below? Otherwise, if `parallel` needs to be reset to `1` below, maybe that can be logged below so people know it was changed.
Okay, I could take a crack at some of that follow-up clean-up afterwards, if you want.
```suggestion time_keeper = TimeKeeper() if options.timing else NullTimeKeeper() with time_keeper.timed('Total run'): ```
```suggestion time_keeper.results() ```
```suggestion for table_name, table_rows in rows: ```
[This is only an estimate on InnoDB tables](https://dev.mysql.com/doc/refman/5.7/en/tables-table.html) which is the default table engine and what's used on CI. > The number of rows. Some storage engines, such as MyISAM, store the exact count. For other storage engines, such as InnoDB, this value is an approximation, and may vary from the actual value by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate count. In short that means this value could report 0 while there's actually rows in the table and cause errors similar to the one you are experiencing.
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
Chop blank line.
Tests are failing for a different reason due to qwirks with our CI system; notice that SQLite tests are failing as well.
extra space after [
You don't need to mock, it will return `False` for a bad file descriptor.
Instead of defining `success`, just return directly in the above code. I think it is simple enough.
I would rather try to create a second non-blocking lock: ```suggestion file_path = Path(__file__).parent / 'test.png' f1 = open(file_path) f2 = open(file_path) self.assertIs(locks.lock(f1, locks.LOCK_EX), True) self.assertIs(locks.lock(f2, locks.LOCK_EX | LOCK_NB), False) ```
You need to specify a type of lock, e.g. `locks.LOCK_NB | locks.LOCK_EX`. Currently it returns `False` because we passed an invalid argument.
We want to avoid a `GETS ` here. What's the rationale for not simply returning `self._cache.delete(key)`? This is prone to race conditions anyway.
`python-mecached` should return the right value as long as we don't pass `noreply=True` to `delete` which we don't. https://github.com/linsomniac/python-memcached/blob/bad41222379102e3f18f6f2f7be3ee608de6fbff/memcache.py#L548-L575 And `pylibmc` should work as well https://github.com/lericson/pylibmc/blob/d8bafe91f57ebdd73f76eb80bdb4d4a515c7fc48/src/_pylibmcmodule.c#L1445-L1451
Remove the blank line here.
ditto no need for `else`
Do we need to call `bool()`? `touch()` returns `True` or `False` according to `pylibmc` docs.
prefer hanging style: ``` return { self.fk_field: ..., } ```
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
I would use `%s` formatting consistently.
This would be more readable as a one-liner: `predicate = inspect.isfunction if six.PY3 else inspect.ismethod`
Correctly indent the bracket to match the `return` indentation.
I'm not exactly sure what "straight away" means here. I wonder if something like this could be an improvement: ``` # Registering new type handlers cannot be done before the extension is # installed, otherwise a subsequent data migration would use the same # connection. ```
A bit simpler could be "Clear cached, stale oids."
Please chop all unnecessary blank lines.
_"Use single quotes for strings, or a double quote if the string contains a single quote. Don’t waste time doing unrelated refactoring of existing code to conform to this style."_
Use single quotes.
IMO, we can use `assertEqual` instead of `assertAlmostEqual` in all tests.
I think we should avoid writing new test suites that use fixtures. Fixture loading is extremely slow, and it's actually harder, IMO, to follow what the data should look like once you've aggregated it. I would suggest either creating all the data in a setUp method, or creating the data you need at the top of each test.
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
`George. R. R. Martin` → `George R. R. Martin` (Remove the extra period, and throughout below.)
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
The main difference is that `integer_validator` is not used internally. `int_list_validator` is used in (deprecated) `CommaSeparatedIntegerField` and it's recommended as a validator for `CharField` that can be used instead. Unfortunately, values are not cast to `int()`, so non-ASCII digits can cause issues. We can change both :thinking:
@apollo13 What do you think? We can change both or neither.
OK, will revert :+1:
I'd rather build regex string with interpolation so as not to repeat the other logic.
more like: `'^%(negative)s\d+(?:%(sep)s%(negative)s?\d+)*\Z' % ({'negative': '(-)?' if allow_negative else '', ...})`
Use single quotes for the names.
We can also import `include()` from `django.urls` instead of `django.conf.urls`.
Let's be consistent about whether `app_name` appears above or below `urlpatterns`.
1. Including another URLconf
It would probably be less confusing if this were `dict(greeting='Hello!')` so we don't have so many parts called "extra_email_context".
The rest of Django's test use `@mock.patch` so I think we should use that.
Using hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Perhaps this could mock `random.choice('?.')` to test both scenarios.
Same here, not following order `(value, expected)`
Perhaps this test could mock `random.randint` to be more useful.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
please use `assertRaisesMessage` to verify this is the `TypeError` we expect (also helps for tracking which tests map to which code).
I think something like `SETTING_BOTH` will be fine. No need to memorialize the bug number.
I fixed this issue in fe0ddbc84e4d8836ce8d27a1218d360c5482c2be.
What about `prefetch_related()`? It's a new method so we should raise `ValueError` when `aiterator()` is used after `prefetch_related()`, e.g. ```python async def aiterator(self, chunk_size=2000): if chunk_size is None: if self._prefetch_related_lookups: raise ValueError( "chunk_size must be provided when using QuerySet.iterator() after " "prefetch_related()." ) elif chunk_size <= 0: .... ```
> We'll want to do something with regards to the newly added support for iterator's prefetch_related here. That looks like a _moderate_ task in itself (to implement) — `islice`, `prefetch_related_objects`, ... — it might be that adjusting the PR here match the new interface, but emitting a warning if prefetches are set would let us get this in, to work on async prefetches later. (Would be equivalent to the sync behaviour before edbf930287cb72e9afab1f7208c24b1146b0c4ec — of _either prefetch or iterator_.) 🤔
```python async with contextlib.aclosing(aiter(self._iterable_class(...))) as agen: async for item in agen: yield item ``` You should explicitly aclose your async generators when you create them: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators
We'll want to do something with regards to the newly added support for `iterator`'s `prefetch_related` here.
Shouldn't this be along the lines of ```python def iterator(self, chunked_fetch=None): if chunked_fetch is None: chunked_fetch = connections[self.db].settings_dict.get('ENABLE_SERVER_SIDE_CURSORS', True) return iter(self._iterable_class(self, chunked_fetch=chunked_fetch)) ```
```suggestion **kwargs, ) ```
```suggestion **kwargs, ) ```
Please do not change formatting
Well, we _could_ make `on_delete` an actually-required arg to `ForeignObject` right now, and move it even before `from_fields` and `to_fields`, but that would require duplicating the deprecation warning in both `ForeignKey` and `OneToOneField`.
This is a nitpick, but `on_delete` is not an attribute you set, it is an argument you pass. I think that second sentence could just be removed. What might be more useful here is a stable link to the `on_delete` docs.
We can revert this unrelated change.
I see the idea, but for me if a function is called only once and only contains some simple lines, the function call overhead is not worth it. You can let this for now and wait for the Django fellows opinion.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
I'd chop every other empty line and group the `auto_now` and `auto_now_add`, but that's just cosmetics.
I don't mind either way, it just took a second to spot the differences between the groups.
It would clear ambiguity if you added some parentheses here and on the next line: `(' LIMIT %d' % limit) if limit ...`. Initially, I thought the grouping was `% (limit if limit else '')`.
I think that: ```python return 'FOR UPDATE%s%s%s' % ( ' OF %s' % ', '.join(of) if of else '', ' NOWAIT' if nowait else '', ' SKIP LOCKED' if skip_locked else '', ) ``` is more readable.
I would remove a temporary variable (`clauses`), e.g. ```python return ' '.join(sql for sql in ( ('LIMIT %d' % limit) if limit else None, ('OFFSET %d' % offset) if offset else None, ) if sql) ```
I typically use this style to avoid such long strings near the length limit: ``` raise NotSupportedError( '...' '...' ) ``` (could also be applied in the other file)
`s/allowed/supported/` -- and coming to think of it, use `django.db.NotSupportedError`.
I don't think that SQLite can pass kwargs, so I think that this can be replaced by `if None in args`.
Please add `@functools.wraps(func)` to this.
It'd be interesting to see some numbers for doing it this way[^1], as it may be 'good enough' to obviate #14849 entirely, which would be nice from a simplicity point of view. [^1]: and indeed I'll try and check the numbers against my own at some point.
above you didn't include a blank line before each elif branch
If we `from itertools import chain` we can save the overhead of attribute access here.
I am just going to make this docstring a bit more descriptive.
Please include periods in docstrings.
Could you explain why the limit is 8? (or mention it's somewhat arbitrary)
put closing ) on the next line
Should be ``self.weight``
Silencing far more exceptions than previously (where it was `ImportError`) ... is this intentional, and will it lead to people having a harder time debugging when their app config goes wrong? I guess it'd be somewhere higher up the chained stack traces, maybe? Same expansion of caught exceptions (`ImportError` -> `Exception`) happens at the `import_string` so I assume the answer to this also answers that.
True, I missed this.
Chop trailing space.
This is here for appending to the follow-ups later. One or other is always appended so...
I would chop `simply`.
Right (actually there's a bug in that code, the `ImproperlyConfigured` can never be raised).
This logic seems a little convoluted. Consider: ``` python conns = connetions.values() if settings.DATABASE_ROUTERS else [connections[DEFAULT_DB_ALIAS]] for conn in conns: if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(router.allow_migrate(connection.alias, label) for label in labels)): ```
They should always be the same but you might want to use `model._meta.object_name` instead.
Avoid using `Test that` prefixes in docstring, this is necessarily testing something as it is a test. ``` Teardown functions are run when run_checks raises SystemCheckError. ```
```suggestion elif databases[DEFAULT_DB_ALIAS] == {}: ```
It feels like unrolling the loop by accessing `where.children[]` and inlining `_test` like in other tests do would make the actual assertions simpler to interpret in the case of future failures. I'll let the committer make the last call here though since the assertions are actually correct.
I really don't like that we increase indentation here, it make code less readable, and it's complicated even without this :disappointed: We could reduce the number of changes significantly with: ```python if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) clause.add(condition, AND) # When col is nullable, add IS NOT NULL. col = self._gen_cols(reffed_expression) if col: lookup_type = condition.lookup_name target = col.target if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None and self.is_nullable(target): lookup_class = target.get_lookup('isnull') col = self._get_col(target, target, alias) clause.add(lookup_class(col, False), AND) return clause, () ``` and reverting related adjustments.
FYI I ran into the same issue of `AttributeError: 'generator' object has no attribute 'target'".` with this test checking if this PR fixed the issue when using exclude with an `alias` (flagged up in duplicate [ticket-32896](https://code.djangoproject.com/ticket/32896)): ```python # ExcludeTests def test_exclude_aliased_nullable_fields(self): number = Number.objects.create(num=1, other_num=1) Number.objects.create(num=2, other_num=2, another_num=2) qs = Number.objects.alias(aliased_num=F('num')) self.assertSequenceEqual( qs.exclude(another_num=F('aliased_num')), [number], ) self.assertSequenceEqual( qs.exclude(aliased_num=F('another_num')), [number], ) ```
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
put closing parenthesis on the next line
I don't think that we need this check. I would rather remove from docs [note](https://github.com/django/django/blob/77d335e5abec889b15323975187a8d5b10bfcb0f/docs/topics/db/queries.txt#L965-L979) about setting `id` to `None`. That is outdated after this patch. \cc @spookylukey
> I was under the impression that only `AutoField`'s were to be made `None`. You can also set `pk` that is an `AutoField` to a string value, in all such cases Django raises `ValueError`, so I don't see any issue in it. Moreover we can have a primary key that is not an `AutoField` but has a default value, e.g. `UUIDField(default=uuid.uuid4)` and this should also work.
IMO this check is unnecessary.
`parent_link` and `field` is the same field, you can use `self._meta.parents.values()` without `zip` and `.items()`, e.g. ```python for parent_link in self._meta.parents.values(): ... ```
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
Despite the existing style of the first test, I would remove the intermediate `f` variable in the new tests as it'll help balance line lengths and make things more readable.
In the case of an empty select (`choices = []`), this will still output the `required` attribute, which is still not valid: ``` >>> class TestForm(Form): ... some_field = forms.ChoiceField(choices=[]) ... >>> t = TestForm() >>> print(t['some_field']) <select id="id_some_field" name="some_field" required> </select> ``` ``` html <!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <title>Validation test</title> </head> <body> <select id="id_some_field" name="some_field" required> </select> </body> </html> ``` Check it here: https://validator.w3.org/nu/#textarea
In each of the three cases, can you change `False` to `None` and add a trailing comma. (I think we *could* also move the placeholder line to the top to allow it to be overridden by the context, but it may not be worth it as I'm not sure the attributes passed down can be specified for each select individually...)
Does it not render with `placeholder="False"` then? Seems strange to me...
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
skip the blank line
Our convention is to include a trailing comma in places like this so if more items to the list later, we don't have to modify this line again.
reword: "force_login() skips authentication backends without a get_user() method."
prefer `setUpTestData` since that executes once per test class instead of once for every method
We can move the test that involves `login()` to the other pull request.
Use single quotes consistently.
We could lowercase the vendored files, that would help at least for the `zh-*` variants.
Cannot this information solely be extracted from the model itself? ie `.model._meta.app_label`.
It seems this URL doesn't work anymore.
no restructured text (:class:) in docstrings please
The trailing space can be removed.
email_field_name -> email_address to make it more realistic
Unnecessary -> ```suggestion def __str__(self): ```
I think `__str__` can be omitted here. If it needs to stay, `CustomUserWithIntegerUsername` should be wrapped by `@python_2_unicode_compatible`.
(inadvertence revert here too)
without the blank lines would be more readable, I think
I'd chop the blank lines around `for_update_part`.
Unnecessary list comprehension, `tuple(self.model._meta.pk.get_col(inner_query.get_initial_alias()))` should do.
This solution introduce really unexpected behavior, i.e. change every raw SQL that contains name of any column from a parent model with that column, e.g. if a parent model contains column `name` then following examples will be replaced by `"annotations_store"."name"`: - `case when name='foo' then 'oof' else 'foo' end` -> `"annotations_store"."name"`, - `concat(chain, 'name')` -> `"annotations_store"."name"`, - `other_column_with_name_in_it` -> `"annotations_store"."name"`, etc.
`regex` will be clunky. IMO unnecessary `JOIN`'s are acceptable in this case, there is not much we can do.
You are right here as well. Your version is clearer for people that understand bitwise operators the flags structure, plus its shorter. For me he more "explicit" version is easier to follow, and probably true too for other people that do not have experience with the postgis bites structure or bitwise operators. But the conciseness of your version is convincing so lets use it.
Thanks @ivorbosloper now it makes sense to me and works fine. I got confused with upper and lower bits wording. Interesting that bits are counted from right to left from that point of view, and that the mask operation works. It would not work the same way with the `BANDTYPE_FLAGS_MASK` as my example shows.
comma after tuple
How about checking for the `ValueError` on older versions? Would be nice to have a test for the `Nodata value must be numeric or None` error as well.
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
Here's a regression test that passes on master but crashes with the new version (after the deprecation warning is silenced): ``` diff diff --git a/tests/model_fields/tests.py b/tests/model_fields/tests.py index 4677962..b2845ff 100644 --- a/tests/model_fields/tests.py +++ b/tests/model_fields/tests.py @@ -31,6 +31,11 @@ from .models import ( class BasicFieldTests(test.TestCase): + + def test_get_val_from_obj(self): + f = BooleanModel() + self.assertEqual(f._meta.get_field('string')._get_val_from_obj(None), 'abc') + def test_show_hidden_initial(self): """ Regression test for #12913. Make sure fields with choices respectdiff --git a/tests/model_fields/tests.py ```
If you can try to make logical commits with the tests passing after each one as in https://github.com/django/django/pull/3770, I've found that quite helpful as a reviewer.
If possible, it would be great to try to submit cleanups like this as separate pull requests that can be merged ahead of the main composite field work. Otherwise, I fear we will end up with a monolithic pull request that will be very difficult to review.
IMO we can simplify condition: ```not self.blank or (self.blank and not self.null)``` to: ```not (self.blank and self.null)```
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
I have to admit that this still feels a bit odd to me 🤔 Especially since the tests above are expecting the initial value to be None, and we are perhaps lacking a bit of explanation why this is the case here.
Maybe instead of repeating this each time we could say something like "Corresponds to test_inlineformset_factory_nulls_default_pks for the case of ..."
You're already calling `super()` above.
Use single quotes.
Chop blank line.
This could work: it's only the `current-app`, `current-model`, `current-page` attribute values that are dependent on `request`, and for the index page app list they're always not set anyway, so it's only when the side bar is set that `request` is serving any purpose.
I was thinking about leaving it as a warning and disabling the sidebar when `request` is not provided, so about a soft requirement: - raise a warning (that will remain a warning in the future) if `enable_nav_sidebar`, e.g. ```python checks.Warning( "'django.template.context_processors.request' must be enabled " "in DjangoTemplates (TEMPLATES) in order to use the navigation " "sidebar in the admin application." id='admin.W411', ) ``` - disable a navigation sidebar (even in a template) when `request` is not provided.
OK. I'll adjust this now on that basis, so we can get it in this morning. Thanks both!
I think we should add this check only if `enable_nav_sidebar` is enabled on any site and raise an error instead of warning :thinking:
This line is horrible. 😄 Simon mentioned this in his review before but, maybe leaving up until the `and\n` as is and putting the new check on the next line, to keep the diff that bit smaller...? (I don't mind this as it is per se — whichever way we do it, it is long and horrible.)
Use `assertNotIn` instead.
Actually you should use `assertNotContains(response, '"/test_admin/admin/r/%s/1/"' % content_type_pk)` to also account for `byte` response content on py3.
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
This should go to the 2nd commit :pick:
The benefit of the extra tests is they make the HTML structure clear, but the CSS selector perhaps does that... We should use hanging indent for the wrapping, so maybe pull the CSS selector into a variable, so it's easy read/see, and then the lines would be shorter too, and we can just have the two assertions.
I don't have a strong feeling about either, this approach avoids an unnecessary intermediary list creation though.
Use a `set` if this value is only used for containment checks ```suggestion local_action_names = {self.get_action(action)[1] for action in self.actions} if self.actions else set() ```
> I'd prefer to return a list of errors rather than a single concatenated error. Is that the method I should change it to? Sorry - I didn't get around to replying, but yes, multiple works better.
This is a classic case where you may have duplicates of multiple action names but are only warned about the first one. You resolve that and then get nagged again about the next one. It would be better to list all of the duplicated names. It also probably makes sense to just count all of the names using `collections.Counter` and look directly for duplicates; to wit: ```python counts = collections.Counter(names) duplicates = [name for name, count in counts.items() if count > 1] if duplicates: return [checks.Error( ￼ '__name__ attributes of actions defined in %s must be ' ￼ 'unique. Duplicated names: %s' % (obj.__class__, ', '.join(duplicates)), ￼ obj=obj.__class__, ￼ id='admin.E130', ￼ )] ```
Please remove temporary variable `actions`, also IMO it will be clearer to unpack `action` e.g. ```python names = [name for _, name, _ in obj._get_base_actions()] ```
This docstring is the same as for `wait_page_loaded()`. Do we even need it in either case? Or perhaps the docstring should explain the difference between these two methods.
`lambda` works better on Firefox, let's leave it.
Can we use [number_of_windows_to_be()](https://www.selenium.dev/selenium/docs/api/py/webdriver_support/selenium.webdriver.support.expected_conditions.html#selenium.webdriver.support.expected_conditions.number_of_windows_to_be)? ```suggestion self.wait_until(ec.number_of_windows_to_be(2)) ``` Also, we can probably chop `self.assertEqual(len(self.selenium.window_handles), 2)` in the next line.
State the expected behavior rather than "Test ...." (all tests test things). No need for a selenium test as no JavaScript is involved. See 3aad955ea8db1592fad0012155eaa25b72e50dc5 for similar changes.
use single quotes throughout params also, if the params fit on the same line as `Thing.objects.get_or_create(` that's fine. You could change "does_not_exist" to "nonexistent" and "some_value" to "b" to save a few characters if it helps with line length.
similar to `get()` above, I appreciate the code reuse, but I personally would prefer if `get()` and `delete()` were not touched.
I think it's fine to tidy up here, we're basically just inverting the reuse where previously `delete_many` reused `delete`
huh, TIL. Transitioning to Python3 from 2.7 for my personal projects and I didn't know they had changed that. Thanks for pointing it out.
This is fine as-is. It is well known that iterating over a dictionary iterates over the keys. Also this is explicitly returning a `list` and not an iterator (as is the case with Python 3). Try out `type({}.keys())` to see the difference.
Use literals rather than functions, i.e. `{}` not `dict()`. This should come at the top of the function as the stuff before it does not need to happen if it is empty.
This isn't great and invites test state leakage - it's directly touching the internals of the code under test and not resetting it to the way it was after the tests. It would be best if a copy of `all_sites` was made and then in `tearDown` it was reset to the original state, at least Possibly fixed by #6980 anyway
We typically use an underscore prefix in a case like this: `self._previous_sites`
```python cache_params['LOCATION'] = Path(self.dirname) ```
"a DeprecationWarning" -> "an Error"
You can safely join this an the next line. You have up to 119 chars per line. ;)
```suggestion # Validate app_label. ```
Now we can call this `test_migrate_app_name_specified_as_label` (and similar for the similar test).
```suggestion f"App '{app_label}' does not have migrations." ```
There is no need to resolve replaced/applied migrations so I would pass `None` instead of the default connection: ```suggestion loader = MigrationLoader(None) ```
I would use f-strings for these messages.
We can chop this docstring.
I would rather create a custom model with field that has `db_column`, e.g. ```python project_state = self.apply_operations('test_rfwdbc', ProjectState(), operations=[ migrations.CreateModel('Pony', fields=[ ('id', models.AutoField(primary_key=True)), ('field', models.IntegerField(db_column='db_field')), ]), ]) operation = migrations.RenameField('Pony', 'field', 'renamed_field') new_state = project_state.clone() operation.state_forwards('test_rfwdbc', new_state) ```
I don't see much value in this check.
We shouldn't use the same chain on `replace()` in multiple places, use `quote_value()` instead.
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
Can you explain why it's okay to move `patch_vary_headers()`? (I know nothing about it and am just reading about it now.) Also, remove (I think) the failing test.
```suggestion request.method in ('GET', 'HEAD') ```
`response.request.method` would be more idiomatic.
Oh, that surprises me too...
```suggestion self.assertEqual(value, b'text/plain') ```
We can ignore `name`, `path`, and `args`, e.g. `*_, kwargs = field.deconstruct()`
Please add trailing comma.
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
no blank line
try to be consistent and use single quotes in most places (sorry existing code is inconsistent)
The closing parenthesis should always go on the next line.
@timgraham already pointed the code formatting of the tests. Please don't make newlines at dots, `tests/annotations/tests.py` has good examples of the style.
The blank lines in this method aren't needed.
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
No need for `Value` wrapping since 1e38f1191de21b6e96736f58df57dfb851a28c1f ```suggestion is_book=1, ``` Ditto for all `Values` uses below.
Ahh looks like you'll need to keep passing `Value` in this case but you can drop the `output_field`. ```suggestion is_book=Value(1) ```
What about ```suggestion self.assertNotIn('is_book', books.values().first()) ```
Per new code guidelines, can we use `assertIs`? :)
`self.assertIsNone` except for that the patch LGTM.
Chop blank line.
In MySQL introspection we use `table_schema = DATABASE()`, I think we should use it here.
```suggestion with self.connection.cursor() as cursor: cursor.execute(""" SELECT table_name, table_rows FROM information_schema.tables WHERE table_schema = %s AND table_name IN %s """, (schema_name, tables)) rows = cursor.fetchall() ```
```suggestion def sequence_reset_by_name_sql(self, style, sequences): return [ '%s %s %s %s = 1;' % ( style.SQL_KEYWORD('ALTER'), style.SQL_KEYWORD('TABLE'), style.SQL_FIELD(self.quote_name(sequence_info['table'])), style.SQL_FIELD('AUTO_INCREMENT'), ) for sequence_info in sequences ] ```
```suggestion for table_name, table_rows in rows: ```
Don't add a blank line.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
@romgar If you find the time that would be great!
It might be smarter to validate the token first and only modify the session + redirect if it's valid. Otherwise it makes it really easy to create a session just by GET'ing a url (possible DoS vector). It also means you can't pass `accounts/password_reset` as the token and take advantage of our `request.path.replace()` code. It probably means validating the token twice, which is slightly slower. Seems fine to me if an invalid token gets leaked.
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
Please wrap at 79 chars.
The closing ) goes on the next line.
line too long
Spaces around `=` and PostgreSQL docs have `EXCLUDED`. ```suggestion ', '.join(f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields or ())), ```
Please remove `DEFAULT-CHARACTER-SET` from all tests.
Please revert unrelated blank line. ```suggestion ```
I would either remove this or add a helpful exception message.
@tchaumeny reverted fa534b9 here.
According to the coverage report, this line isn't executed.
Exception seems okay, but I've investigated possible failure scenarios
I think this change really indicates the need for a second test for wrapping a non-string object.
Are all the `six.text_type` needed? Tests seem to be passing with at least the first one removed. Shouldn't there be tests with lazy versions of args, kwargs? It looks like these tests are mainly testing `str.format()`.
I'm not sure the docstring adds any value here.
This should go to the 2nd commit :pick:
Are both of these going through the `__radd__` path? At a glance, I'd have _guessed_ that both are using `__add__` because the LHS is a `SimpleLazyObject` which now has that magic method? I could be wrong, it has been a _long_ time since I filed the ticket, so I may be misremembering.
I think this error message isn't very helpful (i.e. it's not actionable), and it leaks an internal detail, that we monkey-patch response objects with a `templates` attribute). What happened is a detail, what we need to know is **why** it happened, so we can fix it.
`assertRaisesMessage` should be sufficient here.
I moved renaming `_assert_template_used()` to a separate commit.
I moved this to the `test()` method to avoid code duplication.
I think just `Ordering of query string parameters is ignored for distinct names. For example...`
I don't think this is necessary - this is a developer only message - it will never be displayed to end users.
Why is `force_text` needed here? `%s` should already call the correct methods.
Why this refactoring? (Touches a lot of the other tests...)
Ah, didn't know this existed yet. I see that this PR is mostly a "copy" of the ContentTypes one. Sounds alright for now, then.
It's not required here. It was used in f179113e6cbc8ba0a8d4e87e1d4410fb61d63e75 because we were handling a possible `IntegrityError`.
@charettes thanks for the idea. I made PR #7755 with regression fix.
Maybe it will be better to move `force_text` to the return line ```python return force_text(query, self.charset), self._format_params(params) ``` instead of repeating it in each case.
I'd rename this parameter to "unify_by_values" or something like that, which is a better description of what is happening here, and also explains better why it isn't relevant for execute_many.
Also I think that `is_ref` will need to be handled in a special way. The reference will need to be resolved to inline the expression. This can be tested by with the following code ```python updated_count = UniqueNumber.objects.annotate( number_inverse=F('number') * -1 ).order_by('number_inverse').update( number=F('number') + 2, ) self.assertEqual(updated_count, 2) ``` In this case `number_inverse` will yield `is_ref=True` and `expr` will be an instance of `Ref` if I'm not mistaken.
`{'connection': self.db, 'cursor': self}` is faster and imo clearer. `dict(foo=bar)` actually goes through two dict creation steps: first it creates the keyword args dict, then it finds the global name 'dict' (which could refer to anything), then it calls that name which creates the final dict.
drop 'this will" / "it will"
Please add a trailing comma.
Despite the existing style of the first test, I would remove the intermediate `f` variable in the new tests as it'll help balance line lengths and make things more readable.
I think we can simplify this: ```python def json_script(value, element_id=None, json_encoder=None): from django.core.serializers.json import DjangoJSONEncoder json_str = json.dumps(value, cls=json_encoder or DjangoJSONEncoder).translate(_json_script_escapes) ```
```suggestion self.assertEqual( ```
You're right :+1:. I missed that.
@JunyiJ My previous suggestion was to use the `TAN` database function on Oracle, i.e. ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='1 / TAN(%(expressions)s)') ```
I think we want to avoid altering `self.extra` here and pass `db_type` as a kwag to `super().as_sql()`.
I'm not sure why the change I suggested to add `ATan2.as_sqlite()` targeting SpatiaLite >= 4.3.0 resolved this issue for me locally and not on Jenkins. Could you confirm the version of SpatiaLite on the xenial and bionic boxes, @timgraham? (Maybe a build just needs to be re-triggered.)
Sorry - I should clarify - the tests were failing for float and decimal. This was fixed by inverting the order of the arguments, but that caused integer to fail: ``` ====================================================================== FAIL: test_integer (db_functions.math.test_atan2.ATan2Tests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/usr/lib/python3.6/unittest/case.py", line 59, in testPartExecutor yield File "/usr/lib/python3.6/unittest/case.py", line 605, in run testMethod() File "/home/nick/Sources/django/tests/db_functions/math/test_atan2.py", line 32, in test_integer self.assertAlmostEqual(obj.atan2_sn, math.atan2(obj.small, obj.normal)) File "/usr/lib/python3.6/unittest/case.py", line 878, in assertAlmostEqual raise self.failureException(msg) AssertionError: 1.5707963267948966 != 0.0 within 7 places ``` Casting the arguments to float seemed to then make the integer test pass. If somebody else could scrutinise my suggested fix, that would be great.
Instead of passing in `db_type` and `internal_type`, I would suggest just passing the field and the connection. That way, the method can extract the pieces of information it needs, which may be different for different backends.
Michal and I discussed this on IRC and I don't think such a generic function is going to help here. This is a very narrow use case (implicit casting isn't working for certain fields in case expressions), and it needs to be special cased for certain fields. This isn't an Integer->Float kind of situation. I'm happy enough with the method to stay. If we can generalise later then that will be OK, but I don't want this to hold up the merge.
I definitely do think we should at least try introducing the cast_sql method as described here. The argument types would be Field instances (and the names should likely be changed to input_field and output_field for consitency of Expression.output_field).
(To make the implication explicit: if not, perhaps this method shouldn't have `case` in its name.)
Please remove the unnecessary trailing comma and space.
As the checks are performed against `model_class._default_manager` the `connections[router.db_for_read(model_class)]` connection should be used.
IMO we don't need a `NOT_DEFERRABLE` constant. I would remove it and use `''` here and `None` in `UniqueConstraint.__init__()`), e.g. ```python constraint = self.sql_unique_constraint % { 'columns': ', '.join(map(self.quote_name, fields)), 'defer': defer or '', } ``` ```python class UniqueConstraint(BaseConstraint): def __init__(self, *, fields, name, condition=None, defer=None) ```
We can revert changes in `_delete_unique_sql()`.
As far as I'm aware, this can create duplicates on multi-value relations, see related fix for forms 556fa4bbba5ba86bc1646a86fb11ab55405d4aa4.
Why are you copying the `QuerySet`s? Shouldn't be necessary as all their attributes are immutable except outside of other operations, and the result cache doesn't seem to affect their use in the combined qs.
I think a docstrings explaining what `prefix_gen` generates would be good.
I may be missing something, but it seems this line could be bumped out one indent - no point in re-setting `prefix` to None on every product, when it won't be used again until the next outer (count) loop.
Are there situations in which this can happen other than "too many subqueries"? If not, I'd suggest an error message that might be more helpful to the end user would be "Maximum recursion depth exceeded: too many subqueries."
Chop blank line.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
This line can be removed :thinking:.
IMO this line is unnecessary, and above `iter()` call can be removed.
`seprate` -> `Separate`, also trailing dot is missing.
It seems that we have two issues here, i.e. you can use fields from the same model multiple times, e.g. `parent__field1__field2__pk__field1`, and you cannot use `pk`. I think we should clean `_cls` if a field is not relation, e.g. ```python if part == 'pk': fld = _cls._meta.pk else: fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` I would split this into two fixes, first for using multiple times fields from the same model (with test): ``` fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` and second to handle `pk` (with test).
add trailing comma
`clean` is not only for validation, but also for data modification in a form.
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
The form class is configuration too, is it not? You can group class attributes using a blank line, but this attribute is inherited from `BaseModelAdmin` where it is not separated. It just seemed odd.
~~I changed this to an assertion for the only file that is affected by the second round of post-processing i.e. `cached/relative.css`.~~
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
I'd combine w/previous line for better readability
I think we can move `msg` to the assertion, I don't see much value in creating a temporary variable here.
Can you re-warp this block to 79 chars? (First line is too short.)
I wonder if this might be bit more readable: `model = type('A' * 101, (models.Model,), {'__module__': self.__module__})`
No, at least not part of this PR.
the quotes around verylong... aren't present in the error message so the test isn't passing
Might be worth testing for the actual type.
`long_field_name` replaces the existing fields
`always_text` is gone.
Could we change this (and other similar places that check for string references) to directly call lazy_related_operation. The idea is that the calling code doesn't need to care if the reference is by string, and it doesn't need to care if the referenced model is already loaded. In all cases, it is OK to just call lazy_related_operation.
I'd not use the ternary: ```suggestion if filtered_relation: pathinfos = field.get_path_info(filtered_relation) else: pathinfos = field.path_infos ```
maybe we could describe what "direct related models" are? not sure the ticket reference is helpful here add period
This test name mentions multi-table inheritance but the body of the test has nothing to do with it.
This docstring isn't necessary as the method name is should be clear enough. ```suggestion ```
You need to specify a type of lock, e.g. `locks.LOCK_NB | locks.LOCK_EX`. Currently it returns `False` because we passed an invalid argument.
You don't need to mock, it will return `False` for a bad file descriptor.
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
chop blank lines
```python objs_to_clear = {field: items - objs for field, items in self.restricted_objects.get(model, {}).items()} ```
Invert the logic of the if statement and indent the two lines above, as the implicit return will be fine here. (Other cases of this should only be done in a separate clean up commit if you get tempted.)
chop blank line
This doesn't feel very efficient - there will be a query per loop. You should be able to fetch all objects in a single query, grouping by the field.
IMO it's more readable without `get(model, {})` I would also collect `ID`'s in the first step, e.g. ```python def clear_restricted_objects_from_queryset(self, model, qs): if model in self.restricted_objects: ids = [ obj.pk for objs in self.restricted_objects[model].values() for obj in objs ] self.restricted_objects[model] = { field: items - set(qs.filter(pk__in=ids)) for field, items in self.restricted_objects[model].items() } ```
Normally these objects will appear in a correct order because `serialize_db_to_string()` sorts dependencies. I've changed this to `Object` and `ObjectReference` with circular dependencies to create a real-life test.
> I had avoided using ObjectReference, since its ForeignKey has db_constraint=False which I assumed would prevent the problem from triggering. Did you try your new testcase without the fix applied? Yes, it fails without this patch with an `IntegrityError`.
When you will create an app with `Object` and `ObjectReference` as defined in `backends.models` then `serialize_db_to_string()` generates `data` with order that causes an `IntegrityError`. That is what I meant by a "real-life" example.
I think it's fine to leave it inside a `try` block.
The test should be possible by just having two test methods, that each test if the car is still there, shouldn't it? ``` python def test_first_car(self): self.assertTrue(Car.objects.exists()) def test_second_car(self): self.assertTrue(Car.objects.exists()) ``` Then you have the benefit that you don't have to override `_post_teardown()`.
What do you think about assigning `has_lookups` to the `transform_function` and be more explicit here? ```suggestion and not getattr(transform_function, "has_lookups", False) ``` and ```diff diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index 7e43ec254d..58ccb8f923 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -1820,6 +1820,7 @@ class Query(BaseExpression): final_transformer = functools.partial( transform, name=name, previous=final_transformer ) + final_transformer.has_lookups = True # Then, add the path to the query's joins. Note that we can't trim # joins at this stage - we will need the information about join type # of the trimmed joins. ```
`def transform(field, alias, *, name, previous)` ? Makes the partial application further down more obvious that name and previous are supplied by keyword args. Not certain this is better, but I had to double check the partial applicability worked correctly.
I would multiline: ``` field.attname for field in self.lookup_opts.fields if field.unique and not field.null ```
I think we prefer the closing paren on a newline
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
I think that `2**31 - 1` instead of `2147483647` is more readable.
Do you see much value in Django validating this? The error message from PostgreSQL seems clear: `django.db.utils.DataError: value 1 out of bounds for option "gin_pending_list_limit" DETAIL: Valid values are between "64" and "2147483647".
It looks like there will be a SQL syntax error due to a trailing comma if gin_pending_list_limit is used without fastupdate. Maybe `with_params` should be a list and joined with `', '`.
A bit unrelated, but I would move the closing parenthesis to improve readability: ``` statement.parts['extra'] = ' WITH (pages_per_range={})'.format( schema_editor.quote_value(self.pages_per_range) ) + statement.parts['extra'] ```
This needs an update following 831358f23d545b8dba017c6b26bd295ba9f6c17d.
You're calling `model_name.lower()` twice in most cases
Yes, this should be taken care of before.
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
I don't think we need an explicit `if` here. `_pending_lookups` is `{}` by default and thus the for-loop body isn't run anyways.
The same amount of caching would be happening in the approach I'm suggesting. It's just that you would be calling `self.resolve_fields_and_relations() / self.all_relations = ...` (e.g. in a method) instead of accessing a cached property. It just seems like the usage in the PR doesn't really match `@cached_property`'s use case. In addition to what I mentioned above, the calls to `self.all_relations` in the PR aren't using the return value, it's just doing that for the caching side effect, which you could do more simply / explicitly.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
Don't think we need to worry about duplicates.
As long as you use `except Exception` and not a bare `except` this should be good.
If we remove this will the tests run on Jenkins? It might be fine.
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
Quote from [PEP-257](https://www.python.org/dev/peps/pep-0257/): > The docstring is a phrase ending in a period. It prescribes the function or method's effect as a command ("Do this", "Return that"), not as a description; e.g. don't write "Returns the pathname ...".
"tuple: (set of model classes, set of app_configs)"
no comma needed
`CommandError` -> CommandError (no markup)
This line can go in "else" of try/except/else since it isn't expected to raise an exception.
Please use single quotes.
In the pattern I provided, the `'Z'` is a plain `'Z'` (because the backslash preceding it is escaped), but your substitution line is removing it.
Yes. However, note that isn't sufficient to replace all occurrences of e.g. `r'\Z'`, for example `r'a\\\Z'`.
```suggestion 1. (?P<a>\w+)/b/(?:\w+)c(?:\w+) => (?P<a>\\w+)/b/c ```
I think the formatted pattern should be wrapped in quotes. "Your URL pattern '{}' uses..".
True, this message is unused since its introduction in d725cc9734272f867d41f7236235c28b3931a1b2. I think we can remove `_parse_header()` hook, see #15802.
But now it will never fall back to the referer check if the Origin header exists (no matter if the origin header validated fine or not)…
Right, my bad.
Arg true, doing to many things at the same time. Yes the `elif` is vastly better than the extra variable before. :+1:
Not sure whether it's worth having a `to_asgi_name()` for completeness? 🤔
Using messages might work.
Simply access `form.cleaned_data` instead.
The output here is suboptimal. e.g.`* p * Ensure this value is greater than or equal to 0` We need to provide custom error messages that make sense when displayed as `messages`. We should maybe add the individual messages, in a loop, rather than the list.
Ahh, right, so :wink: : ```python for error in _search_form.errors.values(): ```
And this to `self.queryset`.
We can remove `'book_join'` from `order_by()`.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
you don't need `nulls_last=True` here because it's a PK you're ordering by, which is non-nullable
Please wrap at 79 chars.
Please start a docstring from a new line ``` """ alternate... ... """ ```
* `--force_color`? (i.e. with `--`) * ~~Re-wrap?~~ (Sorry diff view confused me: you already did this.)
Please wrap at 79 chars.
Please wrap at 79 chars.
can include more than one parameter on each line as noted above
It might be smarter to validate the token first and only modify the session + redirect if it's valid. Otherwise it makes it really easy to create a session just by GET'ing a url (possible DoS vector). It also means you can't pass `accounts/password_reset` as the token and take advantage of our `request.path.replace()` code. It probably means validating the token twice, which is slightly slower. Seems fine to me if an invalid token gets leaked.
I wonder if it would be better to include `.send()` in the new method and call it `send_mail()`. That gives some additional flexibility if the user doesn't want to actually send an email for some reason.
immediatelly -> immediately
any reason for passing args as kwargs? e.g. `subject_template_name=subject_template_name`
If I understand correctly, when the first field is indexed in descending order (like `-fieldname`) and the DB supports it, we will return `None` for this function. 1/ MySQL doesn't drop the implicit FK index when another index has as first field the FK in descending order, is that correct? 2/ The naming of the function is not _entirely_ accurate with respect to the behaviour, since we'll return None even though one would expect to get the first field name.
This is required only for indexes defined in `Meta.indexes`. Should we pass list of pure fields names in `remove_index()` instead? For example: ```python def remove_index(self, model, index): self._create_missing_fk_index( model, fields=[field_name for field_name, _ in index.fields_orders], expressions=index.expressions, ) super().remove_index(model, index) ```
`meta` is used only here so a temporary variable is unnecessary: ```suggestion first_field = model._meta.get_field(first_field_name) ```
This formatting change is not related with a bug fix, please revert.
unique_together-> index? (or something more generic like unique|index_together
My spellcheck tool of choice (languagetool) suggests a little change. ```suggestion """Email this user and return the number of emails sent.""" ```
Unless I'm missing something, this should be: ``` send_mail(subject, message, from_email, [self.email], **kwargs) ``` why the change to `from_email=None` and removing `[self.email]`? Also, don't remove the double newline above `class User`
Both `response` vars are unused.
can include more than one parameter on each line as noted above
any reason for passing args as kwargs? e.g. `subject_template_name=subject_template_name`
You can simplify the rest of the method by doing: ```python if self.verbosity == 1 and level is not None and level < logging.INFO: return print(msg) ``` (This is what I meant when I said the `logging_level` variable could be eliminated.)
Yeah, that works, too.
Since this might not be obvious from the method implementation, it's probably worth spelling out with another sentence in the docstring: "A verbosity of 1 logs INFO (the default level) or above, and verbosity 2 or higher logs all levels" (can go on a separate line).
I think something like, "Log the message at the given logging level." would be a bit better. (PEP 8 says no "s" at the end of "Log," by the way.)
I think you can simplify the above method implementation quite a bit by using more tailored logic. For example, you can start the method with: ```python if self.verbosity == 0: return ``` and then you're left with just two cases: verbosity `2` or more (log everything), and verbosity `None` and `1` (log `INFO` or higher). This should let you do away with the need for a separate `logging_level` variable. Once your test below is fixed, it should help you understand what's needed here.
We usually prefer `assertIs` here as it will also catch issues with an invalid return type ```suggestion self.assertIs(is_open, False) ```
I think you can avoid most of the boiler plate here by using the pool as a context manager. ```suggestion with multiprocessing.Pool(1) as pool: is_open = pool.apply(connection_is_open) ```
This can be dropped since `connection` is already imported in the context of the module. ```suggestion ```
We don't use `assert ` in tests. Please use `unittest` assertions: ```suggestion self.assertIs(self._extension_exists(), False) ```
`This test` is unnecessary. Please write `skipUnless` in one line e.g. `@unittest.skipUnless(connection.vendor == 'mysql', 'MySQL specific test.')`.
`raster_model` or even just `r` is probably fine.
Again, not related but use `force_raster_creation=True` rather than a tough to decipher plain boolean.
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
IMO, we can use `assertEqual` instead of `assertAlmostEqual` in all tests.
Why not using a `bulk_create` here? I may be a bit obsessed with performance, but I like when tests also are fast ;) ``` python self.objs = NullableIntegerArrayModel.objects.bulk_create([ NullableIntegerArrayModel(field=[1]), NullableIntegerArrayModel(field=[2]), NullableIntegerArrayModel(field=[2, 3]), NullableIntegerArrayModel(field=[20, 30, 40]), NullableIntegerArrayModel(field=None), ]) ```
`codename %= ...`
`cls.__name__.lower()` is the same as `self.model_name`. I guess `model_name` would probably be a better placeholder name.
These changes have to be as separated commit (since unrelated to ticket)
Put the } on the next line and add a trailing comma on this line. That's our convention to ease later adding more items to a dictionary, tuple, etc., if needed.
@charettes, any reply here? I guess we shouldn't block the patch about the issue with backwards migrations if we can't find a simple solution.
well, I'd suggest to revert this change entirely as it's unrelated to the patch.
Actually, since that's totally unrelated to the actual change, can you revert your change, please.
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
If you want to use a new name, that's okay with me, but I think `'has_file_field'` should remain for backwards compatibility.
I'm favoring contractions lately, e.g. "Don't", "shouldn't".
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
We need to factor this differently, as it's an exact duplicate of the added block above.
* We're still preferring single quotes, please use those throughout, unless there's a nested single quote. * This change is unrelated, please revert.
All tests ensure expected behavior ;-). Our preference is to use test docstrings to state and explain the expected behavior.
I don't think it's necessary to create new files for this test. We could use for example `django.contrib.auth.models.Group` for a simple model with a name, and the test could be appended to the `TemplateRegressionTests` class, for example.
```suggestion The message from the exception which triggered the 403 (if one was supplied). ```
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
there's also six.assertRaisesRegex which can be useful for checking the message
I would remove the quotes, typically we only use a lazy reference if necessary.
Ditto about `__str__()`.
no parenthesis needed / prefer single quotes
We usually avoid creating new models when we can reuse existing ones as it slowdown the test suite startup. In this case it looks like there's many candidate that could be reused here.
The note should be generic -- describe the sort problem as it could happen to any app -- a reference to contrib.postgres isn't needed.
My spellcheck tool of choice (languagetool) suggests a little change. ```suggestion """Email this user and return the number of emails sent.""" ```
I think the test fails as it is as you're no longer passing `self.timeout` to `smtplib.SMTP_SSL`. I don't think Django should specify a default of 60. Instead it should be `None` and only passed to the SMTP connection if the user specifies it. Here's a quick sketch of what I have in mind (plus some cleanup): ``` python # If local_hostname is not specified, socket.getfqdn() gets used. # For performance, we use the cached FQDN for local_hostname. connection_class = smtplib.SMTP_SSL if self.use_ssl else smtplib.SMTP connection_params = { 'local_hostname': DNS_NAME.get_fqdn(), } if self.timeout is not None: connection_params['timeout'] = self.timeout self.connection = connection_class(self.host, self.port, **connection_params) # TLS/SSL are mutually exclusive, so only attempt TLS over # non-secure connections. if not self.use_ssl and self.use_tls: self.connection.ehlo() self.connection.starttls() self.connection.ehlo() ``` For the test you'd subclass `EmailBackend` and verify the connection has the timeout use specified.
Instead of putting timeout in the `__init__` method, make it a class attribute. Here's an example change where we use this same technique: 8b0014869f666b44cd20692e38073ec0a0a8cb08
You should set `self.timeout` to `timeout`, not 60.
Unless I'm missing something, this should be: ``` send_mail(subject, message, from_email, [self.email], **kwargs) ``` why the change to `from_email=None` and removing `[self.email]`? Also, don't remove the double newline above `class User`
I don't think that we want to split a string using shell-like syntax. We should rather use `smart_split()` and `unescape_string_literal()` like proposed in the ticket, e.g. ```python for bit in smart_split(search_term): bit = unescape_string_literal(bit) if bit.startswith(('"', "'")) else bit ... ``` ```
For clarity here, shouldn't we use `Func` rather than `Transform`, since they are equivalent and the latter is a back-compat-only name? It seems like using `Transform` might suggest to someone reading this code that there's something distinct about `Transform` as opposed to `Func`.
Seems like it would result in less confusing code in the long run. If you do defer it and leave the TODO, I'd suggest to use your GitHub username instead of first name.
Since the existence of instance lookups will be rare I suggest we avoid an unncessary dict creation when `instance_lookups` is missing ```suggestion if not (instance_lookups := self.__dict__.get("instance_lookups"): return class_lookups return {**class_lookups, **instance_lookups} ```
I'd use f-strings for lookups (in all cases): ```suggestion lookup_conditions.append((f'{self.field_path}__isnull', True)) ```
I would remove the quotes, typically we only use a lazy reference if necessary.
We usually avoid creating new models when we can reuse existing ones as it slowdown the test suite startup. In this case it looks like there's many candidate that could be reused here.
Ditto about `__str__()`.
Use hanging indent: ``` special_people = models.ManyToManyField( 'Person', through='ProxiedIndividualCompetitor', related_name='special_event_set', ) ```
Actually, I think we can skip the router stuff and just use `django.db.connection`. These tests aren't run with custom routers so this'll always be run on the default database. (so we can move the skip condition to `test_long_column_name`).
`cls.__name__.lower()` is the same as `self.model_name`. I guess `model_name` would probably be a better placeholder name.
`codename %= ...`
We should mark all tests and model states that use `index_together` in `tests/migrations/test_autodetector.py` for removal. We can also move them to a common class for easier remove when deprecation ends.
These changes have to be as separated commit (since unrelated to ticket)
@charettes, any reply here? I guess we shouldn't block the patch about the issue with backwards migrations if we can't find a simple solution.
I think the `@property` syntax would be more readable here.
Omit the outer `[]` to use a generator instead of list comprehension.
I moved this test to the `tests/messages_tests/tests.py`.
I would either use `self.assertTrue(Carrot.objects.filter(tags__tag='orange').exists())` or `self.assertEqual(Carrot.objects.get(tags__tag='orange'), bear)` but otherwise LGTM.
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
You can use `mock.atomic.assert_called_with(using=db)` here instead.
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
And I would rename this attribute `superusers` as it's meant to contain multiple users.
use `reverse()` rather than a hard coded URL.
`from django.test import mock` -- this uses the package on Python 2 or the built-in version on Python 3.
Please import `mock` from `unittest`, ```python from unittest import mock ```
I'd move all `django.utils.encoding` import to one line.
sort mock before override_settings to fix isort build failure
Un-needed as described below. It should also solve the isort errors.
This attribute does not exist if `isolation_level` has not been specified in `OPTIONS`, AFAICT
"All MySQL storage engines engines except MyISAM support transactions."
Link is unneeded, I think.
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
[This is only an estimate on InnoDB tables](https://dev.mysql.com/doc/refman/5.7/en/tables-table.html) which is the default table engine and what's used on CI. > The number of rows. Some storage engines, such as MyISAM, store the exact count. For other storage engines, such as InnoDB, this value is an approximation, and may vary from the actual value by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate count. In short that means this value could report 0 while there's actually rows in the table and cause errors similar to the one you are experiencing.
```suggestion path = '%s/' % request.path ``` :thinking:
Please remove this blank line.
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Not a blocker or anything but `concurrently` seems more appropriate than `concurrent` for the kwarg name to me. e.g. `add_index(model, index, concurrently=True)`
``` if name is None: name = self._create_index_name(*args, **kwargs) return self.quote_name(name) ```
`remove_index()` accepts `concurrently`, moreover `self.allow_migrate_model()` check `self.allow_migrate_model()` check is missing, IMO we should use ```python if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.remove_index(model, self.index, concurrently=True) ```
```suggestion self.assertNotIn('CSRF_COOKIE', request.META) self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
```suggestion self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
`self.assertNotIn()` is preferred: ```suggestion self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
`Test passing` is unnecessary, IMO, maybe: ```suggestion # A token of length CSRF_SECRET_LENGTH. ```
I'd remove this docstring.
I'd move this line to the top of `__init__()` so it isn't lost below all the conditional logic.
This will not work for `OuterRef()` :disappointed: because we don't resolve it properly, so it generates: ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING(U0."name", 3, 1)) LIMIT 1 ) ``` instead of ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING("expressions_company"."name", 3, 1)) LIMIT 1 ) ``` see `test_slicing_of_outerref`.
`target` is only available for `Col`, so it crashes for expressions, see `test_slicing_of_f_expression_with_annotated_expression`.
```suggestion raise ValueError('Slice stop must be greater than slice start.') ```
We can remove this check after fixing the `Field.slice_expression()`.
Please use f-strings as Python 3.6+ is now the requirement More information is available including some benchmarks. https://cito.github.io/blog/f-strings/
Chop blank line.
We can remove this check after fixing the `Field.slice_expression()`.
I think it will be more readable to keep `int` and `slice` in separate branches, e.g.: ```python def __init__(self, f_obj, slice_obj): if isinstance(slice_obj, int): if slice_obj < 0: raise ValueError('Negative indexing is not supported.') self.low = slice_obj self.length = 1 elif isinstance(slice_obj, slice): if ( (slice_obj.start is not None and slice_obj.start < 0) or (slice_obj.stop is not None and slice_obj.stop < 0) ): raise ValueError('Negative indexing is not supported.') if slice_obj.step is not None: raise ValueError('Step argument is not supported.') self.low = 1 if slice_obj.start is None else int(slice_obj.start) + 1 self.length = None if slice_obj.stop is None else int(slice_obj.stop) - self.low + 1 else: raise TypeError('Argument to slice must be either int or slice instance.') self.expression = f_obj ```
Casting `int` to `int` is not necessary.
We usually avoid creating new models when we can reuse existing ones as it slowdown the test suite startup. In this case it looks like there's many candidate that could be reused here.
Might be worth testing for the actual type.
I suggest to add a line break and list models one per line with 2 spaces indentation.
This isn't working where it's used (Oracle).
Just had to move `field.check()` to the mocked context.
Here's a ticket if you have interest in trying to do the implementation: https://code.djangoproject.com/ticket/24476
I would name the test `test_reverse_text`.
Please remove trailing newlines in files (check code with flake8).
One minor change here, please don't use `os.path.join` but `'/'.join(…)`. `os.path.join` uses `os.sep` which doesn't have to be a slash always.
As said in the previous PR already, I think we should drop this
Is this necessary? I'm sure that `psql` defaults to `postgres` if `dbname` is unspecified. ```suggestion ```
```suggestion service = options.get('service') ```
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
Please revert this whitespace change.
`If the database should be kept and it already exists, don't`
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
This test already passes without the code change. The test for this new feature should fail before you apply your patch and pass after.
You can simply use `assertRedirect(response, obj.get_absolute_url(), ...)` here. No need for string formatting.
You should use `fetch_redirect_response=False` instead of `target_status_code=404`. It seems to be an outdated pattern used in a few places and I'll probably clean it up soon.
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
Was just thinking through what this means for ordering of arguments. `function` is a defaulted argument that may be passed positionally *or* by keyword. So `action(permissions=..., function=...)` worked. I think what we'd want ideally is `def action(function=None, /, permissions=None, description=None):`, making `function` positional only with a default, but that's only available on Python 3.8+. Anyway, just a curiousity really, I think the signature is fine as-is and unlikely to cause problems since the other arguments are named-only.
Here is the explanation I wrote some time ago :) https://python.astrotech.io/advanced/function/parameter-syntax.html
After looking at #6271, I think I'm seeing the use case for subclasses of `Func`.
So do we need to generate SQL with the same config in the `ts_headline` and an inline `tsquery`? (that's my main question) ```sql ts_headline('french'::regconfig, ..., tsquery(..., 'french'::regconfig), ...) ``` If not then I would prefer to leave config only in `tsquery` and don't duplicate its logic in `SearchHeadline`.
Is there any reason to take `config` from a `query`? This should be rather a separate `config` as far as I'm concerned :thinking:
+1, keep self.verbosity because third-party packages will assume ```self.verbosity``` is part of DiscoverRunner. This is a breaking change that's out of the scope of the PR.
It simplifies getting the default behavior for callers defining functions that pass through a logging level because they can just pass `None` for the default, instead of having to hard-code the default in a second location or invoke the function in a different way (without passing the argument).
The default level should be `logging.INFO` rather than `DEBUG`. However, I would implement this by making the default `None` (`level=None`) and interpreting `None` as `logging.INFO` in the body of the method.
Since this might not be obvious from the method implementation, it's probably worth spelling out with another sentence in the docstring: "A verbosity of 1 logs INFO (the default level) or above, and verbosity 2 or higher logs all levels" (can go on a separate line).
I think something like, "Log the message at the given logging level." would be a bit better. (PEP 8 says no "s" at the end of "Log," by the way.)
"Considre case" > "Consider the case".
Given `self.inner_votes` is an instance of `collections.Counter` this could be simplified to `self.inner_votes.update(inner_votes)`.
I would reuse the same wording as in `promote_joins` it's more clear IMO: "demote a->b automatically, or otherwise the demotion of b->c doesn't actually change anything in the query results."
I think we prefer the closing paren on a newline
I have a feeling something else if off here. The outer query's joining strategy should not have to special case inner queries as they are self contained expressions. My guess is that something is getting mixed up wrt to aliases because the same model is being involved in the outer and inner queries.
Can this be simplified to ```suggestion # Collation change? elif getattr(old_field, 'db_collation', None) != getattr(new_field, 'db_collation', None): new_collation = getattr(new_field, 'db_collation', None) fragment = self._alter_column_collation_sql(new_field, new_type, new_collation) actions.append(fragment) ``` Or maybe we want to keep the old code to support field type and collation change at the same time (e.g. `CharField(db_collation='foo') -> TextField(db_collation='bar')`).
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
I'd say "Return a (sql, params) fragment to set a column to null or non-null as required by new_field, or None if no changes are required."
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
In this case the current state of things is preferrable to this pull request. :-1:
- More code - Less obvious code than the original - Overly long constant name - Style not used in the rest of Django
Cleaner API with `empty_label=None`
`clean` is not only for validation, but also for data modification in a form.
You are right! I assumed `render_option` was always converting falsy values to an empty string. It might be worth keeping the method in this case.
I don't think you need this check here. This case will be handled in the for loop. Otherwise you can skip the first item in `cls.mro()` as well.
have this line use 8 space indent and the `raise` line use 4 space.
My thought was caching the return value in someway (in a dict eg. `self.cache[cls]`) to speedup by not looping over the bases each time a inherited manager is accessed. I would like to hear from other devs what they think on this.
I think some caching would make sense here.
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
You don't know what a docstring is? Trying googling "python docstring".
Sorry, was thinking of something else.
I'm not sure if these docstrings are adding much value.
Use single quotes unless the string contains a single quote. Also, this could be combined with the previous line -- we allow up to 119 characters when it helps readability.
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
```suggestion # JSON ```
These should be sorted alphabetically, i.e., `'Chr', 'Concat' ...` and wrapped at 79 chars.
I'd move depracated classes to a separate line: ```suggestion 'GISModelAdmin', 'OpenLayersWidget', # RemovedInDjango50Warning. 'GeoModelAdmin', 'OSMGeoAdmin', ```
Please wrap at 79 chars.
Good catch :+1:
The test failure is a non-deterministic dict ordering issue within "field".
I think we should be consistent and use double-quotes.
Could you annotate the regex similar to: ``` tld_re = ( '\.' # dot '(?!-)' # can't start with a dash '(?:[a-z' + ul + '-]{2,63}' # domain label '|xn--[a-z0-9]{1,59})' # or punycode label '(?<!-)' # can't end with a dash '\.?' # may have a trailing dot ) ```
This branch in untested :thinking:
put closing ) on next lin
The other option is to wrap the file with something like: ``` from django.core.files import File class ChunkedFile(File): DEFAULT_CHUNK_SIZE = 4096 def __iter__(self): return self.chunks() return StreamingResponse(ChunkedFile(open(fullpath, 'rb'))) ``` I considered using this wrapper for FileResponse.
Your solution honestly isn't _that_ much more complex, so I'm not saying we shouldn't do it, I was just curious how you ended up here! I think the resulting patch is pretty nice - I will need to take more time to properly review it but I like it on first glance.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
`aiter` is new in Python 3.10. https://docs.python.org/3.10/library/functions.html#aiter Django 4.2 will support Python 3.8, and 3.9 too.
Give the new `FieldInfo` a different name. Or give the standard `FieldInfo` a different name (`import ..., FieldInfo as BaseFieldInfo, ...`), if you're sure all use of this `FieldInfo` is local and it is never passed to generic methods.
Not sure :thinking: I would prefer to use `BaseFieldInfo` approach in this PR, and to unify introspection for PostgreSQL and MySQL in a separate PR.
I think we can import standard `FieldInfo` as a `BaseFieldInfo`, it seems to be cleaner for me (like in `oracle/introspection.py`).
If all bulit-in backends are adding 'default' now, might as well put it in the the base FieldInfo, I think.
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
Use the indentation style of the other tests. Actually, you can use `assertCountEqual()` instead. Maybe it makes sense to create another Article with a different year to test that the results are correct and not just returning everything.
`CharFieldModel` -> `RangeLookupsModel`. You don't need to create new objects.
assertEquals (deprecated alias) -> assertEqual I would also reverse the order of the arguments and use `self.assertEqual(Article.objects.all().count(), 0)`. That is what I have seen most often in tests.
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
You can reuse `Article`, e.g. ```suggestion Article.objects.filter(headline='Article 1').update(author=self.author_1) Article.objects.filter(headline='Article 2').update(author=self.author_1) Article.objects.filter(headline='Article 3').update(author=self.author_1) Article.objects.filter(headline='Article 4').update(author=self.author_2) articles = Article.objects.values('author').annotate(count=Count('author')) self.assertCountEqual(articles, [ {'author': self.author_1.pk, 'count': 3}, {'author': self.author_2.pk, 'count': 1}, ]) ```
```suggestion """PO files are unchanged unless there are new changes.""" ```
```suggestion self.original_po_contents = Path(self.PO_FILE).read_text() ```
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
Instead of this file dance, it would be easier to use a `tempfile.NamedTemporaryFile`. It is also safer wrt parallel test runs.
I don't think the intermediate `pattern` variable is needed.
Ah, I realized these are E128 which we are ignoring in the flake8 section of setup.cfg. I don't mind the changes, but we are ignoring it because there are 2K+ violations and seemingly not a lot of value in fixing them.
`else: assertFieldType('time_field', "models.DateTimeField()")`
There's a lot of repetitions of ``` python if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): ``` in this function now. Also, for Oracle, it doesn't check things it could check (e.g. that `ip_address_field` is a CharField). I think both issues could be addressed with a smarter field-type-asserter; perhaps this is out of scope for the PR, and should be done separately.
This if (lines 114--123 as I write this) can be folded into the previous one (109--112).
I'm not sure I would even write an assertion for such a broken output. Just ignore? Same below.
```suggestion raise self.exception_class(f'The connection {alias!r} doesn't exist.') ```
Again, I suspect we could use `__slots__` here: ```suggestion __slots__ = ('_connections', '_settings') ```
I think it's fine to leave it.
This came from the connection proxy for the cache connections -- for checking whether a key is in the cache -- and isn't really applicable to the database connections. I'm not sure that's a problem though -- it'll just complain that the connection is not iterable... This is just an observation.
Do we want to use `__slots__` to keep this as thin a layer as possible as it'll probably never have anything else added? ```suggestion __slots__ = ('_alias', '_connections') def __init__(self, connections, alias): super().__setattr__('_connections', connections) super().__setattr__('_alias', alias) ```
I think a list comprehension would be more readable.
longer lines here are okay, we try to avoid non-multiple of 4 indents
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
This is inconsistent but I think the patch can land as is and the test be modified later on based on the direction of [#24082](https://code.djangoproject.com/ticket/24082).
Please use a single quote.
"Boolean Expression object" looks a bit unusual to me. What do you think of "a boolean expression"? I assume this means an expression with output_field=BooleanField.
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
I think we can use the same check like in `UniqueConstraint`: ``` if not isinstance(condition, (type(None), Q)): raise ValueError('ExclusionConstraint.condition must be a Q instance.') ```
Keep what's done in `try` to the minimal expected to raise `self.model.DoesNotExist`. Move this after `except:` block.
Thanks! I see that you included `maxmem` in a string returned by `encode`. Is there any reason it should be there? `maxmem` should not affect a hash
@kerkeslager `hashlib.scrypt` is a low-level function that takes multiple arguments. `maxmem` is one of them, it has a default value that does not suit all cases. Therefore, Django should allow changing the value. @ryowright has already made the necessary change. Note, `maxmem` does not affect generated hashes, its value should not be included in a string saved to a database and should not be compared in `must_update`.
Throught your patch, please use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Do we have any plan on how & when to upgrade those as time passes by? (ie like we have for pbkdf2)
Yes, but these assertions can fail only for users with an incorrect hash in the database. IMO `assert`s can stay here, if you think otherwise we can discuss changing them in all hashers in ticket-32508.
This seemed to include svg as well but django does not accept svg file input.
`step` attribute should only be added if `self.localized is False`
This must also take the sign into account. What about: ``` python max_length = self.max_digits + 1 # for the sign if self.decimal_places is None or self.decimal_places > 0: max_length += 1 # for the dot ``` We could also make the sign check conditional based on `min_value` and `max_value` but it would be a mess.
We might want to avoid doing this if `self.localize is True` since `DECIMAL_SEPARATOR` and `THOUSAND_SEPARATOR` should be taken into account in this case.
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
I believe it's a reference to `ContentTypeManager`'s `get_for_*` methods cache. The actual `get_for_id()` call happens through `self.get_content_type()` below.
It's clearer to me.
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
Do we need to use a dict? It seems unnecessary complicated. Model classes that we pass in the keys must match the base models from querysets. We also don't protect against incorrect values e.g. ```python queryset={ Animal: Bookmark.objects.all() } ``` I would use a list/tuple instead and raise an error when a queryset for the specific model is already resolved, e.g. ```python for qs in querysets: ct_id = self.get_content_type(model=qs.query.model, using=qs.db).pk if ct_id in custom_queryset_dict: raise ValueError(...) custom_queryset_dict[ct_id] = qs ``` We should also add a new argument (maybe `querysets`) because it's misleading to pass list of querysets in the argument called `queryset`.
Why we evaluate the queryset? Couldn't we keep the `QuerySet` object? ```suggestion ret_val.extend(custom_queryset_dict[ct_id]) ```
As noted elsewhere, put the trailing space on this line rather than the next (and in the message below).
This exception message is different from that in `related.py` though the logic/intention surrounding it seems to be the same. Is this intentional? (FWIW, I find the message in `related.py` to be clearer)
We should also use `quote()` because non-integer primary keys may not work properly, e.g. `_40`. Fixed.
```suggestion return format_html('<a href="{}">{}</a>', url, remote_obj) ```
```suggestion caller = f'{obj.__module__}.{caller}' ```
I'm not sure about the `backend` terminology here. I think naming this function `get_password_validators` would be more consistent with the rest of the the code.
Also please keep it as HttpResponseNotFound as bug only occurs when that view throws 404.
I think you can safely remove this.
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
It used to be that way (in Python 2 era). Now gettext is an alias to ugettext and the latter will be deprecated in the future.
New docstrings should use PEP257 verb style "Returns -> Return". I'd write something like "On backends that supported it (memcached), return a list of keys that failed insertion."
It seems a bit confusing to have this docstring here without any `return` statement, perhaps some clarification would be helpful.
Use a single line (we allow up to 119 characters when it helps readability)
Shouldn't django allow lazy-evaluation function as default value? (Calculate the default value as needed)
I think @chicheng means doing the equivalent of: cache.get_or_set('some-timestamp-key', datetime.datetime.now)
@arthurio sorry for the delay here. We really want to be executing operations inside the loop as you suggested here and referred to as LNR, DFS. Else, as you've described, you could end up in a situation where the content types and permissions are missing.
"... final db state after the last state operation, hence ..."
This docstring is unnecessary.
should be `first_state`, not `project_state`, I suspect.
I don't see much value in this check.
single quotes please
The following should be tested as well ```python .update(field__c='Test Value', field__b='Other Value') ```
Please use hanging indent here and below in `assertEqual`: ``` data = [ {'0': 'a', '1': '42'}, ] ```
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
save is not needed : objects.create returns an already saved instance. Tests succeed without the save
`CANONICAL_RANGE_BOUNDS` is unnecessary: ```suggestion def __init__(self, *args, default_bounds='[)', **kwargs): ```
I saw that you're now handling this at the database level. It makes more sense to me.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
Do we need this check? All tests pass without it.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
Can be simplified to `ItalianRestaurant.objects.only('serves_gnocchi').get(pk=italian_restaurant.pk)`.
a single line for these queries should probably be okay
Can be simplified to `ItalianRestaurant.objects.defer('serves_gnocchi').get(pk=italian_restaurant.pk)`.
can we create the `ItalianRestaurant` and then get the related entites we need from that? I think that would be a bit nicer than `save_base(raw=True)`.
please include trailing comma on multiline kwargs so if more are added later, we don't need to edit the last line again
setUp/tearDown should go at the top of the class.
please use periods
seems to be missing a placeholder at the end
include trailing comma
chop "should" (just state the behavior)
Add a trailing comma.
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
Correctly indent the bracket to match the `return` indentation.
We try to avoid accessing the database connections when not necessary, so I'd move `db_features`: ```suggestion if ignore_conflicts and update_conflicts: raise ValueError( 'ignore_conflicts and update_conflicts are mutually exclusive.' ) db_features = connections[self.db].features ```
```suggestion raise NotSupportedError( 'This database backend does not support ignoring conflicts.' ) ```
```suggestion def _select_on_conflict(self, ignore_conflicts, update_conflicts, update_fields, unique_fields): ```
```suggestion 'ignore_conflicts and update_conflicts are mutually exclusive' ```
```suggestion raise NotSupportedError( 'This database backend does not support updating ' 'conflicts with specifying unique fields that will ' 'trigger the upsert.' ) ```
This could possibly be split into additional simple wrappers based on `parameter.kind` if it were `POSITIONAL_ONLY` or `KEYWORD_ONLY`? Then you could have simple conditions: ```python if has_multiple_parameters: def wrapper(*args, **kwargs): if any( isinstance(arg, Promise) for arg in itertools.chain(args, kwargs.values()) ): return lazy_func(*args, **kwargs) return func(*args, **kwargs) elif parameter.kind == parameter.POSITIONAL_ONLY: def wrapper(*args, **kwargs): if isinstance(args[0], Promise): return lazy_func(*args, **kwargs) return func(*args, **kwargs) elif parameter.kind == parameter.KEYWORD_ONLY: def wrapper(*args, **kwargs): if isinstance(kwargs[first_parameter.name], Promise): return lazy_func(*args, **kwargs) return func(*args, **kwargs) else: # parameter.POSITIONAL_OR_KEYWORD def wrapper(*args, **kwargs): if (args and isinstance(args[0], Promise)) or ( first_parameter.name in kwargs and isinstance(kwargs[first_parameter.name], Promise) ): return lazy_func(*args, **kwargs) return func(*args, **kwargs) return wraps(func)(wrapper) ``` Although maybe that is overkill if we just simplify the last case: ```python def wrapper(*args, **kwargs): arg = args[0] if args else kwargs[first_parameter.name] if isinstance(arg, Promise): return lazy_func(*args, **kwargs) return func(*args, **kwargs) ``` (Note that we can assume it exists in `kwargs` if `args` was empty and drop the additional containment check.)
If we `from itertools import chain` we can save the overhead of attribute access here.
Please alphabetize. ```suggestion if inspect.isfunction(func) or isinstance(func, (cached_property, property)): ```
```suggestion if autoescape: args[0] = conditional_escape(args[0]) return func(*args, **kwargs) ```
@adamchainz It says to remove self but can it get called for a static method or a class method? In the case of classmethod it will remove the cls. In the case of staticmethod it may remove argument.
Don't use `.items()` if you don't need the values. ```suggestion # Set timeout for each key individually as .mset() doesn't support # setting the timeout for all keys at the same time. for key in data: if timeout is None: client.persist(key) else: client.expire(key, timeout) ```
Ah, yes. Good observation. 🙂
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
I think that we should unpack `self._options` here and make them arguments of `RedisCacheClient.__init__()`. ```suggestion return self._class(self._servers, **self._options) ``` This is how we approach this for all of the memcached backends using client classes implemented in third-party packages.
We could flatten this? ```suggestion return default if value is None else self._serializer.loads(value) ```
Ahhh, yes, thanks!
Maybe: ```python for name, value in self.scope.get('headers', []): corrected_name = name.decode('latin1').upper().replace('-', '_') if corrected_name not in ('CONTENT_LENGTH', 'CONTENT_TYPE') corrected_name = 'HTTP_%s' corrected_name ```
FYI: we have also [`HttpHeaders`](https://github.com/django/django/blob/fc2536fe66c519b306f673672b795d16f87ed57d/django/http/request.py#L359-L374) class that have reserve logic, I'm not sure if we can reuse it somehow :thinking:
I wouldn't have thought so as `request.GET` is immutable in the WSGI implementation? At least I recall having to `.copy()` it first...
Should this be mutable? (`mutable=True`). `QueryDicts` handles `None` so `self.scope.get('query_string')` should work.
Probably not a bad idea, but it does make the implementation slightly more complicated.
Is it best to remove common parameters like `function` and `template`? Seems to me it improves readability a bit to have common kwargs explicitly declared.
After looking at #6271, I think I'm seeing the use case for subclasses of `Func`.
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
I noted this too and wasn't sure if it was an error or not. Can you 'save' an aggregate? ``` Model.objects.update(salary=Max('salary')) # would this work? ```
this line should be: `def __init__(self, *args, **kwargs):`
Could use single quotes for consistency.
might as well use `setdefault` in the test as well
`assertEqual` (the version you have now is a deprecated alias)
seems like a helper method to get the attachment path would save some repetition
Since the deprecation is in the constructor, shouldn't it specify `django.db.models.sql.aggregates.Aggregate`? **Edit:** Instead of `Aggregate` you could use `self.__class__.__name__` so it works for subclasses. Alternatively you may deprecate the whole module at module level.
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
one line would be fine here I think, or I prefer: ``` return compiler.compile( SecondsToInterval(Avg(IntervalToSeconds(expression))) ) ``` so it's easier to balance the parenthesis
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
I don't see any need for this attribute.
I think you could write `self.program_options.append('-f')` here. This way you won't need to add a new parameter to `compile_messages`.
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
I think it's enough to check `stderr`, e.g. ```python with self.assertRaises(SystemExit), captured_stderr() as stderr: self.get_parser().parse_args(['--parallel', 'unaccepted']) msg = "argument --parallel: 'unaccepted' is not an integer or the string 'auto" self.assertIn(msg, stderr.getvalue()) ```
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
It would be clearer to pass `True` as a keyword argument here.
don't need a trailing comma for lists of length 1 (only applies to tuple).
I don't think this test is sufficient. Having the first element in the output is quite likely. I'd check for the html or at least for `John` and `Paul`
I think we can remove `('B', 'Base B')` and `('B', 'Child B')` because it tests the same case as `A`.
I think the prompt should still happen if `destination_path` is None since we don't check existence in that case. Only skip the prompt if we're certain the destination doesn't exist.
Use hanging indent: ``` destination_exists = ( self.storage.exists(destination_path) and ... ) ```
I think the warning should happen in this case, since we didn't check if files exist or not, it's better to be safe.
You can safely join this an the next line. You have up to 119 chars per line. ;)
Instead of this file dance, it would be easier to use a `tempfile.NamedTemporaryFile`. It is also safer wrt parallel test runs.
> Yes they do, but I think on restarting and being presented with confirm on top of a blank screen, most people would just click "yes, resubmit". Resubmit raises 403 in such case, so I don't think it's an issue: https://user-images.githubusercontent.com/2865885/160332701-2a502657-ebe6-4a37-97d7-fa625856e9c9.mp4
This is funky and looks wrong, couldn't we just do the two lines here instead? ``` context = self.get_context_data(**kwargs) return self.render_to_response(context) ``` Also I don't know if it's been mentioned but rendering during a successful POST shouldn't really be done, Django uses the [“post-redirect-get” pattern](https://en.wikipedia.org/wiki/Post/Redirect/Get) everywhere in normal forms to avoid refreshes causing repeat actions. Couldn't we apply that here? Perhaps complicating things a lot though...
> The browser resubmits the "logout" tab, and the user is logged out again. The browser asks whether it should resubmit POST requests no? But you are right it is not 100% nice if `next_page` is not used.
@adamchainz Does it work for you? :point_up:
`@method_decorator(csrf_protect)` is missing. When the deprecation ends we should move it to `dispatch()`.
Possibly. In general we've been moving toward `SimpleTestCase` but I don't know if requiring it is worth the effort.
I think `assertRaisesMessage` should work here and works on py2/3.
I don't think this needs to live here - it could just live under the definition of `GeometryField` - the `ready` method would be perfect if we were adding this to something which lives outside of `contrib.gis`.
Creating two objects should not be necessary. ```suggestion ```
It's not obvious to me that the template approach is the best solution for readability as opposed to just creating another test settings file.
Maybe _"The 'no_color' and 'force_color' cannot be used together."_.
I'd use `cannot` rather than `can not` here and below
Chop blank line.
This can be single-lined.
I think we can move `msg` to the assertion, I don't see much value in creating a temporary variable here.
@morganwahl yes please!
I'm usually fairly conscious of higher level abstractions accessing very detailed properties or methods from lower down the stack. I would prefer a method within the `sql/query.py` Query object so that other implementations that may or may not yet exist have access to override this behaviour. I'd consider pushing everything from retrieving the inner query into a method and returning on that. ``` return obj.query.as_subquery_filter(obj) ``` Method name and args probably need work but that's the kind of thing I'm considering.
I think the `pk_field` variable could be removed here and below.
Could switch to single quotes as long as this is being modified.
no blank line
To my mind the real issue here is that we shouldn't be using `update_wrapper` at all (here or above in line 76). `view` is not in any way wrapped by `cls.dispatch` or `cls`. We just happen to want to achieve something similar to what we would want to achieve if we were wrapping a function. By using `update_wrapper` we're setting the `__wrapped__` attribute, so when we call `inspect.signature` it thinks that this function is the decorator, and that the function we're actually interested in is `cls.dispatch`. That's the reason why it returns the signature from `dispatch`. We should just do the thing we want to do directly. Something along the lines of: ``` for attr in functools.WRAPPER_ASSIGNMENTS: # I'm not sure which of these we actually want try: value = getattr(cls, attr) except AttributeError: pass else: setattr(view, attr, value) view.__dict__.update(cls.dispatch.__dict__) ```
@pope1ni Sorry it took a while to get back to you - it's been a hectic 24 hours. But yes, the above seems good to me.
I looked into why the tests are failing. It's because some internals of the URL resolver and admindocs rely on the `__name__` set here. But they could also, more accurately, use the `view_class` atttribute. Therefore I've made PR #14138 to change that. If we go that route then I think we shouldn't even set `__name__` / `__qualname__`. Leaving them as their defaults is sensible and doesn't lie (`__name__ = 'view'` , `__qualname__ = '...View.as_view.<locals>.view'`). One can differentiate class-based views with the `view_class` attribute.
Excellent. Happy with that. So, as I have above, without any `__qualname__`-mangling, should do the trick.
Perhaps dropping this blank line.
@lothemar I realized that previous assertions were correct. The current tests work even without this patch. I will restore them, sorry.
I'm not sure why we pass `data` and build a query string in tests views :thinking: I would simplify this: ```python def test_follow_307_and_308_no_get_preserves_query_string(self): methods = ('post', 'head', 'options', 'put', 'patch', 'delete', 'trace') codes = (307, 308) for method, code in itertools.product(methods, codes): with self.subTest(method=method, code=code): req_method = getattr(self.client, method) response = req_method('/redirect_query_%s/' % code, follow=True) self.assertRedirects(response, '/post_view/?hello=world', status_code=code) ``` and in `views.py`: ```python def method_saving_307_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=307) def method_saving_308_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=308) ``` Maybe I'm missing sth.
URL should be capitalized
As above, since `process_request()` returns a response, the second test isn't needed (see 434d309ef6dbecbfd2b322d3a1da78aa5cb05fa8).
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
I don't expect index names to change radically in the future, if at all, but even if it does, I think simplifying the test is worth the "risk" of having to update it in the future, which seems like no big deal.
The `index_type = indexes['reporter_id'].pop('type', None)` pattern from the old test should be used rather than a loop -- otherwise, if there' some mistake in the if-condition or if the loop is empty, it's not certain that this assertion will ever run.
Could be removed I think. If there's a use case for any third-party backends we can add it back later.
"its" (but could chop "and it's type" I think)
Hi, this name should be assert_foreign_key_exists
@ramiro .. and `else` is unnecessary :smile:
Yes, that's better.
I would consider tuple unpacking in the line before: `constraint_table, constraint_column = constraint['foreign_key']`.
`primary_key_column_name` and `column_name` should also be quoted. `backends` tests will crash with, e.g.: ```diff diff --git a/tests/backends/models.py b/tests/backends/models.py index 9a786c4bbd..2d0ce2d2e6 100644 --- a/tests/backends/models.py +++ b/tests/backends/models.py @@ -72,7 +72,7 @@ class ReporterProxy(Reporter): class Article(models.Model): headline = models.CharField(max_length=100) pub_date = models.DateField() - reporter = models.ForeignKey(Reporter, models.CASCADE) + reporter = models.ForeignKey(Reporter, models.CASCADE, db_column='where') reporter_proxy = models.ForeignKey( ReporterProxy, models.SET_NULL, ``` or ```diff diff --git a/tests/backends/models.py b/tests/backends/models.py index 9a786c4bbd..87eb6c63c6 100644 --- a/tests/backends/models.py +++ b/tests/backends/models.py @@ -70,6 +70,7 @@ class ReporterProxy(Reporter): class Article(models.Model): + id = models.AutoField(primary_key=True, db_column='select') headline = models.CharField(max_length=100) pub_date = models.DateField() reporter = models.ForeignKey(Reporter, models.CASCADE) ```
Looks like you're missing a `relations` assignment here.
This doesn't depend on anything above, so use a separate test: `test_middleware_subclasses`
So probably just, ["use hanging indent"](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) here.
use a hanging indent style: ``` INSTALLED_APPS=[ 'django.contrib.admin', ] ```
This and the check below can be single-lined.
Please wrap at 79 chars.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
this doesn't look right
Not sure of the motivation behind these changes but this could be reduced to the following? ```suggestion attrs['declared_fields'] = { key: attrs.pop(key) for key, value in attrs.items() if isinstance(value, Field) } ```
~Never mind, looks it's the other way around. Works on 3.6, fails on 3.8.~ had an old Python 2.7 interpreter lying on my path 🤦
no restructured text (:class:) in docstrings please
> Yes they do, but I think on restarting and being presented with confirm on top of a blank screen, most people would just click "yes, resubmit". Resubmit raises 403 in such case, so I don't think it's an issue: https://user-images.githubusercontent.com/2865885/160332701-2a502657-ebe6-4a37-97d7-fa625856e9c9.mp4
This is funky and looks wrong, couldn't we just do the two lines here instead? ``` context = self.get_context_data(**kwargs) return self.render_to_response(context) ``` Also I don't know if it's been mentioned but rendering during a successful POST shouldn't really be done, Django uses the [“post-redirect-get” pattern](https://en.wikipedia.org/wiki/Post/Redirect/Get) everywhere in normal forms to avoid refreshes causing repeat actions. Couldn't we apply that here? Perhaps complicating things a lot though...
> The browser resubmits the "logout" tab, and the user is logged out again. The browser asks whether it should resubmit POST requests no? But you are right it is not 100% nice if `next_page` is not used.
@adamchainz Does it work for you? :point_up:
`@method_decorator(csrf_protect)` is missing. When the deprecation ends we should move it to `dispatch()`.
me too :+1:
Ah yes I see. Exists being a subclass of Subquery.
@schinckel this workaround shouldn't be necessary once #9765 is merged.
I don't think extending `Subquery.__init__` to allow any `QuerySet` some method (e.g. `filter`, `order_by`, ...) is desirable.
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
That'll be an interesting one to address when we move the schema editor to use model states instead. A problem for later :)
``` if name is None: name = self._create_index_name(*args, **kwargs) return self.quote_name(name) ```
Remember the trailing comma.
I would move this out of the `Statement`: ```python if columns: columns = self._index_columns(table, columns, col_suffixes=(), opclasses=opclasses) else: columns = Expressions(model._meta.db_table, expressions, compiler, self.quote_value) ```
Yeah it's quite inconsistent :disappointed:. I think we should change `columns` to `fields` in a separate PR.
This assertion is not necessary.
I don't think that we need `Approximate()`.
`Count(..., distinct=True)` is already tested in `test_count()` and it is not related with this patch, so we can refactor tests but in a separate commit, e.g. - 1st commit: _"Moved test for distinct Count() to a separate test case."_: ```diff diff --git a/tests/aggregation/tests.py b/tests/aggregation/tests.py index ea11c02edc..2f667a0fe1 100644 --- a/tests/aggregation/tests.py +++ b/tests/aggregation/tests.py @@ -388,9 +388,6 @@ class AggregateTestCase(TestCase): vals = Book.objects.aggregate(Count("rating")) self.assertEqual(vals, {"rating__count": 6}) - vals = Book.objects.aggregate(Count("rating", distinct=True)) - self.assertEqual(vals, {"rating__count": 4}) - def test_count_star(self): with self.assertNumQueries(1) as ctx: Book.objects.aggregate(n=Count("*")) @@ -403,6 +400,10 @@ class AggregateTestCase(TestCase): ) self.assertEqual(aggs['distinct_ratings'], 4) + def test_distinct_on_aggregate(self): + books = Book.objects.aggregate(Count('rating', distinct=True)) + self.assertEqual(books, {'rating__count': 4}) + def test_non_grouped_annotation_not_in_group_by(self): """ An annotation not included in values() before an aggregate should be ``` - 2nd commit, fix and extra test cases (with `self.subTest`), e.g. ```python def test_distinct_on_aggregate(self): for aggregate, expected_result in ( (Count, 4), (Sum, 16.5), (Avg, 4.125), ): with self.subTest(aggregate=aggregate): books = Book.objects.aggregate(ratings=aggregate('rating', distinct=True)) self.assertEqual(books['ratings'], expected_result) ``` Also, I think that `Book.rating` would be better for testing `distinct` argument.
We don't really need all the history of when it was broken/fixed.
no comma needed
Thanks @MatthewWilkes. It was only that sentence/paragraph that needs fixing here, since it's adding the new value that will be unpacked. Any other clean up can wait.
Please don't suggest doing unrelated cleanups along with bug fix or feature work. We try to avoid that as it confuses things when studying a patch.
I'd rather see the docstring updated in this one: just so it's not forgotten. With the change, the paragraph beginning `Return...` isn't right. My worry is if we leave it then it'll be forgotten.
Drop the unneeded parentheses.
```python if not hasattr(final_field, 'resolve_expression'): final_field = final_field.get_col(alias) try: final_field = self.try_transform(final_field, name) ... ```
Python functions implicitly return `None` if return is not called. I feel being explicit is better for a test.
You don't really need a docstring at all, IMO. The test itself explains it well enough.
this could be 1 line
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
Use single quotes unless the string contains a single quote. Also, this could be combined with the previous line -- we allow up to 119 characters when it helps readability.
I think these are too internal, I would rather check that `MultiValueDict` is pickleable: ```python pickle.loads(pickle.dumps(...)) ```
We can keep them together ```suggestion with self.subTest(DEBUG=debug), self.settings(DEBUG=debug): ```
This docstring is unnecessary.
blank line not needed
I don't see much value in this docstring.
Fixed in 67e7dffe9543aff259f63c8f12d15642fe7be100.
`WEEKOF` is not defined in the `Oracle`. You should use `TO_CHAR` with `IW` param ``` diff --- a/django/db/backends/oracle/operations.py +++ b/django/db/backends/oracle/operations.py @@ -84,6 +84,9 @@ WHEN (new.%(col_name)s IS NULL) if lookup_type == 'week_day': # TO_CHAR(field, 'D') returns an integer from 1-7, where 1=Sunday. return "TO_CHAR(%s, 'D')" % field_name + elif lookup_type == 'week': + # TO_CHAR(field, 'IW') returns an integer from 1-52 or 1-53, week of the year based on the ISO standard + return "TO_CHAR(%s, 'IW')" % field_name else: # http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions050.htm return "EXTRACT(%s FROM %s)" % (lookup_type.upper(), field_name) ```
This is really hacky, moving to the previous day should work as expected ```python return "TO_CHAR(%s - 1, 'D')" % field_name ```
`CheckConstraint`, `UniqueConstraint` and `ExclusionConstraint` inherit form `BaseConstraint` it should be fine to call `super().__eq__(other)` if an other's class doesn't match, e.g. ```python def __eq__(self, other): if isinstance(other, UniqueConstraint): return ( self.name == other.name and self.fields == other.fields and self.condition == other.condition ) return super().__eq__(other) ```
Not even if you pass an expression? Just trying to avert a common problem we've had to fix numerous times. If you think there is no expression that could be an issue, I'm happy to ignore this.
I wonder if this could be addressed by adding a `MultiColSource` method that returns `self`
I moved a cleanup part to a separate commit.
Possible I missed something but I'm not seeing any tests failing with this method removed.
`An expression` - no need for the `combinable` bit.
Similarly, I don't see much advantage to creating indirection with a method.
The parentheses around `','` are unnecessary.
Is this import here necessary to avoid a circular import, or can it be moved to the module scope? Also I'm not sure that we need to alias this as `V`. I believe most uses in the Django code use `Value`.
This feels rather clunky - can you not use string formatting, e.g.` '{%s}' % hierarchy` and `'"%s"' % val`? Also, we prefer use of single quotes - this whole PR seems to do quotes inconsistently. Come to think of it, I'm not very keen on the way that this is constructed. What if `hierarchy` contains a mix of string and numeric values as keys? Does that make a difference to how this is constructed? What about `val`? It looks as though the value is always quoted as a string, but we should be able to pass integers or floats here... I would like to see more tests with all the data types supported by JSON and have them re-fetched from the database for comparison.
Either _all_ fields should have an m2m property (because m2m is a fundamental property that a field can have), or none of them do. A hasattr check doesn't make sense here. Same goes for is_gfk a few lines earlier. m2m is probably a fundamental property of fields, but gfk is masking something more abstract.
Then this can just be: ```python for header, value in self._unpack_values(data): ```
@smithdc1 it does thanks!
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
I would call `clean()` in validation tests, we should also move it to a separate tests, e.g. ```python def test_invalid_value(self): field = models.DecimalField(max_digits=4, decimal_places=2) msg = '“%s” value must be a decimal number.' tests = [ (), [], {}, set(), object(), complex(), 'non-numeric string', b'non-numeric byte-string', ] for value in tests: with self.subTest(value): with self.assertRaisesMessage(ValidationError, msg % (value,)): field.clean(value, None) ```
Please update your patch.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
Since the behaviour of the `autocapitalize` attribute has nothing to do with django itself, you'll probably have to write some sort of a test that the field/widget renders that attribute.
This test passes without changes in the `UsernameField`.
You should just check for the presence of the attribute. See tests in #11070.
Please don't make unrelated whitespace changes.
What's the point of this query? I don't see anything in the view which could delete users (and even then, why should it delete users…)
I don't mind either way, it just took a second to spot the differences between the groups.
I'd chop every other empty line and group the `auto_now` and `auto_now_add`, but that's just cosmetics.
Oracle doesn't really have a date-without-time data type. If you're selecting data using raw SQL, you need to account for this yourself.
You mean on Oracle? There's Django's CI infrastructure (I think Oracle is run for all PRs automatically, but it may need special invocation). Other than that, you can [set up an environment locally](https://code.djangoproject.com/wiki/OracleTestSetup) but it's a little involved if you only need it for one patch.
Even when restricted to tests and defined as an inner function, the name `assert...` for a function with a significant side effect (schema change) is disturbing. So is the use of the surrounding-function variable `editor` (which is done outside of the relevant `with` block). Please restructure this.
In Thailand it’s customary to use the [Thai solar calendar](https://en.wikipedia.org/wiki/Thai_solar_calendar) system (as it’s the official legal calendar in Thailand). Dates and months are the same as the common Gregorian Calendar, but years are in Buddhist Era instead of the Christian/Common Era. Just add 543 to the year number when displaying, and subtract 543 from the year number when parsing.
Is it possible to convert year type? (e.g. 2006 &rarr; 2549)
OK then, thanks for the references.
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
Are you sure? Should this not be consistent with `SHORT_DATETIME_FORMAT`, i.e. `SHORT_DATE_FORMAT = 'j N Y'`.
@hannseman Thanks :+1: > I prefer it over the mixin approach. Yes me too :+1: . We can move `Value()` wrapping to the `__init__()` and simplify it a bit, e.g.: ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) if not (config and hasattr(config, 'resolve_expression')): config = Value(config) self.config = config def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save) resolved.config = self.config.resolve_expression(query, allow_joins, reuse, summarize, for_save) return resolved def as_sql(self, compiler, connection): sql, params = compiler.compile(self.config) return '%s::regconfig' % sql, params ``` Please move introducing a `SearchConfig` expression to the separate commit, or even PR.
I would prefer to wrap value with `Value()` and compile `options` separately.
IMO we should check options against PostreSQL names.
append instead of creating a new list ```suggestion options_params.append(', '.join(options)) ``` All off the above could also be reduced to ```python options_params.append(', '.join( '%s=%s' % (option, psycopg2.extensions.adapt(value).getquoted().decode()) for option, value in options.items() ))
The usual pattern is to implement `get_source_expressions` and `set_source_expressions`. ```python def get_source_expressions(self): return [self.config] def set_source_expressions(self, expressions): self.config, = expressions
```python kwargs = {'reuse': can_reuse, 'allow_joins': allow_joins} if isinstance(value, F): kwargs['simple_col'] = simple_col value = value.resolve_expression(self, **kwargs) ```
a misspell? SQLFuncMixn -> SQLFuncMixin
This is precisely this inconsistency in the expressions API about `params: list | tuple` that forces the usage of `tuple` here. Some `lhs.as_sql` return `params: list` and but the backend expects layer only expects `tuples` to be provided. Without this `tuple` some tests crash and I think we want to avoid this expression API inconsistency leak into the backends layer as it could be considered as low level as the compiler which only deals with `params` in tuples.
is it strictly required to cast params to a tuple? I thought it was understood that `params` may be a list or a tuple throughout the ORM code.
chop "one of" add comma before "or"
Can replace `**dict(through_defaults, **{…})` and use unpacking generalisations: `**{**through_defaults, **{…}}`.
keep in mind new_ids could be smaller than objs, messing up index order so intermediate_values won't match up, right? Also, new_ids is a _set_, so order is lost.
I noticed that we use keyword-only arguments for `def set(self, objs, *, clear=False, through_defaults=None):` Do we want to so something similar for other methods: - `def add(self, *objs, *, through_defaults=None)`: - `def create(self, *, through_defaults=None, **kwargs):` - `def get_or_create(self, *, through_defaults=None, **kwargs):` - `def update_or_create(self, *, through_defaults=None, **kwargs):`
Ahh right, I forgot about it. Thanks!
Welcome to the wonderful world of `contenttypes` where clearing a GFK (even an optional one) actually deletes the objects.
`"""` -> `'`
It should give 'Modification de Title et Historique.'. I guess a gettext call is missing inside the `LogEntry.get_change_message`.
chop first comma
Is it correct that this `args` is different from the previous test? I'd expect the same test for both Python 2 and 3 with something like `self.assertEqual(response.status_code, 200 if six.PY3 else 404)` but maybe I missed something.
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
I don't think we need to have a strict policy on `/` vs. `.joinpath()`. I'd prefer `/` but when readability hurts we can also use `.joinpath()` :shrug:
There's no need to define the extra `settings_dir` variable as `pathlib` gives us more flexibility: ```suggestion settings_file_path = self.test_dir / filename / "__init__.py" settings_file_path.parent.mkdir() ```
```suggestion self.temp_app_path.joinpath("__init__.py").touch() ```
```suggestion self.assertTrue(tmpdir.joinpath("1").is_file()) self.assertTrue(tmpdir.joinpath("2").is_file()) self.assertTrue(tmpdir.joinpath("foo", "1").is_file()) self.assertTrue(tmpdir.joinpath("foo", "2").is_file()) self.assertTrue(tmpdir.joinpath("foo", "bar", "1").is_file()) self.assertTrue(tmpdir.joinpath("foo", "bar", "2").is_file()) ```
```python msg = 'Script does-not-exist does not exist.' with self.assertRaisesMessage(RuntimeError, msg): ```
I guess we could introduce `django.utils.zoneinfo` like we did with `simplejson` back in the time. We could start deprecating the module when we drop support for Python 3.8.
I think that we could make use of a six moved import: `six.http_client` (https://pythonhosted.org/six/#module-six.moves)
Diff will be smaller without this unnecessary change.
Collapse these onto one line and order alphabetically.
simpler: "must be a string"
I would move it to the `ManageRunserver` class.
```suggestion """runserver doesn't support --verbosity and --trackback options.""" ```
Please use the same order as in `--help` output, i.e. `--version`, `--verbosity`, `--settings`, `--pythonpath`, `--traceback`, `--no-color`, and `--force-color`.
As no one has offered a rationale for deviating from the PEP, I'd leave it as is.
style guide says this should be "Checks ..."
Use hanging indent: ``` msg = ( "..." ) ``` Are the new messages tested? I think you could avoid the repetition of the two branches by interpolating "keyword " in the message and varying args/kwargs in the params with a variable.
I would assert against `url_name`, e.g. ```suggestion self.assertEqual(response.resolver_match.url_name, 'overridden_urlconf_view') ```
Is there a reason to use `len()` instead of checking the objects? `len()` may take more effort to debug in the event of a failure.
Same as above; let's leave it alone for now.
I think this test can be entirely removed if `test_nested_subquery_outer_ref_with_function` covers the usage case appropriately.
no need for super calls
I'd skip the `assertIsNotNone` since `None.name` will error our later anyway.
I'd be great to assert the permission and content types were appropriately created as well!
assertEqual -- the version with "s" is a deprecated alias.
``` @mock.patch('django.contrib.contenttypes.management.update_contenttypes') def test_remove_contenttypes(self, mocked_update_func): management.remove_contenttypes(self.app_config.name) self.assertEqual(mocked_update_func.call_count, 1) ```
I guess there is a fair amount of wasted effort for the majority(?) of projects that aren't using admindocs, so perhaps we could have a ticket for it to investigate the possibility of moving the admindocs specific-stuff out.
*↑* Oh, I'm sorry! 😂
Maybe change that into a `try/execpt AttributeError`. It's kinda nitpicky, but given that if you want to use session-based CSRF you will most likely have a session object on the request and then try/except would be faster (And even if not, it seems more natural and shows a nice chained error on python3).
Why would you need to sanitize something that's already in your session? Seems a bit late...
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
It looks like should use `f.get_attname()` instead of rebuilding that here.
I think this is a bit vague. Perhaps `_check_single_primary_key`.
"foreign key id" may not be the best wording. For example, this also applies to subclasses like OneToOneField.
Regarding multiple database support, I believe we want to do something like this: ``` from django.conf import settings from django.db import connections for db in settings.DATABASES.keys(): # skip databases where the model won't be created if not router.allow_migrate(db, cls): continue connection = connections[db] allowed_len = connection.ops.max_name_length() ... ``` We can also go back to putting the database alias (`db`) in the error message.
I would suggest integrating this code into `_check_constraints` above, since then the duplicate code up to here can be shared. The name of that function implies that it is expected to check *all* constraints (I' reading it as "check all constraints", not "do something about check-constraints"). There might even be some code sharing in the error generating (e.g. if the constraint-specific check code sets a `message` and `code` variable, some common code could fill in the rest of the warning (especially if the hints are made equal as I suggest below).
`VACUUM INTO` was [added in 3.27.0](https://sqlite.org/releaselog/3_27_0.html). This would bump requirements in `databases.txt` and `check_sqlite_version()` check in `django/db/backends/sqlite3/base.py`
To keep the diff a bit cleaner, I wouldn't make this unrelated whitespace change.
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
I think I would compose the string before the condition ```python exc_msg = 'database %s already exists' % parameters['dbname'] if exc_msg not in str(e): ... ```
I'd chop this blank line since the } on its own line is providing whitespace.
There is no need to simplify paths for private APIs that we will never use in migrations. Please revert changes to the `TemporalSubtraction`, `DurationExpression`, `CombinedExpression`, `Expression`, `SQLiteNumericMixin`, `ResolvedOuterRef`, `ExpressionList`, `Col`, `Ref`, etc.
No, they are not supported, because `BOOLEAN` datatype is available only in PL/SQL on Oracle, so `SELECT` clause cannot return it.
line saver? ``` format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' extra_context['format_string'] = format_string ```
`%`-formatting is called anyway: https://github.com/django/django/blob/f71b0cf769d9ac582ee3d1a8c33d73dad3a770da/django/db/models/expressions.py#L965 Do you think an extra value can cause a performance regression? :thinking: I was thinking about readability.
I added warning to docs.
@sdil Can you take a look? Thanks!
My pleasure :)
@sdil Thanks for checking :+1:
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
OK then, thanks for the references.
> Yes they do, but I think on restarting and being presented with confirm on top of a blank screen, most people would just click "yes, resubmit". Resubmit raises 403 in such case, so I don't think it's an issue: https://user-images.githubusercontent.com/2865885/160332701-2a502657-ebe6-4a37-97d7-fa625856e9c9.mp4
This is funky and looks wrong, couldn't we just do the two lines here instead? ``` context = self.get_context_data(**kwargs) return self.render_to_response(context) ``` Also I don't know if it's been mentioned but rendering during a successful POST shouldn't really be done, Django uses the [“post-redirect-get” pattern](https://en.wikipedia.org/wiki/Post/Redirect/Get) everywhere in normal forms to avoid refreshes causing repeat actions. Couldn't we apply that here? Perhaps complicating things a lot though...
> The browser resubmits the "logout" tab, and the user is logged out again. The browser asks whether it should resubmit POST requests no? But you are right it is not 100% nice if `next_page` is not used.
@adamchainz Does it work for you? :point_up:
`@method_decorator(csrf_protect)` is missing. When the deprecation ends we should move it to `dispatch()`.
Unneeded, I think.
Use list and remove unnecessary whitespace ```suggestion fields = [('name', 'position')] ```
You can reuse `CountryInlineAdmin` and `StateAdmin` instead of defining extra classes: ```suggestion ``` Add `get_formset_params()` to `StateAdmin`.
This can be single-lined.
Chop blank line.
I find it problematic we’d make it possible to override the `aria-describedby` for two reasons: - If the `help_text` is used, then I don’t think it would be appropriate for its content to be missing from the input’s description as computed from `aria-describedby`. - Assuming we implement the other fix for #32819 by adding the field’s error(s) in `aria-describedby`, it would also be inappropriate for that to be missing because of a customization. In both cases I guess this would be ok if the customization included the ids for the help text and error message when needed, but that doesn’t seem very convenient. --- So we could make it possible to customize `aria-describedby`, but if we did in my opinion it should be in addition to Django automatically populating it for `help_text` and field errors: ```suggestion if self.field.help_text and id_for_label: helptext_id = '%s_helptext' % id_for_label if 'aria-describedby' in widget.attrs: attrs['aria-describedby'] = f"{helptext_id} {attrs['aria-describedby']}" else: attrs['aria-describedby'] = helptext_id ``` I’m not too sold on this either because then we’re having to assume the order of the different descriptions. It gets more problematic if we had errors in there too: ```python attrs['aria-describedby'] = f"{helptext_id} {errors_id} {attrs['aria-describedby']}" ```
If 'class' is already in attrs, this should append `self.form.required_css_class` to it, not leave the value unaffected.
Please try to stay near 80 char per line…
We need to factor this differently, as it's an exact duplicate of the added block above.
* We're still preferring single quotes, please use those throughout, unless there's a nested single quote. * This change is unrelated, please revert.
This collation doesn't work for me: ``` django.db.utils.ProgrammingError: collation "en_US" for encoding "UTF8" does not exist ``` I've changed to the `en-x-icu`.
I think a list comprehension would be more readable.
We should move `Foo.objects.create()` outside the context manager, i.e. ```python with connection.schema_editor() as editor: editor.alter_field(Foo, old_field, new_field, strict=True) Foo.objects.create() ```
longer lines here are okay, we try to avoid non-multiple of 4 indents
We can add `Foo.objects.create()` to ensure that primary key and sequence are still valid.
"Raise ValidationError if the address is invalid."
The comma isn't needed.
Existing code isn't consistent, but we usually use single quotes in new code.
You _could_ turn this into a oneliner ... ``` '.'.join([str(int(num)) for num in string.split('.')]) ```
It can be returned immediately without `result` variable
We're a couple months away (Jan. 15) from dropping Python 2 so it would be nice to avoid adding more work to do when dropping it. Have an invalid secret key seems like such an obscure issue, I don't know if it justifies all the time we're spending on it. Maybe we can just update the docs and be done with it.
(Following the pattern of other checks.)
```suggestion 'ALLOWED_HOSTS must be a list or tuple of strings.', ```
Single quotes please and wrap at 119 characters. (Please do this everywhere as appropriate.)
Use the `hint` parameter for listing valid values, e.g. ```python E023 = Error( 'You have set the SECURE_REFERRER_POLICY setting to an invalid value.', hint='Valid values are: {}.'.format(', '.join(sorted(REFERRER_POLICY_VALUES))), id='security.E023', ) ``` Also, the current convention is to not have independent numbering for warnings and errors, so use `E023` instead of `E001`.
I think you should use `type` not `__class__`. At least in python 2 this will break if the class does not inherit from `object`.
I'd keep the current version without `type()` since it's unrelated. If there's a need for this change, create a ticket with a corresponding test.
chop blank line
how about: "Run the system checks on all ModelAdmins, except if they aren't customized at all."
`fix_this` is misleading, because there is nothing to fix here.
```suggestion def _is_default_auto_field_overridden(self): ```
I feel like this setting is out of context here. Should `AppConfig` only provide information in the context of an app? If I want to find out what kind of primary key a given app is asking for, I could look for `AppConfig.model_default_pk`, but if we're overriding if with a project setting it can cause some confusion.
Is there a reason to add a `pass` statement here? The docstring should be enough, you can take a look at [Why does python allow an empty function (with doc-string) body without a “pass” statement? (stackoverflow)](https://stackoverflow.com/a/17735171).
I think Django has generally included `pass` (perhaps a full audit could be done). I'm not sure that omitting is considered "an obscure feature" and I don't have a particular preference one way or another.
My view is that Python design specifically allows to omit 'pass' when docstring is present, in other words it's not some corner case or side effect, it's a style and design decision that a docstring is considered as "body". It's not a strong preference, but I'd prefer if django did not enforce adding 'pass'.
This conditional is not required anymore given the check above.
dunder dun dunnnnn
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
We can remove `'book_join'` from `order_by()`.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
you don't need `nulls_last=True` here because it's a PK you're ordering by, which is non-nullable
I suggest you use the `for`/`else` construct here. ``` python for validator in validators: if isinstance(validator, validators.MinValueValidator) and validator.limit_value <= min_value: break else: validators.append(validators.MinValueValidator(min_value)) ```
consider assertRaisesMessage to make the test a bit more specific.
And this can be reverted.
Ditto about the `for`/`else` construct.
Simply return `validators`.
It's slower, about 10 times.
Please replace this with a regular `try/except`.
This is not a functional change, it's just a simplification.
remove "0" in {0}
Returns -> Return use period
Since everything inherits from `IntegerField` it should be enough to only register lookup for it. In short `models.BigIntegerField.register_lookup(RangeContainedBy)` is redundant.
This can be simplified to the following to reduce the number of `isinstance()` calls when finding a serializer: ```python MigrationWriter.register_serializer( (DateRange, DateTimeRange, DateTimeTZRange, NumericRange), Psycopg2ExtraSerializer, ) ```
I remember looking at this test when merging 233c70f0479beb3bff9027e6cff680882978fd4d. I just tested this now and if you use `with register_lookup(field, Exactly, lookup_name='exact'):`, then this is the state at the end of the test: ``` >>> Author._meta.get_field('birthdate').get_lookup('exact') <class 'custom_lookups.tests.Exactly'> ``` With the current code, the output is `<class 'django.db.models.lookups.Exact'>` which looks correct to me. So I'd leave this as is and remove the unused `CustomExactLookup`.
Hmm it's not clear to me what this test is trying to accomplish, what's the purpose of `CustomExactLookup` in the first place since it's `Exactly` that is registered.
Use `self.assertCountEqual()` when ordering is not specified and we have more than one expected result.
I guess Article/Category deletes aren't doing anything since you already asserted exists() -> False. Anyway, I think I'd put this in a separate method. `test_loading_with_exclude_app` / `test_loading_with_exclude_model`
It would be better to move these two into a separate test method.
We try to avoid non-4 space indent like this. You could move this to `msg = "..."` instead.
Would be slightly better to use non-contrib models in case sites is someday removed.
it's a separate item, but I wonder if we could patch override_settings to handle DATABASE_ROUTERS like is done below
can you call `sort` on the invalid_apps before joining them, please.
@charettes Thanks :+1: I removed unnecessary connector, see #15511. As far as I'm aware we now prefer non-kwargs constructions for internal usage, see 9662193aea2ee982bc8e553c62499aca5e606755 and #14699,
Minor but this could have likely be simplified by using `reduce` to avoid the private `_connector` usage ```python condition = reduce( (Q(app_label=app_label, model__in=models) for app_label, models in needed_models) , operator.or_) ``` In all cases `Q(("app_label", app_label), ("model__in", models), _connector=Q.AND)` can be simplified to `Q(app_label=app_label, model__in=models)` since `_connector` defaults to `Q.AND`.
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
I don't think you need `list()` here.
I'd probably combine that with the outer `if`: `if not rendered and hasattr(...) and callable(...):`
`Exception as e`
Is this possible? If so, it will be good to cover this scenario with tests.
I fixed this issue in fe0ddbc84e4d8836ce8d27a1218d360c5482c2be.
Same as above; let's leave it alone for now.
> @felixxm in my view, below test code is our expected result. No, it's not. `1 != NULL` so why it's expected that `number` is excluded? see 512da9d5855 and ticket-23797 for more details.
> my changs affect when LHS is annotation field and RHS is not field. I know, but this is also an issue with nullable annotation so we should fix it in this PR. If it is a different branch in `build_filter()` then we have another reason to add some hook.
I really don't like that we increase indentation here, it make code less readable, and it's complicated even without this :disappointed: We could reduce the number of changes significantly with: ```python if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) clause.add(condition, AND) # When col is nullable, add IS NOT NULL. col = self._gen_cols(reffed_expression) if col: lookup_type = condition.lookup_name target = col.target if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None and self.is_nullable(target): lookup_class = target.get_lookup('isnull') col = self._get_col(target, target, alias) clause.add(lookup_class(col, False), AND) return clause, () ``` and reverting related adjustments.
FYI I ran into the same issue of `AttributeError: 'generator' object has no attribute 'target'".` with this test checking if this PR fixed the issue when using exclude with an `alias` (flagged up in duplicate [ticket-32896](https://code.djangoproject.com/ticket/32896)): ```python # ExcludeTests def test_exclude_aliased_nullable_fields(self): number = Number.objects.create(num=1, other_num=1) Number.objects.create(num=2, other_num=2, another_num=2) qs = Number.objects.alias(aliased_num=F('num')) self.assertSequenceEqual( qs.exclude(another_num=F('aliased_num')), [number], ) self.assertSequenceEqual( qs.exclude(aliased_num=F('another_num')), [number], ) ```
yeah having an `Expression.nullable` flag that is also present on `Col` instance based on the `Field.null` they resolve would be useful for a few other things I've worked on in the past.
This error no longer makes sense with multiple-arg aggregates. You'll either need to join the output of all source expressions so the error produces: > Cannot compute Sum(arg1, arg2): 'X' is an agggregate # (where X is either arg1 or arg2) Or you'll need a different error message for the case of `len(args) > 1`. There may be another solution (like ditching this message altogether) but I'll let you experiment with that if you like.
Try to reduce line length to make review easier.
I noted this too and wasn't sure if it was an error or not. Can you 'save' an aggregate? ``` Model.objects.update(salary=Max('salary')) # would this work? ```
Is this check correct? A `Coalesce` can still result in a null value (if all of its arguments are null), so even if the expression is already a `Coalesce` ISTM it needs to be wrapped again (or have `Value('')` added to the end of its `source_expressions`, but just wrapping in another `Coalesce` seems cleaner).
Constructing the entire string within the as_sql method departs from how other functions work. Is it possible to do something like: ``` class BaseCaseExpression(Func): function = None template = 'CASE %(simple)s %(conditions)s ELSE %(default)s END' ``` Then build up the dict required to fill in that template, and construct/return at the end? It may flow nicer, and allow 3rd party backends to modify the template without overriding the entire method.
Frankly, I don't remember the details here, and I only have time to glimpse the PR now, but it seems that there may be two cases where multiple rows of returned values may be expected: `bulk_create()` on one hand, and an `UPDATE` statement on the other (you wouldn't need to returned values in an ORM `update()` call, but you would need them in the lower-level API).
I checked and on PostgreSQL we have a list of tuples for multiple rows and a tuple for a single row; on MariaDB we have a tuple of tuples for multiple rows and a tuple for a single row :confused: It's a really implicit logic, we should support both formats in: https://github.com/django/django/blob/8f2a6c76d19e4010c4683b20ed7f1eb4b07c17eb/django/db/models/query.py#L1257-L1260
I wonder why it works without `list()` on PostgreSQL :thinking:
Do we need to call `str()` on `contraint_sql`? ```suggestion if contraint_sql: schema_editor.execute(constraint_sql + ' NOT VALID') ```
Maybe something along the lines of: For databases which do not support returning clause we need to ask the database for the id. Generally last_insert_id is only supported for serial/auto_incr columns, hence we guard it for auto field. \# TODO: Maybe add a marker to fields that their value can be returned by last_insert_id instead of a type check. +/- typos and style cleanups ;)
would it make sense to lazy-load uuid as most projects won't need it? It could be done with just one more line of code in this file and in django/forms/fields.py
This should be Django's vendored copy `from django.utils import six`
This looks unexpected per isort.
`from django.db.models.functions import Cast`
Diff will be smaller without this unnecessary change.
I think wrapping in `Point()` is causing the test crash.
`list` is unneeded here. As an alternative you could use: ``` qs = State.objects.filter(pk=null.pk) self.assertFalse(qs.filter(poly__intersects=LineString((0, 0), (1, 1), (5, 5)))) ```
You could use a loop and subTest to make the test less repetitive. e.g. have a list of dicts like `{'poly__equals': Point(1, 1)}` and then use `qs.filter(**filter_kwarg)` within the loop.
Up to you, but I think the tests are short enough that the blank lines don't help much.
```suggestion functions.FromWKT(Value(g.wkt)), ```
Start the sentence "Duration's number of days..." Also, add a trailing period.
For translators, it would be better to use named placeholders, so languages which need reordering can do it nicely.
You can use `self.assertIsNone` here.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
(same pattern as above, if you change it)
I'd only use mock as a last resort and instead pass some email that will be affected by the normalization.
You should be able to pass `is_active=False` to `create_user()`.
What's the point of this query? I don't see anything in the view which could delete users (and even then, why should it delete users…)
as noted in other PR, think we can omit a newline before a single assert
Please add a trailing comma.
I would multiline: ``` field.attname for field in self.lookup_opts.fields if field.unique and not field.null ```
May as well do the following as a field name can only legally have a single `-` at the start: ```python field_name = part.lstrip('-') ```
```python if ordering_fields.issuperset(field.attname for field in fields): ```
I'd remove this blank line.
"ordering, rely" (add comma & chop "we")
Wrap lines at 79: ``` "The value of 'list_filter[0]' refers to 'RandomClass', which " "does not refer to a Field.", ```
Please put the closing ) on the next line as in other tests.
No, not necessary.
Please remove the leading blank line in all tests.
Chop blank line.
Fair enough, I assumed it was a small tweak to the stdlib version.
Is this code based on an existing implementation? If that's the case, we should specify it / link to it.
I think this line isn't needed, tests seem to work fine without it.
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
chop first comma
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
chop newline for consistency with other tests
`.all()[0]` -> `.first()`
It should give 'Modification de Title et Historique.'. I guess a gettext call is missing inside the `LogEntry.get_change_message`.
You are leaking information about whether somebody has access or something doesn't exist.
Raising a 404 with the same message as in the previous check would mask the issue. Then again I think we already leak a lot like that in other admin pages, will have to double check.
Slow or not, it is kinda pointless to do since we do not need the data -- so yeah, we should not count here
Yeah, this is a good point, reuse an ordering if possible (maybe even force it)
Add a message please.
You can you use the `cached_property` decorator here.
Style: can you sort `__str__` and `__repr__` between the other private methods on top.
Style: Can you move that `add_child()` above `add_parent()`.
I think we should raise a more descriptive error, maybe the same as in `add()` and `set()`.
Please use triple double quotes around docstrings. ([PEP 257](https://www.python.org/dev/peps/pep-0257/#what-is-a-docstring))
I don't think that it is a proper solution because `get_order_dir()` returns only field name and direction, so it will not properly in case of using database functions in `meta.ordering`. I think we should fix this in `find_ordering_name()`, e.g. ```diff diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py index a44adfc760..fb2a4b23b1 100644 --- a/django/db/models/sql/compiler.py +++ b/django/db/models/sql/compiler.py @@ -716,6 +716,9 @@ class SQLCompiler: results = [] for item in opts.ordering: + if isinstance(item, OrderBy): + results.append((item, False)) + continue results.extend(self.find_ordering_name(item, opts, alias, order, already_seen)) return results ```
`test_date_kind()` and `test_time_kind()` in `test_trunc_func_with_timezone()` doesn't have any value because both don't support timezones and are already covered by `test_trunc_func()`. I removed them.
You should use tuple deconstruction in a number of places, starting with `query, params = super().as_sql()`. See other SQLCompiler methods. Also you seem to have replicated a bit of logic from `SQLCompiler.get_order_by()`. You shouldn't do that, but find a way to reuse it. `order_by()` supports many forms beyond the asc/desc field name form you've compiled here.
"Test checks MySQL query syntax"
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
Wouldn't it be a bit more helpful for this error message to specifically note that the module with the given path couldn't be imported? "Invalid" is a very vague term, which could mean all sorts of things - it seems unhelpful to silence an `ImportError` and replace it with a much vaguer message.
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
has a -> is of a
Is there a reason `edit` was chosen instead of `change`. It's the only pattern that differs from it's name.
> ... even if nothing bind us to use the same term for url and pattern name. I know it's just it's just something I noticed. Wouldn't object `edit` being used in the end.
If we had to do it again, "edit" would probably make sense, but I think "change" makes sense given that terminology is used elsewhere "change view", "change permission", etc.
compatibility in Django 1.9
that's the default in 1.9, but I don't if you want to include it anyway
I would remove the quotes, typically we only use a lazy reference if necessary.
We can chop `FK`.
This looks unnecessary: ```suggestion ```
Unnecessary -> ```suggestion def __str__(self): ```
We can reuse `Author` model. If we need two `CharField`s then we can add e.g. `alias` to the `Author`.
The issue here is that we can't do the proper permission check (`if not self.has_perm(request) ...`) until after we've assigned `self.model_admin`, which we return from this method. _Maybe_ it's OK. But… it seems like we have the exact kind of _"Folks can probe the autocomplete view to find out the structure of the application"_ issue that we spend a lot of time thinking about and trying to avoid. If we just raise `PermissionDenied` for all of these cases we don't leak any info. Such exceptions are logged and a developer can use that to debug. Given that this is an ajax view, they're not going to see the debug output page anyway (without taking steps). I'm not convinced the different status code is worth the additional exposure (or even the effort justifying why it's OK). > 🤷 Yes. 🙂
"Django" doesn't add much: ```suggestion # Retrieve objects from parameters. ```
Hey @codingjoe — so I think I would restructure this section slightly, through to line 59. * I'd create a method to configure three attributes on self: `source_field`, `model_admin`, and `to_field_name`. It'd need to take the `request`. In there I'd include all the `try:except:` blocks and raise an `AutoCompleteSetupError` (or similar) if any of them occur. * Outside that method I would have a single `try:except:` to log the error, and return the JSON 403 response. (I'm thinking about how I'd debug this if there's no logging, and all I have to go on is a 403...) I think we should also move the `has_perm() -> 403` check **above** the `get_search_fields() -> 404`. (That last if nicely informative for users but we shouldn't hand out that info to someone without the permissions to access the modeladmin at all… 🤔)
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
I think `GET` is fine for that.
`source` will be **always** `None` so it is not a proper solution.
@CruxBox Please fix also `aggregation.tests.AggregateTestCase.test_combine_different_types`.
Maybe: ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 16df317631..36f88f99ec 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -286,8 +286,15 @@ class BaseExpression: """ sources_iter = (source for source in self.get_source_fields() if source is not None) for output_field in sources_iter: - if any(not isinstance(output_field, source.__class__) for source in sources_iter): - raise FieldError('Expression contains mixed types. You must set output_field.') + for source in sources_iter: + if not isinstance(output_field, source.__class__): + raise FieldError( + 'Expression contains mixed types: %s, %s. You must ' + 'set output_field.' % ( + output_field.__class__.__name__, + source.__class__.__name__, + ) + ) return output_field @staticmethod ```
Use hanging indentation ```python raise FieldError( 'Expression contains mixed types: %s, %s. You must set ' 'output_field to %s.' % ( output_field.__class__.__name__, source.__class__.__name__, source.__class__.__name__, ) ) ```
Might want to use a generator here to make it more readable `(field for field in self.get_source_fields() if field is not None)`.
put closing ) on next lin
(And round-tripping of the messages is already tested in other tests)
I think `force_text()` isn't needed but rather adding `from __future__ import unicode_literals` to this file.
Yes -- does this change affect that case.
I'd probably use `if six.PY2` here, so we remember to remove this branch when we drop Python 2 compatability
Only literal values of functions with literal values arguments should be allowed here. No _resolving_ phase should be necessary if an expression is provided, the only requirement should be an `as_sql` function that gets passed a `compiler` and a `connection` through `compiler.compile`. The way it's currently defined is too lax because it allows field references and event JOINs
Do we want to allow setting both `default` and `db_default`? Might make sense if one only wants to use `db_default` during a deploy to prevent downtime.
I guess we could defer `check_field_default_support` to a system check instead? It could also be performed in `db_default_sql` for good measure.
I'd use a classmethod to provide the default index type (I think that's cleaner than resetting the attribute in the initializer)
I'd vote for making `returning` a `property` instead of a stealth field option at least for now because this is not something we've done in the past. ```python @property def returning(self): return hasattr(self.default, 'as_sql') AutoField.returning = True ``` That would make `DateTimeField(default=Now)` work and avoid the ambiguity of `default=Now, returning=False`. We'd still have to deal with backends that don't support returning fields.
I think at least the latter is worth it - it's confusing to submit two files and be told "the" file is empty.
`assertTrue(value)` will pass for `bool(value) is True` which is different than checking for `True`.
These assertions are not related with this patch. Personally I don't see much value in adding them.
Where in the process of replacing these constructs with `self.assertSequenceEqual`, see #7226.
We should also test for `events = Event.objects.filter(group__in=groups.query)` to test both `isinstance(self.rhs, QuerySet)` branches.
We don't use `self.value.value` anymore so we don't need to serialize it, we should use name instead, i.e. ```python v_string, v_imports = serializer_factory(self.value.name).serialize() imports = {'import %s' % module, *v_imports} return "%s.%s[%s]" % (module, enum_class.__name__, v_string), imports ```
Isn't this equivalent? ``` if (start and start < 0) and (end and end > 0): raise ... ```
We should **return** `NotImplemented` not raise a different exception, see 54ea290e5bbd19d87bd8dba807738eeeaf01a362 and ticket-30651.
This should return `NotImplemented` when a type of `other` doesn't match: ```suggestion if not isinstance(other, RegexObject): return NotImplemented return self.pattern == other.pattern and self.flags == other.flags ```
Can we make any positive assertion? I'm a bit nervous about a negative assertion like this since, for example, a typo in the regular expression could cause the test to pass by mistake.
`HTTPS` is not necessary, so I removed this line.
I suggest: ``` self.assertEqual( csrf_cookie.value, self._csrf_id_cookie, '.....' ) ```
Use `assertContains()/assertNotContains()` instead.
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
Ahh. Got it. That makes sense. (Seems fine to me if we eventually remove it. Maybe raise a deprecation warning.)
Oooooh. _/me grabs shovel, digs hole, hides_
As above, leave the docstring and change to deprecation to 2.0.
Didn't know `__instancecheck__` was never called when `instance.__class__ is self`.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
I think usual formatting is: ``` # -*- coding: utf-8 -*- from __future__ import unicode_literals import os import sys from wsgiref.simple_server ... ``` (wsgiref is a built-in so it goes with os/sys)
Please use the same ` -*- coding: utf-8 -*-` in all files.
only need 'coding' if there are non-ascii chars in the file
We usually only include this if there are non-ASCII characters in the file.
remove extra newline
Minor but I think a warning will be raised here as this is passing a naive datetime will timezone support is enabled.
Ah, I see. I looked for such a change in the original method, not in an override. Maybe that's a sign that such an override isn't the best approach in any case. Using a string might indeed be better, then :-)
And add `obj.normal.close()` at the end to fix the failure on Windows.
``` python # the following time is equivalent to UTC 2014-03-13 05:34:23.24000 ```
@codingjoe I'm going to check why `test_insert` and `test_bulk_insert` fail on Oracle with the current implementation :thinking: .
Also, maybe just call this `post_error` as "to raise" is redundant.
I think you can remove this one-line method and inline the code instead.
Make `__str__` return `self.string_rep` and nuke `__unicode__`.
`HTTPS` is not necessary, so I removed this line.
Since this is a new arg, we can enforce kwarg-only on it: ```suggestion *, headers=None, ``` (in all places) I think this is a good idea to avoid overly long positional argument lists
You can have a look at 9bf652dfd6a738fd841471f6abd71cba1b206d9f as an example of how we introduced object level permission to authentication backends.
Please don't make unrelated whitespace changes.
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
`items = value.split(self.delimiter) if value else []` is slightly faster.
``` # If the filename already exists, generate an alternative filename # until it doesn't exist. ```
Can you describe the reason for using 'singular' here and (as an example) not 'plural'? Code looks fine style-wise; I'm trying to understand the issue a bit more since translation isn't my expertise (If you want a review about that).
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
Please test the entire message.
```suggestion with self.time_keeper.timed('Total database setup'): ```
There should be a way for users to disable the coloring of `runtests` too.
please use hanging indent to make better use of space, e.g. `context = Context({'content': '<b>"Escaped" content to try \'force_escape\ argument & check for errors.</b>'})` might be good here
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
indent style: ``` self.assertEqual( rendered, '...' '...' ) ```
there's also six.assertRaisesRegex which can be useful for checking the message
Ticket describes an issue when `USE_L10N` is off, so I think we should check both combination: ```python with self.settings(USE_L10N=True, DECIMAL_SEPARATOR=','): ... with self.settings(USE_L10N=False, DECIMAL_SEPARATOR=','): ... ``` Please move tests for a thousand separator to a separate commit because they work without this patch.
This will always return the same as `self.db_type()` which is not intended. I added `__mro__[1:]` to fix this.
You mean `super()`? Seems okay to me.
I think it'd work if you put the mixin to the left of the base class where it's used.
Similarly, I don't see much advantage to creating indirection with a method.
Makes sense. Falling back to `field.db_type(self.connection)` will cause silent truncation of `ArrayField(CharField(max_length=100)) -> ArrayField(CharField(max_length=50))` and `ArrayField(Field(), size=10) -> ArrayField(Field(), size=5)` though but I guess it's better than crashing.
Hey @codingjoe — so I think I would restructure this section slightly, through to line 59. * I'd create a method to configure three attributes on self: `source_field`, `model_admin`, and `to_field_name`. It'd need to take the `request`. In there I'd include all the `try:except:` blocks and raise an `AutoCompleteSetupError` (or similar) if any of them occur. * Outside that method I would have a single `try:except:` to log the error, and return the JSON 403 response. (I'm thinking about how I'd debug this if there's no logging, and all I have to go on is a 403...) I think we should also move the `has_perm() -> 403` check **above** the `get_search_fields() -> 404`. (That last if nicely informative for users but we shouldn't hand out that info to someone without the permissions to access the modeladmin at all… 🤔)
The issue here is that we can't do the proper permission check (`if not self.has_perm(request) ...`) until after we've assigned `self.model_admin`, which we return from this method. _Maybe_ it's OK. But… it seems like we have the exact kind of _"Folks can probe the autocomplete view to find out the structure of the application"_ issue that we spend a lot of time thinking about and trying to avoid. If we just raise `PermissionDenied` for all of these cases we don't leak any info. Such exceptions are logged and a developer can use that to debug. Given that this is an ajax view, they're not going to see the debug output page anyway (without taking steps). I'm not convinced the different status code is worth the additional exposure (or even the effort justifying why it's OK). > 🤷 Yes. 🙂
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
This can raise a `LookupError`
If I understood the above code correctly, then `self.field` is on the source model, whereas `self.model_admin` points to the target admin, I think we should really rename those to avoid confusion.
Chop blank line.
Use single quotes consistently.
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
Please use f-strings as Python 3.6+ is now the requirement More information is available including some benchmarks. https://cito.github.io/blog/f-strings/
We can remove this check after fixing the `Field.slice_expression()`.
Chop blank line.
I think it will be more readable to keep `int` and `slice` in separate branches, e.g.: ```python def __init__(self, f_obj, slice_obj): if isinstance(slice_obj, int): if slice_obj < 0: raise ValueError('Negative indexing is not supported.') self.low = slice_obj self.length = 1 elif isinstance(slice_obj, slice): if ( (slice_obj.start is not None and slice_obj.start < 0) or (slice_obj.stop is not None and slice_obj.stop < 0) ): raise ValueError('Negative indexing is not supported.') if slice_obj.step is not None: raise ValueError('Step argument is not supported.') self.low = 1 if slice_obj.start is None else int(slice_obj.start) + 1 self.length = None if slice_obj.stop is None else int(slice_obj.stop) - self.low + 1 else: raise TypeError('Argument to slice must be either int or slice instance.') self.expression = f_obj ```
Casting `int` to `int` is not necessary.
If ...., the locked row is skipped resulting in Person.DoesNotExist.
DatabaseError is raised if a ....
Please add trailing comma.
It would clear ambiguity if you added some parentheses here and on the next line: `(' LIMIT %d' % limit) if limit ...`. Initially, I thought the grouping was `% (limit if limit else '')`.
I think that: ```python return 'FOR UPDATE%s%s%s' % ( ' OF %s' % ', '.join(of) if of else '', ' NOWAIT' if nowait else '', ' SKIP LOCKED' if skip_locked else '', ) ``` is more readable.
I think it's more readable (and readability is crucial in the ORM) with the opposite of `alternate_output_field` e.g. `source_output_field`: ```python def get_col(self, alias, output_field=None): source_output_field = output_field is None if source_output_field: output_field = self if ( alias != self.model._meta.db_table or (not source_output_field and output_field != self) ): from django.db.models.expressions import Col return Col(alias, self, output_field) else: return self.cached_col ```
Put this on the previous line.
Management command use `OutputWrapper()`, so we need to do the same here.
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
If you assign the default as `Value(None)`, then you shouldn't need to conditionally add `self.default` in get/set_source_expressions. It should just convert to NULL sql string.
Yes this would be a good idea
I think this should be instantiated by the runner, rather than a global instance. Otherwise multiple runs in the same process share state (imagine a script that calls `call_command('test')` in a loop).
It seems that the `timing` parameter is doing too much work. We're storing it in the runner, plus passing it down to the time keeper class, for it only to be used here. Q: why is it the time keeper's job to choose whether output is displayed by the runner? (A: it's not) I think two classes would be better than the conditional. `TimeKeeper` and `NullTimeKeeper`, then in the runner we don't store `timing` but just do: ``` self.time_keeper = TimeKeeper() if timing else NullTimeKeeper() ``` `NullTimeKeeper` should implement no-ops for `timed()`, `append()` and `results()` and just a single `yield` for the context manager.
```suggestion new_record = '%s took %.3fs' % (record, record_time) ```
Should we name this `print_results` or move the `sys.stderr.write()` call outside? (I don't know if there would be a use for returning the generated text for something other than printing it out.)
Drop the docstring I think,
Try to avoid `Check that` and `Check`.
Okay, super, thanks for the clarification @pope1ni. I shall take another look tomorrow and hopefully that's job done! Good work, as ever. 😉
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
you can collapse, `with self.assertRaises(Exception), connection.cursor() as cursor:`, and in a few places below.
Not a blocker or anything but `concurrently` seems more appropriate than `concurrent` for the kwarg name to me. e.g. `add_index(model, index, concurrently=True)`
```python hanging = ( indentation, has, a, newline, after, opening, bracket, ) ```
from Python, so we quote and substitute parameters manually.
You may change the others if you like, but please make it a separate commit.
We try not to include ticket references in docstrings unless the ticket has a lot of context that the test cannot convey.
`parent_data` and `child_data` are `CharField`\`s, so maybe `'a'`, `'b'`, ... etc.
This assertion is not related with this fix so I would move it to a separate commit.
Now that I look at this, I think I would combine the 3 cases that use this in 1 test method to avoid the helper method. We prefer using the context manager version of `assertRaisesMessage` for better readability.
My concern with adding `copy()` is that it is adding in redundant work for most cases to appease a small subset of very specific use cases.
with -> the
put `self.object.pk` on the next line include a trailing comma
`msg = None` then only warn if msg is set.
We should have a more generic solution and deep-copy all non-picklable attributes, e.g. ```python for attr in self.non_picklable_attrs: if hasattr(self, attr): setattr(obj, attr, copy.deepcopy(getattr(self, attr), memo)) ```
`pk` is twice. I think the last `and pk` can be removed.
Indentation can do a lot for legibility here: ``` fields.update( (field, (field.name, field.attname)) for field in self.local_fields if include_non_concrete or field.column is not None ) ```
pep8: no spaces around `options_instance`
``` python for obj, query_name in six.iteritems(parent._meta.get_fields(data=False, related_objects=True, include_hidden=True, **options)): ```
Ah... now I see.
NotContains always makes me nervous since it's fragile (a typo or a change in the way we generate the HTML could make it pass). Could we make `class="inlinechangelink">Change</a>` a constant and use it in all 3 of the new tests? That would help alleviate those concerns.
```suggestion '<div class="fieldBox field-position hidden">' '<label class="inline">Position:</label>' '<div class="readonly">0</div></div>', ```
```suggestion '<div class="fieldBox field-position hidden">' '<label class="inline">Position:</label>' '<div class="readonly">1</div></div>', ```
this can be a single line (we prefer longer lines when it improves readability)
I've removed an extra newline that caused a flake8 error.
I think we can drop the empty line here.
I don't think we want to subclass `base.Deserializer`. Instead, we can just do `self.object_list = object_list` and use that instead of `self.stream` below.
returning `None` isn't perfectly equivalent to `continue`. I think it might be cleaner to move some or all of `_handle_object` back into `__iter__`. This allows us to use `continue` again.
You should be able to use `SimpleTestCase` (which prevents any queries) by setting an `id` manually on your score instance, avoiding the `save()` call and passing a singleton list containing `score` to `serializer.serialize()`: ``` python data = serializer.serialize([Score(id=1, score=3.4)]) ``` With this approach you should be able to hardcode the `"pk": 1` below as well.
You might want to `assertIsInstance(serializer.stream, File)` to make sure the `stream_class` attribute was actually used.
I think we should `warnings.warn('...', category=RemovedInDjango40Warning)` here.
If we do it the other way around by using an identity transformer `if isinstance(values[0], qs.model)` we would work around the `QuerySet.values_list('charfield', flat=True)` use case.
These two could be `and`ed.
`self.assertSequenceEqual(qs.values_list('field', flat=True), [(['hello', 'goodbye'])])`
Maybe test it in `tearDownClass()` then? That method is executed after all tests.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
`UniqueConstraint` not `Index`.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
aaah, ok, now I get it.
I don't see a use case for the new argument right now. If you want to replace the strings, it seems more commen to provide your own PO gettext files/translations. That way you can provide your own strings, while not changing the place holders.
Oracle doesn't really have a date-without-time data type. If you're selecting data using raw SQL, you need to account for this yourself.
You mean on Oracle? There's Django's CI infrastructure (I think Oracle is run for all PRs automatically, but it may need special invocation). Other than that, you can [set up an environment locally](https://code.djangoproject.com/wiki/OracleTestSetup) but it's a little involved if you only need it for one patch.
We can revert this unrelated change.
`for data in json.loads(...):`
Here's another place where an unnecessary line break is inserted after the period.
Yes, it would be good to add a docstring.
I feel like we shouldn't override "private" methods to test, I also don't see why that would be necessary here.
Isn't the `Car` left in the database after this test? It should be deleted here too, I think.
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
Do we need an inner import? `from . import urls` should work fine.
As the code itself hints, there's no reason to assume the imported attribute is a class.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Silencing far more exceptions than previously (where it was `ImportError`) ... is this intentional, and will it lead to people having a harder time debugging when their app config goes wrong? I guess it'd be somewhere higher up the chained stack traces, maybe? Same expansion of caught exceptions (`ImportError` -> `Exception`) happens at the `import_string` so I assume the answer to this also answers that.
Oh, that surprises me too...
`response.request.method` would be more idiomatic.
A note about code length, because some users may say "using self.client.get() is more straightforward"... We can also write the lines above (297-301) like this: ``` python view = views.CustomTemplateView.as_instance( RequestFactory().get('/dummy'), foo='bar') ``` That said, the way they are written right now is fine too.
Actually `assertContains` checks the `status_code` too, so the other assertion is redundant.
Yes as the standard response is to redirect to the login page
Use list and remove unnecessary whitespace ```suggestion fields = [('name', 'position')] ```
This can be single-lined.
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
It would be nice to be consistent about the ordering in `assertEqual` using it's `(variable, 'expected value')` but here and a couple other places it's opposite.
Hey @codingjoe — so I think I would restructure this section slightly, through to line 59. * I'd create a method to configure three attributes on self: `source_field`, `model_admin`, and `to_field_name`. It'd need to take the `request`. In there I'd include all the `try:except:` blocks and raise an `AutoCompleteSetupError` (or similar) if any of them occur. * Outside that method I would have a single `try:except:` to log the error, and return the JSON 403 response. (I'm thinking about how I'd debug this if there's no logging, and all I have to go on is a 403...) I think we should also move the `has_perm() -> 403` check **above** the `get_search_fields() -> 404`. (That last if nicely informative for users but we shouldn't hand out that info to someone without the permissions to access the modeladmin at all… 🤔)
```suggestion timeout=60, ``` "60" on its own looks a bit weird. Also, it surely doesn't need to be as long as 60 seconds if `DELAY_AFTER_FAILED_LOGIN` is so much smaller? What if `DELAY_AFTER_FAILED_LOGIN > 60`? Maybe this should be: ```suggestion timeout=self.DELAY_AFTER_FAILED_LOGIN + 10, ```
@pahko `2` , `3` and non-empty lists and objects also will be valid case. Only check for boolean is needed here.
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
Please don't make unrelated whitespace changes.
That docstring doesn't add much info. It isn't useful to paraphrase a function's signature!
This is wrong, `SESSION_COOKIE_NAME` is the name used in the cookie, not an attribute name on the `request` object. Besides it isn't equal to `'session'` by default.
This is also wrong, `LANGUAGE_COOKIE_NAME` is the name of the cookie, not the name used in the session.
unclear if this is `'name' not in lang_info` or `not ('name' in lang_info ...` (I think the first) would be helpful to restructure or adds parens so it's easily readible
I think you could merge the two `if` statements into one: ``` if (lang_code not in supported and lang_code in deprecated_locales and deprecated_locales[lang_code] in supported): return deprecated_locales[lang_code] ```
These could be alphabetized.
I believe the name should be `CITextField` for Case Insensitive Text Field.
(It's kinda hilarious to recommend a case change on a name that's literally case insensitive.)
For consistency, use a tuple instead of a list.
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
Meanwhile, I merged a conflicting patch. I think you just need to remove the quotes from around the star.
OK I figure out why it doesn't fail. `ErrorClassTest` must be the first one, because there is a single instance of `DebugSQLTextTestResult` so `debug_sql_stream` already exists if we run any test before it. Edits is progress ...
This patch fixes the issue for me, however new tests work even without it, so I don't think we need them. Unfortunately, it's more complicated then raising and error in the `setUpTestData()`.
This looks unrelated.
Indents should be four spaces.
I think we should copy `fields_cache`: ```suggestion state['_state'].fields_cache = state['_state'].fields_cache.copy() ``` because a copy of model instance can use the same values and we don't need to fetch it again.
Thanks, the current approach LGTM. Please uncheck "Patch needs improvement" flag on the ticket after local testing.
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
Ah, good point. I don't think it's cleaner in general, I was just trying to keep `QuerySet` / `Query` fast like my optimization efforts. Since it's a fairly small here I don't feel that strongly about the global, you can leave it as-is
Slightly faster: do `suppress_AttributeError = suppress(AttributeError)` at the module level then use `with suppress_AttributeError` here, avoid reconstructing it each time.
Alternatively, you could handle this where `fields` is updated with `new_class.declared fields` like so: ``` for field_name, field in new_class.declared_fields.iteritems(): if opts.exclude and field_name in opts.exclude: continue if opts.fields and field_name not in opts.fields: continue fields[field_name] = field ```
I would structure this like this: ```python fields = fields_for_model( opts.model, opts.fields, opts.exclude, opts.widgets, formfield_callback, opts.localized_fields, opts.labels, opts.help_texts, opts.error_messages, opts.field_classes, # limit_choices_to will be applied during ModelForm.__init__(). apply_limit_choices_to=False, ) ```
These args could be wrapped closer to 79 chars.
Why is this on two lines? Why not just...? ```python data_altering_methods = getattr(cls, 'data_altering_methods', ()) ```
Is `test_doesnt_work_with_init_subclass` meant to test this change? I still don't see any test failures if this change is reverted.
has been -> is
URLconf chop trailing space
Why the `!= 'app'`? This seems to hide some test failures in `test_check_unique_namespaces`.
Prefer the context manager version: ``` self.assertRaises(Resolver404): resolve(url) ```
`url.urlconf_name` is, more often than not, a URLconf name or module, not a list of patterns. It would be better to use `url.url_patterns` here as well.
> Is there any reason to explicitly prefer lowercase? Well, not really anything critical. Elements, attributes, etc. in HTML tend to be case insensitive and I tend to lowercase the lot - more similarity leads to better compression in transit. Granted this isn't going to make much difference for such a short string, and your point about implementation detail is fair. (Hence I didn't press for it...)
I moved this test to the `tests/messages_tests/tests.py`.
missing space after : (check code with flake8)
Could use `charset` over `character_set`? It's a well-known "word" and losing the underscore might make this less noisy visually, especially in the f-strings. Only a suggestion, feel free to ignore.
This can raise a `LookupError`
```suggestion msg = 'Slice stop must be greater than slice start.' ```
`Company` doesn't have a default ordering so we need to use `assertCountEqual()` or add `.order_by(...)`.
I don't think it's necessary. In all cases we test the same (default) implementation. A single assertion should be enough, e.g. ```python def test_invalid_fields_in_slicing_f_expressions(self): msg = 'This field does not support slicing.' with self.assertRaisesMessage(NotSupportedError, msg): Company.objects.update(num_chairs=F('num_chairs')[:4]) ```
Perhaps extend this for a wider range of field types, e.g. `BooleanField`, `IntegerField`, `FloatField`, etc.
Include a trailing comma so that if more items are added later, so we don't need to modify this line again.
I added this missing change to the first commit.
no blank line please
Overall, the changes are mostly fine, I just wonder if we might use this as an opportunity to tighten up large try blocks and use try/except/else instead (such as here).
I don't think you need this check here. This case will be handled in the for loop. Otherwise you can skip the first item in `cls.mro()` as well.
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
This inner import is a syndrom of the circular dependency between `Manager` and `QuerySet`. Could we avoid it by moving this code inside `_Manager`? `Manager` would know how to create a subclass of itself with the methods of a given `QuerySet`.
more than one automatically generated field.? sounds better and more natural with the changes.
I think we can use `in cls` instead of `in cls.__members__.values()` (here and in `names`).
I would use `choices` in `labels` and `values` to simplify implementation, e.g. ```python @property def labels(cls): return [label for _, label in cls.choices] @property def values(cls): return [value for value, _ in cls.choices] ```
I wouldn't call `AutoField` a "legacy", we should also include `SmallAutoField`.
I think that we can squash this to two cases, i.e.: ```python if not self and other: return copy.deepcopy(other) elif not other: return copy.deepcopy(self) ```
I don't think we want to special case `Subquery`, feels like we'll want to duck type on `conditional` ```suggestion if not isinstance(other, Q) and not getattr(other, 'conditional', False) is True: ```
Make `__str__` return `self.string_rep` and nuke `__unicode__`.
I noticed that we missed keys comparison, e.g. `exception_a` and `exception_b` are equal: ```python exception_a = ValidationError({'field1': 'field error', 'field2': 'err'}) exception_b = ValidationError({'field2': 'err', 'field1': 'field error'}) ``` we should fix this, maybe: ```suggestion if hasattr(self, 'error_dict'): return hasattr(other, 'error_dict') and self.error_dict == other.error_dict return sorted(list(self)) == sorted(list(other)) ``` a test is also needed.
Using elif is slightly clearer
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
Unindent by one level, please.
Most likely this will not work on Windows because files created with `NamedTemporaryFile` cannot be reopened on Windows (which defeats the whole purpose of naming them in the first place -- I have no idea why `NamedTemporaryFile` even exists on Windows). I'm not saying this is blocking the merge because I don't think we have that many users of PostgreSQL on Windows, but I thought I'd bring it up in case someone wants to check.
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
This test is already in the `backends.base.test_creation` and it's unrelated with this fix. Please remove it.
Use single quotes consistently.
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
Wrap lines closer to 79 characters and use () when referring to a function. ``` # get_current_site() will lookup a Site object, so these must match the # domains in the MockSite model. ```
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
Is there a need to hardcode pks? This is generally to be avoided, I think.
We don't need to mock `django.db.migrations.questioner.sys.stdout` anymore.
if no app*
Passing `stdout` and `stderr` is not necessary. ```suggestion call_command('makemigrations', 'migrations', interactive=False) ```
was referring to `call_command`. the `os.path.join` is okay.
Please revert unrelated cosmetic changes to keep the diff clean.
Single quote strings ```suggestion module = types.ModuleType('test_module') ```
I don't believe so, this does seem unneeded. As a whole, this and the two lines below are pretty performance critical to the reloader but I don't see how removing `list()` would cause any issues with that.
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
`getattr(module, '__spec__', None) is None` is more concise.
An aside: I see the reference to `EggLoader`. Haven't Python "eggs" been pretty much obsolete for ages? Can we remove this or the bits that are related to "eggs"? (Something to create a separate ticket for, if so.)
Could you annotate the regex similar to: ``` tld_re = ( '\.' # dot '(?!-)' # can't start with a dash '(?:[a-z' + ul + '-]{2,63}' # domain label '|xn--[a-z0-9]{1,59})' # or punycode label '(?<!-)' # can't end with a dash '\.?' # may have a trailing dot ) ```
TIL that character classes also work inside `[]` :D
Try to write a docstring so that looking up the details in the ticket isn't necessary. Include the ticket reference only if it's an obscure issue that would benefit from the additional context provided by the ticket.
I'd rename `subminor` to `patch`.
Yes. Adding `?:` makes it a non-capturing group which allows for use of `m.groups()` below. Otherwise it'd need to be `... = m[1], m[2], m[4]`.
Please use assertRaisesMessage to verify this is the ValueError we expect.
@timgraham It might be more appropriate in another commit then. I believe I wanted to make sure nothing was logged if a m2m backed inline was submitted without changes.
We can move the test that involves `login()` to the other pull request.
You should be able to pass `is_active=False` to `create_user()`.
is this meant to test the `except TypeError` branch in `contrib.auth.authenticate()`? It would be clearer to call that function directly.
using `Lower` seems more readable
Could do `self.assertEqual(qs.get()['float'], 1.2)`
`).values()` on next line
Yes it was Ian, but my example used joined fields for an update which isn't (yet) allowed. How about something like: ``` Author.objects.update(alias=Greatest('name', 'goes_by') ``` Which will also test the handling of varchars in a Greatest.
Not necessary AFAIK; `values('cnt')` infers it.
Collapse this list to one line - we allow up to 119 chars.
under what circumstances do we need this? My system has 'UTF-8', so it's not very exciting as that's the default for these functions.
We should add `charset` to `OPTIONS`: ```suggestion 'OPTIONS': { 'charset': 'utf8', }, ```
This is what we want to test. Please restore `'--default-character-set=utf8'` in this line.
```suggestion fake_client = Path(__file__).with_name('fake_client.py') ```
```suggestion # Validate app_label. ```
There is no need to resolve replaced/applied migrations so I would pass `None` instead of the default connection: ```suggestion loader = MigrationLoader(None) ```
```suggestion f"App '{app_label}' does not have migrations." ```
I would use f-strings for these messages.
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
prefer a longer line for readability
Avoid using `Test that` prefixes in docstring, this is necessarily testing something as it is a test. ``` Teardown functions are run when run_checks raises SystemCheckError. ```
preferred format is "#15346, #15573 - Issue description"
You can probably simulate that with having `run_checks` raise a `SystemCheckError` error instead.
avoid _we_ usage as well ``` SystemCheckError is surfaced when run_checks raises SystemCheckError and teardown databases raises ValueError
`RETURNING` from `UPDATE` is out of this ticket scope.
```suggestion on_conflict=on_conflict, ```
```suggestion on_conflict=on_conflict, ```
Oh, I thought it was referring to two separate issues. Alright then, I'll make a new PR and we can proceed from there
I think we should use `local_concrete_fields` :thinking: Also, the current solutions doesn't work with recursive parents, e.g. ```python Pizzeria.objects.bulk_create([ Pizzeria(name='Vegan Pizza House', rank=33), ]) ``` crashes when we add the `Ranked` model: ```python class Place(models.Model): name = models.CharField(max_length=100) class Meta: abstract = True class Ranked(models.Model): rank = models.IntegerField(null=True) class Restaurant(Ranked, Place): pass class Pizzeria(Restaurant): pass ```` ```
Can we move the default value? ```python def __init__(self, include_html=False, email_backend=None, reporter_class=None): ... self.reporter_class = import_string(reporter_class or 'django.views.debug.ExceptionReporter') ```
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
I feel similarly. Maybe it's better just to add support for list and tuple as originally proposed. It's unclear to me if other types would actually be used.
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
This will need updating to account for #4846 (`getargspec` is deprecated in Python 3 and will soon be removed).
The variable name doesn't need to be / shouldn't be changed, IMO. (My suggestion in the ticket for a variable name was for the string argument, if that was going to be tested separately.)
Yup. It's completely irrelevant to the module it's in with this change.
Yeah, I think it's worth keeping in the same place.
> Is there any backwards compatibility issue with doing this? I.e. is the availability of this import part of Django's public API? Theoretically yes, we should add a reverse import for backward compatibility, or at least a small release notes.
I'd rather build regex string with interpolation so as not to repeat the other logic.
Use `settings.ALLOWED_HOSTS = settings.ALLOWED_HOSTS + ['testserver']` to avoid altering the original list assigned to `request._original_allowed_hosts` above.
yeah I don't see a reason why the imports are not top-level and we don't call the functions directly.
`None` is being passed for the `app_configs` argument - even though the check ignores `app_configs`, `[]` should be used as a more valid test value. I think it's worth looking into refactoring these tests in general, as you're write these property inner-imports are a bit confusing, made a note to self.
It's the pattern that django-secure used. Not sure if the reason is still relevant. \cc @carljm
I think we should check it's iterable AND not a string, there's always the possibility of other mistakes than the one that lead to the ticket, e.g. missing brackets on a function call
`ChoiceFormSet` -> `ArticleFormSet` You mixed `Article` with `Choice` in few places.
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
```suggestion f'<li>Title: <input type="text" name="form-0-title"></li>' f'<li>Pub date: <input type="text" name="form-0-pub_date">' f'{delete_form}</li>' ```
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
IMO checking how `empty_form` is rendered is not necessary. It's enough to check `empty_permitted`, e.g. ```suggestion self.assertIs(formset.empty_form.empty_permitted, True) ```
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
The primary key attribute can only be retrieved on certain databases, this will not work on Oracle or MySQL.
Please chop unnecessary blank lines.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
Tests for `formset_factory()` and `formset_factory()` are missing.
The last parenthesis should be moved to the next line due to hanging indentation.
The last parenthesis should be moved to the next line due to hanging indentation.
I don't think we need to check all rows, probably sth like this: ```python self.assertEqual(list(qs.values_list('lead_default', flat=True).distinct()), [60000]) ``` will be sufficient. We have a similar situation in the `test_nth_returns_null`.
It's weird, because Oracle interprets empty strings as nulls.
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
Really really minor nitpick; if flake8 etc do not complain maybe move `entropy.` up one line; looks really ugly like this especially if the code below is longer :)
While trying to push this PR over the finish line I noted that `salt_len` is not really the `salt_len` we want (it's the size of a string in bytes). I have pushed a new PR #13815 which adds the actual salt to `decode`. I'll update this PR once the other one is merged.
Mhm that is what I was trying to avoid, because for most hasher a salt length is just that and `must_update` should easily be able to handle that globally if it is returned from `decode`. What this PR certainly misses (and what will show you the existing problems) is a test for the behavior of the `bcrypt` hasher. I think now it's `must_update` will *always* return `True` and set a salt *every* time.
IMO, we should use `self.decode` here.
Maybe: ```python def char_count(self): # A string of length: # N / log_2(26+26+10) # provide N bits of entropy. ... ```
Ditto about the `for`/`else` construct.
I suggest you use the `for`/`else` construct here. ``` python for validator in validators: if isinstance(validator, validators.MinValueValidator) and validator.limit_value <= min_value: break else: validators.append(validators.MinValueValidator(min_value)) ```
This could be a single line: [...]
```python kwargs['max_value'] = min(value, kwargs.get('max_value', value)) ```
And this can be reverted.
I understand what you meant, however this message can be difficult for most of folks. Unfortunately, I don't have a better wording (at least for now).
This seems problematic. What happens if you do this: ``` reused_f = F('pk') qs1 = Model1.objects.filter(pk=reused_f) qs2 = Model2.objects.filter(pk=reused_f) ``` By my reading the reused_f will be first prepared for qs1, getting Model1.pk as col. Then the same object is reused and prepared for qs2, this time the reused_f's col is overwritten with Model2.pk. The ExpressionNodes must be either stateless, or they must be copied on prepare(). Doing the latter will be easier. A basic copy method could do the following: ``` def copy(self): copy = Empty() copy.__class__ = self.__class__ copy.__dict__ = self.__dict__.copy() return copy ```
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
```python kwargs = {'reuse': can_reuse, 'allow_joins': allow_joins} if isinstance(value, F): kwargs['simple_col'] = simple_col value = value.resolve_expression(self, **kwargs) ```
a misspell? SQLFuncMixn -> SQLFuncMixin
This is precisely this inconsistency in the expressions API about `params: list | tuple` that forces the usage of `tuple` here. Some `lhs.as_sql` return `params: list` and but the backend expects layer only expects `tuples` to be provided. Without this `tuple` some tests crash and I think we want to avoid this expression API inconsistency leak into the backends layer as it could be considered as low level as the compiler which only deals with `params` in tuples.
is it strictly required to cast params to a tuple? I thought it was understood that `params` may be a list or a tuple throughout the ORM code.
chop "one of" add comma before "or"
I think you can remove temporary `msg`, also dot is missing and probably `preceding` should be uppercased and `n` should be lowercased. ```python raise NotSupportedError( 'PostgreSQL does not support RANGE BETWEEN n PRECEDING AND n ' 'FOLLOWING.' ) ```
Isn't this equivalent? ``` if (start and start < 0) and (end and end > 0): raise ... ```
You do more type checking below, you could put this error into those clauses instead of doing it twice
{0} -> {} (I prefer the less verbose %s, actually) recognised -> recognized
What about erroring if `options` is non-empty at this point? Subclasses should have already consumed their arguments from it, and if there's anything left it's probably a mistake, like `explain(formatt='json')`
Wrap at 79 chars.
Could use `charset` over `character_set`? It's a well-known "word" and losing the underscore might make this less noisy visually, especially in the f-strings. Only a suggestion, feel free to ignore.
```suggestion 'The extra_tests argument is deprecated.', ```
I would move the check to the first line of the function since it's right after receiving the argument.
`captured_stdout()` is unnecessary: ```suggestion suite = runner.build_suite([ f'test_runner_apps.failures.tests_failures.{testcase}', ]) with captured_stderr(): result = runner.run_suite(suite) ```
You should use `self.m2m_db_table` instead of `self.db_table`.
I suggest you skip the check (`return []` early) if the intermediary model (`self.remote_field.through`) is not resolved. That is `isinstance(self.remote_field.through, six.string_types)`. Also I would store `m2m_db_table` in a variable as you'll need to reuse it to lookup `registered_tables` below.
Abort early if `self.db_table is None`
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
I think I would not mix the tests and better create a separate test, if possible.
Add a trailing comma so if more items are added later we don't have to modify this line again.
I think we can remove `tearDown()` and `setUp()` and use ```python with translation.override(language): ``` instead of `activate()`.
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
I prefer stating the expected behavior rather than "Test that..." since all tests are for testing. e.g. "A language not present in settings.LANGUAGES can be installed/used by a project."
``` py template_name = getattr(context, "template_name", "unknown") ```
Could you also update `logger.warning` to `logger.debug`. You may want to wait for confirmation from a core developer before change it. Thanks!
Adding something like this before the loop could help: ``` _bit_undefined() = object() [at module level] bit = _bit_undefined() ```
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
I don't think you need to use the `'template - ...'` prefix here, the log is already namespaced under `'django.template'`.
Please remove, it's redundant.
Please try to follow the indentation style. Same goes for blank lines between the function definitions.
I think `Sqrt` needs `output_field = fields.FloatField()`.
Maybe it could be generalized by always passing the explicit argument `D` to 0, if not called differently.
I haven't had time to look, but we should see what additional arguments `ROUND()` can take in different backends.
But `any()` always returns a bool? https://docs.python.org/3/library/functions.html#any
We should convert column name i.e. `connection.introspection.identifier_converter('large_field')`.
Remove the blank line.
I don't think we need the extra assignment here as this is only used once.
No point in assigning to `path` when used once. Also this doesn't seem right. I think you meant `__qualname__` rather than `__module__`? Which probably also means some tests are lacking...
Clarify "might"? Or simply say `# Silence "Truncated incorrect CHAR(1) value: 'Bob'".`
I'd make it a separate method: `test_cast_to_char_field_without_max_length`
case -> cast in all test names
Since `fan_since` is None at this point, the test cannot pass! Same below.
`).values()` on next line
use parentheses to avoid backslashes and I would also try to keep the comprehension on a single line as breaking it up like this makes readability more difficult IMO.
No need to cast the set into a list. You can iterate over sets.
Hmmm. `start` was unused anyway...
I think we can get rid of `self.nodes` when we add `implementation` to the node itself: `node = Node(key, implementation)`
When you keep sets for `parent_keys` and `children_keys` on a `Node` you don't need a lambda here. Not sure if that's worth it though.
```suggestion help=( 'Shuffle the order of test cases to help check that tests are ' 'properly isolated.' ), ) ```
Prefer "database" to "DB"? ```suggestion help='Output timings such as database creation, cloning, and teardown;' ' and total test run time.', ```
Please add trailing comma.
Remove spaces around the equal sign. It should be ```default=False``` to match PEP8.
Please add trailing comma.
```suggestion # __spec__ may not exist, e.g. when running in a Conda env. ```
`can not` -> `cannot`, or better `may not `
Can we reorganize this a bit? ```python exe_entrypoint = py_script.with_suffix('.exe') if exe_entrypoint.exists(): # Should be executed directly, ignoring sys.executable return [exe_entrypoint, *sys.argv[1:]] script_entrypoint = py_script.with_name('%s-script.py' % py_script.name) if script_entrypoint.exists(): # Should be executed as usual return [*args, script_entrypoint, *sys.argv[1:]] raise RuntimeError('Script %s does not exist.'% py_script) ```
`"Script {} does not exist.".format(py_script)` -> `'Script %s does not exist.' % py_script`
Please replace this with a regular `try/except`.
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
How about omitting it until we have a use case? That will save writing tests and docs for a theoretical feature. :-) From a readability point of view, writing a `re_path()` that mixes regexes and converters in the string, and then has to initialize and pass converters in the URLconf sounds nasty and not something to encourage!
I'm going to be a +1 to just dropping `converters`
I think the formatted pattern should be wrapped in quotes. "Your URL pattern '{}' uses..".
I would revert this change. We want to add a system check so this seems redundant.
I think we can reuse `rels_to_update`.
nitpicking: could you swap these two checks: `old_default != new_default and not self.skip_default(new_field)`
Can this be simplified to ```suggestion # Collation change? elif getattr(old_field, 'db_collation', None) != getattr(new_field, 'db_collation', None): new_collation = getattr(new_field, 'db_collation', None) fragment = self._alter_column_collation_sql(new_field, new_type, new_collation) actions.append(fragment) ``` Or maybe we want to keep the old code to support field type and collation change at the same time (e.g. `CharField(db_collation='foo') -> TextField(db_collation='bar')`).
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
We use `new_default` only when `old_field.null and not new_field.null` so IMO it's fine to use ```diff diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py index bfccf5e8fb..8cd5e11bbf 100644 --- a/django/db/backends/base/schema.py +++ b/django/db/backends/base/schema.py @@ -675,17 +675,17 @@ class BaseDatabaseSchemaEditor: # 3. Replace NULL constraint with NOT NULL # 4. Drop the default again. # Default change? - old_default = self.effective_default(old_field) - new_default = self.effective_default(new_field) - needs_database_default = ( - old_field.null and - not new_field.null and - old_default != new_default and - new_default is not None and - not self.skip_default(new_field) - ) - if needs_database_default: - actions.append(self._alter_column_default_sql(model, old_field, new_field)) + needs_database_default = False + if old_field.null and not new_field.null: + old_default = self.effective_default(old_field) + new_default = self.effective_default(new_field) + if ( + not self.skip_default(new_field) and + old_default != new_default and + new_default is not None + ): + needs_database_default = True + actions.append(self._alter_column_default_sql(model, old_field, new_field)) # Nullability change? if old_field.null != new_field.null: fragment = self._alter_column_null_sql(model, old_field, new_field) ```
I take this back and have a deeper look at the tests.
I think maybe ```py dummy = object() def get(self, key, default=None, version=None, acquire_lock=dummy): if acquire_lock is not dummy: warnings.warn( ``` I still think this arg fits in the grey area for deprecation timeline, would like someone to weigh in e.g. @jarshwah
`acquire_lock` was added for internal usage in 6448dd833524ac3fc503506b624841c9d642de8a, so I don't see a need for a deprecation.
Ok thanks Tim
I think the `else:` could be removed here.
I guess `name` would be another one.
I think we missed some attributes e.g. `related_query_name`, `limit_choices_to`, or `validators`.
I'd simplified this test: ```suggestion def test_reverse_inherited_m2m_with_through_fields_list_hashable(self): reverse_m2m = Person._meta.get_field('events_invited') self.assertEqual(reverse_m2m.through_fields, ['event', 'invitee']) inherited_reverse_m2m = PersonChild._meta.get_field('events_invited') self.assertEqual(inherited_reverse_m2m.through_fields, ['event', 'invitee']) self.assertEqual(hash(reverse_m2m), hash(inherited_reverse_m2m)) ```
It's a bit of a shame that we have to resort to full scan of the project state but I'm afraid it's the only solution to detect `to_field` references without rendering the model states.
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
That seems unfortunate. Not sure I have any good suggestions though.
```suggestion 'MemcachedCache is deprecated in favor of PyMemcacheCache and ' 'PyLibMCCache.' ```
This should be `RemovedInDjango21Warning`.
single quotes for consistency
I see, thanks for pointing that out.
Actually I think it might be possible to reuse most of `super()._create_index_sql` by using `expressions=[RawSQL(...)]` instead of `columns` to avoid heavy duplication between both methods.
I don't think that a separate ticket is necessary, using `super()._create_index_sql()` will fix described issue.
> Current PR (Allows user to specify suffix - consistent with posgresql backend): Users cannot specify `prefix` it is an option that Django uses internally. I think we should keep the current prefix `_id` for backward compatibility.
We can pass `opclasses` to the `super()._create_index_sql()`.
You can't assume the presence of `self.name` here
suggested wording: ``` Strip quotes off of quoted table names to make them safe for use in index names, sequence names, etc. For example '"USER"."TABLE"' (an Oracle naming scheme) becomes 'USER"."TABLE'. ```
Chop blank line.
Please remove this unrelated change.
Both `with` should fit on the same line, `with self.subTest(value=value), self.assertRaisesMessage(ValidationError, "'Enter a number.'"):`
The hexdigest will always be a fixed length so this only happens if the provided suffix is too long, correct? In that case, I think it would be better to raise an error that the provided suffix is too long.
If the `edges.get(None, ())` call above works comparing `key` to `None` here should also be working. I also don't know any other Python object which `str()` representation is `'None'` that are not `None` itself.
A more succinct version might be something like: ``` python for key, subroots in self.edges.items(): if key is not None: for root in subroots: roots.extend(self._nested(root, seen, format_callback)) ```
You don't need to call `keys()` here, iterating over a `dict` yields its keys.
use parentheses to avoid backslashes and I would also try to keep the comprehension on a single line as breaking it up like this makes readability more difficult IMO.
No need to cast the set into a list. You can iterate over sets.
What about indexes and constraints based on `expressions`? For example: ```python Index(F('author'), F('title'), name='author_title_index') ```
Do we need to call `str()` on `contraint_sql`? ```suggestion if contraint_sql: schema_editor.execute(constraint_sql + ' NOT VALID') ```
Here we also should call `super` and not copy-paste code
`constraint_name` should also be quoted.
Chop blank line.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
Don't think we need to worry about duplicates.
As long as you use `except Exception` and not a bare `except` this should be good.
If we remove this will the tests run on Jenkins? It might be fine.
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
I think it's enough to test `None` and `''`.
I don't think it's worth to add multiple fields. `IntegerField(null=True)` should be enough.
Sure, so two extra fields - one to handle `0` and `None`, the other to handle `False`.
```suggestion f'{cls.__qualname__}() got both positional and keyword ' ```
This could become: `# IndexError error is used for historical reasons.`
```suggestion # Validate app_label. ```
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
That's not true, `return` is to avoid setting new migrations.
I prefer the following one rather than the above one ```py def greet(): condition = False if condition: return "Hi" return "Hello" ``` Feel free whether follow the things I point out.
I thought you wanted to remove `return`. Nevertheless I'd also leave the `else` as it increases readability.
Also `django.core.checks.migrations` should be imported in `django/core/checks/__init__.py`.
```suggestion # Validate app_label. ```
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
```suggestion sys.exit(1) ```
I prefer the following one rather than the above one ```py def greet(): condition = False if condition: return "Hi" return "Hello" ``` Feel free whether follow the things I point out.
Yes, I do. Ending statements with semicolons is redundant at best (as used here); if followed by whitespace, the semicolons can actually break things. Code in tests serves as example, and so shouldn't include them. This is essentially like pep8 issues -- you don't have to clean up old code, but please avoid introducing new ones.
```suggestion def test_skip_empty_tables_zero_rows(self): tables = connection.introspection.django_table_names() tables = connection.introspection.exclude_empty_tables(tables) self.assertEqual(tables, []) ```
I'd split this into two tests s o they can fail independently: `test_only_nonempty_tables_empty` and `test_only_nonempty_tables_one` or similarly named
```suggestion def test_skip_empty_tables_one_row(self): City.objects.create(name="London") tables = connection.introspection.django_table_names() tables = connection.introspection.exclude_empty_tables(tables) self.assertEqual(tables, ['introspection_city']) ```
I tested locally and confirmed the view creation is not necessary. Make sure you don't pass `only_existing=True` to the `django_table_names` call and the test will fail without the fix applied and pass with it.
This test passes when testing against an SQLite or MySQL backend as long as psycopg2 is also installed. For this test case, I think the check `connection.vendor == 'postgresql'` skips the test too aggressively.
Did you consider using `PostgreSQLSimpleTestCase`? I would favor that for consistency.
Test -> Tests (for future expansion)
AppConfigTests "TestCase" designates that this is meant to be subclassed and doesn't contain any tests itself.
This fails when running from the root directory rather than the tests directory (i.e. `$ ./tests/runtests.py postgres_tests`). Also, the output doesn't make debugging very easy (`AssertionError: 1 != 0`) -- if that could be improved that could be nice.
Chop blank line.
Use single quotes consistently.
Please add trailing comma.
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
We can move `get_migration_name_timestamp()` call to `if`.
`f-string`s should not contain function calls. This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
f-strings shouldn't contain function calls. This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
We should probably check for empty strings as well.
> What about `_16_more`(16 is the number of operations)? I don't see much value in this format, you still need to open the file to find out more.
built-in imports like unittest should go above django imports, separate by a newline. e.g. ``` from __future__ import unicode_literals import unittest from django ... ```
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
Just use `get_current_site()`.
Do we need this mapping? We could redirect to a `HttpResponse` with the `status_code`, e.g. `HttpResponse(status_code=r.redirect_type)`.
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
Positional arguments cannot follow keyword arguments.
I'm a little concerned about the loss of `constant_time_compare()` here which sounds like it was added as a potential mitigation against timing attacks.
`max_age` is not being passed into `signing.loads()`, nor is `self.serializer`. `session_dict` should be `session_data`.
I don't understand why we have methods with a double underscores prefix which are copies from `SessionBase`, e.g. `__hash()`, `__legacy_encode()`, `__legacy_decode()` :thinking:
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
If it has some readability benefits, it could be done in a separate PR. This looks okay for now.
longer line is fine so you can use same style/indentation as others
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
I'm not sure splitting this out to a separate function makes the code easier to follow.
Remove trailing comma.
Wouldn't the following work here: ``` python except MiddlewareNotUsed: if settings.DEBUG: logger.warning('MiddlewareNotUsed: %r', middleware_path, exc_info=True) ```
What about the following? ```suggestion if asyncio.iscoroutinefunction(getattr(middleware, '__call__', None)): ```
This values needs to be invalidated on `settings_changed` for `MIDDLEWARE` for testing purposes.
A system check seems a good option if the warning would be too noisy.
This wouldn't happen on every request, just on server restart (when `load_middleware()` is called)
OK, so here I'm expecting to just call a backend function — `as_sql_str()` or something. (_Naming!_) * The base implementation would just do the existing `sql % params` — although that's the suboptimal(?) "return something that looks valid but isn't" strategy discussed above. * Then each backend overrides appropriately. The `mogrify` call is then just in the Postgres version. ([There's a wontfix on Python for adding similar to pysqlite](https://bugs.python.org/issue9506).)
you can collapse, `with self.assertRaises(Exception), connection.cursor() as cursor:`, and in a few places below.
from Python, so we quote and substitute parameters manually.
Cool. I forget every time... 🥴
``` # executemany() must use an update query. Make sure it does nothing # by putting a false condition in the WHERE clause. ```
Just curious if there is a reason for the `runTest` name instead of the usual non-camel case name.
I'd combine w/previous line for better readability
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
I don't see much value in this hint, also `Git` is not the only VCS. Please remove it.
I suggest you use the `hint` kwarg for the `'perhaps you forgot a trailing comma?'` part.
Returns -> Return use period
I think this should error somehow get printed or a warning given or something (maybe only with verbose?). (in my case it's happening if pywatchman is installed, but not watchman.): `pywatchman.WatchmanError: "watchman" executable not in PATH (%s), while executing [Errno 2] No such file or directory: 'watchman': 'watchman'`
Yeah, only on the first load if possible, otherwise maybe pass in verbosity from the runserver command and only show it if a higher verbosity is passed in. I think it would also be neat if instead of saying "Watching for file changes with StatReloader" it could figure out the common error and just say something like "Watchman client not available, watching for file changes with StatReloader". That way it's more clear what's going on, but not spamming the console either.
remove "0" in {0}
It's slower, about 10 times.
I think a test could go in a new file: `tests/model_regress/test_state.py`.
@sir-sigurd it's needed to prevent accesses to `ModelState.fields_cache` from crashing which is something some IDEs do under the hood for introspection. See dc1ad69f30f48d3c27406373f62f87e93550cdc5 and b88abd684041ffa66bfe445e1ac26164e803d488.
Not sure, discussion is https://groups.google.com/d/topic/django-developers/3eSHhZUzxv4/discussion.
Past commits standardized the signature for descriptors with `cls=None`.
Please wrap: ``` # If true, uniqueness validation checks will consider this a new, unsaved # object. Necessary for correct validation of new instances of objects with # explicit (non-auto) PKs. This impacts validation only; it has no effect # on the actual ```
I'm not sure if these docstrings are adding much value.
Use single quotes unless the string contains a single quote. Also, this could be combined with the previous line -- we allow up to 119 characters when it helps readability.
```suggestion @ignore_warnings(category=RemovedInDjango50Warning) ```
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
Please use 4 space hanging indent style as seen elsewhere in this file such as `cls.superuser = ...`
Please chop unnecessary blank lines.
Tests for `formset_factory()` and `formset_factory()` are missing.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
This logic could be consolidated to avoid repeating the same conditionals twice. Just check both `max_num` and `absolute_max` independently for `None` and set default as needed, then once they are both set, check that `absolute_max > max_num`. The minor difference in error message here doesn't justify all the repeated logic, IMO; a simple "absolute_max must be greater than max_num" is fine.
Add trailing comma.
We should take keys into account (like in `__eq__()`), so maybe: ```suggestion if hasattr(self, 'error_dict'): return hash(tuple(sorted(make_hashable(self.error_dict)))) return hash(tuple(sorted(self))) ```
You don't need to use `make_hashable()` for primitives: ```suggestion return hash((self.message, self.code, self.params)) ```
I noticed that we missed keys comparison, e.g. `exception_a` and `exception_b` are equal: ```python exception_a = ValidationError({'field1': 'field error', 'field2': 'err'}) exception_b = ValidationError({'field2': 'err', 'field1': 'field error'}) ``` we should fix this, maybe: ```suggestion if hasattr(self, 'error_dict'): return hasattr(other, 'error_dict') and self.error_dict == other.error_dict return sorted(list(self)) == sorted(list(other)) ``` a test is also needed.
We also have to provide `__hash__()` because without it `ValidationError` instances are not hashable anymore.
I think we can simplify this: ```suggestion def __eq__(self, other): if not isinstance(other, ValidationError): return NotImplemented if hasattr(self, 'message'): return ( hasattr(other, 'message') and self.message == other.message and self.code == other.code and self.params == other.params ) return ( hasattr(self, 'error_list') == hasattr(other, 'error_list') and hasattr(self, 'error_dict') == hasattr(other, 'error_dict') and sorted(self.messages) == sorted(other.messages) ) ```
```suggestion def insert_statement(self, on_conflict=None): ``` Also ensure that this change of signature, from `ignore_conflicts=False` → `on_conflict=None`, is mentioned in backward incompatible changes to database backends in the release notes.
When considering my above point please now target 4.1.
It's not resolved.
Chop blank line.
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
Putting all queries on their own newline should help readability: `'...queries were:\n%s'`.
I think at least the latter is worth it - it's confusing to submit two files and be told "the" file is empty.
Do we have sufficient test coverage? In particular, I'm looking for a test which verifies this "QUOTE(?)" bit.
Single quotes please.
Could we also pass `exc_info=True` to the logger? It makes me wonder why we don't simply register a logging handler on the `'django.db.backends'` loggger in the first place instead of relying on `connection.queries`.
```suggestion errors_on_separate_row=True, ```
```suggestion return '<div class="errorlist">%s</div>' % ''.join( f'<div class="error">{error}</div>' for error in self ) ```
Can we avoid duplicating this? Maybe define it at the module level as it is used in multiple test cases.
You don't need to use `"""..."""` here: ``` py self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> custom' '<input id="id_hidden1" name="hidden1" type="hidden" />' '<input id="id_hidden2" name="hidden2" type="hidden" /></p>' ) ```
please limit line lengths so horizontal scrolling isn't required, something like: ``` self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> ' '...' ) ```
Make sure you reference your ticket number in the docstring (see the other tests in the file).
Minor but I think a warning will be raised here as this is passing a naive datetime will timezone support is enabled.
I think the `TestStringAggregateDistinct` class could be reused considering the setup methods are the same -- just remove `String` from the class name.
Running query is not necessary, I think we can check field value instead, e.g. ```python self.assertEqual(instance.field, [[None, None], [None, None]]) ```
I think `test_decimal_parameter` would make more sense here.
```suggestion processed_adjustable_paths = {} ```
It might be nice to reorder this above _post_process so that lots of code doesn't appear as changed when it was only moved. It would certainly ease review.
It seems you'll need to check the patch by hand. This is an obvious syntax error.
```suggestion cached_files = Path(settings.STATIC_ROOT).joinpath("cached").iterdir() ```
We should use a custom storage for this test (instead of mocking).
I don't think there isn't a better alternative. Talking about "positive integers" means we still defer thinking about positive and negative ints to the end user. ``` path('articles/<posint:year>/', views.year_archive), ``` ... isn't at all as nice. Since MOST people still won't have to care about negative ints, I still think keeping "int" as the name is a good default, even though not 100% accurate. Also: there seems to be a common case for negative FLOATS, namely coordinates. But since the DEP says floats shouldn't be included that use-case is nicely sidestepped. There's also two nice workarounds to all this: just specify str as type and do the typecasting in the template, or specify your own type that supports negative floats/ints.
Let's stick with positive integers and wait for complaints.
What is the point in providing an empty base class? Is that in case we want to add some logic to all converters, both built-in and third-party, in the future? Also you can drop `(object)` since the master branch no longer supports Python 3.
Perhaps the base class could look like: ```python class BaseConverter: @property def regex(self): raise NotImplementedError("BaseConverter subclasses must provide a regex") def to_python(self, value): return value def to_url(self, value): return value ``` to prevent duplicating these two methods in most subclasses.
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
Yes it should be `R.p`, we didn't take into account nested protected relations in the ab3cbd8b9a315911248227208630a020cedca08f (probably my fault). Also casting to list is not necessary anymore after this change.
The extra queries could be generated in this line (199), as this is where the instancies are created, so so you should check the number of queries is one.
I don't think that we need 3 authors and 6 books for this test. I will remove the last author.
I think this test is sufficient, no need for the other one. Can you rename it to `test_delete_keep_parents()` though.
Please use 4 space hanging indent style as seen elsewhere in this file such as `cls.superuser = ...`
``` # Unmanaged origin model that is a table. ```
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
``` # Unmanaged related model that is not a table. ```
Chop blank line.
``` # Unmanaged related model that is a table. ```
I would prefer checking `_fields` ```suggestion if self._fields is not None: ```
```suggestion "'obj' must be a model instance." ```
I _think_ there's the potential for a slight discrepancy here - if the `_result_cache` is not None (it's an evaluated queryset) and you fall back to doing `__contains__` on the underlying list, you'd be comparing using `Model.__eq__` right? Ignoring the possibility that the user has overridden the method (and thus there's unavoidably nothing you can do), that method also checks the `concrete_model` meta attribute, for reasons I expect are nuanced but important (my guess: proxy models)
Hmm, I think if it's not an instance of the model I'd expect it to raise an exception, not just ignore it, but I'm not sure.
```python """Return True if the queryset contains an object.""" ```
```suggestion # The Widget.get_context() attrs argument overrides self.attrs. ```
```suggestion # Widget.get_context() returns expected name for geom_type. ```
```suggestion # Widget.get_context() returns 'Geometry' instead of 'Unknown'. ```
Likewise, it seems odd to keep `'point'` here: ```suggestion context = widget.get_context('geometry', None, None) ```
```suggestion 'geom_type': 'Geometry' if geom_type == 'Unknown' else geom_type, ```
If changing the messages, please update them in `docs/ref/checks.txt` as well.
Put the `not field.many_to_many` first and the `isinstance()` second, please.
Can you please choose a new error code that is otherwise unused.
As noted elsewhere, put the trailing space on this line rather than the next (and in the message below).
Can you please choose a new error code that is otherwise unused.
Is this still simulating a read-only database if the mocking is removed? This test might be obsolete considering the exception catching in `check_migrations()` is removed. Some low level tests for the modified `MigrationRecorder` methods might be in order instead.
Also, if you are using a context manager, it seems like you want to assert calling `is_usable()` right before you close (so after the context manager closes).
I think you're talking about the other test. This one passes and fails without `autospec`.
I haven't used `autospec` before and it's used just once in Django's test suite. If you could give a quick description of why it's useful here, that'll help me learn something.
State the expected behavior: MigrationLoader.check_consistent_history() should ignore unapplied squashed migrations that have all of their `replaces` applied.
Ah right. You noted on the ticket that's not the case with the 'spawn' mode, but I guess we shouldn't concern ourselves with that right now, as the test runner doesn't support that. @Valze - maybe make a note for your spawn-mode GSoC project? 😉
I think we should check if it's not already enabled: ```python if not faulthandler.is_enabled() and enable_faulthandler: ```
`file` supports file descriptors so we can use the same workaround like `pytest`: ```python try: faulthandler.enable(file=sys.stderr.fileno()) except (AttributeError, io.UnsupportedOperation): faulthandler.enable(file=sys.__stderr__.fileno()) ```
Please revert removing blank line.
You won't need to pass `INFO` if the default is `INFO`.
Thanks for the patch. Clean and simple. Maybe that's just nitpicking but what about changing that `if` to `elif`? Because since `MEDIA_URL` must always explicitly end in slash, we might not want to add a slash if a trailing one is missing from it.
`weak=True` is the default.
explicit -> specified
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
Maybe a helper method would help eliminate the redundancy of these methods? e.g. `return self._value_or_setting(self._location, settings.MEDIA_ROOT)`
```suggestion *app.split("."), "migrations", "0001_initial.py" ```
```suggestion self.assertIn(f"Deleted {migration_file}", out.getvalue()) ```
This should be defined outside the `try` - if `call_command` raises, `merge_file` won't be defined in the `finally` clause.
title.verbose_name and same typo in else branch
IMO there is no need to check a file content: ```suggestion msg = '...' with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
What about m2m and reverse relationships? Something like `Q(cities=3)` will also produce the join.
If it's an expression its source expression tree should be walked (recursive `get_source_expressions`) and when the expression `isinstance(expr, str)` then you'd need to use split it using `LOOKUP_SEP`. The first part should be used to retrieve the field (`_meta.get_field(parts[0])`). If it's a related field (`field.remote_field is not None`) then you are trying to `JOIN` and it's disallowed.
Looks like we just need to use `_meta._get_fields(reverse=False)`.
I think the function can be simplified to ```python @classmethod def _get_expr_fields(cls, expr): fields = set() if isinstance(expr, Q): for child in expr.children: if isinstance(child, tuple): lookup, value = child fields.add(lookup.split(LOOKUP_SEP)[0]) fields.add(cls._get_expr_fields(value)) else: fields.update(cls._get_expr_fields(child[1])) elif isinstance(expr, F): fields.add(field.name) elif hasattr(expr, 'get_source_expressions'): for src_expr in expr.get_source_expression(): if isinstance(src_expr, str): fields.add(src_expr.split(LOOKUP_SEP)[0]) else: fields.update(cls._get_expr_fields(src_expr)) return fields ``` And you call it directly with `constraint.condition` and `constraint.check`. An alternative would be to create a `sql.Query` object and try to add the where object while disallowing joins https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/constraints.py#L101-L102 https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1361-L1362 This will raise a `FieldError` if there's an attempt at joining https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1660-L1684 But the message won't include the name of the culprit which be a blocker here if we want to provide adequate hints.
Something like ```python elif hasattr(child[1], 'get_source_expressions'): for expr in child[1].get_source_expressions(): if isinstance(expr, str): fields.add(expr.split(LOOKUP_SEP)[0]) else: fields.update(self._get_check_or_condition_fields(expr) ```
same thing here about assuming `is_active` exists and `not user.is_active` -- probably need some tests for that case.
Please don't make unrelated whitespace changes.
@pahko `2` , `3` and non-empty lists and objects also will be valid case. Only check for boolean is needed here.
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
I'd make this a separate test and then you can decorator the test method instead of using `with ....`.
I think `assertNotEqual` is sufficient -- that would be if display_name is None.
The skip condition should be removed as it's not possible to run the tests with an unknown vendor, I think.
you can collapse, `with self.assertRaises(Exception), connection.cursor() as cursor:`, and in a few places below.
You don't need to wrap a connection, you should be able to use `CaptureQueriesContext()` with `commit()` and `rollback()` and test captured queries.
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
I would consider tuple unpacking in the line before: `constraint_table, constraint_column = constraint['foreign_key']`.
```suggestion def test_skip_empty_tables_one_row(self): City.objects.create(name="London") tables = connection.introspection.django_table_names() tables = connection.introspection.exclude_empty_tables(tables) self.assertEqual(tables, ['introspection_city']) ```
`get_constraints()` depends on database, e.g. on PostgreSQL unique constraints are reported as indexes. That's why I decided to move unique constraints assertions to a separate method `assertUniqueConstraintExists()`.
The `index_type = indexes['reporter_id'].pop('type', None)` pattern from the old test should be used rather than a loop -- otherwise, if there' some mistake in the if-condition or if the loop is empty, it's not certain that this assertion will ever run.
I don't expect index names to change radically in the future, if at all, but even if it does, I think simplifying the test is worth the "risk" of having to update it in the future, which seems like no big deal.
Slow or not, it is kinda pointless to do since we do not need the data -- so yeah, we should not count here
You are leaking information about whether somebody has access or something doesn't exist.
Raising a 404 with the same message as in the previous check would mask the issue. Then again I think we already leak a lot like that in other admin pages, will have to double check.
Yeah, this is a good point, reuse an ordering if possible (maybe even force it)
Both `has_perm()` and `has_change_permission()` take an optional `obj=None` argument for object-level permission checks as implemented by e.g. django-guardian. I think we should provide this here as well.
Any disadvantage to making it a separate test method instead? I guess the signal connecting might be better is `setUpClass` at that point.
I'd use `ref.assert_called_once_with()` here.
From looking at the code the call could differ from Python 2 to 3 and is really an implementation detail which is not worth testing after all. My initial reflexion was more about the fact `assert_not_called()` was used below instead of `self.assertFalse(ref.called)` but now I realize there's no `assert_called()` method. LGTM
Ah ofcourse, my bad, you're right. Looks good to me.
There's no need for the `disconnect` function. ```suggestion self.addCleanup(signals.post_init.disconnect, post_signal, sender=Book) ```
Merged in 1e0dcd6c8bfa4519c21014c73eb510620dd1a000.
> I've noticed that these "internal" names leak into migrations. Making this change will cause migrations to be generated when users upgrade. Are you sure? I didn't notice this in a sample project.
> Perhaps when creating migrations we should ensure the value of `related_name` is forced to `'+'` if it ends with `'+'`? We could edit the following in `RelatedField.deconstruct()` to undo the changes made in `ManyToManyField.contribute_to_class()`: https://github.com/django/django/blob/74fd233b1433da8c68de636172ee1c9c6d1c08c9/django/db/models/fields/related.py#L324-L325 Or handle it specially in `ManyToManyField.deconstruct()`.
no blank line please
This could be replaced by `self.remote_field.model._meta.label_lower` https://github.com/django/django/blob/c1b24718e05ea474955777d7bc4d9d5634560cd5/django/db/models/options.py#L136-L138
Perhaps a nice alternative is: ``` result = json.loads(Question.answer_set.field.value_to_string(question)) self.assertCountEqual(result, [answer1.pk, answer2.pk]) ```
I don't think you can assume ordering here.
more descriptive names would be enhance readability of the test, e.g. "ModelWithLongField", "ModelWithDBColumn"
unless you can generate a model so the field length is always `connection.ops.max_name_length() + 1`, the skip condition should probably be `connection.ops.max_name_length() < X` where X is the length of the column name here.
I wonder if this might be bit more readable: `model = type('A' * 101, (models.Model,), {'__module__': self.__module__})`
``` # Environment variables are ignored in non-interactive mode, if provided. ```
This also can be simplify: ```python call_command( 'createsuperuser', interactive=False, username='test_superuser', email='joe@somewhere.org', stdout=StringIO(), ) user = User.objects.get(username='test_superuser') self.assertEqual(user.email, 'joe@somewhere.org') self.assertFalse(user.has_usable_password()) ```
This can be single-lined.
I don't think that this test is required.
Ahh, I see! Thank you for the quick reply! Learning a lot from these PRs! :)
Nit: `test_loader_patterns_not_mutated` (with an "s")
Unnecessary trailing comma and white space.
Since `verbosity=1` is the default, you can leave this out. (It's good to be testing the default behavior.)
I would do what the other tests do and pass `test_labels` as a positional argument. Also, to be clearer what `foo` and `bar` are doing, it might be better to call them something like `notfound1` and `notfound2`. I'm assuming it's finding two failed test instances for labels not found. Alternatively, you could find real tests by passing something starting with `'test_runner_apps...'`.
Please test the entire message.
I'd only use mock as a last resort and instead pass some email that will be affected by the normalization.
prefer `setUpTestData` since that executes once per test class instead of once for every method
You should be able to pass `is_active=False` to `create_user()`.
We can move the test that involves `login()` to the other pull request.
What's the point of this query? I don't see anything in the view which could delete users (and even then, why should it delete users…)
Chop blank line.
`kwargs` are not necessary to raise an exception, e.g. ```python @override_settings(AUTH_USER_MODEL='auth_tests.CustomUserWithM2MThrough') def test_unsupport_fields_with_m2m_and_through(self): msg = ( "Required field 'orgs' specifies a many-to-many relation through " "model, which is not supported." ) with self.assertRaisesMessage(CommandError, msg): call_command('createsuperuser') ```
Yea, it seems a bit unusual, but I don't have an alternative to suggest.
This works without the patch. Extra test coverage is welcome, but should be keep in a separate commit/PR.
Only `test_fields_with_m2m_by_env` fails on a fresh branch without any of your changes in `django/contrib/auth/management/commands/createsuperuser.py` and `tests/auth_tests/models/with_foreign_key.py`,
``` When the object has a ManyToManyField to Site, redirect to the current site only if it's attached to the object.
This is a very minor detail but I think the rest of the code uses tripe double quotes (`"""docstring"""`) for docstrings.
You should use `fetch_redirect_response=False` instead of `target_status_code=404`. It seems to be an outdated pattern used in a few places and I'll probably clean it up soon.
Wrap lines closer to 79 characters and use () when referring to a function. ``` # get_current_site() will lookup a Site object, so these must match the # domains in the MockSite model. ```
Is there a need to hardcode pks? This is generally to be avoided, I think.
python3 tests failed because `six.iteritems(old_test_settings)`.
Please add a trailing comma to this line.
Use literals please - `[]` for `list()` and `{}` for `dict()`. Also, something like `result` would be a better name than `return_dict`.
No need to construct a new `dict` and call `dict.update()` here. Also the key ought to exist in the map or something has gone drastically wrong, so no need to use `dict.get()`. ```python return_dict[key_map[key]] = value ```
This is fine as-is. It is well known that iterating over a dictionary iterates over the keys. Also this is explicitly returning a `list` and not an iterator (as is the case with Python 3). Try out `type({}.keys())` to see the difference.
This conditional is not required anymore given the check above.
Maybe `_check_default_is_not_str()` -> `_check_str_default_value()`?. Please remove unused `kwargs`.
I don't think we want to special case `Subquery`, feels like we'll want to duck type on `conditional` ```suggestion if not isinstance(other, Q) and not getattr(other, 'conditional', False) is True: ```
We can remove quotes around the `default`. Please also wrap at 79 chars.
argument ordering should be reversed
This is a separate cleanup, so please move it do a separate commit.
```suggestion return errors ```
I don't see much value in this hint, also `Git` is not the only VCS. Please remove it.
I suggest you use the `hint` kwarg for the `'perhaps you forgot a trailing comma?'` part.
By using an extra `continue` we reduce the indentation. I also propose that we change the hint message when depending on whether the cache path matches, is inside, or contains one of the other paths: ```suggestion if not setting: continue if name == 'STATICFILES_DIRS': paths = {pathlib.Path(dir).resolve() for dir in setting} else: paths = {pathlib.Path(setting).resolve()} for alias in settings.CACHES: cache = caches[alias] if not isinstance(cache, FileBasedCache): continue cache_path = pathlib.Path(cache._dir).resolve() if any(path == cache_path for path in paths): hint = f"Your '{alias}' cache path matches your {name}." elif any(path in cache_path.parents for path in paths): hint = f"Your '{alias}' cache path is inside your {name}." elif any(cache_path in path.parents for path in paths): hint = f"Your '{alias}' cache path contains your {name}." else: continue errors.append(Warning( 'Your configuration might expose your cache or lead to corruption of your data.', hint=hint, id='cache.W002', )) ```
I would put the arguments all on this line
It is thread safe as long as the integer_field and float_field are used in stateless manner. I think that is the case, but verifying that isn't easy.
Unfortunately annotation names can contain LOOKUP_SEP - that is the reason why the ugly refs_aggregate method was added. For example qs.annotate(Max('id')) will create an annotation named max__id, and that can't be referred if the code checks for len(field_list) == 1.
This error no longer makes sense with multiple-arg aggregates. You'll either need to join the output of all source expressions so the error produces: > Cannot compute Sum(arg1, arg2): 'X' is an agggregate # (where X is either arg1 or arg2) Or you'll need a different error message for the case of `len(args) > 1`. There may be another solution (like ditching this message altogether) but I'll let you experiment with that if you like.
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
I would filter that first, via a generator. I think this might be more readable. ```python lists = (lst for lst in lists if lst) ``` or ```python lists = filter(None, lists) ```
Use `django.utils.datastructures.OrderedSet` to make it clear what you are using this datastructure for.
You could do solve this recursively, but I don't know if this better readable really. meh
Why don't you make unique_items a `set` too? This would save you the whole `not in` clause. You just do `Set.add` which will add the item if it's not in the present anyways ;) That being said, since you are adding all items of the list to a set. Just create a set from the list. This will be a lot faster, since the `in` clause performs only at `O(n)`.
why cast this into a list, normal brackets (generator) will do
In cases like this, we prefer to include a trailing comma so if more items are later added, we don't need to modify this line again.
Use `setUpTestData` now that two models will be used by two methods.
Need to test that result is as expected, not only calling it.
checking the results of the query would be useful. ``` self.assertEqual( Pet.objects.prefetch_related('fleas_hosted').values_list('id', flat=True), [...], ) ```
IMO, these tests would be less verbose with assertRaises. what do you think? edit: actually I'd use six.assertRaisesRegex to verify the message 'Good' (maybe change it to something better) so you're sure you didn't trigger an AttributeError some other way in the test.
You should just check for the presence of the attribute. See tests in #11070.
Since the behaviour of the `autocapitalize` attribute has nothing to do with django itself, you'll probably have to write some sort of a test that the field/widget renders that attribute.
This test passes without changes in the `UsernameField`.
Just missed one `.get()` here.
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
It seems like `name` is never stored. Are you missing a `self.name = name or func.__name__`.
You'll want to branch off `< 3.6`.
Might make sense to check explicitly set name too, because '__name' obviously will not work.
``` class A: __print = cached_property(print, '__print') ``` This will not work and we can easily detect it too.
I would consider that as not working
`targets` is an empty list when `MIGRATE` is `False`: ```suggestion executor.migrate([], plan=[]) ```
`test_fields` or simply `fields` if no name collision
@arthurio yeah I'd suggest we stick to only `post_operation` for now because we have a use case for it. Adding a _pre_ signal could be useful but adding features for the sake of it only complexify the implementation for unknown benefits.
I think it's fine to leave it inside a `try` block.
`len(statements)` => `statements`
```suggestion 1. (?P<a>\w+)/b/(?:\w+)c(?:\w+) => (?P<a>\\w+)/b/c ```
```suggestion def remove_non_capturing_groups(pattern): ```
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
Such an extensive docstring is not necessary, IMO.
Please use single quotes.
> It's compiled once on import no? Yes, but do we need to compile it at all? In most of cases it's not necessary because `boundary` is already parsed in `opts`.
Removed extra code in PR #3852.
`s` is always `bytes` in our case so we can drop the `else` branch: ```suggestion return re.match(b"^[ -~]{0,200}[!-~]$", s) ``` We could also pre-compile this regex and use `fullmatch()`: ```python boundary_re = _lazy_re_compile(b"[ -~]{0,200}[!-~]") def valid_boundary(s): return boundary_re.fullmatch(s) ``` It's used only in `MultiPartParser` so maybe a separate hook is not necessary :thinking: ```python if not boundary or not boundary_re.fullmatch(boundary): raise MultiPartParserError( "Invalid boundary in multipart: %s" % force_str(boundary) ) ```
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
Use hanging indent: ``` call_command( 'flush', verbosity=0, interactive=False, database=self.connection.alias, reset_sequences=True, inhibit_post_migrate=True, ) ```
What does the flush do? I would expect the tests to leave the database in a clean state already.
Ah, that makes a lot of sense. Thanks :)
New tests are failing on Oracle. I think we should avoid creating a test database, maybe by mocking `_create_test_db()` :thinking:
Isn't the `Car` left in the database after this test? It should be deleted here too, I think.
```suggestion self.asserCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
```suggestion self.assertCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
```suggestion self.assertCountEqual(queryset, [self.guitar_book]) ```
This class is unnecessary.
This can be single-lined.
My intuition would be to make this raise `NotImplemented` instead.
add docstring: Return a tuple of the database's version.
`return self.get_database_version() >= self.features.minimum_database_version`
I think it's preferred to wrap this at 79 chars: ``` f'{self.display_name} {min_db_version} or later is required ' f'(found {db_version}).' ```
Unswap `cursor` and `self`.
remove "should", e.g. "debug() bubbles up exceptions before cleanup."
Remove extra spaces around docstring.
avoid _we_ usage as well ``` SystemCheckError is surfaced when run_checks raises SystemCheckError and teardown databases raises ValueError
I would also consider turning that into an instance method called something like `get_runner()` and starting each test method with `runner = self.get_runner()`. The reason is that instantiating a runner is "cheap." You also don't have to think / worry about whether the runner has state that you might unwittingly be carrying from one test to the other (e.g. attributes set when a method is executed).
`for data in json.loads(...):`
return directly, no need for `path` variable.
And there: ``` work_file = os.path.join(self.dirpath, '%s.c' % self.file) ```
And use `work_file` here.
this could use the indent style of the previous `CommandError`.
no `u''` prefixes on strings please
On second thoughts creating a URL with to_field isn't required to test this issue – so the string interpolation can simply be removed: ```suggestion admin_user_change_url = reverse( "admin:%s_%s_change" % (user._meta.app_label, user._meta.model_name), args=(user.username,), ) ```
Just got a typo here 😁 ```suggestion # assert joined_url and pw_change_url are identical ```
Yes, f-strings should use only plain variable and property access as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
```suggestion """Render as <p> elements.""" ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
I saw that you're now handling this at the database level. It makes more sense to me.
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
Wouldn't be required if you subclasses `IntegerField`.
This is only possible if the database allows multiple constraints on the same fields so we can also check the `allows_multiple_constraints_on_same_fields` feature flag.
We can revert changes in `_delete_unique_sql()`.
I would use the same mechanism as for the `E020` and models' labels instead of `__name__`'s, i.e. ```python indexes = defaultdict(list) constraints = defaultdict(list) ... for model_index in model._meta.indexes: indexes[model_index.name].append(model._meta.label) for model_constraint in model._meta.constraints: constraints[model_constraint.name].append(model._meta.label) ```
Use a set here to perform containment checks.
No need to create a `dict` if you're simply iterating over values.
Define a `CookieSessionTests.test_session_save_does_not_resurrect_session_logged_out_in_other_context` method decorated with `unittest.skip` instead to keep `SessionTestsMixin` backend agnostic. See #6203.
I'd move the `separators=(',', ':')` into `__init__` of `MessageEncoder`, so we always get "efficient" (having '__json_message' as key doesn't look to efficient ;)) json without having to specify it everywhere. But we can do this in a 1.6 cleanup commit after committing this.
I'd do: ``` kwargs['separators'] = kwargs.get('separators', (',', ':')) ``` On Wed, Aug 21, 2013 at 8:06 PM, Tim Graham notifications@github.comwrote: > In django/contrib/messages/storage/session.py: > > > ``` > > else: > > self.request.session.pop(self.session_key, None) > > return [] > > ``` > > > > + > > - def serialize_messages(self, messages): > > - encoder = MessageEncoder(separators=(',', ':')) > > look ok? https://gist.github.com/timgraham/dc1cc1abe202d3830eab > > — > Reply to this email directly or view it on GitHubhttps://github.com/django/django/pull/1488/files#r5903355 > .
please use a semantic test name -- ticket reference are reserved for obscure issues that can't be easily described
To verify this is the expected import error, I'd do something like: `self.assertRaisesMessage(ImportError, 'nonexistent')`
Does `serializers.serialize` write bytes or text to the stream? In the case of the later we should probably use codecs.open or similar (for py2 at least)
`stream=open(output, 'w') if output else self.stdout`
So this can be done because we're not trying to _stream_ the zipped output anywhere, only write to a file. I came up with this which seemed to work well: ```python import pathlib, zipfile class SingleZipWriter(zipfile.ZipFile): def write(self, data): path = pathlib.Path(self.filename) name = path.stem if path.suffix == '.zip' else path.name return zipfile.ZipFile.writestr(self, name, data) ```
Ah I see, okay then.
I'd prefer not to use `mock` and check generated SQL instead. Also, `Category` doesn't have `natural_key()` so it works with `XML` serializer even when optimization is not use. Maybe: ```python def test_serialize_only_pk(self): with self.assertNumQueries(5) as ctx: serializers.serialize( self.serializer_name, Article.objects.all(), use_natural_foreign_keys=False, ) categories_sql = ctx[1]["sql"] self.assertNotIn(connection.ops.quote_name("meta_data_id"), categories_sql) meta_data_sql = ctx[2]["sql"] self.assertNotIn(connection.ops.quote_name("kind"), meta_data_sql) def test_serialize_no_only_pk_with_natural_keys(self): with self.assertNumQueries(5) as ctx: serializers.serialize( self.serializer_name, Article.objects.all(), use_natural_foreign_keys=True, ) categories_sql = ctx[1]["sql"] self.assertNotIn(connection.ops.quote_name("meta_data_id"), categories_sql) # CategoryMetaData with natural_key(). meta_data_sql = ctx[2]["sql"] self.assertIn(connection.ops.quote_name("kind"), meta_data_sql) ```
Python < 3.6.
You'll want to branch off greater or equal to Python 3.6 here.
What's the rationale for changing this test class name? It looks like unnecessary noise to me.
> No exception for Python 3.5 but docs say name='_Person__friends' is required. It's required because it won't be cached and no exception is raised because there is no way to detect it.
I feel like this _helper_ is making the assertion harder to reason about. Inlining `getattr(source, attr)` calls would be easier to read IMO.
Ah yes I see. Exists being a subclass of Subquery.
@schinckel this workaround shouldn't be necessary once #9765 is merged.
This should use a variant on the `check_isseq` used elsewhere in the file. At present this does restrict you to a list or a tuple, but we may as well keep this consistent.
`if it encounter` => `if it encounters`
This unfortunately won't work if the subquery refers to any outer references as these must be included in the group by clause.
if a case is only used in 1 file like `FinderTestCase`, I'd put it there.
I usually just end the sentence with "(#26249)." instead of "Regression test..."
This should probably be: ``` try: duplicate_path = os.path.join(test_dir, 'file.txt') .... finally: if os.path.exists(duplicate_path): ``` so if something fails, we still cleanup. Alternatively, could refactor to use setUp/tearDown methods.
~~I changed this to an assertion for the only file that is affected by the second round of post-processing i.e. `cached/relative.css`.~~
This is the failing assertion on Windows. I think it might have to do with the file being written with Windows vs. Unix line endings. If you remove the assertion, the rest of the test passes.
Do we need this check? All tests pass without it.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
Please revert unrelated changes.
Is this branch tested? No tests seem to fail (I tired SQLite & PG) if it's removed.
returning `None` isn't perfectly equivalent to `continue`. I think it might be cleaner to move some or all of `_handle_object` back into `__iter__`. This allows us to use `continue` again.
IMO this check is unnecessary.
I don't think that we need this check. I would rather remove from docs [note](https://github.com/django/django/blob/77d335e5abec889b15323975187a8d5b10bfcb0f/docs/topics/db/queries.txt#L965-L979) about setting `id` to `None`. That is outdated after this patch. \cc @spookylukey
> I was under the impression that only `AutoField`'s were to be made `None`. You can also set `pk` that is an `AutoField` to a string value, in all such cases Django raises `ValueError`, so I don't see any issue in it. Moreover we can have a primary key that is not an `AutoField` but has a default value, e.g. `UUIDField(default=uuid.uuid4)` and this should also work.
`parent_link` and `field` is the same field, you can use `self._meta.parents.values()` without `zip` and `.items()`, e.g. ```python for parent_link in self._meta.parents.values(): ... ```
NotContains always makes me nervous since it's fragile (a typo or a change in the way we generate the HTML could make it pass). Could we make `class="inlinechangelink">Change</a>` a constant and use it in all 3 of the new tests? That would help alleviate those concerns.
When considering my above point please now target 4.1.
It's not resolved.
```suggestion def insert_statement(self, on_conflict=None): ``` Also ensure that this change of signature, from `ignore_conflicts=False` → `on_conflict=None`, is mentioned in backward incompatible changes to database backends in the release notes.
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
Chop blank line.
follow -> following
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
check that -> and that (no comma needed since the two clauses are independent)
Remove ticket number. Capitalise first word of sentence.
And I would rename this attribute `superusers` as it's meant to contain multiple users.
Does this check make sense now that we only handle it if it starts with a relative path? (ie if the prefix where there it would start with a slash anyways)
@jrwdunham I think you can drop this if, yes
@jrwdunham I'm not an expert here, but from what I read the true assumption is that `SCRIPT_NAME` **never** ends with trailing slash. So in case you do not have subfolder, `SCRIPT_NAME` should be just empty/unset.
Please chop `Refs #25598.`.
As said in the previous PR already, I think we should drop this
Because of Python's support for [short-circuiting](https://docs.python.org/3/library/stdtypes.html#boolean-operations-and-or-not) boolean operators, the tests are failing here as sometimes `[]` is being returned. The fix is easy: ```suggestion return bool( ```
could we inspect `query.order_by` instead? Maybe it's fine as-is, but that seems a bit less fragile.
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
May as well do the following as a field name can only legally have a single `-` at the start: ```python field_name = part.lstrip('-') ```
Actually `assertContains` checks the `status_code` too, so the other assertion is redundant.
It's ugly either way, but this way might make it slightly easier to debug if the test fails at some later point. ``` python plot_details_field = list(list(list(response.context['adminform'])[0])[3])[0] self.assertEqual(plot_details_field.field['name'], 'plotdetails') self.assertTrue(plot_details_field.is_readonly) self.assertEqual(plot_details_field.contents(), 'Brand New Plot') ``` I guess it we used the pattern more widely, it might be worth some helper functions to make it easy to extract fields without using magic numbers in the indexing.
No, it would be admin specific so it doesn't belong there. Just a private API mixin for the Django tests is that I was thinking. It might live in this file, for example.
I guess `get_admin_readonly_field()` could take `response` instead of `response.context['adminform']`.
I think that's fine.
IMO this tests should be moved to the `tests.backends.tests.BackendTestCase`, also we don't need to mock a database, checking for a `connection.alias` in a logger should be enough, e.g. ```diff diff --git a/tests/backends/tests.py b/tests/backends/tests.py index da20d94442..5f6e02d91d 100644 --- a/tests/backends/tests.py +++ b/tests/backends/tests.py @@ -3,6 +3,7 @@ import datetime import threading import unittest import warnings +from unittest import mock from django.core.management.color import no_style from django.db import ( @@ -492,6 +493,23 @@ class BackendTestCase(TransactionTestCase): BaseDatabaseWrapper.queries_limit = old_queries_limit new_connection.close() + @mock.patch('django.db.backends.utils.logger') + @override_settings(DEBUG=True) + def test_queries_logger(self, mocked_logger): + sql = 'SELECT 1' + connection.features.bare_select_suffix + with connection.cursor() as cursor: + cursor.execute(sql) + params, kwargs = mocked_logger.debug.call_args + self.assertIn('; alias=%s', params[0]) + self.assertEqual(params[2], sql) + self.assertEqual(params[3], None) + self.assertEqual(params[4], connection.alias) + self.assertEqual( + list(kwargs['extra']), + ['duration', 'sql', 'params', 'alias'], + ) + self.assertEqual(tuple(kwargs['extra'].values()), params[1:]) + def test_timezone_none_use_tz_false(self): connection.ensure_connection() with self.settings(TIME_ZONE=None, USE_TZ=False): ```
Again, not related but use `force_raster_creation=True` rather than a tough to decipher plain boolean.
btw `reversed(x)` doesn't actually iterate the whole list in reverse in python 3, you just get a `list_reverseiterator`... ``` In [1]: reversed([1]) Out[1]: <list_reverseiterator at 0x105098b70> ``` :)
Rather than implementing a special CursorWrapper for Oracle to do this, it is better to include the change in the general CursorWrapper. This has two immediate advantages over doing it in the Oracle backend: 1) The new feature can be shared with any other backend which supports it (3rd party backends included) 2) The new feature is automatically included in CursorDebugWrapper (which your version of make_cursor disables) The disadvantage -- exposing the interface to backends which do not support it -- is a small price to pay in comparison.
The current idiom might be required because some backends (perhaps third-party ones) choke on empty `params`. I'd keep it.
Fine. They're gone. 😀
https://github.com/django/django/pull/10692/commits/deadb225ccb703b24ee685e079930541149e2370 (which is a `fixup`)
OK. That makes sense. Let me have a go at re-writing that.
add trailing comma
I think this test would make a little more sense if we used a `CharField` for the primary key of `Foo`. It's not super important though.
```suggestion if match := time_re.match(value): ```
If I can bring a little bit of nuance to my position. Yes, Python supports aware time. However, the majority opinion in Django contributions (AFAIK) is that using this feature is likely to result in worse design than not using it. Many users aren't experts able to delineate narrow sets of circumstances under which code manipulating aware times is more likely to be correct (e.g. "my code will never be used outside HK and HK will never introduce DST [alternative: I will write a unit test that fails if HK ever introduces DST]"). The recommendation would be to manage the time and the timezone in separate objects. There are other cases where Django diverges from Python's standard behavior. For example, I have found the transaction behavior mandated by PEP 249 less than helpful for most users and I have decided to default to autocommit in Django instead.
```suggestion if match := datetime_re.match(value): ```
```suggestion if match := date_re.match(value): ```
```suggestion return datetime.datetime(**kw, tzinfo=tzinfo) ```
can not -> cannot (we usually opt for "can't")
Raising -> Raise
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
We typically use `assertRaisesMessage` to make it easier to track where the exception originates.
> The browser resubmits the "logout" tab, and the user is logged out again. The browser asks whether it should resubmit POST requests no? But you are right it is not 100% nice if `next_page` is not used.
This could become: `# IndexError error is used for historical reasons.`
I would use `if kwargs:` and swap the branches unless you see a reason not to. In that case "# Slower, kwargs-ready version." may not be needed.
Probably , "We rely on this, so don't change the order without changing the logic." can be removed or else just say, "Don't change the order without changing the logic."
Clarify 'we', if possible.
".. on pop so that get_default() isn't evaluated and then not used (#12057)."
Something is wrong with the indentation here, you might want to use `flake8` from the top directory to spot warnings.
Scanning a list will not be faster than a membership test of a set (unless the list of words is very small).
Since the list is in order of most common use, the code detects incorrect passwords slightly faster if you preserve the order. :bikeshed:
Won't this result in a confusing SQL-level error if you pass in `None` for `expression` or `pos` by accident? I'm assuming `length` is the only one we actually expect to possibly be `None`. If that's true, I think it would be better to do something like: ``` expressions = [expression, pos] if length is not None: expressions.append(length) ``` Or, if you prefer: `expressions = (expression, pos, length) if length is not None else (expression, pos)`
Ah! Of course, sorry I missed that.
`HTTPS` is not necessary, so I removed this line.
It might be helpful to explain: "Invalid - urlparse() raises ValueError", or following the other examples: ``` >>> urlparse('https://[') ValueError: Invalid IPv6 URL ```
put the closing parenthesis on the next line
You can use `self.assertIsNotNone(req2)` I think.
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
Yes. Adding `?:` makes it a non-capturing group which allows for use of `m.groups()` below. Otherwise it'd need to be `... = m[1], m[2], m[4]`.
I'd rename `subminor` to `patch`.
You're right. You know I both saw that and missed it too...
TIL that character classes also work inside `[]` :D
I think we should be consistent and use double-quotes.
I wonder if adding a similar `assertDetails` helper would be worthwhile to reduce verbosity here.
Please remove the unnecessary semicolon.
I would move tuple unpacking to the `for` loop, i.e. ```python for column, expected_string in testable_column_strings: ... ```
from Python, so we quote and substitute parameters manually.
Retrieving metadata from SQLite is always such a pleasure :)
```suggestion "Cannot aggregate over the 'other_age' alias. Use annotate() to promote it" ```
using `Lower` seems more readable
```suggestion authors, [25, 34, 35, 37, 45, 46, 57, 29], lambda a: a['age'] ```
omitting the ellipsis seems okay to me. Do we need to include 'id__max' twice, e.g. `Cannot compute Max(): 'id__max' is an aggregate`
Other tests use naming like: `test_json_agg_empty`
I would separate each `with` statement with a line break. right now it looks like a huge block of stuff.
For test doc strings, rather than "Test X" I try to describe the desired behavior: `A ValueError is raised when the incorrect object type is passed to a query lookup."
`self.oc` doesn't appear to be used
As noted in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style, we're not so strict about it in code.
I'd omit the `shortcut_url` variable and put this directly in the `get()`.
Can you explain why it's okay to move `patch_vary_headers()`? (I know nothing about it and am just reading about it now.) Also, remove (I think) the failing test.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
GZipMiddleware doesn't modify a weak ETag.
```suggestion # Windows registry may not be configured with correct # mimetypes. ```
```suggestion self.assertEqual(value, b'text/plain') ```
put closing ) on next lin
return without intermediate `etags` variable
use single quotes for consistency
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
Looks like a few tests are missing. If I remove this if/else and just leave `return _not_modified(request, response)`, no tests fail.
This check is also redundant.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
I think `GET` is fine for that.
@MarkusH Such a request should not change any state, so it should be `GET`. Using `POST` and `CSRF` wouldn't help against DoS there anyways (unless I miss something). If you are worried about querying the database, you can do the same with a normal request to the list views in the admin…
One empty line above, please.
I don't think there is any requirement for `default` to be a sequence. Previously, this code would work: ``` python >>> MISSING = object() >>> foo = MultiValueDict().getlist('foo', MISSING) >>> foo is MISSING True ``` Following the patch: ``` python >>> MISSING = object() >>> foo = MultiValueDict().getlist('foo', MISSING) Traceback (most recent call last): File "<console>", line 1, in <module> File "/tmp/venv/src/django/django/utils/datastructures.py", line 149, in getlist return list(self._getlist(key, default)) TypeError: 'object' object is not iterable ``` I think we perhaps need to do something like this: ``` python def _getlist(self, key, default=None, force_list=False): try: values = super(MultiValueDict, self).__getitem__(key) except KeyError: if default is None: return [] return default else: if force_list: values = list(values) return values def getlist(self, key, default=None): """ Returns the list of values for the passed key. If key doesn't exist, then a default value is returned. """ return self._getlist(key, default, True) ```
Use PEP257 verb style, "Return ..."
It helps readability to include the kwarg name rather than only a boolean param, i.e. `force_list=True`.
I think @chicheng means doing the equivalent of: cache.get_or_set('some-timestamp-key', datetime.datetime.now)
Shouldn't django allow lazy-evaluation function as default value? (Calculate the default value as needed)
We can do much better here. We don't need to regenerate the `LIMIT 1` snippet for every table, as it never changes. The `AS has_rows` is unnecessary. ```suggestion limit = self.connection.ops.limit_offset_sql(0, 1) sql = ' UNION '.join([ "(SELECT '%s' FROM %s %s)" % (table, self.connection.ops.quote_name(table), limit) for table in tables ]) with self.connection.cursor() as cursor: cursor.execute(sql) return [row[0] for row in cursor.fetchall()] ``` I'm also wondering whether we should pass the table names string literals in the `SELECT` as params to avoid any sniff of SQL injection. I honestly don't know if there is a real risk here. The advantage of keeping it like this is that we don't need to batch for SQLite and the overridden version there can be removed.
```suggestion for table_name, table_rows in rows: ```
Tests are failing for a different reason due to qwirks with our CI system; notice that SQLite tests are failing as well.
I would keep this on multiple lines. IMO, readability is better with the multiline version.
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
, keeping a reference to the cyptes object so that the vsimem file...
format parameters as described above
And there: ``` work_file = os.path.join(self.dirpath, '%s.c' % self.file) ```
And use `work_file` here.
chop blank line
I'd use `assertIsNone`
Use `assertIsNone` instead.
You could use a loop and subTest to make the test less repetitive. e.g. have a list of dicts like `{'poly__equals': Point(1, 1)}` and then use `qs.filter(**filter_kwarg)` within the loop.
`list` is unneeded here. As an alternative you could use: ``` qs = State.objects.filter(pk=null.pk) self.assertFalse(qs.filter(poly__intersects=LineString((0, 0), (1, 1), (5, 5)))) ```
Can we test both `Person` and `Political`?, e.g. ```python def test_create_new_instance_with_pk_equals_none(self): c1 = Congressman.objects.create(state='PA', name='John', title='senator 1') c2 = Person.objects.get(pk=c1.pk).congressman # Create a new congressman by setting pk = None. c2.pk = None c2.name = 'Bill' c2.title = 'senator 2' c2.save() self.assertEqual(Congressman.objects.count(), 2) self.assertEqual(Person.objects.get(pk=c1.pk).name, 'John') self.assertEqual(Politician.objects.get(pk=c1.politician_ptr_id).title, 'senator 1') ```
Would be better to do unrelated cleanups like this (I saw another rename in schema.py) in another commit.
Could use `bulk_create` ```suggestion Product.objects.bulk_create([ Product(name='p1'), Product(name='p1', color='red'), ]) ```
This warning ID was not updated after copy-pasting it.
This should probably be the default for postgresql's `schema_editor.sql_create_index`.
You need to wrap the second instantiation in its own assertRaises to actually test it.
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
They can only be decoded if these bytes were previously encoded in this encoding.
move this to an else block in (try/except/else)
This -> These
`VACUUM INTO` was [added in 3.27.0](https://sqlite.org/releaselog/3_27_0.html). This would bump requirements in `databases.txt` and `check_sqlite_version()` check in `django/db/backends/sqlite3/base.py`
```suggestion elif multiprocessing.get_start_method() == 'spawn': ```
`will re-opened in to ...` should maybe be something like `will re-open in ...`
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
I'd chop this blank line since the } on its own line is providing whitespace.
Can you reference the ticket number in the docstring, please.
This should be something like `self.assertEqual('migrations\n (no migrations)\n', out.getvalue().lower())` (perhaps adjusted a bit to match the output of showmigrations for other apps) (no SystemExit).
if no app*
Please revert unrelated cosmetic changes to keep the diff clean.
Passing `stdout` and `stderr` is not necessary. ```suggestion call_command('makemigrations', 'migrations', interactive=False) ```
I see, thanks for your answer. I really don't want to hold the template based widget stuff from landing any longer. I suppose this is something we could refactor later on.
```suggestion """The cached template loader is always enabled by default.""" ```
We can keep them together ```suggestion with self.subTest(DEBUG=debug), self.settings(DEBUG=debug): ```
Add a trailing comma.
Jinja raises `jinja2.TemplateSyntaxError` in `render()` not in `get_template()` when an error is in the included template, so that's the real usage. We don't need to mock anything here.
I stand corrected. Thanks. I didn't expect that ``` $ python -m timeit 'tuple(i for i in range(10000000))' 1 loop, best of 5: 620 msec per loop $ python -m timeit 'tuple([i for i in range(10000000)])' 1 loop, best of 5: 556 msec per loop ```
I think we can get rid of the list comprehension, can't we? ```suggestion self.wrapper_classes = tuple( wrapper_cls for wrapper_cls in self.wrapper_classes if wrapper_cls is not Collate ) ```
Minor but pep8 suggested using double quotes instead of escaped single ones ```suggestion "Multiple references to %s can't be used in an indexed expression." % ( ```
But we don't mutate `IndexExpression.wrapper_classes`.
We cannot pass `connection` in the `__init__()` because it breaks e.g. `deepcopy()`. I decided to add a separate hook `set_wrapper_classes()`, it is not the cleanest solution, but it's not the end of the world :globe_with_meridians: , and we don't have much time before the feature freeze :clock1: .
Still I think `'&nbsp;<strong>%s</strong>'` could be factored as a variable and `<a href=...` interpolated inside that. Let's use `format_html` instead of `escape`. This return could go in the `else` block of `try/except/else`.
Could you try to improve this so that there isn't duplication of the HTML and `escape(Truncator(obj)....`
This should be outside the try block as it's not expected to raise the exception.
We should also use `quote()` because non-integer primary keys may not work properly, e.g. `_40`. Fixed.
```suggestion return format_html('<a href="{}">{}</a>', url, remote_obj) ```
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
`UniqueConstraint` not `Index`.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
I'd use the preferred style so at least future tests might copy it.
I'd use: ``` self.assertEqual(Bar.check(), expected) ``` to save a line.
I would omit the parenthesis in these messages (I know it's done elsewhere, but "I am at war" with that style unless you like it).
I think this test would make a little more sense if we used a `CharField` for the primary key of `Foo`. It's not super important though.
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
OK then, thanks for the references.
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
Is it possible to convert year type? (e.g. 2006 &rarr; 2549)
```suggestion elif databases[DEFAULT_DB_ALIAS] == {}: ```
```suggestion params = self.settings[alias].copy() ```
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
These lines should be removed; it's possible for `databases` to be an empty list during tests and when no `--database` is passed to `manage.py` check as you've mentioned. When this happens this check should be entirely skipped.
Ok, cool. :thumbsup:
`clean` is not only for validation, but also for data modification in a form.
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
The form class is configuration too, is it not? You can group class attributes using a blank line, but this attribute is inherited from `BaseModelAdmin` where it is not separated. It just seemed odd.
I think this is just as readable on a single line: `(internal_size, desc[4] or 0, desc[5] or 0,) +`
Using tuple unpacking such as `... for a, b, ... in cursor.fetchall()` rather than indexing should help readability.
To be consistent, BigIntegerField should be qualified with `if c.f.can_introspect_big_integer_field`
I think we can use `Article.headline`, chop blank lines, and simplify these tests, e.g. ```python def test_create_index_with_desc_suffix(self): index = Index( fields=['-headline'], name='whitespace_idx', opclasses=['text_pattern_ops'], ) with connection.schema_editor() as editor: self.assertIn( '(%s text_pattern_ops DESC)' % editor.quote_name('headline'), str(index.create_sql(Article, editor)), ) ```
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
Yes, please rebase the branch and remove the try/fail pattern as done in 6729b96d8a15048b2295c916c5b881a59d9417a0. If you're unfamiliar with the process you might find https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/working-with-git/#rebasing-branches helpful.
Please revert unrelated cosmetic changes to keep the diff clean.
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
Management command use `OutputWrapper()`, so we need to do the same here.
`response.request.method` would be more idiomatic.
Oh, that surprises me too...
PEP 8 hedges about line breaks and binary operators but suggests ultimately that breaking before the operator is better. As long as we're touching this I would suggest breaking before the operators.
what "it" refers to is ambiguous
```suggestion request.method in ('GET', 'HEAD') ```
```suggestion @mock.patch('sys._xoptions', {'utf8': True, 'a': 'b'}) ```
Please add a trailing comma: ```suggestion [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver'], ```
```python msg = 'Script does-not-exist does not exist.' with self.assertRaisesMessage(RuntimeError, msg): ```
`can not` -> `cannot`, or better `may not `
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
you don't need `nulls_last=True` here because it's a PK you're ordering by, which is non-nullable
```suggestion ).values_list("siblings_json", flat=True).first() ```
```suggestion self.assertSequenceEqual( ```
I think the `lambda` could go on this line.
`None` in `getattr` is already default.
Similarly, I don't see much advantage to creating indirection with a method.
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
I moved a cleanup part to a separate commit.
Since `SmallAutoField` extends `SmallIntegerField` this can be reduced to ```suggestion elif isinstance(self.lhs.output_field, models.SmallIntegerField): ```
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
should be indented as in other places
please alphabetize with the rest of the django imports
Please don't move import. Also the import in the line below should be alphabetized.
This usage looks a bit magic to me, but I think it can stay as it is. The module level deprecation warnings in https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01 are different than this, so stacklevel=2 can be removed in the following locations: - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-9e264d0b47bfdd60be1698bca9bae281R19 - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-68395a4996a48dd1b3cd34ddd9efe762R12
please use parentheses instead of backslash
I'm torn whether or not this copy is necessary. When we resolve the expression we do a copy of the subquery anyway. Even if the queryset was cached and evaluated, the resolving will copy a new queryset anyway. ```python qs = Model.objects.whatever() sq = SubQuery(qs) list(qs) # this evaluates the queryset that subquery is holding onto OtherModel.objects.annotate(subq=sq) # queryset is copied here anyway, previous eval doesn't matter ``` Let me know if you can poke holes in my reasoning (it is new years day after all...).
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
Yeah that's what I suspected too. Stupid SQL.
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
Languages are ordered by `code`, so this should be above `'tr'`.
I'm wondering if this should be within the `DATABASES` setting
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Водка')) ```
Yes, consistency matters :-) Maybe @timgraham can bring his expertise here.
I don't usually include a blank line here.
I don't think it's necessary to create new files for this test. We could use for example `django.contrib.auth.models.Group` for a simple model with a name, and the test could be appended to the `TemplateRegressionTests` class, for example.
I think we should avoid writing new test suites that use fixtures. Fixture loading is extremely slow, and it's actually harder, IMO, to follow what the data should look like once you've aggregated it. I would suggest either creating all the data in a setUp method, or creating the data you need at the top of each test.
Please wrap docstring at 79 chars.
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
use `unittest.skipIf` decorator on the class
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
I think there are enough tests about forms using the formats machine to sanitize input values. I'd rather specifically tests `sanitize_separators` in a separate `test_sanitize_separators` test.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
You could skip these, but I thought that the rewording read better. I guess if you go for the proposed `Renderable` then they'd be moved anyway and then it doesn't hurt to update them. (Also note that the docstring for `BaseFormSet.as_ul()` neglected to mention that it isn't wrapped in `<ul>`.) 🤷🏻‍♂️
omit the intermediate variables: ``` self.assertEqual(model.check(), [ ]) ```
I don't think you can do it like this for multicolumn lt, gt constraints. The natural constraint is: a < val1 or (a == val1 and b < val2) at least that is what PostgreSQL gives you. EDIT: We can just throw an error in multicolumn non-exact lookups here for now.
Yeah, multicolumn case is what I am interested in, the results will not be correct for cases where the first column match, the second is smaller and we use __lt. So, error out in multicolumn case for now, then lets think if we can make this work properly (for some DBs the DB itself knows how to implement (a, b) < (val1, val2)).
I don't know of this particular case, but I wonder if we will have a fun time ahead regarding NULL handling in general - partial match foreign keys etc, and what it in general means for a composite field to be null... There are some similar cases in Query.add_filter() negated handling.
Current implementation of `get_prefetch_queryset()` assumes that all instances have the same content type (there is an issue), but the fix is not optimal IMO because object IDs can be the same in different content types, e.g. we have two related objects: - object ID 1 with content type ID 1, - object ID 2 with content type ID 2, this query will return also: - object ID 2 with content type ID 1, - object ID 1 with content type ID 2, which is not correct. I know that we are matching them below but still I think we can limit the no. of objects only to actually needed.
IMO we should refactored out `test_rename_field_index_together()`.
Please use this style to limit lines to 120 characters so we don't have to scroll to review it: ``` self.assertEqual( ..., ... ) ```
I'd like to have some actual tests for the underlying foreign keys: see the `self.assertFKExsits()` and `self.assertFKNotExists` usage in `test_rename_model_with_self_referential_fk()`
Can you use `self.assertNumberMigrations()`, `self.assertOperationTypes()` and `self.assertOperationAttributes()` instead of things like `self.assertEqual(first_action.__class__.__name__, "AlterUniqueTogether")`, please. Have a look through at the top of the test case on which arguments they expect and how they work. They are also heavily used all over the place in the autodetector tests. (A overall cleanup is in #3564.)
I'd drop it, and reintroduce the test later on in branches where we'll be able to backport #9383.
This could be replaced by `self.remote_field.model._meta.label_lower` https://github.com/django/django/blob/c1b24718e05ea474955777d7bc4d9d5634560cd5/django/db/models/options.py#L136-L138
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
```suggestion self.remove_model(app_label, old_name) self.reload_model(app_label, new_name, delay=True) ```
As an example. The method signature should be ```python def rename_model(self, app_label, old_model_name, new_model_name): ... ``` And be called from `RenameModel.state_forwards` as `state.rename_model(app_label, self.old_name_lower, self.new_name_lower)` instead of passing the `Operation` instance along.
I think we can abstract away the need to _lower_ the name here. ```suggestion def alter_model_options(self, app_label, model_name, options, alter_option_keys=[]): ```
These kind of changes are not related and should be reverted, IMO. They're also based on a `MiddlewareMixin` behavior that we can remove in the future, that's why I would prefer to keep `process_request()`/`process_response()` tests.
Valid point. Feel free to change the decorator in a separate commit.
One empty line above, please.
I think this test isn't working as expected -- it's resolving to `RedirectView`, same with `test_inline_urls` -- probably the result of the resolve should be checked.
why an empty string? might as well use assertRaises at that point.
the active language's
This isn't related to your changes, but I'm intrigued by Django's behavior here. I would expect `|escape` to give `&amp;` and `|escape|force_escape` to give `&amp;amp;`. Not that this construct makes much sense anyway...
Ha! So it's actually related to your changes :-) Happy to hear that we'll eventually get the semantics that I would expect.
Please add an empty line above.
I don't think you should re-number the existing tests.
I think keeping the explicit `process_response()` call here would make sense. By changing to `__call__()` we're running through `process_request()`, which is not a no-op, which is perhaps fine but it's subtly changing the intent/behaviour of the test. (I guess this is something we'd have to think about removing the `process_x()` hooks, but not in this PR) Same for line 677 below. **Update**: Tests in `csrf_tests` are more explicit about this... (So maybe the small change here is OK)
On balance I will leave this one as it is.
These kind of changes are not related and should be reverted, IMO. They're also based on a `MiddlewareMixin` behavior that we can remove in the future, that's why I would prefer to keep `process_request()`/`process_response()` tests.
Wrap at 79 chars, please.
One empty line above, please.
Surely you want all of the password hashes in the list of available ones so that people can log in with them? Of course argon2 is unlikely to be out there in the wild, but if someone tried it and then decided to switch back they wouldn't be able to do so by deleting the settings, they'd have to copy/paste the default and re-add it. There's little harm in including it by default afaik. You might not want to have something other than PBKDF2 to be the default though, people might accidently have bcrypt or argon2 installed and not realize it and end up unable to log in if they deploy. Not sure if that's a big worry or not though.
Our code currently requires the first hasher to be usable, putting it as first and not installing the extension will break (look at `get_hasher('default')`)
I think the best argument is "There's little harm in including it by default afaik.". If someone tried using argon2 they can as well adjust their settings, after all they are testing against an unreleased version.
From a security stand point, argon2 is better than PBKDF2 because it's memory hard as well as CPU hard. Security wise argon2 > scrypt > PBKDF2 ~= bcrypt.
Presumably at some point this change will be released.
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
It looks like there will be a SQL syntax error due to a trailing comma if gin_pending_list_limit is used without fastupdate. Maybe `with_params` should be a list and joined with `', '`.
Tests for this method seem missing. It seems like we need a better way to build these reprs that's not so complicated and repetitive for each index.
Do you see much value in Django validating this? The error message from PostgreSQL seems clear: `django.db.utils.DataError: value 1 out of bounds for option "gin_pending_list_limit" DETAIL: Valid values are between "64" and "2147483647".
I think that `2**31 - 1` instead of `2147483647` is more readable.
Consider using a single test and `subTest()` to avoid the same boilerplate in each test.
```suggestion now = datetime.utcnow() a = DBArticle.objects.create() ```
`This test` is unnecessary. Please write `skipUnless` in one line e.g. `@unittest.skipUnless(connection.vendor == 'sqlite', 'SQLite specific test.')`.
The fact only a single result is returned is a strong enough assertion here. Some database backend could translate `__isnull` to some different SQL.
Could we check if we actually need this `with` statement again? Maybe the one above is just fine? :man_shrugging:
I don't have a strong opinion about the quote style but use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Creating and isolating new connections in tests are tricky. > if we don't have yet good mocking structure for ORM-database operations Testing database operations is not difficult, but here we want to test a low-level operations related with preparing a database before using ORM.
Testing `prepare_database()` is difficult (a lot of mocking is needed to get a proper isolation). IMO we can push this without tests.
We don't use `assert ` in tests. Please use `unittest` assertions: ```suggestion self.assertIs(self._extension_exists(), False) ```
It would be more elegant, and possibly more efficient, to use: ``` template_postgis = getattr(settings, 'POSTGIS_TEMPLATE', 'template_postgis') cursor.execute('SELECT 1 FROM pg_database WHERE datname = %s LIMIT 1;', template_postgis) if cursor.fetchone(): return template_postgis ``` This is how `QuerySet.exists()` is implemented.
> Current PR (Allows user to specify suffix - consistent with posgresql backend): Users cannot specify `prefix` it is an option that Django uses internally. I think we should keep the current prefix `_id` for backward compatibility.
I don't think that a separate ticket is necessary, using `super()._create_index_sql()` will fix described issue.
Actually I think it might be possible to reuse most of `super()._create_index_sql` by using `expressions=[RawSQL(...)]` instead of `columns` to avoid heavy duplication between both methods.
We can pass `opclasses` to the `super()._create_index_sql()`.
I think we can change `rast_index_wrapper` instead.
For Polish no change is needed. `X days ago` is `X dni temu` and `X days from now` is `za X dni`. Those prefix and suffix doesn't change for any number of days.
Thanks to @mxmerz for writing to the django-i18n mailing list, Hungarian is such an example: - `X days ago` can be translated as `X napja` or `X nappal ezelőtt` while - `X days from now` can be translated as `X nap múlva`
You also have to pass `'number'` as the last argument to `npgettext_lazy`, and in each line below.
Please add trailing comma.
`getattr()` rather than calling a dunder method
, -> . (for consistency with same message in operations/models.py)
Use: ``` python raise ValueError( "Indexes passed to ModelState require a name attribute, " "%r doesn't have one." % index ) ``` While we allow longer lines, we typically break up long strings like this.
Does the ordering of indexes on a database matter? I'm not talking about the order of fields an index applies to, but the indexes itself.
I'm not following exactly what the idea is and what problem it's solving.
I briefly remember that there was an issue with wrong index names a while ago, that _somehow_ got in people's projects. I can't recall the details, but all migration operations should enforce a deterministic index name present. That is, `AddIndex` checking for `self.index.name` and `RemoveIndex` checking for `self.name`.
The parameter to this method seems odd to me. As it stands, no caller is explicitly using the parameter in a call to the method and I can't see many legitimate uses for it in derived classes. I think you're effectively just using the default value as a space to store a class-scope variable. Would it be simpler to just assign a member on the class? Or on the instance, if you prefer.
Having an overridable method seems like the most orthodox OOP solution (it's what a Java programmer would do :-) ) but I'm not convinced it really gives a useful abstraction: by coincidence it's the right place to make this one change, but I'm not sure there's a useful class of future modifications it opens up, so it feels like overkill to me. My thought with an instance variable was just to set it in the constructor in the base class, and overwrite it in the subclass constructor (not exposing it as a kwarg). I'm not sure there's any advantage to this; I think I was thinking about this because it's what I'd do in C++. I don't have a particularly strong feeling on this. I think if I were writing it I'd go with the class-level attribute.
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
@hannseman Thanks :+1: > I prefer it over the mixin approach. Yes me too :+1: . We can move `Value()` wrapping to the `__init__()` and simplify it a bit, e.g.: ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) if not (config and hasattr(config, 'resolve_expression')): config = Value(config) self.config = config def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save) resolved.config = self.config.resolve_expression(query, allow_joins, reuse, summarize, for_save) return resolved def as_sql(self, compiler, connection): sql, params = compiler.compile(self.config) return '%s::regconfig' % sql, params ``` Please move introducing a `SearchConfig` expression to the separate commit, or even PR.
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
chop blank line
Most likely this will not work on Windows because files created with `NamedTemporaryFile` cannot be reopened on Windows (which defeats the whole purpose of naming them in the first place -- I have no idea why `NamedTemporaryFile` even exists on Windows). I'm not saying this is blocking the merge because I don't think we have that many users of PostgreSQL on Windows, but I thought I'd bring it up in case someone wants to check.
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
Same style as above.
I think I would put `change_message = []` below the new code so it's not separated from where it's used.
I'm not sure special-casing the password field is a good idea, as you might as well have user code presenting such cases, and then the function would crash badly. I think a try/except clause catching the KeyError when f is not find in form.fields, defaulting to the raw field name in that case, would be a safer approach.
I suggest to call the variable `changed_fields_labels`.
I believe this line can live within the with statement below without issue.
Use form.changed_data directly and remove the alias as recommended by Tim.
Reading below, I see that Flask has an "any" converter that does something more complicated. Creating a converter with the same name but a different behavior doesn't sound good.
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
Use single quotes consistently.
can omit these two newlines
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Propose to clean this up in https://github.com/django/django/pull/8008.
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
It used to be that way (in Python 2 era). Now gettext is an alias to ugettext and the latter will be deprecated in the future.
Use `gettext` instead of `ugettext`
Discussion of this function is outside of the scope of this ticket, this is merely a backport of what's already in master and 1.6: https://github.com/django/django/blob/master/django/utils/module_loading.py#L12
I don't think we need to have a strict policy on `/` vs. `.joinpath()`. I'd prefer `/` but when readability hurts we can also use `.joinpath()` :shrug:
_Ideally_, unless you are testing a failure condition, you don't want tests to result in an error. So the test case which ensures that an error is raised when the target directory does not exist will be the one in which that error should occur. In this case, the test should ensure that running `$ ... startapp app directory/` works successfully given that everything else is in place. Consider this hypothetical scenario during a refactor: - Code is moved around such that `if not os.path.exists(top_dir): raise Error` occurs before `self.validate_name` - `.rstrip(os.sep)` is deleted. The test case will still pass but the command will fail at that point.
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
Do we need these changes? :thinking: `Path.absolute()` raises `FileNotFoundError`, so why not catch it in `watch_for_translation_changes()`, e.g. ```python for path in directories: try: absolute_path = path.absolute() sender.watch_dir(absolute_path, '**/*.mo') except FileNotFoundError: logger.debug('Skipping watching file %s as it cannot be resolved.', path, exc_info=True) ```
Great, thanks! I will merge #11590 and rebase this PR :+1:
I think we are missing the `call_command()` here.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
Add trailing commas in call_commands.
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Водка')) ```
Also, if you are using a context manager, it seems like you want to assert calling `is_usable()` right before you close (so after the context manager closes).
> For the sqlite3 case the connection will never close (it can't) so the test will fail. The bug can only be reproduced with postgresql oracle and mysql so testing sqlite is pointless to me. Keep in mind that while the default test settings use an in memory SQLite database running the suite with a file based SQLite database is a valid setup that should be accounted for.
Again, not related but use `force_raster_creation=True` rather than a tough to decipher plain boolean.
Did you consider updating the `def create_cursor` definition on the other backends so if/else isn't needed? This could be mentioned in the "Database backend API" changes in the release notes. If we want to keep both signatures, something like `return self.create_cursor(*(name,) if name else ())` might be less repetitive. I see this pattern is used a few times.
To have more balanced line length, I think I prefer: ``` python constraints = self.get_constraints(IntegerArrayModel._meta.db_table) self.assertEqual(constraints['integer_array_model_field_gin']['type'], 'gin') ```
This is not necessary.
IMO it's enough to test that `CreateExtension` honor `allow_migrate()`, creating extension is already tested in `postgres_tests`.
> Is there any specific reason why we would prefer using the operation in this case? Yes, because we have it. Using a RAW SQL is the last option, we're developing the ORM in order not to use them.
You might want to write some tests to prove that the new query search subclasses combine correctly with SearchQuery.
Maybe this inheritance should be refactored a bit as it's not obvious if `PostgreSQLWidgetTestCase` is now using `TestCase` from `PostgreSQLTestCase` or `SimpleTestCase` from `WidgetTest`? e.g. `PostgreSQLTestCase.tearDownClass()` might be moved to a mixin that `PostgreSQLTestCase` and `PostgreSQLWidgetTestCase` can use.
```python kwargs['max_value'] = min(value, kwargs.get('max_value', value)) ```
I suggest you use the `for`/`else` construct here. ``` python for validator in validators: if isinstance(validator, validators.MinValueValidator) and validator.limit_value <= min_value: break else: validators.append(validators.MinValueValidator(min_value)) ```
Ditto about the `for`/`else` construct.
And this can be reverted.
Simply return `validators`.
What if a view based on `DeleteView` overrides `delete` method to actually handle requests with HTTP `DELETE` method? For them this warning would be a false positive.
Good, thanks. Maybe `Note setting ` -> `Set `
I wonder if it makes sense to add a hook (with better name) that could be called here and in `DeletionMixin`: ```python class DeletionMixin: ... def _delete(self): if not getattr(self, 'object', None): self.object = self.get_object() success_url = self.get_success_url() self.object.delete() return HttpResponseRedirect(success_url) def delete(self, request, *args, **kwargs): return self._delete() class BaseDeleteView(DeletionMixin, FormMixin, BaseDetailView): ... def form_valid(self, form): return self._delete() ```
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
Yeah, multicolumn case is what I am interested in, the results will not be correct for cases where the first column match, the second is smaller and we use __lt. So, error out in multicolumn case for now, then lets think if we can make this work properly (for some DBs the DB itself knows how to implement (a, b) < (val1, val2)).
I don't think you can do it like this for multicolumn lt, gt constraints. The natural constraint is: a < val1 or (a == val1 and b < val2) at least that is what PostgreSQL gives you. EDIT: We can just throw an error in multicolumn non-exact lookups here for now.
I don't know of this particular case, but I wonder if we will have a fun time ahead regarding NULL handling in general - partial match foreign keys etc, and what it in general means for a composite field to be null... There are some similar cases in Query.add_filter() negated handling.
I like your option 2 of `get_lookups`, I think it improves clarity over what we already have. You could also introduce some caching within the `get_lookups` to improve perf for classes that are looked up multiple times.
> @felixxm in my view, below test code is our expected result. No, it's not. `1 != NULL` so why it's expected that `number` is excluded? see 512da9d5855 and ticket-23797 for more details.
I wonder if we could support running `runtests.py` from different directories :thinking: like we do for dotted module names, e.g. ```bash ~/repo/django> ./tests/runtests.py backends.postgresql ``` works fine, but ```bash ~/repo/django> ./tests/runtests.py backends/postgresql/ .... File "./tests/runtests.py", line 155, in get_label_module rel_path = path.relative_to(RUNTESTS_DIR) File "/usr/lib/python3.8/pathlib.py", line 904, in relative_to raise ValueError("{!r} does not start with {!r}" ValueError: '/repo/django/backends/postgresql' does not start with '/repo/django/tests' ``` crashes. I tried to fix this with: ```python # Otherwise, interpret the label as a path. if not path.is_absolute(): return path.parts[0] else: path = path.absolute() rel_path = path.relative_to(RUNTESTS_DIR) return rel_path.parts[0] ``` but it crashes with `ModuleNotFoundError` (like without this patch): ``` ====================================================================== ERROR: backends/postgresql (unittest.loader._FailedTest) ---------------------------------------------------------------------- ImportError: Failed to import test module: backends/postgresql Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 154, in loadTestsFromName module = __import__(module_name) ModuleNotFoundError: No module named 'backends/postgresql' ```
Yeah it works for me, sorry again. The current version looks good :+1: , we could only raise a more descriptive error when a relative path is not correct (as proposed in https://github.com/django/django/pull/14507#discussion_r648186310).
Maybe this could be a module constant so as not to repeat it 3 times.
Any idea what the "cost" of this is? ie: because all template output runs through `render_value_in_context` -> `localize` which then dispatches to any of `number_format` / `date_format` / `time_format` each of which _may_ call `settings.USE_L10N` depending on if the `context.use_l10n` value (and I confess I can't remember when/where the details of _that_), each of those values (decimals/ints/floats/datetime.*) is unavoidably going to be slower (if/when `use_l10n` is `None`), and I wonder by how much? And is it avoidable? (eg: `cached_property` or what-have-you)
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
Feels like `--ignore-conflicts` would be a better fit if we want to move forward with this option.
This method implementation could be simplified by doing: ```python if on_conflicts == ON_CONFLICTS_IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflicts == ON_CONFLICTS_UPDATE: ... return result ... ``` This would also let you eliminate the `if-else` below and initializing `result` to `''`.
Chop blank line.
I'd say, "A custom ignore_patterns list, ['*.css'] in this case, can be..."
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
I think we should have a test and handling for the case where `mimetypes.guess_type()` returns `None` as done in `_create_attachment()`.
Use PEP257 verb style for new docsrings: "Create... use..., etc."
There's no need to define the extra `settings_dir` variable as `pathlib` gives us more flexibility: ```suggestion settings_file_path = self.test_dir / filename / "__init__.py" settings_file_path.parent.mkdir() ```
I envisioned something like this: ``` python content = None with open(path, read_mode) as f: try: content = f.read() except UnicodeDecodeError: # If mimetype suggests the file is text but it's actually binary, # read() will raise a UnicodeDecodeError on Python 3. pass # If the previous read in text mode failed, try binary mode. if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE ```
We should use a custom storage for this test (instead of mocking).
yeah you got it
use a comma instead of "-", it will read better
I'll edit this docstring to remove the references to the removed parameers, but please check my edits.
For clarity here, shouldn't we use `Func` rather than `Transform`, since they are equivalent and the latter is a back-compat-only name? It seems like using `Transform` might suggest to someone reading this code that there's something distinct about `Transform` as opposed to `Func`.
Seems like it would result in less confusing code in the long run. If you do defer it and leave the TODO, I'd suggest to use your GitHub username instead of first name.
```suggestion if field_name == '_order': field_name = self.options.get('order_with_respect_to', field_name) ```
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
Perhaps a nice alternative is: ``` result = json.loads(Question.answer_set.field.value_to_string(question)) self.assertCountEqual(result, [answer1.pk, answer2.pk]) ```
To avoid the interesting indentation: ``` msg = "<class 'admin_views.models.Question'> is not registered in the admin." with self.assertRaisesMessage(Http404, msg): ```
chop newline for consistency
This is a much better test that visibly demonstrates things _should_ work again, nice. :) I don't know the stylistic preferences @felixxm _et al_ might have around using `assertEqual` vs. `assertJSONEqual` here, so I'll leave this as a note for highlighting.
This can be single-lined ```suggestion '<ul class="errorlist nonform"><li>Please submit at most 1 form.</li></ul>', ```
You shouldn't have a `u` prefix here
These assertions are not related with a bugfix, please move them to a separate commit.
I don't think this test is sufficient. Having the first element in the output is quite likely. I'd check for the html or at least for `John` and `Paul`
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
`DEFAULT-CHARACTER-SET` is not a supported option. Please remove it. ```suggestion charset = settings_dict['OPTIONS'].get('charset') ``` This ticket is about passing `charset` to the underlying tool not about adding a new setting.
Most likely this will not work on Windows because files created with `NamedTemporaryFile` cannot be reopened on Windows (which defeats the whole purpose of naming them in the first place -- I have no idea why `NamedTemporaryFile` even exists on Windows). I'm not saying this is blocking the merge because I don't think we have that many users of PostgreSQL on Windows, but I thought I'd bring it up in case someone wants to check.
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
Unindent by one level, please.
True, just thought I mention it.
I think we don't need to define `msg` variable: ```suggestion with self.assertRaisesMessage(ValidationError, 'This field is required.'): ```
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
Please use a single quote.
Superfluous `u` prefixes. They are not Python 3.2 compatible and this file already has `from __future__ import unicode_literals` anyway.
I think we always want the input on the `>>` side of the operator to be able to utilise any indexes. So we get the following SQL: ```sql SELECT t, t <->> 'word' AS dist FROM test_trgm ORDER BY dist; ``` That should mean that we want `arg_joiner = ' <->> '`. <details> <summary>Index operator classes query where LHS is the indexed value</summary> <code> SELECT am.amname AS index_method, opf.opfname AS opfamily_name, amop.amopopr::regoperator AS opfamily_operator FROM pg_am am, pg_opfamily opf, pg_amop amop WHERE opf.opfmethod = am.oid AND amop.amopfamily = opf.oid AND opf.opfname IN ('gist_trgm_ops', 'gin_trgm_ops') ORDER BY index_method, opfamily_name, opfamily_operator; </code> </details> ``` index_method | opfamily_name | opfamily_operator --------------+---------------+------------------- gin | gin_trgm_ops | ~(text,text) gin | gin_trgm_ops | ~~(text,text) gin | gin_trgm_ops | ~*(text,text) gin | gin_trgm_ops | ~~*(text,text) gin | gin_trgm_ops | %(text,text) gin | gin_trgm_ops | %>(text,text) gin | gin_trgm_ops | %>>(text,text) gist | gist_trgm_ops | ~(text,text) gist | gist_trgm_ops | ~~(text,text) gist | gist_trgm_ops | ~*(text,text) gist | gist_trgm_ops | ~~*(text,text) gist | gist_trgm_ops | %(text,text) gist | gist_trgm_ops | %>(text,text) gist | gist_trgm_ops | <->(text,text) gist | gist_trgm_ops | <->>(text,text) gist | gist_trgm_ops | %>>(text,text) gist | gist_trgm_ops | <->>>(text,text) (17 rows) ```
> .. i'll follow your decision :) Just asking, I'm not an expert :shrug:. We can wait for the second opinion from Paolo.
Paolo, Can you take a look? (\cc @pauloxnet) :point_up:
@felixxm yes that's what I'm thinking.
> Paolo, Can you take a look? (\cc @pauloxnet) point_up Sorry, I totally missed the notification of this. I'll take a look
chop trailing ,
```suggestion # - MySQL < 8.0.13 doesn't accept default values and implicitly treats them ```
Please wrap at 79 chars.
Please chop the comma here.
Perhaps the tuple should be a module constant somewhere so it can be reused in `validation.py`.
```suggestion self.assertNotContains(response, '<nav aria-label="Breadcrumbs">') ```
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
Remove ticket number. Capitalise first word of sentence.
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
use `reverse()` rather than a hard coded URL.
Please use single quotes.
This one as well.
Shouldn't be part of this PR, but it looks like redundancy in `__repr__()` methods would be a good candidate for a refactor.
I think that you can add `filter` to `kwargs` in `__init__` method and remove redundant `__repr__` (see #8759).
Passing `filter` to kwarg will cause it to be in `self.extra` as well which could interfere `as_sql()` formatting.
or `_('Add %s')`
Move `has_view_permission` above `has_add_permission` for consistency.
Ah yes. It no doubt will. (That's too much DRF that is. 🙂) We need to handle this. 👍
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
```suggestion squashed_migrations_with_deleted_replaced_migrations = [ migration_key for migration_key, migration_obj in executor.loader.replacements.items() if any(replaced in to_prune for replaced in migration_obj.replaces) ] ```
This should be display when `verbosity > 0`.
```suggestion if squashed_migrations_with_deleted_replaced_migrations: msg = ( " Pruning cannot take place until the following squashed " "migrations are recorded as applied (re-run 'manage.py migrate') " "and have their replaces attribute removed:" ) self.stdout.write(msg, self.style.NOTICE) for migration_to_warn in squashed_migrations_with_deleted_replaced_migrations: app, name = migration_to_warn self.stdout.write(f' {app}.{name}') else: to_prune = sorted(migration for migration in to_prune if migration[0] == app_label) if to_prune: for migration in to_prune: app, name = migration if self.verbosity > 0: self.stdout.write(f' Pruning {app}.{name}', ending='') executor.recorder.delete(app, name) if self.verbosity > 0: self.stdout.write(self.style.SUCCESS(' OK')) elif self.verbosity > 0: self.stdout.write(' No migrations to prune.') ```
`--prune` is ignored when `--plan` is used. Maybe we should raise an error that they're mutually exclusive.
I would add `OK`: ```suggestion executor.recorder.delete(app, name) self.stdout.write(self.style.SUCCESS(' OK')) ```
Thanks for your effort :+1:. It is a kindly request for the first option. Trailing dot should be at the end of a sentence but there is no point in doing unrelated refactoring of existing code.
Thinking out loud here but do you think the fact the constraint is now deferred before index creation could cause an issue? I think it shouldn't be given RDMBs usually create an internal b-tree to maintain referential integrity.
Please use single quotes.
Use single quotes consistently (could be done above and below also).
Here we also should call `super` and not copy-paste code
I would like a test that fails if this is removed from the try block.
Please move this inside the if.
Ah, well then we can use `@cached_property` 😉
could this instead go before the try/except? ``` if isinstance(value, float): context = decimal.Context(prec=self.max_digits, rounding=decimal.getcontext().rounding) return context.create_decimal_from_float(value) ```
I would call `clean()` in validation tests, we should also move it to a separate tests, e.g. ```python def test_invalid_value(self): field = models.DecimalField(max_digits=4, decimal_places=2) msg = '“%s” value must be a decimal number.' tests = [ (), [], {}, set(), object(), complex(), 'non-numeric string', b'non-numeric byte-string', ] for value in tests: with self.subTest(value): with self.assertRaisesMessage(ValidationError, msg % (value,)): field.clean(value, None) ```
Maybe: ```suggestion setting = getattr(settings, 'FILE_UPLOAD_TEMP_DIR', None) if setting and not Path(setting).is_dir(): return [Error( f"The FILE_UPLOAD_TEMP_DIR setting refers to the nonexistent " f"directory '{setting}'.", id='files.E001', )] ```
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
And use `work_file` here.
Can you include latin-1, non-ASCII characters? `café` is one of the few English words matching this requirement. `Just latin-1 :)` will encode identically in ASCII, latin-1 and utf-8, making the tests much less interesting.
This is the default charset in Django, I wouldn't call it unusual :)
Mhm that is what I was trying to avoid, because for most hasher a salt length is just that and `must_update` should easily be able to handle that globally if it is returned from `decode`. What this PR certainly misses (and what will show you the existing problems) is a test for the behavior of the `bcrypt` hasher. I think now it's `must_update` will *always* return `True` and set a salt *every* time.
IMO, we should use `self.decode` here.
Add an exception message similar to the other methods.
See the messages for the methods above and add them these here too
Either add `self` or make it `@staticmethod`
`resolve_expression_parameter` maybe? You're not really dealing with combinables here (even though they are also combinable), so just go with expression based names I think.
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
Similarly, I don't see much advantage to creating indirection with a method.
Can you use `['indexes']` here? If not, the list comprehensions in the next lines have a `not in None` and will fail.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
I think you want `options['indexes'].remove(idx_name)` here. That would simplify this code, and I think together with the change in signature mentioned above, remove the need for `get_index_by_name` as well. [List.remove](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists)
Indexes are not constraints, generally.
Move the exists assertions to another test.
Might want to only test for `JOIN` presence as this wouldn't fail if `LEFT JOIN` was used.
Could you create a separate test case so we don't have extra objects created for all the other tests? For that new class, setUpTestData can be used instead.
Could use `assertSequenceEqual` to avoid the `itemgetter`
The fact only a single result is returned is a strong enough assertion here. Some database backend could translate `__isnull` to some different SQL.
Why is this way preferable to ```suggestion def _check_token_present(self, response, csrf_secret=TEST_SECRET): ```
Personally, I like this because you can pass `None` to get the default value. We can decide to change, but it should be a part of a separate PR.
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
docstring with example input/output would be really helpful
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
please limit docstrings to 79 characters and add period
I think you could simplify this a bit by using `self.client.login(self.super_login)` and the ORM to create the initial objects instead of the add view.
I think the test is not in the right class (`AdminViewPermissionsTest` should be limited to test permission-related stuff). We may need a new test class.
that's the default in 1.9, but I don't if you want to include it anyway
Sorry, I couldn't figure out how to continue the conversation that I started here -- the fact that you changed the code seems to "trick" github into thinking that we are done here :) As you pointed out, `get_inline_instances` with no request is very weird and probably (tm) breaks existing code out there. What do you think about the following: Add only one (or two, if it makes handling inlines easier) autocomplete view to the urlpattern (statically) which disapatches to `self.autocomplete_view` and the returns `AutocompleteJsonView` accordingly. This way you'd have access to the request and would just need one view which you'd pass the information you need.
This is already tested in `test_args_kwargs_request_on_self()`, I'm going to remove these assertions.
Perhaps dropping this blank line.
This test is not related with the patch, so I'll move it to a separate commit.
And all the blank lines in this test.
```suggestion Question.objects.create(question='Not a question.') ```
This test won't pass when pytz isn't installed. For consistency with the timezone tests, you should declare: ``` python requires_pytz = skipIf(pytz is None, "this test requires pytz") ``` and then decorate it with `@requires_pytz`. This is a minor concern since the docs now encourage installing all optional dependencies before running the test suite, but I suppose it could save some headaches to people running the test suite without a virtualenv. on or systems that don't have `time.tzset` (that is, Windows). Have
FWIW I didn't find pytz required, except on Windows, but I might have gotten lucky with my particular configuration.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
I think this can go in `NewDatabaseTests` rather than a new class.
TextInput -> Input? I suppose a `test_input.py` file would be better. I wasn't sure about the `test_no_trailing_newline_in_attrs` test -- it's meant to test a template rather than Python code -- probably I could have clarified that. `strict=True` isn't needed since the newline isn't being tested.
```suggestion form.render(), '<div><label for="id_field">Field:</label>' '<input id="id_field" name="field" required type="checkbox"></div>', ```
What happened to `{'attrs': 'date'}`? On 1.10, the output is `'<input attrs="date" name="code_0" type="number" value="1" /><input attrs="date" name="code_1" type="text" value="2" />'`.
```suggestion return format_html('<a href="{}">{}</a>', url, remote_obj) ```
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
Use a single line throughout where possible.
Since dicts are ordered in Python 3.6+, the `list()` could be kept and the `sorted()`s removed, I think.
blank line not needed
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
This is the default charset in Django, I wouldn't call it unusual :)
A better way to do this is with `{self.name!r}`.
Typically repr outputs include quoting around strings. One of the original ideas behind repr was that you should be able to execute the result and get a valid Python object back. ```suggestion return f'{self.__class__.__qualname__}(name=“{self.name}”)' ```
To be more consistent with other `__repr__()` methods I would use: ```suggestion return '<%s name=%r>' % (self.__class__.__qualname__, self.name) ```
This leaves a "dummy" SQLite database on the filesystem after running the tests.
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
@lukaszb which contrib/admin file are you talking about? Notice [how contrib/admin/options.py](https://github.com/django/django/blob/master/django/contrib/admin/options.py#L1860) doesn't have the missing new line icon. Make sure not to add two newlines, just put your cursor right where the missing new line icon is and press ENTER once.
There should be 1 newline (the little icon that github displays shouldn't appear).
```suggestion caller = f'{obj.__module__}.{caller}' ```
`except Exception` unless we really have a good reason for a bare except.
I'm omit the intermediate extra variable in favor of: ``` getattr(logger, level)( message, *args, extra={...}, exc_info=exc_info, ) ```
Can you combine the model states to have 3 fields: `DateField`, `DateTimeField`, and `TimeField`.
This isn't a valid `CharField`. Could you please add a `max_length` attribute.
FWIW in #9383 this is handled by the `RenameField` operation -- no `AlterField` operation will be generated by the auto-detector just like none are generated on a model and `to` rename.
I'd drop it, and reintroduce the test later on in branches where we'll be able to backport #9383.
Please use the helper methods `self.assertOperationType()` et. al.
This change is backwards incompatible for someone having subclassed the widget and customized `none_value`. We might let `none_value` as is, and simply update `none_value` in `__init__` (I'm open to arguments...).
It might be better to say "or null" rather than "or None" since that's the value a user would enter if editing the raw JSON.
I don't know if changing the key is a good idea since would be backwards-incompatible.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
actually I think we should set these 3 values from `none_value` in an else after the new elif I suggested above and then remove them as class attributes. There's an issue if someone has subclassed the widget and set `none_value` -- that value would be ignored with this change.
`print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-'))`
IMO `else`is unnecessary i.e. ```python if '.' in opt_val: ... setattr(options, opt_name, os.path.normpath(opt_val)) ```
@hramezani I think you removed `setattr(options, opt_name, os.path.normpath(opt_val))` by mistake. My proposition was to remove only `else`, i.e. ```python if '.' in opt_val: print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-')) sys.exit(1) setattr(options, opt_name, os.path.normpath(opt_val)) ```
Please add trailing comma.
We should support `--shuffle` with `--bisect` and `--pair`, i.e. handle it in `get_subprocess_args()`.
this line is very hard to read maybe you should do something like this: ``` python builtins = 'builtins' if six.PY3 else '__builtin__' if module == builtins: ... ```
I meant `module == ('builtins' if six.PY3 else '__builtin__')`
I'm thinking about adding a hint to provide a `deconstruct` attribute function for `value`.
Could you use `"uuid.%s" % repr(self.value)` here instead, as in the other serializers? ``` - return "uuid.UUID('%s')" % self.value, {"import uuid"} + return "uuid.%s" % repr(self.value), {"import uuid"} ```
This is not performing any identity check so if a related module happens to have a class the same name (it's not that uncommon to have classes with the same name namespaced in different modules) then it would be considered to be the same class.
I'm not sure about using `globals()` :thinking: What do you think about moving `__dir__()` at the end of the file and using `dir()` instead of `globals()`: ```python # RemovedInDjango50Warning. _DIR = dir() def __dir__(): return sorted([*_DIR, "utc"]) ``` we would avoid adding `_DIR`, `__warningregistry__`, and `__dir__` to the `dir(timezone)`.
```suggestion RemovedInDjango50Warning, stacklevel=2, ```
Usually `__getattr__` is paired with `__dir__`, so that the lazy-loaded stuff is still exposed to `dir()`. My go-to implementation is: ```python def __dir__(): return sorted(list(globals()) + ["utc"]) ```
``` return datetime.datetime(1970, 1, 1, tzinfo=timezone.utc) ```
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
`CANONICAL_RANGE_BOUNDS` is unnecessary: ```suggestion def __init__(self, *args, default_bounds='[)', **kwargs): ```
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
I saw that you're now handling this at the database level. It makes more sense to me.
Either add `self` or make it `@staticmethod`
`clean` is not only for validation, but also for data modification in a form.
OK, it's necessary, see `migrations.test_commands.MigrateTests.test_showmigrations_no_migrations`.
Do we need to take into account `self.ignore_no_migrations`? I don't see any tests failures after removing this check. IMO it's unnecessary.
That's not true, `return` is to avoid setting new migrations.
I prefer the following one rather than the above one ```py def greet(): condition = False if condition: return "Hi" return "Hello" ``` Feel free whether follow the things I point out.
I thought you wanted to remove `return`. Nevertheless I'd also leave the `else` as it increases readability.
I wasn't expecting this additional check to be added in all these cases. In the default case, there's no change and it doesn't seem very DRY to require both.
Move `has_view_permission` above `has_add_permission` for consistency.
Again, it shouldn't be necessary to provide `None` here? (I realise that the existing version of this line did so.) Please fix all cases of this, but only for lines modified by this PR. Other cases can be dealt with by a separate PR some other time.
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
`if not ... and not ...` for consistency with other similar statements...
We don't use `self.value.value` anymore so we don't need to serialize it, we should use name instead, i.e. ```python v_string, v_imports = serializer_factory(self.value.name).serialize() imports = {'import %s' % module, *v_imports} return "%s.%s[%s]" % (module, enum_class.__name__, v_string), imports ```
Isn't this equivalent? ``` if (start and start < 0) and (end and end > 0): raise ... ```
We should **return** `NotImplemented` not raise a different exception, see 54ea290e5bbd19d87bd8dba807738eeeaf01a362 and ticket-30651.
This should return `NotImplemented` when a type of `other` doesn't match: ```suggestion if not isinstance(other, RegexObject): return NotImplemented return self.pattern == other.pattern and self.flags == other.flags ```
Can we make any positive assertion? I'm a bit nervous about a negative assertion like this since, for example, a typo in the regular expression could cause the test to pass by mistake.
We can add a control assertion to confirm that a `house` is cached for the `room`: ```suggestion self.assertIs(Room.house.is_cached(self.room), True) with self.assertNumQueries(0): ```
I think verifying the results wouldn't hurt, e.g. `self.assertSequenceEqual(groups2.filter(id__gte=0), [g])`
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
I think this test would be fine without the blank lines, it's fairly short.
single line looks okay here
@tchaumeny reverted fa534b9 here.
Since we don't use the results `.count()` is definitely more appropriate here.
An optimized `__bool__` definitely makes sense. On the other hand (as mentioned in the ticket), the queryset is (now, since 1.11) only shared per form instance, and not per form class. Given that, an alternative approach would be to remove the `.all()` in `__iter__`, and indeed reuse the queryset for the lifetime of the form-instance.
In which cases does `__len__` gets called by the form layer? I'm asking because if it's only to allow third party to do `if field.choices` we better be implementing an optimized `__bool__` as well because `.count()` can perform bad on large resultsets. ```python def __bool__(self): return self.field.empty_label is not None or self.queryset.exists() ```
Why the obscure `dict.fromkeys` with a list comprehension that could be just `list(queryset)`? IMHO the clearest code that wouldn't require a new method for clarification would be... ```python for obj in set(queryset): ... ``` If you feel the need to clarify why the `set` is used, maybe be more verbose in the unittest and/or commit message and squash the commits into one neat commit.
```suggestion f'{cls.__qualname__}() got both positional and keyword ' ```
I think it's enough to test `None` and `''`.
I don't think it's worth to add multiple fields. `IntegerField(null=True)` should be enough.
Sure, so two extra fields - one to handle `0` and `None`, the other to handle `False`.
This could become: `# IndexError error is used for historical reasons.`
I wonder why it works without `list()` on PostgreSQL :thinking:
I checked and on PostgreSQL we have a list of tuples for multiple rows and a tuple for a single row; on MariaDB we have a tuple of tuples for multiple rows and a tuple for a single row :confused: It's a really implicit logic, we should support both formats in: https://github.com/django/django/blob/8f2a6c76d19e4010c4683b20ed7f1eb4b07c17eb/django/db/models/query.py#L1257-L1260
returns->return (use PEP257 verb style for new docstrings)
`fetchall()` returns a list not a tuple on SQLite. ```suggestion statement into a table, return the list of returned data. ```
We can do much better here. We don't need to regenerate the `LIMIT 1` snippet for every table, as it never changes. The `AS has_rows` is unnecessary. ```suggestion limit = self.connection.ops.limit_offset_sql(0, 1) sql = ' UNION '.join([ "(SELECT '%s' FROM %s %s)" % (table, self.connection.ops.quote_name(table), limit) for table in tables ]) with self.connection.cursor() as cursor: cursor.execute(sql) return [row[0] for row in cursor.fetchall()] ``` I'm also wondering whether we should pass the table names string literals in the `SELECT` as params to avoid any sniff of SQL injection. I honestly don't know if there is a real risk here. The advantage of keeping it like this is that we don't need to batch for SQLite and the overridden version there can be removed.
@sdil Can you take a look? Thanks!
My pleasure :)
@sdil Thanks for checking :+1:
Are you sure? Should this not be consistent with `SHORT_DATETIME_FORMAT`, i.e. `SHORT_DATE_FORMAT = 'j N Y'`.
In fact, unless you have a special sequence like \n, \r, \t, the raw prefix is not strictly necessary. But for consistency, it's better to always add it to indicate that none of the escaped letters have to be interpreted as special-meaning sequences.
"Always return False if the field is disabled since self.bound_data always uses the initial value in that case."
Drop the blank line.
Drop the blank line.
How about: ``` return super(JSONField, self).has_changed(initial, data) or str(initial) != str(data) ``` I think there's no need to repeat the docstring from the superclass but explaining why the `str()` comparison is needed would be useful.
reuse initial here and don't call to_python twice
single line here is okay (lines up to 119 chars are fine when it improves readability)
There should never be a reason to encode ascii to something else. While technically valid it makes mails bigger (especially if at one point we decide to call sanitize address for all addresses)
Use single quotes consistently.
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
Could use single quotes for consistency.
The URL may be incorrectly encoded....
Using `str('name=Hello%20G%C3%BCnter')` would also work here but using `six.PY2` could be a nice reminder to remove the `b'...'` branch.
Chop blank lines.
@lothemar I realized that previous assertions were correct. The current tests work even without this patch. I will restore them, sorry.
I'm not sure why we pass `data` and build a query string in tests views :thinking: I would simplify this: ```python def test_follow_307_and_308_no_get_preserves_query_string(self): methods = ('post', 'head', 'options', 'put', 'patch', 'delete', 'trace') codes = (307, 308) for method, code in itertools.product(methods, codes): with self.subTest(method=method, code=code): req_method = getattr(self.client, method) response = req_method('/redirect_query_%s/' % code, follow=True) self.assertRedirects(response, '/post_view/?hello=world', status_code=code) ``` and in `views.py`: ```python def method_saving_307_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=307) def method_saving_308_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=308) ``` Maybe I'm missing sth.
Nit: `test_loader_patterns_not_mutated` (with an "s")
Since `verbosity=1` is the default, you can leave this out. (It's good to be testing the default behavior.)
I would do what the other tests do and pass `test_labels` as a positional argument. Also, to be clearer what `foo` and `bar` are doing, it might be better to call them something like `notfound1` and `notfound2`. I'm assuming it's finding two failed test instances for labels not found. Alternatively, you could find real tests by passing something starting with `'test_runner_apps...'`.
Please test the entire message.
Unnecessary trailing comma and white space.
The problem here is that you can't just use `Value('')` for the default. If you're doing `GREATEST(date_field, other_date_field)` then coalescing a date type with a char type is going to produce an error. The type itself will probably have to accept a default. ``` sentinel = object() def __init__(self, *expressions, **kwargs): ifnull = kwargs.pop('ifnull', sentinel) if ifnull == sentinel: raise ValueError('ifnull is required') if ifnull is None: # user has asked NOT to use coalesce else: self.ifnull = self._parse_expression(ifnull) ``` And then you would use `Coalesce(expression, self.ifnull)` in the coalesce method, or completely skip calling the coalesce method if `ifnull is None`. This is just one idea, but probably the best one I have right now. I don't really like forcing a user to provide an `ifnull` though, because it feels like we're disadvantaging the user. Another idea would be to use a backend feature. Something like `greatest_least_uses_nulls`, and then the tests could switch on that feature flag to provide different test results. I'd probably like to get a rough consensus on which way to go here.
This one as well.
This looks as though it works, but we can make it much more straightforward: ```python def as_postgresql(self, compiler, connection): # Cast FloatField to DecimalField as PostgreSQL doesn't support # MOD(double precision, double precision) by default. clone = self.copy() clone.set_source_expressions([ Cast(expression, DecimalField()) if isinstance(expression.output_field, FloatField) else expression for expression in clone.get_source_expressions() ]) return clone.as_sql(compiler, connection) ``` The other issue is that your implementation was basing the decision to cast on the `output_field` of this function and not the input source expressions which may be different.
This looks as though it works, but we can make it much more straightforward: ```python def as_postgresql(self, compiler, connection): # Cast FloatField to DecimalField as PostgreSQL doesn't support # LOG(double precision, double precision) by default. clone = self.copy() clone.set_source_expressions([ Cast(expression, DecimalField()) if isinstance(expression.output_field, FloatField) else expression for expression in clone.get_source_expressions() ]) return clone.as_sql(compiler, connection) ``` The other issue is that your implementation was basing the decision to cast on the `output_field` of this function and not the input source expressions which may be different.
This could be a bare `super()`.
I don't think we need parentheses and `Note:`. Also, there is no need to use `!`. Maybe: ```suggestion 'Ignore for now. Existing rows that contain NULL values ' 'will have to be handled manually, for example with a ' 'RunPython or RunSQL operation.', ``` ```
Period: ```suggestion "Quit and manually define a default value in models.py.", ```
I would revert this change, the previous version is clearer to me.
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to change a nullable field '{field_name}' " f"on {model_name} to non-nullable without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n" f"Please select a fix:" [ ... ```
Period ```suggestion 'Quit and manually define a default value in models.py.', ```
these aren't necessary, you can pass `StringIO`s for `stdout` and `stdin` to `call_command` instead. there are lots of examples in existing tests e.g. https://github.com/django/django/blob/master/tests/i18n/test_compilation.py#L41
Aha I found what you should be using for both: `django.utils.captured_stdin` and `django.utils.captured_stdout` 😉 You could also open a second PR removing the hack from `createsuperuser` and change its tests to use `captured_stdin` 👍 Presumably
no need for breaking this over multiple lines now
```suggestion def test_stdin_read_inline_function_call(self, select): ```
Oops, I misread the diff and see that you only modified the existing archives. Still an explanation of exactly what going on would be nice as it's not obvious to me.
Can you explain why it's okay to move `patch_vary_headers()`? (I know nothing about it and am just reading about it now.) Also, remove (I think) the failing test.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
GZipMiddleware doesn't modify a weak ETag.
```suggestion # Windows registry may not be configured with correct # mimetypes. ```
```suggestion self.assertEqual(value, b'text/plain') ```
Not sure that's needed (it's the implicit default) -- anyway, as noted above, it's never executed.
This is never executed.
This should be wrapped at 79 characters.
Slightly more concise? ``` options = {'cls': self.encoder} if self.encoder else {} return json.dumps(obj, **options) ```
Maybe: `if '\x00' in str(value):`
Add a trailing comma.
Add a trailing comma.
how about more simply: "with a through model." (add period)
include a space at the end of the string
Please add a trailing comma.
Please add a trailing comma: ```suggestion [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver'], ```
```suggestion @mock.patch('sys._xoptions', {'utf8': True, 'a': 'b'}) ```
```python msg = 'Script does-not-exist does not exist.' with self.assertRaisesMessage(RuntimeError, msg): ```
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
Maybe it would be nice to put the shared test logic into a helper method.
Was going to suggest the same, but see that @charettes got there first. > Yes, but IMHO it's worse for readability. Fair enough.
Return the readonly fields for a given AdminForm. (following verb style of PEP 0257) -- similar for other docstrings
Ok I didn't think this through, I assumed that one could add inlines with the add permission. Of course for the author. If you like I can also withdraw my PR to django's repo and do the PR to you branch, so you keep control on this (you did all the work, and you're obviously more experienced than me in this, I just thought you may have no more time to spend on this). Also, I'm willing to backport this patch to 1.9 (or 1.10, but can't wait for 1.11 to use it in my projects). I see you have a 1.9 backport branch too, we may want to share efforts on this. My backport branch isn't in production yet, but will probably be in the two or three weeks. It seems to work well for now.
```suggestion form.render(), '<div><label for="id_field">Field:</label>' '<input id="id_field" name="field" required type="checkbox"></div>', ```
I notice that there is a check here on `has_add_permission`. Should the `InlineAdminForm`s above this check for `has_change_permission`? Also I don't understand why we would only need to check for the add case and not the change case when adding view permissions...
Maybe: `return ("%" + str(arg)) % (str(value) if isinstance(value, tuple) else value)`
I was thinking all of this could be in a method like: ```python def validate_values_are_expressions(values, method_name): invalid_args = sorted(str(arg) for arg in values if not hasattr(arg, 'resolve_expression')]) if invalid_args: raise TypeError( 'Queryset.%s() received non-expression(s): %s.' % ( method_name, ', '.join(invalid_args), ) ) ```
Make `__str__` return `self.string_rep` and nuke `__unicode__`.
Maybe something like "call_command() received unrecognized option(s) for the <foo> command: .... " I think listing all the options in the message might not be a bad idea either if it doesn't look too cluttered.
I think that we only want to remove a single `'g'` from the end of the string and continue to allow things like `'gg'`, `'1gg'`, `'g2'`, and `'g3g'` to raise an error as they would have before. ```suggestion if arg.endswith('g'): arg = arg[:-1] force_grouping = True ```
`date=rfc850date` isn't needed in the `subTest()` -- since will appear if the assertion fails.
I would move mocking `datetime` to a decorator, after that we will be able to test different dates, e.g. ```python @mock.patch('django.utils.http.datetime.datetime') def test_parsing_rfc850(self, mocked_datetime): mocked_datetime.side_effect = lambda *args, **kw: datetime(*args, **kw) utcnow_first_fifty = datetime(2019, 11, 6, 8, 49, 37) utcnow_second_fifty = datetime(2051, 11, 6, 8, 49, 37) date = ( ('Tuesday, 31-Dec-69 08:49:37 GMT', datetime(2069, 12, 31, 8, 49, 37), utcnow_first_fifty), ('Monday, 10-Nov-70 18:49:37 GMT', datetime(1970, 11, 10, 18, 49, 37), utcnow_first_fifty), ('Wednesday, 31-Dec-71 18:49:37 GMT', datetime(1971, 12, 31, 18, 49, 37), utcnow_first_fifty), ('Thursday, 31-Dec-99 08:49:37 GMT', datetime(2099, 12, 31, 8, 49, 37), utcnow_second_fifty), ('Thursday, 10-Nov-50 18:49:37 GMT', datetime(2050, 11, 10, 18, 49, 37), utcnow_second_fifty), ('Sunday, 31-Dec-00 18:49:37 GMT', datetime(2000, 12, 31, 18, 49, 37), utcnow_second_fifty), ) for rfc850str, expected_date, utcnow in date: mocked_datetime.utcnow = mock.Mock(return_value=utcnow) with self.subTest(string=rfc850str): parsed = parse_http_date(rfc850str) self.assertEqual(datetime.utcfromtimestamp(parsed), expected_date) ```
I don't think the number of tests is an issue, but since the check depends on a variable, the test should also reflect this, or it'll break at some point.
I think this fails for some cases in the current year as well as for some in the future. ``` python def get_year(year, current_year): assert 0 <= year < 100 if year <= current_year + 50: year += 2000 else: year += 1900 return year assert get_year(19, current_year=2019) == 2019, "same year" assert get_year(20, current_year=2019) == 2020, "next year" assert get_year(18, current_year=2019) == 2018, "last year" assert get_year(40, current_year=2019) == 2040, "21y hence" assert get_year(80, current_year=2019) == 1980, "39y ago, not 61y hence" # fails! assert get_year(10, current_year=2019) == 2010, "9y ago, not 91y hence" assert get_year(69, current_year=2019) == 2069, "50y hence" assert get_year(80, current_year=2070) == 2080, "future 10y hence" assert get_year(60, current_year=2070) == 2060, "future 10y ago, not 90y hence" assert get_year(10, current_year=2070) == 2110, "future 40y hence" # fails! assert get_year(21, current_year=2070) == 2021, "future 49y ago, not 51y hence" assert get_year(20, current_year=2070) == 2120, "future 50y hence" # fails! ``` Can I suggest an alternative implementation? ``` python def get_year(short_year, current_year): assert 0 <= short_year < 100 current_short_year = current_year % 100 delta = short_year - current_short_year if delta < 0: delta += 100 # assume future if delta > 50: delta -= 100 # then shorten if too far in the future return current_year + delta ```
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
``` When the object has a ManyToManyField to Site, redirect to the current site only if it's attached to the object.
Wrap lines closer to 79 characters and use () when referring to a function. ``` # get_current_site() will lookup a Site object, so these must match the # domains in the MockSite model. ```
Is there a need to hardcode pks? This is generally to be avoided, I think.
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
I would use `%s` formatting consistently.
count(*) means it will count all records i.e each and every cell BUT count(1) means it will add one pseudo column with value 1 and returns count of all records is it correct? http://stackoverflow.com/a/280605
Oh, it turns out this wasn't what I thought at all; my bad (I've seen some place in SQL where you can use column numbers instead of column names; apparently, here, like in most of SQL, this is the constant 1, not the first column). I am torn between "remove objection to use `count(1)`" and "Now I object because of ambiguity" -- but frankly, I don't know where that place was, and it is possible the ambiguity is only in my head.
OK I figure out why it doesn't fail. `ErrorClassTest` must be the first one, because there is a single instance of `DebugSQLTextTestResult` so `debug_sql_stream` already exists if we run any test before it. Edits is progress ...
This patch fixes the issue for me, however new tests work even without it, so I don't think we need them. Unfortunately, it's more complicated then raising and error in the `setUpTestData()`.
Indents should be four spaces.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Indexes are not constraints, generally.
I briefly remember that there was an issue with wrong index names a while ago, that _somehow_ got in people's projects. I can't recall the details, but all migration operations should enforce a deterministic index name present. That is, `AddIndex` checking for `self.index.name` and `RemoveIndex` checking for `self.name`.
Although using only the name might cause usability issues in the case of an auto-generated name. The user will have to inspect the database or something in order to determine the index name if they're writing the migration by hand.
It's solving the issue about `DropIndex` taking a name mentioned above and should make a lot stuff easier to deal with (such as index renames) as indexes will be identifiable by a user defined string. Either all `Index` should have a user defined name like field or we should not try to mimic the `RemoveField` API and make `DropIndex` take an `Index` instead of a system generated name.
No need to assign this to `self`, since it's not used outside this one method.
Use [hanging indent](https://docs.djangoproject.com/en/3.2/internals/contributing/writing-code/coding-style/#python-style): ```suggestion request = self.request_factory.get( '/', {'name__in': ",".join(escape_comma(e.name) for e in employees)}, ) ``` (But less than 120 chars it can go on one line.)
This class is unnecessary.
This can be single-lined.
```suggestion self.asserCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
We could just use f-strings here: ```suggestion errno.EACCES: f"You don't have permission to access port {self.port}.", errno.EADDRINUSE: f"Port {self.port} is already in use.", errno.EADDRNOTAVAIL: f"IP address {self.addr!r} can't be assigned to.", ``` (I know this means generating three strings when we'll only show one, but it isn't really going to add any significant overhead.)
If we don't go with the above, this should at least use a dict literal: ```suggestion error_text = ERRORS[e.errno] % {'addr': self.addr, 'port': self.port} ```
You can safely join this an the next line. You have up to 119 chars per line. ;)
And there: ``` work_file = os.path.join(self.dirpath, '%s.c' % self.file) ```
You can safely join this an the next line. You have up to 119 chars per line. ;)
Keep the style the same here and below
This is only used once. Can we move it back to the `color` module? (That way `termcolors` is still only ever used by `color`)
Remove extra spaces around docstring.
I would also consider turning that into an instance method called something like `get_runner()` and starting each test method with `runner = self.get_runner()`. The reason is that instantiating a runner is "cheap." You also don't have to think / worry about whether the runner has state that you might unwittingly be carrying from one test to the other (e.g. attributes set when a method is executed).
remove "should", e.g. "debug() bubbles up exceptions before cleanup."
```suggestion self.assertEqual( columns['duration'][0], connection.features.introspected_field_types['DurationField'], ) ```
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Here we also should call `super` and not copy-paste code
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
This is inconsistent but I think the patch can land as is and the test be modified later on based on the direction of [#24082](https://code.djangoproject.com/ticket/24082).
`it's django-generated` --> `it's a Django-generated`
Things seem to be hung up on "Django-generated". I propose the following wording instead which seems clearer to me. I also note that "sufficiently" sneaked in there, but I'm not sure it really adds anything. Also note that the line wrapping should be maintained. ```suggestion "Your SECRET_KEY has less than %(min_length)s characters, less than " "%(min_unique_chars)s unique characters, or it is prefixed with " "'django-insecure-' indicating that it was generated automatically by " "Django. Please generate a long and random SECRET_KEY, otherwise many of " "Django's security-critical features will be vulnerable to attack." % { ``` (Note this suggestion may not apply cleanly in GitHub as I needed to include unchanged lines around the removed and added lines.)
```suggestion "Your SECRET_KEY has less than %(min_length)s characters, less than " ```
So, I've been hemming and hawing on whether to mention it, because it conceptually works when in the error message, but it still seems slightly _'off'_ to me that the warning would say `SECRET_KEY_FALLBACK` when the setting is `SECRET_KEY_FALLBACKS` (plural). I guess if we're not going to say _which_ one errored (which _we could_, using hints) I think it'd make more sense to say `One of your SECRET_KEY_FALLBACKS has less ...`
This will need to be tested.
Don't add a blank line.
Not a bad plan at all. I originally suggested `force_login` on the ticket to make it clear that it bypasses the authentication systems completely. Everything here is pretty clearly a testing utility mind.
It is more generic than shortcircuting the `is_active` flag, isn't it? It logs in the given user.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Why do you include a `username` key, some backends do not work with username/password pairs (e.g. client certificates).
I wouldn't edit this just to change the quote style.
I'd say something like: ``` # The default_alias property raises TypeError if .... or AttributeError if ... ``` I'm not sure what the second sentence means. It seems like you're saying `hasattr(arg, 'default_alias')` raises an exception if `'default_alias'` isn't a string.
This `if` can go outside the try/except.
From a quick check on SQLite, `AttributeError` can be removed here without any test failures. Might be missing test coverage.
It might help readability to pass `method_name='aggregate'` -- otherwise the meaning of that string isn't so clear without looking up the method's signature.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
OK, it was just a shot in the dark :dart:
I think these are too internal, I would rather check that `MultiValueDict` is pickleable: ```python pickle.loads(pickle.dumps(...)) ```
Use `hash()` instead of `__hash__()`, e.g. ```suggestion self.assertNotEqual(hash(exception_str), hash(exception_list)) ```
Please use hanging indent here and below in `assertEqual`: ``` data = [ {'0': 'a', '1': '42'}, ] ```
Collapse this decorator into a single line.
I think you could use `self.assertSequenceEqual` rather than this.
Please add a trailing comma.
Please use assertRaisesMessage to verify this is the ValueError we expect.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
A bit odd that this test has a doc string and the others don't.
Please add a trailing comma.
Actually, I think we can skip the router stuff and just use `django.db.connection`. These tests aren't run with custom routers so this'll always be run on the default database. (so we can move the skip condition to `test_long_column_name`).
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
Also, what if we have a huge number of very short 'name=value's? This will create a dictionary with lots of small strings -- again lots of memory.
What if the 'field_name' is huge? It seems to me that it still goes into memory.
This might either throw errors or block forever (dunno how field_stream is implemented) if field_stream is empty at this point. Not sure, but something to check!
An unhandled `SuspiciousOperation` will result in a `400 Bad Request` response which is ok since it is a client error. However, `413 Request Entity Too Large` would be the correct status code for this error.
This check seems to be done after the WHOLE field has been read into memory, am I right? The goal was to prevent this.
Adding `time_keeper` as the 3rd argument can cause issues for people that rely on the current signature and do not use keyword args.
It looks that you missed some of Carlton's edits, e.g. https://github.com/django/django/pull/13224#discussion_r468468374.
"Create" (use PEP257 verb-style for new code)
Unnecessary `()` wrapping I believe.
`no_faulthandler=False` -> `enable_faulthandler=True`
I'd put `for key, value in kwargs.items()` on the next line to decrease length a bit.
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
We should take keys into account (like in `__eq__()`), so maybe: ```suggestion if hasattr(self, 'error_dict'): return hash(tuple(sorted(make_hashable(self.error_dict)))) return hash(tuple(sorted(self))) ```
This is never executed.
You don't need to use `make_hashable()` for primitives: ```suggestion return hash((self.message, self.code, self.params)) ```
You can reuse `resolve_model_field_relations()`.
```suggestion self.resolve_model_field_relations(model_key, name, old_field) ```
You can have a flatter function (less nesting) by doing: ```python if not remote_field: continue ```
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
I feel like there should be some dependencies declared on the operation here - the one that comes to mind is that it should depend on creation of its model, and delete model should depend on it.
Ditto, I'm pretty sure this will always be `True`.
Can you use `['indexes']` here? If not, the list comprehensions in the next lines have a `not in None` and will fail.
I'd probably go with operators instead of functions: ``` python added = new_value - old_value removed = old_value - new_value ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
I think it should be quoted in all cases.
We can simplify this with changing a template: ```python sql = self.sql_alter_column_collate if new_field.db_collation else self.sql_alter_column_no_collate return sql % { 'column': self.quote_name(new_field.column), 'type': new_type, 'collation': self.quote_name(new_collation), }, [], } ```
You want to avoid altering `self` here as subsequent calls will reuse this attribute even if this branch's conditions don't match.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
Why we have here a `column` from the `old_field`? ```suggestion "column": self.quote_name(column), ```
This test would be better if we updated the whole model with the expression, like in the PR
checking the results of the query would be useful. ``` self.assertEqual( Pet.objects.prefetch_related('fleas_hosted').values_list('id', flat=True), [...], ) ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
``` python # but in UTC, the __date only matches one of them ```
I would assert that querysets return the expected tag. Also, temporary variables are unnecessary. For example: ```python tag = integration.tags.create() self.assertSequenceEqual(TTag.objects.filter(integration=integration), [tag]) self.assertSequenceEqual(TTag.objects.filter(integration__id=integration.id), [tag]) ```
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
I was asking as major databases support year extract functions, so year comparing can be done as consequent joining of a transform and standard comparison lookup. So, creating YearGt and etc lookups will become really unnecessary if year transform will just convert datetime to a year representation using EXCTRACT, YEAR or STRFTIME calls (depending on database).
The problem is that an expression like extract(year from datefield) = 2015, then the DB will not be able to use indexes on datefield. But if you instead have datefield >= '2015-01-01' and datefield < '2016-01-01', then the db can use indexes. This is the underlying reason why we have the special year lookups.
I don't think we want to subclass `base.Deserializer`. Instead, we can just do `self.object_list = object_list` and use that instead of `self.stream` below.
`else: assertFieldType('time_field', "models.DateTimeField()")`
There's a lot of repetitions of ``` python if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): ``` in this function now. Also, for Oracle, it doesn't check things it could check (e.g. that `ip_address_field` is a CharField). I think both issues could be addressed with a smarter field-type-asserter; perhaps this is out of scope for the PR, and should be done separately.
You don't have to initialize `out` twice. This line can be removed.
To have more balanced line length, I think I prefer: ``` python constraints = self.get_constraints(IntegerArrayModel._meta.db_table) self.assertEqual(constraints['integer_array_model_field_gin']['type'], 'gin') ```
What's the rationale for defaulting charset to 'us-ascii'? Given the way the default is calculated in cpython, it seems like this could result in a behavior change when we remove `SafeMIMEText.__init__()` when our workarounds are no longer needed.
That link appears to be Python 2.7, correct? Python 3.3+ looks to behave differently.
Do we need to check if `token` is an instance of `Mailbox`? I couldn't find an example that needs this check.
Maybe shorter `# The entire email address must be parsed.`.
> ... so I made it a required parameter. Sorry, I think we're not understanding each other. 🤔 * The `on_bind` parameter is defined as `on_bind=None`, so it's optional. * Exactly when `on_bind=None` that `server_bind` is only declared conditionally with lead to a `... is referenced before assignment` problem. If looks like this: ``` >>> on_bind = None >>> if on_bind is not None: ... a = "I won't be defined" ... >>> a Traceback (most recent call last): File "<stdin>", line 1, in <module> NameError: name 'a' is not defined ```
not sure if this really passes the django style guide, compared to plain if/else statements
For similarity with other messages (e.g. 'The nowait option cannot be used with skip_locked.') you might change 'passed' to 'used'.
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
I'll quickly check if an idea I'm having works here.
I think the test should be split into multiple test methods, one per thing-being-tested, as above
Wrap lines at 79: ``` "The value of 'list_filter[0]' refers to 'RandomClass', which " "does not refer to a Field.", ```
Please remove the leading blank line in all tests.
Please put the closing ) on the next line as in other tests.
No, not necessary.
You can reuse `CountryInlineAdmin` and `StateAdmin` instead of defining extra classes: ```suggestion ``` Add `get_formset_params()` to `StateAdmin`.
Use `hash()` instead of `__hash__()`, e.g. ```suggestion self.assertNotEqual(hash(exception_str), hash(exception_list)) ```
`Exception as e`
`.get(self.live_server_url + reverse('admin:admin_views_question_add'))`
No need for the `u` prefix, we're already importing `unicode_literals`.
We should take keys into account (like in `__eq__()`), so maybe: ```suggestion if hasattr(self, 'error_dict'): return hash(tuple(sorted(make_hashable(self.error_dict)))) return hash(tuple(sorted(self))) ```
```suggestion 1. (?P<a>\w+)/b/(?:\w+)c(?:\w+) => (?P<a>\\w+)/b/c ```
```suggestion def remove_non_capturing_groups(pattern): ```
Please use single quotes.
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
I think 1 needs to be '1'. Try it calling `manage.py createsuperuser`: ``` Username: 1 Error: email instance with pk '1' does not exist. ``` even though: ``` >>> Email.objects.values('pk') [{'pk': 1}] ```
this seems to hang on PostgreSQL/MySQL: Error: group instance with pk 1 does not exist.
Yea, it seems a bit unusual, but I don't have an alternative to suggest.
This works without the patch. Extra test coverage is welcome, but should be keep in a separate commit/PR.
Only `test_fields_with_m2m_by_env` fails on a fresh branch without any of your changes in `django/contrib/auth/management/commands/createsuperuser.py` and `tests/auth_tests/models/with_foreign_key.py`,
Right, sorry, forget about `encoding`, should be `gzip.open(str(password_list_path), mode='rt')` according to [the doc](https://docs.python.org/3.7/library/gzip.html#gzip.open). (Notice it's `rt`, not the usual `r`).
If anything is raised besides `OSError`, it will propagate, it won't continue to the `with` part. This is the same as the existing behavior.
From the stacktrace you pasted, it looks like the problem was that we assumed that it is `gzip.open()` that would throw `OSError` if the file is not a gzip, but in fact it only happens when the file is first read. So, it's not the `encoding` that's the problem (this should stay). So I think this is what we want - this time I did try it out :) ```python try: with gzip.open('test', mode='rt', encoding='utf-8') as f: self.passwords = {password.strip() for password in f} except OSError: with open('test') as f: self.passwords = {password.strip() for password in f} ```
I think `{line.decode().strip() for line in f}` reads a little better. Also for the one below. BTW, since Django no longer supports Python 2.7, you can remove the explicit `decode()` step by passing `encoding='utf-8'` to `gzip.open()`, then you'll get a text-mode file rather than a binary-mode one. Finally, if you want to keep the previous idea of not duplicating the set/strip logic, you can write it like this: ```python try: f = gzip.open(str(password_list_path), encoding='utf-8') except OSError: f = open(str(password_list_path)) with f: self.passwords = {line.strip() for line in f} ```
I think this change should be undone. Python 3 (normally) defaults to `utf-8`... and when it doesn't, this change introduces the chance of a regression. The default file isn't the only possible gzipped file.
Here's a regression test that passes on master but crashes with the new version (after the deprecation warning is silenced): ``` diff diff --git a/tests/model_fields/tests.py b/tests/model_fields/tests.py index 4677962..b2845ff 100644 --- a/tests/model_fields/tests.py +++ b/tests/model_fields/tests.py @@ -31,6 +31,11 @@ from .models import ( class BasicFieldTests(test.TestCase): + + def test_get_val_from_obj(self): + f = BooleanModel() + self.assertEqual(f._meta.get_field('string')._get_val_from_obj(None), 'abc') + def test_show_hidden_initial(self): """ Regression test for #12913. Make sure fields with choices respectdiff --git a/tests/model_fields/tests.py ```
If you can try to make logical commits with the tests passing after each one as in https://github.com/django/django/pull/3770, I've found that quite helpful as a reviewer.
If possible, it would be great to try to submit cleanups like this as separate pull requests that can be merged ahead of the main composite field work. Otherwise, I fear we will end up with a monolithic pull request that will be very difficult to review.
IMO we can simplify condition: ```not self.blank or (self.blank and not self.null)``` to: ```not (self.blank and self.null)```
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
Correctly indent the bracket to match the `return` indentation.
OK, good. Thanks. I think it's fine as it is. 👍
I might handle the `if not hasattr(self, 'lastmod')` as a guard first, to get it out of the way: ```suggestion def get_latest_lastmod(self): if not hasattr(self, 'lastmod'): return None if callable(self.lastmod): try: return max([self.lastmod(item) for item in self.items()]) except TypeError: return None else: return self.lastmod ```
```suggestion path( 'lastmod/get-latest-lastmod-none-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_none_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/get-latest-lastmod-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/latest-lastmod-timezone-sitemap.xml', views.index, {'sitemaps': latest_lastmod_timezone_sitemaps}, name='django.contrib.sitemaps.views.index', ), ```
```suggestion path( 'generic-lastmod/index.xml', views.index, {'sitemaps': generic_sitemaps_lastmod}, name='django.contrib.sitemaps.views.index', ), ```
I'd drop the intermediate variable
Unless I'm mistaken, there's no equivalent for this in your new `get_request` function.
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
`HTTPS` is not necessary, so I removed this line.
Please drop that new line
We need to use inline imports or move all Selenium imports to the `try ... except` block (another separate commit) because tests shouldn't crash without it.
Please change to inner imports.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
If we remove this will the tests run on Jenkins? It might be fine.
As long as you use `except Exception` and not a bare `except` this should be good.
```suggestion # LiveServerTestCase's change to ALLOWED_HOSTS should be reverted. ```
```suggestion cls.set_up_called = True ```
```suggestion with self.subTest(location), self.settings(CACHES=settings): ```
Will this statement will fit on a single line? (119 characters is permitted.)
Will this statement will fit on a single line? (119 characters is permitted.)
Same as above, I'd revert to the simpler version. The main idea behind `decode` for me is a consistent interface where it makes sense, we don't have to bend backwards just to use it.
For simplicity I think it would be better to revert this to the previous code, ie simply https://github.com/django/django/blob/69e0d9c553bb55dde8d7d1d479a78bfa7093f406/django/contrib/auth/hashers.py#L425-L427 -- I understand your motivation behind using `decode` here, but simplicity wins especially in security relevant code.
I'd call this `work_factor` as dictionary key and only in `safe_summary` it would be `work_factor`
Yes please, for further reusability of the `decode` function it makes sense to use `int` where the underlying data is actually an `int`. As for consistency that imo went away once we switched `iterations` to `int`. And I still think this switch makes sense since we do not have to call `int` all over the place where we use it. If you think of our endgoal (ie something like a `salt_len` as result of `decode`) so we can update `must_update` to account for the salt, it makes even more sense to have integers. Imo the key->value relation is well defined and with python being as dynamic as it is, let's make use of that.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
please use slightly longer lines such as here (move `EXTENDS_HISTORY_CONTEXT_KEY)` up) when it improves readability
I want to say this is okay, but it might introduce edge cases since `render_context.template` isn't set back to it's original value. I can't identify a specific issue, but it might be safer to mirror the behavior of `RenderContext.push_state`, minus the calls to `self.push()` and `self.pop()`: https://github.com/timgraham/django/blob/3c4944bec3935342871ced38242ae1492b5504d3/django/template/context.py#L206
This looks like a good candidate for `kwargs.setdefault('form', self.get_form())`
`ContextMixin` doesn't use it but is very explicit about what it's trying to achieve. I guess `SingleObjectMixin` could be updated (in another commit) to use `setdefault` and avoid an extraneous `dict` creation and update.
As `BaseFormSet` is inheriting from `Renderable` we can ditch this as the definition is the same: ```suggestion ``` You can also remove `.as_table()`, `.as_p()`, and `.as_ul()`.
Maybe we should move this directly to the `RelatedLookupMixin` :thinking:, I don't have a ready answer.
Please use at most one underscore, double underscores trigger name mangling which makes subclasses easier to use.
Yup, that sounds good too. :)
`later` is a bit misleading, since the expectation is that the dev will update models.py (immediately) after quitting so that they can continue to create their migrations.
I think this docstring should also explain the meaning of the three possible values of `include_parents`
You don't need this `pass` anymore.
I don't know if it's public API, but this is Django Models base metaclass, and there is no other way to do it then use it directly.
Can you use `ModelState.from_model()` here, please, as this is what the migration framework will use internally.
Correct, but if me change `ModelState` at some point, this will work automatically or fail, telling us we did something wrong ;)
"Create" with a capital c
without any arguments
I think we also need to exclude [conditional constraints](https://docs.djangoproject.com/en/3.0/ref/models/constraints/#condition) here.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
Do we need to call `list(fields)` here? :thinking:
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Add a trailing comma.
include a space at the end of the string
Add a trailing comma.
how about more simply: "with a through model." (add period)
Please add a trailing comma.
Let's call this `non_existent`, please.
Why the underscore? "[Nonexistent](http://www.thefreedictionary.com/nonexistent)" is a legitimate word according to the Collins English Dictionary.
You can probably use `assertSequenceEqual` here which might be a bit nicer.
Please use hanging indents here, too: ``` python self.assertEqual( list(...), [...], ) ```
chop blank lines here and below
Yes. Adding `?:` makes it a non-capturing group which allows for use of `m.groups()` below. Otherwise it'd need to be `... = m[1], m[2], m[4]`.
I'd rename `subminor` to `patch`.
You're right. You know I both saw that and missed it too...
TIL that character classes also work inside `[]` :D
I think we should be consistent and use double-quotes.
```suggestion poly = Polygon(((0, 0), (0, 1), (1, 1), (1, 0), (0, 0))) ```
Can we check that the constraint actually exists? ```python with connection.cursor() as cursor: constraints = connection.introspection.get_constraints( cursor, Neighborhood._meta.db_table, ) self.assertIn(constraint_name, constraints) ```
`list` is unneeded here. As an alternative you could use: ``` qs = State.objects.filter(pk=null.pk) self.assertFalse(qs.filter(poly__intersects=LineString((0, 0), (1, 1), (5, 5)))) ```
You don't need to specify `app_label`.
Which proves that it doesn't work properly because names of indexes should be `check_framework_model1_index` and `check_framework_model2_index`, currently it is `check_framework_abstractmodel_index` in both cases.
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
> Or should I just check that those settings doesn't exist outside the context? I think that'd work.
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
@slafs non-existing setting names, e.g. `TEST_SETTING=True`
Can you re-warp this block to 79 chars? (First line is too short.)
I don't see much value in this docstring.
I don't see much value in this docstring.
Why would you need to sanitize something that's already in your session? Seems a bit late...
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
Maybe change that into a `try/execpt AttributeError`. It's kinda nitpicky, but given that if you want to use session-based CSRF you will most likely have a session object on the request and then try/except would be faster (And even if not, it seems more natural and shows a nice chained error on python3).
maybe I'm being a stickler, but I'd make extra assertions on the log record's level and message
`ERROR` in `assertLogs()` is still missing: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ```
Yes, we should check if it's on `ERROR` level: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ... self.assertEqual(cm.records[0].getMessage(), ...) ``` and assert a message (`cm.records[0].getMessage()`) and an exception info (`cm.records[0].exc_info`).
why not use `a_signal` in this test? The signal objects seem to be identical.
If I were writing these tests from scratch, I wouldn't use a separate `expected` variable everywhere (this is related to our preference for longer lines rather than a historical more strict adherence to 79 chars, I think).
no dash in "email"
Valid point. Feel free to change the decorator in a separate commit.
Wrap at 79 chars, please.
Oh I missed that. Sorry!
Scanning a list will not be faster than a membership test of a set (unless the list of words is very small).
save is not needed : objects.create returns an already saved instance. Tests succeed without the save
This error message is confusing. A `Car` instance doesn't have a `car` field. Should it refer to the `make` field instead? The `CarDriver` through table has a `car` foreign key with `to_field='make'`.
Up to you, but I think the tests are short enough that the blank lines don't help much.
Why this error is raised? This should return an empty list without raising an exception.
`1` -> `chicago.pk`
I don't use login rate limiting myself at the moment, but I can see that people might want to use more sophisticated schemes (e.g. exponential delays). So I think it would be good to allow people to opt-out of this feature.
A form validation error seems sensible to me
```suggestion timeout=60, ``` "60" on its own looks a bit weird. Also, it surely doesn't need to be as long as 60 seconds if `DELAY_AFTER_FAILED_LOGIN` is so much smaller? What if `DELAY_AFTER_FAILED_LOGIN > 60`? Maybe this should be: ```suggestion timeout=self.DELAY_AFTER_FAILED_LOGIN + 10, ```
Please don't make unrelated whitespace changes.
@pahko `2` , `3` and non-empty lists and objects also will be valid case. Only check for boolean is needed here.
Wrap at 79 chars: ``` "'choices' must be an iterable containing (actual value, " "human readable name) tuples.", ```
remove trailing whitespace
Drop the comma/space in `[FakeFieldFile(), ]`
We cannot make serial pk assumption: ```diff diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py index 8b54611010..ea68a105d6 100644 --- a/tests/model_forms/tests.py +++ b/tests/model_forms/tests.py @@ -1765,10 +1765,12 @@ class ModelMultipleChoiceFieldTests(TestCase): f.clean([c6.id]) def test_model_multiple_choice_field_validate_choices_called_properly(self): + c1 = self.c1 + class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField, TestCase): def validate_choices(self, queryset, field_name, selected_choices): self.assertIsInstance(queryset, models.QuerySet) - self.assertQuerysetEqual(queryset.order_by('id'), [1], lambda a: a.id) + self.assertSequenceEqual(queryset, [c1]) self.assertIsInstance(field_name, str) self.assertEqual(field_name, 'pk') self.assertIsInstance(selected_choices, frozenset) ```
``` 'BinaryField default cannot be a string, use bytes content ' 'instead.' ```
`0` is unnecessary: ```suggestion return (10, 2) else: return (5, 7) ```
I think we can remove this docstring.
Could we possibly skip the detection feature `if Database.sqlite_version_info >= (3, 29, 0)`? Since this is only present on macOS [could we branch off `platform.platform`](https://docs.python.org/3/library/platform.html?highlight=darwin#platform.platform)? I think this would partially address @claudep's concerns.
We cannot return `True` if a backend doesn't support it at all.
This optimization is used only for backends with `allows_group_by_selected_pks` feature, we should use it here, e.g. ```python def allows_group_by_selected_pks_on_model(self, model): if self.allows_group_by_selected_pks: return model._meta.managed return False ```
`assertEqual` -> `assertTrue`
``` # Unmanaged related model that is a table. ```
Chop blank line.
``` # Unmanaged related model that is not a table. ```
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
I would rename it to `kwargs` ```suggestion kwargs = {} ```
Do we need to check a `current_mask`? This code is reachable only when `umask` is set. ```suggestion kwargs['umask'] = umask ```
This one could do with assigning to a variable: ```suggestion path = base_path / f self.assertTrue(path.exists()) with path.open() as fh: ```
would be fine to use double quotes so you don't have to escape the single
There's no need to define the extra `settings_dir` variable as `pathlib` gives us more flexibility: ```suggestion settings_file_path = self.test_dir / filename / "__init__.py" settings_file_path.parent.mkdir() ```
Why move this line? There's no behaviour change no? I think revert this please.
Possibly, but it makes the commit here less clear. Please do revert. (We could assess whether there's a readability improvement as a separate change, but it's probably not worth it for me.)
`repercent` is a confusing name, maybe `repercent_broken_unicode`? Also it needs a docstring with pointers to the RFC etc.
They can only be decoded if these bytes were previously encoded in this encoding.
You changed the first `_` to capture `field`, but it's not subsequently used.
You'd need to either include both `f.name` and `f.attname` or use `self.model._meta.get_field(name)` for each `defaults` which I think supports both form e.g. ```python get_field = self.model._meta.get_field update_defaults = True for default in defaults: try: field = get_field(default) except FieldError: break if not field.concrete: break else: update_defaults = False ```
> And yes it feels wasteful, but what are the options? I guess `Options` could have a private `cached_property(_concrete_field_names -> frozenset)`. It seems niche enough to be kept private but worth it given this set is computed on every `Model.save(update_fields)` call and on every `QuerySet.update_or_create` call after this PR.
I think this should include non-concrete local field as well since `select_for_update` will lock at tables involved in MTI and `Model.save` handles it just fine.
Perhaps the following to avoid constructing a new set unnecessarily: ```suggestion if fnames.issuperset(defaults): ```
Arf, this is also not optimal either. `pre_save` can have side-effects, like `django.db.models.fields.files.FileField.pre_save` does 😕 We probably don't want to trigger those here. I mean, serendipitously it would work for the `FileField` because even if the returned value is still the same (so we don't add the `field.name` to `updated_fields`), we actually triggered the side-effect committing the file 😂 However, that seems pretty brittle 😅 I'm not sure what the cleanest/Djangoest approach would be here 🤔 We could add an attribute on the Field class, like `Field.has_pre_save: bool`, but that creates a precedent and users/libs must update their code accordingly. But at least, we would know _for sure_ which fields need to be added and which don't. Any other suggestion is very welcome!
I think the test fails as it is as you're no longer passing `self.timeout` to `smtplib.SMTP_SSL`. I don't think Django should specify a default of 60. Instead it should be `None` and only passed to the SMTP connection if the user specifies it. Here's a quick sketch of what I have in mind (plus some cleanup): ``` python # If local_hostname is not specified, socket.getfqdn() gets used. # For performance, we use the cached FQDN for local_hostname. connection_class = smtplib.SMTP_SSL if self.use_ssl else smtplib.SMTP connection_params = { 'local_hostname': DNS_NAME.get_fqdn(), } if self.timeout is not None: connection_params['timeout'] = self.timeout self.connection = connection_class(self.host, self.port, **connection_params) # TLS/SSL are mutually exclusive, so only attempt TLS over # non-secure connections. if not self.use_ssl and self.use_tls: self.connection.ehlo() self.connection.starttls() self.connection.ehlo() ``` For the test you'd subclass `EmailBackend` and verify the connection has the timeout use specified.
You should set `self.timeout` to `timeout`, not 60.
Instead of putting timeout in the `__init__` method, make it a class attribute. Here's an example change where we use this same technique: 8b0014869f666b44cd20692e38073ec0a0a8cb08
I would stick with the one line if/else statements. The style guide says, "Don’t limit lines of code to 79 characters if it means the code looks significantly uglier or is harder to read."
Why do you accept argument here, if you don't pass them to super. Maybe you can just the the correct default for `local_hostname` here and pass the variable. ```suggestion def __init__(self, host='', port=0, local_hostname='[127.0.0.1], **kwargs): super()__init__(host=host, port=port, local_hostname=local_hostname, **kwargs) ```
Let's rename these test methods to be `test_html_autocomplete_attributes`.
You don't need to pass `None` (in all tests).
The signal approach would hopefully eliminate the need to call `reload()` manually.
I'm a bit worried about this `reload()` with overridden settings to trigger the `UserCreationForm` to be recreated with a custom model. It obviously works for this test case, but I think it will leave the customised `UserCreationForm` loaded at the end of the test, won't it? Doesn't this mean that we will potentially have dependencies between this test and other ones that also use the `UserCreationForm`? If so, I think we should find a way to do a `reload()` at the end of the test (in `tearDown()`?) after the settings have been put back to the default.
Use normal dictionary access instead of `.get()`. It is fine for us to blow up with a `KeyError` here and helps debugging because it is clearer whether the attribute is missing or the value is incorrect.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
You can pass `verbosity=0` instead to completely silence the command instead of creating an unused `StringIO` container.
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
Given these methods are all wrapped in `assertTrue` calls they should probably be converted to `assert_all_exists` and `assert_none_exists` that perform the assertion themselves. e.g. ```python def assert_all_exists(self, dir, langs): self.assertTrue(all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ))
```python mo_file_en.with_suffix('.po').touch() ```
Only this parameter is unnecessary, rest of them is necessary to hide std outputs.
`verbosity=0` is not necessary.
Please revert this change, `verbosity` is necessary.
We don't need to mock `django.db.migrations.questioner.sys.stdout` anymore.
`'bar'` is already in `out` from the first execution of `call_command()`. You should reinstantiate or use `out.truncate(0)` before the second call.
```suggestion class ScalarParent(models.Model): foo = 1 class ScalarOverride(ScalarParent): foo = models.IntegerField() self.assertEqual(type(ScalarOverride.foo), DeferredAttribute) ```
We cannot make serial pk assumption: ```diff diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py index 8b54611010..ea68a105d6 100644 --- a/tests/model_forms/tests.py +++ b/tests/model_forms/tests.py @@ -1765,10 +1765,12 @@ class ModelMultipleChoiceFieldTests(TestCase): f.clean([c6.id]) def test_model_multiple_choice_field_validate_choices_called_properly(self): + c1 = self.c1 + class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField, TestCase): def validate_choices(self, queryset, field_name, selected_choices): self.assertIsInstance(queryset, models.QuerySet) - self.assertQuerysetEqual(queryset.order_by('id'), [1], lambda a: a.id) + self.assertSequenceEqual(queryset, [c1]) self.assertIsInstance(field_name, str) self.assertEqual(field_name, 'pk') self.assertIsInstance(selected_choices, frozenset) ```
I think we can remove `('B', 'Base B')` and `('B', 'Child B')` because it tests the same case as `A`.
IMO using `subTest()` is not necessary here, e.g. ```python self.assertEqual(Child(foo='A').get_foo_display(), 'Child A') self.assertEqual(Child(foo='B').get_foo_display(), 'Child B') ``` is more readable.
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
`Company` doesn't have a default ordering so we need to use `assertCountEqual()` or add `.order_by(...)`.
```suggestion msg = 'Slice stop must be greater than slice start.' ```
Perhaps extend this for a wider range of field types, e.g. `BooleanField`, `IntegerField`, `FloatField`, etc.
I don't think it's necessary. In all cases we test the same (default) implementation. A single assertion should be enough, e.g. ```python def test_invalid_fields_in_slicing_f_expressions(self): msg = 'This field does not support slicing.' with self.assertRaisesMessage(NotSupportedError, msg): Company.objects.update(num_chairs=F('num_chairs')[:4]) ```
Include a trailing comma so that if more items are added later, so we don't need to modify this line again.
I think we should ignore inherited PKs and check them only in parents, see #13925.
I think we should catch `ImportError` and return appropriate message, e.g. ```python try: pk_class = import_string(pk_setting) except ImportError: msg = 'The module %r could not be imported.' if hasattr(self.app_config, 'default_auto_field' ): msg += 'Check your %s.default_auto_field attribute.' % self.app_config else: msg += 'Check your DEFAULT_AUTO_FIELD setting.' raise ImproperlyConfigured(msg % pk_setting) ``` We could also add a cached hook, `get_default_auto_field()`.
```suggestion pk_setting = getattr(self.app_config, 'default_auto_field', settings.DEFAULT_AUTO_FIELD) pk_class = import_string(pk_setting) if not issubclass(pk_class, AutoField): raise ValueError("Configured default auto field '%s' is not a subclass of AutoField." % pk_class) auto = pk_class(verbose_name='ID', primary_key=True, auto_created=True) ```
I believe this should included in the `_check_default_pk()` with a different check, e.g. `fields.E102`.
I'd use a classmethod to provide the default index type (I think that's cleaner than resetting the attribute in the initializer)
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
Perhaps the full list could be a class attribute so it doesn't have to be repeated several times.
I think this is fine, but if building paths with a larger number of components, it's probably better to use `.joinpath()` as it's more costly to call `.__truediv__()` many times than `.joinpath()` once. For example: ```suggestion else Path(conf.__file__).parent.joinpath("project_template", "manage.py-tpl") ```
There's no need to define the extra `settings_dir` variable as `pathlib` gives us more flexibility: ```suggestion settings_file_path = self.test_dir / filename / "__init__.py" settings_file_path.parent.mkdir() ```
Maybe this could be a module constant so as not to repeat it 3 times.
DatabaseError is raised if a ....
I added `supports_select_for_update_with_limit` because this will crash on Oracle.
Heh. This line was an `assertRaisesMessage` before, I recommended that it be changed to assertRaises to make the test less prone to break on trivial code changes. The message's content is essentially just "Not supported" anyway, so I think we should leave it this way.
Assuming you use `NotSupportedError`, I think checking for the exception class is enough and is more robust.
should lock -> locks
Following the existing docstring pattern of wording like "Hook for..." seems useful.
Maybe `By default, return the django.contrib.admin.utils.get_deleted_objects.` instead of `By default this just returns django.contrib.admin.utils.get_deleted_objects.`.
" allowed to be deleted permissions" seems like a typo.
This can be single lined.
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
The wording is a bit inconsistent with the one for check constraints, here there is some duplicate info between the warning and the hint, and it talks about "The constraint" without naming it. I would suggest: ``` checks.Warning( "%s does not support unique constraints with conditions." % connection.display_name, hint=( "A constraint won't be created. Silence this " "warning if you don't care about it." ```
The current form is consistent with messages in similar checks. Also, we use here `display_name`, e.g. `MySQL does not support indexes on expressions.` so I don't think that `Database` adds much value here.
Thanks. Good point.
I don't expect index names to change radically in the future, if at all, but even if it does, I think simplifying the test is worth the "risk" of having to update it in the future, which seems like no big deal.
I had a similar thought though I wasn't sure if the change would be an improvement or not. "pr" me think "pull request". I haven't reviewed this in detail yet.
Use `assertNotIn` instead.
Actually you should use `assertNotContains(response, '"/test_admin/admin/r/%s/1/"' % content_type_pk)` to also account for `byte` response content on py3.
```suggestion chapter = Chapter.objects.create(title='testchapter', book=book) ```
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
Minor spelling tweak - "must contain a", not "must contains a".
This and `test_fk_to_bigautofield` above are a funny pair of tests. (`assert did_not_blow_up`... :)
Prefer the context manager version: ``` self.assertRaises(Resolver404): resolve(url) ```
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
Extra wrapping and `str()` call are unnecessary: `… for city "%s".' % city`
Once (field_name, model_name) expand I doubt it'll fit in 80chars even above. Good catch on the quote inconsistency.
Also message above doesn't have quotes around the model name.
Maybe a little too familiar wording? Also a suggestion of what one may want to do would be helpful, for instance: `(e.g. deal with existing NULL using a separate RunSQL or RunPython operation)`.
"operation in the new migration file before the AlterField operation" (to give better guidance?) need newlines in the this message
Period ```suggestion 'Quit and manually define a default value in models.py.', ```
> Hmm, imho set serialization and key item assignment (as for dicts) have slightly different mechanics. Not sure, which one works better here. Doesnt key assignment have the risk of falling back to the hash(value) (identity) evaluation for complex types in cpython, that dont implement __eq__ properly (equality)? Both `set` and `set` rely on the same `__hash__` logic you are referring to so if you are worried about Python/SQL incoherence about using `Counter` you should be equally worried about using `set`. The problem is the same as ticket-25544 though (see 86eccdc8b67728d84440a46e5bf62c78f2eddf6d) it's possible that `model.pk` is not hashable and we must account for it one way or another.
What do you think about using `Counter()`? ```python counter = Counter(obj.pk for obj in objs) if counter.get(None): raise ValueError("All bulk_update() objects must have a primary key set.") if any(count > 1 for count in counter.values()): raise ValueError("...") ``` ... or to fail-fast, e.g. ```python pks = set() for obj in objs: if obj.pk is None: raise ValueError("All bulk_update() objects must have a primary key set.") if obj.pk in pks: raise ValueError(...) pks.add(obj.pk) ```
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Same as below, you should be able to call `self.using()` directly.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
"In Django 5.0" :+1:
```suggestion "behavior and silence this warning or default=Value([]) to retain " ```
Use consistent quotes. Also, maybe `previous` instead of `existing` :thinking: ```suggestion 'From Django 5.0, ArrayAgg() will return None instead of an empty ' 'list if there are no rows. Pass default=None to opt into the new ' 'behavior and silence this warning or default=Value([]) to keep the' 'previous behavior.' ```
I don't think we need underscore prefixes: - `_DeprecatedConvertValueMixin` -> `DeprecatedConvertValueMixin` - `_deprecation_value` -> `deprecation_value` - `_deprecation_message` -> `deprecation_msg`
This can be single-lined: ```suggestion warnings.warn(self._deprecation_message, category=RemovedInDjango50Warning) ```
It would be more readable to raise an error explicitly (like previously), e.g. ```python db_features = connections[self.db].features if ignore_conflicts and not db_features.supports_ignore_conflicts: raise NotSupportedError('This database backend does not support ignoring conflicts.') if update_conflicts: if not db_feature.supports_update_conflicts: raise NotSupportedError( 'This database backend does not support updating conflicts.' ) if unique_fields and not db_features.supports_update_conflicts_with_target: raise NotSupportedError( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ``` (I used new feature flags.)
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
And here. (Also no brackets no needed.)
A list comprehension is preferable here as `str.join()` converts to list internally anyway. ```suggestion ', '.join([ f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields) ]), ```
Spaces around `=` and PostgreSQL docs have `EXCLUDED`. ```suggestion ', '.join(f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields or ())), ```
I fixed this issue in fe0ddbc84e4d8836ce8d27a1218d360c5482c2be.
`Exception as e`
Is this possible? If so, it will be good to cover this scenario with tests.
Same as above; let's leave it alone for now.
Yeah, and here you could again use the hypothetical `self.inner_exception_handler` context manager. Damn, it'll be nice to clean all this up once old-style middleware is gone!
We use hanging indent and try to avoid non-multiple of 4 space indent, something like: ``` warnings.warn( "Access to manager '%s' defined on non-abstract base " "class '%s' from child class '%s' is deprecated." % (self.manager.name, self.model.__name__, cls.__name__), .... ) ``` Add something like: "Add the manager to the child class to silence this warning."
You can't assume the presence of `self.name` here
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
I would deindent these ] and also include a trailing comma in case more items are added later
missing some trailing commas
I thought about it, but it has some value to test this explicitly.
I'm not even sure we really need the extension to be created in this test, checking the SQL command correctness might be sufficient.
Exactly, it's not **related**. That's why we should fix it separately in advance.
preferred format is "#15346, #15573 - Issue description"
argument ordering should be reversed
I'd move it below the `__init__()`.
Also rephrase to a single sentence to avoid mentioning `QuerySet` twice.
`QuerySet` instead of `queryset` for all instances of it in this exception message.
As `BaseFormSet` is inheriting from `Renderable` we can ditch this as the definition is the same: ```suggestion ``` You can also remove `.as_table()`, `.as_p()`, and `.as_ul()`.
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
I'd chop this blank line since the } on its own line is providing whitespace.
param -> params
You could show a message like `"Preserving test database for alias '%s'"` here.
You should try to reuse `connection._connect_string()`.
In the current state, it's not reusable for other lists of expressions, so I would rename it to the `IndexExpressions`
That looks awesome @hannseman 💯 🏅 Regarding `django.contrib.postgres.indexes.OpClass` I guess we could add a `IndexedExpressionWrapper.register_wrapper` and have `django.contrib.postgres.apps.PostgresApp.ready` register `OpClass` to avoid coupling there.
I think that most of the expression special casing and resolving should be done at the `Index.create_sql` level. The only purpose of `ddl_references` is to hold references to identifiers and allow renaming if necessary, it shouldn't have any knowledge about `django.db.models` abstractions.
This seems out of place. Is this branch really specific to MySQL? Is there a way we could avoid the `Col` import in the first place.
I don't think we need the extra assignment here as this is only used once.
Fine by me. I think we could probably omit the keywords in a lot of places and include them only where it's potentially confusing, but probably that's already what you're doing.
In general, I think the `get` / `set` style APIs are familiar enough that we don't need to use keyword arguments with every call. But I don't feel strongly about it.
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
I'd be great if we could avoid calling `get_ancestor_link` if `not has_value` given it will be unused anyway.
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
I wonder if we could support running `runtests.py` from different directories :thinking: like we do for dotted module names, e.g. ```bash ~/repo/django> ./tests/runtests.py backends.postgresql ``` works fine, but ```bash ~/repo/django> ./tests/runtests.py backends/postgresql/ .... File "./tests/runtests.py", line 155, in get_label_module rel_path = path.relative_to(RUNTESTS_DIR) File "/usr/lib/python3.8/pathlib.py", line 904, in relative_to raise ValueError("{!r} does not start with {!r}" ValueError: '/repo/django/backends/postgresql' does not start with '/repo/django/tests' ``` crashes. I tried to fix this with: ```python # Otherwise, interpret the label as a path. if not path.is_absolute(): return path.parts[0] else: path = path.absolute() rel_path = path.relative_to(RUNTESTS_DIR) return rel_path.parts[0] ``` but it crashes with `ModuleNotFoundError` (like without this patch): ``` ====================================================================== ERROR: backends/postgresql (unittest.loader._FailedTest) ---------------------------------------------------------------------- ImportError: Failed to import test module: backends/postgresql Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 154, in loadTestsFromName module = __import__(module_name) ModuleNotFoundError: No module named 'backends/postgresql' ```
Yeah it works for me, sorry again. The current version looks good :+1: , we could only raise a more descriptive error when a relative path is not correct (as proposed in https://github.com/django/django/pull/14507#discussion_r648186310).
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
As the code itself hints, there's no reason to assume the imported attribute is a class.
Yeah, the import itself is very likely non-necessary, too.
no need to specify `obj=None` I believe.
Don't really need this function I think. It's easy enough to decorator other functions if they're added (as in django/core/checks/security.py)
"The SESSION_COOKIE_NAME and LANGUAGE_COOKIE_NAME settings must be different." (don't think the hint is needed as it's just repetitive)
There is no need to `append()` because we have a single error: ```suggestion return [ ```
```suggestion 'SITE_ID must be an integer', ```
And I would rename this attribute `superusers` as it's meant to contain multiple users.
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
use `reverse()` rather than a hard coded URL.
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
check that -> and that (no comma needed since the two clauses are independent)
I remember looking at this test when merging 233c70f0479beb3bff9027e6cff680882978fd4d. I just tested this now and if you use `with register_lookup(field, Exactly, lookup_name='exact'):`, then this is the state at the end of the test: ``` >>> Author._meta.get_field('birthdate').get_lookup('exact') <class 'custom_lookups.tests.Exactly'> ``` With the current code, the output is `<class 'django.db.models.lookups.Exact'>` which looks correct to me. So I'd leave this as is and remove the unused `CustomExactLookup`.
Hmm it's not clear to me what this test is trying to accomplish, what's the purpose of `CustomExactLookup` in the first place since it's `Exactly` that is registered.
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
I'd omit the blank line since it's hard to get confused in 3 lines of code. Also the commit message could describe the issue being fixed instead of the implementation of the fix.
Unnecessary `()` wrapping I believe.
This change isn't needed and adds a bit of noise.
avoid _we_ usage as well ``` SystemCheckError is surfaced when run_checks raises SystemCheckError and teardown databases raises ValueError
These lines should be removed; it's possible for `databases` to be an empty list during tests and when no `--database` is passed to `manage.py` check as you've mentioned. When this happens this check should be entirely skipped.
Missing `cls.cls_atomics` argument.
FWIW +1 to doing it as a separate clean up. IMO it'll be much clearer what change was where looking back that way.
This pattern is common to all backends. Maybe it makes sense to merge them together? If there is reason to call `make_key()` without validation it could learn `validate=False()`. Either way, it's a separate PR.
> This pattern is common to all backends. Note that the `filebased` backend doesn't follow this pattern. It puts the `make_key()` / `validate_key()` lines in a single place: https://github.com/django/django/blob/3445c50a3affc5ae7b1c2712a139d4a5105aeaf5/django/core/cache/backends/filebased.py#L130-L131
See #14802 and ticket-33060.
I wouldn't say it's a separate PR since this is new code being added for the first time, and one can evaluate what is being added on its own merits. The method I'm proposing would be specific to this class, so it wouldn't affect other backends.
The thing is that even if the ORM doesn't have support for it yet using `distinct()` to implement `(UNION|INTERSECT) ALL` might prevent us from adding proper support in the future. What I suggest doing here is setting `query.combinator.all = kwargs['all']` and preventing using `distinct()` on `CombinedQuerySet`. The difference between ordering and combination operation is that the former operates on the _combined_ set of rows while the latter operates on how these rows are combined. I would suggest that options related to combination be passed as `kwargs` (such as `all`) and actions operating of the combined result (`CombinedQuerySet` instances) be added as methods (`order_by`, _slicing_).
Why are you copying the `QuerySet`s? Shouldn't be necessary as all their attributes are immutable except outside of other operations, and the result cache doesn't seem to affect their use in the combined qs.
It's a bit :scream: to me. `filter()` doesn't change anything for combined queries so I think we should handle this in `get()`, e.g. ```python def get(self, *args, **kwargs): clone = self._chain() if self.query.combinator else self.filter(*args, **kwargs) ```
I'll quickly check if an idea I'm having works here.
Yeah that's what I suspected too. Stupid SQL.
Same as above, (simply `postgis`)
I'm in the habit of including an trailing , for all QuerySet filter kwargs.
Note that I didn't plea for keeping the functionality. I just said that if we remove that, it should be done properly (backwards incompatibility note, separate commit).
@sir-sigurd I've already merged this patch, but we can relax this in future optimizations.
Is that removal related to 5f7035cec7d5? If yes, we might commit it separately with an appropriate message.
Despite the existing style of the first test, I would remove the intermediate `f` variable in the new tests as it'll help balance line lengths and make things more readable.
+1, this test was also removed in my force_text audit WIP branch.
please multiline the string ``` '<select id="id_f" name="f" disabled><option value="J">John</option>' '<option value="P">Paul</option></select>') ```
`# Values provided in the form's data are ignored.` Might be good to have a test for `Form(data, initial=...)` too.
```suggestion form.render(), '<div><fieldset><legend>Field:</legend><div id="id_field">' '<div><label for="id_field_0"><input type="checkbox" ' 'name="field" value="J" id="id_field_0"> John</label></div>' '<div><label for="id_field_1"><input type="checkbox" ' 'name="field" value="P" id="id_field_1">Paul</label></div>' '<div><label for="id_field_2"><input type="checkbox" ' 'name="field" value="G" id="id_field_2"> George</label></div>' '<div><label for="id_field_3"><input type="checkbox" ' 'name="field" value="R" id="id_field_3">' "Ringo</label></div></div></fieldset></div>", ```
Missing a test that fails if `(?i)` is removed. Actually as little as `r'^[a-z]+:'` will allow the tests to pass.
``` When the object has a ManyToManyField to Site, redirect to the current site only if it's attached to the object.
Just to make sure, did you account that `STATIC_URL` can be a fully qualified URL? (e.g. http://domain/path).
Is there a need to hardcode pks? This is generally to be avoided, I think.
Wrap lines closer to 79 characters and use () when referring to a function. ``` # get_current_site() will lookup a Site object, so these must match the # domains in the MockSite model. ```
Rather than `get_num_test_processes()`, I wonder if something like `get_max_test_processes()` might be a better name. This is because the number of test processes can wind up being smaller, e.g. if there are fewer `TestCase` classes. (You also assign to `max_parallel` elsewhere, so there is an awareness of this meaning / caveat.)
Is it too late to move the conversion of `auto` to an integer to a post-processing step (e.g. your `get_num_test_processes()` function)? I feel like the `parallel_type` function's job here should only be to check that the value equals `auto` if the value is a string, but not to apply the environment-dependent business logic to convert `auto` to a number. (I also see that `get_num_test_processes()` is already calling `multiprocessing.cpu_count()`, so there may be some duplication of logic with the way things are currently structured.)
We shouldn't silently change passed parameters. IMO it better to raise an exception like we do now: ``` $ export DJANGO_SETTINGS_MODULE=test_oracle $ ./runtests.py queries --parallel=2 Testing against Django installed in '/django/django' with up to 2 processes Found 416 test(s). Creating test database for alias 'default'... Creating test user... Cloning test database for alias 'default'... Traceback (most recent call last): File "./runtests.py", line 659, in <module> failures = django_tests( File "./runtests.py", line 385, in django_tests failures = test_runner.run_tests(test_labels) File "/django/django/test/runner.py", line 881, in run_tests old_config = self.setup_databases( File "/django/django/test/runner.py", line 787, in setup_databases return _setup_databases( File "/django/django/test/utils.py", line 217, in setup_databases connection.creation.clone_test_db( File "/django/django/db/backends/base/creation.py", line 239, in clone_test_db self._clone_test_db(suffix, verbosity, keepdb) File "/django/django/db/backends/base/creation.py", line 255, in _clone_test_db raise NotImplementedError( NotImplementedError: The database backend doesn't support cloning databases. Disable the option to run tests in parallel processes. ```
Historic moment! I don't see a reason why we shouldn't use them.
I think that you could move the slicing inside `DebugLexer._tag_re_split()` and then `DebugLexer.tokenize()` will be even closer to `Lexer.tokenize()`: ```suggestion for bit, position in self._tag_re_split(): ``` Maybe with these changes it makes sense to rename `DebugLexer._tag_re_split()` to something like `.split()` and add the same method to `Lexer` with something like: ```python def split(): yield from ((bit, None) for bit in tag_re.split(self.template_string)) ``` Then you should be able to ditch `DebugLexer.tokenize()` entirely and inherit it.
Use `self.assertIs(cache.touch('something'), True)` since `assertTrue()` passes if `bool(value) is True`.
I'm not convinced this deserves a separate test. Consolidating the `test_forever_timeout` test might be enough.
When fixing the implementation of `RedisCacheClient.get()` to support `default`, this should work fine. ```suggestion ```
Use `assertIs(touched, False)` since `assertFalse` passes even if `bool(touched)` is `False`.
This can be condensed into a single line.
Same as above; let's leave it alone for now.
Yeah, and here you could again use the hypothetical `self.inner_exception_handler` context manager. Damn, it'll be nice to clean all this up once old-style middleware is gone!
Is this possible? If so, it will be good to cover this scenario with tests.
This refactoring of this logic out into out into `check_none_response` is a nice bonus cleanup!
I moved `check_none_response()` to a separate PR #12474 and renamed it to the `check_response()`. I'm going to rebase this patch after merging.
Please don't change all the other unaffected lines.
any reason for passing args as kwargs? e.g. `subject_template_name=subject_template_name`
can include more than one parameter on each line as noted above
I see, thanks for your answer. I really don't want to hold the template based widget stuff from landing any longer. I suppose this is something we could refactor later on.
explain why it needs to be copied
Maybe you've missed `if summarize` branch (below).
We used the same message as in other places that's why I don't want to add a period only in this case.
Add a period to the end of the exception message.
is it possible to make the try/except block a bit smaller? try/except/else maybe? That will help to show where the error is expected.
You can drop the `.contains_column_references` as it's wasteful in this case because of the way it walks the expression tree given we'll have to walk it anyway below.
e.g. I think this should either be a warning or an error.
Yes, that's better.
I think it's fine to make them a bit inconsistent (at least for now). I opened an [issue](https://bugs.python.org/issue40300) in Python.
I wonder if we can just set `default_time_format` attribute.
prefer `request_hander = NoColorWSGIRequestHandler if no_color else WSGIRequestHandler` rather than duplicating more than what's necessary
IMO we can remove this line.
Ahh ok nevermind :smile: I misunderstood. It will work for primary keys that are not auto fields on MySQL :+1:
The `Order` model should do https://github.com/django/django/blob/594cf9bff82e4d840862c2526c29d725d5bf07f0/tests/queries/models.py#L592-L599
You can skip this test on MySQL with `@skipUnlessDBFeature('allows_auto_pk_0')`.
Maybe just :thinking: : ```python falsy_pk = 0 if connection.features.allows_auto_pk_0 else '' ```
I find `assertEqual` preferable since `asserTrue` checks `bool(expr) is True` which could pass for a result we don't want here. Well, I guess what we actually want is `assertIs(expr, True)` as described in the Python docs.
``` py self.assertFalse(r.closed) ```
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
This should use longer lines (up to 119 characters) or hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Please use a hanging indentation: ``` python self.assertEqual( set(...), {...}, ) ```
@MarkusH I don't have a strong opinion on this, but I wouldn't classify this change as a backwards-incompatible, I guess. @rebkwok Maybe we can keep previous indentation i.e.: ``` python deletable_objects, model_count, perms_needed, protected = modeladmin.get_deleted_objects( queryset, opts, request, using) ```
I think that you can remove brackets `deleted_objects, model_count, perms_needed, protected = ...`
This test belongs with the tests for the delete action in `tests/admin_views/test_actions.py`.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Do we need the `tzinfo` bit for the test? I'm worried relying on `get_current_timezone` could make the test flaky.
IMO, this is not related with `index_xinfo` but with naive parsing in introspection on SQLite. I added `_get_index_columns_orders` to fix this issue.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
`UniqueConstraint` not `Index`.
Shouldn't this be along the lines of ```python def iterator(self, chunked_fetch=None): if chunked_fetch is None: chunked_fetch = connections[self.db].settings_dict.get('ENABLE_SERVER_SIDE_CURSORS', True) return iter(self._iterable_class(self, chunked_fetch=chunked_fetch)) ```
Citing @holvianssi on Trac. > The complex solution is to add both the opt-in flag and database settings. The default for the opt-in flag is None, meaning use the default from database settings. True forces this feature on, and False forces the feature off.
We'll want to do something with regards to the newly added support for `iterator`'s `prefetch_related` here.
```python async with contextlib.aclosing(aiter(self._iterable_class(...))) as agen: async for item in agen: yield item ``` You should explicitly aclose your async generators when you create them: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators
> We'll want to do something with regards to the newly added support for iterator's prefetch_related here. That looks like a _moderate_ task in itself (to implement) — `islice`, `prefetch_related_objects`, ... — it might be that adjusting the PR here match the new interface, but emitting a warning if prefetches are set would let us get this in, to work on async prefetches later. (Would be equivalent to the sync behaviour before edbf930287cb72e9afab1f7208c24b1146b0c4ec — of _either prefetch or iterator_.) 🤔
This is unlikely to be enough as JSON can have an array or string as it's top-level data type.
The docs say, "For performance reasons, `from_db_value` is not implemented as a no-op on fields which do not require it (all Django fields)."
I'm not a fan of aliasing builtin names.
```python kwargs = {'reuse': can_reuse, 'allow_joins': allow_joins} if isinstance(value, F): kwargs['simple_col'] = simple_col value = value.resolve_expression(self, **kwargs) ```
I meant changing the signature of `apply_converters()` to: ``` @staticmethod def apply_converters(self, connection, rows, converters): ``` I guess that change doesn't make much sense given `apply_converters()` is called in some other places.
That shouldn't be an issue (see a workaround for `|`).
Ahh right :disappointed: I'm fine with raising exception on Oracle: ```python raise NotSupportedError('Bit-wise xor is not supported in Oracle.') ```
I think that I found complex solution for all binary operators in `MySQL` that return an unsigned 64-bit integer. We can simple convert return value to `SIGNED` integer. I don't know why, but it doesn't work for right shift operator. ```diff --- a/django/db/backends/mysql/operations.py +++ b/django/db/backends/mysql/operations.py @@ -202,8 +202,14 @@ class DatabaseOperations(BaseDatabaseOperations): + lhs, rhs = sub_expressions if connector == '^': return 'POW(%s)' % ','.join(sub_expressions) + # MySQL's binary operators return an unsigned 64-bit integer. + elif connector in ['<<', '|', '&']: + return 'CONVERT(%s, SIGNED)' % connector.join(sub_expressions) + elif connector == '>>': + return 'FLOOR(%(lhs)s / POW(2, %(rhs)s))' % {'lhs': lhs, 'rhs': rhs} return super(DatabaseOperations, self).combine_expression(connector, sub_expressions) ```
You're right. I prepared separate PR #7787.
Trailing space in string not required.
I think that we can squash this to two cases, i.e.: ```python if not self and other: return copy.deepcopy(other) elif not other: return copy.deepcopy(self) ```
I don't think we want to special case `Subquery`, feels like we'll want to duck type on `conditional` ```suggestion if not isinstance(other, Q) and not getattr(other, 'conditional', False) is True: ```
Again, this might as well be `obj = self.__class__(_connector=conn)`.
That won't work, `_combine` must return a _new_ object. I suggest we adapt the code to catch `TypeError` on `deepcopy` and use the old code path on failure.
Should be ``self.weight``
Chop blank line.
@timgraham wilco. As new contributors, it's difficult to know which direction so I appreciate the explanation.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python error = PermissionError(errno.EPERM, 'message') with mock.patch('django.core.files.move.copystat', side_effect=error): ```
Chop blank line.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python with mock.patch('django.core.files.move.os.rename', side_effect=OSError()): ```
```suggestion # Normalize an exception raised by the underlying client library to # ValueError in the event of a nonexistent key when calling incr(). ```
There is a minor behaviour change here. Previously calling `decr()` with `delta=0` would call `self._cache.decr()`, but now it'll call `self._cache.incr()` instead. In theory this shouldn't be a problem, but am highlighting it.
```suggestion # python-memcached ≥ 1.45 returns None for a nonexistent key in # incr()/decr(), python-memcached < 1.45 raises ValueError. ```
Remove blank line (and below).
Remove blank line (and below).
This has been mentioned previously, we can't do it because updating the set in place would update the inherited tags as well. e.g. ```python @tag('foo') class Foo: pass @tag('bar') class Bar(Foo) pass ``` Using `update` would add `'bar'` to `Foo.tags`.
Please test the entire message.
Omit the outer `[]` to use a generator instead of list comprehension.
This can be single-lined: ```suggestion return (matched_tags or not tags) and not test_tags.intersection(exclude_tags) ```
I moved this test to the `tests/messages_tests/tests.py`.
Could you also update `logger.warning` to `logger.debug`. You may want to wait for confirmation from a core developer before change it. Thanks!
``` py template_name = getattr(context, "template_name", "unknown") ```
Adding something like this before the loop could help: ``` _bit_undefined() = object() [at module level] bit = _bit_undefined() ```
I'm not sure if the included traceback will give enough information to debug this, but it seems like a message something like "Rendering `<template name>` raised an exception, so {% include %} will render as an empty string." might be more helpful.
You can simplify this with `assertLogs()`: ```suggestion url = reverse('test_with_sidebar:auth_user_changelist') with self.assertRaisesMessage(AssertionError, 'no logs'): with self.assertLogs('django.template', 'DEBUG'): self.client.get(url) ```
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
As noted elsewhere, put the trailing space on this line rather than the next (and in the message below).
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
Please check test coverage carefully. I didn't spot a test for this change.
We can remove quotes around the `default`. Please also wrap at 79 chars.
Chop blank line.
```suggestion class ModelFieldsCacheTest(TestCase): def test_fields_cache_reset_on_copy(self): department1 = Department.objects.create(id=1, name='department1') department2 = Department.objects.create(id=2, name='department2') worker1 = Worker.objects.create(name='worker', department=department1) worker2 = copy.copy(worker1) self.assertEqual(worker2.department, department1) # Changing related fields doesn't mutate the base object. worker2.department = department2 self.assertEqual(worker2.department, department2) self.assertEqual(worker1.department, department1) ```
This assertion is not necessary.
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
@timgraham It might be more appropriate in another commit then. I believe I wanted to make sure nothing was logged if a m2m backed inline was submitted without changes.
Do we have any plan on how & when to upgrade those as time passes by? (ie like we have for pbkdf2)
I'm not sure, I don't think there is a need to do this per release. :thinking: `work_factor` must be a power of two and the OpenSSL limits memory usage to 32 MiB, so we would have to increase `maxmem` as well: :teacher: ``` (2 ** 15) * (2 * 8) * 64 = 33554432 = 32 MiB ```
Thanks! I see that you included `maxmem` in a string returned by `encode`. Is there any reason it should be there? `maxmem` should not affect a hash
@kerkeslager `hashlib.scrypt` is a low-level function that takes multiple arguments. `maxmem` is one of them, it has a default value that does not suit all cases. Therefore, Django should allow changing the value. @ryowright has already made the necessary change. Note, `maxmem` does not affect generated hashes, its value should not be included in a string saved to a database and should not be compared in `must_update`.
Is it possible for these asserts (and below) to fail without a bug in Django? If so, proper exceptions should be raised a la: https://code.djangoproject.com/ticket/32508
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
If I were writing these tests from scratch, I wouldn't use a separate `expected` variable everywhere (this is related to our preference for longer lines rather than a historical more strict adherence to 79 chars, I think).
I think it's enough to check `stderr`, e.g. ```python with self.assertRaises(SystemExit), captured_stderr() as stderr: self.get_parser().parse_args(['--parallel', 'unaccepted']) msg = "argument --parallel: 'unaccepted' is not an integer or the string 'auto" self.assertIn(msg, stderr.getvalue()) ```
```python msg = 'Script does-not-exist does not exist.' with self.assertRaisesMessage(RuntimeError, msg): ```
it's a separate item, but I wonder if we could patch override_settings to handle DATABASE_ROUTERS like is done below
When calling `on_commit` there are basically two modes: - there is no transaction in progress, so we execute the function right away - we are in an atomic block, so we register the function to execute it later (`self.run_on_commit.append(`) The first case is handled by the PR, but not the second one. And I'd think that we would need to handle a robust execution in the second case too. Does that make it clearer? :)
Use a similar logging to what we do for robust signals? See `django.dispatch.dispatcher.Signal.send_robust` and ``` try: response = receiver(signal=self, sender=sender, **named) except Exception as err: logger.error( "Error calling %s in Signal.send_robust() (%s)", receiver.__qualname__, err, exc_info=err, ) ``` Something like ```suggestion logger.error("Error calling {func.__qualname__} on_commit() ({e}).", exc_info=True) ```
A temporary variable is unnecessary ```suggestion self.run_on_commit.append((set(self.savepoint_ids), func, False)) ```
`func` is called even if no transaction is in progress, so we should move this to the first line. Fixed.
This will become a performance issue for the database before it becomes one for the Python process :-)
Does it also work if you leave away the wrapping DIV? It isn't obvious to me that the issue from the ticket (`'<a/><b/>'` should be contained by `'<a/><b/><c/>'`) is being addressed by this change.
`with self.assertRaisesMessage('Needle HTML does not have a root element'):`
single line here looks okay
We prefer hanging indent like this: ``` self.assertContains( response, '<div class="readonly">Multiline<br />html<br />content<br /> with allow tags</div>', html=True, ) ```
Maybe: ```suggestion template_name_label = 'forms_tests/cyclic_context_boundfield_render.html' ```
Oh I realize that asserting against the results is problematic given all the engines we're testing against support foreign keys. In this case yes, using the same `JOIN` check against `captured_query` should do!
The fact only a single result is returned is a strong enough assertion here. Some database backend could translate `__isnull` to some different SQL.
Ditto, I'd remove.
Move the exists assertions to another test.
``` """ QuerySet.count() on a many-to-many relation doesn't include an unnecessary JOIN. """ ``` Ticket references should be reserved for obscure issues (not needed here, I think).
Oh. Interesting :-| Bisecting the regression on Django's master branch with your test will show where the regression happened. Depending on what this reveals, a backport could be in order, even if the regression is old.
Bisected to 388bb5bd9aa3cd43825cd8a3632a57d8204f875f. I didn't finish investigating to understand why that's relevant here.
The deliberate error in the reproduction script (`u.is_active = False, # assigning a tuple to a boolean field`) doesn't raise a `ValidationError` until that commit.
State the expected behavior in test docstrings and wrap docstrings at 79 chars per [Python style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ``` """ ORM queries are allowed after an error and a rollback in non-autocommit mode (#27504). """ ```
This flag is ignored when `ensure_durability` is `False`, so we should inform users that is not allowed, e.g. ```diff (django-test) git:pr/13708 felixx@felixx-A555:~/repo/django/tests> git diff diff --git a/django/db/transaction.py b/django/db/transaction.py index c6ba346a99..8a84b97237 100644 --- a/django/db/transaction.py +++ b/django/db/transaction.py @@ -172,6 +172,11 @@ class Atomic(ContextDecorator): self.using = using self.savepoint = savepoint self.durable = durable + if self.durable and not self.ensure_durability: + raise ValueError( + 'A durable atomic block is not allowed. If you are running ' + 'tests, you must use TransactionTestCase, not TestCase.' + ) def __enter__(self): connection = get_connection(self.using) ``` We can be descriptive here.
I think you could skip the views file and use `lambda req: HttpResponse('OK')` instead.
patterns is deprecated, please remove.
Use single quotes for the names.
Let's be consistent about whether `app_name` appears above or below `urlpatterns`.
I think you can safely remove this.
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
could you limit line length to 120 characters so horizontal scrolling isn't required in GitHub? missing whitespace for: `{% autoescape on%}`
Can we test both `Person` and `Political`?, e.g. ```python def test_create_new_instance_with_pk_equals_none(self): c1 = Congressman.objects.create(state='PA', name='John', title='senator 1') c2 = Person.objects.get(pk=c1.pk).congressman # Create a new congressman by setting pk = None. c2.pk = None c2.name = 'Bill' c2.title = 'senator 2' c2.save() self.assertEqual(Congressman.objects.count(), 2) self.assertEqual(Person.objects.get(pk=c1.pk).name, 'John') self.assertEqual(Politician.objects.get(pk=c1.politician_ptr_id).title, 'senator 1') ```
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
Would this original line not raise `ValidationError` further down in the `clean()` method? https://github.com/django/django/blob/master/django/forms/models.py#L1240. Might need to add it back.
Please use single quotes.
This will always return the same as `self.db_type()` which is not intended. I added `__mro__[1:]` to fix this.
Yup. This is where we'd need to define `PositiveBigAutoField` which would have this set to `PositiveBigIntegerField`.
I'm afraid that's backward incompatible, this should be handled in #11900.
Actually `return field.db_type(self.connection)` should be enough as it defaults to `connection.data_types.get(self.get_internal_type())` https://github.com/django/django/blob/ff5dfbc63a278219cd929449678b99ebec9a4b5f/django/db/models/fields/__init__.py#L684-L688
I guess this should be more specific like `CheckTemplateSettingsAppDirsTests`
This could work: it's only the `current-app`, `current-model`, `current-page` attribute values that are dependent on `request`, and for the index page app list they're always not set anyway, so it's only when the side bar is set that `request` is serving any purpose.
I think we should add this check only if `enable_nav_sidebar` is enabled on any site and raise an error instead of warning :thinking:
This line is horrible. 😄 Simon mentioned this in his review before but, maybe leaving up until the `and\n` as is and putting the new check on the next line, to keep the diff that bit smaller...? (I don't mind this as it is per se — whichever way we do it, it is long and horrible.)
check that -> and that (no comma needed since the two clauses are independent)
What's the purpose of these lines? When I run the script, the suffix is always ".js" so this condition is always True.
`AttributeError: 'PosixPath' object has no attribute 'with_suffic`
I guess `operator.itemgetter(1)` could be used here.
And there: ``` work_file = os.path.join(self.dirpath, '%s.c' % self.file) ```
Perhaps the full list could be a class attribute so it doesn't have to be repeated several times.
I'm not following the expected usage here. Surely (?) I'm only applying this to filters `needs_autoescape=True` (It seems overly complex…)
```suggestion if autoescape: args[0] = conditional_escape(args[0]) return func(*args, **kwargs) ```
This could possibly be split into additional simple wrappers based on `parameter.kind` if it were `POSITIONAL_ONLY` or `KEYWORD_ONLY`? Then you could have simple conditions: ```python if has_multiple_parameters: def wrapper(*args, **kwargs): if any( isinstance(arg, Promise) for arg in itertools.chain(args, kwargs.values()) ): return lazy_func(*args, **kwargs) return func(*args, **kwargs) elif parameter.kind == parameter.POSITIONAL_ONLY: def wrapper(*args, **kwargs): if isinstance(args[0], Promise): return lazy_func(*args, **kwargs) return func(*args, **kwargs) elif parameter.kind == parameter.KEYWORD_ONLY: def wrapper(*args, **kwargs): if isinstance(kwargs[first_parameter.name], Promise): return lazy_func(*args, **kwargs) return func(*args, **kwargs) else: # parameter.POSITIONAL_OR_KEYWORD def wrapper(*args, **kwargs): if (args and isinstance(args[0], Promise)) or ( first_parameter.name in kwargs and isinstance(kwargs[first_parameter.name], Promise) ): return lazy_func(*args, **kwargs) return func(*args, **kwargs) return wraps(func)(wrapper) ``` Although maybe that is overkill if we just simplify the last case: ```python def wrapper(*args, **kwargs): arg = args[0] if args else kwargs[first_parameter.name] if isinstance(arg, Promise): return lazy_func(*args, **kwargs) return func(*args, **kwargs) ``` (Note that we can assume it exists in `kwargs` if `args` was empty and drop the additional containment check.)
If we `from itertools import chain` we can save the overhead of attribute access here.
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
`to_python()` (add parens)
I noticed a different behavior for floats lower than `1`, they aren't rounded e.g.: ```python >>> f = models.DecimalField(max_digits=4, decimal_places=2) >>> f.to_python(0.0625) Decimal('0.0625') >>> f.to_python(0.00625) Decimal('0.006250') >>> f.to_python(0.000625) Decimal('0.0006250') >>> f.to_python(0.0000625) Decimal('0.00006250') ``` Maybe that's ok and I missed something.
I would call `clean()` in validation tests, we should also move it to a separate tests, e.g. ```python def test_invalid_value(self): field = models.DecimalField(max_digits=4, decimal_places=2) msg = '“%s” value must be a decimal number.' tests = [ (), [], {}, set(), object(), complex(), 'non-numeric string', b'non-numeric byte-string', ] for value in tests: with self.subTest(value): with self.assertRaisesMessage(ValidationError, msg % (value,)): field.clean(value, None) ```
Please update your patch.
The failures on MySQL, PostgreSQL and likely Oracle seems to be an indicator that it should not work on SQLite either. There's only so much that Django can do when coercing types in a database agnostic way and I'm not sure trying to support cases where `float` are implicitly properly converted to `Decimal` at the ORM level is a pattern we should encourage. If you're filtering against decimal/numeric data with floats you're better off defining your coercion rules explicitly at the application level and pass _stable_ numeric data to the database to avoid surprises down the road when a specific float value happens to take an unexpected rounding/loss of precision path along the way to the query executor.
```suggestion return "<%s vendor='%s' alias='%s'>" % ( ```
This can cause credential leaks on crash :fire: , e.g. in Sentry. I would leave only `alias` and `vendor`.
the `reversed` call isn't free, it's slightly more optimal to put the wrappers in the list in the way you want to iterate them
btw `reversed(x)` doesn't actually iterate the whole list in reverse in python 3, you just get a `list_reverseiterator`... ``` In [1]: reversed([1]) Out[1]: <list_reverseiterator at 0x105098b70> ``` :)
`{'connection': self.db, 'cursor': self}` is faster and imo clearer. `dict(foo=bar)` actually goes through two dict creation steps: first it creates the keyword args dict, then it finds the global name 'dict' (which could refer to anything), then it calls that name which creates the final dict.
have this line use 8 space indent and the `raise` line use 4 space.
I don't think you need this check here. This case will be handled in the for loop. Otherwise you can skip the first item in `cls.mro()` as well.
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
My thought was caching the return value in someway (in a dict eg. `self.cache[cls]`) to speedup by not looping over the bases each time a inherited manager is accessed. I would like to hear from other devs what they think on this.
I think some caching would make sense here.
Use single quotes unless a string contains double quotes. Also, this looks fine to fine on the line above.
`assertRaisesMessage()` (this test is broken) as it doesn't pass` on_conflict='ignore'`.
I checked locally. It should pass for other backends.
`# Prevent the RuntimeWarning subclass from appearing as an exception due to the warnings.simplefilter() in runtests.py.`
This second assertion isn't what you want (It'll pass before and after the code change I believe.) Instead, you should be setting `INSTALLED_APPS` to a tuple with duplicates and using `with self.assertRaises(ImproperlyConfigured)`
Can you issue a `RuntimeWarning` here telling the user that Django falls back and it might be time to clean up using `squashmigrations` and link to https://docs.djangoproject.com/en/dev/topics/migrations/#squashing-migrations.
The style I prefer is ``` options = { 'include_parents': include_parents, .... } ``` It's somewhat of a pain to indent additional items if your editor doesn't do it automatically with the other style.
The approach you've taken here is: - Cache the result of get_fields() for a specific set of arguments - look up a name in that list; - Raise FieldDoesNotExist if the name is not found. The other obvious approach I can think of would be: - Cache a list of _all_ fields - Look up the name in that list - Raise FieldDoesNotExist if the name is not found - Raise FieldDoesNotExist if the field doesn't have the requested properties. I'd be interested to see the "memory vs speed" tradeoff for these two approaches.
True about the ML. Regarding the naming for `related_objects/related_m2m` vs `reverse_rel/reverse_m2m`, that's a new API so there isn't historical names to preserve (unlike `many_to_many` vs `m2m`), we just need to pick the best names to represent the relations.
Wording of this error is awkward. I'd suggest: "(old api) is an unofficial API that has been deprecated. Usage of (old API) may be able to be replaced with a call to (new API)"
Whilst we can't show the signal name, I suggest using `Signal.send_robust()` in the message, to provide a little more context: ```suggestion 'Error calling %s in Signal.send_robust() (%s)', ```
maybe I'm being a stickler, but I'd make extra assertions on the log record's level and message
Yes, we should check if it's on `ERROR` level: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ... self.assertEqual(cm.records[0].getMessage(), ...) ``` and assert a message (`cm.records[0].getMessage()`) and an exception info (`cm.records[0].exc_info`).
`ERROR` in `assertLogs()` is still missing: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ```
This test is not such a good idea. I think the order in which signals are executed is not guaranteed but rather an implementation detail and the test does not check if a_signal and c_signal trigger the receiver at all.
This method returns a list and not a dict.
This can go away now, but needs a new test that the warning is raised in the base hashers `decode`
For simplicity I think it would be better to revert this to the previous code, ie simply https://github.com/django/django/blob/69e0d9c553bb55dde8d7d1d479a78bfa7093f406/django/contrib/auth/hashers.py#L425-L427 -- I understand your motivation behind using `decode` here, but simplicity wins especially in security relevant code.
I am currently giving the PR a full final review and I think we can drop those assertions now that they are done in decode already, what do you think? (same for the assertion in `safe_summary` and other hashers)
I'd call this `work_factor` as dictionary key and only in `safe_summary` it would be `work_factor`
you should accumulate all warnings into a list and return that at the end of the function. At the moment this returns early, if there are two non-unique names in use, only the first one will get a warning. If the user fixes that, they run the checks again, and get a new warning about the second non-unique name. Not a great workflow if there are many to fix.
You should probably check `if getattr(settings, 'ROOT_URLCONF', None)`, similar to the `check_url_config()` check.
Why the `!= 'app'`? This seems to hide some test failures in `test_check_unique_namespaces`.
`url.urlconf_name` is, more often than not, a URLconf name or module, not a list of patterns. It would be better to use `url.url_patterns` here as well.
I think a `Warning` is more appropriate here, something like "URL namespace {} is not unique, you may not be able to reverse all URLs in this namespace". Errors prevent management commands from running, which is a bit severe for this case.
The docs say, "For performance reasons, `from_db_value` is not implemented as a no-op on fields which do not require it (all Django fields)."
Why do you fallback to `to_python` method? It's kind of unexpected, since normally `to_python` isn't called from `from_db_value`
`to_python` should _not_ be called here.
According to Django docs: > If present for the field subclass, from_db_value() will be called in all circumstances when the data is loaded from the database, including in aggregates and values() calls. > to_python() is called by deserialization and during the clean() method used from forms. https://docs.djangoproject.com/en/1.8/howto/custom-model-fields/#converting-values-to-python-objects [Here](https://github.com/django/django/blob/8047e3666b0b50bb04e6f16c2a4fb21ddfd5713f/django/contrib/gis/db/models/sql/conversion.py) you can look at from_db_value implementation
Do we need this check? All tests pass without it.
```suggestion widget=MultiWidget(widgets=[TextInput(), TextInput()]), ```
Despite the existing style of the first test, I would remove the intermediate `f` variable in the new tests as it'll help balance line lengths and make things more readable.
Can we move the whole `data` setup into `items`? 🤔 ```suggestion def items(self): o1 = TestModel() o1.lastmod = datetime(2013, 3, 13, 10, 0, 0) o2 = TestModel() o2.lastmod = datetime(2014, 3, 13, 10, 0, 0) return [o1, o2] def lastmod(self, obj): return obj.lastmod ``` (Getting rid of the dict lookup step.) (🤷‍♀️)
please multiline the string ``` '<select id="id_f" name="f" disabled><option value="J">John</option>' '<option value="P">Paul</option></select>') ```
Please use hanging indent here and below in `assertEqual`: ``` data = [ {'0': 'a', '1': '42'}, ] ```
`'rb'` flags are unnecessary.
I would rather try to create a second non-blocking lock: ```suggestion file_path = Path(__file__).parent / 'test.png' f1 = open(file_path) f2 = open(file_path) self.assertIs(locks.lock(f1, locks.LOCK_EX), True) self.assertIs(locks.lock(f2, locks.LOCK_EX | LOCK_NB), False) ```
You need to specify a type of lock, e.g. `locks.LOCK_NB | locks.LOCK_EX`. Currently it returns `False` because we passed an invalid argument.
chop blank line
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
Could probably use an f-string here and in the following branches. ```suggestion return f'{lhs}[%s:%s]', params + [self.start, self.end] ```
Mistake? Looks like test coverage is missing… ```suggestion return '%s[:%%s]' % lhs, params + [self.end] ```
You can rebase your branch and target it for Django 2.0. Since master no longer supports Python 2, you can make a few updates such as using `super().`.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
Stray `,` at the end of the help text.
You can use `type='choice'` with `choices=['ipython', 'bpython']` for options with a predefined set of choices: http://docs.python.org/library/optparse.html#optparse-standard-option-types
Can you add a period at the end, please.
This is minor, but the double exclamation point feels a little overblown. I'm not sure any exclamation points are needed at all; the text should suffice.
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
Sure, so two extra fields - one to handle `0` and `None`, the other to handle `False`.
I don't think it's worth to add multiple fields. `IntegerField(null=True)` should be enough.
I think it's enough to test `None` and `''`.
longer line is fine so you can use same style/indentation as others
Do we need to catch `AttributeError`? It looks unnecessary since d2a26c1a90e837777dabdf3d67ceec4d2a70fb86 :thinking:
Interesting thought. But if a key is compromised one would switch from one key in the list to still one key (the new one) because you wouldn't want to keep the compromised key active. So in the case of a compromise I'd always expect the list to stay constant in length because the offending key would be replace with a new one (independent of other keys probably). Either way for the majority of cases (ie under normal operation) I'd expect just one key in there (or always two if one rotates a key every $x weeks)
Fair warning, I don't know nearly enough about things of this nature to be actually valuable, except possibly to ask questions which might be dumb or might be previously unconsidered. So please take it with a grain of salt... If an adversary is making use of the fact a secret key has been compromised, which scenario gives them less information when the key is subsequently discovered and rotated and they want to stop trying to make use of it (to fly under the radar as much as possible); one constant time compare, or multiple? Layman's gut feeling says you'd want the time comparison to be actually roughly constant, which would probably require always doing either 1 or 2 (I think, it's murky in my brain now) always, regardless of number of keys in the corpus? (ie: if there's only one key, always compare as if there are 2...) And does that kind of scenario _actually_ matter? IDK.
I think we should revert this change (we reverted similar change in `django.core.cache.backends.basedefault_key_func()` in the past) because it will create a regression for non string values. The following example works in the current master: ``` >>> Signer('some_key').sign(1) '1:gJ9gvYHWvcR2rrXTSANB5b-IhU8' ``` but with this change it raises `TypeError`: ``` File "django/django/core/signing.py", line 162, in sign return self.sep.join([value, 'sha1', self.signature(value)]) TypeError: sequence item 0: expected str instance, int found ```
I'm a little concerned about the loss of `constant_time_compare()` here which sounds like it was added as a potential mitigation against timing attacks.
please use single quotes for consistency
I believe this was meant to be a `references` check instead of a `reduce` check? Since `reduce` returns operations, not a boolean. Something like "`not op.references(other)`" so that we can ensure that `other` can properly be pulled forwards
Ah I see. I wasn't aware of the different signatures available for this.
`None` as a default value to `get()` is not required here. I would also just do `if method` since `None` is falsey it's really a nitpick.
Do we need to check `removal_value`? It should be enough to check that `new_value` is not en empty set, I cannot imagine a different scenario :thinking: ```suggestion if new_value: ```
"... final db state after the last state operation, hence ..."
`Delete` sounds better to me, because we delete rows from the `django_migrations` table. Maybe: ```suggestion help='Deletes nonexistent migrations from the django_migrations table.', ```
Good idea :+1:
I noticed that all logs and prompts have `ERROR` style when using `--scriptable`, e.g.: ![image](https://user-images.githubusercontent.com/2865885/148344507-ada0d115-4a48-4001-81a2-b62c919c5e45.png) ![image](https://user-images.githubusercontent.com/2865885/148344684-e00db0d8-c25f-45fc-ba54-9dfef13eac7c.png) We could create a copy of `stderr` without the `ERROR` style and use it where appropriate :thinking: ```diff diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py index cdb200f22e..096702814c 100644 --- a/django/core/management/commands/makemigrations.py +++ b/django/core/management/commands/makemigrations.py @@ -6,7 +6,7 @@ from itertools import takewhile from django.apps import apps from django.conf import settings from django.core.management.base import ( - BaseCommand, CommandError, no_translations, + BaseCommand, CommandError, no_translations, OutputWrapper ) from django.db import DEFAULT_DB_ALIAS, OperationalError, connections, router from django.db.migrations import Migration @@ -62,9 +62,17 @@ class Command(BaseCommand): help='Output only created migration filepaths to stdout; divert logging and prompts to stderr.', ) + def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False): + super().__init__(stdout, stderr, no_color, force_color) + if no_color: + self.stderr_log = self.stderr + else: + # stderr without the ERROR style. + self.stderr_log = OutputWrapper(stderr or sys.stderr) + ```
I don't think adding this makes sense. Perhaps similar logic to the migration consistency check could be used.
`dest='plan',` is unneeded as that's the default value from `--plan` (eac9ab7ebb1ce0cbbc79c4cf65e8f70b0635a240)
Suggestion: "Found duplicate value %s in CreateModel managers/fields/bases argument."
Right, I'll sumit a PR shortly with the required changes.
It was in the initial version of patch when bases and managers were not also checked. If you think this must be present I can submit a PR with the previous changes.
I didn't follow the discussion closely but was there a reason for not including the duplicate value in the message? I thought that was in the first version of the message.
`ExpressionList.__repr__()` can be removed because `Func.__repr__()` works in the same way.
The change is fine, I'm just asking that it be a be separate commit similar to 31098e3288595c13f165935f2579f1af744e5240 so that the refactoring isn't mixed in with the new feature.
Please make this change and the test changes unrelated to the bug fix in a separate commit for clarity.
Also fits on a single line.
It looks that only `OneToOneField` is affected, so I'd move your test to the `ExcludeTests`, e.g. ```python def test_exclude_unsaved_object(self): jack = Staff.objects.create(name='jack') jack_staff = StaffUser.objects.create(staff=jack) unsaved_object = Staff(name='jane') self.assertIsNone(unsaved_object.pk) self.assertSequenceEqual(StaffUser.objects.exclude(staff=unsaved_object), [jack_staff]) ```
This docstring doesn't have much value, please remove it.
I think this migration should always start with `from django.db import migrations` and I would find that assertion much simpler.
We don't often use the `msg` param with `subTest()`. Maybe: `"Migration file includes header: %s." % include_header` or just: `include_header=include_header`
This is already covered by `ParseHeaderParameterTests.test_basic()`.
```suggestion "import datetime\nfrom django.db import migrations, models\n", ```
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
I've checked and `icontains` is not affected, we can remove this test. Sorry I should checked this first.
The blank lines aren't needed.
Please follow the style of existing tests and don't use your name for test values.
Ticket references should be reserved for obscure issues (not needed here).
It works with my proposition so we should have both assertions.
You don't need to mock, it will return `False` for a bad file descriptor.
You need to specify a type of lock, e.g. `locks.LOCK_NB | locks.LOCK_EX`. Currently it returns `False` because we passed an invalid argument.
`'rb'` flags are unnecessary.
```suggestion file_path = Path(__file__).parent / 'test.png' ```
I would rather try to create a second non-blocking lock: ```suggestion file_path = Path(__file__).parent / 'test.png' f1 = open(file_path) f2 = open(file_path) self.assertIs(locks.lock(f1, locks.LOCK_EX), True) self.assertIs(locks.lock(f2, locks.LOCK_EX | LOCK_NB), False) ```
"its" add period
I don't think this is correct. `settings.MIGRATION_MODULES` only contains user-defined migration modules -- presumably want the detection to work regardless of whether or not that setting is defined.
Furthermore, why do you construct `unapplied_parents` at all? Can't you just loop over `self.graph.node_map[migration].parents` and on raise an exception when the first one has an inconsistent history? That would safe some time in bigger projects. ``` python for x in self.graph.node_map[migration].parents: if x is unapplied # use the condition from above raise InconsistentMigrationHistory(...) ```
Ahh, that's gonna be more interesting. You'd need to look at `self.migrations_module(x[0]) is not None` for whether there are migrations for that particular app or if they are disabled.
use: `any(name for app, name ... )`
This check is redundant. `skipUnless` already guarantees that we have MySQL. You can remove the `try ... except` leaving only `import`.
This check is also redundant.
If `cx_oracle` is installed, there's an error: ``` File "/home/tim/code/django/tests/backends/test_cursors.py", line 33, in OracleCursorOptionsTestCase class OracleLoggingCursor(LoggingCursorMixin, Database): TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases ``` Also, is this file doing anything useful? I don't see any test methods.
`e` is unnecessary. Maybe it will be better to refactor these tests and put `class` inside `try` e.g. ```python @unittest.skipUnless(connection.vendor == 'postgresql', 'Postgresql specific test.') class PostgreSQLCursorOptionsTestCase(TestCase): try: from psycopg2.extensions import cursor class PostgresLoggingCursor(LoggingCursorMixin, cursor): pass except ImportError: pass ```
This check is also redundant.
I think it's fine to leave it inside a `try` block.
`targets` is an empty list when `MIGRATE` is `False`: ```suggestion executor.migrate([], plan=[]) ```
New tests are failing on Oracle. I think we should avoid creating a test database, maybe by mocking `_create_test_db()` :thinking:
I'd split this line in two
Maybe a `self.patch_execute_statements(self._execute_raise_tablespace_already_exists)` helper method could avoid repetition and long lines requiring unusual indentation.
good catch, the second is fixed in https://github.com/fcurella/django/pull/1
use `with self.assertRaisesMessage(PermissionDenied, 'Forbidden user agent'):`
No `self` parameter, just the exception class.
Great, I just change this line to check the message in calls rather than simply its length.
override `__init__()` instead. after `super()` then `self.style = no_style()`
As long as you use `except Exception` and not a bare `except` this should be good.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
If we remove this will the tests run on Jenkins? It might be fine.
Don't think we need to worry about duplicates.
Never mind, even such an API would be useless since the raw password is no longer available after its initially set. So there really is no way around that limitation of this validator.
This should be replaced with `@isolate_apps()` as done in a08fda2111d811aa53f11218fa03f3300dfff4cb.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
Usually we camel case assertions to match the unittest style. Maybe assertFieldsInModel (considering field_outputs is a list).
Please rewrite `@override_settings` into a single line: ```python @override_settings(STATICFILES_DIRS="a string") ```
Probably the check functions should be called directly rather than invoking them through `run_checks()` (otherwise, this runs all registered checks across all installed apps which doesn't provide good isolation) -- see `tests/check_framework`.
This one as well
I think this can be in single line: ``` url = reverse('admin:auth_user_add', current_app=self.admin_site.name) ```
Move `has_view_permission` above `has_add_permission` for consistency.
You could do this setup in Python. `self.school.students.add(...)`
omit the blank line
I believe you can simplify all this stuff to lines like: ``` assertFieldType('pos_big_int_field', 'models.%s() % connection.features.introspected_field_types['PositiveBigIntegerField']) ``` I don't think the if statements are needed anymore (similar elsewhere in this file).
Ah, I realized these are E128 which we are ignoring in the flake8 section of setup.cfg. I don't mind the changes, but we are ignoring it because there are 2K+ violations and seemingly not a lot of value in fixing them.
This if (lines 114--123 as I write this) can be folded into the previous one (109--112).
`else: assertFieldType('time_field', "models.DateTimeField()")`
There's a lot of repetitions of ``` python if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): ``` in this function now. Also, for Oracle, it doesn't check things it could check (e.g. that `ip_address_field` is a CharField). I think both issues could be addressed with a smarter field-type-asserter; perhaps this is out of scope for the PR, and should be done separately.
I think `assertIsNotNone(req.session.get(CSRF_SESSION_KEY))` would better express the existence assertion here.
Merge with the line below since you are not using `session_token` later on. Is it actually needed to sanitize the session token? After all the user cannot change it.
I think keeping the explicit `process_response()` call here would make sense. By changing to `__call__()` we're running through `process_request()`, which is not a no-op, which is perhaps fine but it's subtly changing the intent/behaviour of the test. (I guess this is something we'd have to think about removing the `process_x()` hooks, but not in this PR) Same for line 677 below. **Update**: Tests in `csrf_tests` are more explicit about this... (So maybe the small change here is OK)
On balance I will leave this one as it is.
Why would you need to sanitize something that's already in your session? Seems a bit late...
We don't wrap at 80 chars, anything below 100 chars is generally fine. Also we shy away from backslashes.
I'd add a note about why "condition" is special.
That would hide the `update_condition` kwarg from signature, that's why I suggested a sentinel should be used.
Keep what's done in `try` to the minimal expected to raise `self.model.DoesNotExist`. Move this after `except:` block.
remove this assertion? (see 90af278203963e3e3f96e443971cd38a2dad34e4)
Please use single quotes consistently in new code.
Ahh didn't notice that. I just remembered a recent commit that converted many of those to literals.
You could use a set literal here.
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
You can safely join this an the next line. You have up to 119 chars per line. ;)
This is compliant with the PEP8 rules that we care about, let's not make the diff bigger than needed.
Might be worth renaming this to `self.root_queryset`.
Should this be `r.field.name` so the error in the example of the ticket is: ``` myapp.specialdetail: Accessor for field 'parent' clashes with accessor for field 'SpecialDetail.target'. Add a related_name argument to the definition for 'parent'. ``` instead of: ``` myapp.specialdetail: Accessor for field 'parent' clashes with accessor for field 'SpecialDetail.myapp:specialdetail'. Add a related_name argument to the definition for 'parent'. ```
You turned the arguments into keyword arguments in one other place. Could you also do this here and below? I don't know if it makes sense to also do this in the tests.
I overlook this myself, but hanging indent, please.
You don't need this `pass` anymore.
I don't know if it's public API, but this is Django Models base metaclass, and there is no other way to do it then use it directly.
"Create" with a capital c
Shouldn't mixins be to the left of the base class `models.Model`? This is my understanding of how mixins on class-based views work anyway.
Correct, but if me change `ModelState` at some point, this will work automatically or fail, telling us we did something wrong ;)
You can use `Path.is_absolute()`.
I've changed it to a deploy check because it's not really an issue in a local environment.
but OK let's have it.
Wrap at 79 chars.
```suggestion id='caches.W003', ```
I'm not sure if there are lookups where it's not the case, but comparisons such as `Choice.objects.filter(votes__gte='2')` seem to work fine with the value as a string so the "transform" stuff seems unnecessary, at this for the first version of this.
Please assert with the expected string e.g. ```python self.assertEqual(repr(cl), '<ChangeList: model=Child model_admin=ChildAdmin>') ```
It would probably be better to check `cl.queryset.query.distinct`
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
`.get(self.live_server_url + reverse('admin:admin_views_question_add'))`
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
Is this line correct? Above it's `subTest(url=url_name)` but then we `reverse(url_name,...)`
Yes, or whatever minimal test is needed for the change.
omit the blank line
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
Use hanging indent: ``` special_people = models.ManyToManyField( 'Person', through='ProxiedIndividualCompetitor', related_name='special_event_set', ) ```
We can drop meta ordering and add it to the queryset: ``` self.assert_pickles(c.concrete_events.order_by('event)) ```
Looking at other test methods I believe this can be reduced to a simple line. ```python self.assertEqual(User.check(), []) ```
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
Actually, I think we can skip the router stuff and just use `django.db.connection`. These tests aren't run with custom routers so this'll always be run on the default database. (so we can move the skip condition to `test_long_column_name`).
Diff will be smaller without this unnecessary change.
This check is also redundant.
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
trailing comma here and next line
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
This cleanup is not related with a patch please move it to a separate commit/PR.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
flake8 complains about missing spaces around `*`
I'm not seeing what the benefit of that would be. `self.addCleanup(self.temp_dir.cleanup)` calls `cleanup()` which removes the finalizer so there isn't a warning.
Okay then, no worries. As context managers are a regular, routine Python idiom, even outside tests, I find them quite readable (even with the indentation) and I find it makes the clenaup extremely explicit. Both forms work, though.
`tempfile.TemporaryDirectory()` can be used as a context manager: ```suggestion with tempfile.TemporaryDirectory() as temp_dir: ``` The other tests were cleaned up in #13211.
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
There's no need to define the extra `settings_dir` variable as `pathlib` gives us more flexibility: ```suggestion settings_file_path = self.test_dir / filename / "__init__.py" settings_file_path.parent.mkdir() ```
This is the failing assertion on Windows. I think it might have to do with the file being written with Windows vs. Unix line endings. If you remove the assertion, the rest of the test passes.
Not sure these asserts bring value ... they seem to test that `override_settings` works.
We should use a custom storage for this test (instead of mocking).
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
if a case is only used in 1 file like `FinderTestCase`, I'd put it there.
This can be single-lined ```suggestion '<ul class="errorlist nonform"><li>Please submit at most 1 form.</li></ul>', ```
Chop blank line.
```suggestion renderer=renderer, ```
Please use hanging indentation: ```python GenericFormFormset = formset_factory( form=GenericForm, can_delete=True, extra=2, ) ```
I renamed the test and removed the docstring.
Put this on the previous line.
Add a custom converter only for MySQL + Concat combination in Concat.get_db_converters()? I believe we are doing the wrong thing for expression converters. We should specialize more (that is, if some aggregate needs custom converters, then add custom converters for that aggregate only instead of for all expressions), and we should also pass the expression instead of the internal_type to backend.get_db_converters. I am going to change the signature of backend.get_db_converters() so that it gets expression instead of internal_type as input parameter.
The problem is MySQL. You can use "--column-type-info" for mysql command line client to see that the return type of the expression is blob. Of course, this being MySQL adding a CAST as char in there doesn't actually do anything. The return type is still blob. You can use "cast(concat(a, b) as char(10000) character set utf8)" to get a real cast as VAR_STRING, but you'll have to supply the length, too. And, this being MySQL you'll get silent truncate of data if the length is too short...
My idea of converters is that backend converters are applied to convert the data to uniform format, then the field converters change that format to the wanted Python object representation. So, in this case, if the bug can't be fixed, then we need to add a backend converter. Doing that for Concat expression would be much better than doing it on all TextFields, but of course before we pass the expressions instead of internal_type to backend's get_db_converters that can't be done. Maybe it is possible to add a cast on SQL level to Concat on MySQL, something like "CAST(Concat('foo', 'bar') AS CHAR)". It might be that if the datatype of Concat expression is incorrect on SQL level, then further operations on the value (say lower()) will not work correctly.
Perhaps this could be a docstring? You might elaborate a bit more -- as someone not familiar with MySQL, it's not clear to me what "improved" means.
Rename this variable to `readonly_fields`. Let's not pollute the code with three things that mean the same thing, i.e. the `uneditable_fields` here and the aforementioned `viewonly_fields`.
Store the result of `self.get_view_on_site_url(obj)` as a local variable to avoid two function calls.
This docstring doesn't have any value, IMO.
If you want to use a new name, that's okay with me, but I think `'has_file_field'` should remain for backwards compatibility.
Move `has_view_permission` above `has_add_permission` for consistency.
Valid point. Feel free to change the decorator in a separate commit.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
Wrap at 79 chars, please.
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
Can you sort those attributes please
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
I would prefer to omit it for now.
IMHO, it's clearer if you use: ``` python if not prefixed_default_language and language == settings.LANGUAGE_CODE: language_path = '/%s' % (request.path_info) else: language_path = '/%s%s' % (language, request.path_info) ```
how about `_resolve_special` -> `resolve_error_handler()`. I don't see a need for separate methods like `resolve4XX` and `resolve5XX`, especially when you pass any status code to either and achieve the same result.
This is minor, but I'm curious -- any reason to use `[::-1]` over `reversed(settings.MIDDLEWARE)`? I think the latter is clearer, and if micro-optimization is a concern (shouldn't be here), I think it is better, as it just creates an iterator over the original list.
I think we can safely remove this. It was overlooked in the post-deprecation removal of `django.core.cache.get_cache()` in d038c547b5. We should do that in a separate commit w/ `Refs #21012 -- ...`.
Pushed to a separate PR #13753.
Can this fail with KeyError? It looks like that was transformed to InvalidCacheBackendError in the old code.
```suggestion params = self.settings[alias].copy() ```
```suggestion raise InvalidCacheBackendError('Could not find backend {backend!r}: {e}') from e ```
`CANONICAL_RANGE_BOUNDS` is unnecessary: ```suggestion def __init__(self, *args, default_bounds='[)', **kwargs): ```
```suggestion msg = f"Cannot use 'default_bounds' with {field_class_name}." with self.assertRaisesMessage(TypeError, msg): ```
Do we need this check? All tests pass without it.
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
Welcome to the wonderful world of `contenttypes` where clearing a GFK (even an optional one) actually deletes the objects.
Same as below, you should be able to call `self.using()` directly.
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
This exception message is different from that in `related.py` though the logic/intention surrounding it seems to be the same. Is this intentional? (FWIW, I find the message in `related.py` to be clearer)
I'd rather find out why we are getting the failure first. User can opt in for `self` to be a custom manager with the `__call__` syntax, doing `self.model._default_manager` bypasses it.
Although the test works fine, this will fail admin checks: `fkuser.CustomUser: (auth.E003) 'CustomUser.username' must be unique because it is named as the 'USERNAME_FIELD'.` so might as well fix that.
Chop blank line.
email_field_name -> email_address to make it more realistic
single line please
`add()` accepts IDs so we can simplify this, e.g. ```python ... user.save(using=self._db) user.orgs.add(*orgs.split()) ```
Yes, I had checked on master, which doesn't make sense. I get the same result on this branch.
This is consistent with how we handle `negated`: ```suggestion kwargs['_connector'] = self.connector ```
Does the ordering of indexes on a database matter? I'm not talking about the order of fields an index applies to, but the indexes itself.
I think we want to crash here if `bases` is not iterable.
How about more simply: "Found duplicate <field/base/manager> '%s' in CreateModel operation." Maybe you could create a helper function so we don't have to repeat a similar loop 3 times.
With a non-English LANGUAGE_CODE and if the active language is ....
```suggestion self.original_po_contents = Path(self.PO_FILE).read_text() ```
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
Remove ticket number. Capitalise first word of sentence.
```suggestion """PO files are unchanged unless there are new changes.""" ```
You are right I missed the fast that exceptions raised during `__enter__` are not going to go through `__exit__` sorry for that. That makes these tests unnecessary.
One solution here would be to make `enable`/`disable` idempotent by having a class level `enabled = False` attribute that gets set/unset and checked for early return in both methods or to override `__exit__` to deal with `exc_value == self.enable_exception` in a special way.
I don't think we need this here. In `disable()` we `raise self.first_exception` (when `not None`) so this line will be unreachable.
Use `as e` or as `as exc` to match other code.
I realize it involves creating a `dict` instance to immediately transform it to a `list` but I'm not convince we should support two initialization paths for `SimpleTestCase._pre_setup`.
Maybe: ```suggestion def get_primary_key_columns(self, cursor, table_name): ```
```suggestion Return a list of primary key columns for the given table. ```
It would be a bit more clear like: ``` {field_name: (field_name_other_table, other_table) for field_name, other_table, field_name_other_table in self.get_key_columns(cursor, table_name)} ```
Composite primary key are not supported so we shouldn't change this (see ticket-373).
OK, let's leave it.
Can replace `**dict(through_defaults, **{…})` and use unpacking generalisations: `**{**through_defaults, **{…}}`.
keep in mind new_ids could be smaller than objs, messing up index order so intermediate_values won't match up, right? Also, new_ids is a _set_, so order is lost.
Missing test for this change.
I noticed that we use keyword-only arguments for `def set(self, objs, *, clear=False, through_defaults=None):` Do we want to so something similar for other methods: - `def add(self, *objs, *, through_defaults=None)`: - `def create(self, *, through_defaults=None, **kwargs):` - `def get_or_create(self, *, through_defaults=None, **kwargs):` - `def update_or_create(self, *, through_defaults=None, **kwargs):`
Sure, I will push those change, except the suggestion for `add()` gives invalid syntax.
directly after _get_called_qs().
`**kwargs` → `**options`
What about async variants of remaining methods: - `values_list()`, - `values()`, - `dates()`, - `datetimes()`, - `none()`, - `all()`, - `filter()`, - `exclude()`, etc. :thinking:
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
To verify this is the expected import error, I'd do something like: `self.assertRaisesMessage(ImportError, 'nonexistent')`
This implementation seems less than ideal. We shouldn't add things to `request.META` that weren't really in the request env; this could be misleading to other middleware or view code. Seems to me we should instead make the "force logout if no header" behavior in `RemoteUserMiddleware` conditional on a class attr which defaults to `True`, then this subclass wouldn't need to do anything but override that class attr.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
Define a `CookieSessionTests.test_session_save_does_not_resurrect_session_logged_out_in_other_context` method decorated with `unittest.skip` instead to keep `SessionTestsMixin` backend agnostic. See #6203.
These kind of changes are not related and should be reverted, IMO. They're also based on a `MiddlewareMixin` behavior that we can remove in the future, that's why I would prefer to keep `process_request()`/`process_response()` tests.
``` if name is None: name = self._create_index_name(*args, **kwargs) return self.quote_name(name) ```
I'm not sure if you intentionally reordered the kwargs. Maybe it makes sense to add a `*` in there to catch bugs in case code is passing kwargs as args.
You can't assume the presence of `self.name` here
Yeah it's quite inconsistent :disappointed:. I think we should change `columns` to `fields` in a separate PR.
Could you please follow the previous indentation style :)
I thought you wanted to remove `return`. Nevertheless I'd also leave the `else` as it increases readability.
I prefer the following one rather than the above one ```py def greet(): condition = False if condition: return "Hi" return "Hello" ``` Feel free whether follow the things I point out.
That's not true, `return` is to avoid setting new migrations.
```suggestion sys.exit(1) ```
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
Migrations are applied and recorded atomically.
Personally if it were happening to me, I'd be **thrilled** if it could tell me what needs applying, and if it couldn't and instead directed me to another command to run I'd _assume_ (and be disappointed) that the information wasn't available at the time the exception occurred. If it is there, I think it's prudent to respect the user's needs and attempt to surface the information. That said, my gut feeling is that the exception output format maybe isn't "right" (for a given value thereof). I can't recall many (any?) places where Django raises with an arg which is multiple lines. Those cases where there's multiple _things_ to enumerate tend to just get comma separated. That does leave the door open to super long lists though, if for whatever reason the partially applied list was big... Maybe because it's related to running migrations, which _are_ line oriented, it's OK? [Edit to add: big thumbs up from me to the information, FWIW. Next step seems much clearer as a result]
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
Use `showmigrations` instead of `"migrate", list=True` which is deprecated (we seem to have a bug in `@ignore_warnings` that causes it to leak state as the tests should catch the use of deprecated features and fail).
This should be in the `finally`: ```python with self.temporary_migration_module(module='migrations.test_migrations'): try: ... finally: # Unmigrate everything. call_command('migrate', 'migrations', 'zero', verbosity=0) ```
When considering my own approach for this same problem, I specifically avoided using xor as when using it on printable characters, you wind up with lots of unprintables you probably don't want to put in your page. Two approaches I considered were: 1. restricting tokens to hex ascii, and xoring their binary forms 2. using a "caeser cipher" approach, where each char is offset in the list of valid chars by the corresponding char in the random pad. [modulo the list of chars, of course]
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
to be -> are
Is that check actually needed? This seems to be only needed if a token is `None` -- which would not happen if we return a token from `sanitize_token` instead of None :D
Is this branch a candidate for removal in some future release? Either way, would be helpful to elaborate on how the backwards-compatibility case arises. I think it's upgrading Django in the presence of existing token set by older versions of Django, but would like t to confirm.
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
I think we should copy `fields_cache`: ```suggestion state['_state'].fields_cache = state['_state'].fields_cache.copy() ``` because a copy of model instance can use the same values and we don't need to fetch it again.
Thanks, the current approach LGTM. Please uncheck "Patch needs improvement" flag on the ticket after local testing.
with -> the
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
Should be able to fix it when committing, just making a note of it. Thanks for the patch; I happen onto the problem from time to time as well. :-)
"actor" variables are unused
NotContains always makes me nervous since it's fragile (a typo or a change in the way we generate the HTML could make it pass). Could we make `class="inlinechangelink">Change</a>` a constant and use it in all 3 of the new tests? That would help alleviate those concerns.
`assertNotContains` is a bit fragile; instead I'd like if you could check `response.context` variables.
Prefer this indent style: ``` response = self.client.post(reverse('...'), { .... }) ```
is the helper method a stylistic change only? makes review difficult.
dependency graph (no dash) I think you mean "intra-app" rather than "in-app"
use dict comprehension: `{op: set() for op in ops}` (although maybe you could use defaultdict too)
I'd keep this on one line for better readability
chop "we" 2x
This test passes when testing against an SQLite or MySQL backend as long as psycopg2 is also installed. For this test case, I think the check `connection.vendor == 'postgresql'` skips the test too aggressively.
Did you consider using `PostgreSQLSimpleTestCase`? I would favor that for consistency.
Test -> Tests (for future expansion)
AppConfigTests "TestCase" designates that this is meant to be subclassed and doesn't contain any tests itself.
This fails when running from the root directory rather than the tests directory (i.e. `$ ./tests/runtests.py postgres_tests`). Also, the output doesn't make debugging very easy (`AssertionError: 1 != 0`) -- if that could be improved that could be nice.
Chop blank line.
This assertion is not necessary.
```suggestion class ModelFieldsCacheTest(TestCase): def test_fields_cache_reset_on_copy(self): department1 = Department.objects.create(id=1, name='department1') department2 = Department.objects.create(id=2, name='department2') worker1 = Worker.objects.create(name='worker', department=department1) worker2 = copy.copy(worker1) self.assertEqual(worker2.department, department1) # Changing related fields doesn't mutate the base object. worker2.department = department2 self.assertEqual(worker2.department, department2) self.assertEqual(worker1.department, department1) ```
I would move this docstring to the class: ```python class MySQLUpdateOrderByTest(TestCase): """Update field with a unique constraint using an ordered queryset.""" ```
This docstring doesn't have much value, please remove it.
We should use key that fails only on a prefix check.
Unfortunately, I don't have a good answer for that. I think now that Django is Python3 only, the project is in a better position to decide if SECRET_KEY is always either bytes or str. That would require some consensus from interested people, though. As long as both types are allowed, some utility function is required. I guess at the moment that is force_bytes/force_text.
According to the [docs](https://docs.djangoproject.com/en/2.0/ref/settings/#std:setting-SECRET_KEY) and ticket https://code.djangoproject.com/ticket/24994 the type of `SECRET_KEY` can be either bytes or str. > Uses of the key shouldn’t assume that it’s text or bytes. Every use should go through force_text() or force_bytes() to convert it to the desired type. So a call to `.encode()` may not always work.
Remove unrelated white-space change.
While I realize we cannot change that now, do we remember why we added `django.http.cookies` here? The salt alone should make sure that we do not clash with other signatures.
We can't really make this backend dependent if we want to store the index name as part of migrations. Migrations are potentially run on any db backend and should work on any.
Use single quotes
Any problem with allowing `self.model = None`. I think conditional attributes which require `hasattr` isn't the best design.
I think this could be `@cached_property` so it doesn't have to be calculated on every access.
I was expecting to raise a ValueError if these conditions aren't met, similar to what we do with "Index names cannot be longer". I don't think it's a good idea to modify the user provided value as it seems like that would only cause confusion.
Chop blank lines.
```suggestion 'Accept': '*', 'Host': 'example.com', ```
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
This doesn't look appropriate for `BuildAbsoluteURITestCase`.
Use hanging indent: ``` request = WSGIRequest({ 'REQUEST_METHOD': 'POST', ... }) ```
```suggestion with self.time_keeper.timed('Total database setup'): ```
I know I suggested it but I think _shadowing_ is the correct term.
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
Since this is only being used in one test case class, I would put it right before that test case class. If it turns out to be useful for other tests, it could always be moved to a more central location and modified as needed, etc.
```suggestion time_keeper = TimeKeeper() if options.timing else NullTimeKeeper() with time_keeper.timed('Total run'): ```
yeah having an `Expression.nullable` flag that is also present on `Col` instance based on the `Field.null` they resolve would be useful for a few other things I've worked on in the past.
This should be added only if column is nullable: ```python if isinstance(value, Col) and self.is_nullable(value.target): clause.add(lookup_class(value, False), AND) ```
> @felixxm in my view, below test code is our expected result. No, it's not. `1 != NULL` so why it's expected that `number` is excluded? see 512da9d5855 and ticket-23797 for more details.
> my changs affect when LHS is annotation field and RHS is not field. I know, but this is also an issue with nullable annotation so we should fix it in this PR. If it is a different branch in `build_filter()` then we have another reason to add some hook.
We can do the same for `reffed_expression`: ```diff diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index b3d92d786c..21bc0aea7a 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -1286,11 +1286,9 @@ class Query(BaseExpression): if check_filterable: self.check_filterable(value) - clause = self.where_class() if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) - clause.add(condition, AND) - return clause, [] + return self.where_class([condition], connector=AND), [] opts = self.get_meta() alias = self.get_initial_alias() @@ -1333,7 +1331,7 @@ class Query(BaseExpression): condition = self.build_lookup(lookups, col, value) lookup_type = condition.lookup_name - clause.add(condition, AND) + clause = self.where_class([condition], connector=AND) require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None: ```
Need to test how many times `update_contenttypes` was called and test arguments which passed to it.
``` @mock.patch('django.contrib.contenttypes.management.update_contenttypes') def test_remove_contenttypes(self, mocked_update_func): management.remove_contenttypes(self.app_config.name) self.assertEqual(mocked_update_func.call_count, 1) ```
assertEqual -- the version with "s" is a deprecated alias.
As `remove_stale_contenttypes` doesn't deal rely on migration generated apps you should be able to remove the three lines above.
no need for super calls
This should probably be updated with the new gdalinfo, which basically includes one more line in the coordinate system: `AUTHORITY["EPSG","3086"]]`
two spaces before #
TIL that character classes also work inside `[]` :D
I wanted to keep them isolated, without calling `cache_clear()` in both one of them will always be no-op.
Why? IMO using regexp is less readable. This is not a really complicated comparison, I can imagine only one case when this can be broken in the future i.e. when Oracle unify their implementation with other dbs. Honestly I would like to catch this.
I would use ```python exc_type, *_ = sys.exc_info() ``` or ```python exc_type, _, _ = sys.exc_info() ``` :thinking:
is `str()` needed? I assume `%s` takes care of that.
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
Single quotes please.
a one -> one
I think we usually avoid _should_ wording in test docstrings.
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
IMO it's enough to test that `CreateExtension` honor `allow_migrate()`, creating extension is already tested in `postgres_tests`.
> Is there any specific reason why we would prefer using the operation in this case? Yes, because we have it. Using a RAW SQL is the last option, we're developing the ORM in order not to use them.
This docstring is unnecessary.
@timgraham that's neat but that looks really fragile. Think `return Signal(providing_args=["app_config", "verbosity", "interactive", "using", "apps", "plan"])` where the name would end up being `'return Signal(providing_args'`) which can lead to more confusion than the actual situation. We could also make `assertSignalSent` accept a `msg` argument (like other `assert` methods do) to allow the user to disambiguate the origin of the failure. From my point of view the traceback is explicit enough to point the users at the correct location in their code base and figure out which signal was unexpectedly sent or not.
I'd revert the logic i.e. check `execute` first: ```suggestion if execute: if is_robust: try: callback() except Exception as e: logger.error( f"Error calling {callback.__qualname__} on_commit() " f"during transaction (%s).", e, exc_info=True, ) else: callback() ```
Why double-underscore? I would also rename `func` to `callback`: ```suggestion for _, callback in connections[using].run_on_commit[start_count:]: callbacks.append(callback) if execute: callback() ```
Single quotes please.
This `atomic()` is not needed. ```suggestion transaction.on_commit(branch_1) ```
Instead of ``` choices = list(filterspec.choices(changelist)) self.assertEqual(len(choices), len(expected_displays)) for i, display in enumerate(expected_displays): self.assertEqual(choices[i]['display'], display) ``` you can write ``` choices = tuple(c['display'] for c in filterspec.choices(changelist)) self.assertEqual(choices, expected_displays) ```
How about adding a `list_filter_sentinel` to the list filter links only if `list_filter_defaults` is used? Then changes like this won't be required, I think.
It would be clearer to pass `True` as a keyword argument here.
This class is unnecessary.
This can be single-lined.
As multiple addresses are allowed, I suggest "to one or more addresses specified ...".
'--version argument does not yet exist'
should this be used? (with a test too) arguments -> options
```suggestion # Validate app_label. ```
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
Use only ``` if PY: # python2 specific code else: # python >= 3 specific code ```
Move this import to the top of the file.
Brackets around the left hand side shouldn't be needed
chop blank line
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
Do we need to call `list(fields)` here? :thinking:
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Is `tz` necessary here ? elsewhere `self.timezone` is passed without it.
Chop blank line.
Not sure if changes to these check methods are required -- was there a discussion somewhere about it? At least tests are missing for these changes.
``` return datetime.datetime(1970, 1, 1, tzinfo=timezone.utc) ```
`value` or `return_value`? or maybe we should swap these lines: ```python if ( not timezone._is_pytz_zone(current_timezone) and timezone._datetime_ambiguous_or_imaginary(value, current_timezone) ): raise ValueError('Ambiguous or non-existent time.') return timezone.make_aware(value, current_timezone) ``` :thinking:
Trailing dot is missing.
`# Sendfile is used only when file_wrapper has been used.`
We should clean `FILE_RESPONSE_HOLDER` in `finally` to ensure tests isolation, e.g.: ```python try: # Verify that sendfile was used which only happens if file_wrapper got # used. self.assertTrue(handler._used_sendfile) # Fetch the original response object self.assertIn('response', FILE_RESPONSE_HOLDER) response = FILE_RESPONSE_HOLDER['response'] # The response should have been closed ... self.assertIs(response.closed, True) # ... as well as all individual file buffers buf1, buf2 = FILE_RESPONSE_HOLDER['buffers'] self.assertIs(buf1.closed, True) self.assertIs(buf2.closed, True) finally: FILE_RESPONSE_HOLDER.pop('response', None) FILE_RESPONSE_HOLDER.pop('buffers', None) ```
This is the default charset in Django, I wouldn't call it unusual :)
This isn't Django's default charset (unless I'm mistaken).
Ah. It is because we are pre-populating `self.records` before the `yield` in the context manager. Changing to `defaultdict` means that the key only gets added after when the context manager is exiting and we do `self.records[name].append(end_time)`. This means that nested uses of `time_keeper.timed()` - as we do in the database setup -- end up being out of order.
```suggestion new_record = '%s took %.3fs' % (record, record_time) ```
Should we name this `print_results` or move the `sys.stderr.write()` call outside? (I don't know if there would be a use for returning the generated text for something other than printing it out.)
It seems that the `timing` parameter is doing too much work. We're storing it in the runner, plus passing it down to the time keeper class, for it only to be used here. Q: why is it the time keeper's job to choose whether output is displayed by the runner? (A: it's not) I think two classes would be better than the conditional. `TimeKeeper` and `NullTimeKeeper`, then in the runner we don't store `timing` but just do: ``` self.time_keeper = TimeKeeper() if timing else NullTimeKeeper() ``` `NullTimeKeeper` should implement no-ops for `timed()`, `append()` and `results()` and just a single `yield` for the context manager.
I think this should be instantiated by the runner, rather than a global instance. Otherwise multiple runs in the same process share state (imagine a script that calls `call_command('test')` in a loop).
> For the sqlite3 case the connection will never close (it can't) so the test will fail. The bug can only be reproduced with postgresql oracle and mysql so testing sqlite is pointless to me. Keep in mind that while the default test settings use an in memory SQLite database running the suite with a file based SQLite database is a valid setup that should be accounted for.
Also, if you are using a context manager, it seems like you want to assert calling `is_usable()` right before you close (so after the context manager closes).
If the line length bothers you, I think dropping "database" would be fine.
The `index_type = indexes['reporter_id'].pop('type', None)` pattern from the old test should be used rather than a loop -- otherwise, if there' some mistake in the if-condition or if the loop is empty, it's not certain that this assertion will ever run.
I don't expect index names to change radically in the future, if at all, but even if it does, I think simplifying the test is worth the "risk" of having to update it in the future, which seems like no big deal.
Ah right. You noted on the ticket that's not the case with the 'spawn' mode, but I guess we shouldn't concern ourselves with that right now, as the test runner doesn't support that. @Valze - maybe make a note for your spawn-mode GSoC project? 😉
I think we should check if it's not already enabled: ```python if not faulthandler.is_enabled() and enable_faulthandler: ```
`file` supports file descriptors so we can use the same workaround like `pytest`: ```python try: faulthandler.enable(file=sys.stderr.fileno()) except (AttributeError, io.UnsupportedOperation): faulthandler.enable(file=sys.__stderr__.fileno()) ```
You won't need to pass `INFO` if the default is `INFO`.
Unnecessary trailing comma and white space.
I guess I would say something like "The inner CharField is missing a max_length."
`float` is clashing with python's builtin
No, at least not part of this PR.
It should be fine to check the complete warning similar to: https://github.com/django/django/blob/4d60261b2a77460b4c127c3d832518b95e11a0ac/tests/check_framework/test_model_field_deprecation.py#L17-L23 I forget if there was a reason the existing test doens't use that approach.
This could be a single line: [...]
there's no need to "cleanup" by logging out as each test creates a new test client
```suggestion '<thead><tr><th class="original"></th>' '<th class="column-name required">Name</th>' '<th class="column-position required hidden">Position</th>' '<th>Delete?</th></tr></thead>', ```
I think you could simplify this a bit by using `self.client.login(self.super_login)` and the ORM to create the initial objects instead of the add view.
I'm unsure the purpose of `ugettext_lazy` here.
@timgraham It might be more appropriate in another commit then. I believe I wanted to make sure nothing was logged if a m2m backed inline was submitted without changes.
I'm favoring contractions lately, e.g. "Don't", "shouldn't".
Could switch to single quotes as long as this is being modified.
new kwargs should be added to the end of the list just to be super safe regarding backwards compatibility.
I see before: `to_fields=[], from_fields=[self.object_id_field_name]` after: `to_fields=[object_id_field], from_fields=[]` I could very well be missing something...
I think leave the original `widget = widget or self.field.widget` here. Then do the `isinstance()` check, so that we're no repeating ourselves in the `else` block. `widgets` might then be clearer as `subwidgets`. (Or such.)
Also, doesn't this fail on Windows? Best use `python -m pip ...` to be safe...
The usual convention is to put flags before positional arguments. Move `--upgrade` before the packages.
pip >= 9.0 and setuptools >= 24.2
I'm not sure "This should not have happened." adds much. Also, use 1 space between sentences.
running -> trying to install
You had a `if not model and not hints` here before. Any reason why this is gone? The only thing I can think of, routers have to take care of `model=None` anyways, so this "precaution" isn't necessary anymore.
I think the _through_ test failure has more to do with how `RemoveField.references_field` deals with through. For example, not saying this is the right solution here, but the following diff happens to make the tests pass as well ```diff diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py index 41c389f79f..d6cbd6b9c6 100644 --- a/django/db/migrations/operations/fields.py +++ b/django/db/migrations/operations/fields.py @@ -36,7 +36,7 @@ class FieldOperation(Operation): return field_references_model(self.field, ModelTuple(app_label, name_lower)) return False - def references_field(self, model_name, name, app_label=None): + def references_field(self, model_name, name, app_label=None, reference_through=True): model_name_lower = model_name.lower() # Check if this operation locally references the field. if model_name_lower == self.model_name_lower: @@ -53,11 +53,12 @@ class FieldOperation(Operation): (not hasattr(self.field, 'to_fields') or name in self.field.to_fields or None in self.field.to_fields)): return True - through = getattr(remote_field, 'through', None) - if (through and ModelTuple.from_model(through) == model_tuple and - (getattr(remote_field, 'through_fields', None) is None or - name in remote_field.through_fields)): - return True + if reference_through: + through = getattr(remote_field, 'through', None) + if (through and ModelTuple.from_model(through) == model_tuple and + (getattr(remote_field, 'through_fields', None) is None or + name in remote_field.through_fields)): + return True return False def reduce(self, operation, app_label=None): @@ -186,6 +187,11 @@ class RemoveField(FieldOperation): def describe(self): return "Remove field %s from %s" % (self.name, self.model_name) + def references_field(self, model_name, name, app_label=None): + return super().references_field( + model_name, name, app_label=app_label, reference_through=False + ) + def reduce(self, operation, app_label=None): from .models import DeleteModel if isinstance(operation, DeleteModel): ```
The previous return value was `not operation.references_field` which meant 1. `not True -> False`, if the operation refers to the field block optimizations through. 2. `not False -> True`, if the operation doesn't refer to the field allow optimizations through. You proposed change makes it the other way around.
What about this? ``` Returns a list with 0, 1 or 2 operations: the actual operation should be replaced by the list Returns None: the pair cannot be optimized Returns True: the operation doesn't affect another 2 operations when they are optimized Returns False: the operation does affect another 2 operations and they cannot be optimized ```
OK we can revert my suggestion, sorry. `RenameModel()` doesn't change `db_table` so `old_db_table` can be different from `new_db_table` only when `db_table` is not defined.
I wasn't suggested that, but perhaps it would make the test more readable/clear, lest someone copy the current pattern.
:+1: using a single query with `annotate()` should help here.
`).order_by('name')` on next line
has very high precision so we can test this on...
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
That link appears to be Python 2.7, correct? Python 3.3+ looks to behave differently.
What's the rationale for defaulting charset to 'us-ascii'? Given the way the default is calculated in cpython, it seems like this could result in a behavior change when we remove `SafeMIMEText.__init__()` when our workarounds are no longer needed.
maybe a module constant could make this slightly more readable? e.g. `RFC5322_EMAIL_LINE_LENGTH_LIMIT = 998`
has the side effect of shortening... (no dash needed)
too many newlines (check code with flake8).
A minor matter of style, but "GO below this line" isn't needed. All you need is the section header. I'd also suggest making the header more prominent - precede and follow the header text line with a line of `####` that goes the full width (or to col 76, anyway - 1 indent back from max line length) of the code. ``` ########################################################################### # Deprecated methods ########################################################################### ```
Wording of this error is awkward. I'd suggest: "(old api) is an unofficial API that has been deprecated. Usage of (old API) may be able to be replaced with a call to (new API)"
get_fields() (add parenthesis) to distinguish it from other alternatives which are properties
Indentation can do a lot for legibility here: ``` fields.update( (field, (field.name, field.attname)) for field in self.local_fields if include_non_concrete or field.column is not None ) ```
As with `@raise_deprecation`, this should be a module-level utility, not a method on the class.
Is this still simulating a read-only database if the mocking is removed? This test might be obsolete considering the exception catching in `check_migrations()` is removed. Some low level tests for the modified `MigrationRecorder` methods might be in order instead.
I think you're talking about the other test. This one passes and fails without `autospec`.
I haven't used `autospec` before and it's used just once in Django's test suite. If you could give a quick description of why it's useful here, that'll help me learn something.
`targets` is an empty list when `MIGRATE` is `False`: ```suggestion executor.migrate([], plan=[]) ```
Yes, please rebase the branch and remove the try/fail pattern as done in 6729b96d8a15048b2295c916c5b881a59d9417a0. If you're unfamiliar with the process you might find https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/working-with-git/#rebasing-branches helpful.
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
`band_input`, you don't get much by saving one char :-)
I think `enumerate` would work here
prefer hanging indent style with 1 arg per line
Actually I would probably keep most of those exceptions as a single line -- we prefer long erlines when it improves readability.
Please check test coverage carefully. I didn't spot a test for this change.
Add trailing comma.
Remove the blank line.
I don't think we need the extra assignment here as this is only used once.
No point in assigning to `path` when used once. Also this doesn't seem right. I think you meant `__qualname__` rather than `__module__`? Which probably also means some tests are lacking...
If changing the messages, please update them in `docs/ref/checks.txt` as well.
Put the `not field.many_to_many` first and the `isinstance()` second, please.
We can pass `opclasses` to the `super()._create_index_sql()`.
comma before "and"
argument ordering should be reversed
use single quotes
Please use at most one underscore, double underscores trigger name mangling which makes subclasses easier to use.
no need for parens
I don't mind either way, it just took a second to spot the differences between the groups.
I'd chop every other empty line and group the `auto_now` and `auto_now_add`, but that's just cosmetics.
```suggestion return f'Remove collation {self.name}' ```
I think it's too late for this check, `locale` shouldn't be an optional argument.
```suggestion return 'Create collation {self.name}' ```
We should also remove `self.collation_exists(schema_editor, self.name)` checks.
Collations are not the same as extensions, they are not determine by names. IMO we shouldn't use `IF (NOT) EXISTS` syntax but fail loudly instead. It can create a tricky issues when we will omit creating collations just because the collation with the same name already exists.
This doesn't work with many conditions, e.g. `a ^ b ^ c` see `XorLookupsTests.test_filter_negated()`.
```suggestion # Convert `A XOR B` to `(A OR B) AND NOT (A AND B)`. lhs = self.__class__(self.children, OR) rhs = self.__class__(self.children, AND, negated=True) return self.__class__((lhs, rhs), AND, self.negated).as_sql(compiler, connection) ```
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
Looking at this, this one picks first source as self.source. Above self.col is picked from last target. Should we just throw an error for multicolumn expressions? I bet they don't work currently in any sane way, so lets not pretend they work.
`fake_user_data` is not passed to the `create_superuser()`.
shorten line (rule of thumb I'm using is ~120 characters so I don't have scroll horizontally in github review)
`CustomUserWithM2MAndThrough` -> `CustomUserWithM2MThrough`
Manager will raise a different `IntegrityError`, e.g. _"The row in table 'auth_tests_customuserwithfk' with primary key '1' has an invalid foreign key: auth_tests_customuserwithfk.group_id contains a value '-1' that does not have a corresponding value in auth_group.id."._
This looks unnecessary.
Please put the test in `AdminActionsTest`.
Try to avoid two branches and lots of code duplication here. You should be able to handle both cases in single path.
Do we need to use `self.restricted_objects` multiple times? I would simplify this, e.g. ```python for model, fields in self.restricted_objects.items(): for field, objs in fields.items(): for obj in objs: raise RestrictedError( "Cannot delete some instances of model '%s' " "because they are referenced through a restricted " "foreign key: '%s.%s'" % ( model.__name__, obj.__class__.__name__, field.name, ), objs, ) ```
Actually, wouldn't it be technically possible to make dynamic `from_queryset` managers directly reconstructable using a similar technique as you used for `as_manager`? As long as the base manager class and queryset class are stored somewhere, you could save both of them and use them both to reconstruct.
Oh, I guess that would only work if you used the `class_name` argument, and matched it to the name you assign it to. Still, I think the error message might be more clear and accurate if it said "Managers created dynamically using `from_queryset` must be importable: inherit from them or assign them to a module-level name." or similar.
`regex` will be clunky. IMO unnecessary `JOIN`'s are acceptable in this case, there is not much we can do.
This solution introduce really unexpected behavior, i.e. change every raw SQL that contains name of any column from a parent model with that column, e.g. if a parent model contains column `name` then following examples will be replaced by `"annotations_store"."name"`: - `case when name='foo' then 'oof' else 'foo' end` -> `"annotations_store"."name"`, - `concat(chain, 'name')` -> `"annotations_store"."name"`, - `other_column_with_name_in_it` -> `"annotations_store"."name"`, etc.
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
Both approaches work but I wonder if we'd want to be a bit more liberal here and simply return `copy` if no `output_field` can be retrieved. ```suggestion field = getattr(copy.lhs, 'output_field', None) if field is None: return copy ``` It would also avoid having to specify an explicit `output_field` when using a `Func` and `RawSQL` when users usually know what they are doing.
Good catch :dart:
I'd vote for making `returning` a `property` instead of a stealth field option at least for now because this is not something we've done in the past. ```python @property def returning(self): return hasattr(self.default, 'as_sql') AutoField.returning = True ``` That would make `DateTimeField(default=Now)` work and avoid the ambiguity of `default=Now, returning=False`. We'd still have to deal with backends that don't support returning fields.
I'd use a classmethod to provide the default index type (I think that's cleaner than resetting the attribute in the initializer)
```suggestion pk_setting = getattr(self.app_config, 'default_auto_field', settings.DEFAULT_AUTO_FIELD) pk_class = import_string(pk_setting) if not issubclass(pk_class, AutoField): raise ValueError("Configured default auto field '%s' is not a subclass of AutoField." % pk_class) auto = pk_class(verbose_name='ID', primary_key=True, auto_created=True) ```
I see before: `to_fields=[], from_fields=[self.object_id_field_name]` after: `to_fields=[object_id_field], from_fields=[]` I could very well be missing something...
I guess we could defer `check_field_default_support` to a system check instead? It could also be performed in `db_default_sql` for good measure.
Why this solution doesn't use `capi.copy_ds()`? :thinking:
Wrap docstring at 79 chars.
Use hanging indentation: ```python raise TypeError( 'Transform only accepts SpatialReference, string, and integer ' 'objects.' ) ```
Chop blank line.
This cleanup is not related with a patch please move it to a separate commit/PR.
Doesn't exist in 1.5, be careful when backporting
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
chop blank line
This import should be alphabetized, but we can fix that up when committing.
should use `RemovedInDjango110Warning`
I think we should revert the logging changes as it appears we're adding additional logging calls where they didn't exist before.
My mistake on 500, but "NOT FOUND" is different from "Not Found"
I think `get_exception_response` would be a better name for the method.
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
I would prefer to omit it for now.
Yes it should be `R.p`, we didn't take into account nested protected relations in the ab3cbd8b9a315911248227208630a020cedca08f (probably my fault). Also casting to list is not necessary anymore after this change.
I don't think that we need 3 authors and 6 books for this test. I will remove the last author.
use single quotes throughout params also, if the params fit on the same line as `Thing.objects.get_or_create(` that's fine. You could change "does_not_exist" to "nonexistent" and "some_value" to "b" to save a few characters if it helps with line length.
I removed it.
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
this doesn't need a separate test class, insert the test after `test_name_contains_double_underscores` which tests E024
We can use one model with two fields instead of two models.
I don't see much value in using `self.subTest()` here.
``` 'BinaryField default cannot be a string, use bytes content ' 'instead.' ```
I would omit the parenthesis in these messages (I know it's done elsewhere, but "I am at war" with that style unless you like it).
`ChoiceFormSet` -> `ArticleFormSet` You mixed `Article` with `Choice` in few places.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
Please chop unnecessary blank lines.
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
Use hanging indentation (the same in the second test).
I think we want to avoid altering `self.extra` here and pass `db_type` as a kwag to `super().as_sql()`.
These should be sorted alphabetically, i.e., `'Chr', 'Concat' ...` and wrapped at 79 chars.
As above. This line doesn't need to change.
I'd use `*args, **kwargs` for arguments that are simply passed-on without being accessed or modified, to reduce the number of places that a change in signature would need to be reflected, and to avoid having to repeat the same default values. We've had issues in the past in Django (in forms/formsets, IIRC) where the default value for some parameter to a superclass method changed, or a new optional argument was added, but nobody remembered to update subclass method signatures accordingly, causing bugs.
The problem here is that you can't just use `Value('')` for the default. If you're doing `GREATEST(date_field, other_date_field)` then coalescing a date type with a char type is going to produce an error. The type itself will probably have to accept a default. ``` sentinel = object() def __init__(self, *expressions, **kwargs): ifnull = kwargs.pop('ifnull', sentinel) if ifnull == sentinel: raise ValueError('ifnull is required') if ifnull is None: # user has asked NOT to use coalesce else: self.ifnull = self._parse_expression(ifnull) ``` And then you would use `Coalesce(expression, self.ifnull)` in the coalesce method, or completely skip calling the coalesce method if `ifnull is None`. This is just one idea, but probably the best one I have right now. I don't really like forcing a user to provide an `ifnull` though, because it feels like we're disadvantaging the user. Another idea would be to use a backend feature. Something like `greatest_least_uses_nulls`, and then the tests could switch on that feature flag to provide different test results. I'd probably like to get a rough consensus on which way to go here.
IMO both cleanup should be added in `_start_server_thread()`, i.e.: ```python @classmethod def _start_server_thread(cls): cls._live_server_modified_settings = modify_settings( ALLOWED_HOSTS={'append': cls.allowed_host}, ) cls._live_server_modified_settings.enable() cls.addClassCleanup(cls._live_server_modified_settings.disable) ... cls.server_thread.start() cls.addClassCleanup(cls._terminate_thread) ... ```
```suggestion # LiveServerTestCase's change to ALLOWED_HOSTS should be reverted. ```
Can we move this conditional out of the loop? (I see it was copied from `_fixture_setup`.
```suggestion cls.set_up_called = True ```
```suggestion def check_allowed_hosts(cls, expected): ```
btw `reversed(x)` doesn't actually iterate the whole list in reverse in python 3, you just get a `list_reverseiterator`... ``` In [1]: reversed([1]) Out[1]: <list_reverseiterator at 0x105098b70> ``` :)
the `reversed` call isn't free, it's slightly more optimal to put the wrappers in the list in the way you want to iterate them
`{'connection': self.db, 'cursor': self}` is faster and imo clearer. `dict(foo=bar)` actually goes through two dict creation steps: first it creates the keyword args dict, then it finds the global name 'dict' (which could refer to anything), then it calls that name which creates the final dict.
It would be more readable to pass boolean arguments as keywords, e.g. `many=False`.
The current idiom might be required because some backends (perhaps third-party ones) choke on empty `params`. I'd keep it.
Please revert this change, `verbosity` is necessary.
Please revert this change, `verbosity` is necessary.
This can be single-lined.
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
This should be in the `finally`: ```python with self.temporary_migration_module(module='migrations.test_migrations'): try: ... finally: # Unmigrate everything. call_command('migrate', 'migrations', 'zero', verbosity=0) ```
an INSERT a RETURNING
It's rather rare that folks have the Oracle database engine installed locally, so it crashes because `expdp` and `impdp` are not available.
You should try to reuse `connection._connect_string()`.
Should this be in a try/finally in case the assertion fails? I see some other test errors in that case.
I'd split this line in two
`tempfile.TemporaryDirectory()` can be used as a context manager: ```suggestion with tempfile.TemporaryDirectory() as temp_dir: ``` The other tests were cleaned up in #13211.
Okay then, no worries. As context managers are a regular, routine Python idiom, even outside tests, I find them quite readable (even with the indentation) and I find it makes the clenaup extremely explicit. Both forms work, though.
I'm not seeing what the benefit of that would be. `self.addCleanup(self.temp_dir.cleanup)` calls `cleanup()` which removes the finalizer so there isn't a warning.
Maybe it would be nice to put the shared test logic into a helper method.
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
The test won't run if it's in the database router.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
argument ordering should be reversed
I see. I guess I would like to understand the test failure a bit better -- what's causing the cross database relation in the first place. I see it's something to do with content types and permissions (probably unrelated to what's being tested here).
@adamchainz Does it work for you? :point_up:
This is funky and looks wrong, couldn't we just do the two lines here instead? ``` context = self.get_context_data(**kwargs) return self.render_to_response(context) ``` Also I don't know if it's been mentioned but rendering during a successful POST shouldn't really be done, Django uses the [“post-redirect-get” pattern](https://en.wikipedia.org/wiki/Post/Redirect/Get) everywhere in normal forms to avoid refreshes causing repeat actions. Couldn't we apply that here? Perhaps complicating things a lot though...
> The browser resubmits the "logout" tab, and the user is logged out again. The browser asks whether it should resubmit POST requests no? But you are right it is not 100% nice if `next_page` is not used.
> Yes they do, but I think on restarting and being presented with confirm on top of a blank screen, most people would just click "yes, resubmit". Resubmit raises 403 in such case, so I don't think it's an issue: https://user-images.githubusercontent.com/2865885/160332701-2a502657-ebe6-4a37-97d7-fa625856e9c9.mp4
Do we need an inner import? `from . import urls` should work fine.
Yeah, I think that falls into YAGNI territory. Better to just do the simpler and faster thing for now, and add indirection later if/when we actually need it.
What is the benefit of having these `set_fields_cache` and `get_fields_cache` methods, over just accessing `instance._state.cache` directly? The only apparent reason is so that you can pass in a field and have `field.get_cache_name()` automatically called, but that could just as well be handled in the field mixin (and it's better handled there, as that keeps the encapsulations cleaner).
Maybe `related_managers_cache` for consistency with `fields_cache` :thinking:
Please wrap: ``` # If true, uniqueness validation checks will consider this a new, unsaved # object. Necessary for correct validation of new instances of objects with # explicit (non-auto) PKs. This impacts validation only; it has no effect # on the actual ```
```suggestion # See e.g. create_forward_many_to_many_manager(). ```
add trailing comma on kwargs
Maybe we could test that `name_color_uniq` is also in the message? ```suggestion with self.assertRaisesMessage(ValidationError, 'name_color_uniq'): ```
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ```suggestion msg = ( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ```
`field` variable is unnecessary: ```suggestion msg = "TwoFields has no field named 'nonexistent'" with self.assertRaisesMessage(FieldDoesNotExist, msg): TwoFields.objects.bulk_create(self.data, update_conflicts=True, update_fields=['nonexistent']) ```
I had suggested doing this before computing `good_origin`: https://github.com/django/django/pull/13829#discussion_r579863426 That way you can avoid the two method calls and string construction in favor of a set membership check.
Maybe test whether `r.headers['x-foo']` is set or something? (`CaseInsensitiveMapping` itself is probably thoroughly tested but it may be useful to verify the case insensitivity here too)
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
👍 Here's a random example if you needed one: ``` >>> urlparse('http://[') ValueError: Invalid IPv6 URL ```
This test works without the patch, I will move it to a separate commit.
Use `django.utils.datastructures.OrderedSet` to make it clear what you are using this datastructure for.
I would filter that first, via a generator. I think this might be more readable. ```python lists = (lst for lst in lists if lst) ``` or ```python lists = filter(None, lists) ```
You could do solve this recursively, but I don't know if this better readable really. meh
Why don't you make unique_items a `set` too? This would save you the whole `not in` clause. You just do `Set.add` which will add the item if it's not in the present anyways ;) That being said, since you are adding all items of the list to a set. Just create a set from the list. This will be a lot faster, since the `in` clause performs only at `O(n)`.
Please use a single quote.
If it has some readability benefits, it could be done in a separate PR. This looks okay for now.
There is not need for an extra variable (`expected_repr_response`), also, we should call `__repr__` directly: ```suggestion self.assertEqual(repr(r), '<StreamingHttpResponse status_code=200>') ```
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
`aiter` is new in Python 3.10. https://docs.python.org/3.10/library/functions.html#aiter Django 4.2 will support Python 3.8, and 3.9 too.
This is the default charset in Django, I wouldn't call it unusual :)
I don't think try/except/fail is a good pattern. See 071801ccff970682a799ce754431a3c3ce3d6902 for the reasoning.
@MarkusH Cleaning up all the tests like this makes sense of course, but since this particular test is not yet committed and the change is rather trivial - it can be done before commit as well (and serve as an example of a good test later). Besides, cleanup may happen but it might not as well for a plenty of reasons (no resources, unexpected difficulties, etc), so imo it's better to do this now with this particular test. Why should one commit something that already needs cleanup? Hope this makes sense.
these assertions would fit on 1 one
Ah I think you could use `assertTrue` without issues as both `1` and `True` are truthy. ```suggestion self.assertTrue(field.null_ok) ```
`editor` is not required to create an instance of `DurationField` or to call `column_classes()` that's why I kept these out of the context manager.
The only allowed values for `view_on_site` are a boolean or a callable thus you can safely use the `self.view_on_site` conditional here.
Correctly indent the bracket to match the `return` indentation.
We can safely assume `hasattr(self, 'view_on_site')` will always be `True` here.
consider removing (I don't think we could ever get here and the default is to return None anyway)
revert -> use
I guess this means that the line below could be replaced when only Python 3.5+ is supported. It would be nice to be more explicit about that.
Use PEP257 verb style (Encode, return, etc.)
I envisioned something like this: ``` python content = None with open(path, read_mode) as f: try: content = f.read() except UnicodeDecodeError: # If mimetype suggests the file is text but it's actually binary, # read() will raise a UnicodeDecodeError on Python 3. pass # If the previous read in text mode failed, try binary mode. if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE ```
Same style as above.
chop blank line
I think connection is a bad name to use because of database connections `django.db.connection`.
assertTrue -> assertIn
missing some trailing commas
I would deindent these ] and also include a trailing comma in case more items are added later
removing unnecessary multilines like this will make it nicer.
missing space after : (check code with flake8)
I would rather keep the current behavior, but other opinions are welcome. It could be the target of a different ticket.
`assertEqual` is fine here (also note that we use `assertEqual`, not `assertEquals` in Django)
I see, thanks for your answer. I really don't want to hold the template based widget stuff from landing any longer. I suppose this is something we could refactor later on.
I moved this test to the `tests/messages_tests/tests.py`.
types -> type
Perhaps the tuple should be a module constant somewhere so it can be reused in `validation.py`.
I'd say, "MySQL (except MariaDB 10.2+) doesn't ..."
Please chop the comma here.
Chop this link.
```suggestion with self.assertRaises((OperationalError, ProgrammingError)): ```
I'm not sure why these tests raises a `ProgrammingError` :thinking:
`field` variable is unnecessary: ```suggestion msg = "TwoFields has no field named 'nonexistent'" with self.assertRaisesMessage(FieldDoesNotExist, msg): TwoFields.objects.bulk_create(self.data, update_conflicts=True, update_fields=['nonexistent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ```suggestion msg = ( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ```
Please add a trailing comma: ```suggestion update_conflicts=False, update_fields=None, unique_fields=None, ```
I think it's something like: 'browser' contains the first browser to run the tests against and 'browsers' will contain the rest of the browsers (if more than one are requested).
quit() .... to avoid a dead.... (chop "we" stuff)
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
Wouldn't it be a bit more helpful for this error message to specifically note that the module with the given path couldn't be imported? "Invalid" is a very vague term, which could mean all sorts of things - it seems unhelpful to silence an `ImportError` and replace it with a much vaguer message.
use same indent style as previous item
These two permissions are never used. Please remove them. `cls.permissionuser` is only used in `test_simple_inline_permissions`. Create it inline there rather than on the class.
Please add a trailing comma.
I think you could use `self.assertSequenceEqual` rather than this.
@timgraham already pointed the code formatting of the tests. Please don't make newlines at dots, `tests/annotations/tests.py` has good examples of the style.
One solution here would be to make `enable`/`disable` idempotent by having a class level `enabled = False` attribute that gets set/unset and checked for early return in both methods or to override `__exit__` to deal with `exc_value == self.enable_exception` in a special way.
You are right I missed the fast that exceptions raised during `__enter__` are not going to go through `__exit__` sorry for that. That makes these tests unnecessary.
Use `as e` or as `as exc` to match other code.
I don't think we need this here. In `disable()` we `raise self.first_exception` (when `not None`) so this line will be unreachable.
Ahh didn't notice `_modified_settings` could have duplicate items.
According to the `Node.render` docstring it should "Return the node rendered as a string" so if we really wanted to optimise for speed, we could potentially forgo the `str` as well, but I think probably better safe than sorry here, so better to leave it in.
The one place this branch might happen is if someone has used `register.tag` to register a tag that doesn't return a `Node` instance. It makes pretty clear in the docs that you should return a `Node`, but it feels like that someone could very easily fall into the trap of not doing so. Since (up until now) such an error would still work (I think) the error would go undetected. As such, maybe a release note could be warranted? It would mean that if some tags suddenly break upon updating Django, then the release notes would provide an avenue for investigation. On the other hand, perhaps I am overestimating how likely this is. 🤷
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
I can't be sure it is performance critical without testing but it looked like it could be when dealing with large loops. I just suggested it because a ticket was recently opened about a template performance regression in between 1.7.x and 1.8.x if I remember correctly.
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
Python2 does not support `super()`.
I wonder if we can just set `default_time_format` attribute.
Yes, that's better.
I think it's fine to make them a bit inconsistent (at least for now). I opened an [issue](https://bugs.python.org/issue40300) in Python.
This change turns this into a confusing/possibly-useless test. What is the response content? What assertion can we make about it? The universe of "things which are not the empty string" is very large, and includes many things which would be wrong.
Why is this way preferable to ```suggestion def _check_token_present(self, response, csrf_secret=TEST_SECRET): ```
Personally, I like this because you can pass `None` to get the default value. We can decide to change, but it should be a part of a separate PR.
I think keeping the explicit `process_response()` call here would make sense. By changing to `__call__()` we're running through `process_request()`, which is not a no-op, which is perhaps fine but it's subtly changing the intent/behaviour of the test. (I guess this is something we'd have to think about removing the `process_x()` hooks, but not in this PR) Same for line 677 below. **Update**: Tests in `csrf_tests` are more explicit about this... (So maybe the small change here is OK)
On balance I will leave this one as it is.
This and similar assertions added for `bloom`, `btree`, `hash`, `gist`, and `spgist` are not related with this patch, and they're unnecessary. Index types are already checked in ``` self.assertEqual(constraints[index_name]["type"], ...) ``` Please remove them.
single line looks okay here
To have more balanced line length, I think I prefer: ``` python constraints = self.get_constraints(IntegerArrayModel._meta.db_table) self.assertEqual(constraints['integer_array_model_field_gin']['type'], 'gin') ```
"its" (but could chop "and it's type" I think)
single line looks okay here
this doesn't pass flake8, I'd probably create a separate variable so you don't need funky indentation. ``` file_storage_settings = ( 'MEDIA_ROOT', ... ) ```
I think we should catch `ImportError` and return appropriate message, e.g. ```python try: pk_class = import_string(pk_setting) except ImportError: msg = 'The module %r could not be imported.' if hasattr(self.app_config, 'default_auto_field' ): msg += 'Check your %s.default_auto_field attribute.' % self.app_config else: msg += 'Check your DEFAULT_AUTO_FIELD setting.' raise ImproperlyConfigured(msg % pk_setting) ``` We could also add a cached hook, `get_default_auto_field()`.
```suggestion pk_setting = getattr(self.app_config, 'default_auto_field', settings.DEFAULT_AUTO_FIELD) pk_class = import_string(pk_setting) if not issubclass(pk_class, AutoField): raise ValueError("Configured default auto field '%s' is not a subclass of AutoField." % pk_class) auto = pk_class(verbose_name='ID', primary_key=True, auto_created=True) ```
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
I believe this should included in the `_check_default_pk()` with a different check, e.g. `fields.E102`.
Since we don't have to support old python versions anymore, you can use the `@property` syntax, which I think is more readable.
If you can try to make logical commits with the tests passing after each one as in https://github.com/django/django/pull/3770, I've found that quite helpful as a reviewer.
If possible, it would be great to try to submit cleanups like this as separate pull requests that can be merged ahead of the main composite field work. Otherwise, I fear we will end up with a monolithic pull request that will be very difficult to review.
I've noticed that `None` from `flatchoices` should update `Unknown` not `All`. I fixed this.
you have essentially built a list comprehension, see below
The main question is what to do with these tests? We should analyze them one by one and prepare alternative versions only with `unique_together` (if necessary). I'm afraid that we cannot simply remove them when deprecation ends because we will end with many not covered scenarios. For example: ```python diff --git a/tests/migrations/test_autodetector.py b/tests/migrations/test_autodetector.py index 547e0b32c5..4c19a34d7f 100644 --- a/tests/migrations/test_autodetector.py +++ b/tests/migrations/test_autodetector.py @@ -2441,10 +2441,10 @@ class AutodetectorTests(TestCase): self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterField"]) + # RemovedInDjango51Warning: When deprecation ends rename to + # test_empty_unique_together(). + @ignore_warnings(category=RemovedInDjango51Warning) def test_empty_foo_together(self): - """ - #23452 - Empty unique/index_together shouldn't generate a migration. - """ # Explicitly testing for not specified, since this is the case after # a CreateModel operation w/o any definition on the original model model_state_not_specified = ModelState( @@ -2457,7 +2457,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": None, + "index_together": None, # RemovedInDjango51Warning "unique_together": None, }, ) @@ -2468,7 +2468,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": set(), + "index_together": set(), # RemovedInDjango51Warning "unique_together": set(), }, ) ```
We should mark all tests and model states that use `index_together` in `tests/migrations/test_autodetector.py` for removal. We can also move them to a common class for easier remove when deprecation ends.
A note in `docs/internals/deprecation.txt` is missing.
`codename %= ...`
`cls.__name__.lower()` is the same as `self.model_name`. I guess `model_name` would probably be a better placeholder name.
You probably don't want this to be a class-level attribute, because they are exactly that (class-level, not object-level). The better approach is to accept an optional timeout argument to `__init__` and store that on `self` to later be passed in to `smtplib.SMTP`.
Thank you for the contribution & taking on the ticket! :smiley_cat:
Whoops, just realized the original author was someone else! Sorry about that. Nonetheless, thanks for discussing!
Ok, I'm +1 on your approach. Thank-you very much for the review and feedback.
This should be a subclass of `ValueError`, IMO.
```suggestion self.resolve_model_field_relations(model_key, name, old_field) ```
```suggestion self.resolve_model_field_relations(model_key, name, field) ```
It looks like you can actually do `fields = self.models[model_key].fields` (similar to further down) since you're only using `model_state.fields` below.
You can reuse `resolve_model_field_relations()`.
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
Glad to see this gone.
This behaves quite unexpected with database functions on some databases (SQLite or MySQL). For example: `~ExtractYear("start_datetime")` crashes on PostgreSQL but returns `False` on SQLite and MySQL :open_mouth: I'm not sure if we can and should do anything about it :thinking:
Please use single quotes.
I think that you can add `filter` to `kwargs` in `__init__` method and remove redundant `__repr__` (see #8759).
Passing `filter` to kwarg will cause it to be in `self.extra` as well which could interfere `as_sql()` formatting.
repetitive with method docstring
Please move this ref below, to the place when we actually use it (for defining flags).
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
prefer hanging indent style: ``` GDAL_TO_CTYPES = [ None, ... .... ] ```
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
Do we need an inner import? `from . import urls` should work fine.
As the code itself hints, there's no reason to assume the imported attribute is a class.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Silencing far more exceptions than previously (where it was `ImportError`) ... is this intentional, and will it lead to people having a harder time debugging when their app config goes wrong? I guess it'd be somewhere higher up the chained stack traces, maybe? Same expansion of caught exceptions (`ImportError` -> `Exception`) happens at the `import_string` so I assume the answer to this also answers that.
This can be single-lined. Also, please use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion custom_libraries = conf.get('OPTIONS', {}).get('libraries', {}) ```
By using an extra `continue` we reduce the indentation. I also propose that we change the hint message when depending on whether the cache path matches, is inside, or contains one of the other paths: ```suggestion if not setting: continue if name == 'STATICFILES_DIRS': paths = {pathlib.Path(dir).resolve() for dir in setting} else: paths = {pathlib.Path(setting).resolve()} for alias in settings.CACHES: cache = caches[alias] if not isinstance(cache, FileBasedCache): continue cache_path = pathlib.Path(cache._dir).resolve() if any(path == cache_path for path in paths): hint = f"Your '{alias}' cache path matches your {name}." elif any(path in cache_path.parents for path in paths): hint = f"Your '{alias}' cache path is inside your {name}." elif any(cache_path in path.parents for path in paths): hint = f"Your '{alias}' cache path contains your {name}." else: continue errors.append(Warning( 'Your configuration might expose your cache or lead to corruption of your data.', hint=hint, id='cache.W002', )) ```
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
I think the formatted pattern should be wrapped in quotes. "Your URL pattern '{}' uses..".
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
I would prefer to wrap value with `Value()` and compile `options` separately.
@hannseman Thanks :+1: > I prefer it over the mixin approach. Yes me too :+1: . We can move `Value()` wrapping to the `__init__()` and simplify it a bit, e.g.: ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) if not (config and hasattr(config, 'resolve_expression')): config = Value(config) self.config = config def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save) resolved.config = self.config.resolve_expression(query, allow_joins, reuse, summarize, for_save) return resolved def as_sql(self, compiler, connection): sql, params = compiler.compile(self.config) return '%s::regconfig' % sql, params ``` Please move introducing a `SearchConfig` expression to the separate commit, or even PR.
append instead of creating a new list ```suggestion options_params.append(', '.join(options)) ``` All off the above could also be reduced to ```python options_params.append(', '.join( '%s=%s' % (option, psycopg2.extensions.adapt(value).getquoted().decode()) for option, value in options.items() ))
IMO we should check options against PostreSQL names.
The usual pattern is to implement `get_source_expressions` and `set_source_expressions`. ```python def get_source_expressions(self): return [self.config] def set_source_expressions(self, expressions): self.config, = expressions
```suggestion self.assertEqual( ```
You missed a backtick at the end of the line.
`# Values provided in the form's data are ignored.` Might be good to have a test for `Form(data, initial=...)` too.
Why `BORN` is uppercased? :thinking: ```suggestion # Add new Country from the born_country select. ```
I think we could simplify the test by simply testing the presence of 3 occurrences of `<option value="0">empty_label</option>` in the result.
I'd tend toward checking at the boundaries rather than some random value.
This isn't Django's default charset (unless I'm mistaken).
Can you include latin-1, non-ASCII characters? `café` is one of the few English words matching this requirement. `Just latin-1 :)` will encode identically in ASCII, latin-1 and utf-8, making the tests much less interesting.
This is the default charset in Django, I wouldn't call it unusual :)
I'm not sure splitting this out to a separate function makes the code easier to follow.
removing unnecessary multilines like this will make it nicer.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
I would deindent these ] and also include a trailing comma in case more items are added later
Yes we should test a real use case instead of emulating this path.
What about ```suggestion self.assertNotIn('is_book', books.values().first()) ```
Ahh looks like you'll need to keep passing `Value` in this case but you can drop the `output_field`. ```suggestion is_book=Value(1) ```
No need for `Value` wrapping since 1e38f1191de21b6e96736f58df57dfb851a28c1f ```suggestion is_book=1, ``` Ditto for all `Values` uses below.
I didn't dig much into this ticket, but is it still possible to have a value type not in the list handled in `_resolve_output_field`? If yes, could we keep a test for such a value (maybe in expressions tests).
```suggestion self.assertEqual([book.rating_count for book in qs], [1]) ```
Few naming suggestions: `ordering_element` -> `expr` `ord_sql` -> `expr_sql` `ord_sql_params` -> `expr_params` `additional_sql_params` -> `ordering_params` `ord_clauses` -> `ordering_expr_sql`
Glad to see this gone.
Please chop all unnecessary blank lines.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
Turn (capitalize) add period. sql -> SQL
Switching to `assertTrue()` seems incorrect.
For consistency, use a tuple instead of a list.
I wanted to keep them isolated, without calling `cache_clear()` in both one of them will always be no-op.
Similarly, I don't see much advantage to creating indirection with a method.
I think we can use `int` instead of `str` as a default value, because that's the most common use case. After that we can remove all types mapped to `NATIVE_INT` from `InsertReturnParameter.types`.
more than one automatically generated field.? sounds better and more natural with the changes.
`'Big serial'` (`BigIntegerField` has `'Big (8 byte) integer'`, but I think we can keep this description simple.)
`form_class` is defined in `RangeField.formfield()` so this is redundant.
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
Maybe we just need to not call `str(alias)` here? If `alias` already works as a key in `connections`, why do we need to change it? That will avoid having to put `str()` calls everywhere.
I would move initialization of these variables to the `ParallelTestSuite.__init_()`.
I think it's fine to leave it.
Again, I suspect we could use `__slots__` here: ```suggestion __slots__ = ('_connections', '_settings') ```
We should run it only on Django's test suite: ```suggestion if os.environ.get("RUNNING_DJANGOS_TEST_SUITE") == "true": self.mark_expected_failures_and_skips() ``` Also I'm not sure if it's the right place :thinking: , see #15477.
We want to change whitespaces in the traceback, so we should test these changes e.g. ```python self.assertIn( ' File "generated", line 2, in funcName\n' ' <source code not available>', text, ) ```
sss :snake: ```suggestion password_help_text = form.fields["password"].help_text ```
Yes, f-strings should use only plain variable and property access as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I think the name could be a bit more specific like `include_with_dollar` to prevent clashes with possible future checks that involve include, slash, or name. Maybe a `views.py` for the dummy view so we don't need to define it in every urls file would be an improvement as well (or even something like `lambda x: x` in place of an actual view might work).
On second thoughts creating a URL with to_field isn't required to test this issue – so the string interpolation can simply be removed: ```suggestion admin_user_change_url = reverse( "admin:%s_%s_change" % (user._meta.app_label, user._meta.model_name), args=(user.username,), ) ```
We are actually only removing a single model, not multiple.
You're calling `model_name.lower()` twice in most cases
```suggestion self.models[app_label, new_name] = renamed_model ```
Yes, this should be taken care of before.
I don't think you need `list()` here.
Also `4x8.png` is left on the file system when the tests conclude.
The extra queries could be generated in this line (199), as this is where the instancies are created, so so you should check the number of queries is one.
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
We should clean `FILE_RESPONSE_HOLDER` in `finally` to ensure tests isolation, e.g.: ```python try: # Verify that sendfile was used which only happens if file_wrapper got # used. self.assertTrue(handler._used_sendfile) # Fetch the original response object self.assertIn('response', FILE_RESPONSE_HOLDER) response = FILE_RESPONSE_HOLDER['response'] # The response should have been closed ... self.assertIs(response.closed, True) # ... as well as all individual file buffers buf1, buf2 = FILE_RESPONSE_HOLDER['buffers'] self.assertIs(buf1.closed, True) self.assertIs(buf2.closed, True) finally: FILE_RESPONSE_HOLDER.pop('response', None) FILE_RESPONSE_HOLDER.pop('buffers', None) ```
Maybe: `if '\x00' in str(value):`
I'm a bit worried about the side effect of reloading this module given how much stuff depend on it indirectly. Tests are passing which is a good sign but that'll make yet another global side effect to think about when debugging weird issues with the test suite. I don't have any other idea of how to test this in another way but maybe raising the error on `DatabaseWrapper.__init__` instead could bring the same benefit while being easier to test? FWIW [we haven't tested such errors](https://github.com/django/django/blob/88619e6129fd8c6668242f1acc1465ca175d2948/django/db/backends/mysql/base.py#L35-L36) in the past and I would be ok with doing the same here.
I would use this style to save some lines: ``` msg = '....' with self.assertRaisesMessage(NotSupportedError, msg): ```
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
Switching to `assertTrue()` seems incorrect.
avoid _we_ usage as well ``` SystemCheckError is surfaced when run_checks raises SystemCheckError and teardown databases raises ValueError
I'd use a semantic test name like `test_error_raised_on_filter_with_dictionary`
I feel worried about keeping a `while True` loop here. I will lead to an infinite test run if the implementation of the code to be tested is broken. Can you change that into a for loop. You are already counting `i` upwards, but aren't using it.
prefer the context manager version: ``` self.assertRaisesMessage(FieldError, 'Cannot ..'): Note.objects.filter({'note': 'n1', 'misc': 'foo'}) ```
`context.exception.message` -> `six.text_type(context.exception)`
You can maybe remove the `i` here: ``` python for _ in xrange(20): x = Tag.objects.filter(pk__in=x) ```
Seems to fine on a single line.
Might be worth testing for the actual type.
To have more balanced line length, I think I prefer: ``` python constraints = self.get_constraints(IntegerArrayModel._meta.db_table) self.assertEqual(constraints['integer_array_model_field_gin']['type'], 'gin') ```
`e` is unnecessary. Maybe it will be better to refactor these tests and put `class` inside `try` e.g. ```python @unittest.skipUnless(connection.vendor == 'postgresql', 'Postgresql specific test.') class PostgreSQLCursorOptionsTestCase(TestCase): try: from psycopg2.extensions import cursor class PostgresLoggingCursor(LoggingCursorMixin, cursor): pass except ImportError: pass ```
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
This message shouldn't be used when constraint is defined with `expressions`.
We should pass `using` to `check()`.
> It just happens to pretty straightforward here as you can directly call `Constraint.validate` without the `exclude` on the constraint you are interested in validating. That's a suitable workaround, but I feel like it should not be necessary. FWIW before Django 4.1 where this feature was added I added manual validation already, since there constraints with conditions where just skipped.
`FieldError` is untested. Do we need it? It looks unnecessary.
We should make use of `self.message`.
Since this only works for instances with an pk, do you think that `bulk_update` would be a better name? The regular `save()` method can either create or update depending on pk status which may confuse users here.
Oh yes, there definitely was some confusion. When looking at the code, I saw references to `obj.pk` and thought we were potentially dealing with a QuerySet (which I guess that _technically_ we _could_ be, but that wouldn't be the right way to use it). My apologies! Carry on. 😋
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
Do we need to call `list(fields)` here? :thinking:
1. Add this import: from {{ project_name }} import views
1. Including another URLconf
I think we could just say, "Function views:" and omit "Example X" for each case
Dotted path isn't deprecated for `include()`
Let's be consistent about whether `app_name` appears above or below `urlpatterns`.
don't add this blank line.
This doesn't seem correct as `SimplePoFileTests` no longer has any tests in it so now this subclass doesn't do anything.
Improved typography and changed to [%-formatting](https://docs.python.org/3/library/stdtypes.html#old-string-formatting) to be consistent with other error messages.
I would add quotes: ```suggestion violation_error_message = _("Constraint '{name}' is violated.") ```
I see :/ Well `force_str` should still save you the promise checks.
`has_select_for_no_key_update` -> `has_select_for_update_no_key`
Please add trailing comma.
DatabaseError is raised if a ....
I think that: ```python return 'FOR UPDATE%s%s%s' % ( ' OF %s' % ', '.join(of) if of else '', ' NOWAIT' if nowait else '', ' SKIP LOCKED' if skip_locked else '', ) ``` is more readable.
If ...., the locked row is skipped resulting in Person.DoesNotExist.
not sure if this really passes the django style guide, compared to plain if/else statements
For similarity with other messages (e.g. 'The nowait option cannot be used with skip_locked.') you might change 'passed' to 'used'.
I think an explicit loop that mutates the dict might be clearer here, and avoid the overhead of a function creation and call. I believe we already do this elsewhere (but I haven't double checked).
I'll quickly check if an idea I'm having works here.
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
Yup, new version is better.
Seems like some slightly more intelligent code to ignore the exception (`issubclass` would do) might be more future proof to any changes in the API
Is this conditional really necessary? If it is, it means that in some cases a success message with placeholders could be returned, that sounds bad.
Just use `get_current_site()`.
Can you sort those attributes please
The variable name doesn't need to be / shouldn't be changed, IMO. (My suggestion in the ticket for a variable name was for the string argument, if that was going to be tested separately.)
TIL that character classes also work inside `[]` :D
Try to write a docstring so that looking up the details in the ticket isn't necessary. Include the ticket reference only if it's an obscure issue that would benefit from the additional context provided by the ticket.
I think we should be consistent and use double-quotes.
Yes. Adding `?:` makes it a non-capturing group which allows for use of `m.groups()` below. Otherwise it'd need to be `... = m[1], m[2], m[4]`.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
`self.assertTrue` -> `self.assertIn` above and below as well.
This isn't passing on any backends. SQLite, for example: `OperationalError: misuse of aggregate function COUNT()`.
I think this could benefit from being split in multiple test methods.
Ahh `group_by` is [trie-valued](https://github.com/django/django/blob/master/django/db/models/sql/query.py#L157-L163). I think `isinstance(self.group_by, list)` has something to do with using `values()`.
I don't think you need to test this case as it's used to denote the existence of `group_by` (it defaults to `None`). From what I understand this instance check could be replaced by a simple boolean check `if self.group_by ...`.
`test_sliced_conditionnal_aggregate()` Did this also fail without the patch applied? I see no mentions of it on the ticket.
It seems like it would be more consistent if the methods were prefixed with `get_` as `get_view_on_site_url` is. Without the prefix, I'd expect a name like `admin_index_url` to be a property. I don't see the usefulness of `admin_viewonsite_url` as a layer of indirection to `get_view_on_site_url()`.
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
Move `has_view_permission` above `has_add_permission` for consistency.
chop newline for consistency with other tests
To avoid the interesting indentation: ``` msg = "<class 'admin_views.models.Question'> is not registered in the admin." with self.assertRaisesMessage(Http404, msg): ```
You are right here as well. Your version is clearer for people that understand bitwise operators the flags structure, plus its shorter. For me he more "explicit" version is easier to follow, and probably true too for other people that do not have experience with the postgis bites structure or bitwise operators. But the conciseness of your version is convincing so lets use it.
Thanks @ivorbosloper now it makes sense to me and works fine. I got confused with upper and lower bits wording. Interesting that bits are counted from right to left from that point of view, and that the mask operation works. It would not work the same way with the `BANDTYPE_FLAGS_MASK` as my example shows.
comma after tuple
How about checking for the `ValueError` on older versions? Would be nice to have a test for the `Nodata value must be numeric or None` error as well.
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
I'd probably change this hunk in the diff to: ``` python if getattr(field, 'auto_now', False) or getattr(field, 'auto_now_add', False): default = timezone.now() internal_type = field.get_internal_type() if internal_type == 'DateField': default = default.date() elif internal_type == 'TimeField': default = default.time() # DateTimeField already has correct default now ```
If we don't and `USE_TZ=True` the default datetime used on column creation will be in the system timezone instead of UTC like Django assumes datetime are stored in the database.
should be `datetime.date.today()`
Yea, that change doesn't make sense. Thanks for explaining timezones to me, Aymeric :wink:
The diff in MarkusH's above doesn't make auto_now(_add) timezone aware, it hardcodes them to be computed in UTC instead of using `settings.TIME_ZONE`, which doesn't make sense to me.
"cannot" is one word. add period.
And this to `self.queryset`.
It's fine to include this test but since it's already passing without the fix, it's better in a separate commit.
For consistency with the rest of the code, I think you can omit the comma at the end.
The output here is suboptimal. e.g.`* p * Ensure this value is greater than or equal to 0` We need to provide custom error messages that make sense when displayed as `messages`. We should maybe add the individual messages, in a loop, rather than the list.
```suggestion functions.FromWKT(Value(g.wkt)), ```
I was just curious why we chose them, it seems that we want to test creation with manually specified `ID`. It can stay.
I think wrapping in `Point()` is causing the test crash.
We should add `annotate()` to the list, also please use hanging indentation.
`assertRaisesMessage()` (this test is broken) as it doesn't pass` on_conflict='ignore'`.
Please wrap at 79 chars.
This and the check below can be single-lined.
@carltongibson Ahh sorry :man_facepalming: I should check discussion.
Please wrap at 79 chars.
Hey @felixxm. In the end we went for not having the "or subclassed" so these changes will disappear. (`checks.txt` did previously have this adjustment, but it's gone now. These are just leftovers to be removed.)
Could we possibly skip the detection feature `if Database.sqlite_version_info >= (3, 29, 0)`? Since this is only present on macOS [could we branch off `platform.platform`](https://docs.python.org/3/library/platform.html?highlight=darwin#platform.platform)? I think this would partially address @claudep's concerns.
Ideally we can pin at `3.35` as you've done here, but perhaps we should pin at `3.35.5` because `3.35.1` included bugfixes for that new functionality, and more importantly `3.35.5` has the following fix: > Fix defects in the new ALTER TABLE DROP COLUMN feature that could corrupt the database file Though it unfortunately doesn't specify further, or linked to a ticket/discussion. ([Docs for the entire 3.35 release line, including patch releases](https://www.sqlite.org/releaselog/3_35_5.html))
Yeah I thought that might be the case, but thought it worth pointing out due to the sheer destructiveness of this specific fix in `.5` FWIW it doesn't look _entirely_ without precedent to use the patch releases (though it is _rare_), insofar as `supports_aggregate_filter_clause` is pinned to a minimum of `3.30.1` where the actual functionality was added in `3.30.0` but had fixes in the `.1` release by my reading of the release notes.
If the functionality introduced in `3.35.0` is known to be buggy, we would introduce potential data corruption issues if we use `3.35.0` in that flag. Not nice for users :-/ I'm with @kezabelle here.
This was the _Right Fix™_ last time I looked into this issue. Typically I no longer see this locally... — I shall try to reproduce, but, provisionally, should be good.
I don't see much value in this docstring.
yeah I don't see a reason why the imports are not top-level and we don't call the functions directly.
`None` is being passed for the `app_configs` argument - even though the check ignores `app_configs`, `[]` should be used as a more valid test value. I think it's worth looking into refactoring these tests in general, as you're write these property inner-imports are a bit confusing, made a note to self.
It's the pattern that django-secure used. Not sure if the reason is still relevant. \cc @carljm
I suggest: ``` self.assertEqual( csrf_cookie.value, self._csrf_id_cookie, '.....' ) ```
Please don't change all the other unaffected lines.
We don't need to call `len()`, `slice()` will work the same with `None`.
Please remove type annotations. We don't currently use them in Django.
Did you intentionally keep the unused `TemplateEncodingError` for backwards compatibility? I think it could be removed.
explain why it needs to be copied
`seprate` -> `Separate`, also trailing dot is missing.
IMO this line is unnecessary, and above `iter()` call can be removed.
This line can be removed :thinking:.
Oh I missed the fact `datetime_trunc_sql` was used by `datetimes()`. This is fixing the reported use case where `'field'` is a `DateField` but wouldn't it break in the case of `dates('field', 'day')` where `'field'` is a `DateTimeField`? It looks like it wouldn't get truncated at all in this case.
could switch to single quotes for consistency
Both approaches work but I wonder if we'd want to be a bit more liberal here and simply return `copy` if no `output_field` can be retrieved. ```suggestion field = getattr(copy.lhs, 'output_field', None) if field is None: return copy ``` It would also avoid having to specify an explicit `output_field` when using a `Func` and `RawSQL` when users usually know what they are doing.
Good catch :dart:
This makes me wonder why `SearchQuery` is a `Value` in the first place given it needs to resolve `config` and `value` now.
If look like could subclass `Func` and avoid any `resolve_expression` or `as_sql` overrides. ```python class SearchQuery(SearchQueryCombinable, Func): output_field = SearchQueryField() SEARCH_TYPES = { 'plain': 'plainto_tsquery', 'phrase': 'phraseto_tsquery', 'raw': 'to_tsquery', 'websearch': 'websearch_to_tsquery', } def __init__(value, output_field=None, *, config=None, invert=False, search_type='plain'): function = self.SEARCH_TYPES.get(search_type) if function is None: raise ValueError("Unknown search_type argument '%s'." % search_type) if not hasattr(value, 'resolve_expression'): value = Value(value) expressions = (value,) if config is not None: config = SearchConfig.from_parameter(config) expressions = (config,) + expressions super().__init__(*expressions, output_field=output_field, function=function) if invert: self.template = '!!(%s)' % Func.template ```
@hannseman Thanks :+1: > I prefer it over the mixin approach. Yes me too :+1: . We can move `Value()` wrapping to the `__init__()` and simplify it a bit, e.g.: ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) if not (config and hasattr(config, 'resolve_expression')): config = Value(config) self.config = config def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save) resolved.config = self.config.resolve_expression(query, allow_joins, reuse, summarize, for_save) return resolved def as_sql(self, compiler, connection): sql, params = compiler.compile(self.config) return '%s::regconfig' % sql, params ``` Please move introducing a `SearchConfig` expression to the separate commit, or even PR.
prefer hanging indent style: ``` GDAL_TO_CTYPES = [ None, ... .... ] ```
This constant is unused.
comma after tuple
, keeping a reference to the cyptes object so that the vsimem file...
flake8 complains about missing spaces around `*`
IPAddressField is removed from Django so shouldn't be listed.
We use `field` only to find `internal_type`, so maybe instead of storing `field` we can find and store `internal_type` in `__init__()`? What do you think? ```python def __init__(self, field): self.internal_type = getattr(field, 'target_field', field).get_internal_type() ```
I think all the defaults here should be mappings to the same type (e.g. `'PositiveIntegerField': 'PositiveIntegerField'`), so that backends have to specify the types they introspect differently.
`DATE` -> `DATETIME`
I would remove `get_field_name()` hook and call it `internal_type` (`field_name` is confusing IMO), e.g. ```python internal_type = getattr(self.field, 'target_field', self.field).get_internal_type() ```
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
Hah. Had the same thought before I got here. See the caveats mentioned above.
Unlike `_sqlite_lpad()`, I'm not sure we can really improve this. `fill_text * length` is likely to be too long in most cases, and even worse if `fill_text` is multiple characters, but any alternative will probably be slower in general.
I don't think we need the `re_` prefix to the arguments? And perhaps `text` instead of `string` for consistency? We should also avoid coercing to `str` unless we need to: ```python In [1]: text = "This is some text" In [2]: %timeit str(text) 54.7 ns ± 4.28 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) In [3]: %timeit isinstance(text, str) 33.8 ns ± 0.106 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) ``` It might make the non-`str` case slower, but, unless I'm mistaken, we're expecting `text` to be `str` in the majority of cases. ```suggestion def _sqlite_regexp(pattern, text): if pattern is None or text is None: return None if not isinstance(text, str): text = str(text) return bool(re_search(pattern, text)) ``` As an aside, I wonder whether we can do something to compile and cache patterns? This could make a significant difference if the function is called for a large number of rows.
```suggestion geom_type = gdal.OGRGeomType(self.attrs['geom_type']) ```
```suggestion 'geom_type': 'Geometry' if geom_type == 'Unknown' else geom_type, ```
```suggestion # The Widget.get_context() attrs argument overrides self.attrs. ```
Likewise, it seems odd to keep `'point'` here: ```suggestion context = widget.get_context('geometry', None, None) ```
Use single quotes consistently.
I think the warning should happen in this case, since we didn't check if files exist or not, it's better to be safe.
I think the prompt should still happen if `destination_path` is None since we don't check existence in that case. Only skip the prompt if we're certain the destination doesn't exist.
Use hanging indent: ``` destination_exists = ( self.storage.exists(destination_path) and ... ) ```
You can safely join this an the next line. You have up to 119 chars per line. ;)
Move this import to the top of the file.
This test name mentions multi-table inheritance but the body of the test has nothing to do with it.
use of one the styles in 04de4369325097472d7ad036dac262555002ba88
I guess you could use `self.assertIs(child.parent, parent)` to make sure the object was not recreated as well.
I'd omit the blank line since it's hard to get confused in 3 lines of code. Also the commit message could describe the issue being fixed instead of the implementation of the fix.
Use `assertIs(..., False)` to check for boolean attributes.
When Python 2 needs a bytestring and Python 3 a normal str, the current usage in Django is to use `force_str()`, which by default encodes in UTF-8 (on Python 2 only).
Why not do: ``` if key not in self: self[key] = value ```
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
Omit the outer `[]` to use a generator instead of list comprehension.
I tried a similar approach while working on acfaec3db5ba39de52f6e607e74343dccf72fba1 and came to the conclusion that this approach can't work (due to something like module caching). As far as I know, you'll have to register the admin to a separate `AdminSite`.
Use hanging indentation ```python raise FieldError( 'Expression contains mixed types: %s, %s. You must set ' 'output_field to %s.' % ( output_field.__class__.__name__, source.__class__.__name__, source.__class__.__name__, ) ) ```
Maybe: ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 16df317631..36f88f99ec 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -286,8 +286,15 @@ class BaseExpression: """ sources_iter = (source for source in self.get_source_fields() if source is not None) for output_field in sources_iter: - if any(not isinstance(output_field, source.__class__) for source in sources_iter): - raise FieldError('Expression contains mixed types. You must set output_field.') + for source in sources_iter: + if not isinstance(output_field, source.__class__): + raise FieldError( + 'Expression contains mixed types: %s, %s. You must ' + 'set output_field.' % ( + output_field.__class__.__name__, + source.__class__.__name__, + ) + ) return output_field @staticmethod ```
@CruxBox Please fix also `aggregation.tests.AggregateTestCase.test_combine_different_types`.
`source` will be **always** `None` so it is not a proper solution.
Might want to use a generator here to make it more readable `(field for field in self.get_source_fields() if field is not None)`.
`self._test_scrypt_upgrade('parallelism', 'parallelism', 2)` fails, it seems we shouldn't take `parallelism` into account.
> My main worry here is: Is this correct and does it make sense to implement for such a complex hasher (notably we already have others where we argue it is simply not possible in a sensible way). > > Since scrypt can raise errors like this: > > > ValueError: Invalid parameter combination for n, r, p, maxmem. > > I am wondering if `must_update` couldn't also trigger this condition. Or can we always calculate `extra_iterations` and `extra_block` and be sure that the combinations are valid? You're right parameters may no be valid, e.g. ``` self.work_factor = 2 **14 decoded['work_factor'] = 2 ** 11 ``` both are a power of 2, however `extra_iterations = 14336` is not and raises `ValueError: n must be a power of 2`.
Is there a good reason to order the data like this? I'd personally expect the hash to be at the end, so it could include a `$` .
Should also include `block_size` and `parallelism`
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
Wrap strings at 79: ``` 'You have provided values in the LANGUAGES_BIDI setting that are not in ' 'the LANGUAGES setting.', ```
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
I would keep `if not ...` in the same line.
Good point :+1: @pope1ni All tests pass with `{}` instead of `{!r}`, so I think we can simplify messages and use `{}`.
This branch in untested :thinking:
docstring with example input/output would be really helpful
I think I would define the additional parameters as keyword parameter, as in `__call__ `. BTW, thanks for fixing this thread issue I created!
`trimmed_something = True` would be more meaningful.
Use single quotes consistently.
This is minor, but the double exclamation point feels a little overblown. I'm not sure any exclamation points are needed at all; the text should suffice.
In the usual case for using this, it wouldn't be because "an initial migration has been applied before,", it'd be because the database pre-existed any (Django) migrations at all. Also, it's really the contents of your initial migration file that you need to compare to, not your model definitions. Suggested wording: "Detect if tables already exist and fake-apply initial migrations if so. Make sure that the current database schema matches your initial migration before using this flag!" As a bonus, this also hints at the fact that the automated check here is no more sophisticated than just checking if tables exist.
Strictly speaking it should be `--only-non-empty-tables` which is a bit of a mouthful. How about we invert the negative? And we can also drop `-tables` as it is obvious that we are flushing tables. ```suggestion '--skip-empty', action='store_true', help='Only delete from non-empty tables.', ```
`dest='plan',` is unneeded as that's the default value from `--plan` (eac9ab7ebb1ce0cbbc79c4cf65e8f70b0635a240)
the wording used for similar options is simply "Can be used multiple times."
`'rb'` flags are unnecessary.
You need to specify a type of lock, e.g. `locks.LOCK_NB | locks.LOCK_EX`. Currently it returns `False` because we passed an invalid argument.
```suggestion file_path = Path(__file__).parent / 'test.png' ```
I would rather try to create a second non-blocking lock: ```suggestion file_path = Path(__file__).parent / 'test.png' f1 = open(file_path) f2 = open(file_path) self.assertIs(locks.lock(f1, locks.LOCK_EX), True) self.assertIs(locks.lock(f2, locks.LOCK_EX | LOCK_NB), False) ```
Yes, please use `self. addCleanup()`.
Same here? ```suggestion __T = r'(?P<hour>[01][0-9]|2[0-3]):(?P<min>[0-5][0-9]):(?P<sec>[0-5][0-9])' ``` Maybe this is a bad idea because of leap seconds 🤷🏻‍♂️
I don't think we should go so deep into validation, we opt out from numbers but at the same time we allow the whole unicode range. Unicode numbers like `๑` would happily validate therefore it's an uphill battle. I'd opt for a vastly simplified regex to validate FQDN: `'(?:[a-z0-9\u00a1-\uffff-]+\.?)+'`. Sure it'll let some invalid segments go through (e.g. leading/trailing hyphens) but at least it doesn't pretend of being exhaustive. Proper validation requires a parser anyway.
Forgot to mention earlier, but on first look I found `[a-z-' + ul` a little confusing because of the dash between two ranges that actually serves as a dash and not a range separator. I think it would be more readable as `[a-z' + ul + r'-]` (similar to how it is in `domain_re` above).
My point wasn't the r prefix (I just copied that from above), it was moving the dash next to the close-bracket. But now that you mentioned it -- yes, the first and last (`'\.'` and `'\.?'`) need an r prefix, because without it the strings don't have a backslash in them and these expressions will just match anything. I think a test for this could use some invalid punctuation as the separator for the tld -- e.g. `http://unquoted~dot!`
This allows `xn----nx` and even `xn-----`. Are they valid? (edit: FWIW, my IceWeasel seems to think they are)
Is this necessary? If not I don't see much harm in changing the type to a list internally or even to always convert it to a `tuple` to avoid hashing errors down the line.
Looks like we favor `type` in similar cases in the ORM ```suggestion return type(value)( ```
Please add trailing comma.
```python kwargs = {'reuse': can_reuse, 'allow_joins': allow_joins} if isinstance(value, F): kwargs['simple_col'] = simple_col value = value.resolve_expression(self, **kwargs) ```
I think what Anssi is asking you to do is prove that the following produces LEFT OUTER joins rather than INNER JOINs. ``` class Timestamp(models.Model): at_time = models.DateTimeField() class Event(models.Model): start = models.ForeignKey(Timestamp, null=True) end = models.ForeignKey(Timestamp, null=True) actual = models.DateTimeField() start_datetime = datetime.datetime(2016, 6, 2) end_datetime = datetime.datetime(2016, 6, 4) actual = datetime.datetime(2016, 6, 3) t1 = Timestamp.objects.create(at_time=start_datetime) t2 = Timestamp.objects.create(at_time=end_datetime) Event.objects.create(start=t1, end=t2, actual=actual) Event.objects.create(start=t1, end=None, actual=actual) Event.objects.create(start=None, end=t2, actual=actual) Event.objects.create(start=None, end=None, actual=actual) # this should produce LEFT OUTER JOINS, not INNER JOIN Event.objects.filter(actual__range=[F('start__at_time'), F('end__at_time')]) ``` I'm not sure what those results will be, but the joins should be LEFT OUTER.
`... Using multi as True` and `...imports as multi`
As above, leave the docstring and change to deprecation to 2.0.
Checking `'exp' in locals()` looks a bit hacky and unconventional to me. Why not simply assign `exp` in the `EOFError` case? For example: ```py try: exp = pickle.load(f) except EOFError: exp = 0 ``` You could use a sentinel other than 0 if you prefer.
This is missing other likely candidates: `y` and `yes` I'd also argue it should be simplified to be case-insensitive so that `TRUE` == `true` (which requires you actually assert the incoming `val` is actuall stringy enough to have `.lower()`, rather than simply doing an equality match against any of the values)
I typically use something like the following: ```python return str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'} ``` This works whether you pass a boolean, integer or string, although we are only expecting a string from the environment anyway. If we wanted to be strict, we should reject invalid values: ```python if str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'}: return True if str(val).lower() in {'0', 'f', 'n', 'off', 'false', 'no'}: return False raise ValueError('Non-boolean string provided.') ```
I don't think it's important to mention PostgreSQL version details in the docstring.
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
decorate the class instead
I'm not sure this is needed since class doesn't have a custom `__repr__()`, we're just testing the base class.
``` class A: __print = cached_property(print, '__print') ``` This will not work and we can easily detect it too.
Might make sense to check explicitly set name too, because '__name' obviously will not work.
I would consider that as not working
I think silently failing to cache the property should be considered not working.
I also still don't understand why it's useful to allow writing code that doesn't work.
Use single lines for all these asserts -- we allow up to 119 characters when it improves readability.
Just state expected behavior instead of "Test...", e.g. "collectstatic --clear should delete broken symlinks."
```suggestion self.assertIs(self.temp_dir.joinpath(f_name).exists(), True) ```
Remove one of these blank lines (should only be two total). (`tests/file_storage/tests.py:454:1: E303 too many blank lines (3)`)
Perhaps the full list could be a class attribute so it doesn't have to be repeated several times.
I think it would be helpful if this were instead named `invalid_token_re`. The reason is that I coincidentally happened to be reading `csrf.py` and was confused by these lines: https://github.com/django/django/blob/b746596f5f0e1fcac791b0f7c8bfc3d69dfef2ff/django/middleware/csrf.py#L111-L112 The reason this was confusing is that this isn't a regex that matches tokens. It matches invalid tokens. And then I saw this was changed in this PR only a few days ago.
Good catch :dart: , I missed this :facepalm:. Please feel-free to send a patch
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
Instead of putting timeout in the `__init__` method, make it a class attribute. Here's an example change where we use this same technique: 8b0014869f666b44cd20692e38073ec0a0a8cb08
I think the test fails as it is as you're no longer passing `self.timeout` to `smtplib.SMTP_SSL`. I don't think Django should specify a default of 60. Instead it should be `None` and only passed to the SMTP connection if the user specifies it. Here's a quick sketch of what I have in mind (plus some cleanup): ``` python # If local_hostname is not specified, socket.getfqdn() gets used. # For performance, we use the cached FQDN for local_hostname. connection_class = smtplib.SMTP_SSL if self.use_ssl else smtplib.SMTP connection_params = { 'local_hostname': DNS_NAME.get_fqdn(), } if self.timeout is not None: connection_params['timeout'] = self.timeout self.connection = connection_class(self.host, self.port, **connection_params) # TLS/SSL are mutually exclusive, so only attempt TLS over # non-secure connections. if not self.use_ssl and self.use_tls: self.connection.ehlo() self.connection.starttls() self.connection.ehlo() ``` For the test you'd subclass `EmailBackend` and verify the connection has the timeout use specified.
You should set `self.timeout` to `timeout`, not 60.
I would stick with the one line if/else statements. The style guide says, "Don’t limit lines of code to 79 characters if it means the code looks significantly uglier or is harder to read."
the try/except needs to be added back
this class has a bunch of details of WSGI environ so I think it more accurately belongs in `django.http.request`
Mapping allowing case-insensitive key lookups. Original case of keys is preserved for iteration and string representation.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
There are only two uses of `_destruct_iterable_mapping_values()` and we use this same pattern exactly. I think that you could push the `isinstance(..., Mapping)` check into that function.
What I meant was that you could stick the following in the top of `_destruct_iterable_mapping_values()` to make it more DRY: ```python if isinstance(data, Mapping): yield from data.items() return ``` I don't see why you think we'd need an extra for-loop...
This can be single-lined.
I don't think that this test is required.
This also can be simplify: ```python call_command( 'createsuperuser', interactive=False, username='test_superuser', email='joe@somewhere.org', stdout=StringIO(), ) user = User.objects.get(username='test_superuser') self.assertEqual(user.email, 'joe@somewhere.org') self.assertFalse(user.has_usable_password()) ```
``` # Environment variables are ignored in non-interactive mode, if provided. ```
Chop blank line.
This list of registrations was roughly in order of the definitions above, I think we should preserve that
This is really similar to `process_rhs` in `KeyTransformExact` though, can we reuse that somehow? Also, this is a rather edge case, but this means one of the elements of the rhs can't be `None` on SQLite (unless we add `OR JSON_TYPE` in the lhs.
Similarly, I don't see much advantage to creating indirection with a method.
Does it change anything? :thinking: The previous solution works fine for a dictionary on the RHS.
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
Use single quotes consistently (could be done above and below also).
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
We can add `Foo.objects.create()` to ensure that primary key and sequence are still valid.
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
Chop the ticket number `(#25253)`.
`git pull --rebase` on your branch should be enough.
It looks that this change is not required. All tests pass without it.
I don't think this is needed (probably accidentally copied from line 327).
This code ignores the value of `readonly_fields`. I noticed this because it breaks an inline with a field which is defined as a method in the inline itself (and, thus, needs to be in `readonly_fields`). I'm currently using this workaround (there might be a more clever way to solve it): ```python return [field.name for field in self.opts.local_fields] + \ [field.name for field in self.opts.local_many_to_many] + \ list(self.get_readonly_fields(request, obj)) ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
I would typically put the "and"s on the previous line
if they define
Looking at other test methods I believe this can be reduced to a simple line. ```python self.assertEqual(User.check(), []) ```
I am not sure what the "rem" prefix means
The 4 lines above look identical to the `remote_model_key` lines a few lines before, except with `through` instead of `remote_field.model`. Maybe that can be a helper method accepting that argument.
Could you annotate the regex similar to: ``` tld_re = ( '\.' # dot '(?!-)' # can't start with a dash '(?:[a-z' + ul + '-]{2,63}' # domain label '|xn--[a-z0-9]{1,59})' # or punycode label '(?<!-)' # can't end with a dash '\.?' # may have a trailing dot ) ```
TIL that character classes also work inside `[]` :D
Let's be consistent about whether `app_name` appears above or below `urlpatterns`.
This can be simplified significantly: ```suggestion if match := re.match(r'^(?:\d+_squashed_)(\d+)', name): return int(match[1]) ```
Yes - sorry - not sure how I dropped that: ```python if match := re.match(r'^(?:\d+_squashed_)?(\d+)', name): return int(match[1]) ```
master is only supporting Python 2.7 and 3.4+
since there's no validation here and `get_port()` is relying on this code I would think you'd need to consider other malformed cases, such as `example.com:abc` or `1.1.1.1:443]`
You can move this to the previous line (we are favoring slightly longer lines to avoid non-hanging indentation).
Do we need to check if `token` is an instance of `Mailbox`? I couldn't find an example that needs this check.
I think we can leave the list of exceptions.
Might want to join both branches now that they are mostly similar. ```python select_list = [] cols = self.query.default_cols or self.query.select for col in cols: select_list.append(select_idx) select.append((col, None)) select_idx += 1 klass_info = { 'model': self.query.model, 'select_fields': select_list, } ```
I think `annotation` or `expr` might be a more appropriate variable name.
```suggestion new_order_by.append(annotation) ```
Pretty sure we can't drop the `order_by` based on 779e615e362108862f1681f965ee9e4f1d0ae6d2 which explicitly deals with this `annotate` / `FieldError` issue.
`by` :thinking: ```suggestion f"Cannot update when ordering by an aggregate: " ```
I think what Anssi is asking you to do is prove that the following produces LEFT OUTER joins rather than INNER JOINs. ``` class Timestamp(models.Model): at_time = models.DateTimeField() class Event(models.Model): start = models.ForeignKey(Timestamp, null=True) end = models.ForeignKey(Timestamp, null=True) actual = models.DateTimeField() start_datetime = datetime.datetime(2016, 6, 2) end_datetime = datetime.datetime(2016, 6, 4) actual = datetime.datetime(2016, 6, 3) t1 = Timestamp.objects.create(at_time=start_datetime) t2 = Timestamp.objects.create(at_time=end_datetime) Event.objects.create(start=t1, end=t2, actual=actual) Event.objects.create(start=t1, end=None, actual=actual) Event.objects.create(start=None, end=t2, actual=actual) Event.objects.create(start=None, end=None, actual=actual) # this should produce LEFT OUTER JOINS, not INNER JOIN Event.objects.filter(actual__range=[F('start__at_time'), F('end__at_time')]) ``` I'm not sure what those results will be, but the joins should be LEFT OUTER.
I believe this to be broken. It shouldn't be possible for one of the rhs values to produce a new lookup which others didn't produce.
Make this and new_lookups sets.
The check should be inside prepare_lookup_value, not in build_filter.
Hadn't considered this.
either that or leave the attribute name alone and define a `db_column='CaTeGoRy'` to put more emphasis on it.
please remove `on_delete=` from these FKs.
(inadvertence revert here too)
Please add a trailing comma.
Unnecessary -> ```suggestion def __str__(self): ```
try to avoid "we", e.g. "Because it's a parent link, all the data is available in the instance, ...
Fine by me. I think we could probably omit the keywords in a lot of places and include them only where it's potentially confusing, but probably that's already what you're doing.
In general, I think the `get` / `set` style APIs are familiar enough that we don't need to use keyword arguments with every call. But I don't feel strongly about it.
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
```suggestion **kwargs, ) ```
This is not a functional change, it's just a simplification.
It's slower, about 10 times.
Please replace this with a regular `try/except`.
extra space after [
remove "0" in {0}
Is there a specific reason to `insert(0...` instead of `append`? `basedirs` is transformed to a set just below, so I think ordering really doesn't matter here.
This change is not tested and I'm not sure if it's excepted. I would focus on improving an error message.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Водка')) ```
```suggestion self.assertCountEqual(queryset, [self.guitar_book]) ```
```suggestion self.assertCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
```suggestion self.asserCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
This can be single-lined.
This class is unnecessary.
Thanks @MatthewWilkes. It was only that sentence/paragraph that needs fixing here, since it's adding the new value that will be unpacked. Any other clean up can wait.
Please don't suggest doing unrelated cleanups along with bug fix or feature work. We try to avoid that as it confuses things when studying a patch.
I'd rather see the docstring updated in this one: just so it's not forgotten. With the change, the paragraph beginning `Return...` isn't right. My worry is if we leave it then it'll be forgotten.
Maybe: _"Ensure the last element is a field or a transform."_ :thinking:
This is getting out of hand, especially considering callers ignoring so many of the return values. Does it make sense to create a type to model these values? At a minimum I think we should consider namedtuple.
This should be added only if column is nullable: ```python if isinstance(value, Col) and self.is_nullable(value.target): clause.add(lookup_class(value, False), AND) ```
yeah having an `Expression.nullable` flag that is also present on `Col` instance based on the `Field.null` they resolve would be useful for a few other things I've worked on in the past.
I'll edit this docstring to remove the references to the removed parameers, but please check my edits.
Hadn't considered this.
I think the original `reffed_expression.__class__.__name__` should be used.
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
Wrap strings at 79: ``` 'You have provided values in the LANGUAGES_BIDI setting that are not in ' 'the LANGUAGES setting.', ```
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
I would keep `if not ...` in the same line.
Good point :+1: @pope1ni All tests pass with `{}` instead of `{!r}`, so I think we can simplify messages and use `{}`.
If `formfield.queryset` is already filtered both the outer query and the subquery will have this filter applied which is unnecessary ```suggestion Exists(formfield.queryset.model._base_manager.filter(complex_filter)), ```
I think "if needed" rather than "if it and the....exist." is sufficient given the code is straightforward.
We use line lengths up to 119 characters when it helps readability. I wouldn't reformat this line when it doesn't have any other changes.
"actor" variables are unused
Should be able to fix it when committing, just making a note of it. Thanks for the patch; I happen onto the problem from time to time as well. :-)
use set comprehension (I guess it might be better to defer this task to a separate commit)
Seems fine to rename everywhere, but it seems out of the scope of this PR to touch `BoundField.__init__`.
I was thinking: ``` python def bind_to_form(self, form, name, **kwargs): return BoundField(form, self, name, **kwargs) ``` but I'm not convinced this is a good practice for a "just in case" scenario, so we can probably drop the idea.
I wonder if we might add `**kwargs` to the signature of this method and `BoundField` to allow for future expansion? (In the past, there have been some instances where we've wanted to add additional parameters and we have to add non-trivial backwards compatibility shims to allow that.)
reuse initial here and don't call to_python twice
better name? `get_filter_kargs_for_object()`
prefer hanging style: ``` return { self.fk_field: ..., } ```
Overall, the changes are mostly fine, I just wonder if we might use this as an opportunity to tighten up large try blocks and use try/except/else instead (such as here).
no blank line please
I added this missing change to the first commit.
Might want to only run `replace` on `str` params or use `str(param).replace('-', '')`.
Should `params` be a tuple? i.e. ```python params = tuple(param.replace('-', '') for param in params) ``` Just want to make sure we avoid issues such as the one in #11784.
`# Check that ...`
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
I would omit the blank line above each "with", up to you though.
I suggest you use the `hint` kwarg for the `'perhaps you forgot a trailing comma?'` part.
I thinking removing APP_DIRS from TEMPLATES (since it defaults to False) is a better suggestion than setting it to False.
.get() falls back to None to `False` isn't really needed I think.
check that -> and that (no comma needed since the two clauses are independent)
prefer including a trailing comma in kwargs so if more items are added in the future we don't have to modify this line again
`for data in json.loads(...):`
Here's another place where an unnecessary line break is inserted after the period.
Yes, it would be good to add a docstring.
I feel like we shouldn't override "private" methods to test, I also don't see why that would be necessary here.
Isn't the `Car` left in the database after this test? It should be deleted here too, I think.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
OK then, thanks for the references.
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
Ideally this would be passed as a parameter instead of being baked into the SQL. Maybe adding a `%%s` placeholder and inserting the format string at `params[0]` would work? ```python template = "strftime(%%s, %(expressions)s)" sql, params = self.as_sql(compiler, connection, template=template, **extra_context) format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' params.insert(0, format_string) return sql, params ```
I've never seen underscores in model names before, since I don't think we are testing that behavior, it may make sense to remove them. Also, please use double quotes for docstrings, I believe that's what the majority of Django uses.
It's preferable to re-use models instead of adding new ones if possible.
no parenthesis needed / prefer single quotes
Please remove those lines as it will target 2.0.
Why does this change the existing test? Generally, changing old tests indicates that you're introducing a potential regression, because old behavior isn't going to be tested any more.
It might be smarter to validate the token first and only modify the session + redirect if it's valid. Otherwise it makes it really easy to create a session just by GET'ing a url (possible DoS vector). It also means you can't pass `accounts/password_reset` as the token and take advantage of our `request.path.replace()` code. It probably means validating the token twice, which is slightly slower. Seems fine to me if an invalid token gets leaked.
@romgar If you find the time that would be great!
immediatelly -> immediately
yeah, `request.session.get` would return none for the token and this wouldn't pass the comparision (which would be perfectly fine)
This throws a 500 if the token is not set!
You can drop `(object)` as master only supports Python3.
I would say: _"""Validate that the string does not contain null characters."""_
Is `text` used? If unused, you can remove.
Please use single quote. `message` can be single lined.
Maybe: `if '\x00' in str(value):`
I don't think that it is a proper solution because `get_order_dir()` returns only field name and direction, so it will not properly in case of using database functions in `meta.ordering`. I think we should fix this in `find_ordering_name()`, e.g. ```diff diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py index a44adfc760..fb2a4b23b1 100644 --- a/django/db/models/sql/compiler.py +++ b/django/db/models/sql/compiler.py @@ -716,6 +716,9 @@ class SQLCompiler: results = [] for item in opts.ordering: + if isinstance(item, OrderBy): + results.append((item, False)) + continue results.extend(self.find_ordering_name(item, opts, alias, order, already_seen)) return results ```
Please chop all unnecessary blank lines.
Test coverage lacking here? Don't see any failures with just `order_type = 'desc'`
You should use tuple deconstruction in a number of places, starting with `query, params = super().as_sql()`. See other SQLCompiler methods. Also you seem to have replicated a bit of logic from `SQLCompiler.get_order_by()`. You shouldn't do that, but find a way to reuse it. `order_by()` supports many forms beyond the asc/desc field name form you've compiled here.
Put the close ] on the next line.
```suggestion return '-' + value if neg else value ```
```suggestion return '-' + value if neg else int(value) ```
Not sure this is any better, probably slower due to the function call, but putting it out there for consideration. ```suggestion num, remainder = divmod(num, 62) res = BASE62_ALPHABET[remainder] + res ```
Are we expecting `s` to be anything other than `str`? If it were `bytes` this would fail as it would convert to `"b'...'"`. ```suggestion ```
The failures on MySQL, PostgreSQL and likely Oracle seems to be an indicator that it should not work on SQLite either. There's only so much that Django can do when coercing types in a database agnostic way and I'm not sure trying to support cases where `float` are implicitly properly converted to `Decimal` at the ORM level is a pattern we should encourage. If you're filtering against decimal/numeric data with floats you're better off defining your coercion rules explicitly at the application level and pass _stable_ numeric data to the database to avoid surprises down the road when a specific float value happens to take an unexpected rounding/loss of precision path along the way to the query executor.
Please remove type annotations. We don't currently use them in Django.
I added the comma to be consistent with the `include` and `condition` attributes. Also, on `ExclusionConstraint` we separate attributes by comma but not on `UniqueConstraint`, so 🤷 indeed..
Calling `is_valid()` in `__repr__` is not an option (as it triggers validation).
I would revert these changes, a string representation of `condition` and `deferrable` doesn't need and extra quotes.
`expressions` should be before the `name` like in other classes.
This line can be removed :thinking:.
IMO this line is unnecessary, and above `iter()` call can be removed.
`seprate` -> `Separate`, also trailing dot is missing.
Alright let's keep it as it is then. I just wanted to make sure this case was covered by a test.
add trailing comma
Nit: I would call this "saved" or "original" patterns, because technically it might not be the default.
```suggestion with self.time_keeper.timed('Total database setup'): ```
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
An aside: I see the reference to `EggLoader`. Haven't Python "eggs" been pretty much obsolete for ages? Can we remove this or the bits that are related to "eggs"? (Something to create a separate ticket for, if so.)
```suggestion # RemovedInDjango50Warning class NoOpTestRunner(DiscoverRunner): def setup_test_environment(self, **kwargs): return def setup_databases(self, **kwargs): return def run_checks(self, databases): return def teardown_databases(self, old_config, **kwargs): return def teardown_test_environment(self, **kwargs): return class DiscoverRunnerExtraTestsDeprecationTests(SimpleTestCase): msg = 'The extra_tests argument is deprecated.' def setUp(self): self.runner = NoOpTestRunner(verbosity=0, interactive=False) def test_extra_tests_build_suite(self): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.build_suite(extra_tests=[]) def test_extra_tests_run_tests(self): with captured_stderr(): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.run_tests( test_labels=['test_runner_apps.sample.tests_sample.EmptyTestCase'], extra_tests=[], ) ```
I think you missed this one in your recent updates.
Move this above `has_add_permission` for consistency.
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
Again, it shouldn't be necessary to provide `None` here? (I realise that the existing version of this line did so.) Please fix all cases of this, but only for lines modified by this PR. Other cases can be dealt with by a separate PR some other time.
I don't think this is needed (probably accidentally copied from line 327).
proxy model and won't ...
We usually put the closing parenthesis on the next line.
I would change ```diff --git a/django/core/management/commands/dumpdata.py b/django/core/management/commands/dumpdata.py index df9eecc0f8..953f261ef4 100644 --- a/django/core/management/commands/dumpdata.py +++ b/django/core/management/commands/dumpdata.py @@ -67,7 +67,7 @@ class Command(BaseCommand): def handle(self, *app_labels, **options): format = options['format'] indent = options['indent'] - using = options['database'] + database = options['database'] excludes = options['exclude'] output = options['output'] show_traceback = options['traceback'] ``` to simplify this. We should also skip models with different `db` for read, instead of checking `router.allow_migrate_model()`, e.g. ```python using = router.db_for_read(model) if not model._meta.proxy and (not database or using == database): if use_base_manager: ... ```
please remove the unrelated change
I'd omit a blank line after each docstring.
Remove one of these blank lines (should only be two total). (`tests/file_storage/tests.py:454:1: E303 too many blank lines (3)`)
We should use a custom storage for this test (instead of mocking).
`type_` -> `invalid_type`
FWIW I didn't find pytz required, except on Windows, but I might have gotten lucky with my particular configuration.
These assertions are not related with this patch. Personally I don't see much value in adding them.
Let me put this differently :-) Is this required to make the test suite pass? If not, I'd prefer we do not include it. If yes, I'd like to look at the failing tests, because they must be weird.
`if kwargs['setting'] in ('INSTALLED_APPS', 'STATICFILES_DIRS')` The later is fixed at initialization time too I think
Call `clear_url_caches()` instead. It's more likely to stay up to date when the code lives on, and it resets the `get_callable` cache which is missing from your patch.
No need to use `in` here, `kwargs['settings] == 'ROOT_URLCONF'`.
I suggest you use the `hint` kwarg for the `'perhaps you forgot a trailing comma?'` part.
Use list and remove unnecessary whitespace ```suggestion fields = [('name', 'position')] ```
This can be single-lined.
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
It would be nice to be consistent about the ordering in `assertEqual` using it's `(variable, 'expected value')` but here and a couple other places it's opposite.
Hey @codingjoe — so I think I would restructure this section slightly, through to line 59. * I'd create a method to configure three attributes on self: `source_field`, `model_admin`, and `to_field_name`. It'd need to take the `request`. In there I'd include all the `try:except:` blocks and raise an `AutoCompleteSetupError` (or similar) if any of them occur. * Outside that method I would have a single `try:except:` to log the error, and return the JSON 403 response. (I'm thinking about how I'd debug this if there's no logging, and all I have to go on is a 403...) I think we should also move the `has_perm() -> 403` check **above** the `get_search_fields() -> 404`. (That last if nicely informative for users but we shouldn't hand out that info to someone without the permissions to access the modeladmin at all… 🤔)
The thing is that even if the ORM doesn't have support for it yet using `distinct()` to implement `(UNION|INTERSECT) ALL` might prevent us from adding proper support in the future. What I suggest doing here is setting `query.combinator.all = kwargs['all']` and preventing using `distinct()` on `CombinedQuerySet`. The difference between ordering and combination operation is that the former operates on the _combined_ set of rows while the latter operates on how these rows are combined. I would suggest that options related to combination be passed as `kwargs` (such as `all`) and actions operating of the combined result (`CombinedQuerySet` instances) be added as methods (`order_by`, _slicing_).
no comma since the stuff after "and" couldn't be a sentence on its own
It's a bit :scream: to me. `filter()` doesn't change anything for combined queries so I think we should handle this in `get()`, e.g. ```python def get(self, *args, **kwargs): clone = self._chain() if self.query.combinator else self.filter(*args, **kwargs) ```
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
These tests should be moved to a separate commit.
Should this be? ```suggestion for_where=False): ```
This check of for_save could be added to the place where resolve_expression is called in the compiler (first call resolve_expression, then check if resolved.contains_aggregate -> FAIL).
Both approaches work but I wonder if we'd want to be a bit more liberal here and simply return `copy` if no `output_field` can be retrieved. ```suggestion field = getattr(copy.lhs, 'output_field', None) if field is None: return copy ``` It would also avoid having to specify an explicit `output_field` when using a `Func` and `RawSQL` when users usually know what they are doing.
Good catch :dart:
This solution introduce really unexpected behavior, i.e. change every raw SQL that contains name of any column from a parent model with that column, e.g. if a parent model contains column `name` then following examples will be replaced by `"annotations_store"."name"`: - `case when name='foo' then 'oof' else 'foo' end` -> `"annotations_store"."name"`, - `concat(chain, 'name')` -> `"annotations_store"."name"`, - `other_column_with_name_in_it` -> `"annotations_store"."name"`, etc.
Simplify to the following? ```python columns = ['%s.%s' % (self.quote_name(f.model._meta.db_table), self.quote_name(f.column)) for f in fields] params = tuple(InsertVar(f) for f in fields) ```
I guess I find comprehensions more legible than loops like this, especially with single item tuple appends which are syntactically ugly. Comprehensions are fast with dedicated operations in bytecode, calling methods like `.append()` multiple times in the loop is slow. In terms of performance, it should be negligible anyway as I expect this to be called once before the query executes, not per row returned, and typically I expect the number of fields to be very small...
Please use single quotes everywhere in this method.
Please add trailing comma.
Sorry, I meant `range()`, not `len()`. (Or just ditch the `len()` and iterate over the elements.)
@akulakov `passed_check` is to check if list is not empty. if it is not empty, method will return no error, otherwise error will be returned (`[] if passed_check else [W020]`).
`not statement` is used several times above, so need to be consistent in code style.
@MarkusH - that looks good to me.
@coldmind With the current code, `passed_check` will be `True` if `settings.ALLOWED_HOSTS` IS empty. That is backwards. `passed_check` should be `True` if `settings.ALLOWED_HOSTS` is NOT empty.
Since this is just a type check which should apply to all environments, not just production ones, it doesn't need the `deploy` flag
This can be single-lined ```suggestion '<ul class="errorlist nonform"><li>Please submit at most 1 form.</li></ul>', ```
Chop blank line.
```suggestion renderer=renderer, ```
I renamed the test and removed the docstring.
```suggestion f'<li>Title: <input type="text" name="form-0-title"></li>' f'<li>Pub date: <input type="text" name="form-0-pub_date">' f'{delete_form}</li>' ```
True about the ML. Regarding the naming for `related_objects/related_m2m` vs `reverse_rel/reverse_m2m`, that's a new API so there isn't historical names to preserve (unlike `many_to_many` vs `m2m`), we just need to pick the best names to represent the relations.
The approach you've taken here is: - Cache the result of get_fields() for a specific set of arguments - look up a name in that list; - Raise FieldDoesNotExist if the name is not found. The other obvious approach I can think of would be: - Cache a list of _all_ fields - Look up the name in that list - Raise FieldDoesNotExist if the name is not found - Raise FieldDoesNotExist if the field doesn't have the requested properties. I'd be interested to see the "memory vs speed" tradeoff for these two approaches.
The style I prefer is ``` options = { 'include_parents': include_parents, .... } ``` It's somewhat of a pain to indent additional items if your editor doesn't do it automatically with the other style.
Keeping the try block limited to just the code you expect to throw the exception is a good practice. It prevents a situation where there's some other bug than what you expected. For example, if `warnings.warn(` somehow threw a `KeyError` and it was in the try block, you would unexpectedly hide that bug.
to minimize size of try: ``` try: m2m = kwargs['many_to_many'] except KeyError: pass else: warnings.warn(.... ```
I would like a test that fails if this is removed from the try block.
(same pattern as above, if you change it)
Marc, did you try to store by default in a binary column? AFAIK PostgreSQL is using a binary field internally.
I wonder if the `isinstance()`condition results in any performance savings? I tend to think always casting might be simpler.
append(...), not append[...].
Well, we _could_ make `on_delete` an actually-required arg to `ForeignObject` right now, and move it even before `from_fields` and `to_fields`, but that would require duplicating the deprecation warning in both `ForeignKey` and `OneToOneField`.
This is a nitpick, but `on_delete` is not an attribute you set, it is an argument you pass. I think that second sentence could just be removed. What might be more useful here is a stable link to the `on_delete` docs.
Well, there are a number of existing cases of docs URLs in user-facing messages (especially in migrations, but other places as well). I think there is a lot to recommend them from a UX perspective; someone who gets this warning is quite likely to in short order need a reference of the available `on_delete` options. I don't think the URL-going-stale issue is that big for a deprecation warning, which has a limited lifespan anyway. If someone does happen to rearrange those docs in the next couple years, we'd just update the message. (Like the ones in migrations, the message should use a Django-version-specific docs link, not the `stable` redirect, so that for a given Django version the link shouldn't ever go stale.)
Please do not change formatting
Is there really no alternative to a plain except? This would even catch KeyboardInterupt etc which we surely don't want. Which exceptions can occur here? As a last resort you can use except Exception, but I'd prefer it explicit.
I think we should revert the logging changes as it appears we're adding additional logging calls where they didn't exist before.
My mistake on 500, but "NOT FOUND" is different from "Not Found"
I think `get_exception_response` would be a better name for the method.
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
I would prefer to omit it for now.
It also needs to account about usage of boolean expressions such as lookups (e.g. `Q(Exact('field', 134))`); not all rhs are tuples of the form `(lookup: str, value: Any)` as `Q.__init__(*args)` also ends up in `Q.children`. https://github.com/django/django/blob/a69b0e9cfe0af7cd2deaf55c069453c4c4598604/django/db/models/query_utils.py#L48-L50
We can use `{x for x in ...}` instead of `set(x for x in ...)`: ```suggestion f_references = {expr.name for expr in self.flatten() if isinstance(expr, F)} q_references = { child[0].split(LOOKUP_SEP)[0] for expr in self.flatten() if isinstance(expr, Q) for child in expr.children if isinstance(child, tuple) } ```
no comma needed (and the commit can be squashed)
Insertion order is maintained from Python 3.6 onwards so sorting is only required for 3.5: https://www.python.org/dev/peps/pep-0468/
I don't think we can rely on `kwargs.items()` to be ordered. I suggest using `sorted` to enforce an ordering.
`date=rfc850date` isn't needed in the `subTest()` -- since will appear if the assertion fails.
I don't think the number of tests is an issue, but since the check depends on a variable, the test should also reflect this, or it'll break at some point.
I would move mocking `datetime` to a decorator, after that we will be able to test different dates, e.g. ```python @mock.patch('django.utils.http.datetime.datetime') def test_parsing_rfc850(self, mocked_datetime): mocked_datetime.side_effect = lambda *args, **kw: datetime(*args, **kw) utcnow_first_fifty = datetime(2019, 11, 6, 8, 49, 37) utcnow_second_fifty = datetime(2051, 11, 6, 8, 49, 37) date = ( ('Tuesday, 31-Dec-69 08:49:37 GMT', datetime(2069, 12, 31, 8, 49, 37), utcnow_first_fifty), ('Monday, 10-Nov-70 18:49:37 GMT', datetime(1970, 11, 10, 18, 49, 37), utcnow_first_fifty), ('Wednesday, 31-Dec-71 18:49:37 GMT', datetime(1971, 12, 31, 18, 49, 37), utcnow_first_fifty), ('Thursday, 31-Dec-99 08:49:37 GMT', datetime(2099, 12, 31, 8, 49, 37), utcnow_second_fifty), ('Thursday, 10-Nov-50 18:49:37 GMT', datetime(2050, 11, 10, 18, 49, 37), utcnow_second_fifty), ('Sunday, 31-Dec-00 18:49:37 GMT', datetime(2000, 12, 31, 18, 49, 37), utcnow_second_fifty), ) for rfc850str, expected_date, utcnow in date: mocked_datetime.utcnow = mock.Mock(return_value=utcnow) with self.subTest(string=rfc850str): parsed = parse_http_date(rfc850str) self.assertEqual(datetime.utcfromtimestamp(parsed), expected_date) ```
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
I think this fails for some cases in the current year as well as for some in the future. ``` python def get_year(year, current_year): assert 0 <= year < 100 if year <= current_year + 50: year += 2000 else: year += 1900 return year assert get_year(19, current_year=2019) == 2019, "same year" assert get_year(20, current_year=2019) == 2020, "next year" assert get_year(18, current_year=2019) == 2018, "last year" assert get_year(40, current_year=2019) == 2040, "21y hence" assert get_year(80, current_year=2019) == 1980, "39y ago, not 61y hence" # fails! assert get_year(10, current_year=2019) == 2010, "9y ago, not 91y hence" assert get_year(69, current_year=2019) == 2069, "50y hence" assert get_year(80, current_year=2070) == 2080, "future 10y hence" assert get_year(60, current_year=2070) == 2060, "future 10y ago, not 90y hence" assert get_year(10, current_year=2070) == 2110, "future 40y hence" # fails! assert get_year(21, current_year=2070) == 2021, "future 49y ago, not 51y hence" assert get_year(20, current_year=2070) == 2120, "future 50y hence" # fails! ``` Can I suggest an alternative implementation? ``` python def get_year(short_year, current_year): assert 0 <= short_year < 100 current_short_year = current_year % 100 delta = short_year - current_short_year if delta < 0: delta += 100 # assume future if delta > 50: delta -= 100 # then shorten if too far in the future return current_year + delta ```
I guess "@" is some convention I don't know about.
I added warning to docs.
IMO we should check options against PostreSQL names.
I'd suggest a `ValueError` instead. And this requires also a test. You can see what `Substr` does.
Could you also change this line for me? ```diff - Cast(expression, FloatField()) if not isinstance(expression.output_field, FloatField) + Cast(expression, FloatField()) if isinstance(expression.output_field, IntegerField) ``` Don't forget to import `IntegerField`.
Makes sense, let's stick with `raise e`.
Thanks for investigating, so simply raising `exc_info[1]` seems the way to go, unless some test can demonstrate the opposite.
This makes makes it not obvious at all that the contents of the `try/except IntegrityError` are properly wrapped in a transaction. This is necessary to prevent errors on databases which actually enforce transactional integrity on errors like PostgreSQL.
This is not used only by `get_or_create`.
create -> creates
Generally we would rather expand the docstring with sufficient explanation rather than include a ticket reference (or at least keep the mention limited to a simple "(#18247)" as in tests).
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
Why the `CombinedExpression` and not `Expression`? IMO it's misleading, I know that `CombinedExpression` has the concept of right-hand and left-hand sides but for other purposes.
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
It would be more elegant, and possibly more efficient, to use: ``` template_postgis = getattr(settings, 'POSTGIS_TEMPLATE', 'template_postgis') cursor.execute('SELECT 1 FROM pg_database WHERE datname = %s LIMIT 1;', template_postgis) if cursor.fetchone(): return template_postgis ``` This is how `QuerySet.exists()` is implemented.
Please chop all unnecessary blank lines.
Few naming suggestions: `ordering_element` -> `expr` `ord_sql` -> `expr_sql` `ord_sql_params` -> `expr_params` `additional_sql_params` -> `ordering_params` `ord_clauses` -> `ordering_expr_sql`
Put the close ] on the next line.
`"""Return the index at which the ordering expressions start."""`
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
It seems the original value of the class should be stored by setUp and then restored here in case the default value of 5 changes.
use """ for consistency with other docstrings
`type_` -> `invalid_type`
Not sure these asserts bring value ... they seem to test that `override_settings` works.
We should use a custom storage for this test (instead of mocking).
Use a descriptive name, not Ticket22550.
Chop blank line.
IMO this is not a proper fix because `CustomPK` doesn't appear in a `FOR UPDATE OF` statement, so this can cause a data loss. Both models should be included.
I added `supports_select_for_update_with_limit` because this will crash on Oracle.
Heh. This line was an `assertRaisesMessage` before, I recommended that it be changed to assertRaises to make the test less prone to break on trivial code changes. The message's content is essentially just "Not supported" anyway, so I think we should leave it this way.
I suggested that because `annotation_select` now contains expressions other than aggregates. But I didn't notice the method was in the AggregateCompiler, so it probably is just aggregates in that dict. Not worth worrying about I guess.
```suggestion "Cannot aggregate over the 'other_age' alias. Use annotate() to promote it" ```
This isn't safe unfortunately. Consider the following test results (which fail): ``` def test_empty_expression_char(self): books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value('Empty')), default=Value('Not Empty'), output_field=CharField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, 'Not Empty') def test_empty_expression_datetime(self): from django.utils import timezone from datetime import timedelta now = timezone.now() then = now + timedelta(days=1) books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value(now)), default=Value(then), output_field=DateTimeField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, then) ``` Depending on whether or not there are dbconverters run, these will fail with one of the following kinds of errors: 1. `TypeError: expected string or buffer` 2. `AssertionError: 0 != datetime.datetime(2016, 5, 23, 18, 59, 26, 409777)` For what it's worth, both of these tests fail without your patch too, except they fail during the count just like the report on the ticket says. This certainly needs fixing in some way, but we can't just use 0 as a value all of the time.
Case expressions use Q internally which led me to writing the above tests. I think you're right that EmptyResultSet might be able to be caught directly, and then it could use the `default` argument in place of the static `'0'` you have above. The changes need to be made in tandem though.
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
This could be a bare `super()`.
Turn (capitalize) add period. sql -> SQL
This one as well.
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
Chop "Helper function that" "Return ..." (use PEP 257 verb style)
This could be moved closer to where it's used or even eliminated as an intermediate variable.
I'd say "Return a (sql, params) fragment to set a column to null or non-null as required by new_field, or None if no changes are required."
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
```suggestion new_field.get_internal_type() in ('CharField', 'TextField')): ```
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
```suggestion path = '%s/' % request.path ``` :thinking:
OK, that sounds/looks interesting. Let me have a play. Thanks @jdufresne!
This will _break_ the debug page I think: instead of a list of routed URL patterns, we'll get a plain 404 error response. (Would like to do something at the resolver level, but we don't have the request... Can we limit it just to `DEBUG=False`? 🤔)
The check here should include `is_staff`. If you don't have permission to access the admin at all then we don't need to apply the redirect.
Can we please exclude any potential deprecation of the APPEND_SLASH in the admin from the scope of this PR.
Could we possibly skip the detection feature `if Database.sqlite_version_info >= (3, 29, 0)`? Since this is only present on macOS [could we branch off `platform.platform`](https://docs.python.org/3/library/platform.html?highlight=darwin#platform.platform)? I think this would partially address @claudep's concerns.
```suggestion supports_update_conflicts_with_target = supports_update_conflicts ```
`0` is unnecessary: ```suggestion return (10, 2) else: return (5, 7) ```
Is this supposed to be `sqlite_version_info` rather than `version_info`? I guess other usages in this file might be incorrect also.
Ideally we can pin at `3.35` as you've done here, but perhaps we should pin at `3.35.5` because `3.35.1` included bugfixes for that new functionality, and more importantly `3.35.5` has the following fix: > Fix defects in the new ALTER TABLE DROP COLUMN feature that could corrupt the database file Though it unfortunately doesn't specify further, or linked to a ticket/discussion. ([Docs for the entire 3.35 release line, including patch releases](https://www.sqlite.org/releaselog/3_35_5.html))
I think `request` should be optional.
What if we make `level` default to "info" or "debug" instead? That way if you call `log_response` on a non-error response you'd just get an info/debug log, instead of getting a confusing "module logger has no attribute None" error (or whatever the wording actually would be)
Or in some cases (e.g. CSRF) it's because we want to log the response under a particular non-default logger. But even in those cases, we never want to double-log a response.
response (no cap) unless you mean to write HttpResponse
I'm omit the intermediate extra variable in favor of: ``` getattr(logger, level)( message, *args, extra={...}, exc_info=exc_info, ) ```
@felixxm I was thinking about only specifying `css` OR `js` – the default values are empty datastructures which are falsy as well. There's no point in iterating through `_js_lists` or `_css_lists` to find whether an empty datastructure already exists in there. But it's probably a pointless microoptimization.
Including falsy is a user's mistake and we don't remove them from the source lists, so I think we shouldn't change this.
~Is this only required for the specifics of the test cases, or is it required to satisfy the merging and sorting in `Media` itself? If the former, all well and good, if the latter, would that need to be part of the `Paths as objects` interface contract?~ Oh I guess it's the `and be hashable` part already. My bad, ignore!
I don't know if you need to actually create all the Medias. At this point a unit tests calling merge is sufficient. What I would like to see is: ```python assert list(merge([1,2],[1,3],[2,3], [5,7], [5,6], [6,7,9], [8,9])) == [1,2,3,5,6,7,8,9] ```
This isn't quite right. Now the lists in `combined` are assigned to those in `self` by reference. That means that the lists in `self` will also be modified. We can also avoid the unnecessary tuple construction. ```suggestion combined._css_lists = self._css_lists[:] combined._js_lists = self._js_lists[:] ``` I'm not sure how this extra copying will affect performance.
`value` or `return_value`? or maybe we should swap these lines: ```python if ( not timezone._is_pytz_zone(current_timezone) and timezone._datetime_ambiguous_or_imaginary(value, current_timezone) ): raise ValueError('Ambiguous or non-existent time.') return timezone.make_aware(value, current_timezone) ``` :thinking:
`IS_DST_PASSED` is confusing, maybe `NOT_PROVIDED`.
If it's changed to return naive current local time when `USE_TZ=False` (as discussed above) that should also be mentioned here.
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
Maybe: ```python for name, value in self.scope.get('headers', []): corrected_name = name.decode('latin1').upper().replace('-', '_') if corrected_name not in ('CONTENT_LENGTH', 'CONTENT_TYPE') corrected_name = 'HTTP_%s' corrected_name ```
FYI: we have also [`HttpHeaders`](https://github.com/django/django/blob/fc2536fe66c519b306f673672b795d16f87ed57d/django/http/request.py#L359-L374) class that have reserve logic, I'm not sure if we can reuse it somehow :thinking:
Ahhh, yes, thanks!
`scope` is a dict, isn't the `None` already the default anyways? Same below.
epecting -> expecting
use a single line here -- lines up to 119 characters are preferred when it helps readability.
ATM is -> than with
What about using an `elif isinstance(m2m_relation, ManyToManyRel)` clause instead and issuing a `continue` in an `else` branch? This looks more safe in regard to third party fields that might exposed them as `many_to_many = True`.
fixme -> TODO
chop blank line
We should probably keep this class. I think I'd call it `SitemapIndexItem`, and give it a docstring. 🤔 I guess deprecating the `__str__()` usage will keep everyone on the same page. (Without something like this, we're still passing a list of pair or dicts or ... — given that we have the class already, we may as well keep it.)
📖 I think we could add a docstring to this explaining why `__init__` was overridden. This and `CaseInsensitiveMapping.__init__` looks pretty similar
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
An aside: I see the reference to `EggLoader`. Haven't Python "eggs" been pretty much obsolete for ages? Can we remove this or the bits that are related to "eggs"? (Something to create a separate ticket for, if so.)
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
Yeah, this is a good point, reuse an ordering if possible (maybe even force it)
Slow or not, it is kinda pointless to do since we do not need the data -- so yeah, we should not count here
You are leaking information about whether somebody has access or something doesn't exist.
Raising a 404 with the same message as in the previous check would mask the issue. Then again I think we already leak a lot like that in other admin pages, will have to double check.
Both `has_perm()` and `has_change_permission()` take an optional `obj=None` argument for object-level permission checks as implemented by e.g. django-guardian. I think we should provide this here as well.
We can remove `'book_join'` from `order_by()`.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
I think the `lambda` could go on this line.
Check existing tests for the style to use for `assertRaisesMessage`.
Shouldn't we replace `and` with `or`? what about a file with a path like `'/vsimem/nonexistent.tif'`
Remove the parentheses, please.
The parameter to this method seems odd to me. As it stands, no caller is explicitly using the parameter in a call to the method and I can't see many legitimate uses for it in derived classes. I think you're effectively just using the default value as a space to store a class-scope variable. Would it be simpler to just assign a member on the class? Or on the instance, if you prefer.
Having an overridable method seems like the most orthodox OOP solution (it's what a Java programmer would do :-) ) but I'm not convinced it really gives a useful abstraction: by coincidence it's the right place to make this one change, but I'm not sure there's a useful class of future modifications it opens up, so it feels like overkill to me. My thought with an instance variable was just to set it in the constructor in the base class, and overwrite it in the subclass constructor (not exposing it as a kwarg). I'm not sure there's any advantage to this; I think I was thinking about this because it's what I'd do in C++. I don't have a particularly strong feeling on this. I think if I were writing it I'd go with the class-level attribute.
There's a lambda called `strip_prefix` in `inspectdb.py` that should be of use.
@charettes, any reply here? I guess we shouldn't block the patch about the issue with backwards migrations if we can't find a simple solution.
Ah, didn't know this existed yet. I see that this PR is mostly a "copy" of the ContentTypes one. Sounds alright for now, then.
I guess some tests might be needed for the router stuff.
"... final db state after the last state operation, hence ..."
Could these functions be defined as methods instead? It feels like it would make the execution flow easier to follow and be more in line with the usual coding style; _private_ methods are usually defined instead of relying on internal functions.
Note that this code is most probably going away in the next (post 1.10) version of Django.
I think we could swap this and the previous `if` over - no reason to do the `has_related` check if we've specified the list. Alternatively, move the `has_related` inside an `if ... is False`
Why cast to a tuple? We could just check if it's falsey...
Just because you _can_ cram this all on one line, doesn't mean you have to. This would be a lot easier to read as: ``` field_list = tree[self] if self.proxy: field_list += tree[self.concrete_model._meta] for f in field_list: ... ```
I'm usually fairly conscious of higher level abstractions accessing very detailed properties or methods from lower down the stack. I would prefer a method within the `sql/query.py` Query object so that other implementations that may or may not yet exist have access to override this behaviour. I'd consider pushing everything from retrieving the inner query into a method and returning on that. ``` return obj.query.as_subquery_filter(obj) ``` Method name and args probably need work but that's the kind of thing I'm considering.
You can remove parentheses.
What happens if the pk field isn't in the self.query.select? I think using self.query.get_initial_alias() instead of self.query.get_meta().db_table should fix this issue.
Might want to join both branches now that they are mostly similar. ```python select_list = [] cols = self.query.default_cols or self.query.select for col in cols: select_list.append(select_idx) select.append((col, None)) select_idx += 1 klass_info = { 'model': self.query.model, 'select_fields': select_list, } ```
`if it encounter` => `if it encounters`
This unfortunately won't work if the subquery refers to any outer references as these must be included in the group by clause.
Do we need to check `removal_value`? It should be enough to check that `new_value` is not en empty set, I cannot imagine a different scenario :thinking: ```suggestion if new_value: ```
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Indexes are not constraints, generally.
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
As an example. The method signature should be ```python def rename_model(self, app_label, old_model_name, new_model_name): ... ``` And be called from `RenameModel.state_forwards` as `state.rename_model(app_label, self.old_name_lower, self.new_name_lower)` instead of passing the `Operation` instance along.
They should always be the same but you might want to use `model._meta.object_name` instead.
Any reason not to use a list comprehension? I think that's usually more readable.
This logic seems a little convoluted. Consider: ``` python conns = connetions.values() if settings.DATABASE_ROUTERS else [connections[DEFAULT_DB_ALIAS]] for conn in conns: if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(router.allow_migrate(connection.alias, label) for label in labels)): ```
Right (actually there's a bug in that code, the `ImproperlyConfigured` can never be raised).
Chop blank line.
I would also consider turning that into an instance method called something like `get_runner()` and starting each test method with `runner = self.get_runner()`. The reason is that instantiating a runner is "cheap." You also don't have to think / worry about whether the runner has state that you might unwittingly be carrying from one test to the other (e.g. attributes set when a method is executed).
```suggestion # RemovedInDjango50Warning class NoOpTestRunner(DiscoverRunner): def setup_test_environment(self, **kwargs): return def setup_databases(self, **kwargs): return def run_checks(self, databases): return def teardown_databases(self, old_config, **kwargs): return def teardown_test_environment(self, **kwargs): return class DiscoverRunnerExtraTestsDeprecationTests(SimpleTestCase): msg = 'The extra_tests argument is deprecated.' def setUp(self): self.runner = NoOpTestRunner(verbosity=0, interactive=False) def test_extra_tests_build_suite(self): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.build_suite(extra_tests=[]) def test_extra_tests_run_tests(self): with captured_stderr(): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.run_tests( test_labels=['test_runner_apps.sample.tests_sample.EmptyTestCase'], extra_tests=[], ) ```
Maybe just do this in the `__init__()` method of your subclass, after calling `super()`? That will keep all your modifications together in one place. This will also let you remove the `hasattr` check in `get_test_runner_kwargs()`.
I would make the test of `build_suite()` and `run_tests()` separate test methods.
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
should this be used? (with a test too) arguments -> options
I feel like this boiler-plate could be handled more nicely. For example, what about defining a function above that looks something like-- ```python def add_argument(parser, name, *args, help=None, **kwargs): if name in self.suppressed_base_arguments: help = argparse.SUPPRESS parser.add_argument(*args, help=help, **kwargs) ``` Then each `parser.add_argument(...)` would become `add_argument(parser, name, ...)`. I also think it would be better if the convention were for the string in `suppressed_base_arguments` to match the first option string passed to `parser.add_argument()` (e.g. `--force-color` instead of `force-color`). I think it would be easier to remember. Also, if that were done, the name wouldn't have to be passed a second time, or manipulated in any way inside the helper function above before checking for membership in `self.suppressed_base_arguments`.
the wording used for similar options is simply "Can be used multiple times."
I think you could write `self.program_options.append('-f')` here. This way you won't need to add a new parameter to `compile_messages`.
The latin1 encoding mess is a WSGI thing, Django wasn't always a WSGI framework, and who knows what will be the next best thing in the future. When these things were contained in the WSGIHandler that made sense, but if we extract a reusable function it shouldn't be tied to such specifics.
I would have been interested in something closer to werkezeug's. That takes encoding as a parameter, etc. **Edit**: TL;DR skip to https://github.com/django/django/pull/2932/files#r15440287
`repercent` is a confusing name, maybe `repercent_broken_unicode`? Also it needs a docstring with pointers to the RFC etc.
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
Another vote for moving this logic into apps as a private method.
Thanks for the link, would be nice to have a ticket for it, probably.
Yes, this should be taken care of before.
a nice line to see gone
I don't think we need an explicit `if` here. `_pending_lookups` is `{}` by default and thus the for-loop body isn't run anyways.
This version works fine, however it's a bit confusing that we concatenate escaped and unescaped string. I would use `middle` for both, e.g. ```python punctuation_count = len(middle_unescaped) - len(stripped) trail = middle[-punctuation_count:] + trail middle = middle[:-punctuation_count] ```
I think I would define the additional parameters as keyword parameter, as in `__call__ `. BTW, thanks for fixing this thread issue I created!
Need spaces around `+` sign.
docstring with example input/output would be really helpful
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
I would also consider turning that into an instance method called something like `get_runner()` and starting each test method with `runner = self.get_runner()`. The reason is that instantiating a runner is "cheap." You also don't have to think / worry about whether the runner has state that you might unwittingly be carrying from one test to the other (e.g. attributes set when a method is executed).
```suggestion # RemovedInDjango50Warning class NoOpTestRunner(DiscoverRunner): def setup_test_environment(self, **kwargs): return def setup_databases(self, **kwargs): return def run_checks(self, databases): return def teardown_databases(self, old_config, **kwargs): return def teardown_test_environment(self, **kwargs): return class DiscoverRunnerExtraTestsDeprecationTests(SimpleTestCase): msg = 'The extra_tests argument is deprecated.' def setUp(self): self.runner = NoOpTestRunner(verbosity=0, interactive=False) def test_extra_tests_build_suite(self): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.build_suite(extra_tests=[]) def test_extra_tests_run_tests(self): with captured_stderr(): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.run_tests( test_labels=['test_runner_apps.sample.tests_sample.EmptyTestCase'], extra_tests=[], ) ```
Maybe just do this in the `__init__()` method of your subclass, after calling `super()`? That will keep all your modifications together in one place. This will also let you remove the `hasattr` check in `get_test_runner_kwargs()`.
I would make the test of `build_suite()` and `run_tests()` separate test methods.
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
Seems wrong to hard code this list when Django fully supports user-written commands.
What about just adding `**kwargs` here? It should be the same but without the need for the creation of an intermediate dictionary.
Historic moment! I don't see a reason why we shouldn't use them.
Is it too late to move the conversion of `auto` to an integer to a post-processing step (e.g. your `get_num_test_processes()` function)? I feel like the `parallel_type` function's job here should only be to check that the value equals `auto` if the value is a string, but not to apply the environment-dependent business logic to convert `auto` to a number. (I also see that `get_num_test_processes()` is already calling `multiprocessing.cpu_count()`, so there may be some duplication of logic with the way things are currently structured.)
I think that this comprehension could be collapsed to a single line.
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
I think invalidating the `size` cache would make more sense than re-computing the size on every single write. ```python self.__dict__.pop('_size', None) ```
```suggestion file_path = Path(__file__).parent / 'test.png' ```
> this test is checking the support for a possible object that is seekable but has no `.tell()`. > `tempfile.NamedTemporaryFile()` has `.tell()`. Just as an aside, whether there is any change here or not, but you could do: ```python with tempfile.NamedTemporaryFile() as tmp: del tmp.tell # Emulate seekable file handle without .tell(). ... ```
`'rb'` flags are unnecessary.
Or you can still use f-strings for this too: ```python number = f'{number:_.{decimal_pos}f}' ```
Why don't you do the decimal precision as part of the format expression? Something like: ```python number = ("{:_.%sf}" % decimal_pos).format(number) ```
IMHO I would simply use `_` not `,` and always replace. Reduces complexity and a replacement isn't too slow. In fact, it's probably faster than the if clause. If clauses can significantly slow down code execution, since your processor doesn't know which instructions to preload until you reached that particular instruction and decided where to go from there.
`as defined by the arguments` is not really telling me anything. I would either add a longer more descriptive doc string or none.
Besides, this change doesn't improve speed. From experience, any change will slow down reviews and hinder this from being merged ;)
Combining this commit with the next one seems fine. It works the same as override_settings, but you can use `with self.settings`.
Use single quotes unless a string contains double quotes. Also, this looks fine to fine on the line above.
this doesn't seem relevant since we're testing with dry run anyway.
```suggestion backend = self.base_params['BACKEND'] ```
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
rather than custom caching with a dict, this might be clearer with a module-level function using `@lru_cache(maxsize=2)`, with the current value of `USE_TZ` as the only argument. It would save some lines and clarify it's a cache.
this now generates invalidate SQL if both assignments happen: ``` chainz@localhost [7]> set session transaction isolation level read committed, sql_auto_is_null = 0; ERROR 1064 (42000): You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near 'sql_auto_is_null = 0' at line 1 chainz@localhost [8]> ``` Instead we should generate two statements, they can be sent as a single sql string to avoid roundtrips though by using a `;` delim: ``` chainz@localhost [8]> set session transaction isolation level read committed; set sql_auto_is_null = 0; Query OK, 0 rows affected (0.00 sec) Query OK, 0 rows affected (0.00 sec) chainz@localhost [9]> ```
I'm omit the intermediate extra variable in favor of: ``` getattr(logger, level)( message, *args, extra={...}, exc_info=exc_info, ) ```
Or in some cases (e.g. CSRF) it's because we want to log the response under a particular non-default logger. But even in those cases, we never want to double-log a response.
I think the `@property` syntax would be more readable here.
I wouldn't create the postgis_topology extension, as AFAIK it is not used currently in Django.
Indents should be four spaces.
I don't think it's accurate to query the database at init time, as we are not even sure yet that we will need this info. I'd rather have a cached property, so it will only get fetched when we really need it.
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
param -> params
`Company` doesn't have a default ordering so we need to use `assertCountEqual()` or add `.order_by(...)`.
```suggestion msg = 'Slice stop must be greater than slice start.' ```
I don't think it's necessary. In all cases we test the same (default) implementation. A single assertion should be enough, e.g. ```python def test_invalid_fields_in_slicing_f_expressions(self): msg = 'This field does not support slicing.' with self.assertRaisesMessage(NotSupportedError, msg): Company.objects.update(num_chairs=F('num_chairs')[:4]) ```
Perhaps extend this for a wider range of field types, e.g. `BooleanField`, `IntegerField`, `FloatField`, etc.
omit the blank line
oh that's what i've missed. thats true there is something wrong on that line
Is there a reason that I'm missing (probably) that the field's length is 36 (and each DB's backend definition is 36, with the exception of postgres, which has the native datatype)? Removing the dashes (if a string) or calling `.hex` turns the value into 32 chars, which both `uuid.UUID()` and postgres' datatype support as a input format, and both use the dash-inclusive output format.
`'Boolean (True, False or None if nullable)'` ? cf. `NullBooleanField.description`
Marc, did you try to store by default in a binary column? AFAIK PostgreSQL is using a binary field internally.
(same pattern as above, if you change it)
In such case we will need to calculate this multiple times because it is inside a loop. Moreover `if` is for a deprecated usage, so ...
> 1. we don't process a model which is processed already. I restored this. > 2. we don't process extra model when we find the `alias` in the join column names. Yes, but we're doing this multiple times (for each model), so :heavy_plus_sign: / :heavy_minus_sign: . I believe it's better to pre-calculate. > 3. we don't need to process model if `allow_aliases = False` Right, we can optimize this.
You could retrieve `target_model` while avoiding creating a an unnecessary `list` and `dict`. ``` python for seen_model, seen_alias in seen_models.items(): if seen_model and seen_alias == alias: ancestor_link = seen_model._meta.get_ancestor_link(model) if ancestor_link: column = ancestor_link.column break ```
You can have a flatter function (less nesting) by doing: ```python if not remote_field: continue ```
no blank line
I think that `ValidationError` is only raised out of `Field.to_python()`, not `Widget.value_from_datadict()`, so this can be simplified: ```suggestion widget = field.hidden_widget() value = self.form._widget_data_value(widget, self.html_initial_name) try: initial_value = field.to_python(value) ```
Remove arguments from `super().`
I would prefer `tag=None` because we will be able to pass `None` to get the default value.
Would `tag='label'` be simpler? Also perhaps the docstring could be updated with the new param, since it's not always `<label>` now.
How about: ``` return super(JSONField, self).has_changed(initial, data) or str(initial) != str(data) ``` I think there's no need to repeat the docstring from the superclass but explaining why the `str()` comparison is needed would be useful.
I think the prompt should still happen if `destination_path` is None since we don't check existence in that case. Only skip the prompt if we're certain the destination doesn't exist.
Use hanging indent: ``` destination_exists = ( self.storage.exists(destination_path) and ... ) ```
I think the warning should happen in this case, since we didn't check if files exist or not, it's better to be safe.
Can you reference the ticket number in the docstring, please.
Can you reference the ticket number in the docstring, please.
~~Should we check `posix` instead?~~ ```suggestion if sys.platform != 'win32': ```
I think we should be more explicit here, maybe: ```python if not value or '://' not in str(value): raise ValidationError(self.message, code=self.code) ... ```
Oops, I misread the diff and see that you only modified the existing archives. Still an explanation of exactly what going on would be nice as it's not obvious to me.
Do we need to check a `current_mask`? This code is reachable only when `umask` is set. ```suggestion kwargs['umask'] = umask ```
```suggestion if scheme and scheme not in self.schemes: ``` 🤔
This docstring doesn't have much value, please remove it.
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
I would separate each `with` statement with a line break. right now it looks like a huge block of stuff.
For test doc strings, rather than "Test X" I try to describe the desired behavior: `A ValueError is raised when the incorrect object type is passed to a query lookup."
I think this should be a `ValueError`
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
"Both Y and X must be provided". Switch the Y and X in the error.
blank line not needed
It might be a tiny bit faster to create `TEST_RANGE - Author.objects.count()` objects rather than deleting the existing ones.
However, I think it's worth to keep it for backends without built-in converters.
This is already covered by `tests.queries.test_db_returning.ReturningValuesTests.test_bulk_insert`, that's why `ReturningValuesTests` tests crash on SQLite 3.35+ (see #14227).
Yes please remove unnecessary blank lines.
I'd prefer something that makes it slightly more obvious where the exceptions are expected to happen: ``` python try: site = getattr(obj, field.name) except Site.DoesNotExist: pass if site is not None: object_domain = site.domain ``` This is a slightly different issue, but it's not clear if `Site.DoesNotExist` can actually happen (no tests fail if it's removed).
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
I would leave it as a `lambda`.
Wrap lines closer to 79 characters and use () when referring to a function. ``` # get_current_site() will lookup a Site object, so these must match the # domains in the MockSite model. ```
Is there a need to hardcode pks? This is generally to be avoided, I think.
single line please
to ensure the a typo in the credentials isn't the reason for the failure, you could create a dict with them and verify authentication is successful before you set `self.user.is_active = False`. e.g. `self.assertEqual(authenticate(**credentials), self.user)`
as above, state expected behavior in a docstring
I'd make this a separate test and then you can decorator the test method instead of using `with ....`.
same thing here about assuming `is_active` exists and `not user.is_active` -- probably need some tests for that case.
"Test checks MySQL query syntax"
Small nitpick, I would use `bulk_create` here. ``` python Article.objects.bulk_create( Article(pub_date=pub_datetime.date(), pub_datetime=pub_datetime) for pub_datetime in pub_datetimes ) ```
I'd use `Article.objects.create()` instead of `.save()`
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
Do we need the `tzinfo` bit for the test? I'm worried relying on `get_current_timezone` could make the test flaky.
`__str__` is not necessary.
I added a temporary storage.
Unnecessary -> ```suggestion def __str__(self): ```
Use hanging indent: ``` special_people = models.ManyToManyField( 'Person', through='ProxiedIndividualCompetitor', related_name='special_event_set', ) ```
You can reuse the `PlotDetails` model instead of defining a new one as it slow downs the test suite execution.
We don't need to add the `_` prefix to the new methods. They are considered a private API even without it.
As far as I'm aware we don't need to iterate twice over the same list: ```suggestion return { '%s.%s' % ( fixture_name, '.'.join([ext for ext in combo if ext]), ) for combo in product(databases, ser_fmts, cmp_fmts) } ```
We try to avoid non 4-space indent. I'd do something like: ``` return ( connection.features.can_defer_constraint_checks and not connection.needs_rollback and connection.is_usable() ) ```
`product()` handles iterables so we don't need to call `list()`: ```suggestion cmp_fmts = self.compression_formats if cmp_fmt is None else [cmp_fmt] ```
May be an easier change for django reviewers if you keep this block in the same format as the one you replaced
Please don't change all the other unaffected lines.
They can be empty for subclasses, I think we can leave it that way.
Please create a `_stream()` helper with this signature and use it so that the deprecated parameters don't appear in the `stream()` signature.
I see, thanks for your answer. I really don't want to hold the template based widget stuff from landing any longer. I suppose this is something we could refactor later on.
Oh, right, of course; it's because of the default behavior of FS loader to look back at the engine's dirs.
yeah I don't see a reason why the imports are not top-level and we don't call the functions directly.
`None` is being passed for the `app_configs` argument - even though the check ignores `app_configs`, `[]` should be used as a more valid test value. I think it's worth looking into refactoring these tests in general, as you're write these property inner-imports are a bit confusing, made a note to self.
It's the pattern that django-secure used. Not sure if the reason is still relevant. \cc @carljm
I don't see much value in this docstring.
I don't see much value in this docstring.
I think that should be `hire_date` (two words).
Use single quotes.
Use single quotes.
note that `Meta` should appear after fields per: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#model-style I made this one change when I committed it.
Since you don't actually need the instances of all those models, can you use `WindowTestModel.objects.bulk_create()` please.
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
Seems to fine on a single line.
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
I would add quotes: ```suggestion violation_error_message = _("Constraint '{name}' is violated.") ```
Use meaningful test names, e.g. `test_no_arguments`. Also I would have 3 tests and use a loop a `subTest()` to test the three cases for each template. For example: ``` tests = (('0', 'votes'), ...) for value, expected in tests: with self.subTest(value=value): output = self.engine.render_to_string('pluralize01', {'value': value}) self.assertEqual(output, expected) ```
OracleDbshellTests ("TestCase" implies this is meant to be subclassed.)
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
Does it work if you use `override_settings` for this too? That would be cleaner.
This doesn't seem correct as `SimplePoFileTests` no longer has any tests in it so now this subclass doesn't do anything.
multi-line as other messages: ``` "The model cannot have more than one field with " "'primary_key=True'.", ```
```suggestion return rows_updated ```
No need to use `any`... instead: `getattr(create_field, 'primary_key', False) or (a and b) ...`
"foreign key id" may not be the best wording. For example, this also applies to subclasses like OneToOneField.
```suggestion rows_updated = 0 if not objs: ```
I think `f.remote_field.through` should always be available.
All m2m fields should have `remote_field.through` defined.
I suggest you skip the check (`return []` early) if the intermediary model (`self.remote_field.through`) is not resolved. That is `isinstance(self.remote_field.through, six.string_types)`. Also I would store `m2m_db_table` in a variable as you'll need to reuse it to lookup `registered_tables` below.
I guess renaming the `fields` variable to `columns` wouldn't hurt here. At first I assumed `fields` was a list of `db.models.Field` and thought there could be an issue with the use of `f.name` instead of `f.column`
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
might as well use `setdefault` in the test as well
this line should be: `def __init__(self, *args, **kwargs):`
`assertEqual` (the version you have now is a deprecated alias)
seems like a helper method to get the attachment path would save some repetition
Both `response` vars are unused.
Please use single quotes.
Yes. However, note that isn't sufficient to replace all occurrences of e.g. `r'\Z'`, for example `r'a\\\Z'`.
In the pattern I provided, the `'Z'` is a plain `'Z'` (because the backslash preceding it is escaped), but your substitution line is removing it.
```suggestion def remove_non_capturing_groups(pattern): ```
```suggestion 1. (?P<a>\w+)/b/(?:\w+)c(?:\w+) => (?P<a>\\w+)/b/c ```
This can be moved outside of `try...except...`.
You shouldn't need the extra parentheses inside `extend()`, FYI.
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
Is this line correct? Above it's `subTest(url=url_name)` but then we `reverse(url_name,...)`
Use single quotes consistently.
I second Tim. Unless a very specific use case, mixins should be on the left.
Read also https://www.ianlewis.org/en/mixins-and-python
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
chop "one of" add comma before "or"
put closing parenthesis on the next line
However, I think it's worth to keep it for backends without built-in converters.
This is already covered by `tests.queries.test_db_returning.ReturningValuesTests.test_bulk_insert`, that's why `ReturningValuesTests` tests crash on SQLite 3.35+ (see #14227).
There's no assertion for `created_date`. You could check that is `datetime.date`and maybe also that `created_date == created.date()`? Alternatively you could drop `created_date`.
[`assertEquals` is a deprecated alias](https://docs.python.org/3/library/unittest.html?highlight=assertequals#deprecated-aliases) ```suggestion self.assertEqual(obj.pi, 3.14159265358979) ```
`RETURNING` from `UPDATE` is out of this ticket scope.
How about making these two flags `False` by default, thus making the feature not causing backwards incompatible changes.
I think we should add this to the opclasses as well then.
Well, mariadb support in the mysql backend. Will get on to that soonish.
I think this can be single lined: ```python # Does the backed support window expressions (aggregate OVER (expression))? ```
We should add release notes for these feature flags.
`depth a recursive subquery references adds` → `depth recursive subquery references add`
prefer assertRaisesMessage to make sure we get the `ValueError` we expect and not some other one.
I feel worried about keeping a `while True` loop here. I will lead to an infinite test run if the implementation of the code to be tested is broken. Can you change that into a for loop. You are already counting `i` upwards, but aren't using it.
I may be missing something, but it seems this line could be bumped out one indent - no point in re-setting `prefix` to None on every product, when it won't be used again until the next outer (count) loop.
`context.exception.message` -> `six.text_type(context.exception)`
We can leave an assertion for `value()`, but the two above assertions should also be added. It's not enough to check that `as_p()` is not `None`.
I don't see much value in this assertion we should check `as_p()` and `errors`, e.g. ```python self.assertEqual(form.errors['json_field'], ['This field is required.']) self.assertIn('null</textarea>', form.as_p()) ```
`clean()` works without this patch. The issue is in rendering a bound field. We should check `errors` and `as_p()`.
> I guess the behaviour of the field informs what the widget/form render? Yes.
This is the same as the previous assertion. I'd think only 1 assertionis needed since all the `as_*` methods use `_html_output()`.
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
Please move `clear()` below `set_many()` to keep the order consistent with the definition in BaseCache and other backends. (It's probably worth ordering the methods in `RedisCacheClient` in the same way.)
Instead of defining `success`, just return directly in the above code. I think it is simple enough.
I take this back and have a deeper look at the tests.
FWIW +1 to doing it as a separate clean up. IMO it'll be much clearer what change was where looking back that way.
version -> pickled_version `current_version = get_version()` (so we don't have to call it multiple times) check `if version:` first so we can skip `get_version()` if no version on pickled model.
you need to drop the `__class__`, the `object` itself should be an instance of `Author`
`msg = None` then only warn if msg is set.
with -> the
The idea is that we could always have all field_names and values present for the from_db() call. The QuerySet iterator is using some extra effort to supply just the field_names and values which are non-deferred. Instead we could supply all field_names and have DEFERRED objs in the values for those fields which are deferred. This might make the logic in queryset iteration a bit simpler, though there isn't a guarantee of that. The real TODO is to check if this is actually a good change or not. Sorry I haven't been able to work on this issue, I have been too busy lately.
Given the logic of this method, I'd reverse the conjuncts here: ``` If the lookup is simple (no double underscores) and the node is carrying generic foreign key lookup... ``` Also, the project doesn't make use of `:param lookup:` and `:return:` annotations.
I have a feeling something else if off here. The outer query's joining strategy should not have to special case inner queries as they are self contained expressions. My guess is that something is getting mixed up wrt to aliases because the same model is being involved in the outer and inner queries.
Please put the test in `AdminActionsTest`.
I don't think we want to special case `Subquery`, feels like we'll want to duck type on `conditional` ```suggestion if not isinstance(other, Q) and not getattr(other, 'conditional', False) is True: ```
Given `self.inner_votes` is an instance of `collections.Counter` this could be simplified to `self.inner_votes.update(inner_votes)`.
You can have a look at 9bf652dfd6a738fd841471f6abd71cba1b206d9f as an example of how we introduced object level permission to authentication backends.
Having an overridable method seems like the most orthodox OOP solution (it's what a Java programmer would do :-) ) but I'm not convinced it really gives a useful abstraction: by coincidence it's the right place to make this one change, but I'm not sure there's a useful class of future modifications it opens up, so it feels like overkill to me. My thought with an instance variable was just to set it in the constructor in the base class, and overwrite it in the subclass constructor (not exposing it as a kwarg). I'm not sure there's any advantage to this; I think I was thinking about this because it's what I'd do in C++. I don't have a particularly strong feeling on this. I think if I were writing it I'd go with the class-level attribute.
The parameter to this method seems odd to me. As it stands, no caller is explicitly using the parameter in a call to the method and I can't see many legitimate uses for it in derived classes. I think you're effectively just using the default value as a space to store a class-scope variable. Would it be simpler to just assign a member on the class? Or on the instance, if you prefer.
Remove one of these blank lines (should only be two total). (`tests/file_storage/tests.py:454:1: E303 too many blank lines (3)`)
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
`This test` is unnecessary. Please write `skipUnless` in one line e.g. `@unittest.skipUnless(connection.vendor == 'mysql', 'MySQL specific test.')`.
Indents should be four spaces.
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
from Python, so we quote and substitute parameters manually.
You should try to reuse `connection._connect_string()`.
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Trailing comma: ```suggestion migrations.RunPython.noop, ```
```suggestion 'INSERT INTO test_runsql_pony (pink, weight) VALUES (1, 1)\n', ```
Perhaps we should continue to test the simpler case where we don't provide a `name` or `condition`.
This is not necessary.
Can you use `['indexes']` here? If not, the list comprehensions in the next lines have a `not in None` and will fail.
Nitpick but `dict.get` default value for a missing key is already `None`.
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
These are unnecessary ```suggestion ```
I see. Any thoughts about passing the _local_ field instead of the remote one and the model it's from? e.g. in the case of tests below `field_name` would be `'uuid'` instead of `'question_with_to_field'`. That's how the other `to_field` enabled admin views work and what `to_field_allowed` expects. It also feels like a nicer API to me and would allow you to stop passing `app_label` and `model_name`.
This can raise a `LookupError`
If I understood the above code correctly, then `self.field` is on the source model, whereas `self.model_admin` points to the target admin, I think we should really rename those to avoid confusion.
`getattr` will throw a `ValueError` if the `to_field` does not exist, this has to be handled.
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
I will move this test to the `model_forms/tests.py`.
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
You can probably use `assertSequenceEqual` here which might be a bit nicer.
It would be nice to be consistent about the ordering in `assertEqual` using it's `(variable, 'expected value')` but here and a couple other places it's opposite.
I renamed the test and removed the docstring.
Add trailing comma.
```suggestion time_keeper.results() ```
```suggestion time_keeper = TimeKeeper() if options.timing else NullTimeKeeper() with time_keeper.timed('Total run'): ```
We shouldn't silently change passed parameters. IMO it better to raise an exception like we do now: ``` $ export DJANGO_SETTINGS_MODULE=test_oracle $ ./runtests.py queries --parallel=2 Testing against Django installed in '/django/django' with up to 2 processes Found 416 test(s). Creating test database for alias 'default'... Creating test user... Cloning test database for alias 'default'... Traceback (most recent call last): File "./runtests.py", line 659, in <module> failures = django_tests( File "./runtests.py", line 385, in django_tests failures = test_runner.run_tests(test_labels) File "/django/django/test/runner.py", line 881, in run_tests old_config = self.setup_databases( File "/django/django/test/runner.py", line 787, in setup_databases return _setup_databases( File "/django/django/test/utils.py", line 217, in setup_databases connection.creation.clone_test_db( File "/django/django/db/backends/base/creation.py", line 239, in clone_test_db self._clone_test_db(suffix, verbosity, keepdb) File "/django/django/db/backends/base/creation.py", line 255, in _clone_test_db raise NotImplementedError( NotImplementedError: The database backend doesn't support cloning databases. Disable the option to run tests in parallel processes. ```
`run_keeper` → `time_keeper` for consistency? It feels like a hangover from when the class was called `time_keeper` before it changed to `TimeKeeper`. Are we also not still using single quotes? ```suggestion time_keeper = TimeKeeper() if options['timing'] else NullTimeKeeper() ```
Something is wrong with the indentation here, you might want to use `flake8` from the top directory to spot warnings.
Won't this result in a confusing SQL-level error if you pass in `None` for `expression` or `pos` by accident? I'm assuming `length` is the only one we actually expect to possibly be `None`. If that's true, I think it would be better to do something like: ``` expressions = [expression, pos] if length is not None: expressions.append(length) ``` Or, if you prefer: `expressions = (expression, pos, length) if length is not None else (expression, pos)`
Ah! Of course, sorry I missed that.
Can we move this function up by `get_traceback_highlighter`. (That way we keep the two related helper functions next to each other.)
I think we can drop the empty line here.
You've added seven asserts, but only two are related with this fix, so I think it will be better to send: ```python self.assertEqual(stringformat([1, None], 's'), '[1, None]') self.assertEqual(stringformat({1, 2}, 's'), '{1, 2}') self.assertEqual(stringformat({1: 2, 2: 3}, 's'), '{1: 2, 2: 3}') ... self.assertEqual(stringformat(object(), 'd'), '') self.assertEqual(stringformat(None, 'd'), '') ``` in advance in a separate PR.
This is the same test as above.
Use a single quote.
I think these are too internal, I would rather check that `MultiValueDict` is pickleable: ```python pickle.loads(pickle.dumps(...)) ```
I see your point and can't think of anything sensible either. Assertion-less tests just seem pointless other than to put a tick in the coverage box.
Just make it: ``` if len(expressions) < 2: ``` That avoids problems with sqlite and mysql. GREATEST(x) is always x on backends that support single arguments anyway.
I'd suggest a `ValueError` instead. And this requires also a test. You can see what `Substr` does.
You can ditch the temporary variable, and just the arguments directly `__init__`.
The problem here is that you can't just use `Value('')` for the default. If you're doing `GREATEST(date_field, other_date_field)` then coalescing a date type with a char type is going to produce an error. The type itself will probably have to accept a default. ``` sentinel = object() def __init__(self, *expressions, **kwargs): ifnull = kwargs.pop('ifnull', sentinel) if ifnull == sentinel: raise ValueError('ifnull is required') if ifnull is None: # user has asked NOT to use coalesce else: self.ifnull = self._parse_expression(ifnull) ``` And then you would use `Coalesce(expression, self.ifnull)` in the coalesce method, or completely skip calling the coalesce method if `ifnull is None`. This is just one idea, but probably the best one I have right now. I don't really like forcing a user to provide an `ifnull` though, because it feels like we're disadvantaging the user. Another idea would be to use a backend feature. Something like `greatest_least_uses_nulls`, and then the tests could switch on that feature flag to provide different test results. I'd probably like to get a rough consensus on which way to go here.
The SQL function `COALESCE` can be called with a single argument (at least on PostgreSQL). That might not be useful, still I believe Django shouldn't prevent this.
Use single quotes consistently.
Could use `assertSequenceEqual` to avoid the `itemgetter`
think these newlines can be omitted -- a parens on its own line adds spacing.
```suggestion authors, [25, 34, 35, 37, 45, 46, 57, 29], lambda a: a['age'] ```
This can be single-lined.
Does it work if you use `override_settings` for this too? That would be cleaner.
There's a class method called `setUpTestData()`. Please use that instead.
Remove ticket number. Capitalise first word of sentence.
use snake case, please: `test_login_required()`
`settings.LANGUAGE_CODE` as you pointed out.
No trailing comma (see also 83a36ac49a98d5d8801ed8428612e9a56aeb8699).
Can you use `self.assertNumberMigrations()`, `self.assertOperationTypes()` and `self.assertOperationAttributes()` instead of things like `self.assertEqual(first_action.__class__.__name__, "AlterUniqueTogether")`, please. Have a look through at the top of the test case on which arguments they expect and how they work. They are also heavily used all over the place in the autodetector tests. (A overall cleanup is in #3564.)
I've suggested https://github.com/django/django/pull/9232 to avoid redundant `version_info` in Django.
Chop blank line.
Add trailing comma.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
`UniqueConstraint` not `Index`.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
This is the same as the previous assertion. I'd think only 1 assertionis needed since all the `as_*` methods use `_html_output()`.
Maybe: ```suggestion template_name_label = 'forms_tests/cyclic_context_boundfield_render.html' ```
Would it be enough to check `form.fields`? This might make the test a bit easier to follow instead of having to parse the HTML to see what's expected..
Does it also work if you leave away the wrapping DIV? It isn't obvious to me that the issue from the ticket (`'<a/><b/>'` should be contained by `'<a/><b/><c/>'`) is being addressed by this change.
The expected value should be a second argument in `assertEqual()` and `assertHTMLEqual()` assertions.
Chop blank line.
) goes on the next line as in other tests
Docstrings should state the expected behavior and omit prefixes like "Make sure" since all tests make sure of things.
This should be: ```python try: cursor.execute('SET standard_conforming_strings TO ON;') ... finally: cursor.execute('...') ``` so that if the assertion fails, the "tear down" in finally still happens. The second query shouldn't assume the original value of standard_conforming_strings is "on".
Please remove the unnecessary semicolon.
Hi, I was looking for a domain validator in Django and I've found this PR. I think a domain name should also be checked against a max length, as `URLValidator` does (https://github.com/django/django/blob/master/django/core/validators.py#L137).
This will overwrite an explicitly given message if you use ``` python validator = DomainNameValidator(accept_idna=True, message='Only IDNA domain allowed') ```
more like: `'^%(negative)s\d+(?:%(sep)s%(negative)s?\d+)*\Z' % ({'negative': '(-)?' if allow_negative else '', ...})`
I'd rather build regex string with interpolation so as not to repeat the other logic.
TIL that character classes also work inside `[]` :D
`~` is not a supported operator, this should be `-`.
About Josh's suggestion, we've considered try/except/fail an antipattern because it hides the original exception and thus makes fixing a failure more difficult. There's no problem with a test erroring rather than failing.
Generally we don't include the ticket numbers unless the issue is an obscure one that benefits from additional context that the ticket provides. If so "Sentence.... (#19513, #18580)." is the usual format
Per new code guidelines, can we use `assertIs`? :)
use `with self.assertRaisesMessage(FieldError, "Aggregate functions are't allowed in this query."):`
use single quotes for consistency
return without intermediate `etags` variable
When changing docstrings, we are updating them to use PEP 257 verb style: Parse / Return, etc.
```suggestion request.method in ('GET', 'HEAD') ```
PEP 8 hedges about line breaks and binary operators but suggests ultimately that breaking before the operator is better. As long as we're touching this I would suggest breaking before the operators.
We use `new_default` only when `old_field.null and not new_field.null` so IMO it's fine to use ```diff diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py index bfccf5e8fb..8cd5e11bbf 100644 --- a/django/db/backends/base/schema.py +++ b/django/db/backends/base/schema.py @@ -675,17 +675,17 @@ class BaseDatabaseSchemaEditor: # 3. Replace NULL constraint with NOT NULL # 4. Drop the default again. # Default change? - old_default = self.effective_default(old_field) - new_default = self.effective_default(new_field) - needs_database_default = ( - old_field.null and - not new_field.null and - old_default != new_default and - new_default is not None and - not self.skip_default(new_field) - ) - if needs_database_default: - actions.append(self._alter_column_default_sql(model, old_field, new_field)) + needs_database_default = False + if old_field.null and not new_field.null: + old_default = self.effective_default(old_field) + new_default = self.effective_default(new_field) + if ( + not self.skip_default(new_field) and + old_default != new_default and + new_default is not None + ): + needs_database_default = True + actions.append(self._alter_column_default_sql(model, old_field, new_field)) # Nullability change? if old_field.null != new_field.null: fragment = self._alter_column_null_sql(model, old_field, new_field) ```
nitpicking: could you swap these two checks: `old_default != new_default and not self.skip_default(new_field)`
Why are you setting it to `None` here? It looks like it's not used between this line and line `#581`.
Use `drop=True` rather than an arg for better readability. Use a different var for `sql`here, maybe `changes_sql`? It's a little confusing to have the `sql` name reused in the next line.
Maybe `null_actions` for consistency with `post_actions`? And move it to where we init `actions` and `post_actions`? L581.
`ERROR` in `assertLogs()` is still missing: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ```
Yes, we should check if it's on `ERROR` level: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ... self.assertEqual(cm.records[0].getMessage(), ...) ``` and assert a message (`cm.records[0].getMessage()`) and an exception info (`cm.records[0].exc_info`).
maybe I'm being a stickler, but I'd make extra assertions on the log record's level and message
why not use `a_signal` in this test? The signal objects seem to be identical.
I would move it to the `test_send_robust_fail()`.
Is there a reason to add a `pass` statement here? The docstring should be enough, you can take a look at [Why does python allow an empty function (with doc-string) body without a “pass” statement? (stackoverflow)](https://stackoverflow.com/a/17735171).
I think Django has generally included `pass` (perhaps a full audit could be done). I'm not sure that omitting is considered "an obscure feature" and I don't have a particular preference one way or another.
My view is that Python design specifically allows to omit 'pass' when docstring is present, in other words it's not some corner case or side effect, it's a style and design decision that a docstring is considered as "body". It's not a strong preference, but I'd prefer if django did not enforce adding 'pass'.
I feel like this setting is out of context here. Should `AppConfig` only provide information in the context of an app? If I want to find out what kind of primary key a given app is asking for, I could look for `AppConfig.model_default_pk`, but if we're overriding if with a project setting it can cause some confusion.
```suggestion def _is_default_auto_field_overridden(self): ```
This should probably be updated with the new gdalinfo, which basically includes one more line in the coordinate system: `AUTHORITY["EPSG","3086"]]`
I updated the file on my branch such that the wkt contains the correct information. `ds.srs.srid` returns `3086` https://github.com/geodesign/django/blob/raster/django/contrib/gis/gdal/tests/data/raster.tif
no space for "Spatial Reference"? (or no caps if it's not meant to refer to the class)
two spaces before #
This cleanup is not related with a patch please move it to a separate commit/PR.
Why `stacklevel=2`? :thinking: IMO we can remove it.
True, thanks :+1:
Also `favour` → `favor`.
`django.conf.urls.url` -> `django.conf.urls.url()` `django.urls.re_path` -> `django.urls.re_path()`
The wording `update your urlpatterns with a list of ...` seems unclear to me, it almost sounds like I need to call an `update` method with some argument that is a list, or something. I would say `update your urlpatterns to be a list of ...`.
Should also include `block_size` and `parallelism`
> My main worry here is: Is this correct and does it make sense to implement for such a complex hasher (notably we already have others where we argue it is simply not possible in a sensible way). > > Since scrypt can raise errors like this: > > > ValueError: Invalid parameter combination for n, r, p, maxmem. > > I am wondering if `must_update` couldn't also trigger this condition. Or can we always calculate `extra_iterations` and `extra_block` and be sure that the combinations are valid? You're right parameters may no be valid, e.g. ``` self.work_factor = 2 **14 decoded['work_factor'] = 2 ** 11 ``` both are a power of 2, however `extra_iterations = 14336` is not and raises `ValueError: n must be a power of 2`.
`self._test_scrypt_upgrade('parallelism', 'parallelism', 2)` fails, it seems we shouldn't take `parallelism` into account.
Throught your patch, please use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Is there a good reason to order the data like this? I'd personally expect the hash to be at the end, so it could include a `$` .
It should give 'Modification de Title et Historique.'. I guess a gettext call is missing inside the `LogEntry.get_change_message`.
chop first comma
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
Extra wrapping and `str()` call are unnecessary: `… for city "%s".' % city`
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
Should use `assertRaisesMessage()` to verify the string also.
```suggestion if scheme and scheme not in self.schemes: ``` 🤔
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
I think `assertIs` was used because `assertTrue(1)` doesn't fail.
`assertTrue` would be appropriate here.
Never mind, just read the whole ticket :) Maybe the initial `assertIsInstance(p.restaurant.serves_pizza, bool)` would make more sense here. Else it might end up being refactored.
Use hanging indent as mentioned before.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
On second thoughts creating a URL with to_field isn't required to test this issue – so the string interpolation can simply be removed: ```suggestion admin_user_change_url = reverse( "admin:%s_%s_change" % (user._meta.app_label, user._meta.model_name), args=(user.username,), ) ```
Just got a typo here 😁 ```suggestion # assert joined_url and pw_change_url are identical ```
Yes, f-strings should use only plain variable and property access as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
```suggestion """Render as <p> elements.""" ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
`acquire_lock` was added for internal usage in 6448dd833524ac3fc503506b624841c9d642de8a, so I don't see a need for a deprecation.
I think maybe ```py dummy = object() def get(self, key, default=None, version=None, acquire_lock=dummy): if acquire_lock is not dummy: warnings.warn( ``` I still think this arg fits in the grey area for deprecation timeline, would like someone to weigh in e.g. @jarshwah
Ok thanks Tim
I take this back and have a deeper look at the tests.
Use single quotes consistently.
This logic could be consolidated to avoid repeating the same conditionals twice. Just check both `max_num` and `absolute_max` independently for `None` and set default as needed, then once they are both set, check that `absolute_max > max_num`. The minor difference in error message here doesn't justify all the repeated logic, IMO; a simple "absolute_max must be greater than max_num" is fine.
Please chop unnecessary blank lines.
Trailing commas: ```suggestion MAX_NUM_FORM_COUNT: self.max_num, }, renderer=self.renderer, ```
Gotcha, okay I think this is acceptable.
IMO a single test with custom `too_many_forms` and `too_few_forms` is enough.
I think we should avoid writing new test suites that use fixtures. Fixture loading is extremely slow, and it's actually harder, IMO, to follow what the data should look like once you've aggregated it. I would suggest either creating all the data in a setUp method, or creating the data you need at the top of each test.
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
put `RegrSXX,` on the next line to wrap imports at 79 characters.
I would say: `pass # psycopg2 isn't installed`
"Both Y and X must be provided". Switch the Y and X in the error.
Why is this way preferable to ```suggestion def _check_token_present(self, response, csrf_secret=TEST_SECRET): ```
Personally, I like this because you can pass `None` to get the default value. We can decide to change, but it should be a part of a separate PR.
wrap docstrings at 79 characters
I don't think flake8 does any checking of docstrings. The 79 char suggested limit is mentioned in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style.
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
Not sure we want to use `settings.CSRF_COOKIE_NAME` for this. What about `CSRF_SESSION_KEY = '_csrf_token'` just like we do with `LANGUAGE_SESSION_KEY`.
We could rename `CSRF_COOKIE_NAME` as `CSRF_ENTRY_NAME` or `CSRF_ENTRY_KEY`, and then using it as cookie name if we're cookie based and session key if we're session based. This would be an improvement over the current code, but probably not over separate settings.
I think the session cookie should be independently configurable. Technically there's no reason we'd need two settings, it would be possible to just have `CSRF_SESSION_KEY`, and use it both as the session key and the trigger to use sessions at all (if it's not set, we don't). Not sure if that's actually better than just having two settings.
Assuming we use something other than `CSRF_COOKIE_NAME` as the session key, `"CSRF_COOKIE"` seems like an odd key into `request.META`.
Maybe change that into a `try/execpt AttributeError`. It's kinda nitpicky, but given that if you want to use session-based CSRF you will most likely have a session object on the request and then try/except would be faster (And even if not, it seems more natural and shows a nice chained error on python3).
We should mark all tests and model states that use `index_together` in `tests/migrations/test_autodetector.py` for removal. We can also move them to a common class for easier remove when deprecation ends.
The main question is what to do with these tests? We should analyze them one by one and prepare alternative versions only with `unique_together` (if necessary). I'm afraid that we cannot simply remove them when deprecation ends because we will end with many not covered scenarios. For example: ```python diff --git a/tests/migrations/test_autodetector.py b/tests/migrations/test_autodetector.py index 547e0b32c5..4c19a34d7f 100644 --- a/tests/migrations/test_autodetector.py +++ b/tests/migrations/test_autodetector.py @@ -2441,10 +2441,10 @@ class AutodetectorTests(TestCase): self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterField"]) + # RemovedInDjango51Warning: When deprecation ends rename to + # test_empty_unique_together(). + @ignore_warnings(category=RemovedInDjango51Warning) def test_empty_foo_together(self): - """ - #23452 - Empty unique/index_together shouldn't generate a migration. - """ # Explicitly testing for not specified, since this is the case after # a CreateModel operation w/o any definition on the original model model_state_not_specified = ModelState( @@ -2457,7 +2457,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": None, + "index_together": None, # RemovedInDjango51Warning "unique_together": None, }, ) @@ -2468,7 +2468,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": set(), + "index_together": set(), # RemovedInDjango51Warning "unique_together": set(), }, ) ```
A note in `docs/internals/deprecation.txt` is missing.
`codename %= ...`
`cls.__name__.lower()` is the same as `self.model_name`. I guess `model_name` would probably be a better placeholder name.
This is the failing assertion on Windows. I think it might have to do with the file being written with Windows vs. Unix line endings. If you remove the assertion, the rest of the test passes.
Not sure these asserts bring value ... they seem to test that `override_settings` works.
or just `# CSS files shouldn't be touched...`
This can probably also be cleaned in existing cases but `BaseCollectionTestCase` inherits `BaseStaticFilesTestCase` so it looks like it's redundant here.
Please use `assertRaisesMessage` for exception checking.
This docstring is the same as for `wait_page_loaded()`. Do we even need it in either case? Or perhaps the docstring should explain the difference between these two methods.
I think `GET` is fine for that.
@MarkusH Such a request should not change any state, so it should be `GET`. Using `POST` and `CSRF` wouldn't help against DoS there anyways (unless I miss something). If you are worried about querying the database, you can do the same with a normal request to the list views in the admin…
`lambda` works better on Firefox, let's leave it.
Can we use [number_of_windows_to_be()](https://www.selenium.dev/selenium/docs/api/py/webdriver_support/selenium.webdriver.support.expected_conditions.html#selenium.webdriver.support.expected_conditions.number_of_windows_to_be)? ```suggestion self.wait_until(ec.number_of_windows_to_be(2)) ``` Also, we can probably chop `self.assertEqual(len(self.selenium.window_handles), 2)` in the next line.
Manipulating `second` here is not strictly necessary, `first.save()` raises the `IntegrityError`. I believe the reason for `second` to be manipulated here is to show the difference with initially deferred constraints behavior. If that's the case, perhaps a function could show that the same code passes under initially deferred constraints but not under immediate constraints. Something like: ```diff diff --git a/tests/constraints/tests.py b/tests/constraints/tests.py index 067b38cfb6..b3257b6789 100644 --- a/tests/constraints/tests.py +++ b/tests/constraints/tests.py @@ -196,17 +196,17 @@ class UniqueConstraintTests(TestCase): first = Product.objects.create(name='First', shelf='Front') second = Product.objects.create(name='Second', shelf='Back') + def swap(): + first.shelf = 'Back' + second.shelf = 'Front' + first.save() + second.save() + with self.assertRaises(IntegrityError): with set_constraints(unique_shelf=IMMEDIATE): - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() first.refresh_from_db() self.assertEqual(first.shelf, 'Back') ```
Use `assertIs(..., False)` to check for boolean attributes.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Yes it was Ian, but my example used joined fields for an update which isn't (yet) allowed. How about something like: ``` Author.objects.update(alias=Greatest('name', 'goes_by') ``` Which will also test the handling of varchars in a Greatest.
Maybe we could test that `name_color_uniq` is also in the message? ```suggestion with self.assertRaisesMessage(ValidationError, 'name_color_uniq'): ```
> Please leave feedback on my solution, why it was not good enough, if it's possible? It's unnecessarily complicated.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
```suggestion self.assertIsNone(table_description[1].collation) ```
Could you please follow the previous indentation style :)
Ah yes, and if we `lru_cache` the main `get_srid_info`, we can get rid of that caching.
Caching SRID data makes sense to me (not for you?), but we may use a more modern caching method, like lru_cache.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
put closing parenthesis on the next line
`0` is unnecessary: ```suggestion return (10, 2) else: return (5, 7) ```
I tried to use a generated condition the `WHERE` clause and it works fine, so IMO we can safely assume that it's an Oracle caveat :smile:
Could we possibly skip the detection feature `if Database.sqlite_version_info >= (3, 29, 0)`? Since this is only present on macOS [could we branch off `platform.platform`](https://docs.python.org/3/library/platform.html?highlight=darwin#platform.platform)? I think this would partially address @claudep's concerns.
Nit-pick: I think Django generally favors the syntax with parens instead of the `\` continuation char.
Might be better to define this as separate method like this: ``` def window_frame_start(self, start): if isinstance(start, int): if start < 0: return '%d %s' % (abs(start), self.PRECEDING) elif start == 0: return self.CURRENT_ROW elif start is None: return self.UNBOUNDED_PRECEDING raise ValueError('Illegal argument for start, must be either a negative integer, zero or None') ```
This should use longer lines (up to 119 characters) or hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
~~Should we check `posix` instead?~~ ```suggestion if sys.platform != 'win32': ```
return directly, no need for `path` variable.
Can we make any positive assertion? I'm a bit nervous about a negative assertion like this since, for example, a typo in the regular expression could cause the test to pass by mistake.
We need to consume the entire iterator: ``` Exception ignored in: <posix.ScandirIterator object at 0x7f5a9e95de10> ResourceWarning: unclosed scandir iterator <posix.ScandirIterator object at 0x7f5a9e95de10> ```
Wrap at 80 characters.
Looks like this could be a 1 line docstring.
`Determines` -> `Determine` `will support` -> `supports` This docstring can be single-lined.
Indents should be four spaces.
Chop this link.
I think we should raise a more descriptive error, maybe the same as in `add()` and `set()`.
`1` -> `chicago.pk`
I was just curious why we chose them, it seems that we want to test creation with manually specified `ID`. It can stay.
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
Prefer this indent style: ``` response = self.client.post(reverse('...'), { .... }) ```
We would fallback to an empty `bytes` string as well ```suggestion boundary = opts.get('boundary', b'') ```
Was `MultiPartParserError` before and should at least be `Exception`
Removed extra code in PR #3852.
I think I would define the additional parameters as keyword parameter, as in `__call__ `. BTW, thanks for fixing this thread issue I created!
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
I think you can remove temporary `msg`, also dot is missing and probably `preceding` should be uppercased and `n` should be lowercased. ```python raise NotSupportedError( 'PostgreSQL does not support RANGE BETWEEN n PRECEDING AND n ' 'FOLLOWING.' ) ```
Isn't this equivalent? ``` if (start and start < 0) and (end and end > 0): raise ... ```
"start argument must be a negative integer, zero, or None, but got %s."
This `raise` seems redundant. I would remove these two lines (617-618) and leave only `raise ValueError(...)` at the end of this method.
Oracle restricts the number of parameters in a query.
Probably, I don't think the benefit is worth the cognitive load of someone looking at the test and wondering about it.
Use single quotes consistently.
This can be single-lined.
Also put `self.adduser` back in front of `self.changeuser`...
Yes it was Ian, but my example used joined fields for an update which isn't (yet) allowed. How about something like: ``` Author.objects.update(alias=Greatest('name', 'goes_by') ``` Which will also test the handling of varchars in a Greatest.
could we inspect `query.order_by` instead? Maybe it's fine as-is, but that seems a bit less fragile.
I added `supports_select_for_update_with_limit` because this will crash on Oracle.
yeah you're right, the previous test was affected by the silent truncation of transforms from field references as reported by users. I think the original intent was to do `count=Count('value')` and not `Count('value__d__0')` though so I'd switch it to do the latter.
Could use `assertSequenceEqual` to avoid the `itemgetter`
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
Remove ticket number. Capitalise first word of sentence.
These two permissions are never used. Please remove them. `cls.permissionuser` is only used in `test_simple_inline_permissions`. Create it inline there rather than on the class.
Will this statement will fit on a single line? (119 characters is permitted.)
Will this statement will fit on a single line? (119 characters is permitted.)
I think it's fine to leave it inside a `try` block.
If I were writing these tests from scratch, I wouldn't use a separate `expected` variable everywhere (this is related to our preference for longer lines rather than a historical more strict adherence to 79 chars, I think).
```python msg = 'Script does-not-exist does not exist.' with self.assertRaisesMessage(RuntimeError, msg): ```
This whole `try`/`except` logic can be replaced by a `self.assertRaises(SSLError, backend.open)`.
Another option could be to refactor into 3 separate test methods that call a common helper method to run the logic currently in the loop. This can be easier to debug than assertions that run within a loop.
I would revert these changes, a string representation of `condition` and `deferrable` doesn't need and extra quotes.
`expressions` should be before the `name` like in other classes.
~~Also use `%r` and not `repr()`.~~
`include` is a tuple, that's why we need `repr()`.
We should use `__qualname__` in all classes.
quit() .... to avoid a dead.... (chop "we" stuff)
I think it's something like: 'browser' contains the first browser to run the tests against and 'browsers' will contain the rest of the browsers (if more than one are requested).
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
If we remove this will the tests run on Jenkins? It might be fine.
As long as you use `except Exception` and not a bare `except` this should be good.
``` return datetime.datetime(1970, 1, 1, tzinfo=timezone.utc) ```
I don't think the number of tests is an issue, but since the check depends on a variable, the test should also reflect this, or it'll break at some point.
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
`date=rfc850date` isn't needed in the `subTest()` -- since will appear if the assertion fails.
put closing parenthesis on the next line
I would add `('availability', BooleanFieldListFilter)` to the `BookAdminWithTupleBooleanFilter` instead of creating a separate class.
"cannot" is one word. add period.
put closing ) on the next line
I don't think this is necessary? It should default to an empty string.
We don't reuse `availability_choices` anywhere so there is no need for a separate variable.
This condition is problematic on databases that use random rather than serial pk values (failure observed on CockroachDB).
Something like `id=1` here would also work just as well. Not sure if you rejected that for some reason.
single line looks okay here
I think this test would be fine without the blank lines, it's fairly short.
Chop blank line.
`return HttpResponseNotAllowed()` should be all that's required.
The `View` class does this by default for unimplemented methods ;) Hence I'd like a solution where we can just drop the `get` in 4.0.
Yes that's fair, I haven't used CBV's so much recently and forget there are mixins for the Template and Context behaviour.
How would the code in 4.0 look then? Just removing `get` will not do the trick since `TemplateView` defines it. IMO we should write the code as it would behave in 4.0 and then add the deprecation to the `get` part.
We need to remove `get` from `http_method_names` because `TemplateView` still defines it and I really don't want it to be callable :) Or We stop using `TemplateView` and inherit from `ContextMixin` ` TemplateResponseMixin ` and `View` ourself…
The use of Empty that is imported from models.fields looks very weird until one looks at its definition. Can't you use object() directly? Edit: No, you can't, Python2 won't let you. Still, the use of a class imported from fields feels hackish.
Use single quotes unless the string contains a single quote. Also, this could be combined with the previous line -- we allow up to 119 characters when it helps readability.
use single quotes
Unnecessary -> ```suggestion def __str__(self): ```
I would rename `self.model_name` -> `self.name` (like in `CreateModel`, `DeleteModel`, or `RenameModel`).
As above -- it seems somewhat useless to implement this test for every subclass. At the least, maybe there could be a base test class that implements some common tests if that's warranted.
You need to wrap the second instantiation in its own assertRaises to actually test it.
Use single quotes consistently.
I think you want `options['indexes'].remove(idx_name)` here. That would simplify this code, and I think together with the change in signature mentioned above, remove the need for `get_index_by_name` as well. [List.remove](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists)
I'm not following exactly what the idea is and what problem it's solving.
create_initial_data and create_big_data below
I'd omit the second "inner_method" since it's not meant as a backwards operation and not used as far as I can tell.
Do we need to delete these models? I don't think that below tests are required,
I don't think that we need a `source_value`. You can move `create_initial_data()` outside this loop to the previous place. This should reduce the diff.
should be `first_state`, not `project_state`, I suspect.
Any problem with allowing `self.model = None`. I think conditional attributes which require `hasattr` isn't the best design.
Use single quotes
I think this could be `@cached_property` so it doesn't have to be calculated on every access.
I was expecting to raise a ValueError if these conditions aren't met, similar to what we do with "Index names cannot be longer". I don't think it's a good idea to modify the user provided value as it seems like that would only cause confusion.
I understand, thanks for explanation.
I'd put this after `_check_unique_together` here, so it's grouped with the other callers of `_check_local_fields`
Add trailing comma.
I think you can to exclude conditional unique constraints here ```suggestion if not cls._meta.get_field(cls.USERNAME_FIELD).unique and not any( isinstance(constraint, models.UniqueConstraint) and constraint.fields == (cls.USERNAME_FIELD,) for constraint in cls._meta.total_unique_constraints ): ``` Kind of wish there was a way to avoid checking both the field and `cls._meta.total_unique_constraints`.
This change isn't correct as it will disable the check unless testing. Maybe this would work: `if 'django.contrib.auth.backends.ModelBackend' in settings.AUTHENTICATION_BACKENDS`
> Is SmallAutoField ever the right choice for a primary key field? Why not, it can be the right choice for any small dictionary tables if you really want to save space. I would even say that it's justified more often then `BigAutoField` :wink:
Please add a docstring explaining this.
Maybe it would be better to change 'path' to 'file_path' for consistency with the rest of the references to the signal arg.
extra space after [
Please replace this with a regular `try/except`.
It's slower, about 10 times.
This leaves a "dummy" SQLite database on the filesystem after running the tests.
You could use single quotes in all strings for consistency (don't worry about existing tests).
This should be something like `self.assertEqual('migrations\n (no migrations)\n', out.getvalue().lower())` (perhaps adjusted a bit to match the output of showmigrations for other apps) (no SystemExit).
Copy / paste? I would have expected the ordering to change for the `duth1` and `duth2` arguments.
non existing -> nonexistent
Could move `executable = '/usr/bin/python'` to a class attribute.
, or None...
Oh yes the tests! You are right then.
I think we can remove `tearDown()` and `setUp()` and use ```python with translation.override(language): ``` instead of `activate()`.
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
Need to test that result is as expected, not only calling it.
`Editor 1` -> `Editor`
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
you don't need `nulls_last=True` here because it's a PK you're ordering by, which is non-nullable
I would make separate test classes for each data set e.g. the two tests that use cars can be a separate class with setUpTestData limited to creating the two cars.
Wrap docstring at 79 chars
This test seems correct. I think the class (or this method) docstring should call out the exception case.
URL should be capitalized
You don't know what a docstring is? Trying googling "python docstring".
Sorry, was thinking of something else.
Can we replace this with `ELLIPSIS = '…'` rather than some unrelated marker character? This makes it easier for consumers of the new paginator to use the correct character.
Use a more descriptive name? Looks like this would fit on a single line.
`# Prevent the RuntimeWarning subclass from appearing as an exception due to the warnings.simplefilter() in runtests.py.`
Let's go with "ellipsis": it's primary meaning is _the omision_, for which folks _could_ use any symbol. It's secondary meaning is the three dots `…` that we actually use.
Should we call it "ellipsis"? It's basically an option to customize a separator and do not use ellipsis :thinking:
Please use assertRaisesMessage to verify this is the ValueError we expect.
We can move the test that involves `login()` to the other pull request.
@pahko `2` , `3` and non-empty lists and objects also will be valid case. Only check for boolean is needed here.
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
is this meant to test the `except TypeError` branch in `contrib.auth.authenticate()`? It would be clearer to call that function directly.
``` "...when `extra_context` is passed to all admin urls." ```
Wrap docstring at 79 chars
With a non-English LANGUAGE_CODE and if the active language is ....
IMHO, it's clearer if you use: ``` python if not prefixed_default_language and language == settings.LANGUAGE_CODE: language_path = '/%s' % (request.path_info) else: language_path = '/%s%s' % (language, request.path_info) ```
, or None...
Please chop the comma here.
types -> type
chop trailing ,
Perhaps the tuple should be a module constant somewhere so it can be reused in `validation.py`.
So maybe without cache, with a separate property we will be able to fix this in only one place after [30712](https://code.djangoproject.com/ticket/30712).
This second assertion isn't what you want (It'll pass before and after the code change I believe.) Instead, you should be setting `INSTALLED_APPS` to a tuple with duplicates and using `with self.assertRaises(ImproperlyConfigured)`
`self.assertFalse()` -> `self.assertIs(..., False)` `self.assertTrue()` -> `self.assertIs(..., True)`
To verify this is the expected import error, I'd do something like: `self.assertRaisesMessage(ImportError, 'nonexistent')`
preferred format is "#15346, #15573 - Issue description"
it's a separate item, but I wonder if we could patch override_settings to handle DATABASE_ROUTERS like is done below
The fact only a single result is returned is a strong enough assertion here. Some database backend could translate `__isnull` to some different SQL.
I think we should skip this test on other backends, because only on Oracle we execute a SELECT query.
Maybe we could test that `name_color_uniq` is also in the message? ```suggestion with self.assertRaisesMessage(ValidationError, 'name_color_uniq'): ```
I don't think it's good practice to change instances created in `setUpTestData` as they should be identical for the whole test class.
Oh I realize that asserting against the results is problematic given all the engines we're testing against support foreign keys. In this case yes, using the same `JOIN` check against `captured_query` should do!
You can drop this assertion, the way `from_date` is constructed and that this branch is behind the `if day` one makes it impossible to reach.
Use `django.utils.timezone.make_aware` instead.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
I partly restored `dates_or_datetimes` (removed in e88d2dfcf4daa2b4ee451f518085413bb3b8deeb), it looks simpler IMO.
Annoying that `datetime.time` cannot be subtracted from each other to give a `datetime.timedelta`, so we cannot use `duration_microseconds()` as in `_sqlite_timestamp_diff()` below.
We should keep both assertions: ```suggestion self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='ar').exists(), False) self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='bar').exists(), True) ```
It works with my proposition so we should have both assertions.
My only question is if this skip logic is still correctly applied (i.e. none of the other classes that inherited `ExtractorTests` require it)? If you verify that, ship it.
Tests are missing for some validators, e.g. `DecimalValidator` and codes `invalid`, `max_digits`, `max_whole_digits`, and `max_decimal_places`.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
Use [PEP 257](https://www.python.org/dev/peps/pep-0257/) verb style: "Update..."
Then it's settled, I think. Thanks :)
Why the `CombinedExpression` and not `Expression`? IMO it's misleading, I know that `CombinedExpression` has the concept of right-hand and left-hand sides but for other purposes.
I think we want to avoid altering `self.extra` here and pass `db_type` as a kwag to `super().as_sql()`.
I'd use `*args, **kwargs` for arguments that are simply passed-on without being accessed or modified, to reduce the number of places that a change in signature would need to be reflected, and to avoid having to repeat the same default values. We've had issues in the past in Django (in forms/formsets, IIRC) where the default value for some parameter to a superclass method changed, or a new optional argument was added, but nobody remembered to update subclass method signatures accordingly, causing bugs.
I think you should use `type` not `__class__`. At least in python 2 this will break if the class does not inherit from `object`.
I'd keep the current version without `type()` since it's unrelated. If there's a need for this change, create a ticket with a corresponding test.
chop blank line
how about: "Run the system checks on all ModelAdmins, except if they aren't customized at all."
`fix_this` is misleading, because there is nothing to fix here.
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
When calling `on_commit` there are basically two modes: - there is no transaction in progress, so we execute the function right away - we are in an atomic block, so we register the function to execute it later (`self.run_on_commit.append(`) The first case is handled by the PR, but not the second one. And I'd think that we would need to handle a robust execution in the second case too. Does that make it clearer? :)
Use a similar logging to what we do for robust signals? See `django.dispatch.dispatcher.Signal.send_robust` and ``` try: response = receiver(signal=self, sender=sender, **named) except Exception as err: logger.error( "Error calling %s in Signal.send_robust() (%s)", receiver.__qualname__, err, exc_info=err, ) ``` Something like ```suggestion logger.error("Error calling {func.__qualname__} on_commit() ({e}).", exc_info=True) ```
`func` is called even if no transaction is in progress, so we should move this to the first line. Fixed.
This will become a performance issue for the database before it becomes one for the Python process :-)
```suggestion def on_commit(self, func, is_robust=False): ``` Add default value for better backward compatibility.
Super — let me give that a run. Thanks @felixxm
@felixxm the `if to_field.primary_key` check is needed for the FK as PK case. Two questions: 1. Can we tidy this block? 2. Do we need the same kind of thing again inside the `while` loop? 🤔
In general, I think _it shouldn't be as hard as this_ (at least not exposed 😀)
Yeah I also gave it a try by replacing the `return (value.pk,)` by `return tuple(getattr(value, field) for field in lhs.output_field.to_fields)` but the `place=restaurant_instance` test was failing. I suppose we'll require input from @akaariai.
This being the change in question.
I'm torn whether or not this copy is necessary. When we resolve the expression we do a copy of the subquery anyway. Even if the queryset was cached and evaluated, the resolving will copy a new queryset anyway. ```python qs = Model.objects.whatever() sq = SubQuery(qs) list(qs) # this evaluates the queryset that subquery is holding onto OtherModel.objects.annotate(subq=sq) # queryset is copied here anyway, previous eval doesn't matter ``` Let me know if you can poke holes in my reasoning (it is new years day after all...).
Good catch, this cleanup should be moved to a separate commit.
That's what I thought. Thanks for the clarification 👍 The patch is fine to me 🚀
😮 I see that we have a similar condition here `django.db.models.expressions.Exists.as_sql`: ``` features = compiler.connection.features if not features.supports_boolean_expr_in_select_clause: return "1=1", () return compiler.compile(Value(True)) ``` Would it make sense to somehow move them to the same piece of logic? We could either have `compile(Value(True))` determine if it should generate a `1=1`, but it have other side-effects I think 😕
`FieldError('This queryset contains a reference to an outer query, and cannot be evaluated on its own')` How's that? Same goes for OuterRef I guess. Maybe: ``` FieldError("This queryset contains a reference to an outer query, and cannot be evaluated without its' parent") ```
```suggestion ''', [os.devnull]) ```
This can be moved outside of `try...except...`.
Use single quotes.
I see this is copied from the other test, but single quotes should be preferred per the style guide.
Same style as above.
Committed this change in ab643cd63402ef8ed4776faebc0ed4f00b933e1d because @apollo13 also stumbled on it.
Use `//` instead with a `from __future__ import division` import.
@hramezani I think you removed `setattr(options, opt_name, os.path.normpath(opt_val))` by mistake. My proposition was to remove only `else`, i.e. ```python if '.' in opt_val: print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-')) sys.exit(1) setattr(options, opt_name, os.path.normpath(opt_val)) ```
IMO `else`is unnecessary i.e. ```python if '.' in opt_val: ... setattr(options, opt_name, os.path.normpath(opt_val)) ```
IMHO specifically this change worsen readability. Something like this might look better: ``` if app_labels: if len(app_labels) == 1: ... else: ... else: ... ```
I think we should wrap this in a `try... except...` in order to catch any final lingerers: ``` try: from django.utils.deprecation import RemovedInDjango40Warning except ImportError: raise Exception( 'django-admin.py was deprecated in Django 3.1 and removed in Django ' '4.0. Please manually remove this script from your venv and use ' 'django-admin instead.' ) ``` (Since a `pip install -U Django` isn't ever going to actually delete it.)
Meh... I think, if after 4.0, someone is still running this, we should fail hard. (Exception, rather than warning.) But open to arguments... — this is just the last safety net. I don't think we should spend too much time here.
should be indented as in other places
please use parentheses instead of backslash
This usage looks a bit magic to me, but I think it can stay as it is. The module level deprecation warnings in https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01 are different than this, so stacklevel=2 can be removed in the following locations: - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-9e264d0b47bfdd60be1698bca9bae281R19 - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-68395a4996a48dd1b3cd34ddd9efe762R12
I think we don't need to define `msg` variable: ```suggestion with self.assertRaisesMessage(ValidationError, 'This field is required.'): ```
Same here: ```suggestion with self.assertRaisesMessage(ValidationError, 'Enter a valid duration.'): ```
Use assertRaisesMessage to verify the message also.
I wasn't suggested that, but perhaps it would make the test more readable/clear, lest someone copy the current pattern.
This is the only case that fails if the patch is reverted.
If I can bring a little bit of nuance to my position. Yes, Python supports aware time. However, the majority opinion in Django contributions (AFAIK) is that using this feature is likely to result in worse design than not using it. Many users aren't experts able to delineate narrow sets of circumstances under which code manipulating aware times is more likely to be correct (e.g. "my code will never be used outside HK and HK will never introduce DST [alternative: I will write a unit test that fails if HK ever introduces DST]"). The recommendation would be to manage the time and the timezone in separate objects. There are other cases where Django diverges from Python's standard behavior. For example, I have found the transaction behavior mandated by PEP 249 less than helpful for most users and I have decided to default to autocommit in Django instead.
```suggestion if match := datetime_re.match(value): ```
```suggestion return datetime.datetime(**kw, tzinfo=tzinfo) ```
```suggestion if match := date_re.match(value): ```
Did you consider trying to factor out the common code between the two `if match` branches? Not sure if that would help or hurt readability.
When considering my own approach for this same problem, I specifically avoided using xor as when using it on printable characters, you wind up with lots of unprintables you probably don't want to put in your page. Two approaches I considered were: 1. restricting tokens to hex ascii, and xoring their binary forms 2. using a "caeser cipher" approach, where each char is offset in the list of valid chars by the corresponding char in the random pad. [modulo the list of chars, of course]
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
to be -> are
Is that check actually needed? This seems to be only needed if a token is `None` -- which would not happen if we return a token from `sanitize_token` instead of None :D
Is this branch a candidate for removal in some future release? Either way, would be helpful to elaborate on how the backwards-compatibility case arises. I think it's upgrading Django in the presence of existing token set by older versions of Django, but would like t to confirm.
I'd use `*args, **kwargs` for arguments that are simply passed-on without being accessed or modified, to reduce the number of places that a change in signature would need to be reflected, and to avoid having to repeat the same default values. We've had issues in the past in Django (in forms/formsets, IIRC) where the default value for some parameter to a superclass method changed, or a new optional argument was added, but nobody remembered to update subclass method signatures accordingly, causing bugs.
The SQL function `COALESCE` can be called with a single argument (at least on PostgreSQL). That might not be useful, still I believe Django shouldn't prevent this.
I just checked and Postgres/MySQL support that but SQLite doesn't... so I guess you're right, it's better this way.
Please use 4 space indent as done in other `self.assertEqual` assertions in the file I mentioned.
Since you don't actually need the instances of all those models, can you use `WindowTestModel.objects.bulk_create()` please.
I think you mean `ByteType`
Can you please rename this one to `ModelManagerSerializer` and let it inherit from `DeconstructableSerializer`.
Can you please rename it to `ModelManagerSerializer`. I think you just missed it.
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
Ticket describes an issue when `USE_L10N` is off, so I think we should check both combination: ```python with self.settings(USE_L10N=True, DECIMAL_SEPARATOR=','): ... with self.settings(USE_L10N=False, DECIMAL_SEPARATOR=','): ... ``` Please move tests for a thousand separator to a separate commit because they work without this patch.
I will split them. At first glance I made a false assumption that all five affect `{% localize off %}` tag.
chop blank line
I couldn't see a reason not to use `super` here, otherwise LGTM.
These assertions can be single lined.
I think the `_module_exists` and argument name could be improved. What about ```suggestion def _contains_subclass(subclass_path, candidate_paths): ```
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
This values needs to be invalidated on `settings_changed` for `MIDDLEWARE` for testing purposes.
, or None...
As the code itself hints, there's no reason to assume the imported attribute is a class.
I think it's better to use `module_file` and don't override builtins.
I don't think we need to run the entire `test_load()`.
Ahh didn't notice that. I just remembered a recent commit that converted many of those to literals.
You could use a set literal here.
There is no need to use `assertRaisesRegex()`: ```suggestion msg = 'Migration 0001_initial already exists. Use a different name.' with self.temporary_migration_module(module='migrations.test_migrations'): with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
Use this style: ``` self.assertEqual(field.check(), [ ]) ```
Could you rename the field to `RemovedField` given the test case name.
Makes sense. Lets go with `MyField` then.
This warning ID was not updated after copy-pasting it.
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
I'm not sure if there's much benefit to this warning. Removing it would allow third-party apps that set it to have warning free backwards-compatibility.
Wrap strings at 79 characters. ``` '....' '....' ```
Yeah, I think that falls into YAGNI territory. Better to just do the simpler and faster thing for now, and add indirection later if/when we actually need it.
What is the benefit of having these `set_fields_cache` and `get_fields_cache` methods, over just accessing `instance._state.cache` directly? The only apparent reason is so that you can pass in a field and have `field.get_cache_name()` automatically called, but that could just as well be handled in the field mixin (and it's better handled there, as that keeps the encapsulations cleaner).
This needs to be named `related` for it to work.
could you limit line length to 120 characters so horizontal scrolling isn't required in GitHub? missing whitespace for: `{% autoescape on%}`
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
This isn't related to your changes, but I'm intrigued by Django's behavior here. I would expect `|escape` to give `&amp;` and `|escape|force_escape` to give `&amp;amp;`. Not that this construct makes much sense anyway...
Ha! So it's actually related to your changes :-) Happy to hear that we'll eventually get the semantics that I would expect.
I think the test is more readable with `type(s)` -> `SafeData`, but I'll leave the choice to you.
Doesn't seem required now that the test is skipped on non-Oracle.
Trailing zeros are stripped on PostgreSQL, so I changed to ```suggestion self.assertRegex(now_string, rf"^.*\.\d{{1,{precision}}}") ```
We can revert this unrelated change.
Same here, it may just drive complexity.
At first sight it could be simplified to: ``` [option not in [None, False] for option in mutually_exclusive_options].count(True) ``` But I have a feeling even more simplification might be possible. Note that we can't simply cast default to bool, which would make this even simpler, as some valid dates evaluate to false: https://mail.python.org/pipermail/python-ideas/2014-March/026446.html
Please add a trailing comma: ```suggestion [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver'], ```
```suggestion @mock.patch('sys._xoptions', {'utf8': True, 'a': 'b'}) ```
```python msg = 'Script does-not-exist does not exist.' with self.assertRaisesMessage(RuntimeError, msg): ```
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
Maybe it would be nice to put the shared test logic into a helper method.
adding trailing comma
The URL may be incorrectly encoded....
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
`_combine()` is unnecessary since its introduction, I moved it to a separate commit b62c58d5fccaeedc7bc4a064b4678e4ed1e77581.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
I think we prefer a different indentation style in docstrings, i.e.: ```python """ A Q object with an empty condition should be rejected as the conditional expression in a Case(). """ ```
What if `default` is not a constant but a field reference? e.g. `F('integer')`
"Boolean Expression object" looks a bit unusual to me. What do you think of "a boolean expression"? I assume this means an expression with output_field=BooleanField.
Manipulating `second` here is not strictly necessary, `first.save()` raises the `IntegrityError`. I believe the reason for `second` to be manipulated here is to show the difference with initially deferred constraints behavior. If that's the case, perhaps a function could show that the same code passes under initially deferred constraints but not under immediate constraints. Something like: ```diff diff --git a/tests/constraints/tests.py b/tests/constraints/tests.py index 067b38cfb6..b3257b6789 100644 --- a/tests/constraints/tests.py +++ b/tests/constraints/tests.py @@ -196,17 +196,17 @@ class UniqueConstraintTests(TestCase): first = Product.objects.create(name='First', shelf='Front') second = Product.objects.create(name='Second', shelf='Back') + def swap(): + first.shelf = 'Back' + second.shelf = 'Front' + first.save() + second.save() + with self.assertRaises(IntegrityError): with set_constraints(unique_shelf=IMMEDIATE): - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() first.refresh_from_db() self.assertEqual(first.shelf, 'Back') ```
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Hey @felixxm. In the end we went for not having the "or subclassed" so these changes will disappear. (`checks.txt` did previously have this adjustment, but it's gone now. These are just leftovers to be removed.)
@carltongibson Ahh sorry :man_facepalming: I should check discussion.
Please wrap at 79 chars.
Please wrap at 79 chars.
This and the check below can be single-lined.
`Backend` supports negative precision, `SQLite` does not: ```suggestion raise ValueError('SQLite does not support negative precision.') ```
Please remove, it's redundant.
This looks as though it works, but we can make it much more straightforward: ```python def as_postgresql(self, compiler, connection): # Cast FloatField to DecimalField as PostgreSQL doesn't support # MOD(double precision, double precision) by default. clone = self.copy() clone.set_source_expressions([ Cast(expression, DecimalField()) if isinstance(expression.output_field, FloatField) else expression for expression in clone.get_source_expressions() ]) return clone.as_sql(compiler, connection) ``` The other issue is that your implementation was basing the decision to cast on the `output_field` of this function and not the input source expressions which may be different.
I might have suggested it, but I don't think arity is useful in this type.
```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='((%%(expressions)s) * 180 / %s)' % math.pi) ```
I moved a cleanup part to a separate commit.
I don't know of this particular case, but I wonder if we will have a fun time ahead regarding NULL handling in general - partial match foreign keys etc, and what it in general means for a composite field to be null... There are some similar cases in Query.add_filter() negated handling.
Yeah, multicolumn case is what I am interested in, the results will not be correct for cases where the first column match, the second is smaller and we use __lt. So, error out in multicolumn case for now, then lets think if we can make this work properly (for some DBs the DB itself knows how to implement (a, b) < (val1, val2)).
I don't think you can do it like this for multicolumn lt, gt constraints. The natural constraint is: a < val1 or (a == val1 and b < val2) at least that is what PostgreSQL gives you. EDIT: We can just throw an error in multicolumn non-exact lookups here for now.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
I didn't dig much into this ticket, but is it still possible to have a value type not in the list handled in `_resolve_output_field`? If yes, could we keep a test for such a value (maybe in expressions tests).
What about ```suggestion self.assertNotIn('is_book', books.values().first()) ```
Ahh looks like you'll need to keep passing `Value` in this case but you can drop the `output_field`. ```suggestion is_book=Value(1) ```
No need for `Value` wrapping since 1e38f1191de21b6e96736f58df57dfb851a28c1f ```suggestion is_book=1, ``` Ditto for all `Values` uses below.
Per new code guidelines, can we use `assertIs`? :)
add trailing comma
add trailing comma
include trailing ,
As with `@raise_deprecation`, this should be a module-level utility, not a method on the class.
get_fields() (add parenthesis) to distinguish it from other alternatives which are properties
The thing is that even if the ORM doesn't have support for it yet using `distinct()` to implement `(UNION|INTERSECT) ALL` might prevent us from adding proper support in the future. What I suggest doing here is setting `query.combinator.all = kwargs['all']` and preventing using `distinct()` on `CombinedQuerySet`. The difference between ordering and combination operation is that the former operates on the _combined_ set of rows while the latter operates on how these rows are combined. I would suggest that options related to combination be passed as `kwargs` (such as `all`) and actions operating of the combined result (`CombinedQuerySet` instances) be added as methods (`order_by`, _slicing_).
Why are you copying the `QuerySet`s? Shouldn't be necessary as all their attributes are immutable except outside of other operations, and the result cache doesn't seem to affect their use in the combined qs.
I'll quickly check if an idea I'm having works here.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
URL should be capitalized
"Stay on ..." (and please be consistent with no spacing around the sentences) Add a period to each sentence too.
Please use assertRaisesMessage to check the message too. We prefer the context manager version usually `with self.assertRaisesMessage(ValueError, msg)`. I think combining the two tests so you can reuse the `msg` variable would be fine.
argument -> a GET parameter
We avoid backslashes and use this style: ``` msg = ( "Redirection loop for authenticated user detected. Check that " "...." ) ```
`related_manager_name` not `related_model_name`
I think `base_mgr` would be more clear/consistent with the rest of the code
I don't think "then remove use_for_related_fields" is needed. Removing usage of the deprecated feature is always implied by deprecation warnings. Can the two options not be used together though? That might be problematic for projects that want to support multiple versions of Django.
We use hanging indent and try to avoid non-multiple of 4 space indent, something like: ``` warnings.warn( "Access to manager '%s' defined on non-abstract base " "class '%s' from child class '%s' is deprecated." % (self.manager.name, self.model.__name__, cls.__name__), .... ) ``` Add something like: "Add the manager to the child class to silence this warning."
The style I prefer is ``` options = { 'include_parents': include_parents, .... } ``` It's somewhat of a pain to indent additional items if your editor doesn't do it automatically with the other style.
override `__init__()` instead. after `super()` then `self.style = no_style()`
prefer `request_hander = NoColorWSGIRequestHandler if no_color else WSGIRequestHandler` rather than duplicating more than what's necessary
Could we patch a StringIO instead of devnull and then verify the contents of log_message()? See tests/check_framework/tests.py for an example. Also the patching should be in setUp/tearDown or in a try/finally so if something goes wrong the unpatching still happens.
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
would be fine to use double quotes so you don't have to escape the single
I think it's the right class: ``` In [38]: class desc: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: return instance.__dict__['_%s__mangled' % cls.__name__] In [39]: class A: ...: d = desc() ...: ...: def __init__(self): ...: self.__mangled = 42 ...: In [40]: A().d Out[40]: 42 ```
@graingert `cls` is passed here.
I'd say `on Python < 3.6`
I think silently failing to cache the property should be considered not working.
I also still don't understand why it's useful to allow writing code that doesn't work.
Actually, I think we can skip the router stuff and just use `django.db.connection`. These tests aren't run with custom routers so this'll always be run on the default database. (so we can move the skip condition to `test_long_column_name`).
I don't think nesting the test cases is the correct approach to avoid the errors you encountered.
Yes, but there we are testing behavior on TestCase so it makes more sense. Maybe it's fine here, but it seems fishy. In any case, I haven't looked into alternatives.
Same note goes here.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
I think we can reuse `rels_to_update`.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Check constraints don't seem to be related with this issue, moreover `unique` is `False` for all check constraints. Please revert this unrelated change.
It appears to me that, since this previously returned an iterator (`zip()`'s return value), you don't need to construct an intermediate list here and can simply `yield` the tuples directly.
Yes, `_is_relevant_relation` should return the same result :thinking:
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
Oh I missed the fact `datetime_trunc_sql` was used by `datetimes()`. This is fixing the reported use case where `'field'` is a `DateField` but wouldn't it break in the case of `dates('field', 'day')` where `'field'` is a `DateTimeField`? It looks like it wouldn't get truncated at all in this case.
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
This is not covered by tests, also raising an exceptions in user-defined functions is not really helpful for users: ```python django.db.utils.OperationalError: user-defined function raised exception ``` I think we should return `None` instead.
I moved this check to the `DurationExpression`.
Is `plan` meant as the second argument? Looks like we're missing a test for this branch.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
We've been using "Take / apply" verb-style in new docstrings.
Double checking the commit, this change, in this form leaks some state across migrations. Testing on CI right now. ``` python ERROR: test_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) psycopg2.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/markus/Coding/django/django/test/utils.py", line 182, in inner return test_func(*args, **kwargs) File "/home/markus/Coding/django/tests/migrations/test_executor.py", line 401, in test_alter_id_type_with_fk executor.migrate([("author_app", "0002_alter_id")]) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 94, in migrate self.apply_migration(states[migration], migration, fake=fake, fake_initial=fake_initial) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 131, in apply_migration state = migration.apply(state, schema_editor) File "/home/markus/Coding/django/django/db/migrations/migration.py", line 118, in apply operation.database_forwards(self.app_label, schema_editor, old_state, project_state) File "/home/markus/Coding/django/django/db/migrations/operations/fields.py", line 201, in database_forwards schema_editor.alter_field(from_model, from_field, to_field) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 482, in alter_field old_db_params, new_db_params, strict) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 635, in _alter_field params, File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 106, in execute cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 79, in execute return super(CursorDebugWrapper, self).execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/utils.py", line 95, in __exit__ six.reraise(dj_exc_type, dj_exc_value, traceback) File "/home/markus/Coding/django/django/utils/six.py", line 658, in reraise raise value.with_traceback(tb) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) django.db.utils.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. ``` However, integrating this with the second commit on my PR fixes the issue. I thus squash those commits there and close your PR here.
Use single quotes for strings, unless there's a nested single quote. ([Python style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style))
``` "...when `extra_context` is passed to all admin urls." ```
, or None...
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
I think we can remove `tearDown()` and `setUp()` and use ```python with translation.override(language): ``` instead of `activate()`.
So the js18n view for admin, why does it still load django.conf on top of django.contrib.admin? Is it there because no one ever noticed there are no longer js ranslations for django.conf? If so it would be good to have it cleared also
This bit wasn't broken before, right? So, there should be already tests covering this behavior.
I would keep the tests as atomic as possible. That aside, if you want to test the behavior for `abstract=False`, I would recommend dropping the PK and test that the check fails, hence the code inside the if-statement is actually being executed.
I think we can remove `('B', 'Base B')` and `('B', 'Child B')` because it tests the same case as `A`.
IMO using `subTest()` is not necessary here, e.g. ```python self.assertEqual(Child(foo='A').get_foo_display(), 'Child A') self.assertEqual(Child(foo='B').get_foo_display(), 'Child B') ``` is more readable.
I would omit the parenthesis in these messages (I know it's done elsewhere, but "I am at war" with that style unless you like it).
We can't assume six is installed; Django bundles it. This line needs to be `from django.utils import six` instead.
`exceptions.ObjectDoesNotExist` is referenced at line 1819.
Nitpick, `deprecation` comes before `encoding`.
The new import order guidelines haven't merged yet, but they call for putting try/except imports last (as isort can't parse them to order them elsewhere).
Yes, it looks good.
In each of the three cases, can you change `False` to `None` and add a trailing comma. (I think we *could* also move the placeholder line to the top to allow it to be overridden by the context, but it may not be worth it as I'm not sure the attributes passed down can be specified for each select individually...)
Does it not render with `placeholder="False"` then? Seems strange to me...
```python raise ValueError( "ISO week directive '%s' is incompatible with the year " "directive '%s'. Use the ISO year '%%G' instead." % ( week_format, year_format, ) ) ```
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
Use single quotes consistently.
plus use hanging indentation, e.g. ``` Person.objects.get_or_create( first_name="George", defaults={"last_name": "Harrison", "birthday": lambda: date(1943, 2, 25)}, ) ```
I'd add a note about why "condition" is special.
For those of you following along at home, the problem is that `None` is a valid value for a kwarg (check to see if the value from the database is `NULL`). That wasn't obvious to me so I thought I'd clarify. One solution would be to not add a parameter at all, and see if `"update_condition"` is in `kwargs`.
That would hide the `update_condition` kwarg from signature, that's why I suggested a sentinel should be used.
Keep what's done in `try` to the minimal expected to raise `self.model.DoesNotExist`. Move this after `except:` block.
`GenericForeignKey` or `GenericRelation`? Shouldn't we move this logic to the `ReverseGenericManyToOneDescriptor`? :thinking:
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
Use `self.assertIs(wrapper.is_hidden, True)` since assertTrue passes for bool(value) is True.
This needs to be named `related` for it to work.
Actually a relation is hidden if it ends with a `'+'`. Here `rel` has a `is_hidden` method that abstract this check.
Drop the comma/space in `[FakeFieldFile(), ]`
I think we could simplify the test by simply testing the presence of 3 occurrences of `<option value="0">empty_label</option>` in the result.
```suggestion form.render(), '<div><label for="id_field">Field:</label>' '<input id="id_field" name="field" required type="checkbox"></div>', ```
The expected value should be a second argument in `assertEqual()` and `assertHTMLEqual()` assertions.
I think you can remove the blank lines as the helpers for checking HTML should ignore whitespace between tags.
Can we wrap this line after the comma.
This can be single-lined.
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
Makes sense. Lets go with `MyField` then.
Do we need to swap arguments? IMO we want to keep the same order as in `SIMILARITY()` calls. ```suggestion class TrigramWordSimilarity(TrigramBase): function = 'WORD_SIMILARITY' ``` e.g. - `TrigramWordSimilarity('Cat sat on mat.', 'cat')` should be equal to `0.30769232` instead of `1` - `TrigramWordDistance('Cat sat on mat.', 'cat')` should be equal to `0.6923077` instead of `0`
> .. i'll follow your decision :) Just asking, I'm not an expert :shrug:. We can wait for the second opinion from Paolo.
> Paolo, Can you take a look? (\cc @pauloxnet) point_up Sorry, I totally missed the notification of this. I'll take a look
@felixxm yes that's what I'm thinking.
Paolo, Can you take a look? (\cc @pauloxnet) :point_up:
I'm not sure if the included traceback will give enough information to debug this, but it seems like a message something like "Rendering `<template name>` raised an exception, so {% include %} will render as an empty string." might be more helpful.
Wording suggestion: "Rendering {% include (template_name) %} raised (error)."
You want to either pass `exc_info=True` or `sys.exc_info()` here. `exc_info=e` only worked because it evaluated to `True`.
I don't think you need to use the `'template - ...'` prefix here, the log is already namespaced under `'django.template'`.
rather than silenced and rendered as an empty string.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
set default `step_size=None` instead of `"any"` and only render that attribute if it's `not None`.
I'll take the time to write one later today but we could use a `@property`: ``` python @property def widget(self): if self.localize: return TextInput else: return NumberInput ``` One of the con here is that `NumberField.widget` will be an instance of `property`. We could also write a descriptor to maintain backward compatibilty: ``` python class WidgetDescriptor(object): def __init__(self, widget, localized_widget): self.widget = widget self.localized_widget = localized_widget def __get__(self, instance, owner): if instance and instance.localize: return self.localized_widget return self.widget class IntegerField(Field): widget = WidgetDescriptor(NumberInput, TextInput) ``` Maybe I'm just over-complicating this whole thing.
`items = value.split(self.delimiter) if value else []` is slightly faster.
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
I can have a look after lunch @adamchainz — thanks for your work! 🏅
Just to be clear, I meant `processes` variable. But if you want to go with the other suggestion, I won't object.
I think it's okay to use the variable, IMO, especially since it's used twice further down.
You won't need to pass `INFO` if the default is `INFO`.
```suggestion with self.time_keeper.timed('Total database setup'): ```
We shouldn't raise errors about private APIs, we can error nicely when using `Prefetch` with `raw()`, e.g. ```python if queryset is not None: if isinstance(queryset, RawQuerySet) or ( hasattr(queryset, '_iterable_class') and not issubclass(queryset._iterable_class, ModelIterable) ): raise AttributeError('Prefetch querysets cannot use raw() and values().') ```
```suggestion "'obj' must be a model instance." ```
Do we need to use a dict? It seems unnecessary complicated. Model classes that we pass in the keys must match the base models from querysets. We also don't protect against incorrect values e.g. ```python queryset={ Animal: Bookmark.objects.all() } ``` I would use a list/tuple instead and raise an error when a queryset for the specific model is already resolved, e.g. ```python for qs in querysets: ct_id = self.get_content_type(model=qs.query.model, using=qs.db).pk if ct_id in custom_queryset_dict: raise ValueError(...) custom_queryset_dict[ct_id] = qs ``` We should also add a new argument (maybe `querysets`) because it's misleading to pass list of querysets in the argument called `queryset`.
We should pass `using` from the queryset ```suggestion ct_id = self.get_content_type(model=model_cls, using=ct_queryset.db).pk ```
We can add a control assertion to confirm that a `house` is cached for the `room`: ```suggestion self.assertIs(Room.house.is_cached(self.room), True) with self.assertNumQueries(0): ```
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
Wouldn't it be a bit more helpful for this error message to specifically note that the module with the given path couldn't be imported? "Invalid" is a very vague term, which could mean all sorts of things - it seems unhelpful to silence an `ImportError` and replace it with a much vaguer message.
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
has a -> is of a
This error is raised when instantiating so we don't need to include a `route` in the message.
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
Wrap at 79 chars, please.
A small oversight I noticed in an old Python 3.7.0 virtualenv: https://github.com/django/django/pull/13393
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
They are helpful when using (i)pdb.
This `raise` seems redundant. I would remove these two lines (629-630) and leave only raise `ValueError(...)` at the end of this method.
`abs()` is redundant since `end` is greater than 0.
"start argument must be a negative integer, zero, or None, but got %s."
This isn't really a state you can end up with, because you have two leaf nodes in one app. `manage.py migrate` will not work: https://github.com/django/django/blob/master/django/core/management/commands/migrate.py#L78
Use consistent docstring style with rest of file? ``` """ Text """ ```
Could you please keep the cross-app reference that we had before.
Move this to the top.
add trailing comma on kwargs
I'm not completely convinced we should have this as a lookup. The API feels very strange, and we have the `TrigramDistance` expression which feels more similar to other things. `trigram_similar` is fine.
We definitely want to have a way of saying `.filter(TrigramDistance(F('foo'), 'test') > 0.7)` or something, but we haven't been able to come up with the right syntax yet so annotate is the compromise. I wasn't aware of the geo lookups, they were written a long time before expressions existed when that would have been the only way of implementing them. GeoDjango in general is in need of a lot of tidy up in a post-expressions world.
> Just so I'm clear then, sorry, would filter(foo__trigram_distance=("Test", 0.5)) be the same as filter(foo=TrigramDistance("Test", 0.5))? If so, then that's fine, I just thought they differed somehow. Until [#25367](https://code.djangoproject.com/ticket/25367) is fixed you have to rely on annotate. Should be along the lines of: ``` python annotate( foo_distance=TrigramDistance(F('foo'), 'Test') ).filter(foo_distance__lte=0.5)` ```
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
Since `SmallAutoField` extends `SmallIntegerField` this can be reduced to ```suggestion elif isinstance(self.lhs.output_field, models.SmallIntegerField): ```
I think a `Warning` is more appropriate here, something like "URL namespace {} is not unique, you may not be able to reverse all URLs in this namespace". Errors prevent management commands from running, which is a bit severe for this case.
`url.urlconf_name` is, more often than not, a URLconf name or module, not a list of patterns. It would be better to use `url.url_patterns` here as well.
Why the `!= 'app'`? This seems to hide some test failures in `test_check_unique_namespaces`.
You should probably check `if getattr(settings, 'ROOT_URLCONF', None)`, similar to the `check_url_config()` check.
you should accumulate all warnings into a list and return that at the end of the function. At the moment this returns early, if there are two non-unique names in use, only the first one will get a warning. If the user fixes that, they run the checks again, and get a new warning about the second non-unique name. Not a great workflow if there are many to fix.
The other option is to wrap the file with something like: ``` from django.core.files import File class ChunkedFile(File): DEFAULT_CHUNK_SIZE = 4096 def __iter__(self): return self.chunks() return StreamingResponse(ChunkedFile(open(fullpath, 'rb'))) ``` I considered using this wrapper for FileResponse.
Your solution honestly isn't _that_ much more complex, so I'm not saying we shouldn't do it, I was just curious how you ended up here! I think the resulting patch is pretty nice - I will need to take more time to properly review it but I like it on first glance.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
`aiter` is new in Python 3.10. https://docs.python.org/3.10/library/functions.html#aiter Django 4.2 will support Python 3.8, and 3.9 too.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
Don't think we need to worry about duplicates.
As long as you use `except Exception` and not a bare `except` this should be good.
If we remove this will the tests run on Jenkins? It might be fine.
We shouldn't silently change passed parameters. IMO it better to raise an exception like we do now: ``` $ export DJANGO_SETTINGS_MODULE=test_oracle $ ./runtests.py queries --parallel=2 Testing against Django installed in '/django/django' with up to 2 processes Found 416 test(s). Creating test database for alias 'default'... Creating test user... Cloning test database for alias 'default'... Traceback (most recent call last): File "./runtests.py", line 659, in <module> failures = django_tests( File "./runtests.py", line 385, in django_tests failures = test_runner.run_tests(test_labels) File "/django/django/test/runner.py", line 881, in run_tests old_config = self.setup_databases( File "/django/django/test/runner.py", line 787, in setup_databases return _setup_databases( File "/django/django/test/utils.py", line 217, in setup_databases connection.creation.clone_test_db( File "/django/django/db/backends/base/creation.py", line 239, in clone_test_db self._clone_test_db(suffix, verbosity, keepdb) File "/django/django/db/backends/base/creation.py", line 255, in _clone_test_db raise NotImplementedError( NotImplementedError: The database backend doesn't support cloning databases. Disable the option to run tests in parallel processes. ```
```suggestion reg_key_value, _ = winreg.QueryValueEx(reg_key, 'VirtualTerminalLevel') ```
I'm not sure that it makes any sense checking the registry. There is no guarantee that you are using a terminal that uses this. So it could just result in a blanket "on" if this is set. It would be better to take the `ctypes` approach mentioned to check whether currently enabled for the actual terminal in use.
It is also "Windows Terminal", not "Microsoft Terminal".
`Determines` -> `Determine` `will support` -> `supports` This docstring can be single-lined.
Do we really need this inner function? We could just shortcut out early if not a TTY.
This formatting change is not related with a bug fix, please revert.
I moved a cleanup part to a separate commit.
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
line saver? ``` format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' extra_context['format_string'] = format_string ```
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
I suggested that because `annotation_select` now contains expressions other than aggregates. But I didn't notice the method was in the AggregateCompiler, so it probably is just aggregates in that dict. Not worth worrying about I guess.
```suggestion "Cannot aggregate over the 'other_age' alias. Use annotate() to promote it" ```
This isn't safe unfortunately. Consider the following test results (which fail): ``` def test_empty_expression_char(self): books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value('Empty')), default=Value('Not Empty'), output_field=CharField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, 'Not Empty') def test_empty_expression_datetime(self): from django.utils import timezone from datetime import timedelta now = timezone.now() then = now + timedelta(days=1) books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value(now)), default=Value(then), output_field=DateTimeField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, then) ``` Depending on whether or not there are dbconverters run, these will fail with one of the following kinds of errors: 1. `TypeError: expected string or buffer` 2. `AssertionError: 0 != datetime.datetime(2016, 5, 23, 18, 59, 26, 409777)` For what it's worth, both of these tests fail without your patch too, except they fail during the count just like the report on the ticket says. This certainly needs fixing in some way, but we can't just use 0 as a value all of the time.
Case expressions use Q internally which led me to writing the above tests. I think you're right that EmptyResultSet might be able to be caught directly, and then it could use the `default` argument in place of the static `'0'` you have above. The changes need to be made in tandem though.
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
Doesn't matter much, but something like `AuthenticationMiddlewareSubclass` would be more descriptive about the purpose.
This method should be added after the docstring
You've done well to limit the latin-1 charset to this class. :1st_place_medal:
good point, this avoids my laziness on the ticket :)
This can be single-lined. Also, please use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion custom_libraries = conf.get('OPTIONS', {}).get('libraries', {}) ```
Could we call this `BaseManager` instead? That's what it is now...
We usually use the `opts` variable to store `_meta` locally.
I'm curious if there's a guideline about when to use these techniques. I'm particularly surpised at things like `_setattr = setattr`, though I haven't done much micro-optimization.
Shouldn't mixins be to the left of the base class `models.Model`? This is my understanding of how mixins on class-based views work anyway.
Didn't know `__instancecheck__` was never called when `instance.__class__ is self`.
I'd add `HAS_CX_ORACLE` flag to use it here: ```python try: import oracledb except ImportError: import cx_Oracle as oracledb HAS_CX_ORACLE = True else: HAS_CX_ORACLE = False ... @cached_property def data_types_reverse(self): # RemovedInDjango51Warning. if HAS_CX_ORACLE and self.connection.cx_oracle_version < (8,): ```
missing whitespace around ==
it would help readability if description[5] and description[4] were assigned local variables describing what they represent
```python return value if isinstance(value, list) else [value] ```
Use double quote docstrtings.
Ah, yes. Good observation. 🙂
We could flatten this? ```suggestion return default if value is None else self._serializer.loads(value) ```
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
Don't use `.items()` if you don't need the values. ```suggestion # Set timeout for each key individually as .mset() doesn't support # setting the timeout for all keys at the same time. for key in data: if timeout is None: client.persist(key) else: client.expire(key, timeout) ```
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
You can just say `expected`. (It's clear from the next line.)
This test data seems wrong to me. For example, you have verbosity `1` leading to level `DEBUG`, which means that logging at a level of `DEBUG` should result in output per the logic below (since `logging_level >= level` appends `output = True`). That isn't right though, since verbosity `1` shouldn't show `DEBUG`. The test would be a lot easier to understand and update if it was simply a hard-coded, sorted list of tuples, e.g. ```python cases = [ (0, None, False), (0, logging.DEBUG, False), (0, logging.INFO, False), (0, logging.WARNING, False), ... ] ``` Including `level=None` will serve to check the default case. Also, you don't need to check `level=logging.NOTSET` since that's not a level that anyone would ever pass when logging a message. That level is more for when reading what level is set on a configured logger. Having the correct test should help with getting your logic correct in the `log()` method above.
No problem, happy to help. Thanks for keeping at it.
I think you can simplify the above method implementation quite a bit by using more tailored logic. For example, you can start the method with: ```python if self.verbosity == 0: return ``` and then you're left with just two cases: verbosity `2` or more (log everything), and verbosity `None` and `1` (log `INFO` or higher). This should let you do away with the need for a separate `logging_level` variable. Once your test below is fixed, it should help you understand what's needed here.
Add a trailing comma so if more items are added later we don't have to modify this line again.
`remove_index()` accepts `concurrently`, moreover `self.allow_migrate_model()` check `self.allow_migrate_model()` check is missing, IMO we should use ```python if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.remove_index(model, self.index, concurrently=True) ```
`add_index()` accepts `concurrently`, moreover `self.allow_migrate_model()` check is missing, IMO we should use ```python if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.add_index(model, self.index, concurrently=True) ```
Chop blank line.
I briefly remember that there was an issue with wrong index names a while ago, that _somehow_ got in people's projects. I can't recall the details, but all migration operations should enforce a deterministic index name present. That is, `AddIndex` checking for `self.index.name` and `RemoveIndex` checking for `self.name`.
It's solving the issue about `DropIndex` taking a name mentioned above and should make a lot stuff easier to deal with (such as index renames) as indexes will be identifiable by a user defined string. Either all `Index` should have a user defined name like field or we should not try to mimic the `RemoveField` API and make `DropIndex` take an `Index` instead of a system generated name.
Despite the existing style of the first test, I would remove the intermediate `f` variable in the new tests as it'll help balance line lengths and make things more readable.
please multiline the string ``` '<select id="id_f" name="f" disabled><option value="J">John</option>' '<option value="P">Paul</option></select>') ```
+1, this test was also removed in my force_text audit WIP branch.
`# Values provided in the form's data are ignored.` Might be good to have a test for `Form(data, initial=...)` too.
```suggestion form.render(), '<div><fieldset><legend>Field:</legend><div id="id_field">' '<div><label for="id_field_0"><input type="checkbox" ' 'name="field" value="J" id="id_field_0"> John</label></div>' '<div><label for="id_field_1"><input type="checkbox" ' 'name="field" value="P" id="id_field_1">Paul</label></div>' '<div><label for="id_field_2"><input type="checkbox" ' 'name="field" value="G" id="id_field_2"> George</label></div>' '<div><label for="id_field_3"><input type="checkbox" ' 'name="field" value="R" id="id_field_3">' "Ringo</label></div></div></fieldset></div>", ```
Not sure which of `defer` or `deferrable` makes more sense. The latter might be preferable if we choose the `Deferrable(Enum)` solution.
Sorry yes I meant `transaction` 🤦‍♂. I think there's `connections[using].in_atomic_block` or something like that.
Looks like this should live on the connection.
If the connection becomes unusable at this point this will obscure the original exception.
returns->return (use PEP257 verb style for new docstrings)
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
Use `showmigrations` instead of `"migrate", list=True` which is deprecated (we seem to have a bug in `@ignore_warnings` that causes it to leak state as the tests should catch the use of deprecated features and fail).
usual style is to put the ticket number in parenthesis at the end of the sentence
if no app*
Positional arguments cannot follow keyword arguments.
I'm a little concerned about the loss of `constant_time_compare()` here which sounds like it was added as a potential mitigation against timing attacks.
`max_age` is not being passed into `signing.loads()`, nor is `self.serializer`. `session_dict` should be `session_data`.
While I realize we cannot change that now, do we remember why we added `django.http.cookies` here? The salt alone should make sure that we do not clash with other signatures.
Maybe we could add `pbkdf2_sha1` in place of `sha1`.
@lothemar I realized that previous assertions were correct. The current tests work even without this patch. I will restore them, sorry.
I'm not sure why we pass `data` and build a query string in tests views :thinking: I would simplify this: ```python def test_follow_307_and_308_no_get_preserves_query_string(self): methods = ('post', 'head', 'options', 'put', 'patch', 'delete', 'trace') codes = (307, 308) for method, code in itertools.product(methods, codes): with self.subTest(method=method, code=code): req_method = getattr(self.client, method) response = req_method('/redirect_query_%s/' % code, follow=True) self.assertRedirects(response, '/post_view/?hello=world', status_code=code) ``` and in `views.py`: ```python def method_saving_307_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=307) def method_saving_308_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=308) ``` Maybe I'm missing sth.
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
It's a small detail, but I think the variable naming could be improved here. `request_method` and `req_method` are very similar names (one is just a shortening of the other) but they mean very different things. I might rename `request_method` to `req_method_name` or something. Or you could probably just turn this into a single line and avoid a temporary variable.
I wouldn't include this test in the PR because it's testing existing behavior. But it doesn't seem needed as there's a test in `test_client_regress` that fails if the `isinstance(data, dict)` check is `_encode_json` is removed.
Imports should be wrapped at 79 chars. Please move `Choice` to the next line: ```python Bookmark, Box, Category, Chapter, ChapterXtra1, Child, ChildOfReferer, Choice, City, Collector, Color, Color2, ComplexSortedPerson, CoverLetter, ```
It usually isn't a problem. There always the option to add another field to that model if making the existing field nullable causes an issue.
```suggestion City, Collector, Color, Color2, ComplexSortedPerson, CoverLetter, ```
Use `self.assertCountEqual()` when ordering is not specified and we have more than one expected result.
We want to get rid of `repr` in `assertQuerysetEqual()`, can we change to the `self.assertSequenceEqual()`, e.g. ```python @classmethod def setUpTestData(cls): ... cls.c5 = Company.objects.create(name='99300 Ltd', num_employees=99, num_chairs=300, ceo=ceo) def test_range_lookup_namedtuple(self): EmployeeRange = namedtuple('EmployeeRange', 'minimum maximum') qs = Company.objects.filter( num_employees__range=EmployeeRange(minimum=51, maximum=100), ) self.assertSequenceEqual(qs, [self.c5]) ```
While my tests suggest that iterating a set is ~8% slower in this case, it is a negligible difference once you look at the whole `_expire_cache` function.
to minimize size of try: ``` try: m2m = kwargs['many_to_many'] except KeyError: pass else: warnings.warn(.... ```
Keeping the try block limited to just the code you expect to throw the exception is a good practice. It prevents a situation where there's some other bug than what you expected. For example, if `warnings.warn(` somehow threw a `KeyError` and it was in the try block, you would unexpectedly hide that bug.
The approach you've taken here is: - Cache the result of get_fields() for a specific set of arguments - look up a name in that list; - Raise FieldDoesNotExist if the name is not found. The other obvious approach I can think of would be: - Cache a list of _all_ fields - Look up the name in that list - Raise FieldDoesNotExist if the name is not found - Raise FieldDoesNotExist if the field doesn't have the requested properties. I'd be interested to see the "memory vs speed" tradeoff for these two approaches.
True about the ML. Regarding the naming for `related_objects/related_m2m` vs `reverse_rel/reverse_m2m`, that's a new API so there isn't historical names to preserve (unlike `many_to_many` vs `m2m`), we just need to pick the best names to represent the relations.
I think it would be better to use the same parameter formatting style as the `save()` method below.
import should go at the top of the file unless it causes a circular import
Chop blank line.
You can probably use `assertSequenceEqual` here which might be a bit nicer.
`add()` accepts IDs so we can simplify this, e.g. ```python ... user.save(using=self._db) user.orgs.add(*orgs.split()) ```
I'd rather not pollute the global namespace. Could you use a temporary `Apps` (e.g. https://github.com/django/django/blob/master/tests/migrations/models.py#L24)
It would be great to also have a test with a reverse manager.
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
I don't see much value in this docstring.
it's a separate item, but I wonder if we could patch override_settings to handle DATABASE_ROUTERS like is done below
Please use a hanging indentation: ``` python self.assertEqual( set(...), {...}, ) ```
This test works without the patch, I will move it to a separate commit.
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
I think keeping the explicit `process_response()` call here would make sense. By changing to `__call__()` we're running through `process_request()`, which is not a no-op, which is perhaps fine but it's subtly changing the intent/behaviour of the test. (I guess this is something we'd have to think about removing the `process_x()` hooks, but not in this PR) Same for line 677 below. **Update**: Tests in `csrf_tests` are more explicit about this... (So maybe the small change here is OK)
the active language's
btw `reversed(x)` doesn't actually iterate the whole list in reverse in python 3, you just get a `list_reverseiterator`... ``` In [1]: reversed([1]) Out[1]: <list_reverseiterator at 0x105098b70> ``` :)
the `reversed` call isn't free, it's slightly more optimal to put the wrappers in the list in the way you want to iterate them
_execute_create_test_db to fix the tests.
``` python # the following time is equivalent to UTC 2014-03-13 05:34:23.24000 ```
Can you add a `call_count` check, please: https://github.com/django/django/pull/4901/files#diff-c11e6432df7086eda3dfb9ab8e5b2839R1491
Small nitpick, I would replace those bare side effect `Exception` by `AssertionError` while you're around.
Could you add an `assetNumberMigrations` before the `assertOperationTypes` and join the `assertOperationAttribute` checks; they take `**kwargs`.
Can you also check for `questioner.ask_auto_now_add_addition` to be called 3 times, please or is this something we don't do in here but in commands.
Should be changing double quotes to single, if at all. I wouldn't really worry about it though.
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
Unindent by one level, please.
Most likely this will not work on Windows because files created with `NamedTemporaryFile` cannot be reopened on Windows (which defeats the whole purpose of naming them in the first place -- I have no idea why `NamedTemporaryFile` even exists on Windows). I'm not saying this is blocking the merge because I don't think we have that many users of PostgreSQL on Windows, but I thought I'd bring it up in case someone wants to check.
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
This test is already in the `backends.base.test_creation` and it's unrelated with this fix. Please remove it.
parenthesis to next line
`# Prevent the RuntimeWarning subclass from appearing as an exception due to the warnings.simplefilter() in runtests.py.`
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
I would assert `len(warns) == 1`.
I thought the if style of the old PR was a bit better (with more equal line lengths).
PEP 8 recommends breaking before binary operators: https://www.python.org/dev/peps/pep-0008/#should-a-line-break-before-or-after-a-binary-operator
`settings.LANGUAGE_CODE` as you pointed out.
There is no need to check `i18n_patterns_used` here, it's already checked above. I believe the cast to `str()` is unnecessary.
IMHO, it's clearer if you use: ``` python if not prefixed_default_language and language == settings.LANGUAGE_CODE: language_path = '/%s' % (request.path_info) else: language_path = '/%s%s' % (language, request.path_info) ```
`from django.core import signing`
Do you prefer `references.X` as opposed to importing each class? We've sometimes removed that pattern elsewhere.
Doesn't exist in 1.5, be careful when backporting
please alphabetize imports
This import should be alphabetized, but we can fix that up when committing.
We cannot make serial pk assumption: ```diff diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py index 8b54611010..ea68a105d6 100644 --- a/tests/model_forms/tests.py +++ b/tests/model_forms/tests.py @@ -1765,10 +1765,12 @@ class ModelMultipleChoiceFieldTests(TestCase): f.clean([c6.id]) def test_model_multiple_choice_field_validate_choices_called_properly(self): + c1 = self.c1 + class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField, TestCase): def validate_choices(self, queryset, field_name, selected_choices): self.assertIsInstance(queryset, models.QuerySet) - self.assertQuerysetEqual(queryset.order_by('id'), [1], lambda a: a.id) + self.assertSequenceEqual(queryset, [c1]) self.assertIsInstance(field_name, str) self.assertEqual(field_name, 'pk') self.assertIsInstance(selected_choices, frozenset) ```
Can we use "0" instead? ```suggestion f.clean(["0"]) ```
You shouldn't have a `u` prefix here
I don't think this test is sufficient. Having the first element in the output is quite likely. I'd check for the html or at least for `John` and `Paul`
don't need a trailing comma for lists of length 1 (only applies to tuple).
This looks unnecessary.
Manager will raise a different `IntegrityError`, e.g. _"The row in table 'auth_tests_customuserwithfk' with primary key '1' has an invalid foreign key: auth_tests_customuserwithfk.group_id contains a value '-1' that does not have a corresponding value in auth_group.id."._
This is risky, I would use (in all new tests): ```suggestion Group.objects.all().delete() nonexistent_group_id = 1 ```
We run `createsuperuser` in non-interactive mode so `@mock_inputs` is unnecessary.
We run `createsuperuser` in non-interactive mode so `@mock_inputs` is unnecessary.
So, I've been hemming and hawing on whether to mention it, because it conceptually works when in the error message, but it still seems slightly _'off'_ to me that the warning would say `SECRET_KEY_FALLBACK` when the setting is `SECRET_KEY_FALLBACKS` (plural). I guess if we're not going to say _which_ one errored (which _we could_, using hints) I think it'd make more sense to say `One of your SECRET_KEY_FALLBACKS has less ...`
Things seem to be hung up on "Django-generated". I propose the following wording instead which seems clearer to me. I also note that "sufficiently" sneaked in there, but I'm not sure it really adds anything. Also note that the line wrapping should be maintained. ```suggestion "Your SECRET_KEY has less than %(min_length)s characters, less than " "%(min_unique_chars)s unique characters, or it is prefixed with " "'django-insecure-' indicating that it was generated automatically by " "Django. Please generate a long and random SECRET_KEY, otherwise many of " "Django's security-critical features will be vulnerable to attack." % { ``` (Note this suggestion may not apply cleanly in GitHub as I needed to include unchanged lines around the removed and added lines.)
This would set `SECRET_KEYS` to `[None]` if `SECRET_KEY` was `None` which again gives me the impression that using `is_overriden` is the wrong approach here.
`it's django-generated` --> `it's a Django-generated`
Maybe `map()`: ```suggestion fallback_keys=map(_cookie_signer_key, settings.SECRET_KEY_FALLBACKS), ```
I would directly check against `argon2.low_level.ARGON2_VERSION`. What I want to prevent is a new argon version increasing the version number and we have to issue a new django release to take advantage of that.
This means that installing a new version of argon2-cffi might cause all passwords to be rehashed upon login, correct? Might be worth a mention in the docs about this.
Is there any good reason to specify the version? Ie I would assume we would always want the newest? Edit:// Gotta run, full review coming later.
no need for "ok" variable.. can return directly.
As above, please use hanging indent.
looks to me like it could actually be a set comprehension for more speed again since it's only used for N `not in` checks below
It's not used only for combined queries so we should call it only in `not combinator` branch.
I'd chop the blank lines around `for_update_part`.
Unnecessary list comprehension, `tuple(self.model._meta.pk.get_col(inner_query.get_initial_alias()))` should do.
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
Besides, this change doesn't improve speed. From experience, any change will slow down reviews and hinder this from being merged ;)
IMHO I don't think you should use 0 values as boolean. If you want boolean, use boolean. Besides, `grouping` may have too many types now. I can be an integer, a tuple and boolean. I would stick with a separate variable called `use_grouping` here. It's more descriptive.
please avoid non-4 space indentation
Do we need such a large try/except block? That makes it difficult to spot what statement(s) might throw an exception and could hide other bugs.
Out of curiosity, when does `'E'` is present in `str(number)`? Trying to figure out when the `lower()` call is necessary.
_"Use single quotes for strings, or a double quote if the string contains a single quote. Don’t waste time doing unrelated refactoring of existing code to conform to this style."_
Use single quotes.
Please chop all unnecessary blank lines.
A bit simpler could be "Clear cached, stale oids."
I'm not exactly sure what "straight away" means here. I wonder if something like this could be an improvement: ``` # Registering new type handlers cannot be done before the extension is # installed, otherwise a subsequent data migration would use the same # connection. ```
I would stick with the one line if/else statements. The style guide says, "Don’t limit lines of code to 79 characters if it means the code looks significantly uglier or is harder to read."
Instead of putting timeout in the `__init__` method, make it a class attribute. Here's an example change where we use this same technique: 8b0014869f666b44cd20692e38073ec0a0a8cb08
You should set `self.timeout` to `timeout`, not 60.
I think the test fails as it is as you're no longer passing `self.timeout` to `smtplib.SMTP_SSL`. I don't think Django should specify a default of 60. Instead it should be `None` and only passed to the SMTP connection if the user specifies it. Here's a quick sketch of what I have in mind (plus some cleanup): ``` python # If local_hostname is not specified, socket.getfqdn() gets used. # For performance, we use the cached FQDN for local_hostname. connection_class = smtplib.SMTP_SSL if self.use_ssl else smtplib.SMTP connection_params = { 'local_hostname': DNS_NAME.get_fqdn(), } if self.timeout is not None: connection_params['timeout'] = self.timeout self.connection = connection_class(self.host, self.port, **connection_params) # TLS/SSL are mutually exclusive, so only attempt TLS over # non-secure connections. if not self.use_ssl and self.use_tls: self.connection.ehlo() self.connection.starttls() self.connection.ehlo() ``` For the test you'd subclass `EmailBackend` and verify the connection has the timeout use specified.
the try/except needs to be added back
It should be enough to use `lru_cache` instead, e.g.: ```python @functools.lru_cache(maxsize=128) def import_string(dotted_path): ... ```
> @kezabelle This method is very good, but there are currently many Django-related modules that reference import_string during operation. If you add a cache_import, you must modify and adjust the module code that references import_string to improve performance. You can add a new hook and use it in `import_string()`, e.g. ```python def cached_import(module_name, item_name): modules = sys.modules if module_name not in modules: import_module(module_name) return getattr(sys.modules[module_name], item_name) def import_string(dotted_path): """ Import a dotted module path and return the attribute/class designated by the last name in the path. Raise ImportError if the import failed. """ try: module_path, class_name = dotted_path.rsplit('.', 1) except ValueError as err: raise ImportError("%s doesn't look like a module path" % dotted_path) from err try: return cached_import(module_path, class_name) except AttributeError as err: raise ImportError('Module "%s" does not define a "%s" attribute/class' % ( module_path, class_name) ) from err ```
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
I wonder if we could support running `runtests.py` from different directories :thinking: like we do for dotted module names, e.g. ```bash ~/repo/django> ./tests/runtests.py backends.postgresql ``` works fine, but ```bash ~/repo/django> ./tests/runtests.py backends/postgresql/ .... File "./tests/runtests.py", line 155, in get_label_module rel_path = path.relative_to(RUNTESTS_DIR) File "/usr/lib/python3.8/pathlib.py", line 904, in relative_to raise ValueError("{!r} does not start with {!r}" ValueError: '/repo/django/backends/postgresql' does not start with '/repo/django/tests' ``` crashes. I tried to fix this with: ```python # Otherwise, interpret the label as a path. if not path.is_absolute(): return path.parts[0] else: path = path.absolute() rel_path = path.relative_to(RUNTESTS_DIR) return rel_path.parts[0] ``` but it crashes with `ModuleNotFoundError` (like without this patch): ``` ====================================================================== ERROR: backends/postgresql (unittest.loader._FailedTest) ---------------------------------------------------------------------- ImportError: Failed to import test module: backends/postgresql Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 154, in loadTestsFromName module = __import__(module_name) ModuleNotFoundError: No module named 'backends/postgresql' ```
Yeah it works for me, sorry again. The current version looks good :+1: , we could only raise a more descriptive error when a relative path is not correct (as proposed in https://github.com/django/django/pull/14507#discussion_r648186310).
`Test passing` is unnecessary, IMO, maybe: ```suggestion # A token of length CSRF_SECRET_LENGTH. ```
```suggestion self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
```suggestion self.assertNotIn('CSRF_COOKIE', request.META) self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
`self.assertNotIn()` is preferred: ```suggestion self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
This looks odd to me. In my view, assertions should never be considered part of (even internal) API. To strengthen this point -- this test should fail if the test suite is run with `python -o2` (assuming `assertRaises` actually raises an AssertionError, rather than `assert`ing something, of course...).
Please remove this unrelated change.
This must also take the sign into account. What about: ``` python max_length = self.max_digits + 1 # for the sign if self.decimal_places is None or self.decimal_places > 0: max_length += 1 # for the dot ``` We could also make the sign check conditional based on `min_value` and `max_value` but it would be a mess.
```suggestion return '-' + value if neg else value ```
Ah, I realized these are E128 which we are ignoring in the flake8 section of setup.cfg. I don't mind the changes, but we are ignoring it because there are 2K+ violations and seemingly not a lot of value in fixing them.
We might want to avoid doing this if `self.localize is True` since `DECIMAL_SEPARATOR` and `THOUSAND_SEPARATOR` should be taken into account in this case.
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
Such an extensive docstring is not necessary, IMO.
Ok, I don't think it needs to be skipped on sqlite (since it passes). A note in the docstring that it's only a problem on certain databases would be helpful.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
I don't understand why we have methods with a double underscores prefix which are copies from `SessionBase`, e.g. `__hash()`, `__legacy_encode()`, `__legacy_decode()` :thinking:
I don't see a reason we can't use Python's `hash()` builtin, which is even faster and cached on strings I also don't think we need a class here - a single function to do the shuffling would do.
I am currently giving the PR a full final review and I think we can drop those assertions now that they are done in decode already, what do you think? (same for the assertion in `safe_summary` and other hashers)
You should be able to pass `is_active=False` to `create_user()`.
Perhaps some refactoring using `subTest` as done in https://github.com/django/django/pull/7822 would be better.
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
Since you need an extra line anyway, I'd guess I'd do: ``` msg = '...' with self.assertRaisesMessage(ValidationError, msg): ```
Will this statement will fit on a single line? (119 characters is permitted.)
```suggestion self.resolve_model_field_relations(model_key, name, field) ```
I think this would be simpler if you did: ```python if old_remote_field: if new_remote_field: ... else: # Include code from the `if old_remote_field` case below. ... elif new_remote_field: # Include code from the `elif new_remote_field` case below. ```
```suggestion self.resolve_model_field_relations(model_key, name, old_field) ```
It looks like you can actually do `fields = self.models[model_key].fields` (similar to further down) since you're only using `model_state.fields` below.
This would be cleaner if you did the following before handling the `self._relations is not None` case: ```python if self._relations is None: fields[name] = field return ``` Then you don't need to indent after.
Instead of this file dance, it would be easier to use a `tempfile.NamedTemporaryFile`. It is also safer wrt parallel test runs.
```suggestion """PO files are unchanged unless there are new changes.""" ```
I don't think the intermediate `pattern` variable is needed.
```suggestion self.original_po_contents = Path(self.PO_FILE).read_text() ```
Can we make any positive assertion? I'm a bit nervous about a negative assertion like this since, for example, a typo in the regular expression could cause the test to pass by mistake.
I searched a bit and couldn't find the exact ticket but the reported issue had something to do with Django's `lazy` logic and could be triggered even with ASCII only chars.
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
please limit line lengths to 119 characters like this: ``` '<li class="success">The short message "<a href="%s">ShortMessage_Deferred_timestamp object</a>" ' 'was changed ....' ```
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
We can add a control assertion to confirm that a `house` is cached for the `room`: ```suggestion self.assertIs(Room.house.is_cached(self.room), True) with self.assertNumQueries(0): ```
Removing this code now requires us to pass a backend into `force_login` if multiple authentication backends are configured. Was that intentional? It doesn't seem like this requirement is in line with what `force_login` is meant to be. After updating to 1.10, I now have hundreds of calls to `force_login` in my unit tests that need updating. This is an easy mechanical update, but was this commit intended to be a test-code-breaking change in this way? If not, I'm happy to go file a bug...
Yes, I think Django would be obviously broken in such a configuration anyway.
I don't think there's a use case for `settings.AUTHENTICATION_BACKENDS` without any backends that have a `get_user()` method.
`self.request()` rather than `self.handler(self._base_environ())`? Interestingly `Client.request()` is the only method that goes through the middleware, all others (`get()`, `post()`, etc. simply proxy `RequestFactory`.
Please use assertRaisesMessage to verify this is the ValueError we expect.
`depth a recursive subquery references adds` → `depth recursive subquery references add`
Are there situations in which this can happen other than "too many subqueries"? If not, I'd suggest an error message that might be more helpful to the end user would be "Maximum recursion depth exceeded: too many subqueries."
It might be nice to create some objects and verify the ordering so that models aren't inadvertently refactored and ordering attributes lost which would eliminate their regression nature.
I feel worried about keeping a `while True` loop here. I will lead to an infinite test run if the implementation of the code to be tested is broken. Can you change that into a for loop. You are already counting `i` upwards, but aren't using it.
`context.exception.message` -> `six.text_type(context.exception)`
has the side effect of shortening... (no dash needed)
I don't see much value in this docstring, please remove it.
Inner import is not necessary: ```python from django.core.mail import ( DNS_NAME, EmailMessage, EmailMultiAlternatives, mail_admins, mail_managers, send_mail, send_mass_mail, ) ```
Same style as above.
chop blank line
prefer `setUpTestData` since that executes once per test class instead of once for every method
Another option could be to refactor into 3 separate test methods that call a common helper method to run the logic currently in the loop. This can be easier to debug than assertions that run within a loop.
I'd declare this as a `test_params` variable above to avoid the funky indent.
These kind of changes are not related and should be reverted, IMO. They're also based on a `MiddlewareMixin` behavior that we can remove in the future, that's why I would prefer to keep `process_request()`/`process_response()` tests.
I think `__str__` can be omitted here. If it needs to stay, `CustomUserWithIntegerUsername` should be wrapped by `@python_2_unicode_compatible`.
I would add a flag to `Index`, e.g. `is_functional` that could be used here together with `supports_expression_indexes` to skip such indexes, e.g. ```python if not index.is_functional or self.connection.features.supports_expression_indexes: output.append(index.create_sql(model, self)) ``` Also we should return `None` in `_create_index_sql()` and `_delete_index_sql` if `index.is_functional` and `self.connection.features.supports_expression_indexes`
``` if name is None: name = self._create_index_name(*args, **kwargs) return self.quote_name(name) ```
Rebase and add `model` argument.
This formatting change is not related with a bug fix, please revert.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
The thing is that even if the ORM doesn't have support for it yet using `distinct()` to implement `(UNION|INTERSECT) ALL` might prevent us from adding proper support in the future. What I suggest doing here is setting `query.combinator.all = kwargs['all']` and preventing using `distinct()` on `CombinedQuerySet`. The difference between ordering and combination operation is that the former operates on the _combined_ set of rows while the latter operates on how these rows are combined. I would suggest that options related to combination be passed as `kwargs` (such as `all`) and actions operating of the combined result (`CombinedQuerySet` instances) be added as methods (`order_by`, _slicing_).
Why are you copying the `QuerySet`s? Shouldn't be necessary as all their attributes are immutable except outside of other operations, and the result cache doesn't seem to affect their use in the combined qs.
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
I'll quickly check if an idea I'm having works here.
These tests should be moved to a separate commit.
```suggestion # RemovedInDjango50Warning: when the deprecation ends, remove # mark_safe() call. ```
I know this is the sort of layout that `black` would generate, but it's one of the more ugly choices it doesn't get right in my opinion. Perhaps we should `+=` instead of `.extend()`: ```suggestion top_errors += [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ```
I think that `BaseForm.get_context()` describes this perfectly well: ```suggestion ``` But if we must keep it, it should be collapsed onto one line: ```suggestion """Returns context for form rendering.""" ```
```suggestion """Render as <p> elements.""" ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
Having `self.validate_number` being called twice doesn't matter too much, I think.
`# Prevent the RuntimeWarning subclass from appearing as an exception due to the warnings.simplefilter() in runtests.py.`
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
Yeah, this is a good point, reuse an ordering if possible (maybe even force it)
This is inconsistent but I think the patch can land as is and the test be modified later on based on the direction of [#24082](https://code.djangoproject.com/ticket/24082).
To have more balanced line length, I think I prefer: ``` python constraints = self.get_constraints(IntegerArrayModel._meta.db_table) self.assertEqual(constraints['integer_array_model_field_gin']['type'], 'gin') ```
`get_constraints()` depends on database, e.g. on PostgreSQL unique constraints are reported as indexes. That's why I decided to move unique constraints assertions to a separate method `assertUniqueConstraintExists()`.
```suggestion editor.remove_index(Scene, index) ```
longer lines here are okay, we try to avoid non-multiple of 4 indents
`not 100 < status < 599` might look simpler
It might be better to omit the quotes around status since that's making everything seem like a string.
No, it should be made consistent with other codes (capfirst or title, I haven't checked).
this can be 1 line (we prefer longer lines when it improves readability)
we shouldn't reorder kwargs due to the possibility of users passing them as positional args (as the test update you made indicates)
I think this is a bit vague. Perhaps `_check_single_primary_key`.
It looks like should use `f.get_attname()` instead of rebuilding that here.
"foreign key id" may not be the best wording. For example, this also applies to subclasses like OneToOneField.
multi-line as other messages: ``` "The model cannot have more than one field with " "'primary_key=True'.", ```
Looking at the code a bit more, I believe we just want to check `f.db_column` -- it will be `None` if the user hasn't provided a value. With the current implementation, if the user provides a value equal to the auto-generated value, we'll inadvertently perform this check.
Wrap at 79 chars.
Can move `test_conditional_annotation` to the `WindowFunctionTests`? As far as I'm aware it should work now.
Please revert all unrelated changes from single to double quotes.
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
These tests should be moved to a separate commit.
Yes, consistency matters :-) Maybe @timgraham can bring his expertise here.
Looks like in English the period is inside the quotes (see grammar sites).
Use `%r` in the message.
Use consistent docstring style with rest of file? ``` """ Text """ ```
@timgraham It might be more appropriate in another commit then. I believe I wanted to make sure nothing was logged if a m2m backed inline was submitted without changes.
I've checked and `icontains` is not affected, we can remove this test. Sorry I should checked this first.
please include trailing comma in dictionary so if more items are added, we don't have to modify this line again
I think this test is sufficient, no need for the other one. Can you rename it to `test_delete_keep_parents()` though.
Relying on pk might be problematic since we shouldn't assume the values that the database might assign.
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
Maybe `client_servers` without a docstring.
```suggestion # Exception type raised by the underlying client library for a # nonexistent key. ```
```suggestion backend = self.base_params['BACKEND'] ```
prefer `request_hander = NoColorWSGIRequestHandler if no_color else WSGIRequestHandler` rather than duplicating more than what's necessary
Could we patch a StringIO instead of devnull and then verify the contents of log_message()? See tests/check_framework/tests.py for an example. Also the patching should be in setUp/tearDown or in a try/finally so if something goes wrong the unpatching still happens.
I wonder if the `isinstance()`condition results in any performance savings? I tend to think always casting might be simpler.
Similar to above, the `options =` could be outside the try block.
We should find a way to reduce the duplication between the two blocks. What about ```python form = 'int' if isinstance(value, int) else 'hex' try: return uuid.UUID(**{form: value}) except (AttributeError, ValueError): raise exceptions.ValidationError( self.error_messages['invalid'], code='invalid', params={'value': value}, )
Wouldn't be required if you subclasses `IntegerField`.
Oh, no, OK, the nextval will always return a different value. It's just that we might have gaps if one value is not saved.
We can reuse `Author` model. If we need two `CharField`s then we can add e.g. `alias` to the `Author`.
Add a trailing comma.
Please use single quotes.
Do we need to change `related_name` here? We could add `note` with `related_name='owner'` instead.
We usually avoid creating new models when we can reuse existing ones as it slowdown the test suite startup. In this case it looks like there's many candidate that could be reused here.
This should be display when `verbosity > 0`.
```suggestion if squashed_migrations_with_deleted_replaced_migrations: msg = ( " Pruning cannot take place until the following squashed " "migrations are recorded as applied (re-run 'manage.py migrate') " "and have their replaces attribute removed:" ) self.stdout.write(msg, self.style.NOTICE) for migration_to_warn in squashed_migrations_with_deleted_replaced_migrations: app, name = migration_to_warn self.stdout.write(f' {app}.{name}') else: to_prune = sorted(migration for migration in to_prune if migration[0] == app_label) if to_prune: for migration in to_prune: app, name = migration if self.verbosity > 0: self.stdout.write(f' Pruning {app}.{name}', ending='') executor.recorder.delete(app, name) if self.verbosity > 0: self.stdout.write(self.style.SUCCESS(' OK')) elif self.verbosity > 0: self.stdout.write(' No migrations to prune.') ```
I would add `OK`: ```suggestion executor.recorder.delete(app, name) self.stdout.write(self.style.SUCCESS(' OK')) ```
```suggestion squashed_migrations_with_deleted_replaced_migrations = [ migration_key for migration_key, migration_obj in executor.loader.replacements.items() if any(replaced in to_prune for replaced in migration_obj.replaces) ] ```
`--prune` is ignored when `--plan` is used. Maybe we should raise an error that they're mutually exclusive.
Please use a hanging indentation: ``` python self.assertEqual( set(...), {...}, ) ```
Is there a need to hardcode pks? This is generally to be avoided, I think.
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
Wrap lines closer to 79 characters and use () when referring to a function. ``` # get_current_site() will lookup a Site object, so these must match the # domains in the MockSite model. ```
I would use `%s` formatting consistently.
Make it a "private" method: `_initialize_signal_car` just to make it obvious it's not a test method.
I would turn this into a docstring.
This is not a functional change, it's just a simplification.
If I were writing these tests from scratch, I wouldn't use a separate `expected` variable everywhere (this is related to our preference for longer lines rather than a historical more strict adherence to 79 chars, I think).
Possibly. In general we've been moving toward `SimpleTestCase` but I don't know if requiring it is worth the effort.
Can you reference the ticket number in the docstring, please.
```suggestion self._clear_filename = temp_dir / "test" / "cleared.txt" self._clear_filename.parent.mkdir() ```
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
you can collapse, `with self.assertRaises(Exception), connection.cursor() as cursor:`, and in a few places below.
Use [hanging indent](https://docs.djangoproject.com/en/3.2/internals/contributing/writing-code/coding-style/#python-style): ```suggestion request = self.request_factory.get( '/', {'name__in': ",".join(escape_comma(e.name) for e in employees)}, ) ``` (But less than 120 chars it can go on one line.)
Yes only `BigInteger` breaks alphabetical order (in all backends), I don't want to break it more.
Maybe: ```python if internal_type in self.integer_field_ranges: return self.integer_field_ranges[internal_type] return self.integer_field_ranges[override.get(internal_type)] ```
I think we should add `SmallAutoField: (-99999, 99999)` to the `DatabaseOperations.integer_field_ranges` in the Oracle back-end.
This hook is unnecessary we can use the ternary.
This attribute does not exist if `isolation_level` has not been specified in `OPTIONS`, AFAICT
We should check if this statement works instead of returning `name` field, e.g. ```python def test_raw_sql_with_inherited_field(self): DepartmentStore.objects.create( name='Angus & Robinson', original_opening=datetime.date(2014, 3, 8), friday_night_closing=datetime.time(21), chain='Westfield', ) tests = ( ('name', 'Angus & Robinson'), ("case when name='Angus & Robinson' then chain else name end", 'Westfield'), ) for sql, expected_name in tests: with self.subTest(sql=sql): self.assertSequenceEqual( DepartmentStore.objects.annotate( title=RawSQL(sql, ()), ).values_list('title', flat=True), [expected_name], ) ```
`00` is not necessary, `friday_night_closing=datetime.time(21)`.
```suggestion authors, [25, 34, 35, 37, 45, 46, 57, 29], lambda a: a['age'] ```
Yes it was Ian, but my example used joined fields for an update which isn't (yet) allowed. How about something like: ``` Author.objects.update(alias=Greatest('name', 'goes_by') ``` Which will also test the handling of varchars in a Greatest.
using `Lower` seems more readable
Some checks require database access e.g. mysql.W002 ( https://docs.djangoproject.com/en/3.0/ref/checks/#database ) , django-mysql's checks ( https://django-mysql.readthedocs.io/en/latest/checks.html ). Those I've linked to don't strictly need access to an existing schema but I think changing this could be considered a breaking change.
> We could rewrite it so cloning happens after system checks are run If that's easy enough I think it's a good idea. It means that check errors will be displayed and stop the test process sooner, speeding up feedback.
I think you could write `self.program_options.append('-f')` here. This way you won't need to add a new parameter to `compile_messages`.
Rephrase: `# Normalize locale strings input by the user.`
This change is not tested and I'm not sure if it's excepted. I would focus on improving an error message.
Welcome to the wonderful world of `contenttypes` where clearing a GFK (even an optional one) actually deletes the objects.
Same as below, you should be able to call `self.using()` directly.
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
This exception message is different from that in `related.py` though the logic/intention surrounding it seems to be the same. Is this intentional? (FWIW, I find the message in `related.py` to be clearer)
I'd rather find out why we are getting the failure first. User can opt in for `self` to be a custom manager with the `__call__` syntax, doing `self.model._default_manager` bypasses it.
I've removed an extra newline that caused a flake8 error.
The benefit of the extra tests is they make the HTML structure clear, but the CSS selector perhaps does that... We should use hanging indent for the wrapping, so maybe pull the CSS selector into a variable, so it's easy read/see, and then the lines would be shorter too, and we can just have the two assertions.
```suggestion '<div class="fieldBox field-position hidden">' '<label class="inline">Position:</label>' '<div class="readonly">0</div></div>', ```
```suggestion '<tr class="row-form-errors"><td colspan="3">' '<ul class="errorlist nonfield"><li>A non-field error</li></ul></td></tr>', ```
```suggestion '<thead><tr><th class="original"></th>' '<th class="column-name required">Name</th>' '<th class="column-position required hidden">Position</th>' '<th>Delete?</th></tr></thead>', ```
`IS_DST_PASSED` is confusing, maybe `NOT_PROVIDED`.
`value` or `return_value`? or maybe we should swap these lines: ```python if ( not timezone._is_pytz_zone(current_timezone) and timezone._datetime_ambiguous_or_imaginary(value, current_timezone) ): raise ValueError('Ambiguous or non-existent time.') return timezone.make_aware(value, current_timezone) ``` :thinking:
Usually `__getattr__` is paired with `__dir__`, so that the lazy-loaded stuff is still exposed to `dir()`. My go-to implementation is: ```python def __dir__(): return sorted(list(globals()) + ["utc"]) ```
I'd be to test `is_dst=True` as well!
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
`Test passing` is unnecessary, IMO, maybe: ```suggestion # A token of length CSRF_SECRET_LENGTH. ```
```suggestion self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
```suggestion self.assertNotIn('CSRF_COOKIE', request.META) self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
`self.assertNotIn()` is preferred: ```suggestion self.assertNotIn('CSRF_COOKIE_NEEDS_UPDATE', request.META) ```
Move that below the `csrf_processing_done` -- we do not need to do extra work in that case.
Fair enough if there is precedence for it. I thought `ImproperlyConfigured` was usually used for settings or something affected by a setting being incorrect.
Not sure whether this is the right exception - should be `TypeError`.
`QuerySet` instead of `queryset` for all instances of it in this exception message.
Also rephrase to a single sentence to avoid mentioning `QuerySet` twice.
I'm not sure how much of an issue it is but this will be backward incompatible with `SingleObjectTemplateResponseMixin` subclasses that define a `model` attribute but don't have a `get_model()` method. There is no such class in Django's provided CBVs.
I'm not sure about the `backend` terminology here. I think naming this function `get_password_validators` would be more consistent with the rest of the the code.
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
please alphabetize with the rest of the django imports
`hasattr` is ugly because of its propensity to silently hide `AttributeError`, and because of its look-before-you-leap inefficiency. I would avoid it and instead use something like: ``` password_changed = getattr(validator, 'password_changed', lambda *a: None) password_changed(password, user) ```
repetitive with method docstring
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
has a -> is of a
prefer including a trailing comma in kwargs so if more items are added in the future we don't have to modify this line again
You could just do this: ```suggestion JOIN pg_namespace nsp ON nsp.oid = c.relnamespace AND nsp.nspname = current_schema() ```
Can we pass it in params? ```suggestion """, [self.index_name, table_name]) ```
```suggestion """, [self.index_default_access_method, table_name]) ```
I was confused why we have two different queries in `get_key_columns()` and `get_relations()` that return the same columns but in a different format, so I unified them in #11577. What do you think? it should make this change much simpler.
Is all of this necessary?, why not just: ```SQL JOIN pg_class c ON c.relname = kcu.table_name WHERE kcu.table_name = %s AND tc.constraint_type = 'FOREIGN KEY' AND pg_catalog.pg_table_is_visible(c.oid) ``` You don't need to add `pg_catalog.`
Better to rewrite docstrings in a separate commit.
As above, since `process_request()` returns a response, the second test isn't needed (see 434d309ef6dbecbfd2b322d3a1da78aa5cb05fa8).
Great, I just change this line to check the message in calls rather than simply its length.
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
This is the unauthenticated case yes? What's the story for the authenticated user? (Ah, I see the release note...)
Please test the entire message.
Unnecessary trailing comma and white space.
I would either use `self.assertTrue(Carrot.objects.filter(tags__tag='orange').exists())` or `self.assertEqual(Carrot.objects.get(tags__tag='orange'), bear)` but otherwise LGTM.
I would do what the other tests do and pass `test_labels` as a positional argument. Also, to be clearer what `foo` and `bar` are doing, it might be better to call them something like `notfound1` and `notfound2`. I'm assuming it's finding two failed test instances for labels not found. Alternatively, you could find real tests by passing something starting with `'test_runner_apps...'`.
Since `verbosity=1` is the default, you can leave this out. (It's good to be testing the default behavior.)
comparisons with `False`, `True`, and `None` should use `is` or `is not`, rather than `==` or `!=`
The nested if statements seem excessive. Could this whole thing just be simplified to the following: ```python def formfield(self, **kwargs): if self.choices: include_blank = not (self.has_default() or 'initial' in kwargs) defaults = {'choices': self.get_choices(include_blank=include_blank)} else: form_class = forms.NullBooleanField if self.null else forms.BooleanField # In HTML checkboxes, 'required' means "must be checked" which is different # from the choices case ("must select some value"). # required=False allows unchecked checkboxes. defaults = {'form_class': form_class, 'required': False} return super().formfield(**{**defaults, **kwargs}) ```
Use single quotes.
more than one automatically generated field.? sounds better and more natural with the changes.
no need for parens
This should use `assertEqual` and not `assertCountEqual`, otherwise there is no point in entirely recreating the expected warning, you could just hardcode 1 or 0.
This warning ID was not updated after copy-pasting it.
I think this test would make a little more sense if we used a `CharField` for the primary key of `Foo`. It's not super important though.
Fine. They're gone. 😀
Add the `@skipUnlessDBFeature('supports_table_check_constraints')` decorator.
`s/_managed/_unmanaged/` I think.
Might want to make this an `IntegerField` to avoid taking alteration to an incompatible type into account (e.g. uuid to int).
Can you also check for `questioner.ask_auto_now_add_addition` to be called 3 times, please or is this something we don't do in here but in commands.
Stick with single quote strings.
Could you add an `assetNumberMigrations` before the `assertOperationTypes` and join the `assertOperationAttribute` checks; they take `**kwargs`.
my preferred style is: "#17903 -- Inactive users shouldn't have permissions..."
First we should verify this passes before we toggle `is_active` to False.
Chop blank line.
You don't need to mock, it will return `False` for a bad file descriptor.
Use single lines for all these asserts -- we allow up to 119 characters when it improves readability.
Interesting. I just tried it. This returns 2. ``` def func(): try: return 1 finally: return 2 ```
Anyway, good practices include: - keeping the try clause as small as possible - avoiding multiple returns Hence the correct idiom is: ``` try: import autopep8 except ImportError: pass else: prepared_migration_statement = autopep8.fix_code(prepared_migration_statement, ...) return prepared_migration_statement ```
please move this to `except` and return `autopep8` result in `try`
Can you use hanging indents here: ``` python a = b( c, d=e, ) ```
Remove the parentheses, please.
Please revert whitespace change.
Wrap at 79 chars.
Ticket references are typically reserved for obscure issues that can't easily be described in the docstring. Not sure that's the case here.
```suggestion msg = ... with self.assertRaisesMessage(ValueError, msg): ```
Good. Super. Thank you!
I think you can use `with self.assertRaisesMessage` equivalently here (context manager form is much easier to read IMO)
This is redundant with an existing assertion, IMO we can drop it.
slightly prefer this style so lines don't have some non-multiple of 4 indent: ``` msg = ( "..." ) ```
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
I see your point and can't think of anything sensible either. Assertion-less tests just seem pointless other than to put a tick in the coverage box.
```suggestion def _is_default_auto_field_overridden(self): ```
I feel like this setting is out of context here. Should `AppConfig` only provide information in the context of an app? If I want to find out what kind of primary key a given app is asking for, I could look for `AppConfig.model_default_pk`, but if we're overriding if with a project setting it can cause some confusion.
`self.assertFalse()` -> `self.assertIs(..., False)` `self.assertTrue()` -> `self.assertIs(..., True)`
> Is SmallAutoField ever the right choice for a primary key field? Why not, it can be the right choice for any small dictionary tables if you really want to save space. I would even say that it's justified more often then `BigAutoField` :wink:
I wouldn't call `AutoField` a "legacy", we should also include `SmallAutoField`.
The closing ) goes on the next line.
I think something like the following (untested) code would do? ```python def __repr__(self): start = self.start - 1 stop = None if self.length is None else start + self.length subscript = slice(start, stop) return f'{self.__class__.__qualname__}({self.name!r}, {subscript!r})' ```
Perhaps it's an additional burden that can be deferred for another time, but IMHO it'd be _cool_ if the `__repr__` included either the subscript object or the final attributes it leads to (the latter would require it be `<SliceableF ...>` though, I guess). I only bring it up because you specifically asserted it though; it's by no means a requirement given there's already an _acceptable_ repr for it.
line too long
You need to wrap the second instantiation in its own assertRaises to actually test it.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
Don't think we need to worry about duplicates.
This will need to be updated to use argparse.
If we remove this will the tests run on Jenkins? It might be fine.
As long as you use `except Exception` and not a bare `except` this should be good.
Ahh, that's gonna be more interesting. You'd need to look at `self.migrations_module(x[0]) is not None` for whether there are migrations for that particular app or if they are disabled.
Furthermore, why do you construct `unapplied_parents` at all? Can't you just loop over `self.graph.node_map[migration].parents` and on raise an exception when the first one has an inconsistent history? That would safe some time in bigger projects. ``` python for x in self.graph.node_map[migration].parents: if x is unapplied # use the condition from above raise InconsistentMigrationHistory(...) ```
I don't think this is correct. `settings.MIGRATION_MODULES` only contains user-defined migration modules -- presumably want the detection to work regardless of whether or not that setting is defined.
"its" add period
use PEP 257 verb style "Check ... Raise .."
It would be fine to call the function with `None` since `r` isn't used. Again, use `self.settings` to verify that `settings.LANGUAGE_CODE` is returned.
I'm thinking it might be better to use the approach in `test_caches.py` rather than repeating the error message here twice.
You could also remove `self._supported_languages` in `__init__` (and OrderedDict import).
This is also wrong, `LANGUAGE_COOKIE_NAME` is the name of the cookie, not the name used in the session.
`settings.LANGUAGE_CODE` as you pointed out.
I think you can remove temporary `msg`, also dot is missing and probably `preceding` should be uppercased and `n` should be lowercased. ```python raise NotSupportedError( 'PostgreSQL does not support RANGE BETWEEN n PRECEDING AND n ' 'FOLLOWING.' ) ```
Isn't this equivalent? ``` if (start and start < 0) and (end and end > 0): raise ... ```
"start argument must be a negative integer, zero, or None, but got %s."
This `raise` seems redundant. I would remove these two lines (617-618) and leave only `raise ValueError(...)` at the end of this method.
Oracle restricts the number of parameters in a query.
You can reuse `resolve_model_field_relations()`.
Are you sure this branch is ever skipped? AFAIK `auto_created` models are not part `ProjectState.models` entries.
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
The 4 lines above look identical to the `remote_model_key` lines a few lines before, except with `through` instead of `remote_field.model`. Maybe that can be a helper method accepting that argument.
It looks like `update_model_field_relation()` is only called when `self._relations` is not `None`. Can you use `self._relations` here, then, instead? That would eliminate the uncertainty when reading of what code path is executing when the `relations` property is called.
I removed it.
You could also use `self.settings()` (it's a bit shorter) -- doesn't matter much though.
I think you can use `with self.assertRaisesMessage` equivalently here (context manager form is much easier to read IMO)
slightly prefer this style so lines don't have some non-multiple of 4 indent: ``` msg = ( "..." ) ```
, -> % (missing tests for this branch) same issue with InvalidTemplateLibrary raised below
How about more simply: "Found duplicate <field/base/manager> '%s' in CreateModel operation." Maybe you could create a helper function so we don't have to repeat a similar loop 3 times.
I think we want to crash here if `bases` is not iterable.
what if two mixins have the same name (from different packages)? hypothetically: `facebook.models.UserMixin` and `twitter.models.UserMixin`
, -> . (for consistency with same message in operations/models.py)
Use: ``` python raise ValueError( "Indexes passed to ModelState require a name attribute, " "%r doesn't have one." % index ) ``` While we allow longer lines, we typically break up long strings like this.
Follow existing style and don't include a blank line at the start of each test.
`obj=None` -> `obj`
You can reuse `CountryInlineAdmin` and `StateAdmin` instead of defining extra classes: ```suggestion ``` Add `get_formset_params()` to `StateAdmin`.
Chop blank line.
Please use single quotes.
Slightly simpler: ```suggestion passed_check = ( isinstance(settings.ALLOWED_HOSTS, (list, tuple)) and all(isinstance(element, str) for element in settings.ALLOWED_HOSTS) ) ``` `else False` reminds me of: https://adamj.eu/tech/2020/01/17/simplify-your-ifs-that-return-booleans/
I think we should check it's iterable AND not a string, there's always the possibility of other mistakes than the one that lead to the ticket, e.g. missing brackets on a function call
Since this is just a type check which should apply to all environments, not just production ones, it doesn't need the `deploy` flag
@coldmind With the current code, `passed_check` will be `True` if `settings.ALLOWED_HOSTS` IS empty. That is backwards. `passed_check` should be `True` if `settings.ALLOWED_HOSTS` is NOT empty.
`not statement` is used several times above, so need to be consistent in code style.
Is there a good reason to order the data like this? I'd personally expect the hash to be at the end, so it could include a `$` .
`self._test_scrypt_upgrade('parallelism', 'parallelism', 2)` fails, it seems we shouldn't take `parallelism` into account.
Is it possible for these asserts (and below) to fail without a bug in Django? If so, proper exceptions should be raised a la: https://code.djangoproject.com/ticket/32508
Yes, but these assertions can fail only for users with an incorrect hash in the database. IMO `assert`s can stay here, if you think otherwise we can discuss changing them in all hashers in ticket-32508.
> My main worry here is: Is this correct and does it make sense to implement for such a complex hasher (notably we already have others where we argue it is simply not possible in a sensible way). > > Since scrypt can raise errors like this: > > > ValueError: Invalid parameter combination for n, r, p, maxmem. > > I am wondering if `must_update` couldn't also trigger this condition. Or can we always calculate `extra_iterations` and `extra_block` and be sure that the combinations are valid? You're right parameters may no be valid, e.g. ``` self.work_factor = 2 **14 decoded['work_factor'] = 2 ** 11 ``` both are a power of 2, however `extra_iterations = 14336` is not and raises `ValueError: n must be a power of 2`.
I see what you mean - with tests being run so often it's only a matter of time. To resolve it we can call `random.seed(seed + i)` in the for loop before the string is created. And set `seed = 42`(or some other int) outside the loop. This way we'll have a set of known good random strings that aren't the same. Since if they are the same the zlib compression will detect the duplication and compress them efficiently, since the messages are stored in a single cookie which is processed all at once. BTW I tested with the initial `seed =42` and it passes the messages tests.
New PR #13800 with tests
(And round-tripping of the messages is already tested in other tests)
I guess we could remove the mention of Oracle and just say "for databases which limit..."
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
Use single quotes
I don't think it's important to mention PostgreSQL version details in the docstring.
Can you please run `pages_per_range` through `quote_value()` (internal function on the schema editor).
This should probably be the default for postgresql's `schema_editor.sql_create_index`.
I would assert `len(warns) == 1`.
Use `warnings.simplefilter('once')` in this case. There has been a lot of stuff moving around lately in the `Field` and `_meta` API andI just want to make sure the backward compatibility shim you added doesn't use deprecated stuff itself.
Verify the message as well, please.
A better approach might be to pass `'^%s$' % re.escape(expected_warning))` to `assertWarnsRegex` instead of manually escaping.
`# Prevent the RuntimeWarning subclass from appearing as an exception due to the warnings.simplefilter() in runtests.py.`
And a another alternative in #11642
Here's what I came up with https://github.com/django/django/pull/11641.
No, they are not supported, because `BOOLEAN` datatype is available only in PL/SQL on Oracle, so `SELECT` clause cannot return it.
You should use `1` instead of `True`, sorry for misleading. If you will use `True` as a param than it will be automatically converted into `1`.
That's what I thought. Thanks for the clarification 👍 The patch is fine to me 🚀
I see. Any thoughts about passing the _local_ field instead of the remote one and the model it's from? e.g. in the case of tests below `field_name` would be `'uuid'` instead of `'question_with_to_field'`. That's how the other `to_field` enabled admin views work and what `to_field_allowed` expects. It also feels like a nicer API to me and would allow you to stop passing `app_label` and `model_name`.
This can raise a `LookupError`
If I understood the above code correctly, then `self.field` is on the source model, whereas `self.model_admin` points to the target admin, I think we should really rename those to avoid confusion.
`getattr` will throw a `ValueError` if the `to_field` does not exist, this has to be handled.
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
This file is mostly for unit testing the `LogEntry` model, so I would limit the tests to `LogEntryManager.log_action()`. Similarly, could you try to unit test the `ModelAdmin` methods rather than having complete request/response tests? Maybe in `tests/modeladmin`. p.s. when sending or updating a pull request, please also update the ticket as I just did.
It should give 'Modification de Title et Historique.'. I guess a gettext call is missing inside the `LogEntry.get_change_message`.
`str(self.band)` doesn't seem like a realistic value for the message.
Will this statement will fit on a single line? (119 characters is permitted.)
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
Hi All, I was a little surprised to see a get_uneditable_fields method in addition to get_readonly_fields. I suppose that provides the best backward compatibility, though it was a little confusing on first glance to have _two_ methods with very similar names. I don't really have a better suggestion though. _Maybe_ a get_field_names() that handles the possibility of declared_fieldsets, and a can_edit() that checks add and change permissions. It makes the code more complicated, but it might be a little more intuitive. Just a thought.
please limit line length to 119 chars so horizontal scrolling isn't required to view the patch.
Minor rephrasing: `... and the user does not have permission ...` Also, typo: `exlcude` → `exclude`
Why `list(set(`? No tests seems to fail if I remove them.
This code ignores the value of `readonly_fields`. I noticed this because it breaks an inline with a field which is defined as a method in the inline itself (and, thus, needs to be in `readonly_fields`). I'm currently using this workaround (there might be a more clever way to solve it): ```python return [field.name for field in self.opts.local_fields] + \ [field.name for field in self.opts.local_many_to_many] + \ list(self.get_readonly_fields(request, obj)) ```
or "don't necessarily" -> "may not"
`skipUnlessAnyDBFeature` -> `skipUnlessDBFeature`
add trailing ,
Maybe you can use `subTest` here, e.g.: ```python for model, pk_pos in ( (Book, -1), # Unmanaged origin model. (Author, 0), # Unmanaged related model. ): with self.subTest(model=model, pk_pos=pk_pos): with mock.patch.object(model._meta, 'managed', False): _, _, grouping = queryset.query.get_compiler(using='default').pre_sql_setup() self.assertEqual(len(grouping), len(model._meta.fields) + 1) self.assertIn(Author._meta.pk.name, grouping[pk_pos][0]) for index, field in enumerate(model._meta.fields): self.assertIn(field.name, grouping[index + pk_pos + 1][0]) assert_queryset_results(queryset) ``` but I'm not convinced that it isn't less readable.
I think we can remove this docstring.
`# TODO: Remove when dropping support for PY37.`
A small oversight I noticed in an old Python 3.7.0 virtualenv: https://github.com/django/django/pull/13393
Grrr... I think I probably preferred the `if PY38` version then. (Let me confer with Mariusz.)
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
📖 I think we could add a docstring to this explaining why `__init__` was overridden. This and `CaseInsensitiveMapping.__init__` looks pretty similar
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
put the closing parenthesis on the next line
This and one above, replace `self.function = ..` with `function=...` in as_sql method call.
Remove `self.function = ..` and move it to a kwarg of the `as_sql` call below: ``` return super(Length, self).as_sql(compiler, connection, function='CHAR_LENGTH') ```
I think it would make sense.
What about erroring if `options` is non-empty at this point? Subclasses should have already consumed their arguments from it, and if there's anything left it's probably a mistake, like `explain(formatt='json')`
{0} -> {} (I prefer the less verbose %s, actually) recognised -> recognized
In the current implementation if ``supported_formats`` evaluates to ``False``, then there would be a trailing space at the end of the error message. Probably it would be better to remove it from this string and add it to the string below: ``` msg += ' Allowed formats: {0}'.format(', '.join(supported_formats)) ```
Is this condition necessary? Surely all backends will support a default `TEXT` format? (Even if it can't be explicitly provided in the query...)
`NotSupportedError`, and please use single-quotes, and add a dot at the end.
You could skip these, but I thought that the rewording read better. I guess if you go for the proposed `Renderable` then they'd be moved anyway and then it doesn't hurt to update them. (Also note that the docstring for `BaseFormSet.as_ul()` neglected to mention that it isn't wrapped in `<ul>`.) 🤷🏻‍♂️
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
```suggestion """Render as <p> elements.""" ```
Although this was changed to use `self._bound_items()`, it is still doing `self[name]` and `field` is unused. ```suggestion fields = [] hidden_fields = [] top_errors = self.non_field_errors().copy() for name, bf in self._bound_items(): bf_errors = self.error_class(bf.errors) if bf.is_hidden: if bf_errors: top_errors.extend( [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ) hidden_fields.append(bf) else: fields.append((bf, mark_safe(str(bf_errors)))) return { 'form': self, 'fields': fields, 'hidden_fields': hidden_fields, 'errors': top_errors, } ```
You can use the new `self._bound_items()` here, which is now in `main`.
with -> the
`msg = None` then only warn if msg is set.
version -> pickled_version `current_version = get_version()` (so we don't have to call it multiple times) check `if version:` first so we can skip `get_version()` if no version on pickled model.
Just state the expected behavior such as "Pickling a QuerySet with an `__in=inner_qs` lookup, shouldn't evaluate inner_qs." We're reserving ticket references for obscure issues that can't be easily described in docstrings (the above tests aren't a good example, unfortunately).
This is fine as-is. It is well known that iterating over a dictionary iterates over the keys. Also this is explicitly returning a `list` and not an iterator (as is the case with Python 3). Try out `type({}.keys())` to see the difference.
You also needs to "unmock" this method in a try/finally block. Maybe we can first decide on a resolution about using mock (#23289) so we don't have to add more of this cruft though.
yeah, i don't think instance patching requires cleanup, that instance goes away at the end of the test
this can be a single line (we prefer longer lines when it improves readability)
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
Also put `self.adduser` back in front of `self.changeuser`...
Also put `self.adduser` back in front of `self.changeuser`...
please create the list separately so as to limit line lengths to 119 chars. ``` logins = [ self.super_login, ... ] ```
Will this statement will fit on a single line? (119 characters is permitted.)
Remove ticket number. Capitalise first word of sentence.
This inner import is a syndrom of the circular dependency between `Manager` and `QuerySet`. Could we avoid it by moving this code inside `_Manager`? `Manager` would know how to create a subclass of itself with the methods of a given `QuerySet`.
This would be more readable as a one-liner: `predicate = inspect.isfunction if six.PY3 else inspect.ismethod`
Following your note on `_update` below -- keep the `queryset_only is None` part; otherwise you can't override the default to avoid copying private methods.
I think it's a better API; a custom manager could be using its name in a `__new__` method.
Might be nice to copy `__doc__` here as well
yeah, `request.session.get` would return none for the token and this wouldn't pass the comparision (which would be perfectly fine)
This throws a 500 if the token is not set!
You should fetch the arguments and url name from `request.resolver_match` here to ensure that we redirect to the same view, if someone hooks up `password_reset_confirm` with a different name you'd get an error here.
I think so, btw please do `resolver.kwargs.copy()` to leave the original kwargs in place on the resolver object.
```suggestion if 'uidb64' not in kwargs or 'token' not in kwargs: ```
Ah, well then we can use `@cached_property` 😉
Please move this inside the if.
I would like a test that fails if this is removed from the try block.
could this instead go before the try/except? ``` if isinstance(value, float): context = decimal.Context(prec=self.max_digits, rounding=decimal.getcontext().rounding) return context.create_decimal_from_float(value) ```
According to Django docs: > If present for the field subclass, from_db_value() will be called in all circumstances when the data is loaded from the database, including in aggregates and values() calls. > to_python() is called by deserialization and during the clean() method used from forms. https://docs.djangoproject.com/en/1.8/howto/custom-model-fields/#converting-values-to-python-objects [Here](https://github.com/django/django/blob/8047e3666b0b50bb04e6f16c2a4fb21ddfd5713f/django/contrib/gis/db/models/sql/conversion.py) you can look at from_db_value implementation
I'm not sure what you have in mind, but `django/contrib/admin/utils.py` doesn't contain any public APIs (and this code doesn't seem to be admin-specific). I think to make it a public API (e.g. in django.forms) we would want to see it used outside the admin.
This `except` block is never tested in the `formsets` case.
This seems incorrect -- we aren't using any data from the formset.
please revert whitespace addition
Extra wrapping and `str()` call are unnecessary: `… for city "%s".' % city`
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
Single quotes please.
We want to change whitespaces in the traceback, so we should test these changes e.g. ```python self.assertIn( ' File "generated", line 2, in funcName\n' ' <source code not available>', text, ) ```
```suggestion caller = f'{obj.__module__}.{caller}' ```
A docstring describing the purpose of this test may be useful.
You can't assume the presence of `self.name` here
The hexdigest will always be a fixed length so this only happens if the provided suffix is too long, correct? In that case, I think it would be better to raise an error that the provided suffix is too long.
It sounds like maybe index_type could be used as the suffix and this method doesn't need that argument. I guess the question is whether index_type should be limited to 3 characters or if truncating the first 3 characters of "index_type" as the suffix is okay.
I'm not sure if you intentionally reordered the kwargs. Maybe it makes sense to add a `*` in there to catch bugs in case code is passing kwargs as args.
Add trailing comma.
IMO we should check options against PostreSQL names.
We should make use of `self.message`.
Thanks for these tests, they look great!
@hannseman Thanks :+1: > I prefer it over the mixin approach. Yes me too :+1: . We can move `Value()` wrapping to the `__init__()` and simplify it a bit, e.g.: ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) if not (config and hasattr(config, 'resolve_expression')): config = Value(config) self.config = config def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save) resolved.config = self.config.resolve_expression(query, allow_joins, reuse, summarize, for_save) return resolved def as_sql(self, compiler, connection): sql, params = compiler.compile(self.config) return '%s::regconfig' % sql, params ``` Please move introducing a `SearchConfig` expression to the separate commit, or even PR.
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
You should use `fetch_redirect_response=False` instead of `target_status_code=404`. It seems to be an outdated pattern used in a few places and I'll probably clean it up soon.
We prefer hanging indent like this: ``` self.assertContains( response, '<div class="readonly">Multiline<br />html<br />content<br /> with allow tags</div>', html=True, ) ```
Is it correct that this `args` is different from the previous test? I'd expect the same test for both Python 2 and 3 with something like `self.assertEqual(response.status_code, 200 if six.PY3 else 404)` but maybe I missed something.
This change is unrelated. Reverted.
I guess the `LoggingCaptureMixin` addition isn't related to this patch? It could be added in a separate commit that explains it.
This isn't great and invites test state leakage - it's directly touching the internals of the code under test and not resetting it to the way it was after the tests. It would be best if a copy of `all_sites` was made and then in `tearDown` it was reset to the original state, at least Possibly fixed by #6980 anyway
We typically use an underscore prefix in a case like this: `self._previous_sites`
The lines below do not belong into the try block, since they don't raise the exception. ```python try: errors = checks.run_checks() else: expected = [] self.assertEqual(errors, expected) finally: admin.site.unregister(Book) admin.site.unregister(Author) ```
Yes, we'd need a separate test for check registration. Possibly https://github.com/django/django/pull/7781 will come up with a template to use.
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
```suggestion # LiveServerTestCase's change to ALLOWED_HOSTS should be reverted. ```
```suggestion cls.set_up_called = True ```
Will this statement will fit on a single line? (119 characters is permitted.)
`mutliple` -> `multiple`
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
Chop blank line.
I don't see much value in this assertion we should check `as_p()` and `errors`, e.g. ```python self.assertEqual(form.errors['json_field'], ['This field is required.']) self.assertIn('null</textarea>', form.as_p()) ```
We can leave an assertion for `value()`, but the two above assertions should also be added. It's not enough to check that `as_p()` is not `None`.
```suggestion form = PartiallyRequiredForm({'f_0': '', 'f_1': ''}) ```
It would be nice to be consistent about the ordering in `assertEqual` using it's `(variable, 'expected value')` but here and a couple other places it's opposite.
`__str__` is not necessary.
I added a temporary storage.
email_field_name -> email_address to make it more realistic
Chop blank line.
I think the suggestion is to maintain the "Invalid field name(s) for model ..." error message a property that doesn't have a `setter`.
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
And I would rename this attribute `superusers` as it's meant to contain multiple users.
use `reverse()` rather than a hard coded URL.
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
You can use `mock.atomic.assert_called_with(using=db)` here instead.
OK, it was just a shot in the dark :dart:
`self.assertIsNone(x.getlist('a'))` seems okay.
single line looks okay for this and the next test
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
I'm not sure we need to test implementation details of `MultiValueDict`. It seems like the following test should be enough ```python def test_empty_data_files_multivalue_dict(self): form = Person() self.assertIsInstance(form.data, MultiValueDict) self.assertIsInstance(form.files, MultiValueDict)
Hah. Had the same thought before I got here. See the caveats mentioned above.
Unlike `_sqlite_lpad()`, I'm not sure we can really improve this. `fill_text * length` is likely to be too long in most cases, and even worse if `fill_text` is multiple characters, but any alternative will probably be slower in general.
I'm not sure this is really worth it. Perhaps we can just add `step = list.append` to each of the four aggregates below and make them inherit from `list` directly? It might be clearer keeping `step` and `finalize` together, but I'm easy either way.
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
This one as well.
This could be a bare `super()`.
I noted this too and wasn't sure if it was an error or not. Can you 'save' an aggregate? ``` Model.objects.update(salary=Max('salary')) # would this work? ```
Try to reduce line length to make review easier.
This error no longer makes sense with multiple-arg aggregates. You'll either need to join the output of all source expressions so the error produces: > Cannot compute Sum(arg1, arg2): 'X' is an agggregate # (where X is either arg1 or arg2) Or you'll need a different error message for the case of `len(args) > 1`. There may be another solution (like ditching this message altogether) but I'll let you experiment with that if you like.
quit() .... to avoid a dead.... (chop "we" stuff)
Can you use `with self.assertRaisesMessage()` here instead of a bare try-except, please.
Correct, but if me change `ModelState` at some point, this will work automatically or fail, telling us we did something wrong ;)
Can you use `ModelState.from_model()` here, please, as this is what the migration framework will use internally.
Shouldn't mixins be to the left of the base class `models.Model`? This is my understanding of how mixins on class-based views work anyway.
I added a temporary storage.
You don't need `record` here.
Use single quotes.
Use single quotes.
We can remove `bases` from all `migrations.CreateModel()`.
I'd omit this blank line.
Just use `get_current_site()`.
Please rewrite `@override_settings` into a single line: ```python @override_settings(STATICFILES_DIRS="a string") ```
Probably the check functions should be called directly rather than invoking them through `run_checks()` (otherwise, this runs all registered checks across all installed apps which doesn't provide good isolation) -- see `tests/check_framework`.
I suggest you use the `hint` kwarg for the `'perhaps you forgot a trailing comma?'` part.
This test won't pass when pytz isn't installed. For consistency with the timezone tests, you should declare: ``` python requires_pytz = skipIf(pytz is None, "this test requires pytz") ``` and then decorate it with `@requires_pytz`. This is a minor concern since the docs now encourage installing all optional dependencies before running the test suite, but I suppose it could save some headaches to people running the test suite without a virtualenv. on or systems that don't have `time.tzset` (that is, Windows). Have
FWIW I didn't find pytz required, except on Windows, but I might have gotten lucky with my particular configuration.
Also `4x8.png` is left on the file system when the tests conclude.
Remove one of these blank lines (should only be two total). (`tests/file_storage/tests.py:454:1: E303 too many blank lines (3)`)
You don't need to mock, it will return `False` for a bad file descriptor.
You don't need `record` here.
I think that should be `hire_date` (two words).
Use single quotes.
Use single quotes.
We usually avoid creating new models when we can reuse existing ones as it slowdown the test suite startup. In this case it looks like there's many candidate that could be reused here.
Something like `test_header_omitted_for_no_to_recipients` may be more descriptive.
Please add a trailing comma.
I think you could use `self.assertSequenceEqual` rather than this.
Okay, I'll drop that point, however, it seems odd to me to reject an empty scheme even if someone specifies `schemes=['']` (which seems unlikely anyway). I don't know that rejecting this case is important.
Please drop that new line
No guarantees doesn't mean no efforts :-) However let others chime in and tell their opinion on this.
Sounds like there's no choice then? At least an additional note in 3.1.txt `Database backend API` section. (I've always imagined backend maintainers keep an eye on that for exactly this reason...)
I'm in favor of re-raising `subprocess.CalledProcessError` as a `CommandError`, e.g. ```python def handle(self, **options): connection = connections[options['database']] try: connection.client.runshell(options['parameters']) except OSError: # Note that we're assuming OSError means that the client program # isn't installed. There's a possibility OSError would be raised # for some other reason, in which case this error message would be # inaccurate. Still, this message catches the common case. raise CommandError( 'You appear not to have the %r program installed or on your path.' % connection.client.executable_name ) except subprocess.CalledProcessError as e: raise CommandError( '"%s" returned non-zero exit status %s.' % ( ' '.join(e.cmd), e.returncode), ) ``` which will end with: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: "psql -U djangoticket -h localhost -p 5432 djangoticket --asdasdad" returned non-zero exit status 1. ```
I wonder if we should suppress `subprocess.CalledProcessError` when arguments are not correct, to get e.g. ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. ``` instead of ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. Traceback (most recent call last): File "manage.py", line 22, in <module> main() File "manage.py", line 18, in main execute_from_command_line(sys.argv) File "django/django/core/management/__init__.py", line 401, in execute_from_command_line utility.execute() File "django/core/management/__init__.py", line 395, in execute self.fetch_command(subcommand).run_from_argv(self.argv) File "django/django/core/management/base.py", line 328, in run_from_argv self.execute(*args, **cmd_options) File "django/django/core/management/base.py", line 369, in execute output = self.handle(*args, **options) File "django/django/core/management/commands/dbshell.py", line 25, in handle connection.client.runshell(options['parameters']) File "django/django/db/backends/postgresql/client.py", line 55, in runshell self.runshell_db(self.connection.get_connection_params(), parameters) File "django/django/db/backends/postgresql/client.py", line 49, in runshell_db subprocess.run(args, check=True, env=subprocess_env) File "/usr/lib/python3.6/subprocess.py", line 438, in run output=stdout, stderr=stderr) subprocess.CalledProcessError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ``` We can also re-raise it as a `CommandError`: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ```
I think this is good, but wonder if we can also change to the following in `django.db.backends.postgresql.client.DatabaseClient.settings_to_cmd_args_env()`: ```python return args, (env or None) ``` This seems to fit with the expectation that `None` is returned when nothing is being added to the environment.
`msg = None` then only warn if msg is set.
with -> the
version -> pickled_version `current_version = get_version()` (so we don't have to call it multiple times) check `if version:` first so we can skip `get_version()` if no version on pickled model.
My concern with adding `copy()` is that it is adding in redundant work for most cases to appease a small subset of very specific use cases.
Just state the expected behavior such as "Pickling a QuerySet with an `__in=inner_qs` lookup, shouldn't evaluate inner_qs." We're reserving ticket references for obscure issues that can't be easily described in docstrings (the above tests aren't a good example, unfortunately).
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
Rather than passing all of `OPTIONS` here we should only pass the protocol: ```suggestion def __init__(self, protocol=None): self._protocol = pickle.HIGHEST_PROTOCOL if protocol is None else protocol def dumps(self, value): return pickle.dumps(value, self._protocol) ```
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
I would use a dict instead. ```suggestion self._pools = {} ``` and in `_get_connection_pool()`: ```python def _get_connection_pool(self, write): index = self._get_connection_pool_index(write) if index not in self._pools: self._pools[index] = self._pool_class.from_url( self._servers[index], **self._client_kwargs, ) return self._pools[index] ```
Chop blank line.
Remove this line as `opts` is already added by `ctx = Context(context)`.
Please remove the added blank line.
no need to reformat
Except the message displayed isn't quite right in this case: ``` The X "Great new X" was added successfully. You may edit it again below. ``` It's not true that it may be edited.
You can use the new `self._bound_items()` here, which is now in `main`.
`order_by` only needs to check for slice thus it can call this method like `check_queryset_method_allowed('order_by', combinator_check=False)`
The dict can be removed if this method is only called by those methods which have to make sure slice has not been taken or union, intersection, difference has not been applied. Then this method can be shorten to. ``` def check_queryset_method_allowed(self, action_to_msg, slice_check=True, combinator_check=True): if slice_check: assert not self.query.has_limit(), 'Cannot use %s ' % action_to_msg + 'once a slice has been taken' if combinator_check: assert not self.query.combinator==None , 'Cannot use %s ' % action_to_msg + 'once %s has been applied' % self.query.combinator ``` Now methods like _filter_or_exclude, count, extra etc will have to just call this method to make sure they can execute. As we only have restrictions on query combinators (union, intersection and difference) and slice, the two keyword arguments are passed to this method.
I'd drop the list comprehension, `sorted` accepts a generator.
Yes, because it can also be "truthy" by containing a list of fields. True means all fields. FWIW I also tested `objects.values().annotate().exists()` and that was fine before and after this patch.
I don't like how a mistyped action will pass silently.
The last parenthesis should be moved to the next line due to hanging indentation.
The last parenthesis should be moved to the next line due to hanging indentation.
I don't think we need to check all rows, probably sth like this: ```python self.assertEqual(list(qs.values_list('lead_default', flat=True).distinct()), [60000]) ``` will be sufficient. We have a similar situation in the `test_nth_returns_null`.
It's weird, because Oracle interprets empty strings as nulls.
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
How about more simply: "Found duplicate <field/base/manager> '%s' in CreateModel operation." Maybe you could create a helper function so we don't have to repeat a similar loop 3 times.
I think we want to crash here if `bases` is not iterable.
names -> name
what if two mixins have the same name (from different packages)? hypothetically: `facebook.models.UserMixin` and `twitter.models.UserMixin`
Use: ``` python raise ValueError( "Indexes passed to ModelState require a name attribute, " "%r doesn't have one." % index ) ``` While we allow longer lines, we typically break up long strings like this.
I'm not sure that it makes any sense checking the registry. There is no guarantee that you are using a terminal that uses this. So it could just result in a blanket "on" if this is set. It would be better to take the `ctypes` approach mentioned to check whether currently enabled for the actual terminal in use.
```suggestion reg_key_value, _ = winreg.QueryValueEx(reg_key, 'VirtualTerminalLevel') ```
It is also "Windows Terminal", not "Microsoft Terminal".
`Determines` -> `Determine` `will support` -> `supports` This docstring can be single-lined.
Do we really need this inner function? We could just shortcut out early if not a TTY.
Reading below, I see that Flask has an "any" converter that does something more complicated. Creating a converter with the same name but a different behavior doesn't sound good.
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
Use `assertEqual()`, e.g. ```python self.assertEqual( conf_url(r'^regex/(?P<pk>[0-9]+)/$', empty_view, name='regex'), re_path(r'^regex/(?P<pk>[0-9]+)/$', empty_view, name='regex'), ) ```
TBH, I don't think we need this test. I will chop it.
I don't think we need to have a strict policy on `/` vs. `.joinpath()`. I'd prefer `/` but when readability hurts we can also use `.joinpath()` :shrug:
There's no need to define the extra `settings_dir` variable as `pathlib` gives us more flexibility: ```suggestion settings_file_path = self.test_dir / filename / "__init__.py" settings_file_path.parent.mkdir() ```
```suggestion self.temp_app_path.joinpath("__init__.py").touch() ```
```suggestion self.assertTrue(tmpdir.joinpath("1").is_file()) self.assertTrue(tmpdir.joinpath("2").is_file()) self.assertTrue(tmpdir.joinpath("foo", "1").is_file()) self.assertTrue(tmpdir.joinpath("foo", "2").is_file()) self.assertTrue(tmpdir.joinpath("foo", "bar", "1").is_file()) self.assertTrue(tmpdir.joinpath("foo", "bar", "2").is_file()) ```
```python msg = 'Script does-not-exist does not exist.' with self.assertRaisesMessage(RuntimeError, msg): ```
Oh, of course, sorry. Totally missed the loop somehow. Ignore this, I think it's fine as-is.
Use hanging indentation: ```suggestion raise exceptions.FieldError( "Cannot compute %s('%s'): '%s' is an aggregate" % (annotation.name, name, name) ) ```
```suggestion if expr.contains_aggregate and isinstance(expr, Ref) and expr.refs in kwargs: ```
To match `django.db.models.sql.compiler` behavior, as_sql() should probably be replaced by `self.compile(annotation)`.
not aggregate is tested twice
We need to `run_formatters()` on new files, see d113b5a837f726d1c638d76c4e88445e6cd59fd5.
```suggestion sys.exit(1) ```
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
I prefer the following one rather than the above one ```py def greet(): condition = False if condition: return "Hi" return "Hello" ``` Feel free whether follow the things I point out.
That's not true, `return` is to avoid setting new migrations.
Do we need to check `removal_value`? It should be enough to check that `new_value` is not en empty set, I cannot imagine a different scenario :thinking: ```suggestion if new_value: ```
I'd keep this on one line for better readability
This could be made more DRY: ```python for option in ('unique_together', 'index_together'): ... ```
use dict comprehension: `{op: set() for op in ops}` (although maybe you could use defaultdict too)
dependency graph (no dash) I think you mean "intra-app" rather than "in-app"
`pos_list` could be changed to be a generator now that it is only unpacked into `itemgetter`: ```diff -pos_list = [row_pos for _, _, row_pos in reorder_map] -self.reorder_for_init = operator.itemgetter(*pos_list) +self.reorder_for_init = operator.itemgetter(*(v[2] for v in reorder_map)) ```
It looks okay to me to do in the same commit.
`annotations` is spelled incorrectly here.
I'm not a fan of aliasing builtin names.
I meant changing the signature of `apply_converters()` to: ``` @staticmethod def apply_converters(self, connection, rows, converters): ``` I guess that change doesn't make much sense given `apply_converters()` is called in some other places.
Are you sure? Should this not be consistent with `SHORT_DATETIME_FORMAT`, i.e. `SHORT_DATE_FORMAT = 'j N Y'`.
My pleasure :)
@sdil Can you take a look? Thanks!
@sdil Thanks for checking :+1:
In Thailand it’s customary to use the [Thai solar calendar](https://en.wikipedia.org/wiki/Thai_solar_calendar) system (as it’s the official legal calendar in Thailand). Dates and months are the same as the common Gregorian Calendar, but years are in Buddhist Era instead of the Christian/Common Era. Just add 543 to the year number when displaying, and subtract 543 from the year number when parsing.
It would probably be less confusing if this were `dict(greeting='Hello!')` so we don't have so many parts called "extra_email_context".
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
I'm surprised if `str()` is doing something here since `capfirst()` also has some `str()` calls.
@pahko `2` , `3` and non-empty lists and objects also will be valid case. Only check for boolean is needed here.
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
Please use single quotes consistently in new code.
Ahh didn't notice that. I just remembered a recent commit that converted many of those to literals.
You could use a set literal here.
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
You can safely join this an the next line. You have up to 119 chars per line. ;)
Use double quote docstrtings.
I'd use `return a if b else c` but it's up to you.
`get_table_collation()` is missing for Oracle, I added it to the main query.
Prefer a set (or tuple) to list for containment check.
I would consider tuple unpacking in the line before: `constraint_table, constraint_column = constraint['foreign_key']`.
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
I think there's also a word missing here: "will **be** truncated".
I think I would define the additional parameters as keyword parameter, as in `__call__ `. BTW, thanks for fixing this thread issue I created!
docstring with example input/output would be really helpful
Please add a trailing comma.
I think you could use `self.assertSequenceEqual` rather than this.
Collapse this decorator into a single line.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
These two permissions are never used. Please remove them. `cls.permissionuser` is only used in `test_simple_inline_permissions`. Create it inline there rather than on the class.
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
I wouldn't include this test in the PR because it's testing existing behavior. But it doesn't seem needed as there's a test in `test_client_regress` that fails if the `isinstance(data, dict)` check is `_encode_json` is removed.
argument -> a GET parameter
We avoid backslashes and use this style: ``` msg = ( "Redirection loop for authenticated user detected. Check that " "...." ) ```
I'm not sure why we pass `data` and build a query string in tests views :thinking: I would simplify this: ```python def test_follow_307_and_308_no_get_preserves_query_string(self): methods = ('post', 'head', 'options', 'put', 'patch', 'delete', 'trace') codes = (307, 308) for method, code in itertools.product(methods, codes): with self.subTest(method=method, code=code): req_method = getattr(self.client, method) response = req_method('/redirect_query_%s/' % code, follow=True) self.assertRedirects(response, '/post_view/?hello=world', status_code=code) ``` and in `views.py`: ```python def method_saving_307_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=307) def method_saving_308_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=308) ``` Maybe I'm missing sth.
Same as below, I think I'd prefer a loop that breaks early.
What about: ```py for secret in self.secrets: if constant_time_compare(self._make_token_with_timestamp(user, ts, secret), token): break else: return False ``` EDIT: f'uped the indendation. First time I think I am using for … else
While we're here... `token that is invalidated`
It might be smarter to validate the token first and only modify the session + redirect if it's valid. Otherwise it makes it really easy to create a session just by GET'ing a url (possible DoS vector). It also means you can't pass `accounts/password_reset` as the token and take advantage of our `request.path.replace()` code. It probably means validating the token twice, which is slightly slower. Seems fine to me if an invalid token gets leaked.
@romgar If you find the time that would be great!
This isn't related to your changes, but I'm intrigued by Django's behavior here. I would expect `|escape` to give `&amp;` and `|escape|force_escape` to give `&amp;amp;`. Not that this construct makes much sense anyway...
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
I don't think you should re-number the existing tests.
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
I renamed the test and removed the docstring.
Use `self.assertIs(wrapper.is_hidden, True)` since assertTrue passes for bool(value) is True.
Chop blank line.
I'd use single quotes throughout.
What about `prefetch_related()`? It's a new method so we should raise `ValueError` when `aiterator()` is used after `prefetch_related()`, e.g. ```python async def aiterator(self, chunk_size=2000): if chunk_size is None: if self._prefetch_related_lookups: raise ValueError( "chunk_size must be provided when using QuerySet.iterator() after " "prefetch_related()." ) elif chunk_size <= 0: .... ```
Citing @holvianssi on Trac. > The complex solution is to add both the opt-in flag and database settings. The default for the opt-in flag is None, meaning use the default from database settings. True forces this feature on, and False forces the feature off.
Shouldn't this be along the lines of ```python def iterator(self, chunked_fetch=None): if chunked_fetch is None: chunked_fetch = connections[self.db].settings_dict.get('ENABLE_SERVER_SIDE_CURSORS', True) return iter(self._iterable_class(self, chunked_fetch=chunked_fetch)) ```
> We'll want to do something with regards to the newly added support for iterator's prefetch_related here. That looks like a _moderate_ task in itself (to implement) — `islice`, `prefetch_related_objects`, ... — it might be that adjusting the PR here match the new interface, but emitting a warning if prefetches are set would let us get this in, to work on async prefetches later. (Would be equivalent to the sync behaviour before edbf930287cb72e9afab1f7208c24b1146b0c4ec — of _either prefetch or iterator_.) 🤔
```python async with contextlib.aclosing(aiter(self._iterable_class(...))) as agen: async for item in agen: yield item ``` You should explicitly aclose your async generators when you create them: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators
simpler: "must be a string"
Yes, I think Django would be obviously broken in such a configuration anyway.
I don't think there's a use case for `settings.AUTHENTICATION_BACKENDS` without any backends that have a `get_user()` method.
I'd suggest something like: ``` 'You have multiple authentication backends configured; ' 'you must provide the `backend` argument or set the `backend` ' 'attribute on the user.' ``` You can omit the plus sign.
I'd revert this as I don't think it is better and it isn't making this more consistent with code elsewhere. ```suggestion if isinstance(stored_backend, RemoteUserBackend): ```
How about more simply: "Found duplicate <field/base/manager> '%s' in CreateModel operation." Maybe you could create a helper function so we don't have to repeat a similar loop 3 times.
I think we want to crash here if `bases` is not iterable.
names -> name
what if two mixins have the same name (from different packages)? hypothetically: `facebook.models.UserMixin` and `twitter.models.UserMixin`
Use: ``` python raise ValueError( "Indexes passed to ModelState require a name attribute, " "%r doesn't have one." % index ) ``` While we allow longer lines, we typically break up long strings like this.
Please use the helper methods `self.assertOperationType()` et. al.
`s/_managed/_unmanaged/` I think.
Could you add a check for `options` here the same way as below.
Can you also check for `questioner.ask_auto_now_add_addition` to be called 3 times, please or is this something we don't do in here but in commands.
Could you add an `assetNumberMigrations` before the `assertOperationTypes` and join the `assertOperationAttribute` checks; they take `**kwargs`.
Same here? ```suggestion __T = r'(?P<hour>[01][0-9]|2[0-3]):(?P<min>[0-5][0-9]):(?P<sec>[0-5][0-9])' ``` Maybe this is a bad idea because of leap seconds 🤷🏻‍♂️
TIL that character classes also work inside `[]` :D
I think we should be consistent and use double-quotes.
We can also import `include()` from `django.urls` instead of `django.conf.urls`.
I think you can safely remove this.
I think this category can be dropped
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
I try to avoid "we", e.g. The check allows a double slash, presuming the user knows....
Could you a docstring along the lines of `test_file_url()`, please :smile:
I'm in two minds on this. On one hand, yes, @carltongibson is right. On the other hand, a lot of this code treats `CSRF_USE_SESSIONS` as an afterthought (which, historically, it is, but...). Maybe this way is more consistent with the rest, and changing the not-necessarily-correct references to cookies (e.g. `request.META['CSRF_COOKIE']`) into something more befitting the dual use should be the subject of a separate refactoring, if we want it. Perhaps when we remove the distinction between the cookie/token and the secret, we should rename this to `_set_secret()`. Perhaps a good name now is `_set_masked_secret()`. Not sure. Whatever choice is picked here, should also apply to `_add_new_csrf_cookie()` above.
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
Again single quotes
Use single quotes to stay consistent with the code above.
add trailing comma
`all(f.name != db_field for f in fields)` (not sure if it's bettter/worse than the current version)
I'd change that to `found_add_field_migration`
... and change this to `return (found_create_model_migration or found_add_field_migration), after_state`
I'd rename that to `found_create_model_migration`
I think we need to ignore models with `managed=False` or `proxy=True` here as they never receive any database level operations anyways.
IMO, `%r` might be an improvement (to avoid quoting integers) except for the `u''` prefix that would be added for strings on Python 2...
`"""` -> `'`
Wrap lines closer to 79 characters and use () when referring to a function. ``` # get_current_site() will lookup a Site object, so these must match the # domains in the MockSite model. ```
``` When the object has a ManyToManyField to Site, redirect to the current site only if it's attached to the object.
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
Please use single quotes throughout the patch except if the string contains a single quote.
Yes, for new code we're trying to follow the [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
In the usual case for using this, it wouldn't be because "an initial migration has been applied before,", it'd be because the database pre-existed any (Django) migrations at all. Also, it's really the contents of your initial migration file that you need to compare to, not your model definitions. Suggested wording: "Detect if tables already exist and fake-apply initial migrations if so. Make sure that the current database schema matches your initial migration before using this flag!" As a bonus, this also hints at the fact that the automated check here is no more sophisticated than just checking if tables exist.
I think you could write `self.program_options.append('-f')` here. This way you won't need to add a new parameter to `compile_messages`.
> .... that is not `many_to_one` or `many_to_one`. A `BooleanField`. I think there are a few typos in the sentence above. It's hard for me to understand what you meant. It seems to be a separate issue that can be fixed and tested separately. As for the test it should be enough to pass `first_name` in the command line in a test similar to the `test_validate_password_against_required_fields`.
This should be: ```python try: cursor.execute('SET standard_conforming_strings TO ON;') ... finally: cursor.execute('...') ``` so that if the assertion fails, the "tear down" in finally still happens. The second query shouldn't assume the original value of standard_conforming_strings is "on".
) goes on the next line as in other tests
Chop blank line.
Docstrings should state the expected behavior and omit prefixes like "Make sure" since all tests make sure of things.
suggested wording: "SystemExit is raised if the user answers "no" to the prompt asking if it's okay to delete the test tablespace."
I would put "decode" into quotes or so (@felixxm can certainly tell us what the proper syntax is)
This warning text could include `type(self).__name__` to provide a bit of additional guidance.
IMO, we should use `self.decode` here.
Mhm that is what I was trying to avoid, because for most hasher a salt length is just that and `must_update` should easily be able to handle that globally if it is returned from `decode`. What this PR certainly misses (and what will show you the existing problems) is a test for the behavior of the `bcrypt` hasher. I think now it's `must_update` will *always* return `True` and set a salt *every* time.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
This test belongs with the tests for the delete action in `tests/admin_views/test_actions.py`.
I don't think this test is needed. The default implementation is already tested as well as overriding the method.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
put this tuple on a single line
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
OK then, thanks for the references.
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
In Thailand it’s customary to use the [Thai solar calendar](https://en.wikipedia.org/wiki/Thai_solar_calendar) system (as it’s the official legal calendar in Thailand). Dates and months are the same as the common Gregorian Calendar, but years are in Buddhist Era instead of the Christian/Common Era. Just add 543 to the year number when displaying, and subtract 543 from the year number when parsing.
I would rename `self.model_name` -> `self.name` (like in `CreateModel`, `DeleteModel`, or `RenameModel`).
The previous return value was `not operation.references_field` which meant 1. `not True -> False`, if the operation refers to the field block optimizations through. 2. `not False -> True`, if the operation doesn't refer to the field allow optimizations through. You proposed change makes it the other way around.
I think the _through_ test failure has more to do with how `RemoveField.references_field` deals with through. For example, not saying this is the right solution here, but the following diff happens to make the tests pass as well ```diff diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py index 41c389f79f..d6cbd6b9c6 100644 --- a/django/db/migrations/operations/fields.py +++ b/django/db/migrations/operations/fields.py @@ -36,7 +36,7 @@ class FieldOperation(Operation): return field_references_model(self.field, ModelTuple(app_label, name_lower)) return False - def references_field(self, model_name, name, app_label=None): + def references_field(self, model_name, name, app_label=None, reference_through=True): model_name_lower = model_name.lower() # Check if this operation locally references the field. if model_name_lower == self.model_name_lower: @@ -53,11 +53,12 @@ class FieldOperation(Operation): (not hasattr(self.field, 'to_fields') or name in self.field.to_fields or None in self.field.to_fields)): return True - through = getattr(remote_field, 'through', None) - if (through and ModelTuple.from_model(through) == model_tuple and - (getattr(remote_field, 'through_fields', None) is None or - name in remote_field.through_fields)): - return True + if reference_through: + through = getattr(remote_field, 'through', None) + if (through and ModelTuple.from_model(through) == model_tuple and + (getattr(remote_field, 'through_fields', None) is None or + name in remote_field.through_fields)): + return True return False def reduce(self, operation, app_label=None): @@ -186,6 +187,11 @@ class RemoveField(FieldOperation): def describe(self): return "Remove field %s from %s" % (self.name, self.model_name) + def references_field(self, model_name, name, app_label=None): + return super().references_field( + model_name, name, app_label=app_label, reference_through=False + ) + def reduce(self, operation, app_label=None): from .models import DeleteModel if isinstance(operation, DeleteModel): ```
should this be super()
What about ```python def can_reduce_through(self, operation, app_label): return not operation.references_model(self.name, app_label) def reduce(self, operation, app_label): return ( super().reduce(operation, app_label) or self.can_reduce_through(self, operation, app_label) ) ```
Don't think we need to repeat the docstrings from individual methods.
This docstring isn't necessary as the method name is should be clear enough. ```suggestion ```
From looking at the code the call could differ from Python 2 to 3 and is really an implementation detail which is not worth testing after all. My initial reflexion was more about the fact `assert_not_called()` was used below instead of `self.assertFalse(ref.called)` but now I realize there's no `assert_called()` method. LGTM
I'd use `ref.assert_called_once_with()` here.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
override `__init__()` instead. after `super()` then `self.style = no_style()`
I think you should use `six` to support both Python 2 and Python 3. ``` py from django.utils.six.moves import xrange ```
prefer `request_hander = NoColorWSGIRequestHandler if no_color else WSGIRequestHandler` rather than duplicating more than what's necessary
This crashes: ``` Complete output from command python setup.py egg_info: Traceback (most recent call last): File "<string>", line 1, in <module> File "/tmp/pip-K04os1-build/setup.py", line 36, in <module> """.format('.'.join(REQUIRED_PYTHON), '.'.join(HAS_PYTHON))) TypeError: sequence item 0: expected string, int found ```
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
```suggestion self.temp_app_path.joinpath("__init__.py").touch() ```
```suggestion self._clear_filename = temp_dir / "test" / "cleared.txt" self._clear_filename.parent.mkdir() ```
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
You can pass `verbosity=0` instead to completely silence the command instead of creating an unused `StringIO` container.
```suggestion self.assertIs(app_dir.joinpath("apps.py").exists(), True) ```
Here's the style we usually use for long messages: ``` msg = ( '....' '....' ) with self.assertRaisesMessage(ImproperlyConfigured, msg): ```
are the Meta classes necessary? the test fails and passes before and after the fix without them
`self.assertFalse()` -> `self.assertIs(..., False)` `self.assertTrue()` -> `self.assertIs(..., True)`
I don't think you need `list()` here.
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
Catching `AttributeError` like this may mask errors raised from inside `as_sql()` and make debugging difficult. I'd suggest: ```suggestion elif hasattr(node, "as_sql"): sql, params = node.as_sql(self, self.connection) else: sql, params = None, (node,) ```
```suggestion squashed_migrations_with_deleted_replaced_migrations = [ migration_key for migration_key, migration_obj in executor.loader.replacements.items() if any(replaced in to_prune for replaced in migration_obj.replaces) ] ```
We expect compileable to always have an `as_sql` method. e.g. see `effective_default`'s implementation. ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) return compiler.compile(node) ```
Can you issue a `RuntimeWarning` here telling the user that Django falls back and it might be time to clean up using `squashmigrations` and link to https://docs.djangoproject.com/en/dev/topics/migrations/#squashing-migrations.
I think it's a bit neater to invert the check for `node.as_sql` and return early: ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) sql, params = compiler.compile(node) return sql, tuple(params) ```
```python self.assertHTMLEqual( field.widget.render('name', []), ( '<ul>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="entertainment">Entertainment</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="test">A test</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="third-test">Third</label></li>' '</ul>' ) % (self.c1.pk, self.c2.pk, self.c3.pk), ) ```
```suggestion form.render(), '<div><fieldset><legend>Field:</legend><div id="id_field">' '<div><label for="id_field_0"><input type="checkbox" ' 'name="field" value="J" id="id_field_0"> John</label></div>' '<div><label for="id_field_1"><input type="checkbox" ' 'name="field" value="P" id="id_field_1">Paul</label></div>' '<div><label for="id_field_2"><input type="checkbox" ' 'name="field" value="G" id="id_field_2"> George</label></div>' '<div><label for="id_field_3"><input type="checkbox" ' 'name="field" value="R" id="id_field_3">' "Ringo</label></div></div></fieldset></div>", ```
```suggestion form.render(), '<div><label for="id_field">Field:</label>' '<input id="id_field" name="field" required type="checkbox"></div>', ```
The expected value should be a second argument in `assertEqual()` and `assertHTMLEqual()` assertions.
```suggestion '<div class="fieldBox field-position hidden">' '<label class="inline">Position:</label>' '<div class="readonly">1</div></div>', ```
I don't think there's a use case for `settings.AUTHENTICATION_BACKENDS` without any backends that have a `get_user()` method.
Yes, I think Django would be obviously broken in such a configuration anyway.
It is more generic than shortcircuting the `is_active` flag, isn't it? It logs in the given user.
You should be able to pass `is_active=False` to `create_user()`.
reword: "force_login() skips authentication backends without a get_user() method."
Add trailing commas in call_commands.
Use single quotes where possible.
I think we are missing the `call_command()` here.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
Please add trailing comma.
Please add trailing comma.
Single quotes, trailing dot.
undo unrelated change here (revert the comma)
It would be clearer to the end-user if the help was "Shows output from passing tests."
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Unlike `_sqlite_lpad()`, I'm not sure we can really improve this. `fill_text * length` is likely to be too long in most cases, and even worse if `fill_text` is multiple characters, but any alternative will probably be slower in general.
Hah. Had the same thought before I got here. See the caveats mentioned above.
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
I don't think we need the `re_` prefix to the arguments? And perhaps `text` instead of `string` for consistency? We should also avoid coercing to `str` unless we need to: ```python In [1]: text = "This is some text" In [2]: %timeit str(text) 54.7 ns ± 4.28 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) In [3]: %timeit isinstance(text, str) 33.8 ns ± 0.106 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) ``` It might make the non-`str` case slower, but, unless I'm mistaken, we're expecting `text` to be `str` in the majority of cases. ```suggestion def _sqlite_regexp(pattern, text): if pattern is None or text is None: return None if not isinstance(text, str): text = str(text) return bool(re_search(pattern, text)) ``` As an aside, I wonder whether we can do something to compile and cache patterns? This could make a significant difference if the function is called for a large number of rows.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
`UniqueConstraint` not `Index`.
I remember looking at this test when merging 233c70f0479beb3bff9027e6cff680882978fd4d. I just tested this now and if you use `with register_lookup(field, Exactly, lookup_name='exact'):`, then this is the state at the end of the test: ``` >>> Author._meta.get_field('birthdate').get_lookup('exact') <class 'custom_lookups.tests.Exactly'> ``` With the current code, the output is `<class 'django.db.models.lookups.Exact'>` which looks correct to me. So I'd leave this as is and remove the unused `CustomExactLookup`.
Hmm it's not clear to me what this test is trying to accomplish, what's the purpose of `CustomExactLookup` in the first place since it's `Exactly` that is registered.
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
I'd omit the blank line since it's hard to get confused in 3 lines of code. Also the commit message could describe the issue being fixed instead of the implementation of the fix.
I'd prefer to keep the docstring consistent with those in the rest of the file (which don't have the extra line).
I think we should revert this change (we reverted similar change in `django.core.cache.backends.basedefault_key_func()` in the past) because it will create a regression for non string values. The following example works in the current master: ``` >>> Signer('some_key').sign(1) '1:gJ9gvYHWvcR2rrXTSANB5b-IhU8' ``` but with this change it raises `TypeError`: ``` File "django/django/core/signing.py", line 162, in sign return self.sep.join([value, 'sha1', self.signature(value)]) TypeError: sequence item 0: expected str instance, int found ```
Why not do: ``` if key not in self: self[key] = value ```
Please don't make unrelated whitespace changes.
```suggestion def loads( s, key=None, salt='django.core.signing', serializer=JSONSerializer, max_age=None, fallback_keys=None, ): ```
As far as I'm concerned this should impact only `307` and `308` redirects, so maybe: ```diff diff --git a/django/test/client.py b/django/test/client.py index b26504f762..e4201bead4 100644 --- a/django/test/client.py +++ b/django/test/client.py @@ -827,7 +827,10 @@ class Client(ClientMixin, RequestFactory): if response.status_code in (HTTPStatus.TEMPORARY_REDIRECT, HTTPStatus.PERMANENT_REDIRECT): # Preserve request method post-redirect for 307/308 responses. - request_method = getattr(self, response.request['REQUEST_METHOD'].lower()) + request_method = response.request['REQUEST_METHOD'].lower() + if request_method != 'get': + extra['QUERY_STRING'] = url.query + request_method = getattr(self, request_method) else: request_method = self.get data = QueryDict(url.query) ```
It's a small detail, but I think the variable naming could be improved here. `request_method` and `req_method` are very similar names (one is just a shortening of the other) but they mean very different things. I might rename `request_method` to `req_method_name` or something. Or you could probably just turn this into a single line and avoid a temporary variable.
Chop blank lines.
It is not the status code that needs to preserve the request method. Perhaps the following reads better: `# Preserve request method post-redirect for 307 and 308 responses.`
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
In such case we will need to calculate this multiple times because it is inside a loop. Moreover `if` is for a deprecated usage, so ...
> 1. we don't process a model which is processed already. I restored this. > 2. we don't process extra model when we find the `alias` in the join column names. Yes, but we're doing this multiple times (for each model), so :heavy_plus_sign: / :heavy_minus_sign: . I believe it's better to pre-calculate. > 3. we don't need to process model if `allow_aliases = False` Right, we can optimize this.
Please do not assume a model only inherits from `django.db.models.Model` I inherit from standard python classes as well. Add check for `issubclass(model, django.db.models.Model)`.
```suggestion self.resolve_model_field_relations(model_key, name, old_field) ```
could switch to single quotes for consistency
You should be able to reuse an existing model, e.g. `Number`.
We can drop this model and reuse `PeopleMoreData`, e.g. ```python class ForeignKeyToField(models.Model): to_field_fk = models.ForeignKey(PeopleMoreData, models.CASCADE, to_field='people_unique') ```
Just had to move `field.check()` to the mocked context.
This isn't working where it's used (Oracle).
Yeah, just mentioned as this was pointed out to me in the past: https://github.com/django/django/pull/11059#discussion_r266598250
I think you can use `django.utils.deconstruct` to decorate the class, the `path` argument can be passed explicitly. Since Django 2.0+ is Python 3 only, you can use keyword-only arguments with `*, arg1=None, arg2=None`.
```python hanging = ( indentation, has, a, newline, after, opening, bracket, ) ```
`path` is unused, so we can use a `_` instead.
`quote_name` is a temporary variable that's used only once, therefore I think we can remove it and use `schema_editor.quote_name` directly, i.e.: ```python 'name': schema_editor.quote_name(self.name), ```
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
I don't think this is needed (probably accidentally copied from line 327).
to minimize size of try: ``` try: m2m = kwargs['many_to_many'] except KeyError: pass else: warnings.warn(.... ```
Keeping the try block limited to just the code you expect to throw the exception is a good practice. It prevents a situation where there's some other bug than what you expected. For example, if `warnings.warn(` somehow threw a `KeyError` and it was in the try block, you would unexpectedly hide that bug.
The approach you've taken here is: - Cache the result of get_fields() for a specific set of arguments - look up a name in that list; - Raise FieldDoesNotExist if the name is not found. The other obvious approach I can think of would be: - Cache a list of _all_ fields - Look up the name in that list - Raise FieldDoesNotExist if the name is not found - Raise FieldDoesNotExist if the field doesn't have the requested properties. I'd be interested to see the "memory vs speed" tradeoff for these two approaches.
no blank line
I think we want to crash here if `bases` is not iterable.
How about more simply: "Found duplicate <field/base/manager> '%s' in CreateModel operation." Maybe you could create a helper function so we don't have to repeat a similar loop 3 times.
Use: ``` python raise ValueError( "Indexes passed to ModelState require a name attribute, " "%r doesn't have one." % index ) ``` While we allow longer lines, we typically break up long strings like this.
My gut feeling is that it's normal that these test assertions lost a bit of their original _intent_ now we're not using rendered models anymore. The reason for that is that `.field_name` gets assigned on model rendering which we completely avoid doing here. The fact _rendered_ model fields were making their way into operations breaks the `ModelState.__init__` expectations and was really just an implementation detail. Looking more at the ticket-23415 and the resulting patch 215aa4f53b6bbd07d5c1eecfa94e7fcd00da813e these particular assertions had little to do with the issue of unmanaged models not including their fields in the first place. It's true that the symptom that the reporter mentioned was improper foreign key references by models pointing at the unmanaged model but the true bug there was that unmanaged model fields were not tracked in migration state. TL;DR I think this is fine.
what if two mixins have the same name (from different packages)? hypothetically: `facebook.models.UserMixin` and `twitter.models.UserMixin`
please use longer/more descriptive names than `f` and `k`, like `f_obj` and `slice`
Using `int` is untested and doesn't work as expected, because it uses 1-based indexing instead of 0-based indexing.
Both approaches work but I wonder if we'd want to be a bit more liberal here and simply return `copy` if no `output_field` can be retrieved. ```suggestion field = getattr(copy.lhs, 'output_field', None) if field is None: return copy ``` It would also avoid having to specify an explicit `output_field` when using a `Func` and `RawSQL` when users usually know what they are doing.
Casting `int` to `int` is not necessary.
I think it will be more readable to keep `int` and `slice` in separate branches, e.g.: ```python def __init__(self, f_obj, slice_obj): if isinstance(slice_obj, int): if slice_obj < 0: raise ValueError('Negative indexing is not supported.') self.low = slice_obj self.length = 1 elif isinstance(slice_obj, slice): if ( (slice_obj.start is not None and slice_obj.start < 0) or (slice_obj.stop is not None and slice_obj.stop < 0) ): raise ValueError('Negative indexing is not supported.') if slice_obj.step is not None: raise ValueError('Step argument is not supported.') self.low = 1 if slice_obj.start is None else int(slice_obj.start) + 1 self.length = None if slice_obj.stop is None else int(slice_obj.stop) - self.low + 1 else: raise TypeError('Argument to slice must be either int or slice instance.') self.expression = f_obj ```
What happens if the pk field isn't in the self.query.select? I think using self.query.get_initial_alias() instead of self.query.get_meta().db_table should fix this issue.
Unnecessary list comprehension, `tuple(self.model._meta.pk.get_col(inner_query.get_initial_alias()))` should do.
This unfortunately won't work if the subquery refers to any outer references as these must be included in the group by clause.
This solution introduce really unexpected behavior, i.e. change every raw SQL that contains name of any column from a parent model with that column, e.g. if a parent model contains column `name` then following examples will be replaced by `"annotations_store"."name"`: - `case when name='foo' then 'oof' else 'foo' end` -> `"annotations_store"."name"`, - `concat(chain, 'name')` -> `"annotations_store"."name"`, - `other_column_with_name_in_it` -> `"annotations_store"."name"`, etc.
`regex` will be clunky. IMO unnecessary `JOIN`'s are acceptable in this case, there is not much we can do.
Use normal dictionary access instead of `.get()`. It is fine for us to blow up with a `KeyError` here and helps debugging because it is clearer whether the attribute is missing or the value is incorrect.
Don't forget the trailing commas! However, I also expect that this can fit on one line - we allow 119 chars, and it is not too complicated to understand.
You don't need to pass `None` (in all tests).
Let's rename these test methods to be `test_html_autocomplete_attributes`.
The signal approach would hopefully eliminate the need to call `reload()` manually.
I tried to use a generated condition the `WHERE` clause and it works fine, so IMO we can safely assume that it's an Oracle caveat :smile:
When fixing the implementation of `RedisCacheClient.get()` to support `default`, this should work fine. ```suggestion ```
Assuming this works, don't forget that we'll need some solution (like the environment variable used before) to only run `mark_expected_failures_and_skips()` when running Django's test suite.
This must be an inner skip, please revert (ticket-31888).
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
the try/except needs to be added back
No reason to use `dict.update()` anymore.
might as well use `setdefault` in the test as well
This whole `try`/`except` logic can be replaced by a `self.assertRaises(SSLError, backend.open)`.
I would stick with the one line if/else statements. The style guide says, "Don’t limit lines of code to 79 characters if it means the code looks significantly uglier or is harder to read."
Using `self.connection.features`: ```suggestion elif ( on_conflict == OnConflict.Update and self.connection.features.supports_update_conflicts_with_target ): ```
Use `self.quote_name()` to do the quoting of fields: ```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ', '.join(map(self.quote_name, unique_fields or ())), ', '.join(f'{field}=excluded.{field}' for field in map(self.quote_name, update_fields or ())), ) ```
You should use `supports_update_conflicts_with_unique_fields`.
```suggestion elif ( on_conflict == OnConflict.Update and not self.connection.features.supports_update_conflicts_with_target ): ```
Chop blank line.
Perhaps the following? ```python collections.deque(self.result, maxlen=0) # consume iterator quickly. ``` Some performance numbers: ``` Python 3.7.0 (default, Sep 15 2018, 19:13:07) Type 'copyright', 'credits' or 'license' for more information IPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: from collections import deque ...: from itertools import repeat ...: n = 10000 ...: %timeit -n1000 [__ for __ in repeat(0, n)] ...: %timeit -n1000 for __ in repeat(0, n): pass ...: %timeit -n1000 list(repeat(0, n)) ...: %timeit -n1000 deque(repeat(0, n), maxlen=0) 195 µs ± 5.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 74.3 µs ± 204 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each) 53.2 µs ± 4.66 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 43 µs ± 428 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each) ``` So even calling `list()` seems better than an empty loop, and `collections.deque()` is fastest because it is written in C.
Thanks for checking :+1:
@maguayo do you have a better suggestions on how to consume an iterator without materializing it? That seems the most elegant way of doing it to me.
Oh, that surprises me too...
`response.request.method` would be more idiomatic.
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
Remove ticket number. Capitalise first word of sentence.
Will this statement will fit on a single line? (119 characters is permitted.)
Test -> Tests (and I suggest a new `test_history_view.py` file since this file is quite large already.
Adding new code in a good location is fine.
Since index name generation is deterministic, I don't think this is needed. `test_name_auto_generation` already checks for a specific name. If this index is truncated is some different way, then it would be okay to keep it but check for the actual name rather than testing the length.
Use single quotes consistently.
Perhaps we should continue to test the simpler case where we don't provide a `name` or `condition`.
Manipulating `second` here is not strictly necessary, `first.save()` raises the `IntegrityError`. I believe the reason for `second` to be manipulated here is to show the difference with initially deferred constraints behavior. If that's the case, perhaps a function could show that the same code passes under initially deferred constraints but not under immediate constraints. Something like: ```diff diff --git a/tests/constraints/tests.py b/tests/constraints/tests.py index 067b38cfb6..b3257b6789 100644 --- a/tests/constraints/tests.py +++ b/tests/constraints/tests.py @@ -196,17 +196,17 @@ class UniqueConstraintTests(TestCase): first = Product.objects.create(name='First', shelf='Front') second = Product.objects.create(name='Second', shelf='Back') + def swap(): + first.shelf = 'Back' + second.shelf = 'Front' + first.save() + second.save() + with self.assertRaises(IntegrityError): with set_constraints(unique_shelf=IMMEDIATE): - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() first.refresh_from_db() self.assertEqual(first.shelf, 'Back') ```
I think we can use the same check like in `UniqueConstraint`: ``` if not isinstance(condition, (type(None), Q)): raise ValueError('ExclusionConstraint.condition must be a Q instance.') ```
could you fix the other test cases in this file and make it a separate commit? I see at least `BooleanFieldTests` that has database activity but uses `unittest.TestCase`.
suggestion: "commands that don't need settings succeed if settings file doesn't exist"
Keep the null property of the old field. If it has changed, .... separately. (also please wrap at 79 chars)
I would rename `self.model_name` -> `self.name` (like in `CreateModel`, `DeleteModel`, or `RenameModel`).
You could, just seemed easier not to have nested if statements.
This is not used only by `get_or_create`.
Keep what's done in `try` to the minimal expected to raise `self.model.DoesNotExist`. Move this after `except:` block.
This exception message is different from that in `related.py` though the logic/intention surrounding it seems to be the same. Is this intentional? (FWIW, I find the message in `related.py` to be clearer)
That would hide the `update_condition` kwarg from signature, that's why I suggested a sentinel should be used.
For those of you following along at home, the problem is that `None` is a valid value for a kwarg (check to see if the value from the database is `NULL`). That wasn't obvious to me so I thought I'd clarify. One solution would be to not add a parameter at all, and see if `"update_condition"` is in `kwargs`.
If I understand correctly "let's delegate..." -> "that will be done in instance.full_clean()"? I'd like to check a few more things later today so you can hold off on that update until I finish review.
Do Django's automated tests ensure backward compatibility? If not I probably don't have enough familiarity with Django to do so. Glad I'm not taking crazy pills, though. :)
I'm not sure special-casing the password field is a good idea, as you might as well have user code presenting such cases, and then the function would crash badly. I think a try/except clause catching the KeyError when f is not find in form.fields, defaulting to the raw field name in that case, would be a safer approach.
please revert whitespace addition
We should make use of `self.message`.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
Is `plan` meant as the second argument? Looks like we're missing a test for this branch.
We've been using "Take / apply" verb-style in new docstrings.
Double checking the commit, this change, in this form leaks some state across migrations. Testing on CI right now. ``` python ERROR: test_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) psycopg2.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/markus/Coding/django/django/test/utils.py", line 182, in inner return test_func(*args, **kwargs) File "/home/markus/Coding/django/tests/migrations/test_executor.py", line 401, in test_alter_id_type_with_fk executor.migrate([("author_app", "0002_alter_id")]) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 94, in migrate self.apply_migration(states[migration], migration, fake=fake, fake_initial=fake_initial) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 131, in apply_migration state = migration.apply(state, schema_editor) File "/home/markus/Coding/django/django/db/migrations/migration.py", line 118, in apply operation.database_forwards(self.app_label, schema_editor, old_state, project_state) File "/home/markus/Coding/django/django/db/migrations/operations/fields.py", line 201, in database_forwards schema_editor.alter_field(from_model, from_field, to_field) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 482, in alter_field old_db_params, new_db_params, strict) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 635, in _alter_field params, File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 106, in execute cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 79, in execute return super(CursorDebugWrapper, self).execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/utils.py", line 95, in __exit__ six.reraise(dj_exc_type, dj_exc_value, traceback) File "/home/markus/Coding/django/django/utils/six.py", line 658, in reraise raise value.with_traceback(tb) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) django.db.utils.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. ``` However, integrating this with the second commit on my PR fixes the issue. I thus squash those commits there and close your PR here.
Chop blank line
That looks awesome @hannseman 💯 🏅 Regarding `django.contrib.postgres.indexes.OpClass` I guess we could add a `IndexedExpressionWrapper.register_wrapper` and have `django.contrib.postgres.apps.PostgresApp.ready` register `OpClass` to avoid coupling there.
I think that most of the expression special casing and resolving should be done at the `Index.create_sql` level. The only purpose of `ddl_references` is to hold references to identifiers and allow renaming if necessary, it shouldn't have any knowledge about `django.db.models` abstractions.
This seems out of place. Is this branch really specific to MySQL? Is there a way we could avoid the `Col` import in the first place.
In the current state, it's not reusable for other lists of expressions, so I would rename it to the `IndexExpressions`
I would move this out of the `Statement`: ```python if columns: columns = self._index_columns(table, columns, col_suffixes=(), opclasses=opclasses) else: columns = Expressions(model._meta.db_table, expressions, compiler, self.quote_value) ```
why cast this into a list, normal brackets (generator) will do
I don't know if this is an overkill, but we could log the exception.
again, why not just return a generator
I would filter that first, via a generator. I think this might be more readable. ```python lists = (lst for lst in lists if lst) ``` or ```python lists = filter(None, lists) ```
You could do solve this recursively, but I don't know if this better readable really. meh
No need for `keys()` here.
s/non empty/non-empty/ (twice)
I think there's a constant for `'self'` as well somewhere in `django.db`.
You can remove the whole `else:` branch as `None` will be returned by the function implicitly.
I think that `result` should be a tuple `result = ()` rather than list.
I thought about it, but it has some value to test this explicitly.
I'm not even sure we really need the extension to be created in this test, checking the SQL command correctness might be sufficient.
Exactly, it's not **related**. That's why we should fix it separately in advance.
preferred format is "#15346, #15573 - Issue description"
argument ordering should be reversed
```suggestion 'related_name has no effect on ManyToManyField with ' 'a symmetrical relationship to "self".', ```
Add a trailing comma.
Please add a trailing comma.
Please add a trailing comma.
Use this style: ``` self.assertEqual(field.check(), [ ]) ```
```suggestion self, (app_label, model_name), (old_name, found), ```
```suggestion self.reload_model(app_label, model_name, delay=delay) ```
These are unnecessary ```suggestion ```
I think we can abstract away the need to _lower_ the name here. ```suggestion def alter_model_options(self, app_label, model_name, options, alter_option_keys=[]): ```
```suggestion def alter_model_managers(self, app_label, model_name, managers): ```
May be he wanted to catch system exiting exceptions - BaseException, SystemExit, KeyboardInterrupt and GeneratorExit. But i fail to see the reason for this
Put import at top of file.
A bit simpler? ``` python python_startup = os.environ.get('PYTHONSTARTUP') python_rc = os.path.expanduser('~/.pythonrc.py') python_rcs = [os.path.expanduser(python_startup)] if python_startup else [] if python_rc != python_startup: python_rcs.append(python_rc) ```
I think we should use `globals()` ```suggestion exec(options['command'], globals()) ``` some commands will crash with an empty globals, e.g. ``` >>> python -m django shell -c <<EOF " def f(): with open(__file__, 'r'): pass f()" EOF ... File "/django/django/core/management/commands/shell.py", line 88, in handle exec(options['command'], {}) File "<string>", line 5, in <module> File "<string>", line 3, in f NameError: name '__file__' is not defined ```
chop blank line
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
Don't use a mutable default: `{}`. Should default to `None` and then add : ``` if json_dumps_params is None: json_dumps_params={} ```
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
remove first comma (also as someone not intimately familiar with the ORM, I'm not quite sure what "default select" means (I assume it's a reference to `default_cols` -- maybe no further explanation is needed).
IMO, these tests would be less verbose with assertRaises. what do you think? edit: actually I'd use six.assertRaisesRegex to verify the message 'Good' (maybe change it to something better) so you're sure you didn't trigger an AttributeError some other way in the test.
No sure about which parts should remain in `Q.checks` instead. Current separation seems relatively good but I'd be curious about input from others.
~~Are you sure the `Value` wrapping and the `output_field` are necessary here? As long as you pass an `output_field=models.BooleanField()` to `Case.__init__` you should be good to go.`~~ _Edit: Well it looks like passing `output_field=models.BooleanField()` to `Case.__init__` doesn't work yet._
FWIW `Q(Exists(is_ceo)) | Q(Exists(is_poc))` already works and `Exists(is_ceo) | Exists(is_poc)` doesn't require much changes. ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 5b82ae97a7..d18de75e9a 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -101,6 +101,8 @@ class Combinable: return self._combine(other, self.BITRIGHTSHIFT, False) def __or__(self, other): + if getattr(self, 'conditional', False) and getattr(other, 'conditional', False): + return Q(self) | Q(other) raise NotImplementedError( "Use .bitand() and .bitor() for bitwise logical operations." ) diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py index 6c00f813d9..d3d75f1ce1 100644 --- a/tests/expressions/tests.py +++ b/tests/expressions/tests.py @@ -595,11 +595,9 @@ class BasicExpressionsTests(TestCase): def test_case_valid_in_filter_if_boolean_output_field(self): is_ceo = Company.objects.filter(ceo=OuterRef('pk')) is_poc = Company.objects.filter(point_of_contact=OuterRef('pk')) - outer_1 = Employee.objects.filter(Case( - When(Exists(is_ceo), then=Value(True)), - When(Exists(is_poc), then=Value(True)), - default=Value(False, output_field=models.BooleanField()) - )) + outer_1 = Employee.objects.filter( + Exists(is_ceo) | Exists(is_poc) + ) self.assertQuerysetEqual( outer_1, ['<Employee: Joe Smith>', '<Employee: Frank Meyer>', '<Employee: Max Mustermann>'], ```
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
Please use 4 space indent: ``` templates = [{ 'BACKEND': ... }] ```
This is `verbose_name` and you should make it translatable. Look at how other contrib apps do it.
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
I would rather create a custom model with field that has `db_column`, e.g. ```python project_state = self.apply_operations('test_rfwdbc', ProjectState(), operations=[ migrations.CreateModel('Pony', fields=[ ('id', models.AutoField(primary_key=True)), ('field', models.IntegerField(db_column='db_field')), ]), ]) operation = migrations.RenameField('Pony', 'field', 'renamed_field') new_state = project_state.clone() operation.state_forwards('test_rfwdbc', new_state) ```
Please use this style to limit lines to 120 characters so we don't have to scroll to review it: ``` self.assertEqual( ..., ... ) ```
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
This docstring is unnecessary.
I suggest you use a constant to refer to the default `template_name`. Have a look at how it was dealt with in #5577.
I think we shouldn't silence the exception in all cases here, only when `template_name != 'csrf_failure.html'`. Changing the default value of `template_name` to `None` and actually raising the exception `if template_name is not None` should do.
This can be single-lined, e.g. ```python return HttpResponseServerError( ERROR_PAGE_TEMPLATE % {'title': 'Server Error (500)', 'details': ''}, content_type='text/html', ) ``` The same in `bad_request()` and `permission_denied()`.
`# Render template (even though there are no substitutions) to allow inspecting the context in tests.`
Testing `load_template` should be enough.
We use triple quotes for new docstrings.
Might want to squeeze all lines to follow the _style_ of the test module.
Combining this commit with the next one seems fine. It works the same as override_settings, but you can use `with self.settings`.
```suggestion backend = self.base_params['BACKEND'] ```
When fixing the implementation of `RedisCacheClient.get()` to support `default`, this should work fine. ```suggestion ```
In fact, unless you have a special sequence like \n, \r, \t, the raw prefix is not strictly necessary. But for consistency, it's better to always add it to indicate that none of the escaped letters have to be interpreted as special-meaning sequences.
I think that the string should be prefixed by 'r' (raaw string), so as the backslashes are not interpreted as special sequences.
My pleasure :)
@sdil Can you take a look? Thanks!
@sdil Thanks for checking :+1:
According to the `Node.render` docstring it should "Return the node rendered as a string" so if we really wanted to optimise for speed, we could potentially forgo the `str` as well, but I think probably better safe than sorry here, so better to leave it in.
Could be reduced to a list comprehension ```python return [ value for key, value in request.POST.items() if regexp.match(key) ] ```
We expect compileable to always have an `as_sql` method. e.g. see `effective_default`'s implementation. ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) return compiler.compile(node) ```
I think it's a bit neater to invert the check for `node.as_sql` and return early: ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) sql, params = compiler.compile(node) return sql, tuple(params) ```
Can you issue a `RuntimeWarning` here telling the user that Django falls back and it might be time to clean up using `squashmigrations` and link to https://docs.djangoproject.com/en/dev/topics/migrations/#squashing-migrations.
This check is redundant. `skipUnless` already guarantees that we have MySQL. You can remove the `try ... except` leaving only `import`.
If `cx_oracle` is installed, there's an error: ``` File "/home/tim/code/django/tests/backends/test_cursors.py", line 33, in OracleCursorOptionsTestCase class OracleLoggingCursor(LoggingCursorMixin, Database): TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases ``` Also, is this file doing anything useful? I don't see any test methods.
This check is also redundant.
`e` is unnecessary. Maybe it will be better to refactor these tests and put `class` inside `try` e.g. ```python @unittest.skipUnless(connection.vendor == 'postgresql', 'Postgresql specific test.') class PostgreSQLCursorOptionsTestCase(TestCase): try: from psycopg2.extensions import cursor class PostgresLoggingCursor(LoggingCursorMixin, cursor): pass except ImportError: pass ```
This check is also redundant.
I think the test should be split into multiple test methods, one per thing-being-tested, as above
checking the results of the query would be useful. ``` self.assertEqual( Pet.objects.prefetch_related('fleas_hosted').values_list('id', flat=True), [...], ) ```
For similarity with other messages (e.g. 'The nowait option cannot be used with skip_locked.') you might change 'passed' to 'used'.
```suggestion msg = 'Slice stop must be greater than slice start.' ```
not sure if this really passes the django style guide, compared to plain if/else statements
beautiful, assuming it works
I don't think `lru_cache` makes much sense here, the `cached_property` decorator should do the trick.
Simply deindent and remove the `else`.
Return a tuple...
I would move `create_namedtuple_class` outside of `NamedValuesListIterable` or even better to `django.db.models.utils`, e.g. ```python def unpickle_row(names, values): return create_namedtuple_class(*names)(*values) @functools.lru_cache() def create_namedtuple_class(*names): # Cache type() with @lru_cache() since it's too slow to be called for every # QuerySet evaluation. def namedtuple_reduce(self): return unpickle_row, (names, tuple(self)) return type('Row', (namedtuple('Row', names),), { '__reduce__': namedtuple_reduce, }) ```
Surely you want all of the password hashes in the list of available ones so that people can log in with them? Of course argon2 is unlikely to be out there in the wild, but if someone tried it and then decided to switch back they wouldn't be able to do so by deleting the settings, they'd have to copy/paste the default and re-add it. There's little harm in including it by default afaik. You might not want to have something other than PBKDF2 to be the default though, people might accidently have bcrypt or argon2 installed and not realize it and end up unable to log in if they deploy. Not sure if that's a big worry or not though.
Our code currently requires the first hasher to be usable, putting it as first and not installing the extension will break (look at `get_hasher('default')`)
I think the best argument is "There's little harm in including it by default afaik.". If someone tried using argon2 they can as well adjust their settings, after all they are testing against an unreleased version.
From a security stand point, argon2 is better than PBKDF2 because it's memory hard as well as CPU hard. Security wise argon2 > scrypt > PBKDF2 ~= bcrypt.
Presumably at some point this change will be released.
However, I think it's worth to keep it for backends without built-in converters.
This is already covered by `tests.queries.test_db_returning.ReturningValuesTests.test_bulk_insert`, that's why `ReturningValuesTests` tests crash on SQLite 3.35+ (see #14227).
Technically, `name` should be a string, not an integer. For brevity, you could use `[Person(name=name, person_country=self.usa) for name in 'abcde']`
I don't think such a regression is likely and we don't have similar checking elsewhere so I think it's fine to remove. Yes, please squash commits.
is this to ensure that `bulk_create()` didn't create any objections even though it raised an error? I don't think that's really needed. Otherwise, this patch looks good.
Use a `set` if this value is only used for containment checks ```suggestion local_action_names = {self.get_action(action)[1] for action in self.actions} if self.actions else set() ```
I don't have a strong feeling about either, this approach avoids an unnecessary intermediary list creation though.
Please remove temporary variable `actions`, also IMO it will be clearer to unpack `action` e.g. ```python names = [name for _, name, _ in obj._get_base_actions()] ```
This is a classic case where you may have duplicates of multiple action names but are only warned about the first one. You resolve that and then get nagged again about the next one. It would be better to list all of the duplicated names. It also probably makes sense to just count all of the names using `collections.Counter` and look directly for duplicates; to wit: ```python counts = collections.Counter(names) duplicates = [name for name, count in counts.items() if count > 1] if duplicates: return [checks.Error( ￼ '__name__ attributes of actions defined in %s must be ' ￼ 'unique. Duplicated names: %s' % (obj.__class__, ', '.join(duplicates)), ￼ obj=obj.__class__, ￼ id='admin.E130', ￼ )] ```
> I'd prefer to return a list of errors rather than a single concatenated error. Is that the method I should change it to? Sorry - I didn't get around to replying, but yes, multiple works better.
Check constraints don't seem to be related with this issue, moreover `unique` is `False` for all check constraints. Please revert this unrelated change.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
This formatting change is not related with a bug fix, please revert.
Here we also should call `super` and not copy-paste code
Thanks for your effort :+1:. It is a kindly request for the first option. Trailing dot should be at the end of a sentence but there is no point in doing unrelated refactoring of existing code.
`self.assertEqual(f.choices), [])` looks simpler to me (plus if the list isn't empty, another debugging step isn't needed to see what the list contains).
``` # If the filename already exists, generate an alternative filename # until it doesn't exist. ```
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
Do we need to call `str()` on `contraint_sql`? ```suggestion if contraint_sql: schema_editor.execute(constraint_sql + ' NOT VALID') ```
I think we are missing the `call_command()` here.
Yes, f-strings should use only plain variable and property access as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
On second thoughts creating a URL with to_field isn't required to test this issue – so the string interpolation can simply be removed: ```suggestion admin_user_change_url = reverse( "admin:%s_%s_change" % (user._meta.app_label, user._meta.model_name), args=(user.username,), ) ```
sss :snake: ```suggestion password_help_text = form.fields["password"].help_text ```
Just got a typo here 😁 ```suggestion # assert joined_url and pw_change_url are identical ```
Lastly we should mention what the specific issue is about the link in the helptext 🙂 ```suggestion def test_bug_34066_link_to_password_reset_in_helptext(self): # The password reset link should always refer to the primary key even when accessed via a to_field ```
As discussed, we can simplify this a bit, also benefiting from the `min(0, ...)` in `get_backend_timeout()`: ```suggestion if timeout == 0: if ret := bool(client.set(key, value, nx=True)) client.delete(key) return ret else: return bool(client.set(key, value, ex=timeout, nx=True)) ```
As discussed, we can simply `.delete()` here when `timeout == 0`. We can do this if we fix `get_backend_timeout()` to prevent negative numbers as mentioned above. ```suggestion if timeout == 0: client.delete(key) else: client.set(key, value, ex=timeout) ```
Ensure we return booleans here for consistency? ```suggestion if timeout is None: return bool(client.persist(key)) else: return bool(client.expire(key, timeout)) ```
So [`.flushall()`](https://redis-py.readthedocs.io/en/stable/#redis.Redis.flushall) will clear everything in all databases. (Apparently Redis has 16 logical databases that can be switched between.) We should change this to use [`.flushdb()`](https://redis-py.readthedocs.io/en/stable/#redis.Redis.flushdb) instead and only clear the current database. For consistency we can also ensure this returns a boolean. ```suggestion return bool(client.flushdb()) ``` (We should probably also expose a `db` parameter via `RedisCacheClient.__init__()` which can be passed through via `_client_kwargs`. It should have a default value of `0`.)
Yes, sorry, I meant `max()`.
Please revert unrelated changes.
This will become a performance issue for the database before it becomes one for the Python process :-)
I don't think that SQLite can pass kwargs, so I think that this can be replaced by `if None in args`.
I think it's better to test a "normal" function instead of `lambda`, e.g. ```python with self.assertRaisesMessage(TypeError, msg). @sensitive_variables def test_func(self, password): pass ```
Please add `@functools.wraps(func)` to this.
Return the readonly fields for a given AdminForm. (following verb style of PEP 0257) -- similar for other docstrings
please wrap docstrings at 79 characters
Was going to suggest the same, but see that @charettes got there first. > Yes, but IMHO it's worse for readability. Fair enough.
Remove ticket number. Capitalise first word of sentence.
Extra wrapping and `str()` call are unnecessary: `… for city "%s".' % city`
Is it possible to use something from `connection.ops` or similar to avoid a vendor check? Otherwise, looks good.
I'm always wary of putting assertions inside loops and if-statements because you're never certain they are executed. If you added a counter and an assertion that `count==1` after the loop, that would be defensive.
This is because `'tests'` will be used for `app_label` if not explicitly specified.
I don't understand why this is required to avoid `RuntimeError: Model class schema.tests.Author doesn't declare an explicit app_label and isn't in an application in INSTALLED_APPS.`. I thought `isolate_apps` takes care of that.
Use single quotes consistently (could be done above and below also).
Another vote for moving this logic into apps as a private method.
Thanks for the link, would be nice to have a ticket for it, probably.
Yes, this should be taken care of before.
a nice line to see gone
I don't think we need an explicit `if` here. `_pending_lookups` is `{}` by default and thus the for-loop body isn't run anyways.
_Gut feeling_ says that this ought to be a _clone_, so as not to leak the _original_ (un-negated) mutable expression out. e.g something like: ``` return self.expression.copy() ``` Currently you've got a test for `self.assertEqual(~~c, c)` which I would _guess_ (reading the diff only) would also pass with `assertIs` where I presume it oughtn't.
The failures on MySQL, PostgreSQL and likely Oracle seems to be an indicator that it should not work on SQLite either. There's only so much that Django can do when coercing types in a database agnostic way and I'm not sure trying to support cases where `float` are implicitly properly converted to `Decimal` at the ORM level is a pattern we should encourage. If you're filtering against decimal/numeric data with floats you're better off defining your coercion rules explicitly at the application level and pass _stable_ numeric data to the database to avoid surprises down the road when a specific float value happens to take an unexpected rounding/loss of precision path along the way to the query executor.
Could use `assertSequenceEqual` to avoid the `itemgetter`
Maybe e.g. `Calling exclude() is not supported after union().`
~~Are you sure the `Value` wrapping and the `output_field` are necessary here? As long as you pass an `output_field=models.BooleanField()` to `Case.__init__` you should be good to go.`~~ _Edit: Well it looks like passing `output_field=models.BooleanField()` to `Case.__init__` doesn't work yet._
Hehe :D Thanks, I'll approve now and merge later today after a final testrun
My question would be: do you need to define a set of allowed characters? Does not just base64 encoding (with the URL-safe character set) the output of secure random not achieve the same goal? On Mon, Aug 4, 2014 at 9:52 AM, Curtis Maloney notifications@github.com wrote: > In django/middleware/csrf.py: > > > @@ -25,6 +25,7 @@ > > REASON_BAD_TOKEN = "CSRF token missing or incorrect." > > > > CSRF_KEY_LENGTH = 32 > > +VALID_CHARS = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789' > > This same set of chars is defined in django.utils.crypto as the default > for "allowed_chars" for the get_random_string function. > > Should we consider making this a more accessible constant? > > — > Reply to this email directly or view it on GitHub > https://github.com/django/django/pull/1477/files#r15738414.
Yeah, screw that :D in the worst case make it an attribute on the CSRF class, so a user can override it if we go down the route with an extra class.
I think this could use a generator expression instead of list comprehension to avoid additional temporary lists in memory. For example: ``` pairs = zip((chars.index(x) for x in nonce), (chars.index(x) for x in pad)) ``` (Same in `_unpad_cipher_token()`)
`string.letters + string.digits`
Again, the `os.sep` bit here will be stripped off when passed to `Path()`: ```suggestion cwd_prefix = os.curdir ``` It's probably worth reviewing this whole section.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
Please wrap docstrings at 79 chars.
My only question is if this skip logic is still correctly applied (i.e. none of the other classes that inherited `ExtractorTests` require it)? If you verify that, ship it.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
note that `Meta` should appear after fields per: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#model-style I made this one change when I committed it.
removing unnecessary multilines like this will make it nicer.
Chop blank line.
`CustomUserWithM2MAndThrough` -> `CustomUserWithM2MThrough`
Actually you should use `assertNotContains(response, '"/test_admin/admin/r/%s/1/"' % content_type_pk)` to also account for `byte` response content on py3.
Use `assertNotIn` instead.
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
Prefer this indent style: ``` response = self.client.post(reverse('...'), { .... }) ```
This is fine as is.
This is fine as is.
This is fine as is.
This is fine as is.
An unhandled `SuspiciousOperation` will result in a `400 Bad Request` response which is ok since it is a client error. However, `413 Request Entity Too Large` would be the correct status code for this error.
Why do you continue here? `app_label` might still be invalid.
> PS - you might ask: why not fix ticket 29062 first? The reason is that fixing ticket 29062 properly would involve properly closing connections. Thus, any correct fix of ticket 29062 would be a superset of this PR, which would make it an even bigger change. Yes that was my first question :smile: Thanks for details :+1: . I'm afraid that it can be still confusing for a future me. I will try to move something to a separate commit e.g. `_make_connections_override()` which should reduce the number of changes and make it easier to bisect and fix potential regression.
Do we need this methods? Maybe I'm missing sth but thread's database connections should already by overridden, and we don't pass `connections_override` to the `_create_server()` anywhere in Django :thinking:
Use single quotes.
We shouldn't silently change passed parameters. IMO it better to raise an exception like we do now: ``` $ export DJANGO_SETTINGS_MODULE=test_oracle $ ./runtests.py queries --parallel=2 Testing against Django installed in '/django/django' with up to 2 processes Found 416 test(s). Creating test database for alias 'default'... Creating test user... Cloning test database for alias 'default'... Traceback (most recent call last): File "./runtests.py", line 659, in <module> failures = django_tests( File "./runtests.py", line 385, in django_tests failures = test_runner.run_tests(test_labels) File "/django/django/test/runner.py", line 881, in run_tests old_config = self.setup_databases( File "/django/django/test/runner.py", line 787, in setup_databases return _setup_databases( File "/django/django/test/utils.py", line 217, in setup_databases connection.creation.clone_test_db( File "/django/django/db/backends/base/creation.py", line 239, in clone_test_db self._clone_test_db(suffix, verbosity, keepdb) File "/django/django/db/backends/base/creation.py", line 255, in _clone_test_db raise NotImplementedError( NotImplementedError: The database backend doesn't support cloning databases. Disable the option to run tests in parallel processes. ```
still seems like we're missing this type of query: `filter(tags__content_type=ctype)`
Please use single quotes (everywhere), you mixed single with double quotes.
As noted in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style, we're not so strict about it in code.
chop newline for consistency
I would separate each `with` statement with a line break. right now it looks like a huge block of stuff.
You could do this setup in Python. `self.school.students.add(...)`
State the expected behavior as per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style. Also wrap docstrings at 79 chars.
Same style as above.
might as well use `setdefault` in the test as well
URL should be capitalized
I don't see much value in this check.
IMO it's enough to test that `CreateExtension` honor `allow_migrate()`, creating extension is already tested in `postgres_tests`.
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Use the context manager version for better readability: ``` msg = '....' with self.assertRaisesMessage(ImproperlyConfigured, msg): self.set_up_test_model(True) ```
I think we usually avoid _should_ wording in test docstrings.
Combining this commit with the next one seems fine. It works the same as override_settings, but you can use `with self.settings`.
Use single quotes unless a string contains double quotes. Also, this looks fine to fine on the line above.
check flake8 ("missing whitespace around operator" here)
Remove blank line (and below).
Remove blank line (and below).
But `any()` always returns a bool? https://docs.python.org/3/library/functions.html#any
We should convert column name i.e. `connection.introspection.identifier_converter('large_field')`.
Remove the blank line.
I don't think we need the extra assignment here as this is only used once.
No point in assigning to `path` when used once. Also this doesn't seem right. I think you meant `__qualname__` rather than `__module__`? Which probably also means some tests are lacking...
I don't think it's terribly important as both checks use the same code path (although this could obviously be refactored later at which point that argument would fail...).
my preferred style is: "#17903 -- Inactive users shouldn't have permissions..."
First we should verify this passes before we toggle `is_active` to False.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
prefer this style for multilined docstrings: ``` """ Text """ ```
I'd drop it, and reintroduce the test later on in branches where we'll be able to backport #9383.
FWIW in #9383 this is handled by the `RenameField` operation -- no `AlterField` operation will be generated by the auto-detector just like none are generated on a model and `to` rename.
Please use the helper methods `self.assertOperationType()` et. al.
@atombrella Do we need inner imports here? Imports at the top works fine for me.
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
First we should verify this passes before we toggle `is_active` to False.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
I don't think it's terribly important as both checks use the same code path (although this could obviously be refactored later at which point that argument would fail...).
my preferred style is: "#17903 -- Inactive users shouldn't have permissions..."
Please add a trailing comma.
I would chop `simply`.
```suggestion 'Django now detects this configuration automatically. ' 'You can simply remove default_app_config.' ```
Wrap at 79 chars.
Chop trailing space.
This is here for appending to the follow-ups later. One or other is always appended so...
Please add a trailing comma to this line.
No need to construct a new `dict` and call `dict.update()` here. Also the key ought to exist in the map or something has gone drastically wrong, so no need to use `dict.get()`. ```python return_dict[key_map[key]] = value ```
Use literals please - `[]` for `list()` and `{}` for `dict()`. Also, something like `result` would be a better name than `return_dict`.
Please add a trailing comma to this line.
This is fine as-is. It is well known that iterating over a dictionary iterates over the keys. Also this is explicitly returning a `list` and not an iterator (as is the case with Python 3). Try out `type({}.keys())` to see the difference.
```suggestion raise NotSupportedError( 'This database backend does not support updating ' 'conflicts with specifying unique fields that will ' 'trigger the upsert.' ) ```
```suggestion raise NotSupportedError( 'This database backend does not support ignoring conflicts.' ) ```
We try to avoid accessing the database connections when not necessary, so I'd move `db_features`: ```suggestion if ignore_conflicts and update_conflicts: raise ValueError( 'ignore_conflicts and update_conflicts are mutually exclusive.' ) db_features = connections[self.db].features ```
```suggestion 'ignore_conflicts and update_conflicts are mutually exclusive' ```
```suggestion name = self.model._meta.pk.attname ```
This is already done in the super method, so undo: ```suggestion self.get_response = get_response ```
I'm wondering if this should be within the `DATABASES` setting
I don't see much value in this docstring.
Please keep this list in alphabetical order, i.e. place this after `SECURE_CONTENT_TYPE_NOSNIFF`
Only if we use another variable, from the guide: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style > As a guide, f-strings should use only plain variable and property access, with prior local variable assignment for more complex cases I think it's fine as-is
`step` attribute should only be added if `self.localized is False`
This seemed to include svg as well but django does not accept svg file input.
We might want to avoid doing this if `self.localize is True` since `DECIMAL_SEPARATOR` and `THOUSAND_SEPARATOR` should be taken into account in this case.
Likewise, it seems odd to keep `'point'` here: ```suggestion context = widget.get_context('geometry', None, None) ```
```suggestion # The Widget.get_context() attrs argument overrides self.attrs. ```
```suggestion path = '%s/' % request.path ``` :thinking:
OK, that sounds/looks interesting. Let me have a play. Thanks @jdufresne!
This will _break_ the debug page I think: instead of a list of routed URL patterns, we'll get a plain 404 error response. (Would like to do something at the resolver level, but we don't have the request... Can we limit it just to `DEBUG=False`? 🤔)
The check here should include `is_staff`. If you don't have permission to access the admin at all then we don't need to apply the redirect.
Can we please exclude any potential deprecation of the APPEND_SLASH in the admin from the scope of this PR.
Is `test_doesnt_work_with_init_subclass` meant to test this change? I still don't see any test failures if this change is reverted.
A test is missing for this change.
Why is this on two lines? Why not just...? ```python data_altering_methods = getattr(cls, 'data_altering_methods', ()) ```
this doesn't look right
I guess this needs to be something like `inherited_attributes |= set(base.__dict__.keys())` to work on Python 2.
unchecked -> unselected
You can probably use `assertSequenceEqual` here which might be a bit nicer.
please include a trailing comma in cases like this so if we add more items later, we don't have to modify the line again
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
TBH this is not what I suggested, I wanted to use `mocked_mode` to keep code DRY. I pushed edits.
The interesting test case is this: ``` season_2009 = Season.objects.create(year=2009, gt=111) season_2009.games.create(home="Houston Astros", away="St. Louis Cardinals") season_2009.games.create(home="Houston Astros", away="Chicago Cubs") season_2009.games.create(home="St. Louis Cardinals", away="Houston Atros") season_2010 = Season.objects.create(year=2010, gt=222) season_2010.games.create(home="Houston Astros", away="Chicago Cubs") qs1 = Season.objects.exclude(games__home__contains='Houston') qs2 = Season.objects.exclude(lookups.Contains(F('games__home'), 'Houston')) ``` where the qs1 and qs2 objects should match. The encouraging thing is that the code is trying to call split_exclude(). It might be hard to make this test actually work, the split_exclude() code is pretty big hack, and especially if the expression creates joins to multiple different relations it will be hard to make the current code work properly. But, if I recall correctly, we don't support .filter(games__away__contains=F('games__home')) either.
This can be single-lined.
Ditto, I'd remove.
Use the indentation style of the other tests. Actually, you can use `assertCountEqual()` instead. Maybe it makes sense to create another Article with a different year to test that the results are correct and not just returning everything.
You can reuse `Article`, e.g. ```suggestion Article.objects.filter(headline='Article 1').update(author=self.author_1) Article.objects.filter(headline='Article 2').update(author=self.author_1) Article.objects.filter(headline='Article 3').update(author=self.author_1) Article.objects.filter(headline='Article 4').update(author=self.author_2) articles = Article.objects.values('author').annotate(count=Count('author')) self.assertCountEqual(articles, [ {'author': self.author_1.pk, 'count': 3}, {'author': self.author_2.pk, 'count': 1}, ]) ```
Excellent. Happy with that. So, as I have above, without any `__qualname__`-mangling, should do the trick.
I looked into why the tests are failing. It's because some internals of the URL resolver and admindocs rely on the `__name__` set here. But they could also, more accurately, use the `view_class` atttribute. Therefore I've made PR #14138 to change that. If we go that route then I think we shouldn't even set `__name__` / `__qualname__`. Leaving them as their defaults is sensible and doesn't lie (`__name__ = 'view'` , `__qualname__ = '...View.as_view.<locals>.view'`). One can differentiate class-based views with the `view_class` attribute.
To my mind the real issue here is that we shouldn't be using `update_wrapper` at all (here or above in line 76). `view` is not in any way wrapped by `cls.dispatch` or `cls`. We just happen to want to achieve something similar to what we would want to achieve if we were wrapping a function. By using `update_wrapper` we're setting the `__wrapped__` attribute, so when we call `inspect.signature` it thinks that this function is the decorator, and that the function we're actually interested in is `cls.dispatch`. That's the reason why it returns the signature from `dispatch`. We should just do the thing we want to do directly. Something along the lines of: ``` for attr in functools.WRAPPER_ASSIGNMENTS: # I'm not sure which of these we actually want try: value = getattr(cls, attr) except AttributeError: pass else: setattr(view, attr, value) view.__dict__.update(cls.dispatch.__dict__) ```
@pope1ni Sorry it took a while to get back to you - it's been a hectic 24 hours. But yes, the above seems good to me.
```suggestion # the dispatch method. Note that __name__ and __qualname__ are # intentionally left unchanged, as view_class should be used to robustly ``` A slight change of word order here makes this read more naturally.
So do we need to generate SQL with the same config in the `ts_headline` and an inline `tsquery`? (that's my main question) ```sql ts_headline('french'::regconfig, ..., tsquery(..., 'french'::regconfig), ...) ``` If not then I would prefer to leave config only in `tsquery` and don't duplicate its logic in `SearchHeadline`.
Is there any reason to take `config` from a `query`? This should be rather a separate `config` as far as I'm concerned :thinking:
Should be a `frozenset` since it's only used for containment. From that point you use `set(options).difference(self.VALID_OPTIONS)` to determine `invalid_options`.
IMO we should check options against PostreSQL names.
@hannseman Thanks :+1: > I prefer it over the mixin approach. Yes me too :+1: . We can move `Value()` wrapping to the `__init__()` and simplify it a bit, e.g.: ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) if not (config and hasattr(config, 'resolve_expression')): config = Value(config) self.config = config def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save) resolved.config = self.config.resolve_expression(query, allow_joins, reuse, summarize, for_save) return resolved def as_sql(self, compiler, connection): sql, params = compiler.compile(self.config) return '%s::regconfig' % sql, params ``` Please move introducing a `SearchConfig` expression to the separate commit, or even PR.
Could you write the test without using fixtures? I think it would be a lot simpler.
It would be better to move these two into a separate test method.
We try to avoid non-4 space indent like this. You could move this to `msg = "..."` instead.
Please use single quotes (everywhere), you mixed single with double quotes.
assertEqual -- the version with "s" is a deprecated alias.
I wonder if you might add an assertion that the `_iterable_class` for `Teacher.objects_custom.all()` is `ModelIterableSubclass` just to be sure that isn't inadvertently refactored away in some future change.
checking the results of the query would be useful. ``` self.assertEqual( Pet.objects.prefetch_related('fleas_hosted').values_list('id', flat=True), [...], ) ```
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
single line looks okay here
I think this test would be fine without the blank lines, it's fairly short.
Instead of defining `success`, just return directly in the above code. I think it is simple enough.
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
This feels wrong, `JSONSerializer = BaseJSONSerializer` should work too (I know we could just import JSONSerializer from signing and use as is, but that feels wrong)
I would use a dict instead. ```suggestion self._pools = {} ``` and in `_get_connection_pool()`: ```python def _get_connection_pool(self, write): index = self._get_connection_pool_index(write) if index not in self._pools: self._pools[index] = self._pool_class.from_url( self._servers[index], **self._client_kwargs, ) return self._pools[index] ```
I take this back and have a deeper look at the tests.
This assertion is not necessary.
Please break this down into a couple of lines to make it easier to read. Also, the `distinct` call should be unnecessary for this bug, and only introduces extra work that distracts from the main problem.
@felixxm that's a tricky one for sure. We could adjust MySQL's `allows_group_by_pk` feature to be based of `not ONLY_FULL_GROUP_BY` but that would likely incur a large performance hit which is definitely not suitable for a backport. I guess we could always skip the test on MySQL for now.
Per new code guidelines, can we use `assertIs`? :)
I didn't dig much into this ticket, but is it still possible to have a value type not in the list handled in `_resolve_output_field`? If yes, could we keep a test for such a value (maybe in expressions tests).
@djackson-saa and I investigated the `PermissionError` and it was only added to Python in version 3.3 as a subclass of `OSError` and **not** available in Python2.7. In order to make this Python2.7 compatible, we are going to change the class we are excepting to `OSError` to cover all bases.
Ok, will do.
FYI, `errno.EPERM` maps to errno 1 so this is the errno we will check for instead of an integer like we originally submitted in the PR.
I think it would be safe to access `e.errno` directly in this case. The `winerr` attribute is only present on Windows platform hence the `getattr()`.
OSError will happen... os.rename()
Please add trailing comma.
I typically use this style to avoid such long strings near the length limit: ``` raise NotSupportedError( '...' '...' ) ``` (could also be applied in the other file)
`s/allowed/supported/` -- and coming to think of it, use `django.db.NotSupportedError`.
To match `django.db.models.sql.compiler` behavior, as_sql() should probably be replaced by `self.compile(annotation)`.
DatabaseError is raised if a ....
Do we really need this test? seems it doesn't relate to this change.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
```suggestion form.render(), '<div><fieldset><legend>Field:</legend><div id="id_field">' '<div><label for="id_field_0"><input type="checkbox" ' 'name="field" value="J" id="id_field_0"> John</label></div>' '<div><label for="id_field_1"><input type="checkbox" ' 'name="field" value="P" id="id_field_1">Paul</label></div>' '<div><label for="id_field_2"><input type="checkbox" ' 'name="field" value="G" id="id_field_2"> George</label></div>' '<div><label for="id_field_3"><input type="checkbox" ' 'name="field" value="R" id="id_field_3">' "Ringo</label></div></div></fieldset></div>", ```
```suggestion f'<li>Title: <input type="text" name="form-0-title"></li>' f'<li>Pub date: <input type="text" name="form-0-pub_date">' f'{delete_form}</li>' ```
On 1.10, the output is: `'<input type="number" value="1" name="code_0" />' '<input type="number" value="2" name="code_1" />' '<input type="number" value="3" name="code_2" />'`.
Careful, you're mutating `self.config` rather than a copy of it. If you hang onto an instance of `SearchVector` and reuse it then resolve_expression will be called on it twice. You'd be better off figuring out a way to add `config` via `self.set_source_expressions()` rather than overriding resolve_expression and `as_sql`. Even if that means using private expressions to build the components.
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
comma after tuple
Maybe test it in `tearDownClass()` then? That method is executed after all tests.
The test should be possible by just having two test methods, that each test if the car is still there, shouldn't it? ``` python def test_first_car(self): self.assertTrue(Car.objects.exists()) def test_second_car(self): self.assertTrue(Car.objects.exists()) ``` Then you have the benefit that you don't have to override `_post_teardown()`.
I mean you are running only one test anyway, so "running after each test" basically means "running once".
What I meant is, to leave the database in a clean state for other tests, we need: ``` self.assertTrue(Car.objects.exists()) Car.objects.delete() ```
Isn't the `Car` left in the database after this test? It should be deleted here too, I think.
This needs an update following 831358f23d545b8dba017c6b26bd295ba9f6c17d.
I see. Thanks @pope1ni and @timgraham
A bit unrelated, but I would move the closing parenthesis to improve readability: ``` statement.parts['extra'] = ' WITH (pages_per_range={})'.format( schema_editor.quote_value(self.pages_per_range) ) + statement.parts['extra'] ```
It looks like there will be a SQL syntax error due to a trailing comma if gin_pending_list_limit is used without fastupdate. Maybe `with_params` should be a list and joined with `', '`.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
I think it's the right class: ``` In [38]: class desc: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: return instance.__dict__['_%s__mangled' % cls.__name__] In [39]: class A: ...: d = desc() ...: ...: def __init__(self): ...: self.__mangled = 42 ...: In [40]: A().d Out[40]: 42 ```
@graingert `cls` is passed here.
You'll want to branch off `< 3.6`.
I think silently failing to cache the property should be considered not working.
``` class A: __print = cached_property(print, '__print') ``` This will not work and we can easily detect it too.
This test doesn't fail with or without the patch applied so it's likely unnecessary.
don't need variables here
You could avoid the delete query with: `AggregateTestModel.objects.none().aggregate(...)`. (I guess the other tests could use the same pattern, not for this PR though.)
Please use hanging indentation and avoid using of `\` (here and below), e.g. ```python subquery = AggregateTestModel.objects.values('char_field').annotate( stringagg=StringAgg('char_field', delimiter=';', ordering='-char_field'), ).exclude( char_field=OuterRef('char_field'), ).values('stringagg') ... ```
I don't think `list()` is needed. `self.assertEqual(sorted(values['arrayagg'], ['Bar', 'Foo', 'Foo'])` looks good to me.
It should be enough to use `lru_cache` instead, e.g.: ```python @functools.lru_cache(maxsize=128) def import_string(dotted_path): ... ```
> @kezabelle This method is very good, but there are currently many Django-related modules that reference import_string during operation. If you add a cache_import, you must modify and adjust the module code that references import_string to improve performance. You can add a new hook and use it in `import_string()`, e.g. ```python def cached_import(module_name, item_name): modules = sys.modules if module_name not in modules: import_module(module_name) return getattr(sys.modules[module_name], item_name) def import_string(dotted_path): """ Import a dotted module path and return the attribute/class designated by the last name in the path. Raise ImportError if the import failed. """ try: module_path, class_name = dotted_path.rsplit('.', 1) except ValueError as err: raise ImportError("%s doesn't look like a module path" % dotted_path) from err try: return cached_import(module_path, class_name) except AttributeError as err: raise ImportError('Module "%s" does not define a "%s" attribute/class' % ( module_path, class_name) ) from err ```
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
I wonder if we could support running `runtests.py` from different directories :thinking: like we do for dotted module names, e.g. ```bash ~/repo/django> ./tests/runtests.py backends.postgresql ``` works fine, but ```bash ~/repo/django> ./tests/runtests.py backends/postgresql/ .... File "./tests/runtests.py", line 155, in get_label_module rel_path = path.relative_to(RUNTESTS_DIR) File "/usr/lib/python3.8/pathlib.py", line 904, in relative_to raise ValueError("{!r} does not start with {!r}" ValueError: '/repo/django/backends/postgresql' does not start with '/repo/django/tests' ``` crashes. I tried to fix this with: ```python # Otherwise, interpret the label as a path. if not path.is_absolute(): return path.parts[0] else: path = path.absolute() rel_path = path.relative_to(RUNTESTS_DIR) return rel_path.parts[0] ``` but it crashes with `ModuleNotFoundError` (like without this patch): ``` ====================================================================== ERROR: backends/postgresql (unittest.loader._FailedTest) ---------------------------------------------------------------------- ImportError: Failed to import test module: backends/postgresql Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 154, in loadTestsFromName module = __import__(module_name) ModuleNotFoundError: No module named 'backends/postgresql' ```
Yeah it works for me, sorry again. The current version looks good :+1: , we could only raise a more descriptive error when a relative path is not correct (as proposed in https://github.com/django/django/pull/14507#discussion_r648186310).
They can be empty for subclasses, I think we can leave it that way.
Oh, I see your answer to @charettes below.
Please don't change all the other unaffected lines.
Please create a `_stream()` helper with this signature and use it so that the deprecated parameters don't appear in the `stream()` signature.
I see, thanks for your answer. I really don't want to hold the template based widget stuff from landing any longer. I suppose this is something we could refactor later on.
Similarly, I don't see much advantage to creating indirection with a method.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
`resolve_expression_parameter` maybe? You're not really dealing with combinables here (even though they are also combinable), so just go with expression based names I think.
put closing parenthesis on the next line
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
You don't check for the conversion flag and type specifiers. But I think that's fine. Would get a bit noisy otherwise and the current approach seems unlikely to give false positives.
Good, thanks. Maybe `Note setting ` -> `Set `
I wonder if it makes sense to add a hook (with better name) that could be called here and in `DeletionMixin`: ```python class DeletionMixin: ... def _delete(self): if not getattr(self, 'object', None): self.object = self.get_object() success_url = self.get_success_url() self.object.delete() return HttpResponseRedirect(success_url) def delete(self, request, *args, **kwargs): return self._delete() class BaseDeleteView(DeletionMixin, FormMixin, BaseDetailView): ... def form_valid(self, form): return self._delete() ```
Is this conditional really necessary? If it is, it means that in some cases a success message with placeholders could be returned, that sounds bad.
Chop the ticket number `(#25253)`.
I think a list comprehension would be more readable.
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
We should move `Foo.objects.create()` outside the context manager, i.e. ```python with connection.schema_editor() as editor: editor.alter_field(Foo, old_field, new_field, strict=True) Foo.objects.create() ```
```suggestion return '-' + value if neg else int(value) ```
I think you want: `'{0:f}'.format(d)`
```suggestion return '-' + value if neg else value ```
Out of curiosity, when does `'E'` is present in `str(number)`? Trying to figure out when the `lower()` call is necessary.
@charettes Hmm. Maybe it doesn't... 🤔 My mum would call that "belt and braces".
I don't see a reason for modifying a source exception, you can use: ```python raise ValueError(...) from e ``` Also `blew up` is not a appropriate wording and a new exception is not more informative because it refers to the field class `... the field <django.db.models.fields.CharField>` instead of `<app_label>.<model_name>.<field_name>`, maybe: ```python raise ValueError('Error during %s serializing: %s' % (field, e)) from e ``` I don't have a quick answer how to get a field path.
Thanks for updates :+1: > ... but I had trouble getting the field name, any ideas on that one? Unfortunately not, moreover I'm afraid that we will not be able to get `<app label>.<model name>.<field name>` or even `<app label>.<model name>` in a reliable way. We serialize `field` from `django.db.models` not a model attribute, that's why it's complicated or even not feasible. Each approach doesn't work in some cases, e.g. constructing messages in the `FunctionTypeSerializer` will not work for `lambda`s defined in the module: ``` Error during serializing test_one.models.<lambda>: ... ``` or imported from other modules: ``` ValueError: Error during serializing test_one.utils.<lambda>: ... ``` I think we should close this as wontfix :disappointed:
This check is also redundant.
Wouldn't be required if you subclasses `IntegerField`.
Oh, no, OK, the nextval will always return a different value. It's just that we might have gaps if one value is not saved.
You can drop this assertion, the way `from_date` is constructed and that this branch is behind the `if day` one makes it impossible to reach.
actually I think we should set these 3 values from `none_value` in an else after the new elif I suggested above and then remove them as class attributes. There's an issue if someone has subclassed the widget and set `none_value` -- that value would be ignored with this change.
Use hanging indent: ``` python RangesModel.objects.create( ints=None, dates=(cls.dates[0], cls.dates[3]), timestamps=(cls.timestamps[0], cls.timestamps[3])) ) ```
Could you remove this outer try/except (it was only for debugging)? The build is failing because `print` needs to be `print(e)` for Python 3 compatibility but that can be removed anyway.
I'd go with `elif empty_label is not None:` and remove the next line
Use `assertContains()/assertNotContains()` instead.
Single line here is fine (as the style guide says, we allow up to 119 characters if it improve readability).
put this tuple on a single line
I don't think this test is needed. The default implementation is already tested as well as overriding the method.
Blank line not needed.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
Perhaps the full list could be a class attribute so it doesn't have to be repeated several times.
title.verbose_name and same typo in else branch
IMO there is no need to check a file content: ```suggestion msg = '...' with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
I think this is fine, but if building paths with a larger number of components, it's probably better to use `.joinpath()` as it's more costly to call `.__truediv__()` many times than `.joinpath()` once. For example: ```suggestion else Path(conf.__file__).parent.joinpath("project_template", "manage.py-tpl") ```
You should use `self.m2m_db_table` instead of `self.db_table`.
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
I suggest you skip the check (`return []` early) if the intermediary model (`self.remote_field.through`) is not resolved. That is `isinstance(self.remote_field.through, six.string_types)`. Also I would store `m2m_db_table` in a variable as you'll need to reuse it to lookup `registered_tables` below.
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
Use outer double quotes to avoid backslashes.
IMO this line is unnecessary, and above `iter()` call can be removed.
This line can be removed :thinking:.
`seprate` -> `Separate`, also trailing dot is missing.
It's a bit of a shame that we have to resort to full scan of the project state but I'm afraid it's the only solution to detect `to_field` references without rendering the model states.
Alright let's keep it as it is then. I just wanted to make sure this case was covered by a test.
```python cache_params['LOCATION'] = Path(self.dirname) ```
When fixing the implementation of `RedisCacheClient.get()` to support `default`, this should work fine. ```suggestion ```
add trailing comma
Chop blank lines: ```suggestion pool_index = cache._cache._get_connection_pool_index(write=False) ```
The nested import doesn't look needed. 🤔
chop blank line
> PS - you might ask: why not fix ticket 29062 first? The reason is that fixing ticket 29062 properly would involve properly closing connections. Thus, any correct fix of ticket 29062 would be a superset of this PR, which would make it an even bigger change. Yes that was my first question :smile: Thanks for details :+1: . I'm afraid that it can be still confusing for a future me. I will try to move something to a separate commit e.g. `_make_connections_override()` which should reduce the number of changes and make it easier to bisect and fix potential regression.
Do we need this methods? Maybe I'm missing sth but thread's database connections should already by overridden, and we don't pass `connections_override` to the `_create_server()` anywhere in Django :thinking:
Again, I suspect we could use `__slots__` here: ```suggestion __slots__ = ('_connections', '_settings') ```
```suggestion raise self.exception_class(f'The connection {alias!r} doesn't exist.') ```
`assertTrue(value)` will pass for `bool(value) is True` which is different than checking for `True`.
I think at least the latter is worth it - it's confusing to submit two files and be told "the" file is empty.
These assertions are not related with this patch. Personally I don't see much value in adding them.
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
You don't need to mock, it will return `False` for a bad file descriptor.
Hey @felixxm. In the end we went for not having the "or subclassed" so these changes will disappear. (`checks.txt` did previously have this adjustment, but it's gone now. These are just leftovers to be removed.)
@carltongibson Ahh sorry :man_facepalming: I should check discussion.
Please wrap at 79 chars.
Wrap at 79 chars.
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
```suggestion is_same_domain(request_netloc, host) for host in self.allowed_origin_subdomains.get(request_scheme, ()) ```
👍 Here's a random example if you needed one: ``` >>> urlparse('http://[') ValueError: Invalid IPv6 URL ```
I had suggested doing this before computing `good_origin`: https://github.com/django/django/pull/13829#discussion_r579863426 That way you can avoid the two method calls and string construction in favor of a set membership check.
Yeah the settings dependent part could be moved into the `__init__` of the middleware I guess.
This just occurred to me, but would it make sense to structure things so the `CSRF_TRUSTED_ORIGINS` processing can be done just once instead of with each request? (There is similar parsing / processing [below](https://github.com/django/django/pull/13829/files#diff-eaa105f5b436e20dd838c27c7a753ef4cf888edcc8f868c084600f6cb7343166R314-R317) in the referer checking.)
The code I proposed sets the same content in the variable with the same length. It's not a major change, just a small improvement. IMO
couldn't we use the following code here? ``` import string RANDOM_STRING_CHARS = string.ascii_letters + string.digits ```
I would add a docstring, e.g. ``` """Algorithm is not supported by hashlib.""" ```
This should be a subclass of `ValueError`, IMO.
While I realize we cannot change that now, do we remember why we added `django.http.cookies` here? The salt alone should make sure that we do not clash with other signatures.
Chop blank line.
Use a descriptive name, not Ticket22550.
IMO this is not a proper fix because `CustomPK` doesn't appear in a `FOR UPDATE OF` statement, so this can cause a data loss. Both models should be included.
We should also test for `events = Event.objects.filter(group__in=groups.query)` to test both `isinstance(self.rhs, QuerySet)` branches.
Good catch, I think it might be worth doing and testing for yes.
I'd use a semantic test name like `test_error_raised_on_filter_with_dictionary`
prefer the context manager version: ``` self.assertRaisesMessage(FieldError, 'Cannot ..'): Note.objects.filter({'note': 'n1', 'misc': 'foo'}) ```
I feel worried about keeping a `while True` loop here. I will lead to an infinite test run if the implementation of the code to be tested is broken. Can you change that into a for loop. You are already counting `i` upwards, but aren't using it.
You can use `assertRaisesMessage(FieldError, '...', Note.objects.filter, kws)` instead of the `lambda` here. I think it'd improve readability a bit.
`context.exception.message` -> `six.text_type(context.exception)`
In cases like this, we prefer to include a trailing comma so if more items are later added, we don't need to modify this line again.
checking the results of the query would be useful. ``` self.assertEqual( Pet.objects.prefetch_related('fleas_hosted').values_list('id', flat=True), [...], ) ```
Assuming you use `NotSupportedError`, I think checking for the exception class is enough and is more robust.
I wonder if you might add an assertion that the `_iterable_class` for `Teacher.objects_custom.all()` is `ModelIterableSubclass` just to be sure that isn't inadvertently refactored away in some future change.
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
Since this might not be obvious from the method implementation, it's probably worth spelling out with another sentence in the docstring: "A verbosity of 1 logs INFO (the default level) or above, and verbosity 2 or higher logs all levels" (can go on a separate line).
I think something like, "Log the message at the given logging level." would be a bit better. (PEP 8 says no "s" at the end of "Log," by the way.)
+1, keep self.verbosity because third-party packages will assume ```self.verbosity``` is part of DiscoverRunner. This is a breaking change that's out of the scope of the PR.
It simplifies getting the default behavior for callers defining functions that pass through a logging level because they can just pass `None` for the default, instead of having to hard-code the default in a second location or invoke the function in a different way (without passing the argument).
The default level should be `logging.INFO` rather than `DEBUG`. However, I would implement this by making the default `None` (`level=None`) and interpreting `None` as `logging.INFO` in the body of the method.
Please use the helper methods `self.assertOperationType()` et. al.
Can you also check for `questioner.ask_auto_now_add_addition` to be called 3 times, please or is this something we don't do in here but in commands.
`s/_managed/_unmanaged/` I think.
Replace "items" with "values"
Could you add an `assetNumberMigrations` before the `assertOperationTypes` and join the `assertOperationAttribute` checks; they take `**kwargs`.
@hannseman Thanks :+1: > I prefer it over the mixin approach. Yes me too :+1: . We can move `Value()` wrapping to the `__init__()` and simplify it a bit, e.g.: ```python class SearchConfig(Expression): def __init__(self, config): super().__init__(output_field=None) if not (config and hasattr(config, 'resolve_expression')): config = Value(config) self.config = config def resolve_expression(self, query=None, allow_joins=True, reuse=None, summarize=False, for_save=False): resolved = super().resolve_expression(query, allow_joins, reuse, summarize, for_save) resolved.config = self.config.resolve_expression(query, allow_joins, reuse, summarize, for_save) return resolved def as_sql(self, compiler, connection): sql, params = compiler.compile(self.config) return '%s::regconfig' % sql, params ``` Please move introducing a `SearchConfig` expression to the separate commit, or even PR.
I would prefer to wrap value with `Value()` and compile `options` separately.
IMO we should check options against PostreSQL names.
append instead of creating a new list ```suggestion options_params.append(', '.join(options)) ``` All off the above could also be reduced to ```python options_params.append(', '.join( '%s=%s' % (option, psycopg2.extensions.adapt(value).getquoted().decode()) for option, value in options.items() ))
The usual pattern is to implement `get_source_expressions` and `set_source_expressions`. ```python def get_source_expressions(self): return [self.config] def set_source_expressions(self, expressions): self.config, = expressions
I don't think this is necessary - this is a developer only message - it will never be displayed to end users.
This doesn't look correct... Did you mean something like: ```python ctypes.add(None) searched_perms.extend((None, perm) for perm in getattr(settings, 'GLOBAL_PERMS', [])) ```
prefer the context manager version of `self.assertRaisesMessage()`
I guess some tests might be needed for the router stuff.
It's not required here. It was used in f179113e6cbc8ba0a8d4e87e1d4410fb61d63e75 because we were handling a possible `IntegrityError`.
You can define an `as_sqlite` method for this case.
`# Check that ...`
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
Similarly, I don't see much advantage to creating indirection with a method.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
The log message makes no sense. You are trying to normalize (or rather kludge) something that should be a locale to be a language code/tag, to then convert to a locale. But you are saying the locale has been normalized to a language code/tag which is incorrect. A language code/tag is not a locale, and here we *should be providing a locale*, hence my misgivings already stated about this whole thing. Regardless, you probably want to do this: ```python def normalize_locale(original, stdout): """ Normalizes incorrect locale strings, e.g. zh-cn, zh_cn, ZH-CN are converted to zh_CN. """ corrected = to_locale(original.lower().replace('_', '-')) if original != corrected: stdout.write('Normalized %s to %s.' % (original, corrected)) return corrected ```
That docstring doesn't add much info. It isn't useful to paraphrase a function's signature!
) goes on the next line.
I think we can remove `tearDown()` and `setUp()` and use ```python with translation.override(language): ``` instead of `activate()`.
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
check flake8 ("missing whitespace around operator" here)
`self.assertRaisesMessage()` (if all sublcasses inherit from Django's test case)
Use single quotes unless a string contains double quotes. Also, this looks fine to fine on the line above.
Might want to squeeze all lines to follow the _style_ of the test module.
Could this test be moved to `BaseCacheTests` under `test_empty_cull` to make sure the implementation works on all backends instead of only the database one? https://github.com/django/django/blob/0bebe5266f2e52a76fcf6d23b76942399d087bf2/tests/cache/tests.py#L601-L622
the wording used for similar options is simply "Can be used multiple times."
Single quotes, trailing dot.
Unrelated, but I wonder if we need '-k', '-r', '-d' for the new options rather than only their verbose counterparts. Seems like we are going to run into a conflict a some point with two options with the same first letter if we keep doing that.
Please add trailing comma.
In the usual case for using this, it wouldn't be because "an initial migration has been applied before,", it'd be because the database pre-existed any (Django) migrations at all. Also, it's really the contents of your initial migration file that you need to compare to, not your model definitions. Suggested wording: "Detect if tables already exist and fake-apply initial migrations if so. Make sure that the current database schema matches your initial migration before using this flag!" As a bonus, this also hints at the fact that the automated check here is no more sophisticated than just checking if tables exist.
FWIW I made sure we don't forget to remove these methods [when we drop support for Python 2](https://code.djangoproject.com/ticket/23919).
[Python 3 defaults `__ne__` as the opposite of `__eq__`](https://docs.python.org/3/reference/datamodel.html#object.__ne__). So I think we could drop this method.
`CheckConstraint`, `UniqueConstraint` and `ExclusionConstraint` inherit form `BaseConstraint` it should be fine to call `super().__eq__(other)` if an other's class doesn't match, e.g. ```python def __eq__(self, other): if isinstance(other, UniqueConstraint): return ( self.name == other.name and self.fields == other.fields and self.condition == other.condition ) return super().__eq__(other) ```
~Is this only required for the specifics of the test cases, or is it required to satisfy the merging and sorting in `Media` itself? If the former, all well and good, if the latter, would that need to be part of the `Paths as objects` interface contract?~ Oh I guess it's the `and be hashable` part already. My bad, ignore!
Is this a typo? ```suggestion def __ge__(self, other): ```
Ahh, right, so :wink: : ```python for error in _search_form.errors.values(): ```
The output here is suboptimal. e.g.`* p * Ensure this value is greater than or equal to 0` We need to provide custom error messages that make sense when displayed as `messages`. We should maybe add the individual messages, in a loop, rather than the list.
Using messages might work.
Simply access `form.cleaned_data` instead.
It would probably be better to check `cl.queryset.query.distinct`
I know this is just a test, but to increase future readability I would suggest using talking names and not single characters (e.g. `c`, `t`, `x`) to store variables, and I would also remove unnecessary blank lines
I updated variable names. > and I would also remove unnecessary blank lines I don't see any unnecessary blank lines :thinking:
```suggestion """The cache instance is different for each thread.""" ```
Please swap the order in the assertions and put `response` on the left, `self.assertEqual(response['Expires'], 'Sun, 17 Jul 2016 10:00:02 GMT')`
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
Can we adjust the test name. We know this is `modelchoicefield`, because the whole `TestCase` is called that, so we can drop that. Maybe... `test_initial_accepts_model_instance_for_validation_when_field_disabled`? It's a bit long and horrible but... (???: suggestions welcome!)
It's better to use `assertIs(..., False)` since `assertFalse` will also pass if `bool(result) is False`.
These assertions are not related with a bugfix, please move them to a separate commit.
I will move this test to the `model_forms/tests.py`.
I think we should revert the logging changes as it appears we're adding additional logging calls where they didn't exist before.
My mistake on 500, but "NOT FOUND" is different from "Not Found"
I think `get_exception_response` would be a better name for the method.
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
I would prefer to omit it for now.
I should have been clearer but `firstname` and `lastname` can be omited as they'll default to `''` if missing.
~~Are you sure the `Value` wrapping and the `output_field` are necessary here? As long as you pass an `output_field=models.BooleanField()` to `Case.__init__` you should be good to go.`~~ _Edit: Well it looks like passing `output_field=models.BooleanField()` to `Case.__init__` doesn't work yet._
FWIW `Q(Exists(is_ceo)) | Q(Exists(is_poc))` already works and `Exists(is_ceo) | Exists(is_poc)` doesn't require much changes. ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 5b82ae97a7..d18de75e9a 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -101,6 +101,8 @@ class Combinable: return self._combine(other, self.BITRIGHTSHIFT, False) def __or__(self, other): + if getattr(self, 'conditional', False) and getattr(other, 'conditional', False): + return Q(self) | Q(other) raise NotImplementedError( "Use .bitand() and .bitor() for bitwise logical operations." ) diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py index 6c00f813d9..d3d75f1ce1 100644 --- a/tests/expressions/tests.py +++ b/tests/expressions/tests.py @@ -595,11 +595,9 @@ class BasicExpressionsTests(TestCase): def test_case_valid_in_filter_if_boolean_output_field(self): is_ceo = Company.objects.filter(ceo=OuterRef('pk')) is_poc = Company.objects.filter(point_of_contact=OuterRef('pk')) - outer_1 = Employee.objects.filter(Case( - When(Exists(is_ceo), then=Value(True)), - When(Exists(is_poc), then=Value(True)), - default=Value(False, output_field=models.BooleanField()) - )) + outer_1 = Employee.objects.filter( + Exists(is_ceo) | Exists(is_poc) + ) self.assertQuerysetEqual( outer_1, ['<Employee: Joe Smith>', '<Employee: Frank Meyer>', '<Employee: Max Mustermann>'], ```
You can drop all the `firstname`, `lastname` above and default to `''`. Also could create a single `Employee` and use `cnt__gt=0` below.
Not necessary AFAIK; `values('cnt')` infers it.
```suggestion """ ```
From what I understand, the point of being able to turn off durability checking (via `ensure_durability`) is that durable atomic blocks _will_ be able to be run within a `TestCase`. So I think it's correct that it should ignore, rather than error.
This flag is ignored when `ensure_durability` is `False`, so we should inform users that is not allowed, e.g. ```diff (django-test) git:pr/13708 felixx@felixx-A555:~/repo/django/tests> git diff diff --git a/django/db/transaction.py b/django/db/transaction.py index c6ba346a99..8a84b97237 100644 --- a/django/db/transaction.py +++ b/django/db/transaction.py @@ -172,6 +172,11 @@ class Atomic(ContextDecorator): self.using = using self.savepoint = savepoint self.durable = durable + if self.durable and not self.ensure_durability: + raise ValueError( + 'A durable atomic block is not allowed. If you are running ' + 'tests, you must use TransactionTestCase, not TestCase.' + ) def __enter__(self): connection = get_connection(self.using) ``` We can be descriptive here.
That's actually the last name of a character in the comic these tests are based upon :-)
should lock -> locks
The primary key attribute can only be retrieved on certain databases, this will not work on Oracle or MySQL.
Tests for `formset_factory()` and `formset_factory()` are missing.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
Please chop unnecessary blank lines.
Add trailing comma.
I don't think it really make sense to pass recipient_list... the point of using `email_user` is to send mail to `AbstractUser.email`
include trailing , (that way if more values are added in the future, we won't have to edit this line again)
the dictionary key/values should be indented
Both `response` vars are unused.
Unless I'm missing something, this should be: ``` send_mail(subject, message, from_email, [self.email], **kwargs) ``` why the change to `from_email=None` and removing `[self.email]`? Also, don't remove the double newline above `class User`
```suggestion Update a queryset using order_by on a unique constraint. ```
I would move this docstring to the class: ```python class MySQLUpdateOrderByTest(TestCase): """Update field with a unique constraint using an ordered queryset.""" ```
This should be `+1` because `+2` works even without including `ORDER BY` clauses.
The `.all()` is redundant ```suggestion updated_count = UniqueNumber.objects.order_by('-number', 'id').update(number=F('number') + 1) ```
You could use `self.subTest()`, e.g. ```python def test_order_by_update_on_unique_constraint(self): tests = [ ('-number', 'id'), (F('number').desc(), 'id'), (F('number') * -1,), ] for ordering in tests: with self.subTest(ordering=ordering): updated_count = UniqueNumber.objects.order_by(*ordering).update( number=F('number') + 1, ) self.assertEqual(updated_count, 2) ```
There should be a sane API through `schema` ( A SchemaEditor, I presume) to do this.
At the point where the instance is created, there is not access to the model or its fields (we are in a nested class in the model class definition). Options and/or the modelbase metaclass, will have to connect the model to the index.
I think this could be `@cached_property` so it doesn't have to be calculated on every access.
Use single quotes
Any problem with allowing `self.model = None`. I think conditional attributes which require `hasattr` isn't the best design.
comma after tuple
Looking at this, this one picks first source as self.source. Above self.col is picked from last target. Should we just throw an error for multicolumn expressions? I bet they don't work currently in any sane way, so lets not pretend they work.
This loop seems strange to say the least - all but last result are overwritten by the looping.
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
Unfortunately annotation names can contain LOOKUP_SEP - that is the reason why the ugly refs_aggregate method was added. For example qs.annotate(Max('id')) will create an annotation named max__id, and that can't be referred if the code checks for len(field_list) == 1.
This is unlikely to be enough as JSON can have an array or string as it's top-level data type.
The docs say, "For performance reasons, `from_db_value` is not implemented as a no-op on fields which do not require it (all Django fields)."
I'm not a fan of aliasing builtin names.
```python kwargs = {'reuse': can_reuse, 'allow_joins': allow_joins} if isinstance(value, F): kwargs['simple_col'] = simple_col value = value.resolve_expression(self, **kwargs) ```
I meant changing the signature of `apply_converters()` to: ``` @staticmethod def apply_converters(self, connection, rows, converters): ``` I guess that change doesn't make much sense given `apply_converters()` is called in some other places.
Yeah, screw that :D in the worst case make it an attribute on the CSRF class, so a user can override it if we go down the route with an extra class.
In the DutH sprints, @raphaelm and I considered an option to make `CSRF_USE_SESSIONS` default to "use sessions if sessions are being used in the project". We found it a bit too "magical", so we dropped it. Since the default project template does use sessions, and is likely to prefer to use sessions for CSRF too, it would be nice to make this default to `True`. Regretfully, this would introduce a backwards-incompatibility with AJAX code. I suggest, though, that we add `CSRF_USE_SESSIONS = True` to the default new-project template.
Use single quotes to stay consistent with the code above.
Yes, just be careful not to mess up the `else:` case below
Is there any reason you are not using `request.get_port` like above? I also do not like the duplication, can you set `good_referer` before like: ``` good_referer = settings.SESSION_COOKIE_DOMAIN if settings.USE_CSRF_SESSIONS else settings.CSRF_COOKIE_DOMAIN ``` and then simply check on ``` if good_referer is not None and … ```
Given `self.inner_votes` is an instance of `collections.Counter` this could be simplified to `self.inner_votes.update(inner_votes)`.
"Considre case" > "Consider the case".
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
I wasn't suggested that, but perhaps it would make the test more readable/clear, lest someone copy the current pattern.
This can be single-lined.
:+1: using a single query with `annotate()` should help here.
assertEquals (deprecated alias) -> assertEqual I would also reverse the order of the arguments and use `self.assertEqual(Article.objects.all().count(), 0)`. That is what I have seen most often in tests.
You can reuse `Article`, e.g. ```suggestion Article.objects.filter(headline='Article 1').update(author=self.author_1) Article.objects.filter(headline='Article 2').update(author=self.author_1) Article.objects.filter(headline='Article 3').update(author=self.author_1) Article.objects.filter(headline='Article 4').update(author=self.author_2) articles = Article.objects.values('author').annotate(count=Count('author')) self.assertCountEqual(articles, [ {'author': self.author_1.pk, 'count': 3}, {'author': self.author_2.pk, 'count': 1}, ]) ```
would be fine to use double quotes so you don't have to escape the single
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
I think we are missing the `call_command()` here.
```suggestion content = app_path.joinpath("apps.py").read_text(encoding="utf8") ```
This test is passing even without a fix.
@codingjoe unless I'm missing something that would require stopping to use a list comprehension. I guess the `alias` checking could be broken to a new line ```python expressions = [pk] + [ expr for expr in expressions if expr in having or ( getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases ) ] ```
Instead of "set expressions to that field" maybe it would be better to say, "group by that field, HAVING expressions, and ..." since it's more useful to explain what the assignment means.
RawSQL needs to be added to the group by clause, we can't know if it refers to something that doesn't have an existing alias. Getting CombinedExpression and Date here seems curious. These should be fixable, but lets not do it in this patch.
We should test with a different expression since this might be fixed in the future ```suggestion expr = ExpressionWrapper(Lower('field'), output_field=IntegerField()) self.assertEqual(expr.get_group_by_cols(alias=None), [expr.expression]) ```
Use hanging indentation: ```suggestion raise exceptions.FieldError( "Cannot compute %s('%s'): '%s' is an aggregate" % (annotation.name, name, name) ) ```
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
`print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-'))`
We should validate `self.requires_system_checks`, currently we run all checks also for any truthy value e.g. `requires_system_checks = 'x'`, maybe ```python if not isinstance(value, (list, tuple)) and value != '__all__': raise TypeError(...) ```
I think the `@property` syntax would be more readable here.
I moved this test to the `tests/messages_tests/tests.py`.
prefer hanging indent: ``` self.assertEqual( len(calls), 1, "..." ) ```
Add a trailing comma so if more items are added later we don't have to modify this line again.
You can simplify this with `assertLogs()`: ```suggestion url = reverse('test_with_sidebar:auth_user_changelist') with self.assertRaisesMessage(AssertionError, 'no logs'): with self.assertLogs('django.template', 'DEBUG'): self.client.get(url) ```
You don't need to wrap a connection, you should be able to use `CaptureQueriesContext()` with `commit()` and `rollback()` and test captured queries.
I think a simple `django.template.Context` will do here.
What I'd prefer is a proper enum type, but we don't have one that we've adopted for use in Django. Lacking that, I don't think there's really much difference between True/False/PROXY_PARENTS and ALL/NONE/PROXY_PARENTS.
Are you using PROXY_PARENTS as some type of flag? We already went through the "flags" path throughout the Meta API refactor and ended by removing it because it required imports. Even though this is an internal function, I would advise to find a better solution because, personally, I don't think it's good practice to have one argument that can be of different types (in this case, boolean or object) as it increases the risk of bugs, and it also can be confusing to other people. But that's just me.
I think this docstring should also explain the meaning of the three possible values of `include_parents`
recopied (no dash) get a different
Indentation can do a lot for legibility here: ``` fields.update( (field, (field.name, field.attname)) for field in self.local_fields if include_non_concrete or field.column is not None ) ```
What about m2m and reverse relationships? Something like `Q(cities=3)` will also produce the join.
If it's an expression its source expression tree should be walked (recursive `get_source_expressions`) and when the expression `isinstance(expr, str)` then you'd need to use split it using `LOOKUP_SEP`. The first part should be used to retrieve the field (`_meta.get_field(parts[0])`). If it's a related field (`field.remote_field is not None`) then you are trying to `JOIN` and it's disallowed.
Looks like we just need to use `_meta._get_fields(reverse=False)`.
I think the function can be simplified to ```python @classmethod def _get_expr_fields(cls, expr): fields = set() if isinstance(expr, Q): for child in expr.children: if isinstance(child, tuple): lookup, value = child fields.add(lookup.split(LOOKUP_SEP)[0]) fields.add(cls._get_expr_fields(value)) else: fields.update(cls._get_expr_fields(child[1])) elif isinstance(expr, F): fields.add(field.name) elif hasattr(expr, 'get_source_expressions'): for src_expr in expr.get_source_expression(): if isinstance(src_expr, str): fields.add(src_expr.split(LOOKUP_SEP)[0]) else: fields.update(cls._get_expr_fields(src_expr)) return fields ``` And you call it directly with `constraint.condition` and `constraint.check`. An alternative would be to create a `sql.Query` object and try to add the where object while disallowing joins https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/constraints.py#L101-L102 https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1361-L1362 This will raise a `FieldError` if there's an attempt at joining https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1660-L1684 But the message won't include the name of the culprit which be a blocker here if we want to provide adequate hints.
Something like ```python elif hasattr(child[1], 'get_source_expressions'): for expr in child[1].get_source_expressions(): if isinstance(expr, str): fields.add(expr.split(LOOKUP_SEP)[0]) else: fields.update(self._get_check_or_condition_fields(expr) ```
Note to self: the DEP specifies a delayed deprecation.
Yes, it looks good.
In general, this utility is long overdue. In detail, I think error_prefix is odd here -- you're essentially mixing a piece of error formatting (or even logging) with the function.
Discussion of this function is outside of the scope of this ticket, this is merely a backport of what's already in master and 1.6: https://github.com/django/django/blob/master/django/utils/module_loading.py#L12
As the code itself hints, there's no reason to assume the imported attribute is a class.
Since `separate_logs` seems like a higher-level mode that does multiple things, maybe you can make it so the mode doesn't need to be stored as an attribute. For example, the following line could write to a `self.output_stream` that defaults to `os.devnull`. When running in script mode, it could be set to `self.stdout`. It would also eliminate the need for an `if` statement.
`# Write the migrations file to the disk.` and something like `# Alternatively, makemigrations --dry-run --verbosity 3 will output the merge migrations file to stdout rather than saving the file to the disk.`
We could add this hook in a separate commit/PR.
We can use here `self.style.WARNING`.
`--prune` is ignored when `--plan` is used. Maybe we should raise an error that they're mutually exclusive.
This can be single-lined. Also, please use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion custom_libraries = conf.get('OPTIONS', {}).get('libraries', {}) ```
```suggestion def check_for_template_tags_with_the_same_name(app_configs, **kwargs): ```
`str` -> `six.string_types` for compatibility with Python 2.
Why do you continue here? `app_label` might still be invalid.
`mutliple` -> `multiple`
> Although... _Does_ TextInput support datetimes? Yes, with TextInput, the date is serialized like this: 2014-05-09 14:08:21.805873 and you can manually edit any part, including microseconds.
`hasattr` is a more idiomatic approach to this (also saves a couple lines of code), unless there is a specific reason for using an object like this.
I think that `ValidationError` is only raised out of `Field.to_python()`, not `Widget.value_from_datadict()`, so this can be simplified: ```suggestion widget = field.hidden_widget() value = self.form._widget_data_value(widget, self.html_initial_name) try: initial_value = field.to_python(value) ```
Drop the comma/space in `[FakeFieldFile(), ]`
`max_age` is not being passed into `signing.loads()`, nor is `self.serializer`. `session_dict` should be `session_data`.
This is clearly incorrect: * This will blow up if you don't have exactly two parameters. * If you had two, the output would probably be something like `?['a', 1]=['b', 2]` * The issue is due to the generator in the arguments to `str.join()`. * Why a list comprehension? I think it should remain a generator expression. A correct fix would be: ```python ('%s=%s' % (k, v) for k, v in params.items()), ```
this class has a bunch of details of WSGI environ so I think it more accurately belongs in `django.http.request`
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
This branch in untested :thinking:
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
However, I think it's worth to keep it for backends without built-in converters.
This is already covered by `tests.queries.test_db_returning.ReturningValuesTests.test_bulk_insert`, that's why `ReturningValuesTests` tests crash on SQLite 3.35+ (see #14227).
Manipulating `second` here is not strictly necessary, `first.save()` raises the `IntegrityError`. I believe the reason for `second` to be manipulated here is to show the difference with initially deferred constraints behavior. If that's the case, perhaps a function could show that the same code passes under initially deferred constraints but not under immediate constraints. Something like: ```diff diff --git a/tests/constraints/tests.py b/tests/constraints/tests.py index 067b38cfb6..b3257b6789 100644 --- a/tests/constraints/tests.py +++ b/tests/constraints/tests.py @@ -196,17 +196,17 @@ class UniqueConstraintTests(TestCase): first = Product.objects.create(name='First', shelf='Front') second = Product.objects.create(name='Second', shelf='Back') + def swap(): + first.shelf = 'Back' + second.shelf = 'Front' + first.save() + second.save() + with self.assertRaises(IntegrityError): with set_constraints(unique_shelf=IMMEDIATE): - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() first.refresh_from_db() self.assertEqual(first.shelf, 'Back') ```
use single quotes throughout params also, if the params fit on the same line as `Thing.objects.get_or_create(` that's fine. You could change "does_not_exist" to "nonexistent" and "some_value" to "b" to save a few characters if it helps with line length.
I removed it.
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
I'd move all `django.utils.encoding` import to one line.
I think "to override the login_url attribute" is more accurate.
Can you sort those attributes please
This doesn't seem correct as `SimplePoFileTests` no longer has any tests in it so now this subclass doesn't do anything.
Same here, it may just drive complexity.
I see the idea, but for me if a function is called only once and only contains some simple lines, the function call overhead is not worth it. You can let this for now and wait for the Django fellows opinion.
Remove blank line (and below).
Undo unrelated change (and below).
There is a minor behaviour change here. Previously calling `decr()` with `delta=0` would call `self._cache.decr()`, but now it'll call `self._cache.incr()` instead. In theory this shouldn't be a problem, but am highlighting it.
Similarly, it seems like `DiscoverRunner` shouldn't have to know about details like `suite.initial_settings`, `suite.serialized_contents`, and `multiprocessing.get_start_method()`. One alternative would be to make this a method of `ParallelTestSuite` called something like `initialize_suite()`. Then, inside `run_suite()` and before calling `runner.run(suite)`, `DiscoverRunner` could do a `hasattr` check for that method and call it if present.
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
```suggestion with self.time_keeper.timed('Total database setup'): ```
Please test the entire message.
I know I suggested it but I think _shadowing_ is the correct term.
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
As `BaseFormSet` is inheriting from `Renderable` we can ditch this as the definition is the same: ```suggestion ``` You can also remove `.as_table()`, `.as_p()`, and `.as_ul()`.
You could skip these, but I thought that the rewording read better. I guess if you go for the proposed `Renderable` then they'd be moved anyway and then it doesn't hurt to update them. (Also note that the docstring for `BaseFormSet.as_ul()` neglected to mention that it isn't wrapped in `<ul>`.) 🤷🏻‍♂️
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
As above, leave the docstring and change to deprecation to 2.0.
Fair, that's me misunderstanding what the tag actually does. Looks great then!
What about just adding `**kwargs` here? It should be the same but without the need for the creation of an intermediate dictionary.
This is missing other likely candidates: `y` and `yes` I'd also argue it should be simplified to be case-insensitive so that `TRUE` == `true` (which requires you actually assert the incoming `val` is actuall stringy enough to have `.lower()`, rather than simply doing an equality match against any of the values)
I typically use something like the following: ```python return str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'} ``` This works whether you pass a boolean, integer or string, although we are only expecting a string from the environment anyway. If we wanted to be strict, we should reject invalid values: ```python if str(val).lower() in {'1', 't', 'y', 'on', 'true', 'yes'}: return True if str(val).lower() in {'0', 'f', 'n', 'off', 'false', 'no'}: return False raise ValueError('Non-boolean string provided.') ```
OK, good. Thanks. I think it's fine as it is. 👍
I might handle the `if not hasattr(self, 'lastmod')` as a guard first, to get it out of the way: ```suggestion def get_latest_lastmod(self): if not hasattr(self, 'lastmod'): return None if callable(self.lastmod): try: return max([self.lastmod(item) for item in self.items()]) except TypeError: return None else: return self.lastmod ```
Correctly indent the bracket to match the `return` indentation.
Separate to this PR: Even given ticket-23403, we could perhaps look at deprecating use of `date` here. 🤔
```suggestion path( 'lastmod/get-latest-lastmod-none-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_none_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/get-latest-lastmod-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/latest-lastmod-timezone-sitemap.xml', views.index, {'sitemaps': latest_lastmod_timezone_sitemaps}, name='django.contrib.sitemaps.views.index', ), ```
actually I think the preferred solution is to omit the u'' prefix, even on Python 2. The output already includes `from __future__ import unicode_literals` so there shouldn't be a problem without it.
There's a lambda called `strip_prefix` in `inspectdb.py` that should be of use.
Yes, I think we should be able to distinguish between automatic indexes and manual indexes. It might not be possible to cover all possible cases (inspectdb doesn't aim for perfect output), but let's try our best. For example, a single-column GIST index on a geometry field is considered as the default index.
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
`'bar'` is already in `out` from the first execution of `call_command()`. You should reinstantiate or use `out.truncate(0)` before the second call.
`assertEqual` (the version you have now is a deprecated alias)
this line should be: `def __init__(self, *args, **kwargs):`
might as well use `setdefault` in the test as well
Can we move the default value? ```python def __init__(self, include_html=False, email_backend=None, reporter_class=None): ... self.reporter_class = import_string(reporter_class or 'django.views.debug.ExceptionReporter') ```
Nitpick : can we remove the parallel assignment here? I have a draft blog post on why it's slower (tuple construction just to immediately deconstruct), and less clear (if an exception is raised, unknown which variable caused it)
Any reason not to do the following? ```python return ( clean_lookup in valid_lookups or LOOKUP_SEP.join(relation_parts + [part]) in valid_lookups ) ``` A better approach would be to make `valid_lookups` a `set()` in the first place (using `add` instead of `append` above) and do: ```python clean_lookups = {LOOKUP_SEP.join(relation_parts), LOOKUP_SEP.join(relation_parts + [part])} return clean_lookups & valid_lookups ```
Make this and new_lookups sets.
No need to change this now... but would base_path = 'foo__bar', prefetch_through = '__baz' and prefetch_to_attr = '__baz_list' clarify things here? You could then append base_path and either prefetch_through or prefetch_to_attr together as needed.
Last `)` on the next line.
I think what Anssi is asking you to do is prove that the following produces LEFT OUTER joins rather than INNER JOINs. ``` class Timestamp(models.Model): at_time = models.DateTimeField() class Event(models.Model): start = models.ForeignKey(Timestamp, null=True) end = models.ForeignKey(Timestamp, null=True) actual = models.DateTimeField() start_datetime = datetime.datetime(2016, 6, 2) end_datetime = datetime.datetime(2016, 6, 4) actual = datetime.datetime(2016, 6, 3) t1 = Timestamp.objects.create(at_time=start_datetime) t2 = Timestamp.objects.create(at_time=end_datetime) Event.objects.create(start=t1, end=t2, actual=actual) Event.objects.create(start=t1, end=None, actual=actual) Event.objects.create(start=None, end=t2, actual=actual) Event.objects.create(start=None, end=None, actual=actual) # this should produce LEFT OUTER JOINS, not INNER JOIN Event.objects.filter(actual__range=[F('start__at_time'), F('end__at_time')]) ``` I'm not sure what those results will be, but the joins should be LEFT OUTER.
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
Remove extra whitespaces: ```suggestion class. If provided, tests will be shuffled within each `classes` group, but keeping tests with other tests of their TestCase class. Reversing is ```
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
This implementation seems less than ideal. We shouldn't add things to `request.META` that weren't really in the request env; this could be misleading to other middleware or view code. Seems to me we should instead make the "force logout if no header" behavior in `RemoteUserMiddleware` conditional on a class attr which defaults to `True`, then this subclass wouldn't need to do anything but override that class attr.
Indeed, you are right.
an app containing a locale folder
This can be single-lined.
Maybe: ```suggestion "file %s. Make sure the 'locale' directory exist in an " "app or LOCALE_PATHS setting is set." ```
Add trailing commas in call_commands.
I think we are missing the `call_command()` here.
I don't think this change is needed. It seems to have been applied to ensure that `CallableChoiceIterator` is used on a copied `ChoiceField`, but if it were needed then the field we are copying would already have a `CallableChoiceIterator`, which we will be copying. So the `callable(value)` if statement in `_set_choices` will never happen. In any case, it would be much nicer to write this as `result.choices = ...` rather than manually using the property.
No input; the diff matches my (vague) memories of looking at this earlier.
I've changed to a non-lambda version.
I don't think that we should pass `memo`.
I don't think it's worth adding a method for this purpose. `first_choice is not None and first_choice[0]` should do.
I would leave the first part of the sentence untouched. Also please use hanging indentation: ```suggestion print( 'The datetime and django.utils.timezone modules are available, so ' 'it is possible to provide e.g. timezone.now as a value.' ) ```
```suggestion print('Please enter the default value as valid Python.') ```
"any other input"
``` The ``default`` ... ```
`return None` doesn't appear to be necessary -- that's the default.
`self.assertRaisesMessage()` (if all sublcasses inherit from Django's test case)
`frozenset` is missing.
`out` and `err` are unused in the second call. IMO we can simplify this call, e.g.: ```python with self.assertRaises(CommandError): call_command(Command(), no_color=True, force_color=True) ```
Jinja raises `jinja2.TemplateSyntaxError` in `render()` not in `get_template()` when an error is in the included template, so that's the real usage. We don't need to mock anything here.
We need to consume the entire iterator: ``` Exception ignored in: <posix.ScandirIterator object at 0x7f5a9e95de10> ResourceWarning: unclosed scandir iterator <posix.ScandirIterator object at 0x7f5a9e95de10> ```
Maybe `_check_default_is_not_str()` -> `_check_str_default_value()`?. Please remove unused `kwargs`.
`CANONICAL_RANGE_BOUNDS` is unnecessary: ```suggestion def __init__(self, *args, default_bounds='[)', **kwargs): ```
I'd reverse the ordering and say "use list instead of []"
We can remove quotes around the `default`. Please also wrap at 79 chars.
I think that such iterables like `[None, False]` should be tuples like `(None, False)`, because it's less memory consuming and faster a bit. Anyway, it is not very important, because of small container size.
You should use `self.m2m_db_table` instead of `self.db_table`.
I suggest you skip the check (`return []` early) if the intermediary model (`self.remote_field.through`) is not resolved. That is `isinstance(self.remote_field.through, six.string_types)`. Also I would store `m2m_db_table` in a variable as you'll need to reuse it to lookup `registered_tables` below.
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
Abort early if `self.db_table is None`
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
I would add quotes: ```suggestion violation_error_message = _("Constraint '{name}' is violated.") ```
Improved typography and changed to [%-formatting](https://docs.python.org/3/library/stdtypes.html#old-string-formatting) to be consistent with other error messages.
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
Do you think `None` is better than an empty string / empty dictionary, respectively? A few other edits: https://dpaste.de/G9P3
I think you can remove this one-line method and inline the code instead.
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
More importantly I think our wsgi handler currently has the oddity to always normalize to at least /, you will never get an empty path_info iirc
This has been mentioned previously, we can't do it because updating the set in place would update the inherited tags as well. e.g. ```python @tag('foo') class Foo: pass @tag('bar') class Bar(Foo) pass ``` Using `update` would add `'bar'` to `Foo.tags`.
Please test the entire message.
Omit the outer `[]` to use a generator instead of list comprehension.
This can be single-lined: ```suggestion return (matched_tags or not tags) and not test_tags.intersection(exclude_tags) ```
I moved this test to the `tests/messages_tests/tests.py`.
Do we need to mock `log_change()`? Should not be reachable when raising a database error in `save_related()`.
> So, should I only mock `log_change()`, as it would execute the last database query in the transaction? Makes sense to me.
The primary key attribute can only be retrieved on certain databases, this will not work on Oracle or MySQL.
Deprecated `assertEquals` should be `assertEqual`.
Tests for `formset_factory()` and `formset_factory()` are missing.
Please try to stay near 80 char per line…
If 'class' is already in attrs, this should append `self.form.required_css_class` to it, not leave the value unaffected.
`attrs['class'] += ' ' + self.form.required_css_class`
don't need outer parentheses
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
This doesn't look correct... Did you mean something like: ```python ctypes.add(None) searched_perms.extend((None, perm) for perm in getattr(settings, 'GLOBAL_PERMS', [])) ```
I don't think this is necessary - this is a developer only message - it will never be displayed to end users.
prefer the context manager version of `self.assertRaisesMessage()`
Why is `force_text` needed here? `%s` should already call the correct methods.
`obj` is not passed to `get_(user|group)_permissions` since it's always equals to `None` at this point; expand the diff and look at the full body of `get_all_permissions`.
`return self.get_database_version() >= self.features.minimum_database_version`
I think it's preferred to wrap this at 79 chars: ``` f'{self.display_name} {min_db_version} or later is required ' f'(found {db_version}).' ```
Also, if you are using a context manager, it seems like you want to assert calling `is_usable()` right before you close (so after the context manager closes).
This is always truthy: ```suggestion mocked_check_database_version_supported.assert_called_once() ```
This can be dropped since `connection` is already imported in the context of the module. ```suggestion ```
I don't think so; base classes shouldn't depend on subclasses. Create a `DatabaseFeatures` subclass for the dummy backend and set the attribute there.
Nice work on `validate` 👍
Yes, that's better.
I wonder if we can just set `default_time_format` attribute.
I think it's fine to make them a bit inconsistent (at least for now). I opened an [issue](https://bugs.python.org/issue40300) in Python.
Please remove this unrelated change.
This must also take the sign into account. What about: ``` python max_length = self.max_digits + 1 # for the sign if self.decimal_places is None or self.decimal_places > 0: max_length += 1 # for the dot ``` We could also make the sign check conditional based on `min_value` and `max_value` but it would be a mess.
```suggestion return '-' + value if neg else value ```
Ah, I realized these are E128 which we are ignoring in the flake8 section of setup.cfg. I don't mind the changes, but we are ignoring it because there are 2K+ violations and seemingly not a lot of value in fixing them.
We might want to avoid doing this if `self.localize is True` since `DECIMAL_SEPARATOR` and `THOUSAND_SEPARATOR` should be taken into account in this case.
You're calling `model_name.lower()` twice in most cases
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
```suggestion def alter_model_managers(self, app_label, model_name, managers): ```
These are unnecessary ```suggestion ```
Excellent. Happy with that. So, as I have above, without any `__qualname__`-mangling, should do the trick.
I looked into why the tests are failing. It's because some internals of the URL resolver and admindocs rely on the `__name__` set here. But they could also, more accurately, use the `view_class` atttribute. Therefore I've made PR #14138 to change that. If we go that route then I think we shouldn't even set `__name__` / `__qualname__`. Leaving them as their defaults is sensible and doesn't lie (`__name__ = 'view'` , `__qualname__ = '...View.as_view.<locals>.view'`). One can differentiate class-based views with the `view_class` attribute.
To my mind the real issue here is that we shouldn't be using `update_wrapper` at all (here or above in line 76). `view` is not in any way wrapped by `cls.dispatch` or `cls`. We just happen to want to achieve something similar to what we would want to achieve if we were wrapping a function. By using `update_wrapper` we're setting the `__wrapped__` attribute, so when we call `inspect.signature` it thinks that this function is the decorator, and that the function we're actually interested in is `cls.dispatch`. That's the reason why it returns the signature from `dispatch`. We should just do the thing we want to do directly. Something along the lines of: ``` for attr in functools.WRAPPER_ASSIGNMENTS: # I'm not sure which of these we actually want try: value = getattr(cls, attr) except AttributeError: pass else: setattr(view, attr, value) view.__dict__.update(cls.dispatch.__dict__) ```
@pope1ni Sorry it took a while to get back to you - it's been a hectic 24 hours. But yes, the above seems good to me.
```suggestion # the dispatch method. Note that __name__ and __qualname__ are # intentionally left unchanged, as view_class should be used to robustly ``` A slight change of word order here makes this read more naturally.
~~IMO you should also pass args/kwargs to `FormatStylePlaceholderCursor.__init__` and change `FormatStylePlaceholderCursor` initialization e.g.:~~ ```diff diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 29ae2a6..8c1fe35 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -383,8 +383,8 @@ class FormatStylePlaceholderCursor: """ charset = 'utf-8' - def __init__(self, connection): - self.cursor = connection.cursor() + def __init__(self, connection, *args, **kwargs): + self.cursor = connection.cursor(*args, **kwargs) # Necessary to retrieve decimal values without rounding error. self.cursor.numbersAsStrings = True ```
~~You should pass args/kwargs also to Oracle cursor.~~
IMO `scrollable=False`, `withhold=self.connection.autocommit` should be add to `kwargs`.
No, args should remain. I was talking about: ```python kwargs.setdefault('scrollable', False) kwargs.setdefault('withhold', self.connection.autocommit) cursor = self.connection.cursor(name, *args, **kwargs) ```
Unswap `cursor` and `self`.
Is this test applicable to the patch anymore? It doesn't seem to me that overriding `attrs` with `render()` is related to what this patch fixes.
I'm in favor of adding this if the benefits become more than theoretical or when only Python 3.6+ is supported.
I'm not sure what Aymeric had in mind but I see that `secrets.py` does `from random import SystemRandom` so as far as I can tell, this doesn't change any behavior or add security.
This allows for backports to exist and makes the code easier to maintain
In the long run I think we should deprecate `get_random_string` in favor of similar functions provided by the `secrets` module. I didn't check whether there was a sensible transition plan to make use of `secrets` on Python 3.6 while still supporting older versions. Since this PR adds complexity without changing the behavior, I don't think it's on the right track.
```python self.assertHTMLEqual( field.widget.render('name', []), ( '<ul>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="entertainment">Entertainment</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="test">A test</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="third-test">Third</label></li>' '</ul>' ) % (self.c1.pk, self.c2.pk, self.c3.pk), ) ```
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
Despite the existing style of the first test, I would remove the intermediate `f` variable in the new tests as it'll help balance line lengths and make things more readable.
Was this intentional? Doesn't seem to be related to the task...
Does it not render with `placeholder="False"` then? Seems strange to me...
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
I don't mind, but I'm not 100% sure why this method has the `_` prefix where others don't. 🤔 (This may have been covered in the discussion.)
Use single quotes to stay consistent with the code above.
Again single quotes
Move that below the `csrf_processing_done` -- we do not need to do extra work in that case.
This is not performing any identity check so if a related module happens to have a class the same name (it's not that uncommon to have classes with the same name namespaced in different modules) then it would be considered to be the same class.
Iterating over `sys.modules` is going to be significantly slow for any medium sized Django projects.
Can you please rename this one to `ModelManagerSerializer` and let it inherit from `DeconstructableSerializer`.
Can you please rename it to `ModelManagerSerializer`. I think you just missed it.
quit() .... to avoid a dead.... (chop "we" stuff)
You can ditch the temporary variable, and just the arguments directly `__init__`.
I'd suggest a `ValueError` instead. And this requires also a test. You can see what `Substr` does.
Avoid calling `self.get_source_expressions()` twice and it becomes clearer: ```python ... expression1 = self.get_source_expressions()[0] if isinstance(expression1, Value) and expression1.value is None: raise ValueError('Oracle does not allow Value(None) for expression1.') ... ``` I've also tweaked the exception message to make it based on the argument provided in Python.
This and one above, replace `self.function = ..` with `function=...` in as_sql method call.
The problem here is that you can't just use `Value('')` for the default. If you're doing `GREATEST(date_field, other_date_field)` then coalescing a date type with a char type is going to produce an error. The type itself will probably have to accept a default. ``` sentinel = object() def __init__(self, *expressions, **kwargs): ifnull = kwargs.pop('ifnull', sentinel) if ifnull == sentinel: raise ValueError('ifnull is required') if ifnull is None: # user has asked NOT to use coalesce else: self.ifnull = self._parse_expression(ifnull) ``` And then you would use `Coalesce(expression, self.ifnull)` in the coalesce method, or completely skip calling the coalesce method if `ifnull is None`. This is just one idea, but probably the best one I have right now. I don't really like forcing a user to provide an `ifnull` though, because it feels like we're disadvantaging the user. Another idea would be to use a backend feature. Something like `greatest_least_uses_nulls`, and then the tests could switch on that feature flag to provide different test results. I'd probably like to get a rough consensus on which way to go here.
Prefer wrapping the expression in parentheses rather than using a backslash
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
I see before: `to_fields=[], from_fields=[self.object_id_field_name]` after: `to_fields=[object_id_field], from_fields=[]` I could very well be missing something...
```suggestion "%s() prohibited to prevent data loss due to unsaved " "related object '%s'." % (operation_name, field.name) ```
`CharFieldModel` -> `RangeLookupsModel`. You don't need to create new objects.
Chop blank line.
Chop blank line.
Why not `first()`? :thinking: ```suggestion ).first().ids, ```
This test is not related with the patch, I will move it to a separate commit.
Maybe something like "call_command() received unrecognized option(s) for the <foo> command: .... " I think listing all the options in the message might not be a bad idea either if it doesn't look too cluttered.
put the closing ) on the next line
I don't think that we need an internal hook.
Is this required? I think we should collect parsers and choices from sub-parsers, e.g. ```python if isinstance(opt, _SubParsersAction): for sub_opt in opt.choices.values(): actions += get_actions(sub_opt) else: actions.append(opt) ``` After that we can remove `if opt.option_strings` from `parse_args += [...`
If we skip sub-parsers as actions then all tests still pass and `if opt.option_strings` condition is not required anymore, e.g. ```python # Parser actions and actions from sub-parser choices. def get_actions(parser): for opt in parser._actions: if isinstance(opt, _SubParsersAction): for sub_opt in opt.choices.values(): yield from get_actions(sub_opt) else: yield opt parser_actions = list(get_actions(parser)) ``` That's because `dest` for sub-parsers is not a valid option and don't need to be in `dest_parameters`.
There is no need to `append()` because we have a single error: ```suggestion return [ ```
Don't really need this function I think. It's easy enough to decorator other functions if they're added (as in django/core/checks/security.py)
```suggestion 'SITE_ID must be an integer', ```
I would use `sites.E101` to separate them from checks related with `CurrentSiteManager`.
We should use `override_settings` for this, to ensure we clean up after ourselves once the test is complete, avoiding breaking unrelated tests.
I don't know that the ticket reference is necessary. We try to reserve it for obscure issues that can't be easily captured in a docstring.
chop "Test that" prefix (and just state the expected behavior)
It might be helpful to explain: "Invalid - urlparse() raises ValueError", or following the other examples: ``` >>> urlparse('https://[') ValueError: Invalid IPv6 URL ```
`HTTPS` is not necessary, so I removed this line.
put the closing parenthesis on the next line
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
It would be more elegant, and possibly more efficient, to use: ``` template_postgis = getattr(settings, 'POSTGIS_TEMPLATE', 'template_postgis') cursor.execute('SELECT 1 FROM pg_database WHERE datname = %s LIMIT 1;', template_postgis) if cursor.fetchone(): return template_postgis ``` This is how `QuerySet.exists()` is implemented.
Remove as `empty_strings_allowed = False` is inherited from `IntegerField`.
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
This is off, if the backend doesn't `supports_functions_in_defaults` the expression will be wrapped in `Value`.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
The problem is that an expression like extract(year from datefield) = 2015, then the DB will not be able to use indexes on datefield. But if you instead have datefield >= '2015-01-01' and datefield < '2016-01-01', then the db can use indexes. This is the underlying reason why we have the special year lookups.
I was asking as major databases support year extract functions, so year comparing can be done as consequent joining of a transform and standard comparison lookup. So, creating YearGt and etc lookups will become really unnecessary if year transform will just convert datetime to a year representation using EXCTRACT, YEAR or STRFTIME calls (depending on database).
put closing parenthesis on the next line
This is moved from a system check -- should the system check be removed then? (code and docs in ref/checks.txt)
Yes, it's redundant to have both. To be honest I'm unsure about the type check here. Perhaps at some point someone will ask to support duck-typing... In the current state of the path, this is also the only reason why the `BaseURL` class exists — it provides no behavior. Perhaps removing this and the base class is the best solution? I don't know how confusing the stack trace looks if there's this kind of error in the URLconf.
You could replace the `resolve_method` variable with `elif getattr(resolver, 'resolve', False)` here.
I think the formatted pattern should be wrapped in quotes. "Your URL pattern '{}' uses..".
Prefer single quotes unless the string has single quotes in it.
I'd declare this as a `test_params` variable above to avoid the funky indent.
Another option could be to refactor into 3 separate test methods that call a common helper method to run the logic currently in the loop. This can be easier to debug than assertions that run within a loop.
Subtests can also be used here.
You can use something like this (wrapping lines at 79 chars): ``` self.assertEqual( encoded, 'scrypt$16384$seasalt$Qj3+9PPyRjSJIebHnG81TMjsqtaIGxNQG/aEB/NYaf' 'TJ7tibgfYz71m0ldQESkXFRkdVCBhhY8mx7rQwite/Pw==$8$1' ) ```
Subtests can be used here (with pairs `(key, expected)`).
Maybe we should move this directly to the `RelatedLookupMixin` :thinking:, I don't have a ready answer.
Have you checked ticket-7488? If admin filters by nonexistent objects then we need to fix this in advance.
I guess you could use `self.assertIs(child.parent, parent)` to make sure the object was not recreated as well.
This is covered by other tests. We can remove it.
We can add a control assertion to confirm that a `house` is cached for the `room`: ```suggestion self.assertIs(Room.house.is_cached(self.room), True) with self.assertNumQueries(0): ```
Prefer the context manager version: ``` self.assertRaises(Resolver404): resolve(url) ```
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
Is this line correct? Above it's `subTest(url=url_name)` but then we `reverse(url_name,...)`
Will this statement will fit on a single line? (119 characters is permitted.)
Will this statement will fit on a single line? (119 characters is permitted.)
Any disadvantage to making it a separate test method instead? I guess the signal connecting might be better is `setUpClass` at that point.
chop blank line
Yea, it wasn't an entirely serious proposal. If the request comes up again, I think adding an optional `name` argument to `Signal.__init__()` might be the way to go.
@timgraham that's neat but that looks really fragile. Think `return Signal(providing_args=["app_config", "verbosity", "interactive", "using", "apps", "plan"])` where the name would end up being `'return Signal(providing_args'`) which can lead to more confusion than the actual situation. We could also make `assertSignalSent` accept a `msg` argument (like other `assert` methods do) to allow the user to disambiguate the origin of the failure. From my point of view the traceback is explicit enough to point the users at the correct location in their code base and figure out which signal was unexpectedly sent or not.
Ah ofcourse, my bad, you're right. Looks good to me.
What happens if `multiple=True` but `attrs={'multiple': False}`? If things break, it would better to raise an exception here than to allow it
Was this intentional? Doesn't seem to be related to the task...
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Use single quotes consistently.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
Thanks. There might be a bug because when I rebase https://github.com/django/django/pull/10337, `self.assertIn('unique_name', constraints)` fails on SQLite.
I know what's causing it. Let me rebase #10337 on top of this branch. That's where the `token.match(Token.Keyword, 'UNIQUE')` should live anyway.
yeah please do, that'll save me doing the rebase.
Simon, did you fix this issue in your branch? Feel free to push an update here.
@Ian-Foote I discovered an issue with this approach is that it will include inlined named foreign key and primary key constraints as well. https://www.sqlite.org/syntaxdiagrams.html#table-constraint Django doesn't create such constraint itself but usually the introspection module is supposed to be able to deal with any form of schema. I'll include the adjustments in a following commit. Thanks for the parsing logic by the way, this is really neat.
PEP 8 hedges about line breaks and binary operators but suggests ultimately that breaking before the operator is better. As long as we're touching this I would suggest breaking before the operators.
```suggestion request.method in ('GET', 'HEAD') ```
Oh, that surprises me too...
`response.request.method` would be more idiomatic.
I think the blank lines could be chopped in this test.
Do we need to do this? it is confusing (at least for me) to split and then join by `','`, maybe: ```python response.setdefault( 'Referrer-Policy', self.referrer_policy if isinstance(self.referrer_policy, str) else ','.join(self.referrer_policy), ) ```
Please wrap at 79 chars.
(Grrr. Always miss one... Done now.)
It should be possible to specify multiple values to allow for fallback where a value is not supported by a user agent: https://www.w3.org/TR/referrer-policy/#policy-token
Are you sure you want to skip if the header already exists? Another option is to append it (by setting the header twice -- don't know if Django/WSGI supports that -- or manually).
Using `int` is untested and doesn't work as expected, because it uses 1-based indexing instead of 0-based indexing.
please use longer/more descriptive names than `f` and `k`, like `f_obj` and `slice`
Casting `int` to `int` is not necessary.
I think it will be more readable to keep `int` and `slice` in separate branches, e.g.: ```python def __init__(self, f_obj, slice_obj): if isinstance(slice_obj, int): if slice_obj < 0: raise ValueError('Negative indexing is not supported.') self.low = slice_obj self.length = 1 elif isinstance(slice_obj, slice): if ( (slice_obj.start is not None and slice_obj.start < 0) or (slice_obj.stop is not None and slice_obj.stop < 0) ): raise ValueError('Negative indexing is not supported.') if slice_obj.step is not None: raise ValueError('Step argument is not supported.') self.low = 1 if slice_obj.start is None else int(slice_obj.start) + 1 self.length = None if slice_obj.stop is None else int(slice_obj.stop) - self.low + 1 else: raise TypeError('Argument to slice must be either int or slice instance.') self.expression = f_obj ```
Please use f-strings as Python 3.6+ is now the requirement More information is available including some benchmarks. https://cito.github.io/blog/f-strings/
OK, it's necessary, see `migrations.test_commands.MigrateTests.test_showmigrations_no_migrations`.
Do we need to take into account `self.ignore_no_migrations`? I don't see any tests failures after removing this check. IMO it's unnecessary.
```suggestion *app.split("."), "migrations", "0001_initial.py" ```
```suggestion content = app_path.joinpath("apps.py").read_text(encoding="utf8") ```
this should be in `finally` just in case the commands before throw an exception
This flag is ignored when `ensure_durability` is `False`, so we should inform users that is not allowed, e.g. ```diff (django-test) git:pr/13708 felixx@felixx-A555:~/repo/django/tests> git diff diff --git a/django/db/transaction.py b/django/db/transaction.py index c6ba346a99..8a84b97237 100644 --- a/django/db/transaction.py +++ b/django/db/transaction.py @@ -172,6 +172,11 @@ class Atomic(ContextDecorator): self.using = using self.savepoint = savepoint self.durable = durable + if self.durable and not self.ensure_durability: + raise ValueError( + 'A durable atomic block is not allowed. If you are running ' + 'tests, you must use TransactionTestCase, not TestCase.' + ) def __enter__(self): connection = get_connection(self.using) ``` We can be descriptive here.
From what I understand, the point of being able to turn off durability checking (via `ensure_durability`) is that durable atomic blocks _will_ be able to be run within a `TestCase`. So I think it's correct that it should ignore, rather than error.
```suggestion """ ```
That's actually the last name of a character in the comic these tests are based upon :-)
should lock -> locks
This could be moved closer to where it's used or even eliminated as an intermediate variable.
I'd say "Return a (sql, params) fragment to set a column to null or non-null as required by new_field, or None if no changes are required."
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
Use `drop=True` rather than an arg for better readability. Use a different var for `sql`here, maybe `changes_sql`? It's a little confusing to have the `sql` name reused in the next line.
```suggestion new_field.get_internal_type() in ('CharField', 'TextField')): ```
I wonder if something like `serialize_result` might be a more descriptive name for this function.
```suggestion Convert the provided model object to a dictionary that is added to the results list. ```
Ah yes. It no doubt will. (That's too much DRF that is. 🙂) We need to handle this. 👍
put `self.object.pk` on the next line include a trailing comma
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
Please remove this blank line.
Tests for this method seem missing. It seems like we need a better way to build these reprs that's not so complicated and repetitive for each index.
immediatelly -> immediately
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
If the `edges.get(None, ())` call above works comparing `key` to `None` here should also be working. I also don't know any other Python object which `str()` representation is `'None'` that are not `None` itself.
You don't need to call `keys()` here, iterating over a `dict` yields its keys.
A more succinct version might be something like: ``` python for key, subroots in self.edges.items(): if key is not None: for root in subroots: roots.extend(self._nested(root, seen, format_callback)) ```
use parentheses to avoid backslashes and I would also try to keep the comprehension on a single line as breaking it up like this makes readability more difficult IMO.
No need to cast the set into a list. You can iterate over sets.
Mapping allowing case-insensitive key lookups. Original case of keys is preserved for iteration and string representation.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
this class has a bunch of details of WSGI environ so I think it more accurately belongs in `django.http.request`
No tests fail if I remove this change. I presume it was to avoid calling `tuple()` unnecessarily? For that matter, we can just change to the following as we're always unpacking into key-value pairs: ```suggestion yield elem ``` I don't think we need any guarantees that this will return a `tuple`. Loosely it only needs return an iterable of two elements with the first being a string.
There are only two uses of `_destruct_iterable_mapping_values()` and we use this same pattern exactly. I think that you could push the `isinstance(..., Mapping)` check into that function.
`if not ... and not ...` for consistency with other similar statements...
please limit line length to 119 chars so horizontal scrolling isn't required to view the patch.
I think you missed this one in your recent updates.
Move this above `has_add_permission` for consistency.
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
Okay, super, thanks for the clarification @pope1ni. I shall take another look tomorrow and hopefully that's job done! Good work, as ever. 😉
Try to avoid `Check that` and `Check`.
`listiterator` i guess, if there can't be other types passed to the iterator creation moment (e.g. tuple)
this should be `assertIsInstance` check
`assertTrue` would be appropriate here.
Never mind, just read the whole ticket :) Maybe the initial `assertIsInstance(p.restaurant.serves_pizza, bool)` would make more sense here. Else it might end up being refactored.
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
@timgraham is ordering by the result of an aggregate allowed without subqueries? If ordering by count does not error, then it should be safe to use that ordering. If not, introducing a different field into the orderby will affect the grouping (not that you suggested that), so we'll need to look at comparing the queryset out of order if there's another assert method available that does that. I'm not able to check either of these things at the moment, but I can take a look in about 8 hours if it's not resolved.
I think the test should be split into multiple test methods, one per thing-being-tested, as above
This will work only for a simple use case, e.g. ``` python manage.py startapp test_four ../../main_directory/ticket_30618/ticket_30618/other_apps_3 ``` produces `name = '......main_directory.ticket_30618.ticket_30618.other_apps_3'`
We could use `top_dir` instead of stripping `os.sep`, e.g ```python else: top_dir = os.path.abspath(os.path.expanduser(target)) if app_or_project == 'app': self.validate_name(os.path.basename(top_dir), 'directory') ... ```
chop trailing ", "
I'd use rename_forwards/backwards for consistency with other methods like database_forwards.
It's not required here. It was used in f179113e6cbc8ba0a8d4e87e1d4410fb61d63e75 because we were handling a possible `IntegrityError`.
Is this accurate? From the looks of it, subdomains are only allowed if a '*' is in there.
In comparision to the `Refer(r)er` check we loose the possibility to override the "initial" override of `get_host`. Would this be something to worry about -- not sure, just thinking out loud…
Regarding the referrer checking, given the length and complexity of the containing function, I was thinking it would be good to have that in a separate function, too. But I didn't want to suggest changes outside the scope of your change. I think either signature you proposed would be an improvement. (Another option, in between, would be to pass `good_origin` and `request.META`.) Perhaps the decision can be guided by what the signatures would be for other portions of the logic if they were similarly broken out (for parallel structure).
What about changing the signature to `_origin_verified(expected_origin, request_origin)` -- this way we'd decouple it from the request and would allow for easy testing. Granted the naming of the params might need a little bit of thinking but you get the idea :)
Right, my bad.
While this duplicates, it seems like an improvement in readability since `j` is eliminated.
This branch in untested :thinking:
use dict comprehension: `{op: set() for op in ops}` (although maybe you could use defaultdict too)
Ah I see. I wasn't aware of the different signatures available for this.
I believe this was meant to be a `references` check instead of a `reduce` check? Since `reduce` returns operations, not a boolean. Something like "`not op.references(other)`" so that we can ensure that `other` can properly be pulled forwards
A list comprehension is preferable here as `str.join()` converts to list internally anyway. ```suggestion ', '.join([ f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields) ]), ```
Spaces around `=` and PostgreSQL docs have `EXCLUDED`. ```suggestion ', '.join(f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields or ())), ```
As far as I'm aware `unique_fields` should be required when `supports_update_conflicts_with_target` is `True`, so there is no need to use `unique_fields or ()`. Moreover, we should raise an exception when it's not provided.
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
Chop blank line.
You can reuse existing models, by adding e.g. `Entity`: ```python class Entity(models.Model): pass class Country(Entity): ... ```
`CustomUserWithM2MAndThrough` -> `CustomUserWithM2MThrough`
Per pep8, this should be `max_length=10` (note the lack of whitespace around the equal sign).
Nice touch to follow the previous model's docstring, but I think this one should simply be: `Model with FK to a model with a CharField primarey key, #21194` The `{Null,}BooleanField` of the previous one just means `NullBooleanField and BooleanField`.
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
Store the result of `self.get_view_on_site_url(obj)` as a local variable to avoid two function calls.
``` When the object has a ManyToManyField to Site, redirect to the current site only if it's attached to the object.
If you want to use a new name, that's okay with me, but I think `'has_file_field'` should remain for backwards compatibility.
Please use single quotes.
can you call `sort` on the invalid_apps before joining them, please.
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
if no app*
Please revert unrelated cosmetic changes to keep the diff clean.
I would not recommend any alternatives: ```suggestion f"Cannot update applied migration {migration}." ```
We could lowercase the vendored files, that would help at least for the `zh-*` variants.
Use single quotes consistently.
Cannot this information solely be extracted from the model itself? ie `.model._meta.app_label`.
It seems this URL doesn't work anymore.
no restructured text (:class:) in docstrings please
Please remove the unnecessary trailing comma and space.
Please remove the unnecessary trailing comma and space.
I would change it to the `DatabaseFeature.supports_collation_on_charfield`.
```suggestion row = cursor.execute(""" SELECT sql FROM sqlite_master WHERE type = 'table' AND name = %s """, [table_name]).fetchone() if not row: return {} sql = row[0] ```
```suggestion cursor.execute('DELETE FROM %s WHERE %s < %%s' % ( ```
Ditto regarding quotes and the `%s=%r` format.
This error no longer makes sense with multiple-arg aggregates. You'll either need to join the output of all source expressions so the error produces: > Cannot compute Sum(arg1, arg2): 'X' is an agggregate # (where X is either arg1 or arg2) Or you'll need a different error message for the case of `len(args) > 1`. There may be another solution (like ditching this message altogether) but I'll let you experiment with that if you like.
Try to reduce line length to make review easier.
What about ```suggestion raise FieldError('Window expressions are not allowed in this query (%s=%r)." % (field, value)) ```
I'd prefer to see two separate conditions/error messages here.
It might be better to omit the quotes around status since that's making everything seem like a string.
`not 100 < status < 599` might look simpler
No, it should be made consistent with other codes (capfirst or title, I haven't checked).
this can be 1 line (we prefer longer lines when it improves readability)
I'm not sure splitting this out to a separate function makes the code easier to follow.
Remove this blank line. (Those above and below, separating the `last_login` check are fine.)
Hey @felixxm. I looked at both of these and thought them OK because they aided readability. (Just a small visual separator between the blocks). Is your objection that to the lines themselves, or that they're unrelated to the change per se? If the latter would a separate commit be better? (Thanks!)
Please chop this unrelated blank line.
I wouldn't add the extra lines for both reasons. Not to say that mistakes aren't made, but generally if we merged a previous patch without them (at least recently when code style is more standardized than in the early days), then blank line changes probably aren't needed. Certainly putting unrelated blank line additions in a patch doesn't help keep things clean and I don't think the blank lines are so important that they deserve a commit.
Please use assertRaisesMessage to verify this is the ValueError we expect.
Ditto regarding quotes and the `%s=%r` format.
Use parentheses instead of backslash escaping ```python msg = ( 'Window expressions are not allowed in this query ("Max(Col(expressions_window_employee, ' 'expressions_window.Employee.salary)) OVER (PARTITION BY Col(expressions_window_employee, ' 'expressions_window.Employee.department))" on expressions_window.Employee.salary).' )
Try to reduce line length to make review easier.
This error no longer makes sense with multiple-arg aggregates. You'll either need to join the output of all source expressions so the error produces: > Cannot compute Sum(arg1, arg2): 'X' is an agggregate # (where X is either arg1 or arg2) Or you'll need a different error message for the case of `len(args) > 1`. There may be another solution (like ditching this message altogether) but I'll let you experiment with that if you like.
Ditto about `msg` in both cases.
How about making these two flags `False` by default, thus making the feature not causing backwards incompatible changes.
I had imagined this flag would be removed, but if you think it will be useful for other backends, I don't mind keeping it. It's difficult to know which tests to apply it to without any backends in core that use it though.
We don't need this feature flag since it's PostgreSQL-specific feature available from `django.contrib.postgres.fields`.
Shouldn't this be named? ```suggestion collate_as_index_expression = False ```
We should add release notes for these feature flags.
How about this? ```python for field_name in self.UserModel.REQUIRED_FIELDS: value = options.get(field_name, os.environ.get('DJANGO_SUPERUSER_' + field_name.upper())) if value is None: raise CommandError('You must use --%s with --noinput.' % field_name) field = self.UserModel._meta.get_field(field_name) user_data[field_name] = field.clean(value, None) ``` Alternatively, a bit more verbose: ```python for field_name in self.UserModel.REQUIRED_FIELDS: env_var = 'DJANGO_SUPERUSER_' + field_name.upper() value = os.environ.get(env_var) value = options.get(field_name, value) if value is None: raise CommandError('You must use --%s with --noinput.' % field_name) field = self.UserModel._meta.get_field(field_name) user_data[field_name] = field.clean(value, None) ```
But still it can be simplify, e.g. ```python for field_name in self.UserModel.REQUIRED_FIELDS: env_var = 'DJANGO_SUPERUSER_' + field_name.upper() value = options[field_name] or os.environ.get(env_var) if not value: raise CommandError('You must use --%s with --noinput.' % field_name) field = self.UserModel._meta.get_field(field_name) user_data[field_name] = field.clean(value, None) ```
Ahh, I see! Thank you for the quick reply! Learning a lot from these PRs! :)
``` Superuser creation skipped due to not running in a TTY. You can run `manage.py createsuperuser` in your project to create one manually. ```
Use `self.username_field` instead.
I think having a separate base class for setting a single flag is probably overkill. If there are future changes that require more customisation then we can introduce a base class to keep things tidy. In the mean time let's not.
You can update this after 08654a99bbdd09049d682ae57cc94241534b29f0, I believe.
Ok, this is our first serious issue. I don't think window functions should be inheriting from `Aggregate`. `Aggregate` implies grouping and `GROUP BY`, but also has other properties (which might be relevant). By inheriting from `Aggregate`, the query is getting a GROUP BY added to it. ``` In [9]: books = Book.objects.annotate(before=Window( ...: expression=Lag('pages'), ...: order_by=F('pages').asc(), ...: partition_by='publisher') ...: ) In [10]: print(books.query) SELECT "aggregation_book"."id", "aggregation_book"."isbn", "aggregation_book"."name", "aggregation_book"."pages", "aggregation_book"."rating", "aggregation_book"."price", "aggregation_book"."contact_id", "aggregation_book"."publisher_id", "aggregation_book"."pubdate", LAG("aggregation_book"."pages", 1) OVER ( PARTITION BY "aggregation_book"."publisher_id" ORDER BY "aggregation_book"."pages" ASC ) AS "before" FROM "aggregation_book" GROUP BY "aggregation_book"."id" ``` That GROUP BY doesn't affect the query results, but it will (I think) add unnecessary overhead to the query execution. Now, since any Aggregate can also be used as a Window function, and those aggregates already inherit the same properties we're concerned with here, the Window function has to cater for that. It might be enough to define `contains_aggregate = False` and `def get_group_by_cols: return []` on `Window`, but you'd need to play around with that. Any window functions that can't be used as aggregates should inherit from `Func`.
I might have suggested it, but I don't think arity is useful in this type.
If you set the class attribute `arity = 1` you can remove the `__init__` altogether. Actually, if you do that, then you can drop this base class and just set `arity` on the subclasses.
@atombrella Do we need inner imports here? Imports at the top works fine for me.
FWIW in #9383 this is handled by the `RenameField` operation -- no `AlterField` operation will be generated by the auto-detector just like none are generated on a model and `to` rename.
I'd drop it, and reintroduce the test later on in branches where we'll be able to backport #9383.
This docstring is unnecessary.
should be `first_state`, not `project_state`, I suspect.
I think we cannot use decorator here. IMO we should use `property()`, e.g. ```python def property_year(self): return self.date.year property_year.admin_order_field = 'date' model_property_year = property(property_year) ``` (see similar patch for `short_description` cec9558fba1bc6401ea2ec6d71b816b4dfd31b28).
For new code, we're using single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Please use single quotes.
The indentation is a bit odd here, it gives the impression that the second line is still in the isinstance()
```suggestion Conveniently add attributes to a display function:: ```
Can you reference the ticket number in the docstring, please.
Can you reference the ticket number in the docstring, please.
You can safely join this an the next line. You have up to 119 chars per line. ;)
For the sake of clarity with the bug report, can you check for `'b"' not in output` :)
I don't think this `\nb#` is actually correct. There should be double quotes after the `b` before `#`.
"Both Y and X must be provided". Switch the Y and X in the error.
I think this should be a `ValueError`
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
Correct, but if me change `ModelState` at some point, this will work automatically or fail, telling us we did something wrong ;)
Can you use `ModelState.from_model()` here, please, as this is what the migration framework will use internally.
Shouldn't mixins be to the left of the base class `models.Model`? This is my understanding of how mixins on class-based views work anyway.
"Create" with a capital c
If you want to respect the user ability to choose their failureException ( https://github.com/python/cpython/blob/master/Lib/unittest/case.py#L357 ), you can use ``` python self.fail("Not resolved metaclass conflict") ``` instead of forcing the AssertionError. Other thought : by doing this, you may lose all the details of the original `TypeError` exception which might prove useful for debugging when the test fail (but I'm less sure about this one since I'm not sure what might trigger the `TypeError` in the first place).
Here's how I would have written it: https://gist.github.com/3911240. Hopefully it's not worse than the previous version.
Nitpicking: I would have reused the test_invalid_project_name test, looping on "for project_name in ('7testproject', '../testproject'):". This would allow us to test more names with less code duplication.
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
Ditto ```suggestion return all( not os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
an app containing a locale folder
I would use the same order as the previous two classes (`TrigramSimilarity` and `TrigramDistance`): ```suggestion class TrigramWordSimilarity(TrigramWordBase): function = 'WORD_SIMILARITY' class TrigramWordDistance(TrigramWordBase): function = '' arg_joiner = ' <<-> ' ```
I think we always want the input on the `>>` side of the operator to be able to utilise any indexes. So we get the following SQL: ```sql SELECT t, t <->> 'word' AS dist FROM test_trgm ORDER BY dist; ``` That should mean that we want `arg_joiner = ' <->> '`. <details> <summary>Index operator classes query where LHS is the indexed value</summary> <code> SELECT am.amname AS index_method, opf.opfname AS opfamily_name, amop.amopopr::regoperator AS opfamily_operator FROM pg_am am, pg_opfamily opf, pg_amop amop WHERE opf.opfmethod = am.oid AND amop.amopfamily = opf.oid AND opf.opfname IN ('gist_trgm_ops', 'gin_trgm_ops') ORDER BY index_method, opfamily_name, opfamily_operator; </code> </details> ``` index_method | opfamily_name | opfamily_operator --------------+---------------+------------------- gin | gin_trgm_ops | ~(text,text) gin | gin_trgm_ops | ~~(text,text) gin | gin_trgm_ops | ~*(text,text) gin | gin_trgm_ops | ~~*(text,text) gin | gin_trgm_ops | %(text,text) gin | gin_trgm_ops | %>(text,text) gin | gin_trgm_ops | %>>(text,text) gist | gist_trgm_ops | ~(text,text) gist | gist_trgm_ops | ~~(text,text) gist | gist_trgm_ops | ~*(text,text) gist | gist_trgm_ops | ~~*(text,text) gist | gist_trgm_ops | %(text,text) gist | gist_trgm_ops | %>(text,text) gist | gist_trgm_ops | <->(text,text) gist | gist_trgm_ops | <->>(text,text) gist | gist_trgm_ops | %>>(text,text) gist | gist_trgm_ops | <->>>(text,text) (17 rows) ```
Paolo, Can you take a look? (\cc @pauloxnet) :point_up:
> .. i'll follow your decision :) Just asking, I'm not an expert :shrug:. We can wait for the second opinion from Paolo.
@felixxm yes that's what I'm thinking.
This should probably be a separate method -- perhaps, one that could be used for the insert as well. The code here should read, ``` python if self.returning_fields: r_sql, r_params = self.return_values_fragment() if r_sql: result.append(r_sql) params += r_params ``` The default `return_values_fragment()` should raise `django.db.utils.NotSupportedError`
I'll quickly check if an idea I'm having works here.
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
Inner functions are slow, especially for pypy - best to extract this!
Add trailing commas in call_commands.
Use single quotes where possible.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
I think we are missing the `call_command()` here.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
`clean` is not only for validation, but also for data modification in a form.
And I would rename this attribute `superusers` as it's meant to contain multiple users.
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
Wouldn't it be a bit more helpful for this error message to specifically note that the module with the given path couldn't be imported? "Invalid" is a very vague term, which could mean all sorts of things - it seems unhelpful to silence an `ImportError` and replace it with a much vaguer message.
(This is also more "food for thought" than an actual request for change - whatever you prefer is fine.)
`hasattr` is ugly because of its propensity to silently hide `AttributeError`, and because of its look-before-you-leap inefficiency. I would avoid it and instead use something like: ``` password_changed = getattr(validator, 'password_changed', lambda *a: None) password_changed(password, user) ```
Never mind, even such an API would be useless since the raw password is no longer available after its initially set. So there really is no way around that limitation of this validator.
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
prefer hanging style: ``` return { self.fk_field: ..., } ```
better name? `get_filter_kargs_for_object()`
Might be nice to copy `__doc__` here as well
This would be more readable as a one-liner: `predicate = inspect.isfunction if six.PY3 else inspect.ismethod`
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
`itertools` looks unnecessary :thinking: I would use `int` variables and alphabetized hooks, e.g. ```python branch_1_call_counter = 0 branch_2_call_counter = 0 leaf_1_call_counter = 0 leaf_2_call_counter = 0 leaf_3_call_counter = 0 def leaf_1(): nonlocal leaf_1_call_counter leaf_1_call_counter += 1 def leaf_2(): nonlocal leaf_2_call_counter leaf_2_call_counter += 1 def leaf_3(): nonlocal leaf_3_call_counter leaf_3_call_counter += 1 def branch_1(): nonlocal branch_1_call_counter branch_1_call_counter += 1 transaction.on_commit(branch_2) transaction.on_commit(leaf_3) def branch_2(): nonlocal branch_2_call_counter branch_2_call_counter += 1 transaction.on_commit(leaf_1) transaction.on_commit(leaf_2) ```
Yes, `nonlocal` is necessary.
This `atomic()` is not needed. ```suggestion transaction.on_commit(branch_1) ```
```suggestion A visualization of the callback tree tested. Each node is expected to be visited only once: └─branch_1 ├─branch_2 │ ├─leaf_1 │ └─leaf_2 └─leaf_3 ```
Same here, not following order `(value, expected)`
I think we always want the input on the `>>` side of the operator to be able to utilise any indexes. So we get the following SQL: ```sql SELECT t, t <->> 'word' AS dist FROM test_trgm ORDER BY dist; ``` That should mean that we want `arg_joiner = ' <->> '`. <details> <summary>Index operator classes query where LHS is the indexed value</summary> <code> SELECT am.amname AS index_method, opf.opfname AS opfamily_name, amop.amopopr::regoperator AS opfamily_operator FROM pg_am am, pg_opfamily opf, pg_amop amop WHERE opf.opfmethod = am.oid AND amop.amopfamily = opf.oid AND opf.opfname IN ('gist_trgm_ops', 'gin_trgm_ops') ORDER BY index_method, opfamily_name, opfamily_operator; </code> </details> ``` index_method | opfamily_name | opfamily_operator --------------+---------------+------------------- gin | gin_trgm_ops | ~(text,text) gin | gin_trgm_ops | ~~(text,text) gin | gin_trgm_ops | ~*(text,text) gin | gin_trgm_ops | ~~*(text,text) gin | gin_trgm_ops | %(text,text) gin | gin_trgm_ops | %>(text,text) gin | gin_trgm_ops | %>>(text,text) gist | gist_trgm_ops | ~(text,text) gist | gist_trgm_ops | ~~(text,text) gist | gist_trgm_ops | ~*(text,text) gist | gist_trgm_ops | ~~*(text,text) gist | gist_trgm_ops | %(text,text) gist | gist_trgm_ops | %>(text,text) gist | gist_trgm_ops | <->(text,text) gist | gist_trgm_ops | <->>(text,text) gist | gist_trgm_ops | %>>(text,text) gist | gist_trgm_ops | <->>>(text,text) (17 rows) ```
Do we need to swap arguments? IMO we want to keep the same order as in `SIMILARITY()` calls. ```suggestion class TrigramWordSimilarity(TrigramBase): function = 'WORD_SIMILARITY' ``` e.g. - `TrigramWordSimilarity('Cat sat on mat.', 'cat')` should be equal to `0.30769232` instead of `1` - `TrigramWordDistance('Cat sat on mat.', 'cat')` should be equal to `0.6923077` instead of `0`
Paolo, Can you take a look? (\cc @pauloxnet) :point_up:
> .. i'll follow your decision :) Just asking, I'm not an expert :shrug:. We can wait for the second opinion from Paolo.
> Paolo, Can you take a look? (\cc @pauloxnet) point_up Sorry, I totally missed the notification of this. I'll take a look
Maybe: `if '\x00' in str(value):`
Please use single quote. `message` can be single lined.
I would say: _"""Validate that the string does not contain null characters."""_
Is `text` used? If unused, you can remove.
you can use `literal_match.group(1)` instead.
Chop blank line.
You can use `super()`: ```suggestion return super().migration_name_fragment + '_not_valid' ```
I would chop _" on all existing rows"_.
Do we need to call `str()` on `contraint_sql`? ```suggestion if contraint_sql: schema_editor.execute(constraint_sql + ' NOT VALID') ```
`constraint_name` should also be quoted.
personal preference: I think `'_language' not in request.session` reads a bit clearer.
this could be modified similar to the below for backwards compatibility I think.
replace "will be removed..." with "RemovedInDjango21Warning"
This is also wrong, `LANGUAGE_COOKIE_NAME` is the name of the cookie, not the name used in the session.
This is wrong, `SESSION_COOKIE_NAME` is the name used in the cookie, not an attribute name on the `request` object. Besides it isn't equal to `'session'` by default.
You want to avoid altering `self` here as subsequent calls will reuse this attribute even if this branch's conditions don't match.
Actually `return field.db_type(self.connection)` should be enough as it defaults to `connection.data_types.get(self.get_internal_type())` https://github.com/django/django/blob/ff5dfbc63a278219cd929449678b99ebec9a4b5f/django/db/models/fields/__init__.py#L684-L688
Makes sense. Falling back to `field.db_type(self.connection)` will cause silent truncation of `ArrayField(CharField(max_length=100)) -> ArrayField(CharField(max_length=50))` and `ArrayField(Field(), size=10) -> ArrayField(Field(), size=5)` though but I guess it's better than crashing.
Similarly, I don't see much advantage to creating indirection with a method.
I would revert this, i.e.: ```python if self.connection.mysql_is_mariadb and self.connection.mysql_version > (10, 2): return True return self._is_limited_data_type(field) ```
Remove the blank line.
Please use also use single quotes in the test where possible.
Use `showmigrations` instead of `"migrate", list=True` which is deprecated (we seem to have a bug in `@ignore_warnings` that causes it to leak state as the tests should catch the use of deprecated features and fail).
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
usual style is to put the ticket number in parenthesis at the end of the sentence
More importantly I think our wsgi handler currently has the oddity to always normalize to at least /, you will never get an empty path_info iirc
(This is also more "food for thought" than an actual request for change - whatever you prefer is fine.)
`hasattr` is ugly because of its propensity to silently hide `AttributeError`, and because of its look-before-you-leap inefficiency. I would avoid it and instead use something like: ``` password_changed = getattr(validator, 'password_changed', lambda *a: None) password_changed(password, user) ```
Very clever! I figured we were going to have to do something uglier to get at the list of default middlewares, but this works well, and as long as it runs on at least one supported Python version it should alert us to an issue; headers shouldn't ever vary between Python versions.
CurrentSiteMiddleware doesn't override `__init__()` whilst not calling `super()`, which is what gets you on this list.
@schinckel this workaround shouldn't be necessary once #9765 is merged.
Ah yes I see. Exists being a subclass of Subquery.
I'm not sure about using `Expression` here (see similar doubts in #13165) :thinking: I would rather use `WhereNode`, e.g. ```suggestion if not isinstance(self.expression, WhereNode): ``` \cc @charettes
I don't have a strong opinion here as that's probably the only type of non-`Expression` wrapper supported in `ExpressionWrapper` but the previous `if isinstance(self.expression, Expression)` felt more correct.
You could put only two spaces before the `#` while you are around.
The form class is configuration too, is it not? You can group class attributes using a blank line, but this attribute is inherited from `BaseModelAdmin` where it is not separated. It just seemed odd.
drop the new line please
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
think we can chop the blank lines in the last 3 tests
I think it's better to omit the try/except and instead say `Settings(settings_module) # should not raise an exception`. See 071801ccff970682a799ce754431a3c3ce3d6902
`None` is being passed for the `app_configs` argument - even though the check ignores `app_configs`, `[]` should be used as a more valid test value. I think it's worth looking into refactoring these tests in general, as you're write these property inner-imports are a bit confusing, made a note to self.
yeah I don't see a reason why the imports are not top-level and we don't call the functions directly.
It's the pattern that django-secure used. Not sure if the reason is still relevant. \cc @carljm
unused import (please check code with flake8 as there are some "expected 2 blank lines" warnings as well).
This is unused. Please remove it. It will fix `flake8` error.
Improved typography and changed to [%-formatting](https://docs.python.org/3/library/stdtypes.html#old-string-formatting) to be consistent with other error messages.
please alphabetize with the rest of the django imports
The `L` suffix raise a `SyntaxError` under python3. This should be `lambda: long(9999999999999999999)`.
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
missing quote after `modelname` which should also be `model_name`
Add a trailing comma.
It would have been more appropriate if `run_checks()` took an `Apps` instance as a parameter instead of a list of `AppConfig`s.
I suggest to add a line break and list models one per line with 2 spaces indentation.
`transform.lookup_name` isn't needed (same in unregister)
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
Could drop the `alias` in `setUpTestData` and `order_by('pk')` or simply use `assertCountEqual` since ordering isn't that important.
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
Please wrap at 79 chars.
Here if a field is not a ForeignKey, but have many_to_one=True then it will go through formfield_for_foreignkey(). If that method returns None, then [None will be returned](https://github.com/django/django/pull/6236/files#diff-3c42de3e53aba87b32c494f995a728dfR168) and [db_field.formfield()](https://github.com/django/django/pull/6236/files#diff-3c42de3e53aba87b32c494f995a728dfR178) won't have a chance to be called. In this case, the formfield [will be ignored by ModelForm](https://github.com/django/django/blob/master/django/forms/models.py#L182-L185). Shouldn't we have a way to use the custom field's formfield() method even if it has many_to_one=True ? Note that this concerned is similar to the one raised in #24227
Shouldn't that be `self.get_autocomplete_fields(request)`
We can safely assume `hasattr(self, 'view_on_site')` will always be `True` here.
any reason not to include `and not isinstance(self.widget, CheckboxSelectMultiple)` as before? I guess the user could still use a custom widget, but maybe not? Otherwise, seems fine.
Put the `not field.many_to_many` first and the `isinstance()` second, please.
Why `BORN` is uppercased? :thinking: ```suggestion # Add new Country from the born_country select. ```
```suggestion '<option value="" selected="">---------</option>', ```
```suggestion '<option value="" selected="">---------</option>', ```
You can move it to the top, because we have an alias.
Can we use [number_of_windows_to_be()](https://www.selenium.dev/selenium/docs/api/py/webdriver_support/selenium.webdriver.support.expected_conditions.html#selenium.webdriver.support.expected_conditions.number_of_windows_to_be)? ```suggestion self.wait_until(ec.number_of_windows_to_be(2)) ``` Also, we can probably chop `self.assertEqual(len(self.selenium.window_handles), 2)` in the next line.
`DATE` -> `DATETIME`
We use `field` only to find `internal_type`, so maybe instead of storing `field` we can find and store `internal_type` in `__init__()`? What do you think? ```python def __init__(self, field): self.internal_type = getattr(field, 'target_field', field).get_internal_type() ```
I would remove `get_field_name()` hook and call it `internal_type` (`field_name` is confusing IMO), e.g. ```python internal_type = getattr(self.field, 'target_field', self.field).get_internal_type() ```
I think we can use `int` instead of `str` as a default value, because that's the most common use case. After that we can remove all types mapped to `NATIVE_INT` from `InsertReturnParameter.types`.
Since you don't actually need the instances of all those models, can you use `WindowTestModel.objects.bulk_create()` please.
please use parentheses instead of backslash
I think we can remove this sentence.
Also please keep it as HttpResponseNotFound as bug only occurs when that view throws 404.
I think you can safely remove this.
``` py self.assertFalse(r.closed) ```
In the case of an empty select (`choices = []`), this will still output the `required` attribute, which is still not valid: ``` >>> class TestForm(Form): ... some_field = forms.ChoiceField(choices=[]) ... >>> t = TestForm() >>> print(t['some_field']) <select id="id_some_field" name="some_field" required> </select> ``` ``` html <!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <title>Validation test</title> </head> <body> <select id="id_some_field" name="some_field" required> </select> </body> </html> ``` Check it here: https://validator.w3.org/nu/#textarea
Shouldn't we handle these situations? ``` >>> class TestForm(Form): ... my_field = forms.ChoiceField(choices=[['', 'zero']]) ... >>> t = TestForm() >>> print(t['my_field']) <select id="id_my_field" name="my_field" required> <option value="" selected="selected">zero</option> </select> ``` Or this: ``` >>> class TestForm(Form): ... my_field = forms.ChoiceField(choices=[(None, 'zero')]) ... >>> t = TestForm() >>> print(t['my_field']) <select id="id_my_field" name="my_field" required> <option value="" selected="selected">zero</option> </select> ```
No need for an `else` branch as the `if` returns.
I don't think it's worth adding a method for this purpose. `first_choice is not None and first_choice[0]` should do.
You are right! I assumed `render_option` was always converting falsy values to an empty string. It might be worth keeping the method in this case.
I meant `self.table or '(default)'` seems more neat and intuitive, but this way it is more explicit. :)
I think it makes sense to use the same order like in `describe()`.
Please chop all unnecessary blank lines.
Indexes are not constraints, generally.
I would rename `self.model_name` -> `self.name` (like in `CreateModel`, `DeleteModel`, or `RenameModel`).
maybe create_and_call -> "test" to be a bit shorter
`{'connection': self.db, 'cursor': self}` is faster and imo clearer. `dict(foo=bar)` actually goes through two dict creation steps: first it creates the keyword args dict, then it finds the global name 'dict' (which could refer to anything), then it calls that name which creates the final dict.
Again, not related but use `force_raster_creation=True` rather than a tough to decipher plain boolean.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
the `reversed` call isn't free, it's slightly more optimal to put the wrappers in the list in the way you want to iterate them
`.all()[0]` -> `.first()`
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
`assertNotContains` is a bit fragile; instead I'd like if you could check `response.context` variables.
I'm unsure the purpose of `ugettext_lazy` here.
I tried a similar approach while working on acfaec3db5ba39de52f6e607e74343dccf72fba1 and came to the conclusion that this approach can't work (due to something like module caching). As far as I know, you'll have to register the admin to a separate `AdminSite`.
`.all()[0]` -> `.first()`
I'm unsure the purpose of `ugettext_lazy` here.
`assertNotContains` is a bit fragile; instead I'd like if you could check `response.context` variables.
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
Prefer this indent style: ``` response = self.client.post(reverse('...'), { .... }) ```
Perhaps it isn't worth breaking consistency. For sure it can wait and be done separately.
I would expect some explanation on why `quote_name` is used for some names and `geo_quote_name` for others.
quote names of objects (`'CREATE INDEX "%(index)s"...'` etc). These parameters are spliced into the statement, not passed as arguments.
Actually, quoting the parameters before interpolation makes _more_ sense on Oracle than other backends, because on Oracle `quote_name` also handles shortening.
I'd use a multiline string and indent it internally. Also, remove the semicolon in the end. Doesn't do any good, and can do harm.
I think we should avoid writing new test suites that use fixtures. Fixture loading is extremely slow, and it's actually harder, IMO, to follow what the data should look like once you've aggregated it. I would suggest either creating all the data in a setUp method, or creating the data you need at the top of each test.
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
put `RegrSXX,` on the next line to wrap imports at 79 characters.
I would say: `pass # psycopg2 isn't installed`
"Both Y and X must be provided". Switch the Y and X in the error.
Wording suggestion: "Rendering {% include (template_name) %} raised (error)."
rather than silenced and rendered as an empty string.
I'm not sure if the included traceback will give enough information to debug this, but it seems like a message something like "Rendering `<template name>` raised an exception, so {% include %} will render as an empty string." might be more helpful.
Adding something like this before the loop could help: ``` _bit_undefined() = object() [at module level] bit = _bit_undefined() ```
Could we maybe put this logic in a context manager or decorator? It'd be nice not to duplicate it from `render_annotated`. Quick example: ``` python from contextlib import contextmanager @contextmanager def annotate_exception(context, token): try: yield except Exception as e: if context.template.engine.debug and not hasattr(e, 'template_debug'): e.template_debug = context.template.get_exception_info(e, token) raise def stream_annotated(self, context): with annotate_exception(context, self.token): for chunk in self.stream(context): yield chunk ```
That'll be an interesting one to address when we move the schema editor to use model states instead. A problem for later :)
Omit the outer `[]` to use a generator instead of list comprehension.
I'd vote for making `returning` a `property` instead of a stealth field option at least for now because this is not something we've done in the past. ```python @property def returning(self): return hasattr(self.default, 'as_sql') AutoField.returning = True ``` That would make `DateTimeField(default=Now)` work and avoid the ambiguity of `default=Now, returning=False`. We'd still have to deal with backends that don't support returning fields.
Use `self.quote_name()` to do the quoting of fields: ```suggestion result = ', '.join(f'{field}=VALUES({field})' for field in map(self.quote_name, update_fields or ())) ```
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
It's not resolved.
When considering my above point please now target 4.1.
```suggestion elif ( on_conflict == OnConflict.Update and not self.connection.features.supports_update_conflicts_with_target ): ```
You should use `supports_update_conflicts_with_unique_fields`.
Using `self.connection.features`: ```suggestion elif ( on_conflict == OnConflict.Update and self.connection.features.supports_update_conflicts_with_target ): ```
In [the original patch](https://code.djangoproject.com/attachment/ticket/10695/defer.6.diff) provided by Alex Gaynor we have: ```python if self.field_name not in instance.__dict__: ``` but Malcolm changed this line to the ```python if data.get(self.field_name, self) is self: ``` That's why I assumed that it was possible that `instance.__dict__` contained a `DeferredAttribute` instance. :thinking:
@charettes Thanks :+1:
You can remove also lines [161-163](https://github.com/django/django/pull/13052/files#diff-77d4793905e702bfe9a8fabac708dcc7L161-L163).
I think splitting this to more lines would increase readability. Probably the same for the above with `self.relname`.
try to avoid "we", e.g. "Because it's a parent link, all the data is available in the instance, ...
Period ```suggestion 'Quit and manually define a default value in models.py.', ```
Yup, that sounds good too. :)
`later` is a bit misleading, since the expectation is that the dev will update models.py (immediately) after quitting so that they can continue to create their migrations.
here in `ask_not_null_addition ` the text is `[...] without specifying a default; because the [...]` but in `ask_not_null_alteration` it is `[...] without providing a default because the [...]` without the semicolon. Both should probably be the same, and personally something _feels_ off about having a because preceded by a semicolon. (though I can't codify the rule as to _why_ in my head), YMMV.
This sentence is too long, IMO. Maybe: ```python choice = self._choice_input( f"It is impossible to add a non-nullable field '{field_name}' " f"to {model_name} without specifying a default. This is " f"because the database needs something to populate existing " f"rows.\n" f"Please select a fix:", [ ... ```
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
This should be: ``params = config_params + params``
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
IIRC get_cols() was renamed to get_group_by_cols() some time ago - no need to have both.
Right, the check would need to happen at `NegatedExpression.resolve_expression` time to be effective. Maybe better to not be to restrictive for now.
I do realize that I'm late to the party and I was the one who suggested the introduction of `NegatedExpression` in the first place but I now wonder if simply returning `Q(self, _negated=True)` could have served the same purpose here.
Please can you duplicate this for `__rxor__()`.
I don't think we want to special case `Subquery`, feels like we'll want to duck type on `conditional` ```suggestion if not isinstance(other, Q) and not getattr(other, 'conditional', False) is True: ```
I think that we can squash this to two cases, i.e.: ```python if not self and other: return copy.deepcopy(other) elif not other: return copy.deepcopy(self) ```
replace "will be removed..." with "RemovedInDjango21Warning"
This is also wrong, `LANGUAGE_COOKIE_NAME` is the name of the cookie, not the name used in the session.
This is wrong, `SESSION_COOKIE_NAME` is the name used in the cookie, not an attribute name on the `request` object. Besides it isn't equal to `'session'` by default.
`next_` -> `next_url`
this could be modified similar to the below for backwards compatibility I think.
Add a trailing comma.
It would have been more appropriate if `run_checks()` took an `Apps` instance as a parameter instead of a list of `AppConfig`s.
missing quote after `modelname` which should also be `model_name`
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
Using `clashing_pair` in a hint is misleading. We should use appropriate model names not field names or table names.
The closing parenthesis should always go on the next line.
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
This docstring doesn't have much value, please remove it.
Please add a trailing comma.
I think you could use `self.assertSequenceEqual` rather than this.
Frankly, I don't remember the details here, and I only have time to glimpse the PR now, but it seems that there may be two cases where multiple rows of returned values may be expected: `bulk_create()` on one hand, and an `UPDATE` statement on the other (you wouldn't need to returned values in an ORM `update()` call, but you would need them in the lower-level API).
I checked and on PostgreSQL we have a list of tuples for multiple rows and a tuple for a single row; on MariaDB we have a tuple of tuples for multiple rows and a tuple for a single row :confused: It's a really implicit logic, we should support both formats in: https://github.com/django/django/blob/8f2a6c76d19e4010c4683b20ed7f1eb4b07c17eb/django/db/models/query.py#L1257-L1260
I wonder why it works without `list()` on PostgreSQL :thinking:
Do we need to call `str()` on `contraint_sql`? ```suggestion if contraint_sql: schema_editor.execute(constraint_sql + ' NOT VALID') ```
Maybe something along the lines of: For databases which do not support returning clause we need to ask the database for the id. Generally last_insert_id is only supported for serial/auto_incr columns, hence we guard it for auto field. \# TODO: Maybe add a marker to fields that their value can be returned by last_insert_id instead of a type check. +/- typos and style cleanups ;)
We don't have strict guidance about this, but I think the test you've written is sufficient. Some `Field` tests will inevitably require more specific classes.
I'd use single quotes throughout.
Use a single line. I think two CharField()s should work just as well and make the line shorter.
`# Values provided in the form's data are ignored.` Might be good to have a test for `Form(data, initial=...)` too.
no newline between fields (see style of other forms) Also, I don't think `label` and `initial` need to be specified. Try to include only the minimum functionality that's needed to reproduce the error and prove the regression is fixed.
Do you think this would be an improvement: ``` python if can_share_in_memory_db: if test_database_name == ':memory:' return ... elif 'mode=memory' in test_database_name raise ... ```
To keep the diff a bit cleaner, I wouldn't make this unrelated whitespace change.
I'm confused. Is there something incorrect here or can this just be: ```suggestion self.connection.settings_dict['NAME'] = worker_db ``` If the intent was to avoid mutating the original then do this (although I'm not sure it's required): ```python self.connection.settings_dict = {**self.connection.settings_dict, 'NAME': worker_db} ```
This code is unreachable, because `get_test_db_clone_settings()` raises an exception for other start methods. ```suggestion ```
We should run it only on Django's test suite: ```suggestion if os.environ.get("RUNNING_DJANGOS_TEST_SUITE") == "true": self.mark_expected_failures_and_skips() ``` Also I'm not sure if it's the right place :thinking: , see #15477.
This is a very minor detail but I think the rest of the code uses tripe double quotes (`"""docstring"""`) for docstrings.
You can simply use `assertRedirect(response, obj.get_absolute_url(), ...)` here. No need for string formatting.
You should use `fetch_redirect_response=False` instead of `target_status_code=404`. It seems to be an outdated pattern used in a few places and I'll probably clean it up soon.
I'm not sure what you mean.
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
I meant for the entire string here to be a constant; otherwise looks good to me.
Running the entire test suite I could reproduce the error, but not if only running `django.contrib.gis`. Not sure exactly the cause but this code seems suspicious as we leave a different model admin registered for other tests.
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
Implementation looks okay but should still check the response here and check that the "protected" page is displayed.
Use single quotes unless the string contains a single quote. Also, this could be combined with the previous line -- we allow up to 119 characters when it helps readability.
It should give 'Modification de Title et Historique.'. I guess a gettext call is missing inside the `LogEntry.get_change_message`.
seems like a helper method to get the attachment path would save some repetition
single line here is okay (lines up to 119 chars are fine when it improves readability)
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
(And round-tripping of the messages is already tested in other tests)
[I'd use `casefold()`](https://docs.python.org/3/library/stdtypes.html?highlight=casefold#str.casefold) and it looks we're not performing `lower()` in the `model._meta.db_table` and `field.remote_field.through._meta.db_table` containment checks below either. The `through` case is also untested.
Not related to these changes but we should probably turn the `existing_table_names` iterable to a `set` if it's only used for containment checks.
You'll want to make this a set as well ```suggestion existing_table_names = {name.casefold() for name in existing_table_names} ```
`'utf-8'` is the default. We can remove it.
Looks like you're missing a `relations` assignment here.
I think we can remove `tearDown()` and `setUp()` and use ```python with translation.override(language): ``` instead of `activate()`.
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
I think I would not mix the tests and better create a separate test, if possible.
```suggestion with with self.subTest(tag), self.settings(LANGUAGE_CODE=tag): ```
I prefer stating the expected behavior rather than "Test that..." since all tests are for testing. e.g. "A language not present in settings.LANGUAGES can be installed/used by a project."
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
has a -> is of a
I'd include the min length in the error message
its so that, for example, a ...
no dash in "email"
Yep. That swings it for me. Leave it as is. Good one. Thanks.
prefer this style for multilined docstrings: ``` """ Text """ ```
What about using the global user model's `normalize_username` method while returning an instance of `self.model`? ```python GlobalUserModel = apps.get_model(self.model._meta.app_label, self.model._meta.object_name) username = GlobalUserModel.normalize_username(username) password = GlobalUserModel.hash_password(password) user = UserModel(username=username, email=email, **extra_fields) user.password = password user.save(using=self._db) return user ```
Looking at it we should also pass `obj` to this method and cache its results, just like we do with `get_group_permissions`: ``` python def get_user_permissions(self, user_obj, obj=None): """ Returns a set of permission names the user has. """ if user_obj.is_anonymous() or obj is not None: return set() if not hasattr(user_obj, '_user_perm_cache'): if user_obj.is_superuser: perms = Permission.objects.all() else: perms = usr_obj.user_permissions.all() perms = perms.values_list('content_type__app_label', 'codename').order_by() user_obj._user_perm_cache = set("%s.%s" % (ct, name) for ct, name in perms) return user_obj._user_perm_cache ```
@pahko `2` , `3` and non-empty lists and objects also will be valid case. Only check for boolean is needed here.
I think you could skip the views file and use `lambda req: HttpResponse('OK')` instead.
Use single quotes for the names.
We can also import `include()` from `django.urls` instead of `django.conf.urls`.
Let's be consistent about whether `app_name` appears above or below `urlpatterns`.
How about # View is not a callable (string import; arbitrary Python object)
Maybe `By default, return the django.contrib.admin.utils.get_deleted_objects.` instead of `By default this just returns django.contrib.admin.utils.get_deleted_objects.`.
Following the existing docstring pattern of wording like "Hook for..." seems useful.
" allowed to be deleted permissions" seems like a typo.
This can be single lined.
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
`getattr(module, '__spec__', None) is None` is more concise.
Why do you continue here? `app_label` might still be invalid.
I don't believe so, this does seem unneeded. As a whole, this and the two lines below are pretty performance critical to the reloader but I don't see how removing `list()` would cause any issues with that.
Single quote strings ```suggestion module = types.ModuleType('test_module') ```
We use the same logic in at least three places, I would add internal hook, e.g. `_module_match_label(self, module_label, label)`.
You preach to a convert! However it's not about not being able to encode in UTF-8, but about the common file encoding on some platforms, especially Windows. I'm not using Windows for a long time now, so I can't say if UTF-8 is a common encoding nowadays or if it needs a special handling (say change a program preference) in most Windows text editors.
`saved_name` is unused, so we can leave only ```python if self.keep_intermediate_files: self._save(hashed_name, content_file) ```
Use single lines for all these asserts -- we allow up to 119 characters when it improves readability.
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
```suggestion self.assertIs(self.temp_dir.joinpath(f_name).exists(), True) ```
The class should really be named `JSONResponse`.
preferred style, also "catched" -> "caught" ``` raise Exception( 'Exception... that should be caught' '...' ) ```
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
please include periods
It's questionable whether this one is worth the change. If we're not building/manipulating the path, then we may as well stick with the `os.path` functions.
Although using only the name might cause usability issues in the case of an auto-generated name. The user will have to inspect the database or something in order to determine the index name if they're writing the migration by hand.
Why does `DropIndex` take name, but `CreateIndex` takes an `Index`? That seems a little counterintuitive.
I'm not following exactly what the idea is and what problem it's solving.
It's solving the issue about `DropIndex` taking a name mentioned above and should make a lot stuff easier to deal with (such as index renames) as indexes will be identifiable by a user defined string. Either all `Index` should have a user defined name like field or we should not try to mimic the `RemoveField` API and make `DropIndex` take an `Index` instead of a system generated name.
I briefly remember that there was an issue with wrong index names a while ago, that _somehow_ got in people's projects. I can't recall the details, but all migration operations should enforce a deterministic index name present. That is, `AddIndex` checking for `self.index.name` and `RemoveIndex` checking for `self.name`.
This check is also redundant.
`e` is unnecessary. Maybe it will be better to refactor these tests and put `class` inside `try` e.g. ```python @unittest.skipUnless(connection.vendor == 'postgresql', 'Postgresql specific test.') class PostgreSQLCursorOptionsTestCase(TestCase): try: from psycopg2.extensions import cursor class PostgresLoggingCursor(LoggingCursorMixin, cursor): pass except ImportError: pass ```
This check is also redundant.
This check is redundant. `skipUnless` already guarantees that we have MySQL. You can remove the `try ... except` leaving only `import`.
If `cx_oracle` is installed, there's an error: ``` File "/home/tim/code/django/tests/backends/test_cursors.py", line 33, in OracleCursorOptionsTestCase class OracleLoggingCursor(LoggingCursorMixin, Database): TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases ``` Also, is this file doing anything useful? I don't see any test methods.
A few grammar fixes: `You are trying to add the field '%s' with 'auto_now_add=True' to %s without a default; the database needs to set a default value for existing fields.`
if no app*
You're calling `model_name.lower()` twice in most cases
prefer `request_hander = NoColorWSGIRequestHandler if no_color else WSGIRequestHandler` rather than duplicating more than what's necessary
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
Is it possible for these asserts (and below) to fail without a bug in Django? If so, proper exceptions should be raised a la: https://code.djangoproject.com/ticket/32508
Yes, but these assertions can fail only for users with an incorrect hash in the database. IMO `assert`s can stay here, if you think otherwise we can discuss changing them in all hashers in ticket-32508.
Do we have any plan on how & when to upgrade those as time passes by? (ie like we have for pbkdf2)
I'm not sure, I don't think there is a need to do this per release. :thinking: `work_factor` must be a power of two and the OpenSSL limits memory usage to 32 MiB, so we would have to increase `maxmem` as well: :teacher: ``` (2 ** 15) * (2 * 8) * 64 = 33554432 = 32 MiB ```
Is there a good reason to order the data like this? I'd personally expect the hash to be at the end, so it could include a `$` .
You can have a flatter function (less nesting) by doing: ```python if not remote_field: continue ```
You can reuse `resolve_model_field_relations()`.
The 4 lines above look identical to the `remote_model_key` lines a few lines before, except with `through` instead of `remote_field.model`. Maybe that can be a helper method accepting that argument.
We can take `model_state` from `self.models`, there is no need to pass `model_state`.
We can use `self.real_apps`, there is no need to pass `real_apps`.
```suggestion 1. (?P<a>\w+)/b/(?:\w+)c(?:\w+) => (?P<a>\\w+)/b/c ```
```suggestion def remove_non_capturing_groups(pattern): ```
Please use single quotes.
In the pattern I provided, the `'Z'` is a plain `'Z'` (because the backslash preceding it is escaped), but your substitution line is removing it.
Yes. However, note that isn't sufficient to replace all occurrences of e.g. `r'\Z'`, for example `r'a\\\Z'`.
As far as I'm aware we don't need to iterate twice over the same list: ```suggestion return { '%s.%s' % ( fixture_name, '.'.join([ext for ext in combo if ext]), ) for combo in product(databases, ser_fmts, cmp_fmts) } ```
IMO we should revert this change `fixture_file` is an absolute path, so it can contain directories with dots in names, this can cause issues in `parse_name()`.
May be an easier change for django reviewers if you keep this block in the same format as the one you replaced
You could use `for else` construct here. ``` python for fixture_label in fixture_labels: if len(self.find_fixtures(fixture_label)) > 0: break else: return ```
My code sucks. Feel free to change in other places.
I see. Any thoughts about passing the _local_ field instead of the remote one and the model it's from? e.g. in the case of tests below `field_name` would be `'uuid'` instead of `'question_with_to_field'`. That's how the other `to_field` enabled admin views work and what `to_field_allowed` expects. It also feels like a nicer API to me and would allow you to stop passing `app_label` and `model_name`.
This can raise a `LookupError`
If I understood the above code correctly, then `self.field` is on the source model, whereas `self.model_admin` points to the target admin, I think we should really rename those to avoid confusion.
`getattr` will throw a `ValueError` if the `to_field` does not exist, this has to be handled.
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
Please update your patch.
I would call `clean()` in validation tests, we should also move it to a separate tests, e.g. ```python def test_invalid_value(self): field = models.DecimalField(max_digits=4, decimal_places=2) msg = '“%s” value must be a decimal number.' tests = [ (), [], {}, set(), object(), complex(), 'non-numeric string', b'non-numeric byte-string', ] for value in tests: with self.subTest(value): with self.assertRaisesMessage(ValidationError, msg % (value,)): field.clean(value, None) ```
There should be 1 newline (the little icon that github displays shouldn't appear).
@lukaszb which contrib/admin file are you talking about? Notice [how contrib/admin/options.py](https://github.com/django/django/blob/master/django/contrib/admin/options.py#L1860) doesn't have the missing new line icon. Make sure not to add two newlines, just put your cursor right where the missing new line icon is and press ENTER once.
Using hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). e.g. ```python self.assertEqual( nformat(Decimal('1e16'), '.', thousand_sep=',', grouping=3, force_grouping=True), '10,000,000,000,000,000' ) ```
According to the [docs](https://docs.djangoproject.com/en/2.0/ref/settings/#std:setting-SECRET_KEY) and ticket https://code.djangoproject.com/ticket/24994 the type of `SECRET_KEY` can be either bytes or str. > Uses of the key shouldn’t assume that it’s text or bytes. Every use should go through force_text() or force_bytes() to convert it to the desired type. So a call to `.encode()` may not always work.
Unfortunately, I don't have a good answer for that. I think now that Django is Python3 only, the project is in a better position to decide if SECRET_KEY is always either bytes or str. That would require some consensus from interested people, though. As long as both types are allowed, some utility function is required. I guess at the moment that is force_bytes/force_text.
As above, please use hanging indent.
Please use 4 space hanging indent: ``` argon2.low_level.hash_secret( force_bytes(password), ..., ) ```
While I realize we cannot change that now, do we remember why we added `django.http.cookies` here? The salt alone should make sure that we do not clash with other signatures.
@pope1ni Sure, but that's a separate issue not related with this patch.
> Perhaps when creating migrations we should ensure the value of `related_name` is forced to `'+'` if it ends with `'+'`? We could edit the following in `RelatedField.deconstruct()` to undo the changes made in `ManyToManyField.contribute_to_class()`: https://github.com/django/django/blob/74fd233b1433da8c68de636172ee1c9c6d1c08c9/django/db/models/fields/related.py#L324-L325 Or handle it specially in `ManyToManyField.deconstruct()`.
Because these are names that are only used internally by Django.
> I've noticed that these "internal" names leak into migrations. Making this change will cause migrations to be generated when users upgrade. Are you sure? I didn't notice this in a sample project.
Should we check explicitly only for name '+'. I'm not sure if users can define some other hidden related name if they want to. In that case we shouldn't override the user's hidden name with an auto generated name.
should this be super()
This can be single-lined.
As an example. The method signature should be ```python def rename_model(self, app_label, old_model_name, new_model_name): ... ``` And be called from `RenameModel.state_forwards` as `state.rename_model(app_label, self.old_name_lower, self.new_name_lower)` instead of passing the `Operation` instance along.
Do we need to check `removal_value`? It should be enough to check that `new_value` is not en empty set, I cannot imagine a different scenario :thinking: ```suggestion if new_value: ```
This docstring is unnecessary.
This argument can be single-lined. (It's only 111 chars so. Shorter if using `obj.__class__`)
Please add a trailing comma.
Please remove temporary variable `actions`, also IMO it will be clearer to unpack `action` e.g. ```python names = [name for _, name, _ in obj._get_base_actions()] ```
This is a classic case where you may have duplicates of multiple action names but are only warned about the first one. You resolve that and then get nagged again about the next one. It would be better to list all of the duplicated names. It also probably makes sense to just count all of the names using `collections.Counter` and look directly for duplicates; to wit: ```python counts = collections.Counter(names) duplicates = [name for name, count in counts.items() if count > 1] if duplicates: return [checks.Error( ￼ '__name__ attributes of actions defined in %s must be ' ￼ 'unique. Duplicated names: %s' % (obj.__class__, ', '.join(duplicates)), ￼ obj=obj.__class__, ￼ id='admin.E130', ￼ )] ```
> I'd prefer to return a list of errors rather than a single concatenated error. Is that the method I should change it to? Sorry - I didn't get around to replying, but yes, multiple works better.
I think this should work: ``` python connection = connections[db] if connection.settings_dict['ENGINE'] != 'django.db.backends.dummy': loader.check_consistent_history(connection) ```
Not sure if this might mask some exceptions, but here's what I came up with for now: ``` python for db in connections: connection = connections[db] try: connection.cursor() except ImproperlyConfigured: # Raised by the dummy backend. pass else: loader.check_consistent_history(connection) ```
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
You can rebase your branch and target it for Django 2.0. Since master no longer supports Python 2, you can make a few updates such as using `super().`.
Just make it: ``` if len(expressions) < 2: ``` That avoids problems with sqlite and mysql. GREATEST(x) is always x on backends that support single arguments anyway.
It might be smarter to validate the token first and only modify the session + redirect if it's valid. Otherwise it makes it really easy to create a session just by GET'ing a url (possible DoS vector). It also means you can't pass `accounts/password_reset` as the token and take advantage of our `request.path.replace()` code. It probably means validating the token twice, which is slightly slower. Seems fine to me if an invalid token gets leaked.
@romgar If you find the time that would be great!
immediatelly -> immediately
You should fetch the arguments and url name from `request.resolver_match` here to ensure that we redirect to the same view, if someone hooks up `password_reset_confirm` with a different name you'd get an error here.
yeah, `request.session.get` would return none for the token and this wouldn't pass the comparision (which would be perfectly fine)
This check of for_save could be added to the place where resolve_expression is called in the compiler (first call resolve_expression, then check if resolved.contains_aggregate -> FAIL).
Is it best to remove common parameters like `function` and `template`? Seems to me it improves readability a bit to have common kwargs explicitly declared.
Probably not a bad idea, but it does make the implementation slightly more complicated.
The flake8 error is due to missing a space after the comma here. Please use single quotes instead of double.
After looking at #6271, I think I'm seeing the use case for subclasses of `Func`.
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
`IS_DST_PASSED` is confusing, maybe `NOT_PROVIDED`.
I wouldn't have reflowed this line since you didn't make any other changes and it would simplify the diff.
Usually `__getattr__` is paired with `__dir__`, so that the lazy-loaded stuff is still exposed to `dir()`. My go-to implementation is: ```python def __dir__(): return sorted(list(globals()) + ["utc"]) ```
`value` or `return_value`? or maybe we should swap these lines: ```python if ( not timezone._is_pytz_zone(current_timezone) and timezone._datetime_ambiguous_or_imaginary(value, current_timezone) ): raise ValueError('Ambiguous or non-existent time.') return timezone.make_aware(value, current_timezone) ``` :thinking:
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
that's the default in 1.9, but I don't if you want to include it anyway
immediatelly -> immediately
Not sure it makes a difference but before it looks like we got `form=None` in the context.
Sorry, I couldn't figure out how to continue the conversation that I started here -- the fact that you changed the code seems to "trick" github into thinking that we are done here :) As you pointed out, `get_inline_instances` with no request is very weird and probably (tm) breaks existing code out there. What do you think about the following: Add only one (or two, if it makes handling inlines easier) autocomplete view to the urlpattern (statically) which disapatches to `self.autocomplete_view` and the returns `AutocompleteJsonView` accordingly. This way you'd have access to the request and would just need one view which you'd pass the information you need.
Damn it, there is clear way to get this working. Ie there is no reliable way to determine the source_model_admin for a given URL :( I think we might have to relax permissions a bit and provide the autocomplete to any user for every model which has search fields defined and where the user has any permissions on it.
then this has to be adopted as well
@smithdc1 it does thanks!
Chop blank line.
```suggestion form = PartiallyRequiredForm({'f_0': '', 'f_1': ''}) ```
Both `with` should fit on the same line, `with self.subTest(value=value), self.assertRaisesMessage(ValidationError, "'Enter a number.'"):`
Things seem to be hung up on "Django-generated". I propose the following wording instead which seems clearer to me. I also note that "sufficiently" sneaked in there, but I'm not sure it really adds anything. Also note that the line wrapping should be maintained. ```suggestion "Your SECRET_KEY has less than %(min_length)s characters, less than " "%(min_unique_chars)s unique characters, or it is prefixed with " "'django-insecure-' indicating that it was generated automatically by " "Django. Please generate a long and random SECRET_KEY, otherwise many of " "Django's security-critical features will be vulnerable to attack." % { ``` (Note this suggestion may not apply cleanly in GitHub as I needed to include unchanged lines around the removed and added lines.)
`it's django-generated` --> `it's a Django-generated`
```suggestion "Your SECRET_KEY has less than %(min_length)s characters, less than " ```
So, I've been hemming and hawing on whether to mention it, because it conceptually works when in the error message, but it still seems slightly _'off'_ to me that the warning would say `SECRET_KEY_FALLBACK` when the setting is `SECRET_KEY_FALLBACKS` (plural). I guess if we're not going to say _which_ one errored (which _we could_, using hints) I think it'd make more sense to say `One of your SECRET_KEY_FALLBACKS has less ...`
This makes it sound like the second to nth key are the only one used for validation, when in fact all keys are used for validation.
don't need outer parentheses
`attrs['class'] += ' ' + self.form.required_css_class`
Please try to stay near 80 char per line…
If 'class' is already in attrs, this should append `self.form.required_css_class` to it, not leave the value unaffected.
I find it problematic we’d make it possible to override the `aria-describedby` for two reasons: - If the `help_text` is used, then I don’t think it would be appropriate for its content to be missing from the input’s description as computed from `aria-describedby`. - Assuming we implement the other fix for #32819 by adding the field’s error(s) in `aria-describedby`, it would also be inappropriate for that to be missing because of a customization. In both cases I guess this would be ok if the customization included the ids for the help text and error message when needed, but that doesn’t seem very convenient. --- So we could make it possible to customize `aria-describedby`, but if we did in my opinion it should be in addition to Django automatically populating it for `help_text` and field errors: ```suggestion if self.field.help_text and id_for_label: helptext_id = '%s_helptext' % id_for_label if 'aria-describedby' in widget.attrs: attrs['aria-describedby'] = f"{helptext_id} {attrs['aria-describedby']}" else: attrs['aria-describedby'] = helptext_id ``` I’m not too sold on this either because then we’re having to assume the order of the different descriptions. It gets more problematic if we had errors in there too: ```python attrs['aria-describedby'] = f"{helptext_id} {errors_id} {attrs['aria-describedby']}" ```
`len(statements)` => `statements`
I guess we have poor organization where some tests are organized by class (test_creation/features) and others are organized by database (test_mysql). I'm not requiring a change here but it would be nice to think about how we want to do this going forward.
Maybe a `self.patch_execute_statements(self._execute_raise_tablespace_already_exists)` helper method could avoid repetition and long lines requiring unusual indentation.
I'd split this line in two
suggested wording: "SystemExit is raised if the user answers "no" to the prompt asking if it's okay to delete the test tablespace."
What about: ```py for secret in self.secrets: if constant_time_compare(self._make_token_with_timestamp(user, ts, secret), token): break else: return False ``` EDIT: f'uped the indendation. First time I think I am using for … else
Same as below, I think I'd prefer a loop that breaks early.
Use `assertIs(…, True/False)` for testing boolean values, rather than `assertTrue()` and `assertFalse()` as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion self.assertIs(p1.check_token(user, tk), True) self.assertIs(p2.check_token(user, tk), True) ```
```suggestion self.assertIs(p2.check_token(user, tk), False) ```
```suggestion self.assertIs(p2.check_token(user, tk), True) ```
Let's go with `...cannot contain whitespace.` (I briefly considered that, so it coming up twice, we'll take as a message from the universe.)
```suggestion raise ImproperlyConfigured("URL route '%s' contains invalid whitespace." % route) ```
I don't think we need the blank line here.
Yes. Adding `?:` makes it a non-capturing group which allows for use of `m.groups()` below. Otherwise it'd need to be `... = m[1], m[2], m[4]`.
Let's be consistent about whether `app_name` appears above or below `urlpatterns`.
Is there a reason this can't be implemented as `BaseExpression.ordered = False` with a `OrderBy.ordered = True` override like other properties are dealt with? (e.g. `filterable`, `window_compatible`). This seems like unnecessary bi-directional coupling.
Implemented in #13738.
`F` doesn't inherit from `BaseExpression` so currently it doesn't have `conditional` property and cannot be used in `filter()` or `exclude()` we can change this in the future.
Both approaches work but I wonder if we'd want to be a bit more liberal here and simply return `copy` if no `output_field` can be retrieved. ```suggestion field = getattr(copy.lhs, 'output_field', None) if field is None: return copy ``` It would also avoid having to specify an explicit `output_field` when using a `Func` and `RawSQL` when users usually know what they are doing.
This makes me wonder why `SearchQuery` is a `Value` in the first place given it needs to resolve `config` and `value` now.
SimpleTestCase should be fine. I would use a separate test file so it can be deleted when the deprecation ends.
Do we need the `tzinfo` bit for the test? I'm worried relying on `get_current_timezone` could make the test flaky.
* `--force_color`? (i.e. with `--`) * ~~Re-wrap?~~ (Sorry diff view confused me: you already did this.)
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Could be simplified to `self.assertFalse(editor.deferred_sql)`.
In practice this may again fail with a `PermissionError`. This might happen if the mount maps users in suboptimal ways. So after copying the file you'd no longer have the rights to change it at all. To keep backwards compatibility we'd still might want to ignore the `EPERM` here.
I think it would be safe to access `e.errno` directly in this case. The `winerr` attribute is only present on Windows platform hence the `getattr()`.
FYI, `errno.EPERM` maps to errno 1 so this is the errno we will check for instead of an integer like we originally submitted in the PR.
Chop blank line.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python with mock.patch('django.core.files.move.os.rename', side_effect=OSError()): ```
```suggestion @mock.patch('sys._xoptions', {'utf8': True, 'a': 'b'}) ```
Please add a trailing comma: ```suggestion [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver'], ```
Maybe it would be nice to put the shared test logic into a helper method.
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
`can not` -> `cannot`, or better `may not `
This needs an order_by clause so that the results are guaranteed to come back in the right order.
Chop blank line.
We can reuse existing objects.
chop newline for consistency
@timgraham It might be more appropriate in another commit then. I believe I wanted to make sure nothing was logged if a m2m backed inline was submitted without changes.
The easiest solution might be to duplicate the warning in `OneToOneField`.
stacklevel 2 isn't useful when the warning is raised for OneToOneField. Ideally we could have stacklevel=3 for that case to give `question = models.OneToOneField(Question)` instead of `super(OneToOneField, self).__init__(to, on_delete, to_field=to_field, **kwargs)`.
Sounds okay. The warning should be updated to say something like "Pass to_field as a kwarg instead of as an arg."
Thanks for the clarity, Tim :-) In that case, I think we may as well still go ahead and provide the deprecation shim and warning that we are able to provide (for `ForeignKey(SomeModel, 'to_field')`, which is likely much more common) by shortening this line to just `if not callable(on_delete)`. And we'll just have to rely on a backwards-incompatibility note in the release notes (that you should no longer pass `to_field` positionally, and you can pass `on_delete` as the positional second arg) to help anyone who is doing `ForeignKey(SomeModel, 'to_field', on_delete=models.WHATEVER)`.
Could be useful to say `Pass to_field='{2}' as a....` and add `on_delete` to the format
Yes, I had checked on master, which doesn't make sense. I get the same result on this branch.
This is consistent with how we handle `negated`: ```suggestion kwargs['_connector'] = self.connector ```
Does the ordering of indexes on a database matter? I'm not talking about the order of fields an index applies to, but the indexes itself.
I think we want to crash here if `bases` is not iterable.
How about more simply: "Found duplicate <field/base/manager> '%s' in CreateModel operation." Maybe you could create a helper function so we don't have to repeat a similar loop 3 times.
Same as above (including the `prefix`)
Use single quotes for consistency (and below)
Keep the `update()` syntax (like below).
I think wrapping in `Point()` is causing the test crash.
In this case, I think a ternary is more complicated to read than: ``` if srid == -1: srid = None ```
Nit-pick: I think Django generally favors the syntax with parens instead of the `\` continuation char.
This must be an inner skip, please revert (ticket-31888).
This hook is unnecessary you can reuse `has_native_uuid_field`, e.g. ```python class DatabaseFeatures(BaseDatabaseFeatures): ... @cached_property def has_native_uuid_field(self): return self.connection.mysql_is_mariadb and self.connection.mysql_version >= (10, 7) ``` ```python class DatabaseWrapper(BaseDatabaseWrapper): ... @cached_property def data_types(self): return { ..., "UUIDField": "uuid" if self.features.has_native_uuid_field else "char(32)", } ```
You're right. You know I both saw that and missed it too...
Yes. Adding `?:` makes it a non-capturing group which allows for use of `m.groups()` below. Otherwise it'd need to be `... = m[1], m[2], m[4]`.
Model instances without primary keys are not hashable.
This current version is more readable.
```suggestion return self is other if self.pk is None else self.pk == other.pk ```
Will do, marking it as unread to remind me.
put `self.object.pk` on the next line include a trailing comma
I wonder why it works without `list()` on PostgreSQL :thinking:
I checked and on PostgreSQL we have a list of tuples for multiple rows and a tuple for a single row; on MariaDB we have a tuple of tuples for multiple rows and a tuple for a single row :confused: It's a really implicit logic, we should support both formats in: https://github.com/django/django/blob/8f2a6c76d19e4010c4683b20ed7f1eb4b07c17eb/django/db/models/query.py#L1257-L1260
returns->return (use PEP257 verb style for new docstrings)
`fetchall()` returns a list not a tuple on SQLite. ```suggestion statement into a table, return the list of returned data. ```
We can do much better here. We don't need to regenerate the `LIMIT 1` snippet for every table, as it never changes. The `AS has_rows` is unnecessary. ```suggestion limit = self.connection.ops.limit_offset_sql(0, 1) sql = ' UNION '.join([ "(SELECT '%s' FROM %s %s)" % (table, self.connection.ops.quote_name(table), limit) for table in tables ]) with self.connection.cursor() as cursor: cursor.execute(sql) return [row[0] for row in cursor.fetchall()] ``` I'm also wondering whether we should pass the table names string literals in the `SELECT` as params to avoid any sniff of SQL injection. I honestly don't know if there is a real risk here. The advantage of keeping it like this is that we don't need to batch for SQLite and the overridden version there can be removed.
This line is now an unused import
don't remove double newline and imports should be alphabetized (`from django.core` would be above `from django.db.models.signals`)
There's a class method called `setUpTestData()`. Please use that instead.
And I would rename this attribute `superusers` as it's meant to contain multiple users.
use snake case, please: `test_login_required()`
You're right :+1:. I missed that.
@JunyiJ My previous suggestion was to use the `TAN` database function on Oracle, i.e. ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='1 / TAN(%(expressions)s)') ```
`COT` doesn't exist on Oracle, please emulate it by `1 / TAN(%s)`.
This is clunky - the extra function, assignments, unnecessary casting to `float()`. Regardless, this will not work. What if the source expression is `Value(5.5)` or some other complex expression? I think this is what you are looking for: ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='((%%(expressions)s) * %s / 180)' % math.pi) ```
You should use the `CEIL` function instead of `CEILING` on Oracle.
Thanks for the patch. Clean and simple. Maybe that's just nitpicking but what about changing that `if` to `elif`? Because since `MEDIA_URL` must always explicitly end in slash, we might not want to add a slash if a trailing one is missing from it.
`weak=True` is the default.
explicit -> specified
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
Maybe a helper method would help eliminate the redundancy of these methods? e.g. `return self._value_or_setting(self._location, settings.MEDIA_ROOT)`
```suggestion return tuple(map(int, m.groups())) ```
You're right. You know I both saw that and missed it too...
I'd rename `subminor` to `patch`.
Yes. Adding `?:` makes it a non-capturing group which allows for use of `m.groups()` below. Otherwise it'd need to be `... = m[1], m[2], m[4]`.
`get_version_tuple(geos_version_info()['version'])` is okay
response (no cap) unless you mean to write HttpResponse
I think `request` should be optional.
Or in some cases (e.g. CSRF) it's because we want to log the response under a particular non-default logger. But even in those cases, we never want to double-log a response.
What if we make `level` default to "info" or "debug" instead? That way if you call `log_response` on a non-error response you'd just get an info/debug log, instead of getting a confusing "module logger has no attribute None" error (or whatever the wording actually would be)
I'm omit the intermediate extra variable in favor of: ``` getattr(logger, level)( message, *args, extra={...}, exc_info=exc_info, ) ```
Please do not change formatting
I think this second sentence could be removed
Well, there are a number of existing cases of docs URLs in user-facing messages (especially in migrations, but other places as well). I think there is a lot to recommend them from a UX perspective; someone who gets this warning is quite likely to in short order need a reference of the available `on_delete` options. I don't think the URL-going-stale issue is that big for a deprecation warning, which has a limited lifespan anyway. If someone does happen to rearrange those docs in the next couple years, we'd just update the message. (Like the ones in migrations, the message should use a Django-version-specific docs link, not the `stable` redirect, so that for a given Django version the link shouldn't ever go stale.)
This is a nitpick, but `on_delete` is not an attribute you set, it is an argument you pass. I think that second sentence could just be removed. What might be more useful here is a stable link to the `on_delete` docs.
Well, we _could_ make `on_delete` an actually-required arg to `ForeignObject` right now, and move it even before `from_fields` and `to_fields`, but that would require duplicating the deprecation warning in both `ForeignKey` and `OneToOneField`.
Do we need to ignore a warning here? `kwargs["value"]` should be a string path to the class, so is it not enough to assign it to the `STORAGES`? ```suggestion storages._storages[DEFAULT_STORAGE_ALIAS] = kwargs["value"] ``` Do we need to `del storages.backends`? The `storages_changed` callback should handle this for us :thinking:
Call `clear_url_caches()` instead. It's more likely to stay up to date when the code lives on, and it resets the `get_callable` cache which is missing from your patch.
It's more important to make a removal straightforward than keeping this DRY.
This is an isolation issue that should be fixed. `StorageHandler` cannot share the same global setting, you can check how it's handled in `BaseConnectionHandler` via `configure_settings()`.
can import go at top of file? also, `test_utils` seems like an odd place for these tests. Generally that module is for testing `django.utils`.
This is required only for indexes defined in `Meta.indexes`. Should we pass list of pure fields names in `remove_index()` instead? For example: ```python def remove_index(self, model, index): self._create_missing_fk_index( model, fields=[field_name for field_name, _ in index.fields_orders], expressions=index.expressions, ) super().remove_index(model, index) ```
This formatting change is not related with a bug fix, please revert.
If I understand correctly, when the first field is indexed in descending order (like `-fieldname`) and the DB supports it, we will return `None` for this function. 1/ MySQL doesn't drop the implicit FK index when another index has as first field the FK in descending order, is that correct? 2/ The naming of the function is not _entirely_ accurate with respect to the behaviour, since we'll return None even though one would expect to get the first field name.
`meta` is used only here so a temporary variable is unnecessary: ```suggestion first_field = model._meta.get_field(first_field_name) ```
unique_together-> index? (or something more generic like unique|index_together
Missing `cls.cls_atomics` argument.
Can we move this conditional out of the loop? (I see it was copied from `_fixture_setup`.
I don't understand why we have methods with a double underscores prefix which are copies from `SessionBase`, e.g. `__hash()`, `__legacy_encode()`, `__legacy_decode()` :thinking:
Rather than have the `_test_marker` as an instance variable that ripples through all the methods, we could have it as a class-level variable that defaults to `False` and override it here on the instance. Also I think a better name would be `_from_testcase` or similar - the word "marker" doesn't really convey much meaning. ```suggestion atomic = transaction.atomic(using=db_name) atomic._from_testcase = True atomics[db_name] = atomic ```
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
If we went with `get_model_class()` above, this could simply be `model`.
I don't understand why we have methods with a double underscores prefix which are copies from `SessionBase`, e.g. `__hash()`, `__legacy_encode()`, `__legacy_decode()` :thinking:
I think it would be clearer if you removed the "else" and deindented the rest of the method.
one longer line is preferred (or at least avoid non-multiple of four indentation).
Positional arguments cannot follow keyword arguments.
this can be 1 line (we prefer longer lines when it improves readability)
No, it should be made consistent with other codes (capfirst or title, I haven't checked).
I'm not sure splitting this out to a separate function makes the code easier to follow.
Default is unnecessary: ```suggestion if content_type := self.headers.get("Content-Type"): ```
Avoid conditional imports.
Ha! So it's actually related to your changes :-) Happy to hear that we'll eventually get the semantics that I would expect.
This isn't related to your changes, but I'm intrigued by Django's behavior here. I would expect `|escape` to give `&amp;` and `|escape|force_escape` to give `&amp;amp;`. Not that this construct makes much sense anyway...
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
Use a single line throughout where possible.
I think you can use `with self.assertRaisesMessage` equivalently here (context manager form is much easier to read IMO)
I'd keep the current version without `type()` since it's unrelated. If there's a need for this change, create a ticket with a corresponding test.
I think you should use `type` not `__class__`. At least in python 2 this will break if the class does not inherit from `object`.
chop blank line
how about: "Run the system checks on all ModelAdmins, except if they aren't customized at all."
`fix_this` is misleading, because there is nothing to fix here.
good catch, the second is fixed in https://github.com/fcurella/django/pull/1
use `with self.assertRaisesMessage(PermissionDenied, 'Forbidden user agent'):`
No `self` parameter, just the exception class.
Great, I just change this line to check the message in calls rather than simply its length.
override `__init__()` instead. after `super()` then `self.style = no_style()`
Use `self.assertIs` and `self.assertIsNot` as these boolean expressions are noop.
Missing blank line at the end of the file.
```suggestion 'The extra_tests argument is deprecated.', ```
Call `super` here instead.
remove "should", e.g. "debug() bubbles up exceptions before cleanup."
Nitpick but `dict.get` default value for a missing key is already `None`.
You're calling `model_name.lower()` twice in most cases
Yes, this should be taken care of before.
It looks like you can actually do `fields = self.models[model_key].fields` (similar to further down) since you're only using `model_state.fields` below.
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
I'm favoring contractions lately, e.g. "Don't", "shouldn't".
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
We need to factor this differently, as it's an exact duplicate of the added block above.
* We're still preferring single quotes, please use those throughout, unless there's a nested single quote. * This change is unrelated, please revert.
This is already covered in `expressions` tests https://github.com/django/django/blob/9624703a06187060c1a494e533f3e27fed946de3/tests/expressions/tests.py#L749-L760
`assertEqual(list(a), [...])` should be simpler
To fix the Oracle failure, rephrase this query as ``` CaseTestModel.objects.only('pk', 'integer').annotate(... ``` or even ``` CaseTestModel.objects.values('pk', 'integer').annotate(... ``` I don't have it in me to test myself now, but the issue is that if you don't do one of these, then `annotate()` over `fk_rel` implies `GROUP BY` all the fields of `CaseTestModel`; this model includes BLOBs (`TextField`, `BinaryField`) and Oracle refuses to compare them and so they can't be grouped over. By the way, doing this should also make your test faster on all databases except PostgreSQL (I think), because PostgreSQL (AFAIK) is the only one smart enough to realize that grouping over all the columns is really the same as grouping over the PK.
Not necessary AFAIK; `values('cnt')` infers it.
Is there a reason to use `len()` instead of checking the objects? `len()` may take more effort to debug in the event of a failure.
style guide says this should be "Checks ..."
As no one has offered a rationale for deviating from the PEP, I'd leave it as is.
no dash needed for "nonexistent"
Sounds good -- `RemovedInDjango21Warning` is now on master.
I think we might be too late to add more deprecation's to 1.8 (also missing deprecation docs).
I would remove this sentence and let the person who changes this code in the future decide of the way to implement it.
Would be fine I guess. I'm not too sure about the safety margin aspect in the first place, but it's SQLite so whatever works, I guess.
I'm not sure I'm a big fan of this error message. "Shadowing" has a specific meaning that may not be clear to everyone. Perhaps something along the lines of "You cannot use the name ... as the to_attr argument, as the model already has a field with this name"
The other benefit of reversing the sense of this flag is that it makes the "normal" case be `False` and the unusual case `True`, which I think is generally preferable for boolean flags.
I see thanks, I missed it because of the `is_cached` removal.
We don't need to call `ArrayLenTransform()`: ```suggestion sibling_count=models.Max('sibling_ids__len') ```
Maybe ```suggestion [len(self.objs) - 1] * len(self.objs), ```
Maybe ```suggestion ).filter(same_sized_fields__len__gt=1), ```
Why not `first()`? :thinking: ```suggestion ).first().ids, ```
```suggestion ).values_list("siblings_json", flat=True).first() ```
First we should verify this passes before we toggle `is_active` to False.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
I don't think it's terribly important as both checks use the same code path (although this could obviously be refactored later at which point that argument would fail...).
my preferred style is: "#17903 -- Inactive users shouldn't have permissions..."
Please add a trailing comma.
On balance I will leave this one as it is.
I think keeping the explicit `process_response()` call here would make sense. By changing to `__call__()` we're running through `process_request()`, which is not a no-op, which is perhaps fine but it's subtly changing the intent/behaviour of the test. (I guess this is something we'd have to think about removing the `process_x()` hooks, but not in this PR) Same for line 677 below. **Update**: Tests in `csrf_tests` are more explicit about this... (So maybe the small change here is OK)
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
put the closing parenthesis on the next line
Please use single quotes as in other tests.
Please move it above `'tr'`.
Obviously this is unwanted changes.
Yep. Looks good @felixxm
You can drop this line.
prefer if you use hanging indent style for this assertion to match the other tests
I think the style is not to have a blank line between the feature-flags, except in the base-backend. Please also see the MySQL feature flag.
Although it's default, `TEXT` is also a supported format.
Please position this up near `has_native_uuid_field` and `has_native_duration_field`. You also need to add `has_native_serial_field = False` to `django/db/backends/base/features.py`.
I'd change `TRADITIONAL` to `TEXT` here as we are now implicitly converting `TEXT` to `TRADITIONAL` in your latest change to `explain_query_prefix()` for MySQL. `TRADITIONAL` is just a formatted text-based output in MySQL, and a silly name. I think it is better to provide a more sensible and consistent name for Django to use.
`TRADITIONAl` → `TRADITIONAL` (You let go of your shift key too early!) Perhaps reword to `# Add TEXT as an alias of TRADITIONAL for consistency with other backends.`
I would assert that querysets return the expected tag. Also, temporary variables are unnecessary. For example: ```python tag = integration.tags.create() self.assertSequenceEqual(TTag.objects.filter(integration=integration), [tag]) self.assertSequenceEqual(TTag.objects.filter(integration__id=integration.id), [tag]) ```
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
I added `supports_select_for_update_with_limit` because this will crash on Oracle.
I think this test would be fine without the blank lines, it's fairly short.
I think verifying the results wouldn't hurt, e.g. `self.assertSequenceEqual(groups2.filter(id__gte=0), [g])`
Slightly more concise? ``` options = {'cls': self.encoder} if self.encoder else {} return json.dumps(obj, **options) ```
Nitpick : can we remove the parallel assignment here? I have a draft blog post on why it's slower (tuple construction just to immediately deconstruct), and less clear (if an exception is raised, unknown which variable caused it)
`form_class` is defined in `RangeField.formfield()` so this is redundant.
I think we can simplify this: ```python def json_script(value, element_id=None, json_encoder=None): from django.core.serializers.json import DjangoJSONEncoder json_str = json.dumps(value, cls=json_encoder or DjangoJSONEncoder).translate(_json_script_escapes) ```
I would put the arguments all on this line
This line can be removed :thinking:.
IMO this line is unnecessary, and above `iter()` call can be removed.
`seprate` -> `Separate`, also trailing dot is missing.
It seems that we have two issues here, i.e. you can use fields from the same model multiple times, e.g. `parent__field1__field2__pk__field1`, and you cannot use `pk`. I think we should clean `_cls` if a field is not relation, e.g. ```python if part == 'pk': fld = _cls._meta.pk else: fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` I would split this into two fixes, first for using multiple times fields from the same model (with test): ``` fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` and second to handle `pk` (with test).
As with `@raise_deprecation`, this should be a module-level utility, not a method on the class.
```suggestion cls.set_up_called = True ```
```suggestion # LiveServerTestCase's change to ALLOWED_HOSTS should be reverted. ```
```suggestion def check_allowed_hosts(cls, expected): ```
quit() .... to avoid a dead.... (chop "we" stuff)
You can use `mock.atomic.assert_called_with(using=db)` here instead.
is `link` what we call `rel` in the rest of the code? link has me thinking `<a href="...">`. Naming is hard.
The return type of get_field()
Return a tuple...
I think splitting this to more lines would increase readability. Probably the same for the above with `self.relname`.
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
title.verbose_name and same typo in else branch
There is no need to use `assertRaisesRegex()`: ```suggestion msg = 'Migration 0001_initial already exists. Use a different name.' with self.temporary_migration_module(module='migrations.test_migrations'): with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
Please revert unrelated cosmetic changes to keep the diff clean.
move to finally
this should be in `finally` just in case the commands before throw an exception
Casting `int` to `int` is not necessary.
I think it will be more readable to keep `int` and `slice` in separate branches, e.g.: ```python def __init__(self, f_obj, slice_obj): if isinstance(slice_obj, int): if slice_obj < 0: raise ValueError('Negative indexing is not supported.') self.low = slice_obj self.length = 1 elif isinstance(slice_obj, slice): if ( (slice_obj.start is not None and slice_obj.start < 0) or (slice_obj.stop is not None and slice_obj.stop < 0) ): raise ValueError('Negative indexing is not supported.') if slice_obj.step is not None: raise ValueError('Step argument is not supported.') self.low = 1 if slice_obj.start is None else int(slice_obj.start) + 1 self.length = None if slice_obj.stop is None else int(slice_obj.stop) - self.low + 1 else: raise TypeError('Argument to slice must be either int or slice instance.') self.expression = f_obj ```
Please use f-strings as Python 3.6+ is now the requirement More information is available including some benchmarks. https://cito.github.io/blog/f-strings/
We can remove this check after fixing the `Field.slice_expression()`.
Chop blank line.
Nothing specific, it's just a pattern commonly used in Django. Probably because it was not the same in Python2.
So I'm fine to leave `type()` calls.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
I think we can use the same check like in `UniqueConstraint`: ``` if not isinstance(condition, (type(None), Q)): raise ValueError('ExclusionConstraint.condition must be a Q instance.') ```
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
Use `self.username_field` instead.
Please don't make unrelated whitespace changes.
I think this blank line can be removed.
I think `__str__` can be omitted here. If it needs to stay, `CustomUserWithIntegerUsername` should be wrapped by `@python_2_unicode_compatible`.
`it's django-generated` --> `it's a Django-generated`
Things seem to be hung up on "Django-generated". I propose the following wording instead which seems clearer to me. I also note that "sufficiently" sneaked in there, but I'm not sure it really adds anything. Also note that the line wrapping should be maintained. ```suggestion "Your SECRET_KEY has less than %(min_length)s characters, less than " "%(min_unique_chars)s unique characters, or it is prefixed with " "'django-insecure-' indicating that it was generated automatically by " "Django. Please generate a long and random SECRET_KEY, otherwise many of " "Django's security-critical features will be vulnerable to attack." % { ``` (Note this suggestion may not apply cleanly in GitHub as I needed to include unchanged lines around the removed and added lines.)
So, I've been hemming and hawing on whether to mention it, because it conceptually works when in the error message, but it still seems slightly _'off'_ to me that the warning would say `SECRET_KEY_FALLBACK` when the setting is `SECRET_KEY_FALLBACKS` (plural). I guess if we're not going to say _which_ one errored (which _we could_, using hints) I think it'd make more sense to say `One of your SECRET_KEY_FALLBACKS has less ...`
```suggestion "Your SECRET_KEY has less than %(min_length)s characters, less than " ```
(That is, the already-existing "upgrade considerations" section.)
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
A test is missing for this change.
Is `test_doesnt_work_with_init_subclass` meant to test this change? I still don't see any test failures if this change is reverted.
This inner import is a syndrom of the circular dependency between `Manager` and `QuerySet`. Could we avoid it by moving this code inside `_Manager`? `Manager` would know how to create a subclass of itself with the methods of a given `QuerySet`.
Why is this on two lines? Why not just...? ```python data_altering_methods = getattr(cls, 'data_altering_methods', ()) ```
> > this attribute should be `non_picklable_attrs` I think. > > ... or `pickleable` 😄 I need to confirm with Carlton. Yeah that's how I was going to recommend spelling it, because it _felt/looked_ right, but then I looked at the python pickle docs and they use `picklable` everywhere. TIL.
We're more consistent then Python when it comes to "pickl(e)able": - Python: `picklable` - 92, `pickleable` - 39 - Django: `picklable` - 45, `pickleable` - 1
don't reorder as above
please include periods
You might also test the user agent string in `mail.outbox[0].body`.
Lets also test that `values_list()` throws the same error. You can do it in the same test method.
checking the results of the query would be useful. ``` self.assertEqual( Pet.objects.prefetch_related('fleas_hosted').values_list('id', flat=True), [...], ) ```
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
Relying on pk might be problematic since we shouldn't assume the values that the database might assign.
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
Ahh, yes, sorry :facepalm: Good catch :dart:
Yes, I think we should be able to distinguish between automatic indexes and manual indexes. It might not be possible to cover all possible cases (inspectdb doesn't aim for perfect output), but let's try our best. For example, a single-column GIST index on a geometry field is considered as the default index.
Please use single quotes. You can use directly `out.getvalue()` instead of a temporary variable, e.g.: ```python self.assertNotIn('class InspectdbPeopleView(models.Model):', out.getvalue()) ```
You don't have to initialize `out` twice. This line can be removed.
If the line length bothers you, I think dropping "database" would be fine.
Will this statement will fit on a single line? (119 characters is permitted.)
Will this statement will fit on a single line? (119 characters is permitted.)
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
```suggestion Update a queryset using order_by on a unique constraint. ```
The `.all()` is redundant ```suggestion updated_count = UniqueNumber.objects.order_by('-number', 'id').update(number=F('number') + 1) ```
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
Single quotes please.
`Final exception` doesn't appear in a template. I added check for `During handling of the above exception`.
I think we should trigger a custom exception here rather than `ZeroDivisionError`
A docstring describing the purpose of this test may be useful.
Could drop the `alias` in `setUpTestData` and `order_by('pk')` or simply use `assertCountEqual` since ordering isn't that important.
Ditto with `.values_list`/`assertSequenceEqual`.
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
Please wrap at 79 chars (like in "_test_sha512.py_").
Does it work if you use `override_settings` for this too? That would be cleaner.
I'd go with `assertEqual(check_setting_language_code(None), [])`. That's a bit easier to debug in the case of a failure since the error will be visible as opposed to just, e.g. 1 != 0.
I'm thinking it might be better to use the approach in `test_caches.py` rather than repeating the error message here twice.
We should use `override_settings` for this, to ensure we clean up after ourselves once the test is complete, avoiding breaking unrelated tests.
Please wrap these lines at 79 characters.
please move this test next to the the `get_many` one
please insert tests on line 1029, after the `setUp`/`tearDown` helpers `create_table` and `drop_table`
I'd make the message (with a placeholder for the key) a module constant so it's not repeated.
There is not need to wrap `CursorWrapper.execute`, we should be able to use `CaptureQueriesContext()`, e.g. ```python def test_has_key_query_columns_quoted(self): with CaptureQueriesContext(connection) as captured_queries: cache.has_key('key') self.assertEqual(len(captured_queries), 1) sql = captured_queries[0]['sql'] # Column names are quoted. self.assertIn(connection.ops.quote_name('expires'), sql) self.assertIn(connection.ops.quote_name('cache_key'), sql) ``` There is also no need to check a table name because it contains spaces, so it's already tested.
This test runs on database cache only
The old options look pretty easy to deprecate. We just accept `**kwargs`, and alias any older `kwarg` to the new one + deprecation warning.
To prevent unexpected `FieldDoesNotExist` exceptions raised in `if field.attname == field_name:` to be silennced. It's generally good practice to restrict the `try` body to the only parts expected to raise the exception.
ideally this bit would be in the `else:` branch of the try/except.
It seems that we have two issues here, i.e. you can use fields from the same model multiple times, e.g. `parent__field1__field2__pk__field1`, and you cannot use `pk`. I think we should clean `_cls` if a field is not relation, e.g. ```python if part == 'pk': fld = _cls._meta.pk else: fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` I would split this into two fixes, first for using multiple times fields from the same model (with test): ``` fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` and second to handle `pk` (with test).
:man_facepalming: Ah, ok. Thanks :+1:
We should also use `quote()` because non-integer primary keys may not work properly, e.g. `_40`. Fixed.
```suggestion return format_html('<a href="{}">{}</a>', url, remote_obj) ```
Could you try to improve this so that there isn't duplication of the HTML and `escape(Truncator(obj)....`
Still I think `'&nbsp;<strong>%s</strong>'` could be factored as a variable and `<a href=...` interpolated inside that. Let's use `format_html` instead of `escape`. This return could go in the `else` block of `try/except/else`.
This could be replaced by `self.remote_field.model._meta.label_lower` https://github.com/django/django/blob/c1b24718e05ea474955777d7bc4d9d5634560cd5/django/db/models/options.py#L136-L138
We cannot make serial pk assumption: ```diff diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py index 8b54611010..ea68a105d6 100644 --- a/tests/model_forms/tests.py +++ b/tests/model_forms/tests.py @@ -1765,10 +1765,12 @@ class ModelMultipleChoiceFieldTests(TestCase): f.clean([c6.id]) def test_model_multiple_choice_field_validate_choices_called_properly(self): + c1 = self.c1 + class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField, TestCase): def validate_choices(self, queryset, field_name, selected_choices): self.assertIsInstance(queryset, models.QuerySet) - self.assertQuerysetEqual(queryset.order_by('id'), [1], lambda a: a.id) + self.assertSequenceEqual(queryset, [c1]) self.assertIsInstance(field_name, str) self.assertEqual(field_name, 'pk') self.assertIsInstance(selected_choices, frozenset) ```
`assertTrue(value)` will pass for `bool(value) is True` which is different than checking for `True`.
Would this original line not raise `ValidationError` further down in the `clean()` method? https://github.com/django/django/blob/master/django/forms/models.py#L1240. Might need to add it back.
don't need a trailing comma for lists of length 1 (only applies to tuple).
```python self.assertHTMLEqual( field.widget.render('name', []), ( '<ul>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="entertainment">Entertainment</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="test">A test</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="third-test">Third</label></li>' '</ul>' ) % (self.c1.pk, self.c2.pk, self.c3.pk), ) ```
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
I feel similarly. Maybe it's better just to add support for list and tuple as originally proposed. It's unclear to me if other types would actually be used.
Don't use a mutable default: `{}`. Should default to `None` and then add : ``` if json_dumps_params is None: json_dumps_params={} ```
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
```suggestion # The not-provided sentinel is distinct from None, as which() returns None when not found ```
```suggestion # Use a sentinel rather than None, as which() returns None when not found. ```
no `u''` prefixes on strings please
or just `# CSS files shouldn't be touched...`
`s/ exists/ exist`
@felixxm that's a tricky one for sure. We could adjust MySQL's `allows_group_by_pk` feature to be based of `not ONLY_FULL_GROUP_BY` but that would likely incur a large performance hit which is definitely not suitable for a backport. I guess we could always skip the test on MySQL for now.
chop blank line
```suggestion self.assertEqual([book.rating_count for book in qs], [1]) ```
@timgraham is ordering by the result of an aggregate allowed without subqueries? If ordering by count does not error, then it should be safe to use that ordering. If not, introducing a different field into the orderby will affect the grouping (not that you suggested that), so we'll need to look at comparing the queryset out of order if there's another assert method available that does that. I'm not able to check either of these things at the moment, but I can take a look in about 8 hours if it's not resolved.
Per new code guidelines, can we use `assertIs`? :)
Make sure you reference your ticket number in the docstring (see the other tests in the file).
You could avoid the delete query with: `AggregateTestModel.objects.none().aggregate(...)`. (I guess the other tests could use the same pattern, not for this PR though.)
I think the `TestStringAggregateDistinct` class could be reused considering the setup methods are the same -- just remove `String` from the class name.
And add `obj.normal.close()` at the end to fix the failure on Windows.
I don't think `list()` is needed. `self.assertEqual(sorted(values['arrayagg'], ['Bar', 'Foo', 'Foo'])` looks good to me.
this goes below `from uuid ...` -- whether it's `import` or `from ... import` doesn't affect ordering
I guess it's a bit defensive, it helps ensuring that behavior is always identical. `print("hello",)` would give different results in PY2 and PY3 for instance.
is print_function needed? it doesn't appear in the rest of the code base.
I am curious if there is any particular reason for this change.
built-in imports like unittest should go above django imports, separate by a newline. e.g. ``` from __future__ import unicode_literals import unittest from django ... ```
You can use `@modify_settings`, e.g. ```suggestion @modify_settings(MIDDLEWARE={ 'prepend': 'test_client.tests.urlconf_override_middleware', }) def test_resolver_match_when_urlconf_modified_by_middleware(self): response = self.client.get('/') ```
I would assert against `url_name`, e.g. ```suggestion self.assertEqual(response.resolver_match.url_name, 'overridden_urlconf_view') ```
use snake case, please: `test_login_required()`
```suggestion self.assertEqual(res.context['week'], datetime.date(2008, 9, 29)) ```
One empty line above, please.
Looking at it we should also pass `obj` to this method and cache its results, just like we do with `get_group_permissions`: ``` python def get_user_permissions(self, user_obj, obj=None): """ Returns a set of permission names the user has. """ if user_obj.is_anonymous() or obj is not None: return set() if not hasattr(user_obj, '_user_perm_cache'): if user_obj.is_superuser: perms = Permission.objects.all() else: perms = usr_obj.user_permissions.all() perms = perms.values_list('content_type__app_label', 'codename').order_by() user_obj._user_perm_cache = set("%s.%s" % (ct, name) for ct, name in perms) return user_obj._user_perm_cache ```
Move this above `has_add_permission` for consistency.
I think you missed this one in your recent updates.
same thing here about assuming `is_active` exists and `not user.is_active` -- probably need some tests for that case.
`obj` is not passed to `get_(user|group)_permissions` since it's always equals to `None` at this point; expand the diff and look at the full body of `get_all_permissions`.
I don't think it's good practice to change instances created in `setUpTestData` as they should be identical for the whole test class.
Can we test both `Person` and `Political`?, e.g. ```python def test_create_new_instance_with_pk_equals_none(self): c1 = Congressman.objects.create(state='PA', name='John', title='senator 1') c2 = Person.objects.get(pk=c1.pk).congressman # Create a new congressman by setting pk = None. c2.pk = None c2.name = 'Bill' c2.title = 'senator 2' c2.save() self.assertEqual(Congressman.objects.count(), 2) self.assertEqual(Person.objects.get(pk=c1.pk).name, 'John') self.assertEqual(Politician.objects.get(pk=c1.politician_ptr_id).title, 'senator 1') ```
Use `assertIs(…, True/False)` for testing boolean values, rather than `assertTrue()` and `assertFalse()` as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion self.assertIs(p1.check_token(user, tk), True) self.assertIs(p2.check_token(user, tk), True) ```
```suggestion self.assertIs(p2.check_token(user, tk), True) ```
```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
try to be consistent and use single quotes in most places (sorry existing code is inconsistent)
Use the context manager version for better readability: ``` msg = '....' with self.assertRaisesMessage(ImproperlyConfigured, msg): self.set_up_test_model(True) ```
Again, not related but use `force_raster_creation=True` rather than a tough to decipher plain boolean.
To have more balanced line length, I think I prefer: ``` python constraints = self.get_constraints(IntegerArrayModel._meta.db_table) self.assertEqual(constraints['integer_array_model_field_gin']['type'], 'gin') ```
I would consider tuple unpacking in the line before: `constraint_table, constraint_column = constraint['foreign_key']`.
quit() .... to avoid a dead.... (chop "we" stuff)
I think it's something like: 'browser' contains the first browser to run the tests against and 'browsers' will contain the rest of the browsers (if more than one are requested).
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
If we remove this will the tests run on Jenkins? It might be fine.
Not sure how much a difference it makes, but it seems better to store this in Python rather than having to read from a text file. Worth it to make the file location customizable? If so, it might be nice to make "common passwords" a separate package so we don't have to include that list in Django. I guess users might not care for the additional setup tasks though.
I'm a bit worried about this `reload()` with overridden settings to trigger the `UserCreationForm` to be recreated with a custom model. It obviously works for this test case, but I think it will leave the customised `UserCreationForm` loaded at the end of the test, won't it? Doesn't this mean that we will potentially have dependencies between this test and other ones that also use the `UserCreationForm`? If so, I think we should find a way to do a `reload()` at the end of the test (in `tearDown()`?) after the settings have been put back to the default.
The signal approach would hopefully eliminate the need to call `reload()` manually.
Use normal dictionary access instead of `.get()`. It is fine for us to blow up with a `KeyError` here and helps debugging because it is clearer whether the attribute is missing or the value is incorrect.
Don't forget the trailing commas! However, I also expect that this can fit on one line - we allow 119 chars, and it is not too complicated to understand.
I think this blank line can be removed.
chop blank line
chop blank line
could probably omit some blanks lines
chop blank line
omit "Tests that" prefix in favor of just stating the expected behavior
Frankly, I don't remember the details here, and I only have time to glimpse the PR now, but it seems that there may be two cases where multiple rows of returned values may be expected: `bulk_create()` on one hand, and an `UPDATE` statement on the other (you wouldn't need to returned values in an ORM `update()` call, but you would need them in the lower-level API).
I checked and on PostgreSQL we have a list of tuples for multiple rows and a tuple for a single row; on MariaDB we have a tuple of tuples for multiple rows and a tuple for a single row :confused: It's a really implicit logic, we should support both formats in: https://github.com/django/django/blob/8f2a6c76d19e4010c4683b20ed7f1eb4b07c17eb/django/db/models/query.py#L1257-L1260
I wonder why it works without `list()` on PostgreSQL :thinking:
Do we need to call `str()` on `contraint_sql`? ```suggestion if contraint_sql: schema_editor.execute(constraint_sql + ' NOT VALID') ```
Maybe something along the lines of: For databases which do not support returning clause we need to ask the database for the id. Generally last_insert_id is only supported for serial/auto_incr columns, hence we guard it for auto field. \# TODO: Maybe add a marker to fields that their value can be returned by last_insert_id instead of a type check. +/- typos and style cleanups ;)
Should also include `block_size` and `parallelism`
This will accept prefixless sha1 hashes which weren't accepted previously.
Same as above, I'd revert to the simpler version. The main idea behind `decode` for me is a consistent interface where it makes sense, we don't have to bend backwards just to use it.
no need for "ok" variable.. can return directly.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
no restructured text (:class:) in docstrings please
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Use single quotes consistently.
We could lowercase the vendored files, that would help at least for the `zh-*` variants.
Cannot this information solely be extracted from the model itself? ie `.model._meta.app_label`.
Also, the atomic(savepoint=False) is really cheap (no DB action at all) when used inside another atomic. So, the atomic() here makes the atomic() inside save cheap enough to not matter (of course, benchmarks tell the truth).
This makes makes it not obvious at all that the contents of the `try/except IntegrityError` are properly wrapped in a transaction. This is necessary to prevent errors on databases which actually enforce transactional integrity on errors like PostgreSQL.
Indeed this one looks fine. It will have beneficial performance effects if: - ATOMIC_REQUESTS is not in use - `update_or_create` ends up creating an object - the `save` method of that objects does long things like sending email _after_ the write (i.e. once it holds an exclusive lock on the database)
I'd add a note about why "condition" is special.
That would hide the `update_condition` kwarg from signature, that's why I suggested a sentinel should be used.
See also my recent Trac ticket suggesting to normalize behavior across Python versions.
Please check with Python 3.6, no exception is raised here (see a7a7ecd2b026c61a39a46d2d7eced0e06a92c970).
``` python # the following time is equivalent to UTC 2014-03-13 05:34:23.24000 ```
``` python # but in UTC, the __date only matches one of them ```
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
I added `exc_value` to the message as suggested by Chris.
a one -> one
What do you think about moving the logic from the loop to a separate hook (as suggested by Chris)?, this will create a separation between iteration through exceptions and their tracebacks e.g. ```python def get_traceback_frames(self): ... frames = [] # No exceptions were supplied to ExceptionReporter if not exceptions: return frames # In case there's just one exception, take the traceback from self.tb exc_value = exceptions.pop() tb = self.tb if not exceptions else exc_value.__traceback__ frames.extend(self.get_inner_traceback_frames(exc_value, tb)) while exceptions: exc_value = exceptions.pop() exc_frames = self.get_inner_traceback_frames(exc_value, exc_value.__traceback__) frames.extend(exc_frames) return frames def get_inner_traceback_frames(self, exc_value, tb): frames = [] exc_cause = self.explicit_or_implicit_cause(exc_value), exc_cause_explicit = getattr(exc_value, '__cause__', True) while tb is not None: # Support for __traceback_hide__ which is used by a few libraries ... frames.append({ 'exc_cause': exc_cause, 'exc_cause_explicit': exc_cause_explicit, 'tb': tb, 'type': 'django' if module_name.startswith('django.') else 'user', 'filename': filename, 'function': function, 'lineno': lineno + 1, 'vars': self.filter.get_traceback_frame_variables(self.request, tb.tb_frame), 'id': id(tb), 'pre_context': pre_context, 'context_line': context_line, 'post_context': post_context, 'pre_context_lineno': pre_context_lineno + 1, }) tb = tb.tb_next return frames ``` Probably, this could be simplified even more.
I didn't suggest using a single loop, but two nested loops, first by exceptions and the second by traceback frames for each exception. Using a single loop is not readable and causes tests failures.
`Final exception` doesn't appear in a template. I added check for `During handling of the above exception`.
Yes, this should be taken care of before.
You're calling `model_name.lower()` twice in most cases
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
I don't think you need `list()` here.
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
Wouldn't it be a bit more helpful for this error message to specifically note that the module with the given path couldn't be imported? "Invalid" is a very vague term, which could mean all sorts of things - it seems unhelpful to silence an `ImportError` and replace it with a much vaguer message.
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
has a -> is of a
I'd include the min length in the error message
you can use `a` here again.
assertEquals (deprecated alias) -> assertEqual I would also reverse the order of the arguments and use `self.assertEqual(Article.objects.all().count(), 0)`. That is what I have seen most often in tests.
This can be single-lined.
You can reuse `Article`, e.g. ```suggestion Article.objects.filter(headline='Article 1').update(author=self.author_1) Article.objects.filter(headline='Article 2').update(author=self.author_1) Article.objects.filter(headline='Article 3').update(author=self.author_1) Article.objects.filter(headline='Article 4').update(author=self.author_2) articles = Article.objects.values('author').annotate(count=Count('author')) self.assertCountEqual(articles, [ {'author': self.author_1.pk, 'count': 3}, {'author': self.author_2.pk, 'count': 1}, ]) ```
I guess we could use `bulk_update` but not a big deal.
Since `separate_logs` seems like a higher-level mode that does multiple things, maybe you can make it so the mode doesn't need to be stored as an attribute. For example, the following line could write to a `self.output_stream` that defaults to `os.devnull`. When running in script mode, it could be set to `self.stdout`. It would also eliminate the need for an `if` statement.
We don't often use the `msg` param with `subTest()`. Maybe: `"Migration file includes header: %s." % include_header` or just: `include_header=include_header`
I would add `OK`: ```suggestion executor.recorder.delete(app, name) self.stdout.write(self.style.SUCCESS(' OK')) ```
`--prune` is ignored when `--plan` is used. Maybe we should raise an error that they're mutually exclusive.
This should be display when `verbosity > 0`.
chop blank line
Do you think renaming the `kwarg` to `cached=True` would make more sense here? I feel like the double negation might be a bit confusing.
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
I try to avoid "we", e.g. The check allows a double slash, presuming the user knows....
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
This used to be in an `else` clause, now it is not. Meaning that calling `self._extract_initial_form_count()` was pointless, because it will be overridden anyway.
Trailing commas: ```suggestion MAX_NUM_FORM_COUNT: self.max_num, }, renderer=self.renderer, ```
If initial_forms=3 and min_num=4 and extra=3 I'd expect total_forms to be 6 and not 7 EDIT:// oh, I see below that this would probably be a change in backwards compat; in that case never mind ;)
This seems like a highly questionable assumption. It means that anytime you have initial forms, you must use a management form to get correct behavior, correct? I am concerned that the failure mode here (having initial forms but forgetting to include the management form) would be very hard to debug.
I don't think the formset and form situations are parallel. Initial form count is used in a variety of ways throughout formsets and model formsets, including when bound. A probably-incomplete list, gleaned from a quick grep: - Deciding whether a form should be permitted/ignored when totally empty/unchanged (this is allowed for extra/additional/new forms, but not for initial forms). - Many uses in inline-formsets, including deciding whether or not to look for a PK field, deciding whether to pass an `instance` to the individual form when instantiating it, deciding which forms should get initial data passed to them from the initial data passed to the inline formset. I am extremely skeptical that it is feasible (or worthwhile) to correctly maintain backwards-compatible behavior in all these cases while removing the concept of initial forms.
I think the `_db` is redundant here - it's quite clear it refers to the database since we're in database features.
I think we should add this to the opclasses as well then.
Well, mariadb support in the mysql backend. Will get on to that soonish.
How about making these two flags `False` by default, thus making the feature not causing backwards incompatible changes.
I think this can be single lined: ```python # Does the backed support window expressions (aggregate OVER (expression))? ```
I think this test is obsolete now.
Similar to above, the `options =` could be outside the try block.
`resolve_expression_parameter` maybe? You're not really dealing with combinables here (even though they are also combinable), so just go with expression based names I think.
more than one automatically generated field.? sounds better and more natural with the changes.
I wonder if the `isinstance()`condition results in any performance savings? I tend to think always casting might be simpler.
docstring with example input/output would be really helpful
I think I would define the additional parameters as keyword parameter, as in `__call__ `. BTW, thanks for fixing this thread issue I created!
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
Wrap docstrings at 79 characters. Try to avoid "we... " (often this results in simpler language).
I'd inline this helper within the subTest()
I'd write this block a little differently: ```python if isinstance(list_filter, (tuple, list)): # This is a custom FieldListFilter class for a given field. field, field_list_filter_class = list_filter if isinstance(field_list_filter_class, str): title = field_list_filter_class field_list_filter_class = FieldListFilter.create else: ... ```
Following the existing docstring pattern of wording like "Hook for..." seems useful.
" allowed to be deleted permissions" seems like a typo.
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
There's a class method called `setUpTestData()`. Please use that instead.
And I would rename this attribute `superusers` as it's meant to contain multiple users.
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
use snake case, please: `test_login_required()`
I think you can safely remove this.
Can you revert this change? It seems unrelated.
`# PostgreSQL environment variables.`
I think that this comprehension could be collapsed to a single line.
Returning a dict would save you the sorting and the string parsing later in the tests, and environment variables are not sensitive to ordering, anyways.
under what circumstances do we need this? My system has 'UTF-8', so it's not very exciting as that's the default for these functions.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
You could use `subtest()` for the loop.
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
Would this be clearer? ``` max_query_params = connection.features.max_query_params if max_query_params is None or max_query_params >= len(numbers): ```
I guess these could be merged by doing a ```python self.assertEqual( qstr.count("LIMIT 1"), 3 if connection.features.supports_limiting_in_compound else 1 ) ```
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
usual style is to put the ticket number in parenthesis at the end of the sentence
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
`out` and `err` are unused in the second call. IMO we can simplify this call, e.g.: ```python with self.assertRaises(CommandError): call_command(Command(), no_color=True, force_color=True) ```
You can safely join this an the next line. You have up to 119 chars per line. ;)
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
Yeah that's what I suspected too. Stupid SQL.
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
That's fair, the number of these created should be quite limited.
Do we want to use `__slots__` to keep this as thin a layer as possible as it'll probably never have anything else added? ```suggestion __slots__ = ('_alias', '_connections') def __init__(self, connections, alias): super().__setattr__('_connections', connections) super().__setattr__('_alias', alias) ```
I think it's fine to leave it.
This came from the connection proxy for the cache connections -- for checking whether a key is in the cache -- and isn't really applicable to the database connections. I'm not sure that's a problem though -- it'll just complain that the connection is not iterable... This is just an observation.
Again, I suspect we could use `__slots__` here: ```suggestion __slots__ = ('_connections', '_settings') ```
It's unused for empty results, so maybe we can move it below the `try...except` block: ```python try: sql, params = self.compile(col) except EmptyResultSet: empty_result_set_value = getattr( col, "empty_result_set_value", NotImplemented ) if empty_result_set_value is NotImplemented: # Select a predicate that's always False. sql, params = "0", () else: sql, params = self.compile(Value(empty_result_set_value)) else: sql, params = col.select_format(self, sql, params) if alias is None and with_col_aliases: alias = f"col{col_idx}" col_idx += 1 ret.append((col, (sql, params), alias)) ```
This isn't safe unfortunately. Consider the following test results (which fail): ``` def test_empty_expression_char(self): books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value('Empty')), default=Value('Not Empty'), output_field=CharField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, 'Not Empty') def test_empty_expression_datetime(self): from django.utils import timezone from datetime import timedelta now = timezone.now() then = now + timedelta(days=1) books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value(now)), default=Value(then), output_field=DateTimeField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, then) ``` Depending on whether or not there are dbconverters run, these will fail with one of the following kinds of errors: 1. `TypeError: expected string or buffer` 2. `AssertionError: 0 != datetime.datetime(2016, 5, 23, 18, 59, 26, 409777)` For what it's worth, both of these tests fail without your patch too, except they fail during the count just like the report on the ticket says. This certainly needs fixing in some way, but we can't just use 0 as a value all of the time.
Case expressions use Q internally which led me to writing the above tests. I think you're right that EmptyResultSet might be able to be caught directly, and then it could use the `default` argument in place of the static `'0'` you have above. The changes need to be made in tandem though.
You can remove the whole `else:` branch as `None` will be returned by the function implicitly.
Dot is missing: `'Choices are: %s.'`.
I'm not sure if the included traceback will give enough information to debug this, but it seems like a message something like "Rendering `<template name>` raised an exception, so {% include %} will render as an empty string." might be more helpful.
Wording suggestion: "Rendering {% include (template_name) %} raised (error)."
You want to either pass `exc_info=True` or `sys.exc_info()` here. `exc_info=e` only worked because it evaluated to `True`.
I don't think you need to use the `'template - ...'` prefix here, the log is already namespaced under `'django.template'`.
rather than silenced and rendered as an empty string.
; -> ,
You're right. I created a separate PR #8341.
Maybe it will be better to use `django.db.NotSupportedError` instead of `DatabaseError`.
One space after period.
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
`'utf-8'` is the default. We can remove it.
We do this twice, so I'd move `joined_column_names` above the first `index_name` creation.
Actually I think it might be possible to reuse most of `super()._create_index_sql` by using `expressions=[RawSQL(...)]` instead of `columns` to avoid heavy duplication between both methods.
I added a small hook for this.
In most of cases names won't contain multibyte chars, so it should be worth avoiding multiple encoding and slicing, e.g.: ```python if len(table_name.encode()) == len(table_name): table_name = table_name[:other_length] else: # Shorten table name accounting for multibyte characters. while len(table_name.encode()) > other_length: table_name = table_name[:-1] ```
So this can be done because we're not trying to _stream_ the zipped output anywhere, only write to a file. I came up with this which seemed to work well: ```python import pathlib, zipfile class SingleZipWriter(zipfile.ZipFile): def write(self, data): path = pathlib.Path(self.filename) name = path.stem if path.suffix == '.zip' else path.name return zipfile.ZipFile.writestr(self, name, data) ```
Ah I see, okay then.
```suggestion RuntimeWarning, ```
Does `serializers.serialize` write bytes or text to the stream? In the case of the later we should probably use codecs.open or similar (for py2 at least)
`stream=open(output, 'w') if output else self.stdout`
We already have a `reverse_ordering()`. Moreover this solution mutates `OrderBy` expression, so maybe: ```python if isinstance(order_field, OrderBy): if pfx == '-': order_field = order_field.copy() order_field.reverse_ordering() ordering.append(order_field) ```
May as well do the following as a field name can only legally have a single `-` at the start: ```python field_name = part.lstrip('-') ```
I would multiline: ``` field.attname for field in self.lookup_opts.fields if field.unique and not field.null ```
For new code, we're using single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
```python if ordering_fields.issuperset(field.attname for field in fields): ```
I think you can to exclude conditional unique constraints here ```suggestion if not cls._meta.get_field(cls.USERNAME_FIELD).unique and not any( isinstance(constraint, models.UniqueConstraint) and constraint.fields == (cls.USERNAME_FIELD,) for constraint in cls._meta.total_unique_constraints ): ``` Kind of wish there was a way to avoid checking both the field and `cls._meta.total_unique_constraints`.
This change isn't correct as it will disable the check unless testing. Maybe this would work: `if 'django.contrib.auth.backends.ModelBackend' in settings.AUTHENTICATION_BACKENDS`
I think the `hasattr` is unnecessary as the check is after `super().__init__()`. A child class of `BaseForm` will always have a `fields` instance variable, right? Removing the `hasattr` does not cause any tests to fail.
Use `self.username_field` instead.
Please don't make unrelated whitespace changes.
I wonder if it would be simpler and more efficient to filter out all empty querysets. from self and other_qs, then use `qs[0].self._combinator_query('union', qs[1:], all=all)`, accounting for the case where qs might have zero or one elements.
Why are you copying the `QuerySet`s? Shouldn't be necessary as all their attributes are immutable except outside of other operations, and the result cache doesn't seem to affect their use in the combined qs.
The thing is that even if the ORM doesn't have support for it yet using `distinct()` to implement `(UNION|INTERSECT) ALL` might prevent us from adding proper support in the future. What I suggest doing here is setting `query.combinator.all = kwargs['all']` and preventing using `distinct()` on `CombinedQuerySet`. The difference between ordering and combination operation is that the former operates on the _combined_ set of rows while the latter operates on how these rows are combined. I would suggest that options related to combination be passed as `kwargs` (such as `all`) and actions operating of the combined result (`CombinedQuerySet` instances) be added as methods (`order_by`, _slicing_).
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
These tests should be moved to a separate commit.
I see. Thanks @pope1ni and @timgraham
This needs an update following 831358f23d545b8dba017c6b26bd295ba9f6c17d.
Use single quotes
Since index name generation is deterministic, I don't think this is needed. `test_name_auto_generation` already checks for a specific name. If this index is truncated is some different way, then it would be okay to keep it but check for the actual name rather than testing the length.
Use single quotes consistently.
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
It looks like there will be a SQL syntax error due to a trailing comma if gin_pending_list_limit is used without fastupdate. Maybe `with_params` should be a list and joined with `', '`.
Tests for this method seem missing. It seems like we need a better way to build these reprs that's not so complicated and repetitive for each index.
Do you see much value in Django validating this? The error message from PostgreSQL seems clear: `django.db.utils.DataError: value 1 out of bounds for option "gin_pending_list_limit" DETAIL: Valid values are between "64" and "2147483647".
I think that `2**31 - 1` instead of `2147483647` is more readable.
Collapse this decorator into a single line.
I think you could use `self.assertSequenceEqual` rather than this.
Please add a trailing comma.
First we should verify this passes before we toggle `is_active` to False.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
See also my recent Trac ticket suggesting to normalize behavior across Python versions.
Please check with Python 3.6, no exception is raised here (see a7a7ecd2b026c61a39a46d2d7eced0e06a92c970).
```suggestion now = datetime.utcnow() a = DBArticle.objects.create() ```
I don't mind either way, it just took a second to spot the differences between the groups.
I'd chop every other empty line and group the `auto_now` and `auto_now_add`, but that's just cosmetics.
Oh, sorry about that. I didn't notice there was more one commit. If a bug is being fixed even by a refactor, I think a regression test is still useful, but I'll defer to others.
In the places where `validate_key()` was being called before `make_key()`, it seems like this is a behavior change (bug fix?) that should put into a separate commit, maybe even with a regression test. That way introducing the new method will be a pure refactor. An example would be a case where the `version` argument causes the allowed length to be exceeded.
You can pass `key_map` directly as `dict.__iter__` yields keys.
Makes sense, thanks for the investigation!
I'd use `return []` for the initial commit and have a separate commit that does the method removals as that's really a separate issue that's less needed for a backport to 2.0.
You should be able to pass `is_active=False` to `create_user()`.
prefer `setUpTestData` since that executes once per test class instead of once for every method
We can move the test that involves `login()` to the other pull request.
@timgraham It might be more appropriate in another commit then. I believe I wanted to make sure nothing was logged if a m2m backed inline was submitted without changes.
Unless I'm missing the purpose of the rest of the test, it seems sufficient to replace from here down with `self.assertEqual(self.u1.backend, 'django.contrib.auth.backends.ModelBackend')`.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
I suggest testing `if empty_label is not None`, because we can imagine someone wants to set empty_label to the empty string.
Use the indentation style of the other tests. Actually, you can use `assertCountEqual()` instead. Maybe it makes sense to create another Article with a different year to test that the results are correct and not just returning everything.
comma after "list" chop "selects box" (or rephrase... currently it doesn't make sense to me)
actually I think we should set these 3 values from `none_value` in an else after the new elif I suggested above and then remove them as class attributes. There's an issue if someone has subclassed the widget and set `none_value` -- that value would be ignored with this change.
clarify: "model field"
I'd move the exception above or below ObjectDoesNotExist
please alphabetize imports
I'd move all `django.utils.encoding` import to one line.
This import should be alphabetized, but we can fix that up when committing.
`getattr` raises an exception when the attribute doesn't exist and no default is given
`getattr(request, 'csrf_processing_done')` would suffice since `None` is not true.
add trailing comma
Move that below the `csrf_processing_done` -- we do not need to do extra work in that case.
Again single quotes
I don't see much value in including `opts`, `lookup_opts`, or `root_queryset`. I would limit representation to the `model` and `model_admin`. We can always add sth in the future, if needed.
Might be worth renaming this to `self.root_queryset`.
Fair enough if there is precedence for it. I thought `ImproperlyConfigured` was usually used for settings or something affected by a setting being incorrect.
`QuerySet` instead of `queryset` for all instances of it in this exception message.
Also rephrase to a single sentence to avoid mentioning `QuerySet` twice.
Seems like there might be some opportunity to share similar logic in `_if_match_passes` and `_if_none_match_passes` but I'll leave it up to you as to whether or not it'll complicate things.
Removing this 'if' and leaving the return doesn't result in any failures.
Looks like a few tests are missing. If I remove this if/else and just leave `return _not_modified(request, response)`, no tests fail.
```suggestion request.method in ('GET', 'HEAD') ```
PEP 8 hedges about line breaks and binary operators but suggests ultimately that breaking before the operator is better. As long as we're touching this I would suggest breaking before the operators.
Can you please choose a new error code that is otherwise unused.
As noted elsewhere, put the trailing space on this line rather than the next (and in the message below).
Can you please choose a new error code that is otherwise unused.
If changing the messages, please update them in `docs/ref/checks.txt` as well.
Put the `not field.many_to_many` first and the `isinstance()` second, please.
I'm unsure the purpose of `ugettext_lazy` here.
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
`assertNotContains` is a bit fragile; instead I'd like if you could check `response.context` variables.
`.all()[0]` -> `.first()`
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
```suggestion 'The extra_tests argument is deprecated.', ```
Since this is only being used in one test case class, I would put it right before that test case class. If it turns out to be useful for other tests, it could always be moved to a more central location and modified as needed, etc.
I would move the check to the first line of the function since it's right after receiving the argument.
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
I know I suggested it but I think _shadowing_ is the correct term.
Please rewrite `@override_settings` into a single line: ```python @override_settings(STATICFILES_DIRS="a string") ```
We should use `pathlib.Path.cwd()` instead, also there is no need to define a constant.
Does it work if you use `override_settings` for this too? That would be cleaner.
Probably the check functions should be called directly rather than invoking them through `run_checks()` (otherwise, this runs all registered checks across all installed apps which doesn't provide good isolation) -- see `tests/check_framework`.
There's a class method called `setUpTestData()`. Please use that instead.
We don't use `self.value.value` anymore so we don't need to serialize it, we should use name instead, i.e. ```python v_string, v_imports = serializer_factory(self.value.name).serialize() imports = {'import %s' % module, *v_imports} return "%s.%s[%s]" % (module, enum_class.__name__, v_string), imports ```
I think you mean `ByteType`
The fact that you have to call `serialize` to determine if the serializer is appropriate differs from the pattern used with the other ones. To me that's a code smell that hints at the fact we're abusing the serializer pattern here.
Please use 4 space hanging indent as done in other tests.
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
```suggestion def test_stdin_read_inline_function_call(self, select): ```
I think we can chop it.
Smart... This only works because `shell.py` does inner imports, but that does seem unlikely to be refactored
no need for breaking this over multiple lines now
`'bar'` is already in `out` from the first execution of `call_command()`. You should reinstantiate or use `out.truncate(0)` before the second call.
That's all fair. I'm happy with just adding the check for 10+. I just like to ask all the questions to ensure that we think of everything. :wink:
```suggestion raise NotSupportedError('Non-deterministic collations require PostgreSQL 12+.') ``` Also, this exception isn't tested.
We should also remove `self.collation_exists(schema_editor, self.name)` checks.
Collations are not the same as extensions, they are not determine by names. IMO we shouldn't use `IF (NOT) EXISTS` syntax but fail loudly instead. It can create a tricky issues when we will omit creating collations just because the collation with the same name already exists.
```suggestion return 'Create collation {self.name}' ```
I have a feeling something else if off here. The outer query's joining strategy should not have to special case inner queries as they are self contained expressions. My guess is that something is getting mixed up wrt to aliases because the same model is being involved in the outer and inner queries.
This won't work in many cases on Oracle :disappointed:
My only question is if this skip logic is still correctly applied (i.e. none of the other classes that inherited `ExtractorTests` require it)? If you verify that, ship it.
I think this would be slightly cleaner: ```python if self.condition is None: return '' query = Query(model=model) query.add_q(self.condition) compiler = query.get_compiler(connection=schema_editor.connection) # Only the WhereNode is of interest for the partial index sql, params = query.where.as_sql(compiler=compiler, connection=schema_editor.connection) # The base schema editor does the same map on the params, but since it's # handled outside of that class, the work is done here return ' WHERE ' + (sql % tuple(map(schema_editor.quote_value, params))) ```
This is supposed to be the most used Accept content, however I don't think it contains those added spaces.
This assertion is not related with this fix so I would move it to a separate commit.
`assertNotIn` may pass from many reasons. I think it is better to check field value with `self._get_field_values()` hook, e.g. ```python self.assertEqual(self._get_field_values(child_data, 'parent_m2m'), []) ```
You might want to `assertIsInstance(serializer.stream, File)` to make sure the `stream_class` attribute was actually used.
No need to have empty lines, see the code above
you need to drop the `__class__`, the `object` itself should be an instance of `Author`
I'm surprised if `str()` is doing something here since `capfirst()` also has some `str()` calls.
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
Rename this variable to `readonly_fields`. Let's not pollute the code with three things that mean the same thing, i.e. the `uneditable_fields` here and the aforementioned `viewonly_fields`.
`getattr` will throw a `ValueError` if the `to_field` does not exist, this has to be handled.
Please including a trailing comma in the last item of a dictionary so if more items are added we don't need to modify this line again.
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
You can drop this line.
please use hanging indent to make better use of space, e.g. `context = Context({'content': '<b>"Escaped" content to try \'force_escape\ argument & check for errors.</b>'})` might be good here
prefer if you use hanging indent style for this assertion to match the other tests
Please add an empty line above.
Can we wrap this line after the comma.
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
We can remove quotes around the `default`. Please also wrap at 79 chars.
You can probably simulate that with having `run_checks` raise a `SystemCheckError` error instead.
I'd omit a blank line here.
"start argument must be a negative integer, zero, or None, but got %s."
This `raise` seems redundant. I would remove these two lines (629-630) and leave only raise `ValueError(...)` at the end of this method.
They are helpful when using (i)pdb.
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
`TRADITIONAl` → `TRADITIONAL` (You let go of your shift key too early!) Perhaps reword to `# Add TEXT as an alias of TRADITIONAL for consistency with other backends.`
I'd change `TRADITIONAL` to `TEXT` here as we are now implicitly converting `TEXT` to `TRADITIONAL` in your latest change to `explain_query_prefix()` for MySQL. `TRADITIONAL` is just a formatted text-based output in MySQL, and a silly name. I think it is better to provide a more sensible and consistent name for Django to use.
You can skip this check, as MySQL 5.5 is not supported anymore, and maybe it's better to move into a class-variable.
I'm curious if the slashes are needed. Both on MySQL and Oracle, the tests seem to pass without them.
Please position this up near `has_native_uuid_field` and `has_native_duration_field`. You also need to add `has_native_serial_field = False` to `django/db/backends/base/features.py`.
This is already covered in `expressions` tests https://github.com/django/django/blob/9624703a06187060c1a494e533f3e27fed946de3/tests/expressions/tests.py#L749-L760
`assertEqual(list(a), [...])` should be simpler
To fix the Oracle failure, rephrase this query as ``` CaseTestModel.objects.only('pk', 'integer').annotate(... ``` or even ``` CaseTestModel.objects.values('pk', 'integer').annotate(... ``` I don't have it in me to test myself now, but the issue is that if you don't do one of these, then `annotate()` over `fk_rel` implies `GROUP BY` all the fields of `CaseTestModel`; this model includes BLOBs (`TextField`, `BinaryField`) and Oracle refuses to compare them and so they can't be grouped over. By the way, doing this should also make your test faster on all databases except PostgreSQL (I think), because PostgreSQL (AFAIK) is the only one smart enough to realize that grouping over all the columns is really the same as grouping over the PK.
Not necessary AFAIK; `values('cnt')` infers it.
Is there a reason to use `len()` instead of checking the objects? `len()` may take more effort to debug in the event of a failure.
You can have a flatter function (less nesting) by doing: ```python if not remote_field: continue ```
You can reuse `resolve_model_field_relations()`.
The 4 lines above look identical to the `remote_model_key` lines a few lines before, except with `through` instead of `remote_field.model`. Maybe that can be a helper method accepting that argument.
Changes in hooks are included in #14781.
We can take `model_state` from `self.models`, there is no need to pass `model_state`.
Nice work on `validate` 👍
"from VERSION if present" seems inaccurate
It might be better to describe how ISO-8601 or give a reference. I'm not sure that the example helps much. I think a description for `ExtractIsoYear` should be added to the docs as well.
I think it's fine to make them a bit inconsistent (at least for now). I opened an [issue](https://bugs.python.org/issue40300) in Python.
Yes, that's better.
It might not be possible. As far as I could tell, the original patch just did a find/replace without any analysis.
Don't see a test failure with this reverted.
Put the `not field.many_to_many` first and the `isinstance()` second, please.
If changing the messages, please update them in `docs/ref/checks.txt` as well.
Can you please choose a new error code that is otherwise unused.
URL->path would be more correct, I guess.
I think we could just omit the "USER" row if it's not on the request.
I think the template system silences the exception -- I just observed that no data appears in the table. Your proposal is what I had in mind.
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
You don't need the trailing \ here. EDIT: I see you just moved that code, that's fine.
Again, the inheritance chain looks questionable to me if this is needed.
Good idea, I will implement it :+1:
I added warning to docs.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
I think this error message isn't very helpful (i.e. it's not actionable), and it leaks an internal detail, that we monkey-patch response objects with a `templates` attribute). What happened is a detail, what we need to know is **why** it happened, so we can fix it.
`assertRaisesMessage` should be sufficient here.
I moved renaming `_assert_template_used()` to a separate commit.
I moved this to the `test()` method to avoid code duplication.
I think just `Ordering of query string parameters is ignored for distinct names. For example...`
Removed extra code in PR #3852.
An unhandled `SuspiciousOperation` will result in a `400 Bad Request` response which is ok since it is a client error. However, `413 Request Entity Too Large` would be the correct status code for this error.
Is there a reason to move this check? I'd move it to the previous place.
Having this around L152 would be very marginally cleaner from my POV. (Ie. it's similar to `num_post_keys` so makes sense for it to get initialized at same point in the codebase)
We would fallback to an empty `bytes` string as well ```suggestion boundary = opts.get('boundary', b'') ```
We can move the test that involves `login()` to the other pull request.
is this meant to test the `except TypeError` branch in `contrib.auth.authenticate()`? It would be clearer to call that function directly.
This change isn't correct as it will disable the check unless testing. Maybe this would work: `if 'django.contrib.auth.backends.ModelBackend' in settings.AUTHENTICATION_BACKENDS`
prefer `setUpTestData` since that executes once per test class instead of once for every method
Please use assertRaisesMessage to verify this is the ValueError we expect.
please use periods
seems to be missing a placeholder at the end
setUp/tearDown should go at the top of the class.
include trailing comma
chop "should" (just state the behavior)
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
``` # Unmanaged related model that is not a table. ```
Chop blank line.
``` # Unmanaged related model that is a table. ```
``` # Unmanaged origin model that is a table. ```
In that case, sure.
`for (old_field,new_field) in zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many):` makes the code in the loop simpler and removes the need for the hack.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Indexes are not constraints, generally.
You should be able to use direct attribute access here: `remote_field.through`
`len(statements)` => `statements`
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
Right (actually there's a bug in that code, the `ImproperlyConfigured` can never be raised).
This logic seems a little convoluted. Consider: ``` python conns = connetions.values() if settings.DATABASE_ROUTERS else [connections[DEFAULT_DB_ALIAS]] for conn in conns: if (connection.settings_dict['ENGINE'] != 'django.db.backends.dummy' and any(router.allow_migrate(connection.alias, label) for label in labels)): ```
It's rather rare that folks have the Oracle database engine installed locally, so it crashes because `expdp` and `impdp` are not available.
`has_select_for_no_key_update` -> `has_select_for_update_no_key`
Please add trailing comma.
DatabaseError is raised if a ....
IMO this is not a proper fix because `CustomPK` doesn't appear in a `FOR UPDATE OF` statement, so this can cause a data loss. Both models should be included.
Heh. This line was an `assertRaisesMessage` before, I recommended that it be changed to assertRaises to make the test less prone to break on trivial code changes. The message's content is essentially just "Not supported" anyway, so I think we should leave it this way.
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [BookForeignObj] ```
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [AuthorWithIndexedNameAndBirthday] ```
We can add `Foo.objects.create()` to ensure that primary key and sequence are still valid.
I moved extra tests to a separate PR, see #16049.
Is it possible to use something from `connection.ops` or similar to avoid a vendor check? Otherwise, looks good.
> @felixxm in my view, below test code is our expected result. No, it's not. `1 != NULL` so why it's expected that `number` is excluded? see 512da9d5855 and ticket-23797 for more details.
> my changs affect when LHS is annotation field and RHS is not field. I know, but this is also an issue with nullable annotation so we should fix it in this PR. If it is a different branch in `build_filter()` then we have another reason to add some hook.
I really don't like that we increase indentation here, it make code less readable, and it's complicated even without this :disappointed: We could reduce the number of changes significantly with: ```python if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) clause.add(condition, AND) # When col is nullable, add IS NOT NULL. col = self._gen_cols(reffed_expression) if col: lookup_type = condition.lookup_name target = col.target if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None and self.is_nullable(target): lookup_class = target.get_lookup('isnull') col = self._get_col(target, target, alias) clause.add(lookup_class(col, False), AND) return clause, () ``` and reverting related adjustments.
FYI I ran into the same issue of `AttributeError: 'generator' object has no attribute 'target'".` with this test checking if this PR fixed the issue when using exclude with an `alias` (flagged up in duplicate [ticket-32896](https://code.djangoproject.com/ticket/32896)): ```python # ExcludeTests def test_exclude_aliased_nullable_fields(self): number = Number.objects.create(num=1, other_num=1) Number.objects.create(num=2, other_num=2, another_num=2) qs = Number.objects.alias(aliased_num=F('num')) self.assertSequenceEqual( qs.exclude(another_num=F('aliased_num')), [number], ) self.assertSequenceEqual( qs.exclude(aliased_num=F('another_num')), [number], ) ```
yeah having an `Expression.nullable` flag that is also present on `Col` instance based on the `Field.null` they resolve would be useful for a few other things I've worked on in the past.
I think it's fine.
I think we should add extra checks, - raise `ValueError` if `self.include and index_type == 'spgist'`, e.g. _"Covering exclusion constraints only support GiST indexes."_, - raise `NotSupportedError` if `self.include and not schema_editor.connection.features.supports_covering_gist_indexes`, e.g. _"'Covering exclusion constraints requires PostgreSQL 12+.'"_.
I think this could be `@cached_property` so it doesn't have to be calculated on every access.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
Use single quotes
Yes, this should be taken care of before.
don't need an else here (raising PermissionDenied short-circuits), that'll make the diff less scary too.
If I understood the above code correctly, then `self.field` is on the source model, whereas `self.model_admin` points to the target admin, I think we should really rename those to avoid confusion.
Use single quotes consistently.
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
I didn't follow the discussion closely but was there a reason for not including the duplicate value in the message? I thought that was in the first version of the message.
Right, I'll sumit a PR shortly with the required changes.
It was in the initial version of patch when bases and managers were not also checked. If you think this must be present I can submit a PR with the previous changes.
Suggestion: "Found duplicate value %s in CreateModel managers/fields/bases argument."
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
I'd move the entire `geoadmin` folder to the `geoadmin_depracated`.
```suggestion @ignore_warnings(category=RemovedInDjango50Warning) ```
Un-needed as described below. It should also solve the isort errors.
Please rewrite `@override_settings` into a single line: ```python @override_settings(STATICFILES_DIRS="a string") ```
Would os.path.normpath() be better here? It seems to remove the trailing slash.
```suggestion cached_files = Path(settings.STATIC_ROOT).joinpath("cached").iterdir() ```
The slashes are stripped off by `pathlib`: ```suggestion STATIC_ROOT=self.test_dir / "static", MEDIA_ROOT=self.test_dir / "media_root", ```
The slashes are stripped off by `pathlib`: ```suggestion STATIC_ROOT=self.test_dir / "static", MEDIA_ROOT=self.test_dir / "media_root", ```
`settings.LANGUAGE_CODE` as you pointed out.
We generally omit `Test that...` in docstrings. You could start by `No exceptions are generated...`
No need for ticket reference.
no ticket reference needed
Temporary file can be empty here, so we don't need these two lines.
`Exception as e`
Call `super` here instead.
Why is `Vary: Cookie` in this list? Doesn't that contradict the stated goal of the test? (I realize that it won't pass without that, until #3672 is merged).
Can we deprecate passing `None` in `errors` in a separate PR? and do this in advance. There is already a lot of changes in this patch, that should make it more readable and easier to review. I can try to refactor this out if you don't have time to keep working on this.
Thanks :+1: , IMO a separate ticket is not necessary, we can `Refs #33348 -- ...`.
Use `assertNotIn` instead.
Sure. A test to check for the issue above, for example!
~~Are you sure the `Value` wrapping and the `output_field` are necessary here? As long as you pass an `output_field=models.BooleanField()` to `Case.__init__` you should be good to go.`~~ _Edit: Well it looks like passing `output_field=models.BooleanField()` to `Case.__init__` doesn't work yet._
FWIW `Q(Exists(is_ceo)) | Q(Exists(is_poc))` already works and `Exists(is_ceo) | Exists(is_poc)` doesn't require much changes. ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 5b82ae97a7..d18de75e9a 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -101,6 +101,8 @@ class Combinable: return self._combine(other, self.BITRIGHTSHIFT, False) def __or__(self, other): + if getattr(self, 'conditional', False) and getattr(other, 'conditional', False): + return Q(self) | Q(other) raise NotImplementedError( "Use .bitand() and .bitor() for bitwise logical operations." ) diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py index 6c00f813d9..d3d75f1ce1 100644 --- a/tests/expressions/tests.py +++ b/tests/expressions/tests.py @@ -595,11 +595,9 @@ class BasicExpressionsTests(TestCase): def test_case_valid_in_filter_if_boolean_output_field(self): is_ceo = Company.objects.filter(ceo=OuterRef('pk')) is_poc = Company.objects.filter(point_of_contact=OuterRef('pk')) - outer_1 = Employee.objects.filter(Case( - When(Exists(is_ceo), then=Value(True)), - When(Exists(is_poc), then=Value(True)), - default=Value(False, output_field=models.BooleanField()) - )) + outer_1 = Employee.objects.filter( + Exists(is_ceo) | Exists(is_poc) + ) self.assertQuerysetEqual( outer_1, ['<Employee: Joe Smith>', '<Employee: Frank Meyer>', '<Employee: Max Mustermann>'], ```
omit the blank line
Running `test_incorrect_field_expression_in_join()` without a fix, doesn't behave like it's described in the ticket on the PostgreSQL database. It raises: _"django.db.utils.ProgrammingError: operator does not exist: character varying = integer"_ IMO using `ceo__pk` instead of `ceo_firstname` should fix this issue.
How about making these two flags `False` by default, thus making the feature not causing backwards incompatible changes.
I think we should add this to the opclasses as well then.
Well, mariadb support in the mysql backend. Will get on to that soonish.
I think this can be single lined: ```python # Does the backed support window expressions (aggregate OVER (expression))? ```
We should add release notes for these feature flags.
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
There's a class method called `setUpTestData()`. Please use that instead.
Do we need this mapping? We could redirect to a `HttpResponse` with the `status_code`, e.g. `HttpResponse(status_code=r.redirect_type)`.
don't remove double newline and imports should be alphabetized (`from django.core` would be above `from django.db.models.signals`)
Usually we camel case assertions to match the unittest style. Maybe assertFieldsInModel (considering field_outputs is a list).
Revert unrelated changes.
@tchaumeny reverted fa534b9 here.
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
single line looks okay here
I think this test would be fine without the blank lines, it's fairly short.
Please drop that new line
Can you please unfold this loop. It's hard to check what actually failed if one item in the list fails.
```suggestion 'Accept': '*', 'Host': 'example.com', ```
Okay, I'll drop that point, however, it seems odd to me to reject an empty scheme even if someone specifies `schemes=['']` (which seems unlikely anyway). I don't know that rejecting this case is important.
I'd omit the `shortcut_url` variable and put this directly in the `get()`.
A bit unrelated, but I would move the closing parenthesis to improve readability: ``` statement.parts['extra'] = ' WITH (pages_per_range={})'.format( schema_editor.quote_value(self.pages_per_range) ) + statement.parts['extra'] ```
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Use single quotes
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
```suggestion '<option value="" selected="">---------</option>', ```
```suggestion '<option value="" selected="">---------</option>', ```
Why `BORN` is uppercased? :thinking: ```suggestion # Add new Country from the born_country select. ```
```suggestion self.assertEqual( ```
Maybe: ```python self.assertEqual(len(self.selenium.find_elements( By.CSS_SELECTOR, '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]', )), 1) ``` or ```python selector = '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]' self.assertEqual(len(self.selenium.find_elements(By.CSS_SELECTOR, selector)), 1) ```
Fine. They're gone. 😀
OK. That makes sense. Let me have a go at re-writing that.
https://github.com/django/django/pull/10692/commits/deadb225ccb703b24ee685e079930541149e2370 (which is a `fixup`)
add trailing comma
I would omit the parenthesis in these messages (I know it's done elsewhere, but "I am at war" with that style unless you like it).
Can you reproduce any failure without `modify_settings()`? This test doesn't need anything from `PostgresConfig.ready()` :game_die: :thinking:
Use a more descriptive name? Looks like this would fit on a single line.
I'm not sure this should be committed.
Usually we camel case assertions to match the unittest style. Maybe assertFieldsInModel (considering field_outputs is a list).
Please test for all of the extra registered range types - you should be able to make use of `self.subTest()`.
```suggestion return datetime.datetime(**kw, tzinfo=tzinfo) ```
```suggestion if match := datetime_re.match(value): ```
If I can bring a little bit of nuance to my position. Yes, Python supports aware time. However, the majority opinion in Django contributions (AFAIK) is that using this feature is likely to result in worse design than not using it. Many users aren't experts able to delineate narrow sets of circumstances under which code manipulating aware times is more likely to be correct (e.g. "my code will never be used outside HK and HK will never introduce DST [alternative: I will write a unit test that fails if HK ever introduces DST]"). The recommendation would be to manage the time and the timezone in separate objects. There are other cases where Django diverges from Python's standard behavior. For example, I have found the transaction behavior mandated by PEP 249 less than helpful for most users and I have decided to default to autocommit in Django instead.
```suggestion if match := date_re.match(value): ```
```suggestion if match := time_re.match(value): ```
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
single line looks okay here
I think a list comprehension would be more readable.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
longer lines here are okay, we try to avoid non-multiple of 4 indents
There is no need to use `assertRaisesRegex()`: ```suggestion msg = 'Migration 0001_initial already exists. Use a different name.' with self.temporary_migration_module(module='migrations.test_migrations'): with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
IMO there is no need to check a file content: ```suggestion msg = '...' with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
> If a migration is squashed twice [1](#user-content-fn-squash-b8f940599d11ece48c2972b0da589b55), Yes, it's not currently supported, see ticket-24529.
You can safely join this an the next line. You have up to 119 chars per line. ;)
You can safely join this an the next line. You have up to 119 chars per line. ;)
I would change this so each of the positional arguments is checked against `self.suppressed_base_arguments`. Then e.g. `--verbosity` doesn't have to be listed first when both `-v` and `--verbosity` are provided. Also, if this is done, then `name` doesn't need to be distinguished / given a name in the argument list.
Please remove type annotations. We don't currently use them in Django.
I think you still want the `-` logic I suggested in the optional argument case (when the first argument starts with `-`). If the first argument doesn't start with `-`, I believe you can restrict to looking at just the argument providing the single name.
I would preserve the original ordering (`-v` then `--verbosity`).
I'd extract the `epilog` string into a variable and re-use it to get the line length down.
above you didn't include a blank line before each elif branch
``` raise InvalidTemplateLibrary( "Unsupported arguments to ..." ```
, -> % (missing tests for this branch) same issue with InvalidTemplateLibrary raised below
I think the `@property` syntax would be more readable here.
Omit the outer `[]` to use a generator instead of list comprehension.
I removed it.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
A bit odd that this test has a doc string and the others don't.
I would either use `self.assertTrue(Carrot.objects.filter(tags__tag='orange').exists())` or `self.assertEqual(Carrot.objects.get(tags__tag='orange'), bear)` but otherwise LGTM.
The same amount of caching would be happening in the approach I'm suggesting. It's just that you would be calling `self.resolve_fields_and_relations() / self.all_relations = ...` (e.g. in a method) instead of accessing a cached property. It just seems like the usage in the PR doesn't really match `@cached_property`'s use case. In addition to what I mentioned above, the calls to `self.all_relations` in the PR aren't using the return value, it's just doing that for the caching side effect, which you could do more simply / explicitly.
> Would that be fine? Or is there something I am missing? `else` is not necessary, there is no need to resolve relations at this point.
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
This should only be performed if the `relations` registry is already computed; `if 'relations' in self.__dict__`
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
The name `test_doesnt_keep_intermediate_files` would be better, to make it come up in a grep for `keep_intermediate_files`.
Just to make sure, this test fails before the change? (It's hard to know with a "negative" test and a hard-coded hash).
```suggestion cached_files = Path(settings.STATIC_ROOT).joinpath("cached").iterdir() ```
`saved_name` is unused, so we can leave only ```python if self.keep_intermediate_files: self._save(hashed_name, content_file) ```
We should use a custom storage for this test (instead of mocking).
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I don't think this test is needed. The default implementation is already tested as well as overriding the method.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
This test belongs with the tests for the delete action in `tests/admin_views/test_actions.py`.
Please add blank line before `class BandAdmin`.
`raise NotImplementedError("ValuesQuerySet does not implement `only()`")`
Arf, this is also not optimal either. `pre_save` can have side-effects, like `django.db.models.fields.files.FileField.pre_save` does 😕 We probably don't want to trigger those here. I mean, serendipitously it would work for the `FileField` because even if the returned value is still the same (so we don't add the `field.name` to `updated_fields`), we actually triggered the side-effect committing the file 😂 However, that seems pretty brittle 😅 I'm not sure what the cleanest/Djangoest approach would be here 🤔 We could add an attribute on the Field class, like `Field.has_pre_save: bool`, but that creates a precedent and users/libs must update their code accordingly. But at least, we would know _for sure_ which fields need to be added and which don't. Any other suggestion is very welcome!
You could use RenameMethodsBase.
The point of `RenameMethodsBase` is to insure that if someone overloads the method then the custom method still gets called. But that's only useful if the implementation of the underlying method hasn't changed. I believe using `RenameMethodsBase` doesn't buy us much here.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Please try to follow the indentation style. Same goes for blank lines between the function definitions.
I haven't had time to look, but we should see what additional arguments `ROUND()` can take in different backends.
Maybe it could be generalized by always passing the explicit argument `D` to 0, if not called differently.
IMO it works exactly the same way in [Oracle](https://docs.oracle.com/database/121/SQLRF/functions169.htm#SQLRF00698) and [MySQL](https://dev.mysql.com/doc/refman/5.7/en/mathematical-functions.html#function_round) database, am I missing sth? 🤔
I think `Sqrt` needs `output_field = fields.FloatField()`.
Ah yes.. I see what you mean.
Sorry, was thinking of something else.
You don't know what a docstring is? Trying googling "python docstring".
```suggestion path( 'lastmod/get-latest-lastmod-none-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_none_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/get-latest-lastmod-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/latest-lastmod-timezone-sitemap.xml', views.index, {'sitemaps': latest_lastmod_timezone_sitemaps}, name='django.contrib.sitemaps.views.index', ), ```
Oh, that surprises me too...
Please use 4 space hanging indent style as seen elsewhere in this file such as `cls.superuser = ...`
I guess `get_admin_readonly_field()` could take `response` instead of `response.context['adminform']`.
Actually `assertContains` checks the `status_code` too, so the other assertion is redundant.
Can you reference the ticket number in the docstring, please.
Can you reference the ticket number in the docstring, please.
preferred style is: ``` @override_settings( INSTALLED_APPS=[ "migrations.migrations_test_apps.lookuperror_a", "....", ], ) ```
This assert can go since we're not using exoplanets anymore.
Chop blank line.
This should be in a `finally` block.
Merged overridden settings into one decorator.
chop blank line
chop blank line
This will need to be tested.
``` # If the filename already exists, generate an alternative filename # until it doesn't exist. ```
chop "should" (just state the behavior)
Chop blank line.
Can you add a `call_count` check, please: https://github.com/django/django/pull/4901/files#diff-c11e6432df7086eda3dfb9ab8e5b2839R1491
if no app*
`file` supports file descriptors so we can use the same workaround like `pytest`: ```python try: faulthandler.enable(file=sys.stderr.fileno()) except (AttributeError, io.UnsupportedOperation): faulthandler.enable(file=sys.__stderr__.fileno()) ```
Maybe _"The 'no_color' and 'force_color' cannot be used together."_.
Something like `test_header_omitted_for_no_to_recipients` may be more descriptive.
This test is passing without any changes.
seems like a helper method to get the attachment path would save some repetition
Can you please unfold this loop. It's hard to check what actually failed if one item in the list fails.
might as well use `setdefault` in the test as well
use single quotes
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
chop blank lines here and below
You can probably use `assertSequenceEqual` here which might be a bit nicer.
move the string to the next line as done in other tests in this file
Put the `not field.many_to_many` first and the `isinstance()` second, please.
If changing the messages, please update them in `docs/ref/checks.txt` as well.
While you're here, please remove the comma.
Using `clashing_pair` in a hint is misleading. We should use appropriate model names not field names or table names.
Can you please choose a new error code that is otherwise unused.
I don't think this test is needed. The default implementation is already tested as well as overriding the method.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
This test belongs with the tests for the delete action in `tests/admin_views/test_actions.py`.
Please add blank line before `class BandAdmin`.
If it's changed to return naive current local time when `USE_TZ=False` (as discussed above) that should also be mentioned here.
I wouldn't have reflowed this line since you didn't make any other changes and it would simplify the diff.
As noted above, `localtime` only works when `USE_TZ` is `True` at this time. There is even a test for this. A straightforward implementation of `localdate` as `localtime(...).date()` will have the same restriction and thus be consistent. It may be useful to make these functions fallback reasonably when `USE_TZ` is `False` for the benefit of pluggable applications. In that case, `localtime()` should return: 1. `datetime.datetime.now()` if no `value` is provided 2. `value` if it is provided and it is naive 3. (probably) an exception if `value` is provided and it is aware The third point is debatable. I tend to be strict in what my code accepts, which may not be a best practice in Python but prevents silent data corruption. It's easy to slip and manipulate the wrong type accidentally when time zones are involved... No changes will be needed in `localdate`; it'll get a consistent behavior automatically if we make these changes to `localtime`. In any case, that should happen in a separate commit.
Yes, I know. I was suggesting that to parallel `localdate`, `localtime` with no `value` when `USE_TZ=False` should return `datetime.datetime.now()` (the naive current local time). I think this may still be a valuable parallel, even though calling `localtime` with a naive `value` does not work. But I don't feel strongly about it. Curious what @aaugustin thinks.
Looking at the parallels between `localtime` and `localdate` again, I wonder how `localtime` ought to behave when `settings.USE_TZ` is `False`. Seems like it ought to just return `datetime.datetime.now()` (that is, the naive current local time) when `value=None`. I think this could easily be accomplished by just calling `now()` instead of the new `_now_utc()` helper. When `value` is set and `USE_TZ=False`, I guess perhaps `localtime` should just have no effect? Or just raise an error? But any change here would be backwards-incompatible, so perhaps not worth it.
this could be 1 line
I think reorganization of the admin views tests deserves its own patch outsie of this ticket.
Test -> Tests (and I suggest a new `test_history_view.py` file since this file is quite large already.
Adding new code in a good location is fine.
See if you can find an existing test case to use. There should be existing tests for log entries that this test could be located with.
Remove unnecessary hanging indent, simplify: `context['can_change_related'] = True`
Remove unnecessary hanging indent, simplify: ```python context['change_related_template_url'] = self.get_related_url(info, 'change', '__fk__') ``` (This makes the line 99 characters, but I think it is clear enough.)
In fact, this should be moved into the definition of `context` above: ```python 'can_view_related': self.can_view_related, ```
If you want to use a new name, that's okay with me, but I think `'has_file_field'` should remain for backwards compatibility.
Move `has_view_permission` above `has_add_permission` for consistency.
```suggestion time_keeper = TimeKeeper() if options.timing else NullTimeKeeper() with time_keeper.timed('Total run'): ```
Add trailing comma.
```suggestion time_keeper.results() ```
I think it's okay to use the variable, IMO, especially since it's used twice further down.
Just to be clear, I meant `processes` variable. But if you want to go with the other suggestion, I won't object.
`CANONICAL_RANGE_BOUNDS` is unnecessary: ```suggestion def __init__(self, *args, default_bounds='[)', **kwargs): ```
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
I saw that you're now handling this at the database level. It makes more sense to me.
Either add `self` or make it `@staticmethod`
`clean` is not only for validation, but also for data modification in a form.
I would keep the tests as atomic as possible. That aside, if you want to test the behavior for `abstract=False`, I would recommend dropping the PK and test that the check fails, hence the code inside the if-statement is actually being executed.
This bit wasn't broken before, right? So, there should be already tests covering this behavior.
You don't need to specify `app_label`.
Which proves that it doesn't work properly because names of indexes should be `check_framework_model1_index` and `check_framework_model2_index`, currently it is `check_framework_abstractmodel_index` in both cases.
`self.assertFalse()` -> `self.assertIs(..., False)` `self.assertTrue()` -> `self.assertIs(..., True)`
I don't have a strong feeling about either case; I think both are equally readable. I was only pushing the `else` alternative forward in the name of consistency. I wish there a was a `try/elif` construct for this exact case.
We usually try to keep the keep only the expression raising the exception dealt with in the `try` clause and move the _safe_ in the `else` clause.
I can see this was already done this way but I think it wouldn't hurt to convert it while you're around.
I do think keeping the try block as small as possible is helpful for understanding how the code is supposed to work.
I find this code a bit confusing -- where is the `FieldError` expected to be raised? `expression.input_field.output_field`? Could you use an if statement for that check rather than try/except or maybe move the code that's not expected to raise into an else block of this try/except? .Not an expert here, so maybe it's fine as is.
I guess `get_admin_readonly_field()` could take `response` instead of `response.context['adminform']`.
Actually `assertContains` checks the `status_code` too, so the other assertion is redundant.
No, it would be admin specific so it doesn't belong there. Just a private API mixin for the Django tests is that I was thinking. It might live in this file, for example.
It's ugly either way, but this way might make it slightly easier to debug if the test fails at some later point. ``` python plot_details_field = list(list(list(response.context['adminform'])[0])[3])[0] self.assertEqual(plot_details_field.field['name'], 'plotdetails') self.assertTrue(plot_details_field.is_readonly) self.assertEqual(plot_details_field.contents(), 'Brand New Plot') ``` I guess it we used the pattern more widely, it might be worth some helper functions to make it easy to extract fields without using magic numbers in the indexing.
I think that's fine.
This is only possible if the database allows multiple constraints on the same fields so we can also check the `allows_multiple_constraints_on_same_fields` feature flag.
We can revert changes in `_delete_unique_sql()`.
I would use the same mechanism as for the `E020` and models' labels instead of `__name__`'s, i.e. ```python indexes = defaultdict(list) constraints = defaultdict(list) ... for model_index in model._meta.indexes: indexes[model_index.name].append(model._meta.label) for model_constraint in model._meta.constraints: constraints[model_constraint.name].append(model._meta.label) ```
Here we also should call `super` and not copy-paste code
This formatting change is not related with a bug fix, please revert.
which must return True if the current user can access the view.
Wrap at 79 chars, please.
Valid point. Feel free to change the decorator in a separate commit.
I think "to override the login_url attribute" is more accurate.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
As far as I'm concerned this should impact only `307` and `308` redirects, so maybe: ```diff diff --git a/django/test/client.py b/django/test/client.py index b26504f762..e4201bead4 100644 --- a/django/test/client.py +++ b/django/test/client.py @@ -827,7 +827,10 @@ class Client(ClientMixin, RequestFactory): if response.status_code in (HTTPStatus.TEMPORARY_REDIRECT, HTTPStatus.PERMANENT_REDIRECT): # Preserve request method post-redirect for 307/308 responses. - request_method = getattr(self, response.request['REQUEST_METHOD'].lower()) + request_method = response.request['REQUEST_METHOD'].lower() + if request_method != 'get': + extra['QUERY_STRING'] = url.query + request_method = getattr(self, request_method) else: request_method = self.get data = QueryDict(url.query) ```
Unless I'm mistaken, there's no equivalent for this in your new `get_request` function.
I'd drop the intermediate variable
The URL may be incorrectly encoded....
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
The reason for this is that your for loop is running on both dbs, at first `allow_migrate()` returns `True` for the first db (`default`) thus setting `connection`, `allowed_len`, `db_alias` accordingly, but you are not terminating the loop, making it try `other` db with `allow_migrate()`, returning `True` and setting the variables again.
The blank space for the string usually goes at the end of the line instead of the start of the next line.
think we should say 'for database "%s".'
a separate model (and same note as above about spaces at end of string)
Regarding multiple database support, I believe we want to do something like this: ``` from django.conf import settings from django.db import connections for db in settings.DATABASES.keys(): # skip databases where the model won't be created if not router.allow_migrate(db, cls): continue connection = connections[db] allowed_len = connection.ops.max_name_length() ... ``` We can also go back to putting the database alias (`db`) in the error message.
Hi, this name should be assert_foreign_key_exists
Use single quotes consistently (could be done above and below also).
This is inconsistent but I think the patch can land as is and the test be modified later on based on the direction of [#24082](https://code.djangoproject.com/ticket/24082).
Makes sense. Lets go with `MyField` then.
longer lines here are okay, we try to avoid non-multiple of 4 indents
In a project where a similar need arose, I chose to sort-of monkeypatch the function instead of copying. The code was, essentially, a general "utility": ``` python def _clone_func(f, new_globals): from types import FunctionType as Function return Function(f.func_code, new_globals, f.func_defaults, f.func_closure) ``` and its use in my child class, adapted to this case: ``` python class WSGIRequestHandler(simple_server.WSGIRequestHandler, object): #... handle = _clone_func(simple_server.WSGIRequestHandler.handle.im_func, globals()) ``` This, essentially, re-interprets the parent class's method with the importing module's globals (of which, the only one relevant is `ServerHandler`). Note the use of `im_func` above to get from the method to the function; also, note that I only tried this on Python 2. I'll see now if it works for Python 3 as well.
Heh. So the fact I used `f.func_code` is a hint that I've been using Python for a while... Here are the versions for modern (2+3) Python: ``` python def _clone_func(f, new_globals): from types import FunctionType as Function return Function(f.__code__, new_globals, f.__defaults__, f.__closure__) ``` and ``` python class WSGIRequestHandler(simple_server.WSGIRequestHandler, object): #... handle = _clone_func(six.get_unbound_function(simple_server.WSGIRequestHandler.handle), globals()) ```
"Log errors..." not "Logs errors..."
override `__init__()` instead. after `super()` then `self.style = no_style()`
I noticed that all logs and prompts have `ERROR` style when using `--scriptable`, e.g.: ![image](https://user-images.githubusercontent.com/2865885/148344507-ada0d115-4a48-4001-81a2-b62c919c5e45.png) ![image](https://user-images.githubusercontent.com/2865885/148344684-e00db0d8-c25f-45fc-ba54-9dfef13eac7c.png) We could create a copy of `stderr` without the `ERROR` style and use it where appropriate :thinking: ```diff diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py index cdb200f22e..096702814c 100644 --- a/django/core/management/commands/makemigrations.py +++ b/django/core/management/commands/makemigrations.py @@ -6,7 +6,7 @@ from itertools import takewhile from django.apps import apps from django.conf import settings from django.core.management.base import ( - BaseCommand, CommandError, no_translations, + BaseCommand, CommandError, no_translations, OutputWrapper ) from django.db import DEFAULT_DB_ALIAS, OperationalError, connections, router from django.db.migrations import Migration @@ -62,9 +62,17 @@ class Command(BaseCommand): help='Output only created migration filepaths to stdout; divert logging and prompts to stderr.', ) + def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False): + super().__init__(stdout, stderr, no_color, force_color) + if no_color: + self.stderr_log = self.stderr + else: + # stderr without the ERROR style. + self.stderr_log = OutputWrapper(stderr or sys.stderr) + ```
Right so I think the skip condition in order to avoid false failures should be: `@unittest.skipIf(connection.ops.max_name_length() > 74` but it would be better if we could keep the skip condition as it is so the test is run on all databases and automatically generate a model that has a field name with length `connection.ops.max_name_length() + 1` If you're still unsure about this, let's sync up on IRC.
I think the skip condition needs to be amended as this test won't pass on DB backends if `connection.ops.max_name_length() >= 74` (the length of the model field), right? It would also be helpful to be a bit more descriptive to say _why_ the test is not required for this database.
more descriptive names would be enhance readability of the test, e.g. "ModelWithLongField", "ModelWithDBColumn"
`long_field_name = 'a' * (allowed_len + 1)`
supports long field names. -> doesn't have a column name length limit.
Does this check make sense now that we only handle it if it starts with a relative path? (ie if the prefix where there it would start with a slash anyways)
@jrwdunham I think you can drop this if, yes
@jrwdunham I'm not an expert here, but from what I read the true assumption is that `SCRIPT_NAME` **never** ends with trailing slash. So in case you do not have subfolder, `SCRIPT_NAME` should be just empty/unset.
Please chop `Refs #25598.`.
As said in the previous PR already, I think we should drop this
This message shouldn't be used when constraint is defined with `expressions`.
We should pass `using` to `check()`.
> It just happens to pretty straightforward here as you can directly call `Constraint.validate` without the `exclude` on the constraint you are interested in validating. That's a suitable workaround, but I feel like it should not be necessary. FWIW before Django 4.1 where this feature was added I added manual validation already, since there constraints with conditions where just skipped.
We should make use of `self.message`.
`FieldError` is untested. Do we need it? It looks unnecessary.
I would have been interested in something closer to werkezeug's. That takes encoding as a parameter, etc. **Edit**: TL;DR skip to https://github.com/django/django/pull/2932/files#r15440287
The latin1 encoding mess is a WSGI thing, Django wasn't always a WSGI framework, and who knows what will be the next best thing in the future. When these things were contained in the WSGIHandler that made sense, but if we extract a reusable function it shouldn't be tied to such specifics.
`repercent` is a confusing name, maybe `repercent_broken_unicode`? Also it needs a docstring with pointers to the RFC etc.
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
Python functions implicitly return `None` if return is not called. I feel being explicit is better for a test.
You don't really need a docstring at all, IMO. The test itself explains it well enough.
Use `setUpTestData` now that two models will be used by two methods.
I think this test would be fine without the blank lines, it's fairly short.
single line looks okay here
```suggestion reg_key_value, _ = winreg.QueryValueEx(reg_key, 'VirtualTerminalLevel') ```
I'm not sure that it makes any sense checking the registry. There is no guarantee that you are using a terminal that uses this. So it could just result in a blanket "on" if this is set. It would be better to take the `ctypes` approach mentioned to check whether currently enabled for the actual terminal in use.
It is also "Windows Terminal", not "Microsoft Terminal".
`Determines` -> `Determine` `will support` -> `supports` This docstring can be single-lined.
Do we really need this inner function? We could just shortcut out early if not a TTY.
Could you please keep the cross-app reference that we had before.
I think, given the way how you rewrite the test function, it's time to split the individual cases into individual test functions.
assertRaisesMessage (and then can also remove `as ex`)
The existing text looks correct to me. If validation is skipped (skip_validation=True), the calling code should call validate_consistency() to do that instead of having this method do it.
I think "by" in this sentence should be replaced by "with": normally we'd say "tried to replace X _with_ Y"
Jinja raises `jinja2.TemplateSyntaxError` in `render()` not in `get_template()` when an error is in the included template, so that's the real usage. We don't need to mock anything here.
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
there's also six.assertRaisesRegex which can be useful for checking the message
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
Unless I'm missing something you don't need to define a class and nest an instance of it in a list to reproduce your use case. Simply passing a callable that throws an exception should do. e.g. ``` python engine = Engine(loaders=[ ('django.template.loaders.locmem.Loader', { 'child': '{{ raises }}', }), ], debug=False) def raises(): raise Exception engine.from_string('{% include "child" %}').render(Context({'raises': raises})) ```
Since `fan_since` is None at this point, the test cannot pass! Same below.
case -> cast in all test names
`).values()` on next line
Clarify "might"? Or simply say `# Silence "Truncated incorrect CHAR(1) value: 'Bob'".`
I'd make it a separate method: `test_cast_to_char_field_without_max_length`
A doc string is needed for get_db_converters so any 3rd party backends know exactly what is expected from this method
Please report bugs at https://code.djangoproject.com/.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
It might be better to describe how ISO-8601 or give a reference. I'm not sure that the example helps much. I think a description for `ExtractIsoYear` should be added to the docs as well.
"Postgres'" looks odd to me. Use "PostgreSQL's" instead.
While moving this, chop "we".
I usually write `msg = '...'`on the line before `with self.assertRaisesMessage(ValueError, msg):` to avoid the unusual indentation.
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
OK. Thanks for taking the extra time to explain. I'll have a think. It's evening for me now. Either way: thank you for your effort!
Probably more important, this means that https://github.com/django/django/blob/cb791a2540c289390b68a3ea9c6a79476890bab2/django/http/request.py#L338 is not guaranteed to read the whole body data. I think we should copy more from werkzeug (they are failing if not everything is readable)
Not your fault (ie this issue already exists), but this code does *not* exhaust the stream; we'd need a while loop here till `read()` returns "" or add an exhaust method like werkzeug
assertEqual(..., True) -> assertTrue(...)
OK , thanks @codingjoe, @cjerdonek both. On reflection, I think it's OK as-is.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
`self.assertTrue` -> `self.assertIn` above and below as well.
The docstring should state the expected behavior rather than including preambles like "Tests that", "Verfies that..." (that is the purpose of all tests).
Please follow the test docstring guidelines in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style
Is this line correct? Above it's `subTest(url=url_name)` but then we `reverse(url_name,...)`
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
This is redundant with an existing assertion, IMO we can drop it.
Yeah that's what I suspected too. Stupid SQL.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
I'm torn whether or not this copy is necessary. When we resolve the expression we do a copy of the subquery anyway. Even if the queryset was cached and evaluated, the resolving will copy a new queryset anyway. ```python qs = Model.objects.whatever() sq = SubQuery(qs) list(qs) # this evaluates the queryset that subquery is holding onto OtherModel.objects.annotate(subq=sq) # queryset is copied here anyway, previous eval doesn't matter ``` Let me know if you can poke holes in my reasoning (it is new years day after all...).
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
assertTrue -> assertIn
I think connection is a bad name to use because of database connections `django.db.connection`.
missing some trailing commas
I would deindent these ] and also include a trailing comma in case more items are added later
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
For the keys, I was thinking we should use the full field name (e.g. 'BigAutoField') rather than some other value like 'big_auto'. I think it would be less mental effort for the developer to have to convert camel case to underscore and remove "field". Let's alphabetize the keys too.
I don't like this suggestion. What do you see as the advantage? Here's why I'm concerned: - It's more verbose - typos in the key name are silently ignored - by implementing a mapping in the base features, it shows which fields are implemented in Django's tests (I don't think we should try to implement all fields proactively but accept PRs if a third party backends needs it)
I was just about to suggest this too :+1:
I would leave it empty (`introspected_field_types = {}`) by default and use `.get()` in tests, e.g. ```python connection.features.introspected_field_types.get('BooleanField') or 'BooleanField'` ```
IPAddressField is removed from Django so shouldn't be listed.
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
To avoid the interesting indentation: ``` msg = "<class 'admin_views.models.Question'> is not registered in the admin." with self.assertRaisesMessage(Http404, msg): ```
No need to use `get_user_model()` (don't think any of the other tests do that?), I think.
`.get(self.live_server_url + reverse('admin:admin_views_question_add'))`
why an empty string? might as well use assertRaises at that point.
```suggestion 'Accept': '*', 'Host': 'example.com', ```
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
Chop blank lines.
blank line not needed
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
Please rebase your branch. Master now supports Python 3 only, so `unicode_literals` may be removed.
I don't think you need `absolute_import` here - you don't need to to do a relative `.models` import a few lines down. You would need it to ensure that `import models` would fail to import the relative module.
newline after json
is print_function needed? it doesn't appear in the rest of the code base.
I guess it's a bit defensive, it helps ensuring that behavior is always identical. `print("hello",)` would give different results in PY2 and PY3 for instance.
We'll also be able to simplify this to the following when #11359 is merged ```suggestion other = Value(other) ```
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
Should be ``self.weight``
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
Do we need `requires_system_checks` flag? All tests pass without this line.
`out` and `err` are unused in the second call. IMO we can simplify this call, e.g.: ```python with self.assertRaises(CommandError): call_command(Command(), no_color=True, force_color=True) ```
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
Please use the same order as in `--help` output, i.e. `--version`, `--verbosity`, `--settings`, `--pythonpath`, `--traceback`, `--no-color`, and `--force-color`.
This can be single-lined.
But it's already covered by the first assertions. Moreover `assertEqual()` uses `assertTupleEqual()` internally.
There is no need to mix these tests with `.extra()` we can use existing columns, e.g. ```python values = Number.objects.values_list('num', 'other_num', named=True).get() ```
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
Relying on pk might be problematic since we shouldn't assume the values that the database might assign.
`first()` is not crucial for this regression, so I've changed this to the `order_by()`.
I think in the first version of the patch you had something like `assertIsInstance(lat, float)` which seemed better to me.
@charettes thanks for the idea. I made PR #7755 with regression fix.
Maybe it will be better to move `force_text` to the return line ```python return force_text(query, self.charset), self._format_params(params) ``` instead of repeating it in each case.
would be helpful to explain what the issue is (e.g. how must the polygon orientation be fixed)
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
chop "Tests that" prefixes, otherwise LGTM. I'm slightly nervous this will create weird edge cases that haven't been tested but I guess that's why it's alpha. :-) (I suggested a simpler commit message in the PR title too).
You can safely join this an the next line. You have up to 119 chars per line. ;)
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
Use `showmigrations` instead of `"migrate", list=True` which is deprecated (we seem to have a bug in `@ignore_warnings` that causes it to leak state as the tests should catch the use of deprecated features and fail).
Yes, please rebase the branch and remove the try/fail pattern as done in 6729b96d8a15048b2295c916c5b881a59d9417a0. If you're unfamiliar with the process you might find https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/working-with-git/#rebasing-branches helpful.
The `index_type = indexes['reporter_id'].pop('type', None)` pattern from the old test should be used rather than a loop -- otherwise, if there' some mistake in the if-condition or if the loop is empty, it's not certain that this assertion will ever run.
I don't expect index names to change radically in the future, if at all, but even if it does, I think simplifying the test is worth the "risk" of having to update it in the future, which seems like no big deal.
Could be removed I think. If there's a use case for any third-party backends we can add it back later.
IMO, this is not related with `index_xinfo` but with naive parsing in introspection on SQLite. I added `_get_index_columns_orders` to fix this issue.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
I kinda dislike that `KeyError` spans this much code, but I do not see a nice way around it either. On a minor nitpick I'd also rename `_get_current_token` to just `_get_token` just to be in line with `_set_token`
add trailing comma
`getattr(request, 'csrf_processing_done')` would suffice since `None` is not true.
`getattr` raises an exception when the attribute doesn't exist and no default is given
Move that below the `csrf_processing_done` -- we do not need to do extra work in that case.
no `u''` prefix -- use `from __future__ import unicode_literals` if you need it.
Please revise the try/except pattern in light of 7fec264e46d2a757f06f857e513072d72686cf9d.
Use `warnings.simplefilter('once')` in this case. There has been a lot of stuff moving around lately in the `Field` and `_meta` API andI just want to make sure the backward compatibility shim you added doesn't use deprecated stuff itself.
I would assert `len(warns) == 1`.
`Editor 1` -> `Editor`
`__unicode__` instead of `__unicode`
Maybe it's better to use `str` here instead of `six.text_type` since you already know that you are in Py3 at this point. Same for the other occurrences of `six.*_type`. Or just use `python_2_unicode_compatible` instead.
This will be slightly different contrary to what is stated in your commit message. Here it was overriding `__str__` with `cls.__text_cast` which is effectively `func(*self.__args, **self.__kw)`. After your change it'll be relying on the original `__str__` which resolves to `str(func(*self.__args, **self.__kw))`. Perhaps this isn't a problem after the following commits though - I'll continue reviewing, but this is noted here.
It think you should be returning `repr(self.__cast())` as this might crash if the proxied object is not and instance of `str`.
As already mentioned, this should be fixed in the earlier commit.
As the code itself hints, there's no reason to assume the imported attribute is a class.
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
Yes, it looks good.
In general, this utility is long overdue. In detail, I think error_prefix is odd here -- you're essentially mixing a piece of error formatting (or even logging) with the function.
Discussion of this function is outside of the scope of this ticket, this is merely a backport of what's already in master and 1.6: https://github.com/django/django/blob/master/django/utils/module_loading.py#L12
Ahh right, I forgot about it. Thanks!
Could use `reduce` here. ```python reduce(operator.or_, content_type_queries) ```
@pope1ni no, it's heavily cached as it's using `ContentType.objects.get_for_model`.
No need for `iter`, a generator expression works just fine.
Current implementation of `get_prefetch_queryset()` assumes that all instances have the same content type (there is an issue), but the fix is not optimal IMO because object IDs can be the same in different content types, e.g. we have two related objects: - object ID 1 with content type ID 1, - object ID 2 with content type ID 2, this query will return also: - object ID 2 with content type ID 1, - object ID 1 with content type ID 2, which is not correct. I know that we are matching them below but still I think we can limit the no. of objects only to actually needed.
Could use `charset` over `character_set`? It's a well-known "word" and losing the underscore might make this less noisy visually, especially in the f-strings. Only a suggestion, feel free to ignore.
I'd change `TRADITIONAL` to `TEXT` here as we are now implicitly converting `TEXT` to `TRADITIONAL` in your latest change to `explain_query_prefix()` for MySQL. `TRADITIONAL` is just a formatted text-based output in MySQL, and a silly name. I think it is better to provide a more sensible and consistent name for Django to use.
`TRADITIONAl` → `TRADITIONAL` (You let go of your shift key too early!) Perhaps reword to `# Add TEXT as an alias of TRADITIONAL for consistency with other backends.`
Wrap at 79 chars.
Please move this above `test_collations()`.
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
Same here, not following order `(value, expected)`
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
This should be outside the try block as it's not expected to raise the exception.
The rest of Django's test use `@mock.patch` so I think we should use that.
Why we have here a `column` from the `old_field`? ```suggestion "column": self.quote_name(column), ```
put self._create_index_name( on the next line of put the suffix="_check") parenthesis on the next line for balance
I'd say "Return a (sql, params) fragment to set a column to null or non-null as required by new_field, or None if no changes are required."
This could be moved closer to where it's used or even eliminated as an intermediate variable.
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
I guess we could use `bulk_update` but not a big deal.
Small nitpick, I would use `bulk_create` here. ``` python Article.objects.bulk_create( Article(pub_date=pub_datetime.date(), pub_datetime=pub_datetime) for pub_datetime in pub_datetimes ) ```
Can we make these multi-line, such as... ``` 'SELECT "postgres_tests_hotelreservation"."id", "postgres_tests_hotelreservation"."room_id", ' '"postgres_tests_hotelreservation"."datespan", ...' '...' ``` ...and so on.
assertEquals (deprecated alias) -> assertEqual I would also reverse the order of the arguments and use `self.assertEqual(Article.objects.all().count(), 0)`. That is what I have seen most often in tests.
Nitpick, you could have used `MAX_GET_RESULTS` here to avoid breakage if we ever change this constant.
There's a difference between this and other cases -- this calls `Logger.error()` directly, while others go through `log_response()`. I'm not sure that, in general, taking threads and async in consideration, calling `sys.exc_info()` out of an `except:` block is valid (although it is done here in all the other cases). However, if it is, we might as well call `security_logger.exception()` instead.
No... But looking at the implementation in `Logger._log()`: ```python if exc_info: if isinstance(exc_info, BaseException): exc_info = (type(exc_info), exc_info, exc_info.__traceback__) elif not isinstance(exc_info, tuple): exc_info = sys.exc_info() ``` If you pass an exception instance, it will decompose it into the `(type, value, traceback)` tuple. [^1] Instead of calling `sys.exc_info()`, perhaps we should hand that off to the logger and pass `exc_info=True` everywhere. Or, perhaps we should instead pass `exc_info=exc` everywhere because `response_for_exception()` is called within the exception block, but could possibly (if unlikely) be called in a different context where `sys.exc_info()` would give the wrong exception. [^1]: Out of interest, there is currently a lot of change going into 3.11 that ditches this 3-tuple mess for exceptions under the hood as it is pointless. Obviously the API will have to keep supporting this for a long time, perhaps forever.
> There's a difference between this and other cases -- this calls `Logger.error()` directly, while others go through `log_response().` Yes, I did notice this. The main difference is that the message is logged before the response is created. That prevents use of `log_response()` by passing `response`, although you can pass `logger` and `level` independently to that function instead. > However, if it is, we might as well call `security_logger.exception()` instead. True. Calling `.exception(…)` is the same as calling `.error(…, exc_info=True)`. > I'm not sure that, in general, taking threads and async in consideration, calling sys.exc_info() out of an except: block is valid (although it is done here in all the other cases). But I guess this is the main thing: If we already have an instance of the exception, why not pass that rather than look it up again with `sys.exc_info()` and run the risk that, somehow, however unlikely, we end up with the wrong exception.
is `str()` needed? I assume `%s` takes care of that.
Or in some cases (e.g. CSRF) it's because we want to log the response under a particular non-default logger. But even in those cases, we never want to double-log a response.
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
if no app*
I'd combine w/previous line for better readability
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Водка')) ```
this should be in `finally` just in case the commands before throw an exception
need a trailing comma to appease isort style
add trailing comma on kwargs
I'd move this ) to the previous line
It should be possible to specify multiple values to allow for fallback where a value is not supported by a user agent: https://www.w3.org/TR/referrer-policy/#policy-token
This is the only case that fails if the patch is reverted.
we lost 'invalid' here
prefer always including a trailing coma so if more items are added we don't have to modify this line again
single line please
try to make this as minimal as possible -- if we don't need all the validators, error_messages, etc. leave them out
I guess the method probably isn't needed but if you want to keep it, please fix it like c62807968d7930bfd34afc2036c67921b943592f.
Please wrap these lines at 79 characters.
I'm not certain `Warn` is the best word now that this is an `Error`, but I'm not sure how to phrase it instead.
The word `generally` doesn't add any value in my opinion.
) goes on the next line.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
too many newlines (check code with flake8).
Use hanging indent: ``` request = WSGIRequest({ 'REQUEST_METHOD': 'POST', ... }) ```
A note about code length, because some users may say "using self.client.get() is more straightforward"... We can also write the lines above (297-301) like this: ``` python view = views.CustomTemplateView.as_instance( RequestFactory().get('/dummy'), foo='bar') ``` That said, the way they are written right now is fine too.
To avoid the interesting indentation: ``` msg = "<class 'admin_views.models.Question'> is not registered in the admin." with self.assertRaisesMessage(Http404, msg): ```
pass the context like the `index` method above does. it's bad practice to include mutables (in this case a dictionary) as the default of a kwarg
This condition is problematic on databases that use random rather than serial pk values (failure observed on CockroachDB).
single line looks okay here
I think this test would be fine without the blank lines, it's fairly short.
Please add a trailing comma.
Something like `id=1` here would also work just as well. Not sure if you rejected that for some reason.
Oh are we creating the `_like` indexes even when `unique=True`? I wasn't expecting that.
According to [Wolfram Alpha](http://bit.ly/29bAENj) that's the same as this and slightly more understandable? ``` python (not old_field.db_index and not old_field.unique and new_field.db_index) or (not old_field.unique and new_field.unique) ```
```suggestion new_field.get_internal_type() in ('CharField', 'TextField')): ```
I'd say "Return a (sql, params) fragment to set a column to null or non-null as required by new_field, or None if no changes are required."
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
( #7778 )
I don't think the docstring is needed -- the comparison is straightforward.
"All MySQL storage engines engines except MyISAM support transactions."
Link is unneeded, I think.
Nit-pick: I think Django generally favors the syntax with parens instead of the `\` continuation char.
I guess none of these lines aren't tested since I don't see any new tests that use `db_tablespace`.
I was expecting to raise a ValueError if these conditions aren't met, similar to what we do with "Index names cannot be longer". I don't think it's a good idea to modify the user provided value as it seems like that would only cause confusion.
It sounds like maybe index_type could be used as the suffix and this method doesn't need that argument. I guess the question is whether index_type should be limited to 3 characters or if truncating the first 3 characters of "index_type" as the suffix is okay.
The hexdigest will always be a fixed length so this only happens if the provided suffix is too long, correct? In that case, I think it would be better to raise an error that the provided suffix is too long.
`path` is unused, so we can use a `_` instead.
I wonder if this might be bit more readable: `model = type('A' * 101, (models.Model,), {'__module__': self.__module__})`
We can use one model with two fields instead of two models.
I don't see much value in using `self.subTest()` here.
Do we expect users to use strings like `&&` and `&` directly anywhere else? It seems like we're exposing an implementation detail we'd usually hide.
Please add a trailing comma.
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
Indeed, we do not need to be so specific. The downside I see when being permissive is a bit more computation by going more often in `get_supported_language_variant` and possible `get_supported_language_variant` lru cache exhaustion. But I don't see a nice alternative.
TIL that character classes also work inside `[]` :D
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
As noted elsewhere, put the trailing space on this line rather than the next (and in the message below).
Can you please choose a new error code that is otherwise unused.
Please check test coverage carefully. I didn't spot a test for this change.
You are leaking information about whether somebody has access or something doesn't exist.
There's no test for the `and not callable(self.lastmod)` branch.
OK, good. Thanks. I think it's fine as it is. 👍
I might handle the `if not hasattr(self, 'lastmod')` as a guard first, to get it out of the way: ```suggestion def get_latest_lastmod(self): if not hasattr(self, 'lastmod'): return None if callable(self.lastmod): try: return max([self.lastmod(item) for item in self.items()]) except TypeError: return None else: return self.lastmod ```
While longer, this avoids creating the extra list, string building and "complex" range calculations: ```suggestion i = None try: while i := lang_code.rindex('-', 0, i): possible_lang_codes.append(lang_code[:i]) except ValueError: pass ``` I know it also uses the walrus operator, but Django 4.0 is targeting Python 3.8+, so it is available to us. It seems much more readable to me. (If this isn't a performance critical path then `contextlib.suppress()` could be used to shave off two lines.)
Is there a need to hardcode pks? This is generally to be avoided, I think.
"nonexistent" would be the word
Please use hanging indentation and capitalize `SQL` syntax, e.g.: ```python cursor.execute( 'CREATE VIEW inspectdb_people_view AS ' 'SELECT name FROM inspectdb_people' ) ```
You don't have to initialize `out` twice. This line can be removed.
actually I think the preferred solution is to omit the u'' prefix, even on Python 2. The output already includes `from __future__ import unicode_literals` so there shouldn't be a problem without it.
There's a lambda called `strip_prefix` in `inspectdb.py` that should be of use.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
```python mo_file_en.with_suffix('.po').touch() ```
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
I think we are missing the `call_command()` here.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
I'm not sure why the change I suggested to add `ATan2.as_sqlite()` targeting SpatiaLite >= 4.3.0 resolved this issue for me locally and not on Jenkins. Could you confirm the version of SpatiaLite on the xenial and bionic boxes, @timgraham? (Maybe a build just needs to be re-triggered.)
Sorry - I should clarify - the tests were failing for float and decimal. This was fixed by inverting the order of the arguments, but that caused integer to fail: ``` ====================================================================== FAIL: test_integer (db_functions.math.test_atan2.ATan2Tests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/usr/lib/python3.6/unittest/case.py", line 59, in testPartExecutor yield File "/usr/lib/python3.6/unittest/case.py", line 605, in run testMethod() File "/home/nick/Sources/django/tests/db_functions/math/test_atan2.py", line 32, in test_integer self.assertAlmostEqual(obj.atan2_sn, math.atan2(obj.small, obj.normal)) File "/usr/lib/python3.6/unittest/case.py", line 878, in assertAlmostEqual raise self.failureException(msg) AssertionError: 1.5707963267948966 != 0.0 within 7 places ``` Casting the arguments to float seemed to then make the integer test pass. If somebody else could scrutinise my suggested fix, that would be great.
Could you also change this line for me? ```diff - Cast(expression, FloatField()) if not isinstance(expression.output_field, FloatField) + Cast(expression, FloatField()) if isinstance(expression.output_field, IntegerField) ``` Don't forget to import `IntegerField`.
@JunyiJ My previous suggestion was to use the `TAN` database function on Oracle, i.e. ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='1 / TAN(%(expressions)s)') ```
You're right :+1:. I missed that.
This will overwrite an explicitly given message if you use ``` python validator = DomainNameValidator(accept_idna=True, message='Only IDNA domain allowed') ```
Not sure if ``` def check(self): return self._check_pattern_startswith_slash() ``` is better or not.
`elif` might be clearer (I understand it's not necessary)
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
How about omitting it until we have a use case? That will save writing tests and docs for a theoretical feature. :-) From a readability point of view, writing a `re_path()` that mixes regexes and converters in the string, and then has to initialize and pass converters in the URLconf sounds nasty and not something to encourage!
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
argument ordering should be reversed
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
The test won't run if it's in the database router.
Still, I wonder if so many tests are needed. I think it would be enough to have one test for ForwardManyToOneDescriptor and ReverseOneToOneDescriptor. In other words, every place that the descriptor is called doesn't need to be tested. Testing the each descriptor once is enough, I think. Please use the context manager version of assertRaisesMessage and follow the style of similar assertions in this file.
Copy / paste? I would have expected the ordering to change for the `duth1` and `duth2` arguments.
non existing -> nonexistent
Why's that? It's non-obvious at first glance.
I made a few edits and squashed commits but before I push those updates I wanted to ask if this test is really needed. None of the changes seem related to verbosity so this test seems unnecessary to me.
You could use single quotes in all strings for consistency (don't worry about existing tests).
Why this restriction? If several files are saved in a quick sequence — for instance with a text editor's "save all" feature" — only the first change willl be taken into account.
Please use parentheses rather than backslashes for line continuations.
There's no need for the `disconnect` function. ```suggestion self.addCleanup(signals.post_init.disconnect, post_signal, sender=Book) ```
If I were writing these tests from scratch, I wouldn't use a separate `expected` variable everywhere (this is related to our preference for longer lines rather than a historical more strict adherence to 79 chars, I think).
@timgraham that's neat but that looks really fragile. Think `return Signal(providing_args=["app_config", "verbosity", "interactive", "using", "apps", "plan"])` where the name would end up being `'return Signal(providing_args'`) which can lead to more confusion than the actual situation. We could also make `assertSignalSent` accept a `msg` argument (like other `assert` methods do) to allow the user to disambiguate the origin of the failure. From my point of view the traceback is explicit enough to point the users at the correct location in their code base and figure out which signal was unexpectedly sent or not.
This is `verbose_name` and you should make it translatable. Look at how other contrib apps do it.
I don't think you need `dispatch_uid` here. AFAIK `dispatch_uid` is largely a workaround for the duplicate import problem that was mostly eliminated by the project structure refactor in 1.4 and completely eliminated by the app loading refactor in 1.7.
This could be indented inside the `if conn.vendor` to avoid a redundant check.
Maybe this inheritance should be refactored a bit as it's not obvious if `PostgreSQLWidgetTestCase` is now using `TestCase` from `PostgreSQLTestCase` or `SimpleTestCase` from `WidgetTest`? e.g. `PostgreSQLTestCase.tearDownClass()` might be moved to a mixin that `PostgreSQLTestCase` and `PostgreSQLWidgetTestCase` can use.
chop blank line
Can replace `**dict(through_defaults, **{…})` and use unpacking generalisations: `**{**through_defaults, **{…}}`.
keep in mind new_ids could be smaller than objs, messing up index order so intermediate_values won't match up, right? Also, new_ids is a _set_, so order is lost.
Missing test for this change.
I noticed that we use keyword-only arguments for `def set(self, objs, *, clear=False, through_defaults=None):` Do we want to so something similar for other methods: - `def add(self, *objs, *, through_defaults=None)`: - `def create(self, *, through_defaults=None, **kwargs):` - `def get_or_create(self, *, through_defaults=None, **kwargs):` - `def update_or_create(self, *, through_defaults=None, **kwargs):`
Oh. Strange. Not sure why that doesn't work. Thanks.
The system check framework will throw an error if a model uses `DecimalField` without those arguments. I'm not sure if there's a use case for instantiating `DecimalField` outside of a model (perhaps in `output_field`, but don't think validators are used there). All in all, I think the current version is okay.
You don't need to break this line, if it's below <=119 characters. It's better readable in my eyes.
This must also take the sign into account. What about: ``` python max_length = self.max_digits + 1 # for the sign if self.decimal_places is None or self.decimal_places > 0: max_length += 1 # for the dot ``` We could also make the sign check conditional based on `min_value` and `max_value` but it would be a mess.
We might want to avoid doing this if `self.localize is True` since `DECIMAL_SEPARATOR` and `THOUSAND_SEPARATOR` should be taken into account in this case.
`to_python()` (add parens)
Single quotes please and wrap at 119 characters. (Please do this everywhere as appropriate.)
Use the `hint` parameter for listing valid values, e.g. ```python E023 = Error( 'You have set the SECURE_REFERRER_POLICY setting to an invalid value.', hint='Valid values are: {}.'.format(', '.join(sorted(REFERRER_POLICY_VALUES))), id='security.E023', ) ``` Also, the current convention is to not have independent numbering for warnings and errors, so use `E023` instead of `E001`.
The list is already sorted, so the sort is redundant.
Only if we use another variable, from the guide: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style > As a guide, f-strings should use only plain variable and property access, with prior local variable assignment for more complex cases I think it's fine as-is
I don't see much value in this docstring.
Use PEP257 verb style for new docsrings: "Create... use..., etc."
+1 to a public method on the handler
This can be moved outside of `try...except...`.
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
return directly, no need for `path` variable.
Doesn't exist in 1.5, be careful when backporting
Do you prefer `references.X` as opposed to importing each class? We've sometimes removed that pattern elsewhere.
`from django.core import signing`
You'll want to use `force_text` here.
Nitpick, `deprecation` comes before `encoding`.
this line should be: `def __init__(self, *args, **kwargs):`
might as well use `setdefault` in the test as well
`assertEqual` (the version you have now is a deprecated alias)
seems like a helper method to get the attachment path would save some repetition
Both `response` vars are unused.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
OK then, thanks for the references.
"from VERSION if present" seems inaccurate
Nice work on `validate` 👍
The primary key attribute can only be retrieved on certain databases, this will not work on Oracle or MySQL.
Tests for `formset_factory()` and `formset_factory()` are missing.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
Please chop unnecessary blank lines.
Add trailing comma.
I should have been clearer but `firstname` and `lastname` can be omited as they'll default to `''` if missing.
Could do `self.assertEqual(qs.get()['float'], 1.2)`
Perhaps I misunderstood Anssi's original intent somehow, but the fact that your filter expression uses INNER joins seems like you're maintaining the status quo at the minimum. @charettes I've just pinged you on IRC but if you've got some thoughts on this I'd like to hear them.
omit the blank line
I don't think it's necessary. In all cases we test the same (default) implementation. A single assertion should be enough, e.g. ```python def test_invalid_fields_in_slicing_f_expressions(self): msg = 'This field does not support slicing.' with self.assertRaisesMessage(NotSupportedError, msg): Company.objects.update(num_chairs=F('num_chairs')[:4]) ```
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [AuthorWithIndexedNameAndBirthday] ```
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [AuthorWithIndexedName] ```
This test is not decorated with `@isolated_apps` so we should use `local_models`. Please move it also outside of the context processor: ```suggestion self.local_models = [BookForeignObj] ```
```suggestion editor.remove_index(Scene, index) ```
I moved extra tests to a separate PR, see #16049.
You could use a loop and subTest to make the test less repetitive. e.g. have a list of dicts like `{'poly__equals': Point(1, 1)}` and then use `qs.filter(**filter_kwarg)` within the loop.
`list` is unneeded here. As an alternative you could use: ``` qs = State.objects.filter(pk=null.pk) self.assertFalse(qs.filter(poly__intersects=LineString((0, 0), (1, 1), (5, 5)))) ```
Chop blank line.
is this to ensure that `bulk_create()` didn't create any objections even though it raised an error? I don't think that's really needed. Otherwise, this patch looks good.
I don't think such a regression is likely and we don't have similar checking elsewhere so I think it's fine to remove. Yes, please squash commits.
please remove added newline
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Don't add a blank line.
Do you think it could be worth deprecating the `host` parameter of `is_safe_url` in favor of an `allowed_hosts` one now that it accepts multiple values? This function is not part of the public API but a lot of third-party applications rely on it.
Wrap at 79 chars, please.
Ticket number and a note about antivirus are not necessary, maybe: ``` """HTML email doesn't contain forms.""" ```
I would add: ``` self.assertIn('<div id="traceback">', htmls[0]) ```
Both `response` vars are unused.
Please drop these unrelated changes.
Remove ticket number. Capitalise first word of sentence.
+1. I like this approach.
Please add an empty line above.
Yes, your version is simpler, Simon.
I'm not sure this `next()` dance is really required, I find the following much easier to read ```python for engine in engines.all(): if isinstance(engine, DjangoTemplates): return engine.engine raise ImproperlyConfigured('No DjangoTemplates backend is configured.') ```
This is mainly to avoid edge cases. Here's an example: Imagine a 3rd-party node sets a value with key `include.html` in `context.render_context`. It's not probable, but perfectly possible. Later `IncludeNode` runs and happens to also use `include.html` as a key. It will pull whatever is already in `render_context` from that previous node when it shouldn't. Using a custom key won't eliminate the edge case completely, but it does reduce the probability of edge cases. The `ExtendsNode` uses a key value of `extends_context`. `IncludeNode` could do something similar.
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
I don't see much value in renaming this method. This wouldn't make it a public API as explicit docs are also required. Also, there is a separate ticket-25671 and #13918 that propose to change related methods. I think we can revert this change for now.
revert this change since you ended up removing has_permission here
Yes, this should be taken care of before.
don't need an else here (raising PermissionDenied short-circuits), that'll make the diff less scary too.
Could you please follow the previous indentation style :)
You can't assume the presence of `self.name` here
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
I think you can use `django.utils.deconstruct` to decorate the class, the `path` argument can be passed explicitly. Since Django 2.0+ is Python 3 only, you can use keyword-only arguments with `*, arg1=None, arg2=None`.
```python hanging = ( indentation, has, a, newline, after, opening, bracket, ) ```
Actually, I think we can skip the router stuff and just use `django.db.connection`. These tests aren't run with custom routers so this'll always be run on the default database. (so we can move the skip condition to `test_long_column_name`).
supports long field names. -> doesn't have a column name length limit.
Same note goes here.
`long_field_name` replaces the existing fields
more descriptive names would be enhance readability of the test, e.g. "ModelWithLongField", "ModelWithDBColumn"
Few naming suggestions: `ordering_element` -> `expr` `ord_sql` -> `expr_sql` `ord_sql_params` -> `expr_params` `additional_sql_params` -> `ordering_params` `ord_clauses` -> `ordering_expr_sql`
Glad to see this gone.
Please chop all unnecessary blank lines.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
Turn (capitalize) add period. sql -> SQL
Yea, it seems a bit unusual, but I don't have an alternative to suggest.
We can move the test that involves `login()` to the other pull request.
email_field_name -> email_address to make it more realistic
As `clean()` can also raise `ValidationError` if overridden I would avoid calling it here and stick to calling `normalize_username()`.
What about using the global user model's `normalize_username` method while returning an instance of `self.model`? ```python GlobalUserModel = apps.get_model(self.model._meta.app_label, self.model._meta.object_name) username = GlobalUserModel.normalize_username(username) password = GlobalUserModel.hash_password(password) user = UserModel(username=username, email=email, **extra_fields) user.password = password user.save(using=self._db) return user ```
Yes a separate PR with unification sounds good.
We could keep the same format as in indexes: ```suggestion return '<%s: %sname=%r%s%s%s%s%s>' % ( self.__class__.__name__, '' if not self.fields else "fields='%s' " % ', '.join(self.fields), self.name, '' if not self.expressions else " expressions='%s'" % ', '.join([ str(expression) for expression in self.expressions ]), ```
Maybe: ```suggestion '' if not self.fields else 'fields=%r ' % self.fields, ```
You can also drop the parentheses :wink:
Remove the blank line.
I would assert `len(warns) == 1`.
Use `warnings.simplefilter('once')` in this case. There has been a lot of stuff moving around lately in the `Field` and `_meta` API andI just want to make sure the backward compatibility shim you added doesn't use deprecated stuff itself.
`str(self.band)` doesn't seem like a realistic value for the message.
please remove the unrelated change
`# Prevent the RuntimeWarning subclass from appearing as an exception due to the warnings.simplefilter() in runtests.py.`
Please move this to a separate commit as an extra test coverage.
This a O(n) scan in `self._result_cache`, not sure this is desirable.
yes I think the `values.contains` point should be discussed on the mailing list if we don't want to explicitly error out in this case. I would personally expect `values.contains` to only accept `dict` instances and `values_list.contains` to only accept `tuple` instances.
Another thing about `self._result_cache` which is problematic is the chaining of `values` (and `values_list`, ..) which will store non-model instances in there. That will result in this strange behavior ```python entry = Entry.objects.get(pk=123) values_queryset = Entry.objects.values('id') values_queryset.contains(entry) # True list(values_queryset) values_queryset.contains(entry) # False ``` I would expect `.contains` to immediately error out `if not issubclass(self._iterable_class, ModelIterable)` or to support `values` and friends in a consistent way. e.g. ```python entry = Entry.objects.get(pk=123) values_queryset = Entry.objects.filter(pk=123).values('id') values_queryset.contains(entry) # Crash values_queryset.contains({'id': 123}) # True values_queryset.contains({'id': 456}) # False list(values_queryset) values_queryset.contains({'id': 123}) # True values_queryset.contains({'id': 456}) # False ``` If we want to go this way the best approach is likely to defer the validation of `obj` and the lookup creation to a new `BaseIterable.contains_lookup(obj)` class method so the implementation can be along the lines of ```python class BaseIterable: ... @classmethod def contains_lookup(cls, queryset, obj): raise NotImplementedError class ModelIterable(BaseIterable): ... @classmethod def contains_lookup(cls, queryset, obj): try: if obj._meta.concrete_model != queryset.model._meta.concrete_model: return False except AttributeError: raise ValueError( 'QuerySet.contains only supports Model objects. You passed in a {}.'.format(type(obj)) ) return {'pk': obj.pk} class ValuesIterable(BaseIterable): ... @classmethod def contains_lookup(cls, queryset, obj): if not isinstance(obj, dict): raise ValueError(...) names = { *query.extra_select, *query.values_select, *query.annotation_select, } if not set(obj) == names: raise ValueError(...) return obj class QuerySet: ... def contains(self, obj): lookup = self._iterable_class.contains_lookup(self, obj) if self._result_cache is None: return self.filter(**lookup).exists() return obj in self._result_cache ```
Erroring out immediately `if not issubclass(self._iterable_class, ModelIterable)` is likely the easiest way to go here. Just wanted to point out that we need to handle this case one way or another.
`An expression containing multiple expressions. Can be used to provide a list of expressions as an argument to another expression, like an ordering clause.`
I believe you can shorten that to `return self.children[:]`.
I'm not sure about using `Expression` here (see similar doubts in #13165) :thinking: I would rather use `WhereNode`, e.g. ```suggestion if not isinstance(self.expression, WhereNode): ``` \cc @charettes
I don't have a strong opinion here as that's probably the only type of non-`Expression` wrapper supported in `ExpressionWrapper` but the previous `if isinstance(self.expression, Expression)` felt more correct.
I have mixed feelings because in other places we check the `resolve_expression` attribute, which we cannot use here 🤔. Neither solution is perfect 😐
`assertIsNot()` as well.
From a quick look I was under the impression that the unit tests for `ModelState` were in there as well, but anyway it's a nitpick.
Well, technically it is not a "deep copy".
Do we need to call `set()` in all tests? it seems unnecessary.
Can you put the `\n`s at the end of the previous line.
A list comprehension is preferable here as `str.join()` converts to list internally anyway. It is better performance to provide a list up front. - https://stackoverflow.com/questions/9060653/list-comprehension-without-in-python/9061024#9061024 - https://github.com/adamchainz/flake8-comprehensions/issues/156 ```suggestion result = ', '.join([ f'{field} = VALUES({field})' for field in map(self.quote_name, update_fields) ]) ```
`update_fields` should always be passed, so there is no need to use `update_fields or ()`.
```suggestion result = ', '.join(f'{field} = VALUES({field})' for field in map(self.quote_name, update_fields or ())) ```
Use `self.quote_name()` to do the quoting of fields: ```suggestion result = ', '.join(f'{field}=VALUES({field})' for field in map(self.quote_name, update_fields or ())) ```
Both `update_fields` and `unique_fields` should be passed through. You can keep them as positional arguments: ```suggestion return super().on_conflict_suffix_sql(opts, fields, on_conflict, update_fields, unique_fields) ```
I'd suggest something like `'example@atm.%s' % 'a' * 63` (and 64 for the invalid one)
We run `createsuperuser` in non-interactive mode so `@mock_inputs` is unnecessary.
These two permissions are never used. Please remove them. `cls.permissionuser` is only used in `test_simple_inline_permissions`. Create it inline there rather than on the class.
this line should be: `def __init__(self, *args, **kwargs):`
This is risky, I would use (in all new tests): ```suggestion Group.objects.all().delete() nonexistent_group_id = 1 ```
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
```suggestion item, fields=fields, using=self.db, ```
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
You mean `super()`? Seems okay to me.
I think it'd work if you put the mixin to the left of the base class where it's used.
I would revert this, i.e.: ```python if self.connection.mysql_is_mariadb and self.connection.mysql_version > (10, 2): return True return self._is_limited_data_type(field) ```
Actually `return field.db_type(self.connection)` should be enough as it defaults to `connection.data_types.get(self.get_internal_type())` https://github.com/django/django/blob/ff5dfbc63a278219cd929449678b99ebec9a4b5f/django/db/models/fields/__init__.py#L684-L688
Makes sense. Falling back to `field.db_type(self.connection)` will cause silent truncation of `ArrayField(CharField(max_length=100)) -> ArrayField(CharField(max_length=50))` and `ArrayField(Field(), size=10) -> ArrayField(Field(), size=5)` though but I guess it's better than crashing.
I think that should be `hire_date` (two words).
Use single quotes.
Use single quotes.
note that `Meta` should appear after fields per: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#model-style I made this one change when I committed it.
Since you don't actually need the instances of all those models, can you use `WindowTestModel.objects.bulk_create()` please.
How about: ``` if storage_engine == 'InnoDB': return self.connection.mysql_version >= ( (10, 2, 2) if self.connection.mysql_is_mariadb else (5, 7, 5) ) return storage_engine in ('MyISAM', 'Aria') ```
comma before "and"
Unrelated: this might be obsolete after 8f97413faed5431713c034897cda486507bf0cc3.
I think I would compose the string before the condition ```python exc_msg = 'database %s already exists' % parameters['dbname'] if exc_msg not in str(e): ... ```
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
This must use `mock.patch` else it will leak between tests as the connection. Also it should be `connection.features.can_rollback_ddl` and not `connection.can_rollback_ddl`.
Two tests i.e. `test_sqlmigrate_ambigious_squashed_migration_name()` and `test_sqlmigrate_squashed_migration()` work without this patch. It's fine to increase coverage but we should move them to a separate commit.
```suggestion self.assertEqual(err.getvalue(), 'No statements found.\n') ```
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
I would use `sites.E101` to separate them from checks related with `CurrentSiteManager`.
```suggestion 'SITE_ID must be an integer', ```
There is no need to `append()` because we have a single error: ```suggestion return [ ```
no need to specify `obj=None` I believe.
"The SESSION_COOKIE_NAME and LANGUAGE_COOKIE_NAME settings must be different." (don't think the hint is needed as it's just repetitive)
The docs say, "For performance reasons, `from_db_value` is not implemented as a no-op on fields which do not require it (all Django fields)."
Why do you fallback to `to_python` method? It's kind of unexpected, since normally `to_python` isn't called from `from_db_value`
`to_python` should _not_ be called here.
According to Django docs: > If present for the field subclass, from_db_value() will be called in all circumstances when the data is loaded from the database, including in aggregates and values() calls. > to_python() is called by deserialization and during the clean() method used from forms. https://docs.djangoproject.com/en/1.8/howto/custom-model-fields/#converting-values-to-python-objects [Here](https://github.com/django/django/blob/8047e3666b0b50bb04e6f16c2a4fb21ddfd5713f/django/contrib/gis/db/models/sql/conversion.py) you can look at from_db_value implementation
Do we need this check? All tests pass without it.
Remove this line as `opts` is already added by `ctx = Context(context)`.
Please remove the added blank line.
Except the message displayed isn't quite right in this case: ``` The X "Great new X" was added successfully. You may edit it again below. ``` It's not true that it may be edited.
Remove this line as `is_popup` is already added by `ctx = Context(context)`. The local variable is just for convenience.
no need to reformat
use `.objects.create` rather than .save()` (works the same, it's just a bit shorter)
I think there's an `assertIs` method.
"Replace" (captialize) chop comma since "so that ..." isn't an independent clause (couldn't be a sentence on its own). Add period at the end of the sentence.
Use `assertIs(..., False)` to check for boolean attributes.
chop blank line
`assertIsNot()` as well.
Well, technically it is not a "deep copy".
From a quick look I was under the impression that the unit tests for `ModelState` were in there as well, but anyway it's a nitpick.
State the expected behavior: MigrationLoader.check_consistent_history() should ignore unapplied squashed migrations that have all of their `replaces` applied.
I moved this test to the `tests/messages_tests/tests.py`.
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
Can you put the `\n`s at the end of the previous line.
Thanks for addressing this.
I think we need to ignore models with `managed=False` or `proxy=True` here as they never receive any database level operations anyways.
You're calling `model_name.lower()` twice in most cases
Is there a reason you used `None` here rather than `constants.GET_ITERATOR_CHUNK_SIZE`? As I was amending the docs with 'The default of ``None`` uses a value of 100." I thought further explanation about that reasoning might be useful.
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
```suggestion def _insert( self, objs, fields, returning_fields=None, raw=False, using=None, on_conflict=None, update_fields=None, unique_fields=None, ): ```
Shouldn't this be along the lines of ```python def iterator(self, chunked_fetch=None): if chunked_fetch is None: chunked_fetch = connections[self.db].settings_dict.get('ENABLE_SERVER_SIDE_CURSORS', True) return iter(self._iterable_class(self, chunked_fetch=chunked_fetch)) ```
Citing @holvianssi on Trac. > The complex solution is to add both the opt-in flag and database settings. The default for the opt-in flag is None, meaning use the default from database settings. True forces this feature on, and False forces the feature off.
single line please
why not define this tuple at import time? `import pytz` seems to already have made the classes accessible.
`value` or `return_value`? or maybe we should swap these lines: ```python if ( not timezone._is_pytz_zone(current_timezone) and timezone._datetime_ambiguous_or_imaginary(value, current_timezone) ): raise ValueError('Ambiguous or non-existent time.') return timezone.make_aware(value, current_timezone) ``` :thinking:
Chop blank line.
Please check with Python 3.6, no exception is raised here (see a7a7ecd2b026c61a39a46d2d7eced0e06a92c970).
> in In.get_prep_lookup and Exact.get_prep_lookup , still there was no failed testcase for this branch. Should I push those changes too? Let's leave it for a separate clean-up.
Should we do the same in `In` and `Exact` lookups? i.e. use `set_values()` instead of ```python self.rhs.clear_select_clause() self.rhs.add_fields(["pk"]) ```
Why? IMO they are affected by exactly the same issue, e.g. ```python long_books_qs = ( Book.objects.filter( pages__gt=400, ) .annotate(book_annotate=Value(1)) .alias(book_alias=Value(1)) ) Book.objects.filter(pk__in=long_books_qs) ```
I'm not sure if this is a good solution. For me, the main question is why `self.lhs.output_field` is set to `generic_relations.TIntegration.tags` and not `generic_relations.TIntegration` :thinking:
`resolve_expression_parameter` maybe? You're not really dealing with combinables here (even though they are also combinable), so just go with expression based names I think.
Do we need to check if `token` is an instance of `Mailbox`? I couldn't find an example that needs this check.
I think we can move this under `try ... except`, e.g. ```python try: token, rest = parser.get_mailbox(addr) if rest: # The entire address must be parsed. raise ValueError nm = token.display_name or '' localpart = token.local_part domain = token.domain or '' except (HeaderParseError, ValueError, IndexError): raise ValueError("Invalid address '{}'".format(addr)) ```
I think we can leave the list of exceptions.
Maybe shorter `# The entire email address must be parsed.`.
What's the rationale for defaulting charset to 'us-ascii'? Given the way the default is calculated in cpython, it seems like this could result in a behavior change when we remove `SafeMIMEText.__init__()` when our workarounds are no longer needed.
I would move it to the `ManageRunserver` class.
Please use triple double quotes around docstrings. ([PEP 257](https://www.python.org/dev/peps/pep-0257/#what-is-a-docstring))
It seems we can probably move deprecation warning handling to the actual test cases now. We can make it a follow-up item after merging the first version of this if you like.
Do we need to check if `token` is an instance of `Mailbox`? I couldn't find an example that needs this check.
In this case, I think a ternary is more complicated to read than: ``` if srid == -1: srid = None ```
IMO there is no need to check a file content: ```suggestion msg = '...' with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
title.verbose_name and same typo in else branch
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
I don't think the intermediate `pattern` variable is needed.
Oh I see, looks good then.
To anyone curious, it's likely a problem of when (or rather, where) `connection.features` gets evaluated. ```python await a_getattr(connection.features, "supports_json_field") ``` is executed in the following order: ```python foo = connection.features bar = a_getattr(foo, "supports_json_field") await bar ``` Evaluating `connection.features` does the following: 1. Since `connection` is a `ConnectionProxy` instance, it first finds a default connection 2. It takes that connection and returns a `DatabaseFeatures` instance bound to it That first step is tricky because it uses the `_connections` object as a cache. `_connections` is an instance of `asgiref.local.Local`, which is thread-local by design. So the same cache instance will contain different attributes depending on where (which thread) it's accessed from. Now, when `connection.features` is evaluated in the main thread, it returns a `DatabaseFeatures` instance bound to the connection object created in the main thread (and only safe to use within that main thread). The last puzzle piece is `sync_to_async`, which creates a one-off worker thread to complete a synchronous function call without blocking the event loop. The `getattr` call executed within `sync_to_async` runs in a new thread. This new thread attempts to use the features object passed from the main thread. Which, in turn, tries to use the connection object created in the main thread (to check if the connection is to a MariaDB server).
Diff reproducing on SQLite: ``` diff --git a/tests/async/tests.py b/tests/async/tests.py index 66eece4b97..0610b6f1b0 100644 --- a/tests/async/tests.py +++ b/tests/async/tests.py @@ -1,13 +1,15 @@ +import _thread import asyncio import os from unittest import mock -from asgiref.sync import async_to_sync +from asgiref.sync import async_to_sync, sync_to_async from django.core.cache import DEFAULT_CACHE_ALIAS, caches from django.core.exceptions import ImproperlyConfigured, SynchronousOnlyOperation +from django.db import connection from django.http import HttpResponse -from django.test import SimpleTestCase +from django.test import SimpleTestCase, TestCase from django.utils.asyncio import async_unsafe from django.views.generic.base import View @@ -25,13 +27,22 @@ class CacheTest(SimpleTestCase): self.assertIs(cache_1, cache_2) -class DatabaseConnectionTest(SimpleTestCase): +class DatabaseConnectionTest(TestCase): """A database connection cannot be used in an async context.""" async def test_get_async_connection(self): with self.assertRaises(SynchronousOnlyOperation): list(SimpleModel.objects.all()) + async def test_validate_thread_sharing(self): + def func(connection): + print(connection.features.supports_json_field) + + await sync_to_async(func)(connection) + + a_getattr = sync_to_async(getattr) + print(await a_getattr(connection.features, "supports_json_field")) + class AsyncUnsafeTest(SimpleTestCase): """ ``` The first version works, wrapping the whole feature check in `sync_to_async`. The second, wrapping `getattr` causes the error.
Using `connection` inside `sync_to_async` correctly finds a `default` connection in `_connections` (which is a `Local` instance). However, using `connection` outside of `sync_to_async` doesn't find a `default` connection in `_connections` and creates a new one. In both cases, `_connections` is the same object according to its `ID`. :exploding_head:
Why not using a `bulk_create` here? I may be a bit obsessed with performance, but I like when tests also are fast ;) ``` python self.objs = NullableIntegerArrayModel.objects.bulk_create([ NullableIntegerArrayModel(field=[1]), NullableIntegerArrayModel(field=[2]), NullableIntegerArrayModel(field=[2, 3]), NullableIntegerArrayModel(field=[20, 30, 40]), NullableIntegerArrayModel(field=None), ]) ```
base class (StatAggregate)
We should also use `quote()` because non-integer primary keys may not work properly, e.g. `_40`. Fixed.
```suggestion return format_html('<a href="{}">{}</a>', url, remote_obj) ```
Could you try to improve this so that there isn't duplication of the HTML and `escape(Truncator(obj)....`
Still I think `'&nbsp;<strong>%s</strong>'` could be factored as a variable and `<a href=...` interpolated inside that. Let's use `format_html` instead of `escape`. This return could go in the `else` block of `try/except/else`.
This could be replaced by `self.remote_field.model._meta.label_lower` https://github.com/django/django/blob/c1b24718e05ea474955777d7bc4d9d5634560cd5/django/db/models/options.py#L136-L138
`~` is not a supported operator, this should be `-`.
About Josh's suggestion, we've considered try/except/fail an antipattern because it hides the original exception and thus makes fixing a failure more difficult. There's no problem with a test erroring rather than failing.
Generally we don't include the ticket numbers unless the issue is an obscure one that benefits from additional context that the ticket provides. If so "Sentence.... (#19513, #18580)." is the usual format
Per new code guidelines, can we use `assertIs`? :)
use `with self.assertRaisesMessage(FieldError, "Aggregate functions are't allowed in this query."):`
remove "but we can't do...."
What I'd prefer is a proper enum type, but we don't have one that we've adopted for use in Django. Lacking that, I don't think there's really much difference between True/False/PROXY_PARENTS and ALL/NONE/PROXY_PARENTS.
Are you using PROXY_PARENTS as some type of flag? We already went through the "flags" path throughout the Meta API refactor and ended by removing it because it required imports. Even though this is an internal function, I would advise to find a better solution because, personally, I don't think it's good practice to have one argument that can be of different types (in this case, boolean or object) as it increases the risk of bugs, and it also can be confusing to other people. But that's just me.
`'bar'` is already in `out` from the first execution of `call_command()`. You should reinstantiate or use `out.truncate(0)` before the second call.
an app containing a locale folder
I think using a semantic name would help here, e.g. `lookup_kwarg_null`
Perhaps something like `allows_not_any`, `allows_empty_choice`? The distinction here isn't "this has a python `None` value", it's a "none of these are included, because the relation is an empty set". Perhaps a docstring along those lines would make sense here, too? Eg. ``` """ Return `True` if a "(None)" choice should be included, which filters out everything except empty relationships. """ ```
If `lookup_params_all` is an instance of `dict` you can iterate over its keys directly: `for key in lookup_params_all`. You can also remove the extra spacing inside any: `any(field_path in lookup_param for lookup_param in lookup_params_all)`. You can detect whitespace issues by running `flake8` from the source.
Might be worth renaming this to `self.root_queryset`.
I'd write this block a little differently: ```python if isinstance(list_filter, (tuple, list)): # This is a custom FieldListFilter class for a given field. field, field_list_filter_class = list_filter if isinstance(field_list_filter_class, str): title = field_list_filter_class field_list_filter_class = FieldListFilter.create else: ... ```
After a quick look I _think_ these can be considered deterministic as well because they don't rely on a connection state directly; they expect `conn_tzname` to be passed as argument.
I'm not sure about raising these exceptions (here, in `_sqlite_datetime_trunc()` and in`_sqlite_datetime_trunc()`), user will get rather unhelpful `OperationalError`: ``` django.db.utils.OperationalError: user-defined function raised exception ``` and we don't do this on other backends.
Sure, perhaps `ValueError` is better. I think PostgreSQL does the nice thing here - silently returning the value unchanged is ugly. Given this is our own implementation, having a third way - returning `NULL` - isn't great. We should align to one of the other two behaviours, and raising an error seems best.
Error is raised only on PostreSQL. On Oracle and MySQL we simply return the same date. Even if we want to raise an exception on SQLite, `NotImplementedError` is probably not the best choice. It's not sth that will or may be implemented in the feature. I'd use `ValueError` as we do in similar cases.
Ah, sorry. Misread these. One gets the quarter number, the other gets the first month of the quarter. Ignore me.
I think we should revert the logging changes as it appears we're adding additional logging calls where they didn't exist before.
My mistake on 500, but "NOT FOUND" is different from "Not Found"
how about `_resolve_special` -> `resolve_error_handler()`. I don't see a need for separate methods like `resolve4XX` and `resolve5XX`, especially when you pass any status code to either and achieve the same result.
Same as above; let's leave it alone for now.
Yeah, and here you could again use the hypothetical `self.inner_exception_handler` context manager. Damn, it'll be nice to clean all this up once old-style middleware is gone!
It might be useful to continue allow passing `None`. That feels a bit more natural to me than passing `set()`.
You can use a literal here: ```py allowed_hosts = {allowed_hosts} ```
I guess if it is a supported interface, it isn't fair to call it a mistake.
This just occurred to me, but would it make sense to structure things so the `CSRF_TRUSTED_ORIGINS` processing can be done just once instead of with each request? (There is similar parsing / processing [below](https://github.com/django/django/pull/13829/files#diff-eaa105f5b436e20dd838c27c7a753ef4cf888edcc8f868c084600f6cb7343166R314-R317) in the referer checking.)
Yeah the settings dependent part could be moved into the `__init__` of the middleware I guess.
I guess "@" is some convention I don't know about.
I added warning to docs.
Is there any reason to take `config` from a `query`? This should be rather a separate `config` as far as I'm concerned :thinking:
So do we need to generate SQL with the same config in the `ts_headline` and an inline `tsquery`? (that's my main question) ```sql ts_headline('french'::regconfig, ..., tsquery(..., 'french'::regconfig), ...) ``` If not then I would prefer to leave config only in `tsquery` and don't duplicate its logic in `SearchHeadline`.
IMO we should check options against PostreSQL names.
couldn't -> can't
I would omit the blank line above each "with", up to you though.
Blank line not needed.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
Please add blank line before `class BandAdmin`.
is the value ever modified such that we need a setup method? if not , I think it would be better if it were simply a class attribute.
There's a typo 24278 should be 24279 -- if you put some thought into it, you'd see this has nothing to do with squashmigrations.
```suggestion def check_allowed_hosts(cls, expected): ```
When fixing the implementation of `RedisCacheClient.get()` to support `default`, this should work fine. ```suggestion ```
prefer a longer line for readability
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
I would keep `if not ...` in the same line.
Wrap strings at 79: ``` 'You have provided values in the LANGUAGES_BIDI setting that are not in ' 'the LANGUAGES setting.', ```
We thought that for some unexpected non-string data types if may be better to return their representation. I think it is not necessary.
The URL may be incorrectly encoded....
Using `str('name=Hello%20G%C3%BCnter')` would also work here but using `six.PY2` could be a nice reminder to remove the `b'...'` branch.
Chop blank lines.
I'd drop the intermediate variable
too many newlines (check code with flake8).
I think we can reuse `Parent` instead of `Author` and maybe add `ChildNullableParent` instead of `Book`.
I think we can reuse `Parent` and `ToFieldChild` models in this test, also this test is not falling without a fix so it has been fix earlier (do you know when?). Please move it to a separate commit.
You can move it to a separate (first) commit in this PR.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
```suggestion self.assertEqual([book.rating_count for book in qs], [1]) ```
Please wrap docstrings at 79 characters and include a period at the end of the sentence.
I'd like to have some actual tests for the underlying foreign keys: see the `self.assertFKExsits()` and `self.assertFKNotExists` usage in `test_rename_model_with_self_referential_fk()`
Please use this style to limit lines to 120 characters so we don't have to scroll to review it: ``` self.assertEqual( ..., ... ) ```
should be `first_state`, not `project_state`, I suspect.
This docstring is unnecessary.
Maybe prepend final sentence with "Since you have set MIDDLEWARE, " -- otherwise it kind of reads as if MIDDLEWARE_CLASSES is _always_ ignored in 1.10.
no need to specify `obj=None` I believe.
Very clever! I figured we were going to have to do something uglier to get at the list of default middlewares, but this works well, and as long as it runs on at least one supported Python version it should alert us to an issue; headers shouldn't ever vary between Python versions.
.get() falls back to None to `False` isn't really needed I think.
Why is `Vary: Cookie` in this list? Doesn't that contradict the stated goal of the test? (I realize that it won't pass without that, until #3672 is merged).
Due to hanging indent, `).first()` should be on the next line.
See my previous review for indentation style of this. Perhaps the common qs stuff before the last filter can be moved to setUpTestData.
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
The closing parenthesis should always go on the next line.
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
You'll have to leave the `or` above to appease `flake8`.
Use `not isinstance(self.max_length, bool)` and wrap the statement in parenthesises instead of using `\`.
This should be `WXXX` instead of `EXXX` since it's a Warning, not an Error.
`'utf-8'` is the default. We can remove it.
I added a small hook for this.
Except the message displayed isn't quite right in this case: ``` The X "Great new X" was added successfully. You may edit it again below. ``` It's not true that it may be edited.
Remove this line as `is_popup` is already added by `ctx = Context(context)`. The local variable is just for convenience.
Remove this line as `opts` is already added by `ctx = Context(context)`.
Please remove the added blank line.
no need to reformat
I'm thinking a single test setting the `custom_name` would be enough.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
> this test is checking the support for a possible object that is seekable but has no `.tell()`. > `tempfile.NamedTemporaryFile()` has `.tell()`. Just as an aside, whether there is any change here or not, but you could do: ```python with tempfile.NamedTemporaryFile() as tmp: del tmp.tell # Emulate seekable file handle without .tell(). ... ```
please use periods
You don't need to mock, it will return `False` for a bad file descriptor.
+1, keep self.verbosity because third-party packages will assume ```self.verbosity``` is part of DiscoverRunner. This is a breaking change that's out of the scope of the PR.
The default level should be `logging.INFO` rather than `DEBUG`. However, I would implement this by making the default `None` (`level=None`) and interpreting `None` as `logging.INFO` in the body of the method.
It simplifies getting the default behavior for callers defining functions that pass through a logging level because they can just pass `None` for the default, instead of having to hard-code the default in a second location or invoke the function in a different way (without passing the argument).
Since this might not be obvious from the method implementation, it's probably worth spelling out with another sentence in the docstring: "A verbosity of 1 logs INFO (the default level) or above, and verbosity 2 or higher logs all levels" (can go on a separate line).
I think something like, "Log the message at the given logging level." would be a bit better. (PEP 8 says no "s" at the end of "Log," by the way.)
This change looks unrelated.
bounds_order (plural? reads funny to me since one bound cannot be ordered)
Seems to fine on a single line.
I think this is fine as-is.
This fails when running from the root directory rather than the tests directory (i.e. `$ ./tests/runtests.py postgres_tests`). Also, the output doesn't make debugging very easy (`AssertionError: 1 != 0`) -- if that could be improved that could be nice.
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
The way I read the docs, it means that if `X-Forwarded-Host` contains a port already we should not attach `X-Forwarded-Port`. So imo we are left with two options: * Throw an error if `USE_X_FORWARDED_PORT` is set to `True` and the forwarded host already contains one. * Simply ignore `HTTP_X_FORWARDED_PORT` if the forwarded host contains a port. I am slightly leaning towards option 1) if it doesn't make the code to ugly (such things are always hard to debug if they don't raise errors)
Couldn't you just call `self.get_port` here to get the `server_port`? The rest of the code looks solid. ie: ``` if settings.USE_X_FORWARDED_PORT: server_port = self.get_port() if server_port != ('443' if self.is_secure() else '80'): host = ... ``` I think that should be enough if someone actually set USE_X_FORWARDED_PORT
Most likely this will not work on Windows because files created with `NamedTemporaryFile` cannot be reopened on Windows (which defeats the whole purpose of naming them in the first place -- I have no idea why `NamedTemporaryFile` even exists on Windows). I'm not saying this is blocking the merge because I don't think we have that many users of PostgreSQL on Windows, but I thought I'd bring it up in case someone wants to check.
Here we need ``` python elif settings.CSRF_COOKIE_DOMAIN is not None and settings.CSRF_USE_SESSIONS: raise ImproperlyConfigured("When CSRF uses sessions, use SESSION_COOKIE_DOMAIN instead of CSRF_COOKIE_DOMAIN") ``` This, to make sure people don't just forget such settings, which probably express some security assumptions about their deployment.
confirmed: ``` >>> from collections import OrderedDict >>> isinstance(OrderedDict(), dict) True ```
Ah, I think I forgot my parens when checking. Thanks for double-checking for me :)
It's only in two places and I don't think it cleans up that much, you'd just end up with `if isinstance(filter_expr, Expression) and filter_expr.is_output_field_boolean():` which is slightly less explicit and slightly slower
Do you think we should build the "is this a boolean field" logic as a method within the expression? It'd hide the mess a bit.
The check should be inside prepare_lookup_value, not in build_filter.
Nuke the `list()` call
Please don't change all the other unaffected lines.
This can be single-lined. Also, please use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion custom_libraries = conf.get('OPTIONS', {}).get('libraries', {}) ```
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
They can be empty for subclasses, I think we can leave it that way.
Put this on the previous line.
Add a custom converter only for MySQL + Concat combination in Concat.get_db_converters()? I believe we are doing the wrong thing for expression converters. We should specialize more (that is, if some aggregate needs custom converters, then add custom converters for that aggregate only instead of for all expressions), and we should also pass the expression instead of the internal_type to backend.get_db_converters. I am going to change the signature of backend.get_db_converters() so that it gets expression instead of internal_type as input parameter.
The problem is MySQL. You can use "--column-type-info" for mysql command line client to see that the return type of the expression is blob. Of course, this being MySQL adding a CAST as char in there doesn't actually do anything. The return type is still blob. You can use "cast(concat(a, b) as char(10000) character set utf8)" to get a real cast as VAR_STRING, but you'll have to supply the length, too. And, this being MySQL you'll get silent truncate of data if the length is too short...
My idea of converters is that backend converters are applied to convert the data to uniform format, then the field converters change that format to the wanted Python object representation. So, in this case, if the bug can't be fixed, then we need to add a backend converter. Doing that for Concat expression would be much better than doing it on all TextFields, but of course before we pass the expressions instead of internal_type to backend's get_db_converters that can't be done. Maybe it is possible to add a cast on SQL level to Concat on MySQL, something like "CAST(Concat('foo', 'bar') AS CHAR)". It might be that if the datatype of Concat expression is incorrect on SQL level, then further operations on the value (say lower()) will not work correctly.
Perhaps this could be a docstring? You might elaborate a bit more -- as someone not familiar with MySQL, it's not clear to me what "improved" means.
I have some nitpicks to these tests but I can push them later after the final review.
Can we use custom `date_friended`? and check is it set properly on an intermediary object.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
is this to ensure that `bulk_create()` didn't create any objections even though it raised an error? I don't think that's really needed. Otherwise, this patch looks good.
no dash in "email"
its so that, for example, a ...
I'd include the min length in the error message
Not sure how much a difference it makes, but it seems better to store this in Python rather than having to read from a text file. Worth it to make the file location customizable? If so, it might be nice to make "common passwords" a separate package so we don't have to include that list in Django. I guess users might not care for the additional setup tasks though.
Scanning a list will not be faster than a membership test of a set (unless the list of words is very small).
``` python not ( isinstance(field, (models.DateField, models.DateTimeField, models.TimeField)) and (field.auto_now or field.auto_now_add) ) and` ```
No, it's unrelated to the underlying database column type, but part of these particular field implementations to define what the "default" value is.
Since we eventually want to get rid of `auto_now` and `auto_now_add`, I'd stick to the `isinstance` check. 3rd party fields can instead inherit from the date and time fields Django provides.
Nitpicking: I don't like the indention here. I'd probably go with: ``` python if (not field.null and not field.has_default() and not isinstance(field, models.ManyToManyField) and not (field.blank and field.empty_strings_allowed)): field = field.clone() ``` The cryptography project uses: ``` python if ( not field.null and not field.has_default() and not isinstance(field, models.ManyToManyField) and not (field.blank and field.empty_strings_allowed) ): field = field.clone() ```
I'd probably change this hunk in the diff to: ``` python if getattr(field, 'auto_now', False) or getattr(field, 'auto_now_add', False): default = timezone.now() internal_type = field.get_internal_type() if internal_type == 'DateField': default = default.date() elif internal_type == 'TimeField': default = default.time() # DateTimeField already has correct default now ```
@lukaszb which contrib/admin file are you talking about? Notice [how contrib/admin/options.py](https://github.com/django/django/blob/master/django/contrib/admin/options.py#L1860) doesn't have the missing new line icon. Make sure not to add two newlines, just put your cursor right where the missing new line icon is and press ENTER once.
There should be 1 newline (the little icon that github displays shouldn't appear).
`except Exception` unless we really have a good reason for a bare except.
A docstring describing the purpose of this test may be useful.
Tests for this feature seem yet to be missing, and I would rename the message a bit ala 'Error in 500 callback'
This is the only case that fails if the patch is reverted.
I think we don't need to define `msg` variable: ```suggestion with self.assertRaisesMessage(ValidationError, 'This field is required.'): ```
Use assertRaisesMessage to verify the message also.
You can use `self.assertIsNone` here.
Same here: ```suggestion with self.assertRaisesMessage(ValidationError, 'Enter a valid duration.'): ```
Removing `**kwargs` from the `as_vendor()` methods sounds good to me.
This and one above, replace `self.function = ..` with `function=...` in as_sql method call.
Again, the inheritance chain looks questionable to me if this is needed.
`LISTAGG` will not work properly without `GROUP BY` clause, it returns reversed string from first row i.e. `htimS nhoJ` for all rows. I would also use `LEVEL` instead of `ROWNUM`, e.g. ```python template=( '(SELECT LISTAGG(s) WITHIN GROUP (ORDER BY n DESC) FROM ' '(SELECT LEVEL n, SUBSTR(%(expressions)s, LEVEL, 1) s ' 'FROM DUAL CONNECT BY LEVEL <= LENGTH(%(expressions)s)) ' 'GROUP BY %(expressions)s)' ) ```
I added warning to docs.
A doc string is needed for get_db_converters so any 3rd party backends know exactly what is expected from this method
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
I would remove extra lookups and based `iso_year` on the `self.lhs`, e.g.: ```python def year_lookup_bounds(self, connection, year): from django.db.models.functions import ExtractIsoYear iso_year = isinstance(self.lhs, ExtractIsoYear) output_field = self.lhs.lhs.output_field if isinstance(output_field, DateTimeField): bounds = connection.ops.year_lookup_bounds_for_datetime_field( year, iso_year=iso_year, ) else: bounds = connection.ops.year_lookup_bounds_for_date_field( year, iso_year=iso_year, ) return bounds ```
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
I was asking as major databases support year extract functions, so year comparing can be done as consequent joining of a transform and standard comparison lookup. So, creating YearGt and etc lookups will become really unnecessary if year transform will just convert datetime to a year representation using EXCTRACT, YEAR or STRFTIME calls (depending on database).
Consider using a single test and `subTest()` to avoid the same boilerplate in each test.
Nit: `test_loader_patterns_not_mutated` (with an "s")
Please test the entire message.
Since `verbosity=1` is the default, you can leave this out. (It's good to be testing the default behavior.)
`captured_stdout()` is unnecessary: ```suggestion suite = runner.build_suite([ f'test_runner_apps.failures.tests_failures.{testcase}', ]) with captured_stderr(): result = runner.run_suite(suite) ```
I think you can simplify the above method implementation quite a bit by using more tailored logic. For example, you can start the method with: ```python if self.verbosity == 0: return ``` and then you're left with just two cases: verbosity `2` or more (log everything), and verbosity `None` and `1` (log `INFO` or higher). This should let you do away with the need for a separate `logging_level` variable. Once your test below is fixed, it should help you understand what's needed here.
No problem, happy to help. Thanks for keeping at it.
Yeah, that works, too.
You can simplify the rest of the method by doing: ```python if self.verbosity == 1 and level is not None and level < logging.INFO: return print(msg) ``` (This is what I meant when I said the `logging_level` variable could be eliminated.)
This test data seems wrong to me. For example, you have verbosity `1` leading to level `DEBUG`, which means that logging at a level of `DEBUG` should result in output per the logic below (since `logging_level >= level` appends `output = True`). That isn't right though, since verbosity `1` shouldn't show `DEBUG`. The test would be a lot easier to understand and update if it was simply a hard-coded, sorted list of tuples, e.g. ```python cases = [ (0, None, False), (0, logging.DEBUG, False), (0, logging.INFO, False), (0, logging.WARNING, False), ... ] ``` Including `level=None` will serve to check the default case. Also, you don't need to check `level=logging.NOTSET` since that's not a level that anyone would ever pass when logging a message. That level is more for when reading what level is set on a configured logger. Having the correct test should help with getting your logic correct in the `log()` method above.
Perhaps the following? ```python collections.deque(self.result, maxlen=0) # consume iterator quickly. ``` Some performance numbers: ``` Python 3.7.0 (default, Sep 15 2018, 19:13:07) Type 'copyright', 'credits' or 'license' for more information IPython 6.5.0 -- An enhanced Interactive Python. Type '?' for help. In [1]: from collections import deque ...: from itertools import repeat ...: n = 10000 ...: %timeit -n1000 [__ for __ in repeat(0, n)] ...: %timeit -n1000 for __ in repeat(0, n): pass ...: %timeit -n1000 list(repeat(0, n)) ...: %timeit -n1000 deque(repeat(0, n), maxlen=0) 195 µs ± 5.2 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 74.3 µs ± 204 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each) 53.2 µs ± 4.66 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each) 43 µs ± 428 ns per loop (mean ± std. dev. of 7 runs, 1000 loops each) ``` So even calling `list()` seems better than an empty loop, and `collections.deque()` is fastest because it is written in C.
Thanks for checking :+1:
@maguayo do you have a better suggestions on how to consume an iterator without materializing it? That seems the most elegant way of doing it to me.
Oh, that surprises me too...
`response.request.method` would be more idiomatic.
I removed these assertions.
adding trailing comma
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
```suggestion self.asserCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
This can be single-lined.
These check should respect `required_db_features`, so we need to omit checking conditions for `UniqueConstraint`\`s if `connection.features.supports_partial_indexes or 'supports_partial_indexes' in cls._meta.required_db_features`.
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
This duplicates logic from `_check_local_fields()` and added unnecessary error `models.E042` which is already covered by `models.E012` in `_check_local_fields()`. I think we should pass fields from `references` to the `_check_local_fields()` and remove redundant logic, e.g. ```python for field_name, *lookups in references: fields.add(field_name) if not lookups: # If it has no lookups it cannot result in a JOIN. continue try: field = cls._meta.get_field(field_name) if not field.is_relation or field.many_to_many or field.one_to_many: continue except FieldDoesNotExist: continue # JOIN must happen at the first lookup. first_lookup = lookups[0] if field.get_transform(first_lookup) is None and field.get_lookup(first_lookup) is None: errors.append( checks.Error( "'constraints' refers to '%s' which results a JOIN attempt, " "JOIN is not permitted in 'constraints'." % LOOKUP_SEP.join([field_name] + lookups), obj=cls, id='models.E042', ) ) errors.extend(cls._check_local_fields(fields, 'constraints')) ```
The wording is a bit inconsistent with the one for check constraints, here there is some duplicate info between the warning and the hint, and it talks about "The constraint" without naming it. I would suggest: ``` checks.Warning( "%s does not support unique constraints with conditions." % connection.display_name, hint=( "A constraint won't be created. Silence this " "warning if you don't care about it." ```
This warning ID was not updated after copy-pasting it.
I would assert against `url_name`, e.g. ```suggestion self.assertEqual(response.resolver_match.url_name, 'overridden_urlconf_view') ```
You can use `@modify_settings`, e.g. ```suggestion @modify_settings(MIDDLEWARE={ 'prepend': 'test_client.tests.urlconf_override_middleware', }) def test_resolver_match_when_urlconf_modified_by_middleware(self): response = self.client.get('/') ```
This should use longer lines (up to 119 characters) or hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I had a similar thought though I wasn't sure if the change would be an improvement or not. "pr" me think "pull request". I haven't reviewed this in detail yet.
Should use `assertRaisesMessage()` to verify the string also.
I would put "decode" into quotes or so (@felixxm can certainly tell us what the proper syntax is)
This warning text could include `type(self).__name__` to provide a bit of additional guidance.
IMO, we should use `self.decode` here.
Mhm that is what I was trying to avoid, because for most hasher a salt length is just that and `must_update` should easily be able to handle that globally if it is returned from `decode`. What this PR certainly misses (and what will show you the existing problems) is a test for the behavior of the `bcrypt` hasher. I think now it's `must_update` will *always* return `True` and set a salt *every* time.
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
This is exactly the same as the previous case, maybe `('test@example.com',)`
format parameters as described above
Please drop that new line
this line should be: `def __init__(self, *args, **kwargs):`
Can you please unfold this loop. It's hard to check what actually failed if one item in the list fails.
Instead of defining `success`, just return directly in the above code. I think it is simple enough.
I take this back and have a deeper look at the tests.
You don't need to mock, it will return `False` for a bad file descriptor.
> This pattern is common to all backends. Note that the `filebased` backend doesn't follow this pattern. It puts the `make_key()` / `validate_key()` lines in a single place: https://github.com/django/django/blob/3445c50a3affc5ae7b1c2712a139d4a5105aeaf5/django/core/cache/backends/filebased.py#L130-L131
FWIW +1 to doing it as a separate clean up. IMO it'll be much clearer what change was where looking back that way.
``` py # #23405 - ... ```
Nitpicking: I don't like the indention here. I'd probably go with: ``` python if (not field.null and not field.has_default() and not isinstance(field, models.ManyToManyField) and not (field.blank and field.empty_strings_allowed)): field = field.clone() ``` The cryptography project uses: ``` python if ( not field.null and not field.has_default() and not isinstance(field, models.ManyToManyField) and not (field.blank and field.empty_strings_allowed) ): field = field.clone() ```
Since we eventually want to get rid of `auto_now` and `auto_now_add`, I'd stick to the `isinstance` check. 3rd party fields can instead inherit from the date and time fields Django provides.
No, it's unrelated to the underlying database column type, but part of these particular field implementations to define what the "default" value is.
``` python not ( isinstance(field, (models.DateField, models.DateTimeField, models.TimeField)) and (field.auto_now or field.auto_now_add) ) and` ```
I'd use `return a if b else c` but it's up to you.
Use double quote docstrtings.
Please add an empty line above.
You can drop this line.
Please report bugs at https://code.djangoproject.com/.
Not sure if this might mask some exceptions, but here's what I came up with for now: ``` python for db in connections: connection = connections[db] try: connection.cursor() except ImproperlyConfigured: # Raised by the dummy backend. pass else: loader.check_consistent_history(connection) ```
I think this should work: ``` python connection = connections[db] if connection.settings_dict['ENGINE'] != 'django.db.backends.dummy': loader.check_consistent_history(connection) ```
Just make it: ``` if len(expressions) < 2: ``` That avoids problems with sqlite and mysql. GREATEST(x) is always x on backends that support single arguments anyway.
I'd rename `subminor` to `patch`.
You're right. You know I both saw that and missed it too...
I would move tuple unpacking to the `for` loop, i.e. ```python for column, expected_string in testable_column_strings: ... ```
Please remove the unnecessary semicolon.
I think we could make use of `self.subTest` here.
Please wrap docstring at 79 chars.
I added `Square` without a sequence to show that delete is used in such case.
Tests for this method seem missing. It seems like we need a better way to build these reprs that's not so complicated and repetitive for each index.
It looks like there will be a SQL syntax error due to a trailing comma if gin_pending_list_limit is used without fastupdate. Maybe `with_params` should be a list and joined with `', '`.
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
Do you see much value in Django validating this? The error message from PostgreSQL seems clear: `django.db.utils.DataError: value 1 out of bounds for option "gin_pending_list_limit" DETAIL: Valid values are between "64" and "2147483647".
I think that `2**31 - 1` instead of `2147483647` is more readable.
Ah right. You noted on the ticket that's not the case with the 'spawn' mode, but I guess we shouldn't concern ourselves with that right now, as the test runner doesn't support that. @Valze - maybe make a note for your spawn-mode GSoC project? 😉
`file` supports file descriptors so we can use the same workaround like `pytest`: ```python try: faulthandler.enable(file=sys.stderr.fileno()) except (AttributeError, io.UnsupportedOperation): faulthandler.enable(file=sys.__stderr__.fileno()) ```
You won't need to pass `INFO` if the default is `INFO`.
I moved this test to the `tests/messages_tests/tests.py`.
I would chop `does_`: ```suggestion if test_match_tags(test, tags, exclude_tags) ```
I think this should be a `ValueError`
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
`Editor 1` -> `Editor`
[`create` already saves the model](https://docs.djangoproject.com/en/dev/ref/models/querysets/#django.db.models.query.QuerySet.create), you don't need to repeat it (same for others below)
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
Low-level tests are not necessary, it should be feasible to test using `Lexeme()` with special characters in a query.
Please revert all unrelated changes from single to double quotes.
Relying on pk might be problematic since we shouldn't assume the values that the database might assign.
Perhaps extend this for a wider range of field types, e.g. `BooleanField`, `IntegerField`, `FloatField`, etc.
I don't think it's necessary. In all cases we test the same (default) implementation. A single assertion should be enough, e.g. ```python def test_invalid_fields_in_slicing_f_expressions(self): msg = 'This field does not support slicing.' with self.assertRaisesMessage(NotSupportedError, msg): Company.objects.update(num_chairs=F('num_chairs')[:4]) ```
I added the comma to be consistent with the `include` and `condition` attributes. Also, on `ExclusionConstraint` we separate attributes by comma but not on `UniqueConstraint`, so 🤷 indeed..
If it has some readability benefits, it could be done in a separate PR. This looks okay for now.
We should use `__qualname__` in all classes.
Not for a single line, the idea is to add one for things like multi-line dicts/tuples so that if more lines are added later, we don't have to modify the last line and add a comma.
I would revert these changes, a string representation of `condition` and `deferrable` doesn't need and extra quotes.
Use `self.quote_name()` to do the quoting of fields: ```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ', '.join(map(self.quote_name, unique_fields or ())), ', '.join(f'{field}=excluded.{field}' for field in map(self.quote_name, update_fields or ())), ) ```
Chop blank line.
```suggestion elif ( on_conflict == OnConflict.Update and not self.connection.features.supports_update_conflicts_with_target ): ```
You should use `supports_update_conflicts_with_unique_fields`.
You can do what I suggested above here as well.
I don't think it a good place for this, I would rather add loop by `self.constraints` and `self.indexes` below ```python self.index_together = normalize_together(self.index_together) ```
Constraints always have names.
These changes have to be as separated commit (since unrelated to ticket)
You can use `super()`: ```suggestion return super().migration_name_fragment + '_not_valid' ```
I would chop _" on all existing rows"_.
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
I think this test isn't working as expected -- it's resolving to `RedirectView`, same with `test_inline_urls` -- probably the result of the resolve should be checked.
```suggestion '<div class="fieldBox field-position hidden">' '<label class="inline">Position:</label>' '<div class="readonly">0</div></div>', ```
`.all()[0]` -> `.first()`
Prefer this indent style: ``` response = self.client.post(reverse('...'), { .... }) ```
Alright let's keep it as it is then. I just wanted to make sure this case was covered by a test.
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
I think this approach is too naïve. `related_model` can be a model class.
could switch to single quotes for consistency
Trailing dot is missing.
We should clean `FILE_RESPONSE_HOLDER` in `finally` to ensure tests isolation, e.g.: ```python try: # Verify that sendfile was used which only happens if file_wrapper got # used. self.assertTrue(handler._used_sendfile) # Fetch the original response object self.assertIn('response', FILE_RESPONSE_HOLDER) response = FILE_RESPONSE_HOLDER['response'] # The response should have been closed ... self.assertIs(response.closed, True) # ... as well as all individual file buffers buf1, buf2 = FILE_RESPONSE_HOLDER['buffers'] self.assertIs(buf1.closed, True) self.assertIs(buf2.closed, True) finally: FILE_RESPONSE_HOLDER.pop('response', None) FILE_RESPONSE_HOLDER.pop('buffers', None) ```
`# Sendfile is used only when file_wrapper has been used.`
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
This isn't Django's default charset (unless I'm mistaken).
```suggestion self.assertEqual( ```
+1, this test was also removed in my force_text audit WIP branch.
Maybe: ```python self.assertEqual(len(self.selenium.find_elements( By.CSS_SELECTOR, '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]', )), 1) ``` or ```python selector = '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]' self.assertEqual(len(self.selenium.find_elements(By.CSS_SELECTOR, selector)), 1) ```
This should go to the 2nd commit :pick:
```suggestion '<option value="" selected="">---------</option>', ```
I'd use a single line.
These changes have to be as separated commit (since unrelated to ticket)
```suggestion "index_together": {("bio", "age")}, # RemovedInDjango51Warning. "indexes": [], ```
Nitpick but `dict.get` default value for a missing key is already `None`.
You don't need to specify `app_label`.
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
I would keep `if not ...` in the same line.
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
Wrap strings at 79: ``` 'You have provided values in the LANGUAGES_BIDI setting that are not in ' 'the LANGUAGES setting.', ```
Good point :+1: @pope1ni All tests pass with `{}` instead of `{!r}`, so I think we can simplify messages and use `{}`.
It should be enough to add a list of missing fields, e.g. ```python _('ManagementForm data is missing or has been tampered with. Missing fields: %s') % ', '.join(form.errors), ```
Trailing commas: ```suggestion MAX_NUM_FORM_COUNT: self.max_num, }, renderer=self.renderer, ```
This should be overridable by `default_error_message` and passing `error_messages` to the formset for consistency with `Field`.
This should pass a `ValidationError` with a code.
Calling `is_valid()` in `__repr__` is not an option (as it triggers validation).
Yeah that's what I suspected too. Stupid SQL.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
I'm torn whether or not this copy is necessary. When we resolve the expression we do a copy of the subquery anyway. Even if the queryset was cached and evaluated, the resolving will copy a new queryset anyway. ```python qs = Model.objects.whatever() sq = SubQuery(qs) list(qs) # this evaluates the queryset that subquery is holding onto OtherModel.objects.annotate(subq=sq) # queryset is copied here anyway, previous eval doesn't matter ``` Let me know if you can poke holes in my reasoning (it is new years day after all...).
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
`HTTPS` is not necessary, so I removed this line.
I'd prefer to decorator the test with `@override_settings` so we don't need to indent the entire test.
Please use single quotes as in other tests.
I find this docstring a bit confusing (copied from elsewhere, I know). I think something like "settings.CSRF_HEADER_NAME can be used to customize the CSRF header name" would be simpler
It seems like there's no longer a need for the defensive use of `.get()` here; `CSRF_COOKIE` must always be set at this point.
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
`test_target_field_may_be_pushed_down` works without the patch. I would move it to a separate commit to make it clear where the behavior has changed.
Would it be worth emphasising that this straying from pythonic expectation is an _undesirable_ behaviour? In case `ModelBase.__new__()` were to get rewritten in future, and whoever works on it ends up thinking they need to be supporting these testcases? Orr just writing the testcase as an expected failure would imply this.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
It would be nice to be consistent about the ordering in `assertEqual` using it's `(variable, 'expected value')` but here and a couple other places it's opposite.
I would rather create a custom model with field that has `db_column`, e.g. ```python project_state = self.apply_operations('test_rfwdbc', ProjectState(), operations=[ migrations.CreateModel('Pony', fields=[ ('id', models.AutoField(primary_key=True)), ('field', models.IntegerField(db_column='db_field')), ]), ]) operation = migrations.RenameField('Pony', 'field', 'renamed_field') new_state = project_state.clone() operation.state_forwards('test_rfwdbc', new_state) ```
I'd probably keep those lines unwrapped. Maximum line length is at 119 chars.
I don't see much value in this check.
This could be made more DRY: ```python for option in ('unique_together', 'index_together'): ... ```
I'd move these methods above "def alter_unique_together" so those alter methods aren't separated from their helper, _delete_composed_index.
Relying on pk might be problematic since we shouldn't assume the values that the database might assign.
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
omit the blank line
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
In the original review of this file, I missed the fact (unless I'm missing something now) that there's no need to call `list()` inside of `len()`.
True, I mixed up sth when switching branches. Nevertheless they work on all databases except PostgreSQL, so we need to fix this.
Please move these tests to the `invalid_models_tests/test_ordinary_fields.py`. Also, we could move a new system check with tests to a separate commit, it would be easier to review.
base class (StatAggregate)
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
```suggestion raise self.exception_class(f'The connection {alias!r} doesn't exist.') ```
You might want to add 2 checks to the `check_settings` in the previous file (or maybe should be a system check?): 1. If `CONN_MAX_AGE == 0` then `CONN_HEALTH_CHECK_DELAY is None`. 2. If `CONN_HEALTH_CHECK_DELAY is not None` then `CONN_HEALTH_CHECK_DELAY < CONN_MAX_AGE`.
python3 tests failed because `six.iteritems(old_test_settings)`.
These settings should be defined per-`DATABASES` entry and not as top level settings. e.g. ```python DATABASES = { 'default': { 'ENGINE': 'django.db.backends.postgresql', 'NAME': 'mydatabase', 'USER': 'mydatabaseuser', 'PASSWORD': 'mypassword', 'HOST': '127.0.0.1', 'PORT': '5432', 'ATOMIC_REQUESTS': True, 'AUTOCOMMIT': True, } } ```
```suggestion params = self.settings[alias].copy() ```
@akulakov `passed_check` is to check if list is not empty. if it is not empty, method will return no error, otherwise error will be returned (`[] if passed_check else [W020]`).
`not statement` is used several times above, so need to be consistent in code style.
@MarkusH - that looks good to me.
@coldmind With the current code, `passed_check` will be `True` if `settings.ALLOWED_HOSTS` IS empty. That is backwards. `passed_check` should be `True` if `settings.ALLOWED_HOSTS` is NOT empty.
Since this is just a type check which should apply to all environments, not just production ones, it doesn't need the `deploy` flag
Makes sense, lets keep things as they are then.
I know the heuristics are not exactly the same but maybe use `rhs_is_direct_value`? ```suggestion if self.rhs_is_direct_value(): ```
This makes me wonder why `SearchQuery` is a `Value` in the first place given it needs to resolve `config` and `value` now.
If look like could subclass `Func` and avoid any `resolve_expression` or `as_sql` overrides. ```python class SearchQuery(SearchQueryCombinable, Func): output_field = SearchQueryField() SEARCH_TYPES = { 'plain': 'plainto_tsquery', 'phrase': 'phraseto_tsquery', 'raw': 'to_tsquery', 'websearch': 'websearch_to_tsquery', } def __init__(value, output_field=None, *, config=None, invert=False, search_type='plain'): function = self.SEARCH_TYPES.get(search_type) if function is None: raise ValueError("Unknown search_type argument '%s'." % search_type) if not hasattr(value, 'resolve_expression'): value = Value(value) expressions = (value,) if config is not None: config = SearchConfig.from_parameter(config) expressions = (config,) + expressions super().__init__(*expressions, output_field=output_field, function=function) if invert: self.template = '!!(%s)' % Func.template ```
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
Don't use a mutable default: `{}`. Should default to `None` and then add : ``` if json_dumps_params is None: json_dumps_params={} ```
" allowed to be deleted permissions" seems like a typo.
I envisioned something like this: ``` python content = None with open(path, read_mode) as f: try: content = f.read() except UnicodeDecodeError: # If mimetype suggests the file is text but it's actually binary, # read() will raise a UnicodeDecodeError on Python 3. pass # If the previous read in text mode failed, try binary mode. if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE ```
We can raise a single error.
I think we should have a test and handling for the case where `mimetypes.guess_type()` returns `None` as done in `_create_attachment()`.
We can raise a single error.
Same style as above.
looks good, but we should move the `allowed_len is not None` check outside the loop as it won't change each iteration
Looking at the code a bit more, I believe we just want to check `f.db_column` -- it will be `None` if the user hasn't provided a value. With the current implementation, if the user provides a value equal to the auto-generated value, we'll inadvertently perform this check.
since we don't use `att_name` you can change the name to `_` -- that's a common convention for unused return values.
Regarding multiple database support, I believe we want to do something like this: ``` from django.conf import settings from django.db import connections for db in settings.DATABASES.keys(): # skip databases where the model won't be created if not router.allow_migrate(db, cls): continue connection = connections[db] allowed_len = connection.ops.max_name_length() ... ``` We can also go back to putting the database alias (`db`) in the error message.
I think the error message that @akaariai provided is a bit better: "Autogenerated column name too long for field [field_name]. Maximum length is [xx] for database alias [somealias]."
We should take keys into account (like in `__eq__()`), so maybe: ```suggestion if hasattr(self, 'error_dict'): return hash(tuple(sorted(make_hashable(self.error_dict)))) return hash(tuple(sorted(self))) ```
You don't need to use `make_hashable()` for primitives: ```suggestion return hash((self.message, self.code, self.params)) ```
I noticed that we missed keys comparison, e.g. `exception_a` and `exception_b` are equal: ```python exception_a = ValidationError({'field1': 'field error', 'field2': 'err'}) exception_b = ValidationError({'field2': 'err', 'field1': 'field error'}) ``` we should fix this, maybe: ```suggestion if hasattr(self, 'error_dict'): return hasattr(other, 'error_dict') and self.error_dict == other.error_dict return sorted(list(self)) == sorted(list(other)) ``` a test is also needed.
We also have to provide `__hash__()` because without it `ValidationError` instances are not hashable anymore.
I think we can simplify this: ```suggestion def __eq__(self, other): if not isinstance(other, ValidationError): return NotImplemented if hasattr(self, 'message'): return ( hasattr(other, 'message') and self.message == other.message and self.code == other.code and self.params == other.params ) return ( hasattr(self, 'error_list') == hasattr(other, 'error_list') and hasattr(self, 'error_dict') == hasattr(other, 'error_dict') and sorted(self.messages) == sorted(other.messages) ) ```
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
These are unnecessary ```suggestion ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
Testing `prepare_database()` is difficult (a lot of mocking is needed to get a proper isolation). IMO we can push this without tests.
Creating and isolating new connections in tests are tricky. > if we don't have yet good mocking structure for ORM-database operations Testing database operations is not difficult, but here we want to test a low-level operations related with preparing a database before using ORM.
We don't use `assert ` in tests. Please use `unittest` assertions: ```suggestion self.assertIs(self._extension_exists(), False) ```
You can assume that PostGIS is enabled, otherwise, the tests won't run at all.
`This test` is unnecessary. Please write `skipUnless` in one line e.g. `@unittest.skipUnless(connection.vendor == 'mysql', 'MySQL specific test.')`.
We should use a custom storage for this test (instead of mocking).
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
use """ for consistency with other docstrings
This is the failing assertion on Windows. I think it might have to do with the file being written with Windows vs. Unix line endings. If you remove the assertion, the rest of the test passes.
Not sure these asserts bring value ... they seem to test that `override_settings` works.
I believe there is a typo here. ```suggestion '`django.forms.BaseForm._html_output` is deprecated.' ```
Shallow copy i.e. `self.non_field_errors().copy()` should be enough. IMO. It doesn't work properly because `ErrorList` is a subclass of `UserList` but we can fix this easily with ```python def copy(self): copy = super().copy() copy.error_class = self.error_class return copy ```
We can drop the backticks, improve indentation, etc. ```suggestion warnings.warn( 'django.forms.BaseForm._html_output() is deprecated. ' 'Please use .render() and .get_context() instead.', RemovedInDjango50Warning, ) ```
I think that `BaseForm.get_context()` describes this perfectly well: ```suggestion ``` But if we must keep it, it should be collapsed onto one line: ```suggestion """Returns context for form rendering.""" ```
```suggestion # RemovedInDjango50Warning: when the deprecation ends, remove # mark_safe() call. ```
Sorry - typo. Fixed.
It seems like a lot of complexity can be stripped out of this: ```python if self.base_field.choices and "choices_form_class" not in kwargs: obj = self.base_field defaults = { "choices_form_class": forms.TypedMultipleChoiceField, "coerce": self.base_field.to_python, # XXX: Do we actually need this? } else: obj = super() defaults = { "form_class": SimpleArrayField, "base_field": self.base_field.formfield(), "max_length": self.size, } if self.choices: warnings.warn("Choices should be defined in base field.", RemovedInDjango51Warning) return obj.formfield(**{**defaults, **kwargs}) ``` Obviously the behaviour of this post-deprecation also needs to be decided: - Does it throw an exception? - Does it silently ignore choices on the `ArrayField`? (Might need to actively strip them out?) - If we promote a system check warning to error, does it matter which approach we choose? (Not everyone uses the checks though.)
Is this is the right commit? I don't think the deprecation of the model field should require any changes. I would have deprecated the model field first, then tackled the question of whether or not to deprecate the form field separately.
IMO we can simplify condition: ```not self.blank or (self.blank and not self.null)``` to: ```not (self.blank and self.null)```
I wonder if the `isinstance()`condition results in any performance savings? I tend to think always casting might be simpler.
It might be nice to create some objects and verify the ordering so that models aren't inadvertently refactored and ordering attributes lost which would eliminate their regression nature.
Probably, I don't think the benefit is worth the cognitive load of someone looking at the test and wondering about it.
Maybe: ```suggestion def test_order_by_f_expression_to_constant_value(self): ```
`asc()` is unnecessary: ```suggestion .order_by(F("test")) ```
```suggestion self.assertSequenceEqual(qs, []) ```
Passing `filter` to kwarg will cause it to be in `self.extra` as well which could interfere `as_sql()` formatting.
I think that you can add `filter` to `kwargs` in `__init__` method and remove redundant `__repr__` (see #8759).
Shouldn't be part of this PR, but it looks like redundancy in `__repr__()` methods would be a good candidate for a refactor.
Please use single quotes.
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
Unrelated, but I wonder if we need '-k', '-r', '-d' for the new options rather than only their verbose counterparts. Seems like we are going to run into a conflict a some point with two options with the same first letter if we keep doing that.
Nitpicking, but I'm not sure the "Defaults to False" is really useful here. That's a bit implied by the option's presence.
In the usual case for using this, it wouldn't be because "an initial migration has been applied before,", it'd be because the database pre-existed any (Django) migrations at all. Also, it's really the contents of your initial migration file that you need to compare to, not your model definitions. Suggested wording: "Detect if tables already exist and fake-apply initial migrations if so. Make sure that the current database schema matches your initial migration before using this flag!" As a bonus, this also hints at the fact that the automated check here is no more sophisticated than just checking if tables exist.
This is minor, but the double exclamation point feels a little overblown. I'm not sure any exclamation points are needed at all; the text should suffice.
Can you add a period at the end, please.
Use `as e` or as `as exc` to match other code.
You are right I missed the fast that exceptions raised during `__enter__` are not going to go through `__exit__` sorry for that. That makes these tests unnecessary.
One solution here would be to make `enable`/`disable` idempotent by having a class level `enabled = False` attribute that gets set/unset and checked for early return in both methods or to override `__exit__` to deal with `exc_value == self.enable_exception` in a special way.
I don't think we need this here. In `disable()` we `raise self.first_exception` (when `not None`) so this line will be unreachable.
Ahh didn't notice `_modified_settings` could have duplicate items.
Black won't mind. 😀
Remove as `empty_strings_allowed = False` is inherited from `IntegerField`.
Yes, `override_settings_tags()` should no longer be necessary. Please change it to the `override_settings()`.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
drop the new line please
Really really minor nitpick; if flake8 etc do not complain maybe move `entropy.` up one line; looks really ugly like this especially if the code below is longer :)
Mhm that is what I was trying to avoid, because for most hasher a salt length is just that and `must_update` should easily be able to handle that globally if it is returned from `decode`. What this PR certainly misses (and what will show you the existing problems) is a test for the behavior of the `bcrypt` hasher. I think now it's `must_update` will *always* return `True` and set a salt *every* time.
IMO, we should use `self.decode` here.
While trying to push this PR over the finish line I noted that `salt_len` is not really the `salt_len` we want (it's the size of a string in bytes). I have pushed a new PR #13815 which adds the actual salt to `decode`. I'll update this PR once the other one is merged.
Maybe `argon2_hash` -> `rest`
We can reuse an existing migration: ```suggestion MIGRATION_MODULES={"migrations": "migrations.test_migrations_manual_porting"} ```
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
You can safely join this an the next line. You have up to 119 chars per line. ;)
If `squashmigrations` could check for replacements, that seems ideal, but not sure introducing the executor into that command is a good idea.
```suggestion self.assertEqual(err.getvalue(), 'No statements found.\n') ```
There are only two uses of `_destruct_iterable_mapping_values()` and we use this same pattern exactly. I think that you could push the `isinstance(..., Mapping)` check into that function.
What I meant was that you could stick the following in the top of `_destruct_iterable_mapping_values()` to make it more DRY: ```python if isinstance(data, Mapping): yield from data.items() return ``` I don't see why you think we'd need an extra for-loop...
this class has a bunch of details of WSGI environ so I think it more accurately belongs in `django.http.request`
Then this can just be: ```python for header, value in self._unpack_values(data): ```
📖 I think we could add a docstring to this explaining why `__init__` was overridden. This and `CaseInsensitiveMapping.__init__` looks pretty similar
Do Django's automated tests ensure backward compatibility? If not I probably don't have enough familiarity with Django to do so. Glad I'm not taking crazy pills, though. :)
If I understand correctly "let's delegate..." -> "that will be done in instance.full_clean()"? I'd like to check a few more things later today so you can hold off on that update until I finish review.
I'm not sure special-casing the password field is a good idea, as you might as well have user code presenting such cases, and then the function would crash badly. I think a try/except clause catching the KeyError when f is not find in form.fields, defaulting to the raw field name in that case, would be a safer approach.
please revert whitespace addition
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
Right, my bad.
Arg true, doing to many things at the same time. Yes the `elif` is vastly better than the extra variable before. :+1:
But now it will never fall back to the referer check if the Origin header exists (no matter if the origin header validated fine or not)…
In comparision to the `Refer(r)er` check we loose the possibility to override the "initial" override of `get_host`. Would this be something to worry about -- not sure, just thinking out loud…
Regarding the referrer checking, given the length and complexity of the containing function, I was thinking it would be good to have that in a separate function, too. But I didn't want to suggest changes outside the scope of your change. I think either signature you proposed would be an improvement. (Another option, in between, would be to pass `good_origin` and `request.META`.) Perhaps the decision can be guided by what the signatures would be for other portions of the logic if they were similarly broken out (for parallel structure).
actually I think the preferred solution is to omit the u'' prefix, even on Python 2. The output already includes `from __future__ import unicode_literals` so there shouldn't be a problem without it.
There's a lambda called `strip_prefix` in `inspectdb.py` that should be of use.
Yes, I think we should be able to distinguish between automatic indexes and manual indexes. It might not be possible to cover all possible cases (inspectdb doesn't aim for perfect output), but let's try our best. For example, a single-column GIST index on a geometry field is considered as the default index.
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
Consider ``` python base_name = 'Field' if not connection.features.lowercases_column_names else 'field' ``` for the general rule that in if expressions, the "iftrue" part should be the more common, reflecting the default.
chop blank line
Up to you but I think we usually put error cases in a separate method.
I wouldn't include this test in the PR because it's testing existing behavior. But it doesn't seem needed as there's a test in `test_client_regress` that fails if the `isinstance(data, dict)` check is `_encode_json` is removed.
This can be dropped since `connection` is already imported in the context of the module. ```suggestion ```
I think a specialized class is not required for this test case as you can rely on `.args` ```python try: raise Exception(2) except Exception as e: try: raise Exception(1) from e except Exception: exc_info = sys.exc_info() ... self.assertEqual(cm.exception.args[0], 1) self.assertEqual(cm.exception.__cause__.args[0], 2)
The benefit of the extra tests is they make the HTML structure clear, but the CSS selector perhaps does that... We should use hanging indent for the wrapping, so maybe pull the CSS selector into a variable, so it's easy read/see, and then the lines would be shorter too, and we can just have the two assertions.
```suggestion # Even the third inline should have the correct verbose_name ```
I think it would be batter to hide a sidebar, e.g. ```python # Hide sidebar. toggle_button = self.selenium.find_element_by_css_selector('#toggle-nav-sidebar') toggle_button.click() ```
This should go to the 2nd commit :pick:
Maybe: ```python self.assertEqual(len(self.selenium.find_elements( By.CSS_SELECTOR, '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]', )), 1) ``` or ```python selector = '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]' self.assertEqual(len(self.selenium.find_elements(By.CSS_SELECTOR, selector)), 1) ```
Please revert this unrelated change.
Shouldn't be part of this PR, but it looks like redundancy in `__repr__()` methods would be a good candidate for a refactor.
I think that you can add `filter` to `kwargs` in `__init__` method and remove redundant `__repr__` (see #8759).
Passing `filter` to kwarg will cause it to be in `self.extra` as well which could interfere `as_sql()` formatting.
This error no longer makes sense with multiple-arg aggregates. You'll either need to join the output of all source expressions so the error produces: > Cannot compute Sum(arg1, arg2): 'X' is an agggregate # (where X is either arg1 or arg2) Or you'll need a different error message for the case of `len(args) > 1`. There may be another solution (like ditching this message altogether) but I'll let you experiment with that if you like.
I think that you should partly restore behavior before https://github.com/django/django/commit/b484f167bed61f4cff215208eddf98a0655239d4 i.e. ```python cursor = self.connection.cursor() try: cursor.execute(self.ops.set_time_zone_sql(), [timezone_name]) finally: cursor.close() ``` instead of ```python with self.connection.cursor() as cursor: cursor.execute(self.ops.set_time_zone_sql(), [timezone_name]) ```
rather than custom caching with a dict, this might be clearer with a module-level function using `@lru_cache(maxsize=2)`, with the current value of `USE_TZ` as the only argument. It would save some lines and clarify it's a cache.
Chop blank line.
Please add trailing comma.
Try to minimize the test that demonstrates the regression. I think this part isn't important -- assigning a value when creating the model should work just as well.
Doesn't seem required now that the test is skipped on non-Oracle.
should be -> are
I think that leading and trailing `"` is missing, i.e. `'"%s"."%s"' % (namespace, table_name)`.
, -> and
At first sight it could be simplified to: ``` [option not in [None, False] for option in mutually_exclusive_options].count(True) ``` But I have a feeling even more simplification might be possible. Note that we can't simply cast default to bool, which would make this even simpler, as some valid dates evaluate to false: https://mail.python.org/pipermail/python-ideas/2014-March/026446.html
Please revert this unrelated change.
I've noticed that `None` from `flatchoices` should update `Unknown` not `All`. I fixed this.
I think using a semantic name would help here, e.g. `lookup_kwarg_null`
I don't think you can depend on a None choice being defined for a nullable field, necessarily. I don't think you need to make a change here.
this hanging indent is intentional, you'll see it throughout Django
> Wouldn't we have to change the tests, if by any chance we change the class name? Yes and it's expected, we will be aware which tests are affected by our change to the base class. IMO it's also more readable.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
There are a couple assertions like this one that maybe should be updated to assertEqual/NotEqual
First we should verify this passes before we toggle `is_active` to False.
I don't think it's terribly important as both checks use the same code path (although this could obviously be refactored later at which point that argument would fail...).
There is no need to create a random suffix. We should also test all described scenarios, e.g. ```suggestion test_connection = copy.copy(connections[DEFAULT_DB_ALIAS]) test_connection.settings_dict = copy.deepcopy( connections[DEFAULT_DB_ALIAS].settings_dict, ) tests = [ ('test.sqlite3', 'test_1.sqlite3'), ('test', 'test_1'), ] for test_db_name, expected_clone_name in tests: with self.subTest(test_db_name=test_db_name): test_connection.settings_dict['NAME'] = test_db_name test_connection.settings_dict['TEST']['NAME'] = test_db_name creation_class = test_connection.creation_class(test_connection) clone_settings_dict = creation_class.get_test_db_clone_settings('1') self.assertEqual(clone_settings_dict['NAME'], expected_clone_name) ```
I think it's fine to leave it inside a `try` block.
I'm confused. Is there something incorrect here or can this just be: ```suggestion self.connection.settings_dict['NAME'] = worker_db ``` If the intent was to avoid mutating the original then do this (although I'm not sure it's required): ```python self.connection.settings_dict = {**self.connection.settings_dict, 'NAME': worker_db} ```
This test is already in the `backends.base.test_creation` and it's unrelated with this fix. Please remove it.
We should run it only on Django's test suite: ```suggestion if os.environ.get("RUNNING_DJANGOS_TEST_SUITE") == "true": self.mark_expected_failures_and_skips() ``` Also I'm not sure if it's the right place :thinking: , see #15477.
Same here, the unique constraint is only removed in the ORM but will still persist in the database.
This will require a migration, run `makemigrations` for the app.
I'm reminded of #21381 (removing contrib.redirects dependency on contrib.sites), but not sure that should block this.
preferred format is "#15346, #15573 - Issue description"
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
This conditional clause can be dropped once we perform an initial `not self._prefetch_related_lookups` as described above.
Could use boolean `not clone._result_cache` check as well.
It'd be great if we could avoid this and all of the following `if not self._prefetch_related_lookups` e.g. ```python # Avoid materialization of chunks of objects if no prefetching must take # place. if not self._prefetch_related_lookups: yield from self._iterable_class(self, chunked_fetch=use_chunked_fetch, chunk_size=chunk_size) return ``` That'll make sure the exact same behavior is preserved when no prefetching is involved and allow you to revert the `test_server_side_cursors.py` changes.
Shouldn't this be along the lines of ```python def iterator(self, chunked_fetch=None): if chunked_fetch is None: chunked_fetch = connections[self.db].settings_dict.get('ENABLE_SERVER_SIDE_CURSORS', True) return iter(self._iterable_class(self, chunked_fetch=chunked_fetch)) ```
😁 ```suggestion while results := list(islice(iterator, chunk_size)): ```
I know that tests in `queries` are mixed up, however I would move it to the `Queries6Tests` class.
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
Should we also have a pointer here of the form ```suggestion with self.assertRaisesMessage(FieldError, "Cannot distinct on 'other_rating' alias. Use annotate to promote it"): ```
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
Use single quotes consistently (could be done above and below also).
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
longer lines here are okay, we try to avoid non-multiple of 4 indents
I think a list comprehension would be more readable.
We can add `Foo.objects.create()` to ensure that primary key and sequence are still valid.
```suggestion timeout=60, ``` "60" on its own looks a bit weird. Also, it surely doesn't need to be as long as 60 seconds if `DELAY_AFTER_FAILED_LOGIN` is so much smaller? What if `DELAY_AFTER_FAILED_LOGIN > 60`? Maybe this should be: ```suggestion timeout=self.DELAY_AFTER_FAILED_LOGIN + 10, ```
`self.fields[self._meta.model.USERNAME_FIELD]`? I think it's a mandatory field.
Use `self.username_field` instead.
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
Please don't make unrelated whitespace changes.
I think we prefer a different indentation style in docstrings, i.e.: ```python """ A Q object with an empty condition should be rejected as the conditional expression in a Case(). """ ```
FWIW `Q(Exists(is_ceo)) | Q(Exists(is_poc))` already works and `Exists(is_ceo) | Exists(is_poc)` doesn't require much changes. ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 5b82ae97a7..d18de75e9a 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -101,6 +101,8 @@ class Combinable: return self._combine(other, self.BITRIGHTSHIFT, False) def __or__(self, other): + if getattr(self, 'conditional', False) and getattr(other, 'conditional', False): + return Q(self) | Q(other) raise NotImplementedError( "Use .bitand() and .bitor() for bitwise logical operations." ) diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py index 6c00f813d9..d3d75f1ce1 100644 --- a/tests/expressions/tests.py +++ b/tests/expressions/tests.py @@ -595,11 +595,9 @@ class BasicExpressionsTests(TestCase): def test_case_valid_in_filter_if_boolean_output_field(self): is_ceo = Company.objects.filter(ceo=OuterRef('pk')) is_poc = Company.objects.filter(point_of_contact=OuterRef('pk')) - outer_1 = Employee.objects.filter(Case( - When(Exists(is_ceo), then=Value(True)), - When(Exists(is_poc), then=Value(True)), - default=Value(False, output_field=models.BooleanField()) - )) + outer_1 = Employee.objects.filter( + Exists(is_ceo) | Exists(is_poc) + ) self.assertQuerysetEqual( outer_1, ['<Employee: Joe Smith>', '<Employee: Frank Meyer>', '<Employee: Max Mustermann>'], ```
Can move `test_conditional_annotation` to the `WindowFunctionTests`? As far as I'm aware it should work now.
Is there a reason to use `len()` instead of checking the objects? `len()` may take more effort to debug in the event of a failure.
~~Are you sure the `Value` wrapping and the `output_field` are necessary here? As long as you pass an `output_field=models.BooleanField()` to `Case.__init__` you should be good to go.`~~ _Edit: Well it looks like passing `output_field=models.BooleanField()` to `Case.__init__` doesn't work yet._
It should be good as long there's no foreign tests or models that get imported along the way. From what I can see it should be good!
Might be worth moving to a `/tests/utils.py` submodule (alongside `runtests.py`) instead of defining it here since it's not meant to be a public API.
Good, thanks. Maybe `Note setting ` -> `Set `
or just `# CSS files shouldn't be touched...`
```suggestion # LiveServerTestCase's change to ALLOWED_HOSTS should be reverted. ```
OracleDbshellTests ("TestCase" implies this is meant to be subclassed.)
Might be worth testing for the actual type.
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
This test is also already in the `backends.base.test_creation` and it's unrelated with this fix. Please remove it.
It would be more elegant, and possibly more efficient, to use: ``` template_postgis = getattr(settings, 'POSTGIS_TEMPLATE', 'template_postgis') cursor.execute('SELECT 1 FROM pg_database WHERE datname = %s LIMIT 1;', template_postgis) if cursor.fetchone(): return template_postgis ``` This is how `QuerySet.exists()` is implemented.
No need to use `get_user_model()` (don't think any of the other tests do that?), I think.
`.get(self.live_server_url + reverse('admin:admin_views_question_add'))`
To avoid the interesting indentation: ``` msg = "<class 'admin_views.models.Question'> is not registered in the admin." with self.assertRaisesMessage(Http404, msg): ```
why an empty string? might as well use assertRaises at that point.
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
Thanks for being more explicit about this than I was! (https://github.com/django/django/pull/14396#discussion_r632488901)
There's no test for the `and not callable(self.lastmod)` branch.
OK, good. Thanks. I think it's fine as it is. 👍
I might handle the `if not hasattr(self, 'lastmod')` as a guard first, to get it out of the way: ```suggestion def get_latest_lastmod(self): if not hasattr(self, 'lastmod'): return None if callable(self.lastmod): try: return max([self.lastmod(item) for item in self.items()]) except TypeError: return None else: return self.lastmod ```
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
Looking at it we should also pass `obj` to this method and cache its results, just like we do with `get_group_permissions`: ``` python def get_user_permissions(self, user_obj, obj=None): """ Returns a set of permission names the user has. """ if user_obj.is_anonymous() or obj is not None: return set() if not hasattr(user_obj, '_user_perm_cache'): if user_obj.is_superuser: perms = Permission.objects.all() else: perms = usr_obj.user_permissions.all() perms = perms.values_list('content_type__app_label', 'codename').order_by() user_obj._user_perm_cache = set("%s.%s" % (ct, name) for ct, name in perms) return user_obj._user_perm_cache ```
First we should verify this passes before we toggle `is_active` to False.
```suggestion raise ValueError('perm_list must be a list or tuple.') ```
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
I don't think it's terribly important as both checks use the same code path (although this could obviously be refactored later at which point that argument would fail...).
I'd be great to assert the permission and content types were appropriately created as well!
On thing to keep in mind is that this is going to be introducing double work.
Silenced the output. The `create_default_site` method deserves a more basic test, but there's more to it than the output, could be another ticket I guess (this one is pretty convolved as is). Here's a [sketch of a test](https://github.com/wrwrwr/django/commit/8927a52a4271ab8208783ce4c2af31814314a6c8).
preferred format is "#15346, #15573 - Issue description"
Need to test how many times `update_contenttypes` was called and test arguments which passed to it.
We should validate `self.requires_system_checks`, currently we run all checks also for any truthy value e.g. `requires_system_checks = 'x'`, maybe ```python if not isinstance(value, (list, tuple)) and value != '__all__': raise TypeError(...) ```
Please use single quotes.
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
If we don't go with the above, this should at least use a dict literal: ```suggestion error_text = ERRORS[e.errno] % {'addr': self.addr, 'port': self.port} ```
We should update `self.requires_system_checks` if it's a boolean, e.g. ```python self.requires_system_checks = '__all__' if self.requires_system_checks else [] ``` we can also add a module level constant: ``` ALL_CHECKS = '__all__' ```
Maybe? ```suggestion def _field_non_database_attrs(self): ```
> `how I would overwrite the non_db_attrs in the sqllite3 case` This doesn't need to be overwrite for SQLite when we move it to the field, because custom fields as `EnumField` from `django-mysql` will be able to remove `"choices"` on their own from `EnumField.non_db_attrs`, so we could add `"choices"` to the `Field.non_db_attrs` for all databases. > within the _field_should_be_altered function, I need to reference the non_db_attrs. There are both an old_field and a new_field in this function, would I pick one of these in order to be the non_db_attrs or would it be better to loop through them separately (unsure if that makes sense) We should do this separately because a field type can change.
Nitpick but `dict.get` default value for a missing key is already `None`.
generate_removed_indexes() and generate_added_indexes() (add parentheses)
I don't think so -- the autodetector isn't a public API that's meant to be extended.
Why we evaluate the queryset? Couldn't we keep the `QuerySet` object? ```suggestion ret_val.extend(custom_queryset_dict[ct_id]) ```
@pope1ni no, it's heavily cached as it's using `ContentType.objects.get_for_model`.
Why this refactoring? (Touches a lot of the other tests...)
Do we need to use a dict? It seems unnecessary complicated. Model classes that we pass in the keys must match the base models from querysets. We also don't protect against incorrect values e.g. ```python queryset={ Animal: Bookmark.objects.all() } ``` I would use a list/tuple instead and raise an error when a queryset for the specific model is already resolved, e.g. ```python for qs in querysets: ct_id = self.get_content_type(model=qs.query.model, using=qs.db).pk if ct_id in custom_queryset_dict: raise ValueError(...) custom_queryset_dict[ct_id] = qs ``` We should also add a new argument (maybe `querysets`) because it's misleading to pass list of querysets in the argument called `queryset`.
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
Why we evaluate the queryset? Couldn't we keep the `QuerySet` object? ```suggestion ret_val.extend(custom_queryset_dict[ct_id]) ```
Ahh right, I forgot about it. Thanks!
@pope1ni no, it's heavily cached as it's using `ContentType.objects.get_for_model`.
Do we need to use a dict? It seems unnecessary complicated. Model classes that we pass in the keys must match the base models from querysets. We also don't protect against incorrect values e.g. ```python queryset={ Animal: Bookmark.objects.all() } ``` I would use a list/tuple instead and raise an error when a queryset for the specific model is already resolved, e.g. ```python for qs in querysets: ct_id = self.get_content_type(model=qs.query.model, using=qs.db).pk if ct_id in custom_queryset_dict: raise ValueError(...) custom_queryset_dict[ct_id] = qs ``` We should also add a new argument (maybe `querysets`) because it's misleading to pass list of querysets in the argument called `queryset`.
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
Assuming this works, don't forget that we'll need some solution (like the environment variable used before) to only run `mark_expected_failures_and_skips()` when running Django's test suite.
I tried to use a generated condition the `WHERE` clause and it works fine, so IMO we can safely assume that it's an Oracle caveat :smile:
This must be an inner skip, please revert (ticket-31888).
How about: ``` if storage_engine == 'InnoDB': return self.connection.mysql_version >= ( (10, 2, 2) if self.connection.mysql_is_mariadb else (5, 7, 5) ) return storage_engine in ('MyISAM', 'Aria') ```
Please move these tests to the `invalid_models_tests/test_ordinary_fields.py`. Also, we could move a new system check with tests to a separate commit, it would be easier to review.
non existing -> nonexistent
Copy / paste? I would have expected the ordering to change for the `duth1` and `duth2` arguments.
Why's that? It's non-obvious at first glance.
I made a few edits and squashed commits but before I push those updates I wanted to ask if this test is really needed. None of the changes seem related to verbosity so this test seems unnecessary to me.
You could use single quotes in all strings for consistency (don't worry about existing tests).
Most of these operators overlap with range lookups, I think we should use the same names for consistency, i.e. - `LESS_THAN` -> `LT`, - `GREATER_THAN` -> `GT`, - `LESS_THAN_EQUAL` -> `LTE`, - `GREATER_THAN_EQUAL` -> `GTE`, - `IS_CONTAINED_BY` -> `CONTAINED_BY`, - `NOT_EXTEND_LEFT_OF` -> `NOT_LT`, - `NOT_EXTEND_RIGHT_OF` -> `NOT_GT`, - `STRICTLY_NOT_EXTEND_LEFT` -> `FULLY_LT`, - `STRICTLY_NOT_EXTEND_RIGHT` -> `FULLY_GT`, - `IS_ADJACENT_TO` -> `ADJACENT_TO`. Maybe we can also reuse this operators in lookups :thinking: , e.g. ```python @RangeField.register_lookup class FullGreaterThan(lookups.PostgresSimpleLookup): lookup_name = 'fully_gt' operator = RangeOperators.FULLY_GT ```
This is the same as the previous assertion. I'd think only 1 assertionis needed since all the `as_*` methods use `_html_output()`.
```suggestion '<thead><tr><th class="original"></th>' '<th class="column-name required">Name</th>' '<th class="column-position required hidden">Position</th>' '<th>Delete?</th></tr></thead>', ```
We'd only put the ticket number for a particularly tricky ticket. I don't think it's necessary here.
```suggestion '<tr class="row-form-errors"><td colspan="3">' '<ul class="errorlist nonfield"><li>A non-field error</li></ul></td></tr>', ```
This seems overly complicated and probably also wrong with tables that are JOIN'ed more than once as the following JOINs will have aliases that are not `db_table`. ```python > from django.contrib.auth.models import User > User.objects.filter(groups__name='foo').query.alias_refcount {'auth_group': 1, 'auth_user': 1, 'auth_user_groups': 1} > User.objects.filter(groups__name='foo').filter(groups__name='bar').query.alias_refcount {'T4': 1, 'T5': 1, 'auth_group': 1, 'auth_user': 2, 'auth_user_groups': 1} ``` Also you probably don't need to build the `from_to_tables` set as it's really inneficent. You should use a loop and exit the function as soon as a matching alias is found.
I would reuse the same wording as in `promote_joins` it's more clear IMO: "demote a->b automatically, or otherwise the demotion of b->c doesn't actually change anything in the query results."
Oh yes the tests! You are right then.
This came from the connection proxy for the cache connections -- for checking whether a key is in the cache -- and isn't really applicable to the database connections. I'm not sure that's a problem though -- it'll just complain that the connection is not iterable... This is just an observation.
I think it's fine to leave it.
This can just be `pass` since the functionality doesn't matter.
It'd be great we if we could avoid creating 5 new tables to reproduce the issue. Existing ones should be reusable somehow.
(inadvertence revert here too)
I would omit the parenthesis in these messages (I know it's done elsewhere, but "I am at war" with that style unless you like it).
```suggestion class Integration(models.Model): ```
I don't think you can depend on a None choice being defined for a nullable field, necessarily. I don't think you need to make a change here.
I'd use f-strings for lookups (in all cases): ```suggestion lookup_conditions.append((f'{self.field_path}__isnull', True)) ```
Please use single quotes.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
I'm not sure if there are lookups where it's not the case, but comparisons such as `Choice.objects.filter(votes__gte='2')` seem to work fine with the value as a string so the "transform" stuff seems unnecessary, at this for the first version of this.
Please assert with the expected string e.g. ```python self.assertEqual(repr(cl), '<ChangeList: model=Child model_admin=ChildAdmin>') ```
It would probably be better to check `cl.queryset.query.distinct`
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
`return` is not necessary.
It would be good to show a warning message here.
Use hanging indent: ``` destination_exists = ( self.storage.exists(destination_path) and ... ) ```
```suggestion files = sorted(self.storage_dir.joinpath("dotted.path").iterdir()) self.assertFalse(self.storage_dir.joinpath("dotted_.path").exists()) ```
I think the warning should happen in this case, since we didn't check if files exist or not, it's better to be safe.
Use `import sys`, `sys.stderr` instead.
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
I would revert this change, the previous version is clearer to me.
`nun` should be `non`.
```suggestion state.rename_model(app_label, self.old_name_lower, self.new_name_lower) ```
We shouldn't use the same chain on `replace()` in multiple places, use `quote_value()` instead.
This behavior doesn't exist in the current implementation of `HttpResponse`.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
seems like we could use `super()` instead.
In general, I think _it shouldn't be as hard as this_ (at least not exposed 😀)
@felixxm the `if to_field.primary_key` check is needed for the FK as PK case. Two questions: 1. Can we tidy this block? 2. Do we need the same kind of thing again inside the `while` loop? 🤔
Super — let me give that a run. Thanks @felixxm
This can happen also for `OneToOneField` so we shouldn't put `ForeignKey` in a message, maybe: ```python exceptions.FieldError( "'%s.%s' refers to field '%s' which is not local to model " "'%s'." % ( self.model._meta.label, self.name, to_field.name, self.remote_field.model._meta.concrete_model._meta.label, ) ) ```
Likely want to raise `FieldDoesNotExist` or `FieldError` here instead.
`mutliple` -> `multiple`
`str` -> `six.string_types` for compatibility with Python 2.
`None` is being passed for the `app_configs` argument - even though the check ignores `app_configs`, `[]` should be used as a more valid test value. I think it's worth looking into refactoring these tests in general, as you're write these property inner-imports are a bit confusing, made a note to self.
Looks like this could be a single line.
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
I think in the first version of the patch you had something like `assertIsInstance(lat, float)` which seemed better to me.
If initial_forms=3 and min_num=4 and extra=3 I'd expect total_forms to be 6 and not 7 EDIT:// oh, I see below that this would probably be a change in backwards compat; in that case never mind ;)
When there are only two coordinates, the for loop doesn't seem to be so much better...
Up to you, but I think the tests are short enough that the blank lines don't help much.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
Since this is just a type check which should apply to all environments, not just production ones, it doesn't need the `deploy` flag
I think we should check it's iterable AND not a string, there's always the possibility of other mistakes than the one that lead to the ticket, e.g. missing brackets on a function call
@coldmind With the current code, `passed_check` will be `True` if `settings.ALLOWED_HOSTS` IS empty. That is backwards. `passed_check` should be `True` if `settings.ALLOWED_HOSTS` is NOT empty.
`not statement` is used several times above, so need to be consistent in code style.
@akulakov `passed_check` is to check if list is not empty. if it is not empty, method will return no error, otherwise error will be returned (`[] if passed_check else [W020]`).
Maybe e.g. `Calling exclude() is not supported after union().`
Clever use of the integer nature of `bool`, first time I've seen this pattern. It kind of hurts readability though IMO.
I think we want to fail as soon as `combinator` is truthy ```suggestion if self.query.combinator: ```
this is usually called `opts = self.model._meta`
rcvr -> receiver (no need to obfuscate it)
I had a similar thought though I wasn't sure if the change would be an improvement or not. "pr" me think "pull request". I haven't reviewed this in detail yet.
Single line looks okay here, in the next test and in the assertEqual of the test.
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
This change is unrelated. Reverted.
```suggestion chapter = Chapter.objects.create(title='testchapter', book=book) ```
Please remove this unrelated change.
I noticed a different behavior for floats lower than `1`, they aren't rounded e.g.: ```python >>> f = models.DecimalField(max_digits=4, decimal_places=2) >>> f.to_python(0.0625) Decimal('0.0625') >>> f.to_python(0.00625) Decimal('0.006250') >>> f.to_python(0.000625) Decimal('0.0006250') >>> f.to_python(0.0000625) Decimal('0.00006250') ``` Maybe that's ok and I missed something.
Do we need such a large try/except block? That makes it difficult to spot what statement(s) might throw an exception and could hide other bugs.
```suggestion return '-' + value if neg else value ```
```suggestion return '-' + value if neg else int(value) ```
start docstring on next line and "Create..."
I think this is implied by the underscore prefix.
suggested wording: "Yield each item in iterable at most once and exclude those that appear in skip_set."
quit() .... to avoid a dead.... (chop "we" stuff)
Oh yes the tests! You are right then.
> This is fine because managers are by definition working on the real model. I thought adding the `use_in_migrations` flag to managers was done specially to allow working on models created in migrations? This is going to break any migration that uses the return value of `create_user` as it will no longer be an instance of the user model class at the particular state the operation is run at. e.g. ```python def forwards(apps, schema_editor): UserModel = apps.get_model('auth', 'User') user = UserModel.objects.create_user('Ms X', password='secure') assert isinstance(user, UserModel) ``` This is really problematic for migrations that use the returned user instance to assign foreign key values as they'll fail with `TypeError`.
Exactly as @charettes says.
As `clean()` can also raise `ValidationError` if overridden I would avoid calling it here and stick to calling `normalize_username()`.
What about using the global user model's `normalize_username` method while returning an instance of `self.model`? ```python GlobalUserModel = apps.get_model(self.model._meta.app_label, self.model._meta.object_name) username = GlobalUserModel.normalize_username(username) password = GlobalUserModel.hash_password(password) user = UserModel(username=username, email=email, **extra_fields) user.password = password user.save(using=self._db) return user ```
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
Move those import to the top of the file.
You can use the new `self._bound_items()` here, which is now in `main`.
no u'' prefixes please (use `from __future__ import unicode_literals` if needed)
We'd likely want to accept `renderer=None` here and default to `get_default_renderer()`.
Wrap docstrings at 79 characters. Try to avoid "we... " (often this results in simpler language).
can you put `if not value` in the isinstance block below
Still I think `'&nbsp;<strong>%s</strong>'` could be factored as a variable and `<a href=...` interpolated inside that. Let's use `format_html` instead of `escape`. This return could go in the `else` block of `try/except/else`.
Could you try to improve this so that there isn't duplication of the HTML and `escape(Truncator(obj)....`
```suggestion return format_html('<a href="{}">{}</a>', url, remote_obj) ```
This is ready for commit. But... don't you think code this could be more readable moving some code to a new helper function? The existing code is already a bit convoluted, and this fix adds lines and indent levels that make it worth some refactoring.
Oh, it's because `SEARCH_VAR`, etc. are variables.
I'm not quite following the BC concern...
Again, this could be a class level attribute.
[This validator is added by default, no need to specify it](https://github.com/django/django/blob/ac956dae1d06ce2ebff7a2966bcaf8a5ecdbb861/django/forms/fields.py#L219). We'll probably want to pass `strip=False` as well to preserve backward compatiblity. Given you have to branch on `var == PAGE_VAR` anyway I don't think there's much value in using a loop here. You could define fields by directly assigning to `self.fields` ```python def __init__(self, *args, **kwargs): self.fields = { SEARCH_VAR: forms.CharField(required=False, strip=False, initial=''), PAGE_VAR: forms.IntegerField(required=False, min_value=0, initial=0), TO_FIELD_VAR: forms.CharField(required=False), } super(ChangeListForm, self).__init__() ``` The `initial` usage will make the `clean()` below unnecessary. ```
Python2 does not support `super()`.
Chop blank line
Double checking the commit, this change, in this form leaks some state across migrations. Testing on CI right now. ``` python ERROR: test_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) psycopg2.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/markus/Coding/django/django/test/utils.py", line 182, in inner return test_func(*args, **kwargs) File "/home/markus/Coding/django/tests/migrations/test_executor.py", line 401, in test_alter_id_type_with_fk executor.migrate([("author_app", "0002_alter_id")]) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 94, in migrate self.apply_migration(states[migration], migration, fake=fake, fake_initial=fake_initial) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 131, in apply_migration state = migration.apply(state, schema_editor) File "/home/markus/Coding/django/django/db/migrations/migration.py", line 118, in apply operation.database_forwards(self.app_label, schema_editor, old_state, project_state) File "/home/markus/Coding/django/django/db/migrations/operations/fields.py", line 201, in database_forwards schema_editor.alter_field(from_model, from_field, to_field) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 482, in alter_field old_db_params, new_db_params, strict) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 635, in _alter_field params, File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 106, in execute cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 79, in execute return super(CursorDebugWrapper, self).execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/utils.py", line 95, in __exit__ six.reraise(dj_exc_type, dj_exc_value, traceback) File "/home/markus/Coding/django/django/utils/six.py", line 658, in reraise raise value.with_traceback(tb) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) django.db.utils.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. ``` However, integrating this with the second commit on my PR fixes the issue. I thus squash those commits there and close your PR here.
In the usual case for using this, it wouldn't be because "an initial migration has been applied before,", it'd be because the database pre-existed any (Django) migrations at all. Also, it's really the contents of your initial migration file that you need to compare to, not your model definitions. Suggested wording: "Detect if tables already exist and fake-apply initial migrations if so. Make sure that the current database schema matches your initial migration before using this flag!" As a bonus, this also hints at the fact that the automated check here is no more sophisticated than just checking if tables exist.
use: `any(name for app, name ... )`
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
``` # Unmanaged origin model that is a table. ```
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
``` # Unmanaged related model that is not a table. ```
Chop blank line.
``` # Unmanaged related model that is a table. ```
I think the template system silences the exception -- I just observed that no data appears in the table. Your proposal is what I had in mind.
I think we could just omit the "USER" row if it's not on the request.
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
I know this is the sort of layout that `black` would generate, but it's one of the more ugly choices it doesn't get right in my opinion. Perhaps we should `+=` instead of `.extend()`: ```suggestion top_errors += [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ```
Would it be enough to check `form.fields`? This might make the test a bit easier to follow instead of having to parse the HTML to see what's expected..
Can you also rename `test_deep_graph()` to `test_graph_recursive()`
`self.assertEqual(f.choices), [])` looks simpler to me (plus if the list isn't empty, another debugging step isn't needed to see what the list contains).
Use single quotes for strings, unless there's a nested single quote. ([Python style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style))
No need to call `keys()` here.
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
If you do the unrelated alignments, please push them in a separate PR.
We tend to favor the dict formatting as: ``` some_dict = { 'key1': 'value', } ```
Do we need to change `related_name` here? We could add `note` with `related_name='owner'` instead.
Use hanging indent: ``` special_people = models.ManyToManyField( 'Person', through='ProxiedIndividualCompetitor', related_name='special_event_set', ) ```
We usually avoid creating new models when we can reuse existing ones as it slowdown the test suite startup. In this case it looks like there's many candidate that could be reused here.
`assertEqual` -> `assertTrue`
``` # Unmanaged related model that is a table. ```
Chop blank line.
``` # Unmanaged related model that is not a table. ```
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
this could use the indent style of the previous `CommandError`.
no `u''` prefixes on strings please
return directly, no need for `path` variable.
My only question is if this skip logic is still correctly applied (i.e. none of the other classes that inherited `ExtractorTests` require it)? If you verify that, ship it.
chop "should" (just state the behavior)
... and I take a closer look and I see the reason - `RelatedObject.model` already exists. So; what about the other way around; add parent_model to field? That way, you can ask every field "what model do you belong to?" and "what model are you associated with?". Normal data fields return the same model for both; RelatedObjects return different models.
True about the ML. Regarding the naming for `related_objects/related_m2m` vs `reverse_rel/reverse_m2m`, that's a new API so there isn't historical names to preserve (unlike `many_to_many` vs `m2m`), we just need to pick the best names to represent the relations.
Just because you _can_ cram this all on one line, doesn't mean you have to. This would be a lot easier to read as: ``` field_list = tree[self] if self.proxy: field_list += tree[self.concrete_model._meta] for f in field_list: ... ```
if include_parents is False, this line generates a result that isn't used. Move it inside the if for a minor performance boost.
The style I prefer is ``` options = { 'include_parents': include_parents, .... } ``` It's somewhat of a pain to indent additional items if your editor doesn't do it automatically with the other style.
Why double-underscore? I would also rename `func` to `callback`: ```suggestion for _, callback in connections[using].run_on_commit[start_count:]: callbacks.append(callback) if execute: callback() ```
We cannot change the order of kwargs: ```suggestion def on_commit(func, using=None, is_robust=False): ```
``` class A: __print = cached_property(print, '__print') ``` This will not work and we can easily detect it too.
Use a similar logging to what we do for robust signals? See `django.dispatch.dispatcher.Signal.send_robust` and ``` try: response = receiver(signal=self, sender=sender, **named) except Exception as err: logger.error( "Error calling %s in Signal.send_robust() (%s)", receiver.__qualname__, err, exc_info=err, ) ``` Something like ```suggestion logger.error("Error calling {func.__qualname__} on_commit() ({e}).", exc_info=True) ```
A temporary variable is unnecessary ```suggestion self.run_on_commit.append((set(self.savepoint_ids), func, False)) ```
This hook is unnecessary, IMO. I would move the logic to `_select_on_conflict()`.
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
It would be more readable to raise an error explicitly (like previously), e.g. ```python db_features = connections[self.db].features if ignore_conflicts and not db_features.supports_ignore_conflicts: raise NotSupportedError('This database backend does not support ignoring conflicts.') if update_conflicts: if not db_feature.supports_update_conflicts: raise NotSupportedError( 'This database backend does not support updating conflicts.' ) if unique_fields and not db_features.supports_update_conflicts_with_target: raise NotSupportedError( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ``` (I used new feature flags.)
```suggestion unique_fields=unique_fields, ```
Maybe `By default, return the django.contrib.admin.utils.get_deleted_objects.` instead of `By default this just returns django.contrib.admin.utils.get_deleted_objects.`.
Following the existing docstring pattern of wording like "Hook for..." seems useful.
" allowed to be deleted permissions" seems like a typo.
This can be single lined.
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
`test_date_kind()` and `test_time_kind()` in `test_trunc_func_with_timezone()` doesn't have any value because both don't support timezones and are already covered by `test_trunc_func()`. I removed them.
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
`).values()` on next line
Please use a single quote.
Use another lookup instead of `epoch` e.g. `second`.
Sorry, I misinterpreted it as a new flag. I also see above that this was all copied so ignore this. While not the best naming, we're stuck with it.
I'd call this `remove_trailing_empty_values` to reflect the containment check on `self.base_field.empty_values` below.
I think `index` will be fine here instead of `null_index`. It would be good to avoid the association with `null` which feels like `None` translated to Python-speak. (Aside from that I could only come up with `first_trailing_empty_value_index` which, while clearly descriptive, is silly... 🙂)
Yes, we should use the same approach as in `SimpleArrayField`, e.g. ```python def has_changed(self, initial, data): try: data, _ = self._remove_trailing_nulls(self.to_python(data)) except ValidationError: pass if initial in self.empty_values and data in self.empty_values: return False return super().has_changed(initial, data) ```
That actually makes sense. I forgot `reversed()` is a bit special because you typically have to have consumed the whole iterator to know the last element.
This test passes when testing against an SQLite or MySQL backend as long as psycopg2 is also installed. For this test case, I think the check `connection.vendor == 'postgresql'` skips the test too aggressively.
Did you consider using `PostgreSQLSimpleTestCase`? I would favor that for consistency.
Test -> Tests (for future expansion)
AppConfigTests "TestCase" designates that this is meant to be subclassed and doesn't contain any tests itself.
This fails when running from the root directory rather than the tests directory (i.e. `$ ./tests/runtests.py postgres_tests`). Also, the output doesn't make debugging very easy (`AssertionError: 1 != 0`) -- if that could be improved that could be nice.
Chop blank line.
```suggestion form = PartiallyRequiredForm({'f_0': '', 'f_1': ''}) ```
Use a single line. I think two CharField()s should work just as well and make the line shorter.
I'd use single quotes throughout.
Tests for `formset_factory()` and `formset_factory()` are missing.
```suggestion with self.subTest(location), self.settings(CACHES=settings): ```
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
I think that we should unpack `self._options` here and make them arguments of `RedisCacheClient.__init__()`. ```suggestion return self._class(self._servers, **self._options) ``` This is how we approach this for all of the memcached backends using client classes implemented in third-party packages.
Please move `add()` above `get()` to keep the order consistent with the definition in `BaseCache` and other backends. (It's probably worth ordering the methods in `RedisCacheClient` in the same way.)
```suggestion backend = self.base_params['BACKEND'] ```
Do you have a traceback or the name(s) of test that fails with the set(). I ran the sqlite suite with the set() without problems.
Why the obscure `dict.fromkeys` with a list comprehension that could be just `list(queryset)`? IMHO the clearest code that wouldn't require a new method for clarification would be... ```python for obj in set(queryset): ... ``` If you feel the need to clarify why the `set` is used, maybe be more verbose in the unittest and/or commit message and squash the commits into one neat commit.
@tchaumeny reverted fa534b9 here.
If `formfield.queryset` is already filtered both the outer query and the subquery will have this filter applied which is unnecessary ```suggestion Exists(formfield.queryset.model._base_manager.filter(complex_filter)), ```
Do we need to use a dict? It seems unnecessary complicated. Model classes that we pass in the keys must match the base models from querysets. We also don't protect against incorrect values e.g. ```python queryset={ Animal: Bookmark.objects.all() } ``` I would use a list/tuple instead and raise an error when a queryset for the specific model is already resolved, e.g. ```python for qs in querysets: ct_id = self.get_content_type(model=qs.query.model, using=qs.db).pk if ct_id in custom_queryset_dict: raise ValueError(...) custom_queryset_dict[ct_id] = qs ``` We should also add a new argument (maybe `querysets`) because it's misleading to pass list of querysets in the argument called `queryset`.
In that case, sure.
`for (old_field,new_field) in zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many):` makes the code in the loop simpler and removes the need for the hack.
OK we can revert my suggestion, sorry. `RenameModel()` doesn't change `db_table` so `old_db_table` can be different from `new_db_table` only when `db_table` is not defined.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Indexes are not constraints, generally.
```suggestion """runserver doesn't support --verbosity and --trackback options.""" ```
Is this still simulating a read-only database if the mocking is removed? This test might be obsolete considering the exception catching in `check_migrations()` is removed. Some low level tests for the modified `MigrationRecorder` methods might be in order instead.
I would move it to the `ManageRunserver` class.
Please add a trailing comma: ```suggestion [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver'], ```
```suggestion @mock.patch('sys._xoptions', {'utf8': True, 'a': 'b'}) ```
We should make use of `self.message`.
Use single quotes.
As far as I'm aware, for backward compatibility we should assigned errors from `UniqueConstraint`s with a single field to this field :thinking:
I think splitting this to more lines would increase readability. Probably the same for the above with `self.relname`.
```suggestion Call clean_fields(), clean(), validate_unique(), and validate_constraints() on the model. ```
is print_function needed? it doesn't appear in the rest of the code base.
I guess it's a bit defensive, it helps ensuring that behavior is always identical. `print("hello",)` would give different results in PY2 and PY3 for instance.
FWIW I don't think that's quite accurate - a third-party project could support a Python-3-only version of Django, but itself also still support earlier Django versions, and Python 2. (That said, I think the convenience import is still the right thing to do.)
I understand your concern and I'm not convinced either. Maybe the decision would be easier to take after evaluating the probable number of uses of mock.
I'm not too keen on beginning each warning with "In your url patterns, ..". How about "Your url patterns .." ? "Your url patterns have used `include` with a regex containing a '$'. " .. "Your url patterns have a regex beginning with a '/'." .. "Your url patterns have a pattern with a name containing a ':'." ..
Maybe something along the lines of: For databases which do not support returning clause we need to ask the database for the id. Generally last_insert_id is only supported for serial/auto_incr columns, hence we guard it for auto field. \# TODO: Maybe add a marker to fields that their value can be returned by last_insert_id instead of a type check. +/- typos and style cleanups ;)
Prefer a set (or tuple) to list for containment check.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Yeah, it's fine.
@codingjoe I'm going to check why `test_insert` and `test_bulk_insert` fail on Oracle with the current implementation :thinking: .
Seems okay to me. I guess the alternative would to vary the message based on OS. Not sure that complexity is required though.
This test is problematic on Windows: ``` ====================================================================== FAIL: test_notafile_error (template_tests.test_loaders.FileSystemLoaderTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\template_tests\test_loaders.py", line 266 , in test_notafile_error self.engine.get_template('first') AssertionError: "Is\ a\ directory" does not match "[Errno 13] Permission denied: u'c:\\Users\\Tim\\code\\django\\tests\\template_tests\\templates\\first'" ```
Oops, I misread the diff and see that you only modified the existing archives. Still an explanation of exactly what going on would be nice as it's not obvious to me.
Jinja raises `jinja2.TemplateSyntaxError` in `render()` not in `get_template()` when an error is in the included template, so that's the real usage. We don't need to mock anything here.
Looks like Windows isn't happy with the dots. I think something like 'nonexistent' should work.
I think we should use `local_concrete_fields` :thinking: Also, the current solutions doesn't work with recursive parents, e.g. ```python Pizzeria.objects.bulk_create([ Pizzeria(name='Vegan Pizza House', rank=33), ]) ``` crashes when we add the `Ranked` model: ```python class Place(models.Model): name = models.CharField(max_length=100) class Meta: abstract = True class Ranked(models.Model): rank = models.IntegerField(null=True) class Restaurant(Ranked, Place): pass class Pizzeria(Restaurant): pass ```` ```
Oh, I thought it was referring to two separate issues. Alright then, I'll make a new PR and we can proceed from there
```suggestion on_conflict=on_conflict, ```
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
`RETURNING` from `UPDATE` is out of this ticket scope.
I know but it's not worth complexity, we can use ```python stream = open_method(output, 'wt', **kwargs) if output else None ``` in `dumpdata` and ```python with open_method(filename, 'rt') as f: ``` in tests.
True, thanks :+1:
`t` is unnecessary, IMO.
Do we need a separate variable? I would include it directly in the `compression_formats`: ```python compression_formats['lzma'] = (lzma.open, {'format': lzma.FORMAT_ALONE}, mode) ```
This check is also redundant.
Please remove unnecessary space i.e. `(validator,)`.
I'd include the min length in the error message
its so that, for example, a ...
no dash in "email"
This would be better as a set rather than a list.
I think you missed this one in your recent updates.
Move this above `has_add_permission` for consistency.
This code ignores the value of `readonly_fields`. I noticed this because it breaks an inline with a field which is defined as a method in the inline itself (and, thus, needs to be in `readonly_fields`). I'm currently using this workaround (there might be a more clever way to solve it): ```python return [field.name for field in self.opts.local_fields] + \ [field.name for field in self.opts.local_many_to_many] + \ list(self.get_readonly_fields(request, obj)) ```
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
If you want to use a new name, that's okay with me, but I think `'has_file_field'` should remain for backwards compatibility.
I would chop `_support`.
Add trailing comma.
Could we check if we actually need this `with` statement again? Maybe the one above is just fine? :man_shrugging:
This collation doesn't work for me: ``` django.db.utils.ProgrammingError: collation "en_US" for encoding "UTF8" does not exist ``` I've changed to the `en-x-icu`.
Can you group both of these under `if self.include`? Or return early after checking `not self.include`.
You're calling `model_name.lower()` twice in most cases
I don't think you need `list()` here.
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
Yes, this should be taken care of before.
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
We should mark all tests and model states that use `index_together` in `tests/migrations/test_autodetector.py` for removal. We can also move them to a common class for easier remove when deprecation ends.
The main question is what to do with these tests? We should analyze them one by one and prepare alternative versions only with `unique_together` (if necessary). I'm afraid that we cannot simply remove them when deprecation ends because we will end with many not covered scenarios. For example: ```python diff --git a/tests/migrations/test_autodetector.py b/tests/migrations/test_autodetector.py index 547e0b32c5..4c19a34d7f 100644 --- a/tests/migrations/test_autodetector.py +++ b/tests/migrations/test_autodetector.py @@ -2441,10 +2441,10 @@ class AutodetectorTests(TestCase): self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterField"]) + # RemovedInDjango51Warning: When deprecation ends rename to + # test_empty_unique_together(). + @ignore_warnings(category=RemovedInDjango51Warning) def test_empty_foo_together(self): - """ - #23452 - Empty unique/index_together shouldn't generate a migration. - """ # Explicitly testing for not specified, since this is the case after # a CreateModel operation w/o any definition on the original model model_state_not_specified = ModelState( @@ -2457,7 +2457,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": None, + "index_together": None, # RemovedInDjango51Warning "unique_together": None, }, ) @@ -2468,7 +2468,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": set(), + "index_together": set(), # RemovedInDjango51Warning "unique_together": set(), }, ) ```
A note in `docs/internals/deprecation.txt` is missing.
`codename %= ...`
`cls.__name__.lower()` is the same as `self.model_name`. I guess `model_name` would probably be a better placeholder name.
```suggestion # Inline annotations in order_by, if possible. ```
Pretty sure we can't drop the `order_by` based on 779e615e362108862f1681f965ee9e4f1d0ae6d2 which explicitly deals with this `annotate` / `FieldError` issue.
```suggestion if annotation := query.annotations.get(col): ```
`by` :thinking: ```suggestion f"Cannot update when ordering by an aggregate: " ```
```suggestion new_order_by.append(annotation) ```
seems like a helper method to get the attachment path would save some repetition
The commas aren't necessary in the docstring sentences.
Same style as above.
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
chop blank lines
This is really a separate fix, but I guess we can do them in the same PR.
Please add a trailing comma: ```suggestion [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver'], ```
Can we reorganize this a bit? ```python exe_entrypoint = py_script.with_suffix('.exe') if exe_entrypoint.exists(): # Should be executed directly, ignoring sys.executable return [exe_entrypoint, *sys.argv[1:]] script_entrypoint = py_script.with_name('%s-script.py' % py_script.name) if script_entrypoint.exists(): # Should be executed as usual return [*args, script_entrypoint, *sys.argv[1:]] raise RuntimeError('Script %s does not exist.'% py_script) ```
`"Script {} does not exist.".format(py_script)` -> `'Script %s does not exist.' % py_script`
`can not` -> `cannot`, or better `may not `
It's not actually a comprehension - this could just use a tuple literal.
Unnecessary list comprehension, `tuple(self.model._meta.pk.get_col(inner_query.get_initial_alias()))` should do.
in case of -> if
Oh, of course, sorry. Totally missed the loop somehow. Ignore this, I think it's fine as-is.
No sure about which parts should remain in `Q.checks` instead. Current separation seems relatively good but I'd be curious about input from others.
Using hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Perhaps this could mock `random.choice('?.')` to test both scenarios.
Perhaps this test could mock `random.randint` to be more useful.
Same here, not following order `(value, expected)`
perhaps this should be moved to a class constant so it doesn't have to be repeated.
Sorry, was thinking of something else.
You don't know what a docstring is? Trying googling "python docstring".
We'd only put the ticket number for a particularly tricky ticket. I don't think it's necessary here.
Would be better to put this as a module constant to avoid compiling it over and over.
This patch looks mostly good and works for me. My one suggestion is that the test with a date object be explicit, like `test_sitemap_last_modified_tz`, rather than put into the i18n test.
I tried to address Simon's request in the da4dd37f5fbb4bf9489f45803ffc0a91d0ac0592, this change also replaces some misleading variables' names.
Is there a reason not to favor the previous approach and pass `returning_fields=self._meta.returning_fields` instead? That seems like a better separation of concerns to me than having the insert compiler lookup `returning_fields`.
```suggestion unique_fields=unique_fields, ```
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
```suggestion return 'Create collation {self.name}' ```
I think it's too late for this check, `locale` shouldn't be an optional argument.
```suggestion return f'Remove collation {self.name}' ```
```suggestion raise NotSupportedError('Non-deterministic collations require PostgreSQL 12+.') ``` Also, this exception isn't tested.
We should also remove `self.collation_exists(schema_editor, self.name)` checks.
~~I changed this to an assertion for the only file that is affected by the second round of post-processing i.e. `cached/relative.css`.~~
Add trailing commas in call_commands.
```suggestion self.assertEqual(err.getvalue(), 'No statements found.\n') ```
`out` and `err` are unused in the second call. IMO we can simplify this call, e.g.: ```python with self.assertRaises(CommandError): call_command(Command(), no_color=True, force_color=True) ```
Probably the check functions should be called directly rather than invoking them through `run_checks()` (otherwise, this runs all registered checks across all installed apps which doesn't provide good isolation) -- see `tests/check_framework`.
You don't really need a docstring at all, IMO. The test itself explains it well enough.
Python functions implicitly return `None` if return is not called. I feel being explicit is better for a test.
We should also test for `events = Event.objects.filter(group__in=groups.query)` to test both `isinstance(self.rhs, QuerySet)` branches.
Where in the process of replacing these constructs with `self.assertSequenceEqual`, see #7226.
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
Maybe: ```suggestion setting = getattr(settings, 'FILE_UPLOAD_TEMP_DIR', None) if setting and not Path(setting).is_dir(): return [Error( f"The FILE_UPLOAD_TEMP_DIR setting refers to the nonexistent " f"directory '{setting}'.", id='files.E001', )] ```
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
This doesn't seem correct as `SimplePoFileTests` no longer has any tests in it so now this subclass doesn't do anything.
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
```suggestion # The not-provided sentinel is distinct from None, as which() returns None when not found ```
```suggestion # Use a sentinel rather than None, as which() returns None when not found. ```
no `u''` prefixes on strings please
or just `# CSS files shouldn't be touched...`
`s/ exists/ exist`
Use a single quote.
This is the same test as above.
Use a single quote.
You've added seven asserts, but only two are related with this fix, so I think it will be better to send: ```python self.assertEqual(stringformat([1, None], 's'), '[1, None]') self.assertEqual(stringformat({1, 2}, 's'), '{1, 2}') self.assertEqual(stringformat({1: 2, 2: 3}, 's'), '{1: 2, 2: 3}') ... self.assertEqual(stringformat(object(), 'd'), '') self.assertEqual(stringformat(None, 'd'), '') ``` in advance in a separate PR.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
Mhm that is what I was trying to avoid, because for most hasher a salt length is just that and `must_update` should easily be able to handle that globally if it is returned from `decode`. What this PR certainly misses (and what will show you the existing problems) is a test for the behavior of the `bcrypt` hasher. I think now it's `must_update` will *always* return `True` and set a salt *every* time.
IMO, we should use `self.decode` here.
I would put "decode" into quotes or so (@felixxm can certainly tell us what the proper syntax is)
While trying to push this PR over the finish line I noted that `salt_len` is not really the `salt_len` we want (it's the size of a string in bytes). I have pushed a new PR #13815 which adds the actual salt to `decode`. I'll update this PR once the other one is merged.
This will accept prefixless sha1 hashes which weren't accepted previously.
A set literal makes a tiny bit more sense here I think: `{'addError', 'addFailure', 'addUnexpectedSuccess',}`
```suggestion """PO files are unchanged unless there are new changes.""" ```
```suggestion self.original_po_contents = Path(self.PO_FILE).read_text() ```
Something is wrong with the indentation here, you might want to use `flake8` from the top directory to spot warnings.
There is no need to split this into multiple assertions: ```suggestion self.assertEqual(check_url_config(None), [ Error( 'URL route ...', id='urls.E009', ), ]) ```
Grrr... I'd much prefer an explicit wait (for a known condition) then keeping the straight asserts...
No, really no. The assertions in the bottom should be replaced by waits until the result have the right length. Sleeping will just slow down the test suite artificially and could still fail on some systems. This is also part of my pull-request. I am not so sure about this ticket. A lot more tests fail for me locally when I run against FireFox. I believe we should consider running selenium tests all the time, as suggested in my GitHub actions patch, to make sure we a stable reference.
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
I think we could swap this and the previous `if` over - no reason to do the `has_related` check if we've specified the list. Alternatively, move the `has_related` inside an `if ... is False`
Why cast to a tuple? We could just check if it's falsey...
FWIW I made sure we don't forget to remove these methods [when we drop support for Python 2](https://code.djangoproject.com/ticket/23919).
[Python 3 defaults `__ne__` as the opposite of `__eq__`](https://docs.python.org/3/reference/datamodel.html#object.__ne__). So I think we could drop this method.
`CheckConstraint`, `UniqueConstraint` and `ExclusionConstraint` inherit form `BaseConstraint` it should be fine to call `super().__eq__(other)` if an other's class doesn't match, e.g. ```python def __eq__(self, other): if isinstance(other, UniqueConstraint): return ( self.name == other.name and self.fields == other.fields and self.condition == other.condition ) return super().__eq__(other) ```
~Is this only required for the specifics of the test cases, or is it required to satisfy the merging and sorting in `Media` itself? If the former, all well and good, if the latter, would that need to be part of the `Paths as objects` interface contract?~ Oh I guess it's the `and be hashable` part already. My bad, ignore!
Is this a typo? ```suggestion def __ge__(self, other): ```
Move `MockViewUser` above `MockAddUser` to keep consistent ordering...
```suggestion if not isinstance(perm_list, (list, tuple)): ValueError('perm_list must be a list or tuple.') ```
Why this refactoring? (Touches a lot of the other tests...)
prefer this style for multilined docstrings: ``` """ Text """ ```
I believe save() isn't required after adding permissions (M2M change)
`ChoiceFormSet` -> `ArticleFormSet` You mixed `Article` with `Choice` in few places.
Please move fixing typo to a separate commit.
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
```suggestion f'<li>Title: <input type="text" name="form-0-title"></li>' f'<li>Pub date: <input type="text" name="form-0-pub_date">' f'{delete_form}</li>' ```
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
Constructing the entire string within the as_sql method departs from how other functions work. Is it possible to do something like: ``` class BaseCaseExpression(Func): function = None template = 'CASE %(simple)s %(conditions)s ELSE %(default)s END' ``` Then build up the dict required to fill in that template, and construct/return at the end? It may flow nicer, and allow 3rd party backends to modify the template without overriding the entire method.
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
I think we should include `six.text_type` to `isinstance` check too.
No need for that. `text_type` is a subset of `string_types`. Python 3: ``` python >>> six.text_type <class 'str'> >>> six.string_types (<class 'str'>,) ``` Python 2: ``` python >>> six.text_type <type 'unicode'> >>> six.string_types (<type 'basestring'>,) >>> str.__bases__ (<type 'basestring'>,) >>> unicode.__bases__ (<type 'basestring'>,) ```
I wonder if this could be addressed by adding a `MultiColSource` method that returns `self`
It usually isn't a problem. There always the option to add another field to that model if making the existing field nullable causes an issue.
To follow the style of other models: `(Series, models.CASCADE null=True)`
Do we need to change `related_name` here? We could add `note` with `related_name='owner'` instead.
(inadvertence revert here too)
Unnecessary -> ```suggestion def __str__(self): ```
I'd leave `'operations'` an empty list. Also, can you use single quotes here, please.
```suggestion "import datetime\nfrom django.db import migrations, models\n", ```
`for data in json.loads(...):`
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
I think we want to avoid altering `self.extra` here and pass `db_type` as a kwag to `super().as_sql()`.
Can you reference the ticket number in the docstring, please.
Can you reference the ticket number in the docstring, please.
You can safely join this an the next line. You have up to 119 chars per line. ;)
IMO there is no need to check a file content: ```suggestion msg = '...' with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
There is no need to use `assertRaisesRegex()`: ```suggestion msg = 'Migration 0001_initial already exists. Use a different name.' with self.temporary_migration_module(module='migrations.test_migrations'): with self.assertRaisesMessage(CommandError, msg): call_command( 'squashmigrations', 'migrations', '0001', '0002', squashed_name='initial', interactive=False, verbosity=0, ) ```
My idea of converters is that backend converters are applied to convert the data to uniform format, then the field converters change that format to the wanted Python object representation. So, in this case, if the bug can't be fixed, then we need to add a backend converter. Doing that for Concat expression would be much better than doing it on all TextFields, but of course before we pass the expressions instead of internal_type to backend's get_db_converters that can't be done. Maybe it is possible to add a cast on SQL level to Concat on MySQL, something like "CAST(Concat('foo', 'bar') AS CHAR)". It might be that if the datatype of Concat expression is incorrect on SQL level, then further operations on the value (say lower()) will not work correctly.
The problem is MySQL. You can use "--column-type-info" for mysql command line client to see that the return type of the expression is blob. Of course, this being MySQL adding a CAST as char in there doesn't actually do anything. The return type is still blob. You can use "cast(concat(a, b) as char(10000) character set utf8)" to get a real cast as VAR_STRING, but you'll have to supply the length, too. And, this being MySQL you'll get silent truncate of data if the length is too short...
Add a custom converter only for MySQL + Concat combination in Concat.get_db_converters()? I believe we are doing the wrong thing for expression converters. We should specialize more (that is, if some aggregate needs custom converters, then add custom converters for that aggregate only instead of for all expressions), and we should also pass the expression instead of the internal_type to backend.get_db_converters. I am going to change the signature of backend.get_db_converters() so that it gets expression instead of internal_type as input parameter.
append(...), not append[...].
A doc string is needed for get_db_converters so any 3rd party backends know exactly what is expected from this method
Alright, let's keep this change for another PR then.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Indexes are not constraints, generally.
`constraint_name` should also be quoted.
should this be super()
PEP 8 requires this blank line
For geometries, the data-source is different from a Geometry instance, as a data-source represents a list/table of geometries and attributes. This difference does not exist for rasters, the data source _is_ the raster. Thats why I named this class GDALRaster, as I suppose that is the more intuitive name. Did you have a second class in mind for the actual raster? If not, all rasters will be instances of RasterSource, which I think is not ideal.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
Fine, but not as part of this PR. If you can change these cases systemically, that would be great.
Oh yeah... That was silly of me :blush:
This crashes: ``` Complete output from command python setup.py egg_info: Traceback (most recent call last): File "<string>", line 1, in <module> File "/tmp/pip-K04os1-build/setup.py", line 36, in <module> """.format('.'.join(REQUIRED_PYTHON), '.'.join(HAS_PYTHON))) TypeError: sequence item 0: expected string, int found ```
Use single quotes.
I'd omit a blank line here.
It will be `django.contrib.postgres.constraints.XXX` but I don't think that's an issue for core constraints we return `django.db.models.XXX`.
Also here: ```python if self.index_type.lower() != 'gist': ```
I would move it to `_init__()`: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ... self.index_type = index_type or `GIST` self.condition = condition super().__init__(name=name) ``` and skip the default in `deconstruct()` and `__str__()`: ```python def deconstruct(self): ... if self.index_type != 'GIST': kwargs['index_type'] = self.index_type ```
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
Maybe `_parse_where()` -> `_get_condition_sql()`, I would return condition and add `WHERE` in `constraint_sql()`, e.g. ```python def _get_condition_sql(self, compiler, schema_editor, query): if self.condition is None: return None where = query.build_where(self.condition) sql, params = where.as_sql(compiler, schema_editor.connection) return sql % tuple(schema_editor.quote_value(p) for p in params) def constraint_sql(self, model, schema_editor): ... condition = self._get_condition_sql(compiler, schema_editor, query) return self.template % { ... 'where': ' WHERE (%s)' % condition if condition else '', } ```
argument ordering should be reversed
The log message makes no sense. You are trying to normalize (or rather kludge) something that should be a locale to be a language code/tag, to then convert to a locale. But you are saying the locale has been normalized to a language code/tag which is incorrect. A language code/tag is not a locale, and here we *should be providing a locale*, hence my misgivings already stated about this whole thing. Regardless, you probably want to do this: ```python def normalize_locale(original, stdout): """ Normalizes incorrect locale strings, e.g. zh-cn, zh_cn, ZH-CN are converted to zh_CN. """ corrected = to_locale(original.lower().replace('_', '-')) if original != corrected: stdout.write('Normalized %s to %s.' % (original, corrected)) return corrected ```
Thanks both :+1: I pushed edits.
While longer, this avoids creating the extra list, string building and "complex" range calculations: ```suggestion i = None try: while i := lang_code.rindex('-', 0, i): possible_lang_codes.append(lang_code[:i]) except ValueError: pass ``` I know it also uses the walrus operator, but Django 4.0 is targeting Python 3.8+, so it is available to us. It seems much more readable to me. (If this isn't a performance critical path then `contextlib.suppress()` could be used to shave off two lines.)
```suggestion with with self.subTest(tag), self.settings(LANGUAGE_CODE=tag): ```
chop trailing ", " in list
could you limit line length to 120 characters so horizontal scrolling isn't required in GitHub? missing whitespace for: `{% autoescape on%}`
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
prefer if you use hanging indent style for this assertion to match the other tests
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
This unfortunately won't work if the subquery refers to any outer references as these must be included in the group by clause.
```suggestion return super().get_group_by_cols() ```
We should test with a different expression since this might be fixed in the future ```suggestion expr = ExpressionWrapper(Lower('field'), output_field=IntegerField()) self.assertEqual(expr.get_group_by_cols(alias=None), [expr.expression]) ```
not sure we really need backwards compatibility here
I wonder if this could be addressed by adding a `MultiColSource` method that returns `self`
I think this test can be removed.
Unrelated: this might be obsolete after 8f97413faed5431713c034897cda486507bf0cc3.
Probably the check functions should be called directly rather than invoking them through `run_checks()` (otherwise, this runs all registered checks across all installed apps which doesn't provide good isolation) -- see `tests/check_framework`.
Just curious if there is a reason for the `runTest` name instead of the usual non-camel case name.
```suggestion elif databases[DEFAULT_DB_ALIAS] == {}: ```
Using `clashing_pair` in a hint is misleading. We should use appropriate model names not field names or table names.
Chop blank line.
Add a trailing comma.
Could you rename the field to `RemovedField` given the test case name.
Makes sense. Lets go with `MyField` then.
`date=rfc850date` isn't needed in the `subTest()` -- since will appear if the assertion fails.
I would move mocking `datetime` to a decorator, after that we will be able to test different dates, e.g. ```python @mock.patch('django.utils.http.datetime.datetime') def test_parsing_rfc850(self, mocked_datetime): mocked_datetime.side_effect = lambda *args, **kw: datetime(*args, **kw) utcnow_first_fifty = datetime(2019, 11, 6, 8, 49, 37) utcnow_second_fifty = datetime(2051, 11, 6, 8, 49, 37) date = ( ('Tuesday, 31-Dec-69 08:49:37 GMT', datetime(2069, 12, 31, 8, 49, 37), utcnow_first_fifty), ('Monday, 10-Nov-70 18:49:37 GMT', datetime(1970, 11, 10, 18, 49, 37), utcnow_first_fifty), ('Wednesday, 31-Dec-71 18:49:37 GMT', datetime(1971, 12, 31, 18, 49, 37), utcnow_first_fifty), ('Thursday, 31-Dec-99 08:49:37 GMT', datetime(2099, 12, 31, 8, 49, 37), utcnow_second_fifty), ('Thursday, 10-Nov-50 18:49:37 GMT', datetime(2050, 11, 10, 18, 49, 37), utcnow_second_fifty), ('Sunday, 31-Dec-00 18:49:37 GMT', datetime(2000, 12, 31, 18, 49, 37), utcnow_second_fifty), ) for rfc850str, expected_date, utcnow in date: mocked_datetime.utcnow = mock.Mock(return_value=utcnow) with self.subTest(string=rfc850str): parsed = parse_http_date(rfc850str) self.assertEqual(datetime.utcfromtimestamp(parsed), expected_date) ```
I don't think the number of tests is an issue, but since the check depends on a variable, the test should also reflect this, or it'll break at some point.
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
I think this fails for some cases in the current year as well as for some in the future. ``` python def get_year(year, current_year): assert 0 <= year < 100 if year <= current_year + 50: year += 2000 else: year += 1900 return year assert get_year(19, current_year=2019) == 2019, "same year" assert get_year(20, current_year=2019) == 2020, "next year" assert get_year(18, current_year=2019) == 2018, "last year" assert get_year(40, current_year=2019) == 2040, "21y hence" assert get_year(80, current_year=2019) == 1980, "39y ago, not 61y hence" # fails! assert get_year(10, current_year=2019) == 2010, "9y ago, not 91y hence" assert get_year(69, current_year=2019) == 2069, "50y hence" assert get_year(80, current_year=2070) == 2080, "future 10y hence" assert get_year(60, current_year=2070) == 2060, "future 10y ago, not 90y hence" assert get_year(10, current_year=2070) == 2110, "future 40y hence" # fails! assert get_year(21, current_year=2070) == 2021, "future 49y ago, not 51y hence" assert get_year(20, current_year=2070) == 2120, "future 50y hence" # fails! ``` Can I suggest an alternative implementation? ``` python def get_year(short_year, current_year): assert 0 <= short_year < 100 current_short_year = current_year % 100 delta = short_year - current_short_year if delta < 0: delta += 100 # assume future if delta > 50: delta -= 100 # then shorten if too far in the future return current_year + delta ```
`for data in json.loads(...):`
Here's another place where an unnecessary line break is inserted after the period.
Yes, it would be good to add a docstring.
I feel like we shouldn't override "private" methods to test, I also don't see why that would be necessary here.
What I meant is, to leave the database in a clean state for other tests, we need: ``` self.assertTrue(Car.objects.exists()) Car.objects.delete() ```
The name "WrongBackend" isn't very descriptive about its purpose.
Sorry just browsing here but there's a typo : `NoAuthenicateArgumentsTest` instead of `NoAuthenticateArgumentsTest`
Please use `SimpleTestCase` here as no database query is performed.
is this meant to test the `except TypeError` branch in `contrib.auth.authenticate()`? It would be clearer to call that function directly.
We can move the test that involves `login()` to the other pull request.
use a single line
prefer assertRaisesMessage to verify the message contents as well
I wouldn't include this test in the PR because it's testing existing behavior. But it doesn't seem needed as there's a test in `test_client_regress` that fails if the `isinstance(data, dict)` check is `_encode_json` is removed.
This is the default charset in Django, I wouldn't call it unusual :)
This isn't Django's default charset (unless I'm mistaken).
Rather than `str(next(iter(...` maybe: ``` messages = [m.message for m in request._messages] self.assertEqual(1, len(messages)) self.assertIn(error, messages[0]) ```
Instead of ``` choices = list(filterspec.choices(changelist)) self.assertEqual(len(choices), len(expected_displays)) for i, display in enumerate(expected_displays): self.assertEqual(choices[i]['display'], display) ``` you can write ``` choices = tuple(c['display'] for c in filterspec.choices(changelist)) self.assertEqual(choices, expected_displays) ```
I'd inline this helper within the subTest()
```suggestion self.asserCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
state the expected behavior, e.g. `The last choice is for the None value.`
@David-Wobrock I checked out your branch to build an alternative to #13904 off model states and I noticed both `through_app_label` and `through_model_name` are unused which makes me believe something is off here.
Are you sure this branch is ever skipped? AFAIK `auto_created` models are not part `ProjectState.models` entries.
please check flake8, I believe this is a warning because the line identation isn't distinguished from the next (fix by add 4 more spaces to this line)
You can reuse `resolve_model_field_relations()`.
The 4 lines above look identical to the `remote_model_key` lines a few lines before, except with `through` instead of `remote_field.model`. Maybe that can be a helper method accepting that argument.
This is already tested in `test_args_kwargs_request_on_self()`, I'm going to remove these assertions.
This test is not related with the patch, so I'll move it to a separate commit.
And all the blank lines in this test.
Perhaps dropping this blank line.
A note about code length, because some users may say "using self.client.get() is more straightforward"... We can also write the lines above (297-301) like this: ``` python view = views.CustomTemplateView.as_instance( RequestFactory().get('/dummy'), foo='bar') ``` That said, the way they are written right now is fine too.
I don't see much value in this check.
I think we usually avoid _should_ wording in test docstrings.
should be `first_state`, not `project_state`, I suspect.
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
> Is there any specific reason why we would prefer using the operation in this case? Yes, because we have it. Using a RAW SQL is the last option, we're developing the ORM in order not to use them.
no comma needed
can you call `sort` on the invalid_apps before joining them, please.
You could use single quotes in all strings for consistency (don't worry about existing tests).
This small optimization is not related with fix. Merged in e12fea24f06f8911ddc2af1d6cbfb1adb529c1f2.
Yes, for new code we're trying to follow the [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I'm not too keen on beginning each warning with "In your url patterns, ..". How about "Your url patterns .." ? "Your url patterns have used `include` with a regex containing a '$'. " .. "Your url patterns have a regex beginning with a '/'." .. "Your url patterns have a pattern with a name containing a ':'." ..
remove extra newline
Please check code with flake8 as described in the patch review checklist and correct the "no newline at end of file" warning here.
remove extra newline
I'd omit this blank line.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python with mock.patch('django.core.files.move.os.rename', side_effect=OSError()): ```
Chop blank line.
Chop blank line.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python error = PermissionError(errno.EPERM, 'message') with mock.patch('django.core.files.move.copystat', side_effect=error): ```
Chop blank line.
I would call this `_field_became_primary_key`.
According to [Wolfram Alpha](http://bit.ly/29bAENj) that's the same as this and slightly more understandable? ``` python (not old_field.db_index and not old_field.unique and new_field.db_index) or (not old_field.unique and new_field.unique) ```
Oh are we creating the `_like` indexes even when `unique=True`? I wasn't expecting that.
We should move `Foo.objects.create()` outside the context manager, i.e. ```python with connection.schema_editor() as editor: editor.alter_field(Foo, old_field, new_field, strict=True) Foo.objects.create() ```
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Maybe: ```python raise TypeError( 'sensitive_post_parameters() must be called to use it as a ' 'decorator, e.g., use @sensitive_post_parameters(), not ' '@sensitive_post_parameters.' ) ```
Wrap at 79 chars.
Please revert unrelated changes.
I would remove this sentence and let the person who changes this code in the future decide of the way to implement it.
Would be fine I guess. I'm not too sure about the safety margin aspect in the first place, but it's SQLite so whatever works, I guess.
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
These are unnecessary ```suggestion ```
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
Use this style: ``` self.assertEqual(field.check(), [ ]) ```
Could you rename the field to `RemovedField` given the test case name.
Makes sense. Lets go with `MyField` then.
Using `clashing_pair` in a hint is misleading. We should use appropriate model names not field names or table names.
As noted elsewhere, put the trailing space on this line rather than the next (and in the message below).
Ah, didn't know this existed yet. I see that this PR is mostly a "copy" of the ContentTypes one. Sounds alright for now, then.
@charettes, any reply here? I guess we shouldn't block the patch about the issue with backwards migrations if we can't find a simple solution.
I guess some tests might be needed for the router stuff.
It's not required here. It was used in f179113e6cbc8ba0a8d4e87e1d4410fb61d63e75 because we were handling a possible `IntegrityError`.
chop trailing ", "
IMO we can simplify condition: ```not self.blank or (self.blank and not self.null)``` to: ```not (self.blank and self.null)```
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
The nested if statements seem excessive. Could this whole thing just be simplified to the following: ```python def formfield(self, **kwargs): if self.choices: include_blank = not (self.has_default() or 'initial' in kwargs) defaults = {'choices': self.get_choices(include_blank=include_blank)} else: form_class = forms.NullBooleanField if self.null else forms.BooleanField # In HTML checkboxes, 'required' means "must be checked" which is different # from the choices case ("must select some value"). # required=False allows unchecked checkboxes. defaults = {'form_class': form_class, 'required': False} return super().formfield(**{**defaults, **kwargs}) ```
Please don't make unrelated whitespace changes.
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
It seems a bit confusing to have this docstring here without any `return` statement, perhaps some clarification would be helpful.
New docstrings should use PEP257 verb style "Returns -> Return". I'd write something like "On backends that supported it (memcached), return a list of keys that failed insertion."
Shouldn't django allow lazy-evaluation function as default value? (Calculate the default value as needed)
I think @chicheng means doing the equivalent of: cache.get_or_set('some-timestamp-key', datetime.datetime.now)
Use a single line (we allow up to 119 characters when it helps readability)
```suggestion "Cannot aggregate over the 'other_age' alias. Use annotate() to promote it" ```
Since `fan_since` is None at this point, the test cannot pass! Same below.
I'd make it a separate method: `test_cast_to_char_field_without_max_length`
using `Lower` seems more readable
```suggestion authors, [25, 34, 35, 37, 45, 46, 57, 29], lambda a: a['age'] ```
You can do what I suggested above here as well.
You should use `supports_update_conflicts_with_unique_fields`.
You should use `supports_update_conflicts_with_unique_fields`.
Chop blank line.
```suggestion elif ( on_conflict == OnConflict.Update and not self.connection.features.supports_update_conflicts_with_target ): ```
Please use the helper methods `self.assertOperationType()` et. al.
Can you also check for `questioner.ask_auto_now_add_addition` to be called 3 times, please or is this something we don't do in here but in commands.
`s/_managed/_unmanaged/` I think.
Replace "items" with "values"
Could you add an `assetNumberMigrations` before the `assertOperationTypes` and join the `assertOperationAttribute` checks; they take `**kwargs`.
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
Use `assertNotIn` instead.
Actually you should use `assertNotContains(response, '"/test_admin/admin/r/%s/1/"' % content_type_pk)` to also account for `byte` response content on py3.
could we make more specific assertions here using `assertFormSetError` - I think that'll make the test more readable.
This test isn't properly acting as a regression test as it passes even if the second change in options.py isn't made.
I would override `clean()` as described in the ticket, e.g. ```python class PubForm(forms.ModelForm): mode = forms.CharField(max_length=255, required=False) mocked_mode = None def clean(self): self.cleaned_data['mode'] = self.mocked_mode return self.cleaned_data class Meta: model = PublicationDefaults fields = ('mode',) default_mode = 'di' pub_form = PubForm({}) pub_form.mocked_mode = 'de' pub = pub_form.save(commit=False) ... ```
TBH this is not what I suggested, I wanted to use `mocked_mode` to keep code DRY. I pushed edits.
unchecked -> unselected
`assertEquals` is deprecated and should be replaced by `assertEqual`. In a more personal-taste spirit, is it really useful to make 4 separate tests instead of consolidating them into one? The fact that the last 3 are identically named is an error, for sure.
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
Definitely -- a place specifically designed for preparing the module is needed. It'll also help 3rd party backends that need to override specific as_sql methods.
It looks like we usually uppercase the function name (e.g. `CAST({} as {})`).
And I would rename this attribute `superusers` as it's meant to contain multiple users.
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
`expressions` should be before the `name` like in other classes.
I would revert these changes, a string representation of `condition` and `deferrable` doesn't need and extra quotes.
`include` is a tuple, that's why we need `repr()`.
~~Also use `%r` and not `repr()`.~~
We should use `__qualname__` in all classes.
I think we want to avoid altering `self.extra` here and pass `db_type` as a kwag to `super().as_sql()`.
Please report bugs at https://code.djangoproject.com/.
append(...), not append[...].
Feels like this should be handled at the database backend level.
Is this check correct? A `Coalesce` can still result in a null value (if all of its arguments are null), so even if the expression is already a `Coalesce` ISTM it needs to be wrapped again (or have `Value('')` added to the end of its `source_expressions`, but just wrapping in another `Coalesce` seems cleaner).
I believe the test shouldn't be skipped on SQLite, it's failing locally because you're closing overridden connections which are used when using in-memory SQLite databases. You should be able to remove this `skipIf` after adjusting the `finally` block to only close non-overriden connections.
I see, I didn't know the SQLite backend `close()` method was already dealing with this case internally. I suggest you only skip the test if an in-memory backend db is used in this case. If you can't do this using `@skipIf` raise a `SkipTest` exception in the test instead.
chop blank line
chop blank line
> PS - you might ask: why not fix ticket 29062 first? The reason is that fixing ticket 29062 properly would involve properly closing connections. Thus, any correct fix of ticket 29062 would be a superset of this PR, which would make it an even bigger change. Yes that was my first question :smile: Thanks for details :+1: . I'm afraid that it can be still confusing for a future me. I will try to move something to a separate commit e.g. `_make_connections_override()` which should reduce the number of changes and make it easier to bisect and fix potential regression.
Multiple values should be allowed only for the `no-cache` directive, this change allows for multiple values for all keys what is not desirable.
`response.get('Cache-Control')` should do.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
Please use a hanging indentation: ``` python self.assertEqual( set(...), {...}, ) ```
I updated variable names. > and I would also remove unnecessary blank lines I don't see any unnecessary blank lines :thinking:
It seems like there's no longer a need for the defensive use of `.get()` here; `CSRF_COOKIE` must always be set at this point.
I personally generate the NONCE's on the client side using javascript (so I don't need the token in the response body). It would be nice to continue long term to accept the raw cookie value as a valid csrf token.
Ahh. Got it. That makes sense. (Seems fine to me if we eventually remove it. Maybe raise a deprecation warning.)
It would allow our "AJAX" method to continue working unchanged: https://docs.djangoproject.com/en/dev/ref/csrf/#ajax
Is this branch a candidate for removal in some future release? Either way, would be helpful to elaborate on how the backwards-compatibility case arises. I think it's upgrading Django in the presence of existing token set by older versions of Django, but would like t to confirm.
``` Superuser creation skipped due to not running in a TTY. You can run `manage.py createsuperuser` in your project to create one manually. ```
We can remove `-- ` prefix from all outputs.
`--prune` is ignored when `--plan` is used. Maybe we should raise an error that they're mutually exclusive.
Please don't make unrelated whitespace changes.
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
Make `__str__` return `self.string_rep` and nuke `__unicode__`.
I think `var_repr` is more explanatory than just `rep`. Also, use single quotes rather than double quotes unless the string contains a single quote.
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
I realize this predates your PR, but why is 'unused' not used? It appears to be the target field provided by the SQLUpdateCompiler during as_sql(). This seems like a really good spot to allow a backend to hook in and CAST the expression to a type that is allowed by the target column.
Not sure how much a difference it makes, but it seems better to store this in Python rather than having to read from a text file. Worth it to make the file location customizable? If so, it might be nice to make "common passwords" a separate package so we don't have to include that list in Django. I guess users might not care for the additional setup tasks though.
Please keep the alphabetical order.
I'm not seeing why this change within this commit, but it could be just me.
`self.assertFalse()` -> `self.assertIs(..., False)` `self.assertTrue()` -> `self.assertIs(..., True)`
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
`else` is unnecessary, I think we can leave: ```python if self.ignorenonexistent: continue raise ```
In `_handle_m2m_field()` and `_handle_foreign_key_field()` we can avoid of temporary variables (`value`) and return directly, e.g. ```python def _handle_foreign_key_field(self, field, field_value): return base.deserialize_fk_value(field, field_value, self.using, self.handle_forward_references) ```
I would keep the previous name for a class attribute: ``` self.ignorenonexistent = ignorenonexistent ```
This can be single-lined.
I don't think we want to subclass `base.Deserializer`. Instead, we can just do `self.object_list = object_list` and use that instead of `self.stream` below.
Typo: annotaion -> annotation
`annotations` is spelled incorrectly here.
I find this code a bit confusing -- where is the `FieldError` expected to be raised? `expression.input_field.output_field`? Could you use an if statement for that check rather than try/except or maybe move the code that's not expected to raise into an else block of this try/except? .Not an expert here, so maybe it's fine as is.
Unfortunately annotation names can contain LOOKUP_SEP - that is the reason why the ugly refs_aggregate method was added. For example qs.annotate(Max('id')) will create an annotation named max__id, and that can't be referred if the code checks for len(field_list) == 1.
I guess none of these lines aren't tested since I don't see any new tests that use `db_tablespace`.
Please use single quotes.
Thanks for your effort :+1:. It is a kindly request for the first option. Trailing dot should be at the end of a sentence but there is no point in doing unrelated refactoring of existing code.
Thinking out loud here but do you think the fact the constraint is now deferred before index creation could cause an issue? I think it shouldn't be given RDMBs usually create an internal b-tree to maintain referential integrity.
Use single quotes consistently (could be done above and below also).
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
Is it possible to use something from `connection.ops` or similar to avoid a vendor check? Otherwise, looks good.
We can add `Foo.objects.create()` to ensure that primary key and sequence are still valid.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
We should move `Foo.objects.create()` outside the context manager, i.e. ```python with connection.schema_editor() as editor: editor.alter_field(Foo, old_field, new_field, strict=True) Foo.objects.create() ```
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
```suggestion """ Return a tuple of the database's version. E.g. for pg_version 120004, return (12, 4). """ return divmod(self.pg_version, 10000) ```
Perhaps this is simpler: ``` from textwrap import wrap return tuple(wrap(str(self.pg_version), 2)) ```
add docstring: Return a tuple of the database's version.
`return self.get_database_version() >= self.features.minimum_database_version`
Rather than implementing a special CursorWrapper for Oracle to do this, it is better to include the change in the general CursorWrapper. This has two immediate advantages over doing it in the Oracle backend: 1) The new feature can be shared with any other backend which supports it (3rd party backends included) 2) The new feature is automatically included in CursorDebugWrapper (which your version of make_cursor disables) The disadvantage -- exposing the interface to backends which do not support it -- is a small price to pay in comparison.
This `raise` seems redundant. I would remove these two lines (629-630) and leave only raise `ValueError(...)` at the end of this method.
`abs()` is redundant since `end` is greater than 0.
I think these temporary variables and blank lines are unnecessary, maybe sth like that: ```python return self.window_frame_start(start), self.window_frame_end(end) ```
They are helpful when using (i)pdb.
"start argument must be a negative integer, zero, or None, but got %s."
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
Need to test that result is as expected, not only calling it.
Here is the explanation I wrote some time ago :) https://python.astrotech.io/advanced/function/parameter-syntax.html
Was just thinking through what this means for ordering of arguments. `function` is a defaulted argument that may be passed positionally *or* by keyword. So `action(permissions=..., function=...)` worked. I think what we'd want ideally is `def action(function=None, /, permissions=None, description=None):`, making `function` positional only with a default, but that's only available on Python 3.8+. Anyway, just a curiousity really, I think the signature is fine as-is and unlikely to cause problems since the other arguments are named-only.
It's a little confusing to not signpost the mismatch between the attribute names. Especially the wording "the attributes" sounds like they should be the same. Perhaps ```suggestion This is equivalent to setting some attributes (with the original, longer names) on the function directly:: ```
```suggestion Conveniently add attributes to a display function:: ```
please use `assertRaisesMessage` to verify this is the `TypeError` we expect (also helps for tracking which tests map to which code).
This can be single-lined, e.g. ```python return HttpResponseServerError( ERROR_PAGE_TEMPLATE % {'title': 'Server Error (500)', 'details': ''}, content_type='text/html', ) ``` The same in `bad_request()` and `permission_denied()`.
Single line looks okay here, in the next test and in the assertEqual of the test.
I think this would be a bit more readable: ``` url = reverse('... show_less_response = self.client.get(url) ```
Move those import to the top of the file.
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
`value` or `return_value`? or maybe we should swap these lines: ```python if ( not timezone._is_pytz_zone(current_timezone) and timezone._datetime_ambiguous_or_imaginary(value, current_timezone) ): raise ValueError('Ambiguous or non-existent time.') return timezone.make_aware(value, current_timezone) ``` :thinking:
If it's changed to return naive current local time when `USE_TZ=False` (as discussed above) that should also be mentioned here.
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
I wouldn't have reflowed this line since you didn't make any other changes and it would simplify the diff.
@akulakov `passed_check` is to check if list is not empty. if it is not empty, method will return no error, otherwise error will be returned (`[] if passed_check else [W020]`).
`not statement` is used several times above, so need to be consistent in code style.
@MarkusH - that looks good to me.
@coldmind With the current code, `passed_check` will be `True` if `settings.ALLOWED_HOSTS` IS empty. That is backwards. `passed_check` should be `True` if `settings.ALLOWED_HOSTS` is NOT empty.
Since this is just a type check which should apply to all environments, not just production ones, it doesn't need the `deploy` flag
I see. `npath` sounds good. IMO the alternative is to explicitly encode under Python 2: ``` if not six.PY3: pf = pf.encode(fs_encoding) os.environ['djangocompilemo'] = pf + str('.mo') os.environ['djangocompilepo'] = pf + str('.po') ``` where `fs_encoding` would be imported from `_os`.
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
```suggestion reg_key_value, _ = winreg.QueryValueEx(reg_key, 'VirtualTerminalLevel') ```
```python mo_file_en.with_suffix('.po').touch() ```
You can pass `verbosity=0` instead to completely silence the command instead of creating an unused `StringIO` container.
Yeah I think that's a good idea in general. I was thinking that a general `**kwargs` added to the signature in all cases was probably correct, but I've come around to your thinking. Most uses outside of `Func` expressions just ignore the `**kwargs` parameter and create noise. So this specific call should be (assuming "extra_context" is a good name): ``` def as_sql(self, compiler, connection, template=None, ordering=None, **extra_context): if template is not None: extra_context['template'] = template if ordering is not None: extra_context['ordering'] = ordering extra_context['ordering'] = ordering place_holders = { .. } place_holders.update(extra_context) ... ```
This method should actually mix `placeholders` with `**kwargs`, which expands the usefulness of `**kwargs` to the `ordering` interpolation variable, but also any other interpolation variables that might be introduced in a subclass.
Please chop all unnecessary blank lines.
This one as well.
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
yeah `.format` crept in while we were supposed to stick to `%`. anyway lets make sure we don't have three ways of formatting strings across the code base 😅 .
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
Really? Surely in this context it should be fine as it is an argument to `getattr()`… (Personally I don't like that check at it leads to cases like this where we have five lines of code instead of a single readable line.)
```suggestion # Windows registry may not be configured with correct # mimetypes. ```
```suggestion self.assertEqual(value, b'text/plain') ```
```python self.assertHTMLEqual( field.widget.render('name', []), ( '<ul>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="entertainment">Entertainment</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="test">A test</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="third-test">Third</label></li>' '</ul>' ) % (self.c1.pk, self.c2.pk, self.c3.pk), ) ```
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
Despite the existing style of the first test, I would remove the intermediate `f` variable in the new tests as it'll help balance line lengths and make things more readable.
Was this intentional? Doesn't seem to be related to the task...
Does it not render with `placeholder="False"` then? Seems strange to me...
Thanks for the clarity, Tim :-) In that case, I think we may as well still go ahead and provide the deprecation shim and warning that we are able to provide (for `ForeignKey(SomeModel, 'to_field')`, which is likely much more common) by shortening this line to just `if not callable(on_delete)`. And we'll just have to rely on a backwards-incompatibility note in the release notes (that you should no longer pass `to_field` positionally, and you can pass `on_delete` as the positional second arg) to help anyone who is doing `ForeignKey(SomeModel, 'to_field', on_delete=models.WHATEVER)`.
Sounds okay. The warning should be updated to say something like "Pass to_field as a kwarg instead of as an arg."
stacklevel 2 isn't useful when the warning is raised for OneToOneField. Ideally we could have stacklevel=3 for that case to give `question = models.OneToOneField(Question)` instead of `super(OneToOneField, self).__init__(to, on_delete, to_field=to_field, **kwargs)`.
The easiest solution might be to duplicate the warning in `OneToOneField`.
Could be useful to say `Pass to_field='{2}' as a....` and add `on_delete` to the format
this could use the indent style of the previous `CommandError`.
no `u''` prefixes on strings please
return directly, no need for `path` variable.
My only question is if this skip logic is still correctly applied (i.e. none of the other classes that inherited `ExtractorTests` require it)? If you verify that, ship it.
chop "should" (just state the behavior)
An error the database
Compare with [L49](https://github.com/scop/django/blob/testdb-destroy/django/db/backends/base/creation.py#L49) and [L207](https://github.com/scop/django/blob/testdb-destroy/django/db/backends/base/creation.py#L207). I think we should aim to do the same everywhere. Perhaps even factor out a `_database_display_str()` method.
`BaseDatabaseCreation` shouldn't contain branches for specific backends.
I'd chop this blank line since the } on its own line is providing whitespace.
param -> params
I think this test would make a little more sense if we used a `CharField` for the primary key of `Foo`. It's not super important though.
The `Foo` model as no `foos` field. As `Foo` is not `auto_created` it should have a similar message to `test_m2m_table_name_clash`.
As the `db_table` is attached to an `auto_created` model the message should be `Field is using a table that has already been registered by 'invalid_models_tests.Baz.foos'.`. The intermediary model `Baz_foos` is an implementation detail and shouldn't be referred to, plus it has no `foos` field.
`test_target_field_may_be_pushed_down` works without the patch. I would move it to a separate commit to make it clear where the behavior has changed.
This should use `assertEqual` and not `assertCountEqual`, otherwise there is no point in entirely recreating the expected warning, you could just hardcode 1 or 0.
`` ```suggestion return resolve(path, urlconf) ```
include a trailing comma
Use `self.assertIs` and `self.assertIsNot` as these boolean expressions are noop.
Return a tuple...
While longer, this avoids creating the extra list, string building and "complex" range calculations: ```suggestion i = None try: while i := lang_code.rindex('-', 0, i): possible_lang_codes.append(lang_code[:i]) except ValueError: pass ``` I know it also uses the walrus operator, but Django 4.0 is targeting Python 3.8+, so it is available to us. It seems much more readable to me. (If this isn't a performance critical path then `contextlib.suppress()` could be used to shave off two lines.)
omitting the ellipsis seems okay to me. Do we need to include 'id__max' twice, e.g. `Cannot compute Max(): 'id__max' is an aggregate`
To fix the Oracle failure, rephrase this query as ``` CaseTestModel.objects.only('pk', 'integer').annotate(... ``` or even ``` CaseTestModel.objects.values('pk', 'integer').annotate(... ``` I don't have it in me to test myself now, but the issue is that if you don't do one of these, then `annotate()` over `fk_rel` implies `GROUP BY` all the fields of `CaseTestModel`; this model includes BLOBs (`TextField`, `BinaryField`) and Oracle refuses to compare them and so they can't be grouped over. By the way, doing this should also make your test faster on all databases except PostgreSQL (I think), because PostgreSQL (AFAIK) is the only one smart enough to realize that grouping over all the columns is really the same as grouping over the PK.
Please break this down into a couple of lines to make it easier to read. Also, the `distinct` call should be unnecessary for this bug, and only introduces extra work that distracts from the main problem.
@timgraham is ordering by the result of an aggregate allowed without subqueries? If ordering by count does not error, then it should be safe to use that ordering. If not, introducing a different field into the orderby will affect the grouping (not that you suggested that), so we'll need to look at comparing the queryset out of order if there's another assert method available that does that. I'm not able to check either of these things at the moment, but I can take a look in about 8 hours if it's not resolved.
What if `default` is not a constant but a field reference? e.g. `F('integer')`
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
Use `assertNotIn` instead.
Actually you should use `assertNotContains(response, '"/test_admin/admin/r/%s/1/"' % content_type_pk)` to also account for `byte` response content on py3.
could we make more specific assertions here using `assertFormSetError` - I think that'll make the test more readable.
This test isn't properly acting as a regression test as it passes even if the second change in options.py isn't made.
Tests for `formset_factory()` and `formset_factory()` are missing.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
Please chop unnecessary blank lines.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
The primary key attribute can only be retrieved on certain databases, this will not work on Oracle or MySQL.
Maybe: ```suggestion setting = getattr(settings, 'FILE_UPLOAD_TEMP_DIR', None) if setting and not Path(setting).is_dir(): return [Error( f"The FILE_UPLOAD_TEMP_DIR setting refers to the nonexistent " f"directory '{setting}'.", id='files.E001', )] ```
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Водка')) ```
I think we are missing the `call_command()` here.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
So [`.flushall()`](https://redis-py.readthedocs.io/en/stable/#redis.Redis.flushall) will clear everything in all databases. (Apparently Redis has 16 logical databases that can be switched between.) We should change this to use [`.flushdb()`](https://redis-py.readthedocs.io/en/stable/#redis.Redis.flushdb) instead and only clear the current database. For consistency we can also ensure this returns a boolean. ```suggestion return bool(client.flushdb()) ``` (We should probably also expose a `db` parameter via `RedisCacheClient.__init__()` which can be passed through via `_client_kwargs`. It should have a default value of `0`.)
Yes, sorry, I meant `max()`.
Ensure we return booleans here for consistency? ```suggestion if timeout is None: return bool(client.persist(key)) else: return bool(client.expire(key, timeout)) ```
As discussed, we can simply `.delete()` here when `timeout == 0`. We can do this if we fix `get_backend_timeout()` to prevent negative numbers as mentioned above. ```suggestion if timeout == 0: client.delete(key) else: client.set(key, value, ex=timeout) ```
As discussed, we can simplify this a bit, also benefiting from the `min(0, ...)` in `get_backend_timeout()`: ```suggestion if timeout == 0: if ret := bool(client.set(key, value, nx=True)) client.delete(key) return ret else: return bool(client.set(key, value, ex=timeout, nx=True)) ```
To verify this is the expected import error, I'd do something like: `self.assertRaisesMessage(ImportError, 'nonexistent')`
These kind of changes are not related and should be reverted, IMO. They're also based on a `MiddlewareMixin` behavior that we can remove in the future, that's why I would prefer to keep `process_request()`/`process_response()` tests.
When fixing the implementation of `RedisCacheClient.get()` to support `default`, this should work fine. ```suggestion ```
preferred format is "#15346, #15573 - Issue description"
immediatelly -> immediately
We would fallback to an empty `bytes` string as well ```suggestion boundary = opts.get('boundary', b'') ```
`s` is always `bytes` in our case so we can drop the `else` branch: ```suggestion return re.match(b"^[ -~]{0,200}[!-~]$", s) ``` We could also pre-compile this regex and use `fullmatch()`: ```python boundary_re = _lazy_re_compile(b"[ -~]{0,200}[!-~]") def valid_boundary(s): return boundary_re.fullmatch(s) ``` It's used only in `MultiPartParser` so maybe a separate hook is not necessary :thinking: ```python if not boundary or not boundary_re.fullmatch(boundary): raise MultiPartParserError( "Invalid boundary in multipart: %s" % force_str(boundary) ) ```
> This is because `\w` already includes `\d`; Yes, exactly. > I wonder if we should switch that to `[a-zA-Z0-9_-]` though since charsets would probably be ASCII, can be done in another commit though Yes, can be done as a separate cleanup.
This is because `\w` already includes `\d`; I wonder if we should switch that to `[a-zA-Z0-9_-]` though since charsets would probably be ASCII, can be done in another commit though
> It's compiled once on import no? Yes, but do we need to compile it at all? In most of cases it's not necessary because `boundary` is already parsed in `opts`.
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
Reading below, I see that Flask has an "any" converter that does something more complicated. Creating a converter with the same name but a different behavior doesn't sound good.
I don't think there isn't a better alternative. Talking about "positive integers" means we still defer thinking about positive and negative ints to the end user. ``` path('articles/<posint:year>/', views.year_archive), ``` ... isn't at all as nice. Since MOST people still won't have to care about negative ints, I still think keeping "int" as the name is a good default, even though not 100% accurate. Also: there seems to be a common case for negative FLOATS, namely coordinates. But since the DEP says floats shouldn't be included that use-case is nicely sidestepped. There's also two nice workarounds to all this: just specify str as type and do the typecasting in the template, or specify your own type that supports negative floats/ints.
Let's stick with positive integers and wait for complaints.
`items = value.split(self.delimiter) if value else []` is slightly faster.
Rather than passing all of `OPTIONS` here we should only pass the protocol: ```suggestion def __init__(self, protocol=None): self._protocol = pickle.HIGHEST_PROTOCOL if protocol is None else protocol def dumps(self, value): return pickle.dumps(value, self._protocol) ```
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
I would use a dict instead. ```suggestion self._pools = {} ``` and in `_get_connection_pool()`: ```python def _get_connection_pool(self, write): index = self._get_connection_pool_index(write) if index not in self._pools: self._pools[index] = self._pool_class.from_url( self._servers[index], **self._client_kwargs, ) return self._pools[index] ```
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
Single quotes please.
`except Exception` unless we really have a good reason for a bare except.
try to make this as minimal as possible -- if we don't need all the validators, error_messages, etc. leave them out
A docstring describing the purpose of this test may be useful.
trailing comma here and next line
When there are only two coordinates, the for loop doesn't seem to be so much better...
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
I would wrap `asvar` and `view_name` in quotes and use `%`-formatting, e.g.: ```python def __repr__(self): return "<%s view_name='%s' args=%s kwargs=%s as='%s'>" % ( self.__class__.__name__, self.view_name, repr(self.args), repr(self.kwargs), self.asvar, ) ```
`asvar` -> `as`
`expressions` should be before the `name` like in other classes.
I would revert these changes, a string representation of `condition` and `deferrable` doesn't need and extra quotes.
If it has some readability benefits, it could be done in a separate PR. This looks okay for now.
`DATE` -> `DATETIME`
We use `field` only to find `internal_type`, so maybe instead of storing `field` we can find and store `internal_type` in `__init__()`? What do you think? ```python def __init__(self, field): self.internal_type = getattr(field, 'target_field', field).get_internal_type() ```
I would remove `get_field_name()` hook and call it `internal_type` (`field_name` is confusing IMO), e.g. ```python internal_type = getattr(self.field, 'target_field', self.field).get_internal_type() ```
I think we can use `int` instead of `str` as a default value, because that's the most common use case. After that we can remove all types mapped to `NATIVE_INT` from `InsertReturnParameter.types`.
And here. (Also no brackets no needed.)
I'd move `'defaults': 'testing'` to the next line and include a trailing comma per our usual style.
Please use `assertRaisesMessage`.
use of one the styles in 04de4369325097472d7ad036dac262555002ba88
plus use hanging indentation, e.g. ``` Person.objects.get_or_create( first_name="George", defaults={"last_name": "Harrison", "birthday": lambda: date(1943, 2, 25)}, ) ```
This assertion is not necessary.
We usually avoid creating new models when we can reuse existing ones as it slowdown the test suite startup. In this case it looks like there's many candidate that could be reused here.
I guess the method probably isn't needed but if you want to keep it, please fix it like c62807968d7930bfd34afc2036c67921b943592f.
remove trailing whitespace
`CustomUserWithM2MAndThrough` -> `CustomUserWithM2MThrough`
in this model, the `ManyToManyField` `authors` is replaced by `books`, right? If yes, could we test it? In other words, test that both directions are influenced by the `default_related_name`.
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
Unindent by one level, please.
Most likely this will not work on Windows because files created with `NamedTemporaryFile` cannot be reopened on Windows (which defeats the whole purpose of naming them in the first place -- I have no idea why `NamedTemporaryFile` even exists on Windows). I'm not saying this is blocking the merge because I don't think we have that many users of PostgreSQL on Windows, but I thought I'd bring it up in case someone wants to check.
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
Mind renaming `schema` to `schema_editor`, please (and in all the other places)
Either add `self` or make it `@staticmethod`
Any problem with allowing `self.model = None`. I think conditional attributes which require `hasattr` isn't the best design.
You can't assume the presence of `self.name` here
I think this could be `@cached_property` so it doesn't have to be calculated on every access.
You could do this setup in Python. `self.school.students.add(...)`
"Stay on ..." (and please be consistent with no spacing around the sentences) Add a period to each sentence too.
URL should be capitalized
We avoid backslashes and use this style: ``` msg = ( "Redirection loop for authenticated user detected. Check that " "...." ) ```
argument -> a GET parameter
```suggestion with self.assertRaises((OperationalError, ProgrammingError)): ```
I'm not sure why these tests raises a `ProgrammingError` :thinking:
`field` variable is unnecessary: ```suggestion msg = "TwoFields has no field named 'nonexistent'" with self.assertRaisesMessage(FieldDoesNotExist, msg): TwoFields.objects.bulk_create(self.data, update_conflicts=True, update_fields=['nonexistent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ```suggestion msg = ( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ```
Please add a trailing comma: ```suggestion update_conflicts=False, update_fields=None, unique_fields=None, ```
if no app*
Can you reference the ticket number in the docstring, please.
I don't think this `\nb#` is actually correct. There should be double quotes after the `b` before `#`.
Yes, please rebase the branch and remove the try/fail pattern as done in 6729b96d8a15048b2295c916c5b881a59d9417a0. If you're unfamiliar with the process you might find https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/working-with-git/#rebasing-branches helpful.
tests aren't entirely consistent, but I prefer omitting a newline after the docstring.
Keep the style the same here and below
This is only used once. Can we move it back to the `color` module? (That way `termcolors` is still only ever used by `color`)
`max_age` is not being passed into `signing.loads()`, nor is `self.serializer`. `session_dict` should be `session_data`.
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
Why would we remove deprecation warnings for Django's own test suite? I think it's a good thing to help us write clean and not obsolete code (I mean by default, without having to specified -Wd).
I updated the file on my branch such that the wkt contains the correct information. `ds.srs.srid` returns `3086` https://github.com/geodesign/django/blob/raster/django/contrib/gis/gdal/tests/data/raster.tif
This should probably be updated with the new gdalinfo, which basically includes one more line in the coordinate system: `AUTHORITY["EPSG","3086"]]`
You need to wrap the second instantiation in its own assertRaises to actually test it.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
assertEquals is deprecated. Please use assertEqual instead.
I wouldn't include this test in the PR because it's testing existing behavior. But it doesn't seem needed as there's a test in `test_client_regress` that fails if the `isinstance(data, dict)` check is `_encode_json` is removed.
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
I'm not sure why we pass `data` and build a query string in tests views :thinking: I would simplify this: ```python def test_follow_307_and_308_no_get_preserves_query_string(self): methods = ('post', 'head', 'options', 'put', 'patch', 'delete', 'trace') codes = (307, 308) for method, code in itertools.product(methods, codes): with self.subTest(method=method, code=code): req_method = getattr(self.client, method) response = req_method('/redirect_query_%s/' % code, follow=True) self.assertRedirects(response, '/post_view/?hello=world', status_code=code) ``` and in `views.py`: ```python def method_saving_307_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=307) def method_saving_308_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=308) ``` Maybe I'm missing sth.
@lothemar I realized that previous assertions were correct. The current tests work even without this patch. I will restore them, sorry.
Sure, I will push those change, except the suggestion for `add()` gives invalid syntax.
I noticed that we use keyword-only arguments for `def set(self, objs, *, clear=False, through_defaults=None):` Do we want to so something similar for other methods: - `def add(self, *objs, *, through_defaults=None)`: - `def create(self, *, through_defaults=None, **kwargs):` - `def get_or_create(self, *, through_defaults=None, **kwargs):` - `def update_or_create(self, *, through_defaults=None, **kwargs):`
Oh. Strange. Not sure why that doesn't work. Thanks.
The style I prefer is ``` options = { 'include_parents': include_parents, .... } ``` It's somewhat of a pain to indent additional items if your editor doesn't do it automatically with the other style.
Just because you _can_ cram this all on one line, doesn't mean you have to. This would be a lot easier to read as: ``` field_list = tree[self] if self.proxy: field_list += tree[self.concrete_model._meta] for f in field_list: ... ```
On consideration, I'd take the first bit of that... ``` # Import the .autoreload module to trigger the registrations of signals. ``` (I'm reviewing now. I'll do it.)
That would be cleaner.
Sounds very sensible!
Can you move this above `...checks.urls` please? (Presumably we're skipping isort here to stop it putting these imports amongst the other _actual imports_ but they're alphabetical within that.)
Please change to single quote.
```suggestion week_choices = {'%W': '1', '%U': '0', '%V': '1'} ```
There is no need to use `assertQuerysetEqual`, I would compare list of instances, e.g.: ```python obj_1_iso_2015 = self.create_model(week_1_day_2014_2015, end_datetime) obj_2_iso_2015 = self.create_model(week_53_day_2015, end_datetime) ... self.assertSequenceEqual(qs, [obj_1_iso_2015, obj_2_iso_2015]) ```
```python raise ValueError( "ISO week directive '%s' is incompatible with the year " "directive '%s'. Use the ISO year '%%G' instead." % ( week_format, year_format, ) ) ```
```suggestion res = self.client.get('/dates/books/2008/week/40/iso_week_format/') ```
Use single quotes. Capitalized "unknown". Add "Choices are: ...".
Won't `symlink_path` and `original_path` be removed automatically as part of the cleanup? `tempfile.TemporaryDirectory` says "On completion of the context or destruction of the temporary directory object the newly created temporary directory and all its contents are removed from the filesystem."
Other tests use naming like: `test_json_agg_empty`
I think that this comprehension could be collapsed to a single line.
Again, not related but use `force_raster_creation=True` rather than a tough to decipher plain boolean.
Rather than passing all of `OPTIONS` here we should only pass the protocol: ```suggestion def __init__(self, protocol=None): self._protocol = pickle.HIGHEST_PROTOCOL if protocol is None else protocol def dumps(self, value): return pickle.dumps(value, self._protocol) ```
Please create a `_stream()` helper with this signature and use it so that the deprecated parameters don't appear in the `stream()` signature.
Please remove the deprecated parameters from `stream()`: context_instance, current_app, dirs, dictionary. Similarly for `stream_to_response()`.
It probably makes sense to remove the helper methods that are now used only once.
I think we can remove this sentence.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
```suggestion f'-X{key}' if value is True else f'-X{key}={value}' ```
`can not` -> `cannot`, or better `may not `
I believe `key` should also be coerced.
```suggestion # __spec__ may not exist, e.g. when running in a Conda env. ```
`"Script {} does not exist.".format(py_script)` -> `'Script %s does not exist.' % py_script`
Yes this would be a good idea
I think this should be instantiated by the runner, rather than a global instance. Otherwise multiple runs in the same process share state (imagine a script that calls `call_command('test')` in a loop).
Ah. It is because we are pre-populating `self.records` before the `yield` in the context manager. Changing to `defaultdict` means that the key only gets added after when the context manager is exiting and we do `self.records[name].append(end_time)`. This means that nested uses of `time_keeper.timed()` - as we do in the database setup -- end up being out of order.
```suggestion new_record = '%s took %.3fs' % (record, record_time) ```
It seems that the `timing` parameter is doing too much work. We're storing it in the runner, plus passing it down to the time keeper class, for it only to be used here. Q: why is it the time keeper's job to choose whether output is displayed by the runner? (A: it's not) I think two classes would be better than the conditional. `TimeKeeper` and `NullTimeKeeper`, then in the runner we don't store `timing` but just do: ``` self.time_keeper = TimeKeeper() if timing else NullTimeKeeper() ``` `NullTimeKeeper` should implement no-ops for `timed()`, `append()` and `results()` and just a single `yield` for the context manager.
```suggestion f'<li>Title: <input type="text" name="form-0-title"></li>' f'<li>Pub date: <input type="text" name="form-0-pub_date">' f'{delete_form}</li>' ```
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
I'd chop this docstring.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
I renamed the test and removed the docstring.
`assertTrue` would be appropriate here.
Never mind, just read the whole ticket :) Maybe the initial `assertIsInstance(p.restaurant.serves_pizza, bool)` would make more sense here. Else it might end up being refactored.
can we create the `ItalianRestaurant` and then get the related entites we need from that? I think that would be a bit nicer than `save_base(raw=True)`.
a single line for these queries should probably be okay
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
repetitive with method docstring
Thanks @ivorbosloper now it makes sense to me and works fine. I got confused with upper and lower bits wording. Interesting that bits are counted from right to left from that point of view, and that the mask operation works. It would not work the same way with the `BANDTYPE_FLAGS_MASK` as my example shows.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
comma after tuple
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
Same here, the unique constraint is only removed in the ORM but will still persist in the database.
This will require a migration, run `makemigrations` for the app.
I'm reminded of #21381 (removing contrib.redirects dependency on contrib.sites), but not sure that should block this.
preferred format is "#15346, #15573 - Issue description"
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
This change isn't right. `Derived.mro()` is ``` [Derived, DescendantOne, DescendantTwo, AbstractBaseOne, AbstractBaseTwo, django.db.models.base.Model, object, ] ``` The existing test is correct that `Derived` should inherit the `name` field from `DescendantTwo`. i.e. `max_length` should be 50.
Would it be worth emphasising that this straying from pythonic expectation is an _undesirable_ behaviour? In case `ModelBase.__new__()` were to get rewritten in future, and whoever works on it ends up thinking they need to be supporting these testcases? Orr just writing the testcase as an expected failure would imply this.
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
`test_target_field_may_be_pushed_down` works without the patch. I would move it to a separate commit to make it clear where the behavior has changed.
This collation doesn't work for me: ``` django.db.utils.ProgrammingError: collation "en_US" for encoding "UTF8" does not exist ``` I've changed to the `en-x-icu`.
```suggestion editor.remove_index(Scene, index) ```
single line looks okay here
single line looks okay here
IMO, this is not related with `index_xinfo` but with naive parsing in introspection on SQLite. I added `_get_index_columns_orders` to fix this issue.
`self.assertTrue` -> `self.assertIn` above and below as well.
This is fine as is.
This might either throw errors or block forever (dunno how field_stream is implemented) if field_stream is empty at this point. Not sure, but something to check!
This is fine as is.
What if the 'field_name' is huge? It seems to me that it still goes into memory.
Also, what if we have a huge number of very short 'name=value's? This will create a dictionary with lots of small strings -- again lots of memory.
why cast this into a list, normal brackets (generator) will do
I don't know if this is an overkill, but we could log the exception.
again, why not just return a generator
I would filter that first, via a generator. I think this might be more readable. ```python lists = (lst for lst in lists if lst) ``` or ```python lists = filter(None, lists) ```
You could do solve this recursively, but I don't know if this better readable really. meh
The benefit of the extra tests is they make the HTML structure clear, but the CSS selector perhaps does that... We should use hanging indent for the wrapping, so maybe pull the CSS selector into a variable, so it's easy read/see, and then the lines would be shorter too, and we can just have the two assertions.
This should go to the 2nd commit :gem:
```suggestion # Even the third inline should have the correct verbose_name ```
This should go to the 2nd commit :pick:
Unless there's a significant difference, a single RTL language seems fine... 🤔
`call_command()` raises an exception so these lines are unreachable.
We run `createsuperuser` in non-interactive mode so `@mock_inputs` is unnecessary.
This is risky, I would use (in all new tests): ```suggestion Group.objects.all().delete() nonexistent_group_id = 1 ```
This looks unnecessary.
Manager will raise a different `IntegrityError`, e.g. _"The row in table 'auth_tests_customuserwithfk' with primary key '1' has an invalid foreign key: auth_tests_customuserwithfk.group_id contains a value '-1' that does not have a corresponding value in auth_group.id."._
Don't think we need to worry about duplicates.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
If we remove this will the tests run on Jenkins? It might be fine.
As long as you use `except Exception` and not a bare `except` this should be good.
We shouldn't silently change passed parameters. IMO it better to raise an exception like we do now: ``` $ export DJANGO_SETTINGS_MODULE=test_oracle $ ./runtests.py queries --parallel=2 Testing against Django installed in '/django/django' with up to 2 processes Found 416 test(s). Creating test database for alias 'default'... Creating test user... Cloning test database for alias 'default'... Traceback (most recent call last): File "./runtests.py", line 659, in <module> failures = django_tests( File "./runtests.py", line 385, in django_tests failures = test_runner.run_tests(test_labels) File "/django/django/test/runner.py", line 881, in run_tests old_config = self.setup_databases( File "/django/django/test/runner.py", line 787, in setup_databases return _setup_databases( File "/django/django/test/utils.py", line 217, in setup_databases connection.creation.clone_test_db( File "/django/django/db/backends/base/creation.py", line 239, in clone_test_db self._clone_test_db(suffix, verbosity, keepdb) File "/django/django/db/backends/base/creation.py", line 255, in _clone_test_db raise NotImplementedError( NotImplementedError: The database backend doesn't support cloning databases. Disable the option to run tests in parallel processes. ```
Use `self.assertCountEqual()` when ordering is not specified and we have more than one expected result.
Hmm it's not clear to me what this test is trying to accomplish, what's the purpose of `CustomExactLookup` in the first place since it's `Exactly` that is registered.
I remember looking at this test when merging 233c70f0479beb3bff9027e6cff680882978fd4d. I just tested this now and if you use `with register_lookup(field, Exactly, lookup_name='exact'):`, then this is the state at the end of the test: ``` >>> Author._meta.get_field('birthdate').get_lookup('exact') <class 'custom_lookups.tests.Exactly'> ``` With the current code, the output is `<class 'django.db.models.lookups.Exact'>` which looks correct to me. So I'd leave this as is and remove the unused `CustomExactLookup`.
Please revert this unrelated cleanup and add: ``` CharField._unregister_lookup(TrigramStrictWordSimilar) TextField._unregister_lookup(TrigramStrictWordSimilar) ``` ``` CharField.register_lookup(TrigramStrictWordSimilar) TextField.register_lookup(TrigramStrictWordSimilar) ``` directly.
Can we test this with nested context processors to see that unregistering also works? e.g. ```python with register_lookup( models.CharField, CustomStartsWith, lookup_name="start") ): with register_lookup(Company.place.field, StartsWith4Char, lookup_name="start"): self.assertCountEqual( Company.objects.filter(place__start="f"), [self.obj1, self.obj3], ) self.assertCountEqual( Company.objects.filter(name__start="a"), [self.obj1, self.obj2, self.obj4], ) self.assertCountEqual( Company.objects.filter(place__start="f"), [self.obj1, self.obj3, self.obj4], ) ```
I simplified this test with `@mock_inputs()`.
``` @mock.patch('django.contrib.contenttypes.management.update_contenttypes') def test_remove_contenttypes(self, mocked_update_func): management.remove_contenttypes(self.app_config.name) self.assertEqual(mocked_update_func.call_count, 1) ```
This also can be simplify: ```python call_command( 'createsuperuser', interactive=False, username='test_superuser', email='joe@somewhere.org', stdout=StringIO(), ) user = User.objects.get(username='test_superuser') self.assertEqual(user.email, 'joe@somewhere.org') self.assertFalse(user.has_usable_password()) ```
This can be single-lined.
Chop blank line.
This can be outside of `try..`.
I'd revert this reformatting to make diff smaller: ```suggestion if code.co_argcount == 2: # one argument is 'self' return attr(obj) else: return attr() ```
I'm not sure if it's correct. What about static methods that have no args: ```python @staticmethod def item_description(): return "Overridden item description" ```
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
double -> single quotes
By the way, [looking up `SpatialOperator`'s implementation](https://github.com/django/django/blob/31a2af1c0101081a3950dab0e66fa41bbbf6d34f/django/contrib/gis/db/backends/utils.py#L7-L27) I think you could probably go away by simply overriding `default_template` instead. ```python class SpatialiteNullCheckOperator(SpatialOperator): @property def default_template(self): return '%s > 0' % super().default_template ```
Add an exception message similar to the other methods.
I'm in the habit of including an trailing , for all QuerySet filter kwargs.
Keep the `update()` syntax (like below).
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
We can add a control assertion to confirm that a `house` is cached for the `room`: ```suggestion self.assertIs(Room.house.is_cached(self.room), True) with self.assertNumQueries(0): ```
I think verifying the results wouldn't hurt, e.g. `self.assertSequenceEqual(groups2.filter(id__gte=0), [g])`
Perhaps I misunderstood Anssi's original intent somehow, but the fact that your filter expression uses INNER joins seems like you're maintaining the status quo at the minimum. @charettes I've just pinged you on IRC but if you've got some thoughts on this I'd like to hear them.
In cases like this, we prefer to include a trailing comma so if more items are later added, we don't need to modify this line again.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
return directly, no need for `path` variable.
I would use `%s` formatting consistently.
```suggestion # Windows registry may not be configured with correct # mimetypes. ```
```suggestion self.assertEqual(value, b'text/plain') ```
This isn't Django's default charset (unless I'm mistaken).
This is the default charset in Django, I wouldn't call it unusual :)
Can you include latin-1, non-ASCII characters? `café` is one of the few English words matching this requirement. `Just latin-1 :)` will encode identically in ASCII, latin-1 and utf-8, making the tests much less interesting.
I don't see a reason for modifying a source exception, you can use: ```python raise ValueError(...) from e ``` Also `blew up` is not a appropriate wording and a new exception is not more informative because it refers to the field class `... the field <django.db.models.fields.CharField>` instead of `<app_label>.<model_name>.<field_name>`, maybe: ```python raise ValueError('Error during %s serializing: %s' % (field, e)) from e ``` I don't have a quick answer how to get a field path.
Thanks for updates :+1: > ... but I had trouble getting the field name, any ideas on that one? Unfortunately not, moreover I'm afraid that we will not be able to get `<app label>.<model name>.<field name>` or even `<app label>.<model name>` in a reliable way. We serialize `field` from `django.db.models` not a model attribute, that's why it's complicated or even not feasible. Each approach doesn't work in some cases, e.g. constructing messages in the `FunctionTypeSerializer` will not work for `lambda`s defined in the module: ``` Error during serializing test_one.models.<lambda>: ... ``` or imported from other modules: ``` ValueError: Error during serializing test_one.utils.<lambda>: ... ``` I think we should close this as wontfix :disappointed:
This check is also redundant.
Wouldn't be required if you subclasses `IntegerField`.
Oh, no, OK, the nextval will always return a different value. It's just that we might have gaps if one value is not saved.
This conditional is not required anymore given the check above.
`ExpressionList.__repr__()` can be removed because `Func.__repr__()` works in the same way.
dunder dun dunnnnn
How about this ```python def __str__(self): return self.arg_joiner.join(str(arg) for arg in self.source_expressions) ``` I don't see a need for a `.format()` call.
Please check test coverage carefully. I didn't spot a test for this change.
how about `_resolve_special` -> `resolve_error_handler()`. I don't see a need for separate methods like `resolve4XX` and `resolve5XX`, especially when you pass any status code to either and achieve the same result.
I would prefer to omit it for now.
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
I think `get_exception_response` would be a better name for the method.
My mistake on 500, but "NOT FOUND" is different from "Not Found"
"Both Y and X must be provided". Switch the Y and X in the error.
I think this should be a `ValueError`
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
I see, thanks for your answer. I really don't want to hold the template based widget stuff from landing any longer. I suppose this is something we could refactor later on.
I think a simple `django.template.Context` will do here.
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
put the closing parenthesis on the next line
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
~~Are you sure the `Value` wrapping and the `output_field` are necessary here? As long as you pass an `output_field=models.BooleanField()` to `Case.__init__` you should be good to go.`~~ _Edit: Well it looks like passing `output_field=models.BooleanField()` to `Case.__init__` doesn't work yet._
FWIW `Q(Exists(is_ceo)) | Q(Exists(is_poc))` already works and `Exists(is_ceo) | Exists(is_poc)` doesn't require much changes. ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 5b82ae97a7..d18de75e9a 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -101,6 +101,8 @@ class Combinable: return self._combine(other, self.BITRIGHTSHIFT, False) def __or__(self, other): + if getattr(self, 'conditional', False) and getattr(other, 'conditional', False): + return Q(self) | Q(other) raise NotImplementedError( "Use .bitand() and .bitor() for bitwise logical operations." ) diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py index 6c00f813d9..d3d75f1ce1 100644 --- a/tests/expressions/tests.py +++ b/tests/expressions/tests.py @@ -595,11 +595,9 @@ class BasicExpressionsTests(TestCase): def test_case_valid_in_filter_if_boolean_output_field(self): is_ceo = Company.objects.filter(ceo=OuterRef('pk')) is_poc = Company.objects.filter(point_of_contact=OuterRef('pk')) - outer_1 = Employee.objects.filter(Case( - When(Exists(is_ceo), then=Value(True)), - When(Exists(is_poc), then=Value(True)), - default=Value(False, output_field=models.BooleanField()) - )) + outer_1 = Employee.objects.filter( + Exists(is_ceo) | Exists(is_poc) + ) self.assertQuerysetEqual( outer_1, ['<Employee: Joe Smith>', '<Employee: Frank Meyer>', '<Employee: Max Mustermann>'], ```
Is there a reason to use `len()` instead of checking the objects? `len()` may take more effort to debug in the event of a failure.
I should have been clearer but `firstname` and `lastname` can be omited as they'll default to `''` if missing.
You can use `self.assertRaisesMessage(ValueError, 'error string')` rather than inspecting the exception args.
Use literals rather than functions, i.e. `{}` not `dict()`. This should come at the top of the function as the stuff before it does not need to happen if it is empty.
Please add a trailing comma to this line.
Use literals please - `[]` for `list()` and `{}` for `dict()`. Also, something like `result` would be a better name than `return_dict`.
This is fine as-is. It is well known that iterating over a dictionary iterates over the keys. Also this is explicitly returning a `list` and not an iterator (as is the case with Python 3). Try out `type({}.keys())` to see the difference.
huh, TIL. Transitioning to Python3 from 2.7 for my personal projects and I didn't know they had changed that. Thanks for pointing it out.
Moving this line is not related with a bugfix. Please revert it and add ```python if check_filterable: ... ``` in both places.
`if not getattr(reffed_expression, 'filterable', True):` Although you should probably be able to just check filterable. If non-resolved F expressions get here, consider adding the filterable attribute onto the F expression class so that you can assume it's always available.
It's only in two places and I don't think it cleans up that much, you'd just end up with `if isinstance(filter_expr, Expression) and filter_expr.is_output_field_boolean():` which is slightly less explicit and slightly slower
Do you think we should build the "is this a boolean field" logic as a method within the expression? It'd hide the mess a bit.
The check should be inside prepare_lookup_value, not in build_filter.
I think this change really indicates the need for a second test for wrapping a non-string object.
Move those import to the top of the file.
I'm not sure the docstring adds any value here.
Are all the `six.text_type` needed? Tests seem to be passing with at least the first one removed. Shouldn't there be tests with lazy versions of args, kwargs? It looks like these tests are mainly testing `str.format()`.
Removed in ea8e7fd989095c1444528c8b9808076985d5ea0a, thanks.
We could rename `CSRF_COOKIE_NAME` as `CSRF_ENTRY_NAME` or `CSRF_ENTRY_KEY`, and then using it as cookie name if we're cookie based and session key if we're session based. This would be an improvement over the current code, but probably not over separate settings.
I think the session cookie should be independently configurable. Technically there's no reason we'd need two settings, it would be possible to just have `CSRF_SESSION_KEY`, and use it both as the session key and the trigger to use sessions at all (if it's not set, we don't). Not sure if that's actually better than just having two settings.
Not sure we want to use `settings.CSRF_COOKIE_NAME` for this. What about `CSRF_SESSION_KEY = '_csrf_token'` just like we do with `LANGUAGE_SESSION_KEY`.
Assuming we use something other than `CSRF_COOKIE_NAME` as the session key, `"CSRF_COOKIE"` seems like an odd key into `request.META`.
Looking at the code changes below in the middleware, I also see no clear reason for not returning a new token here to stay a little bit more compatible to with what we had before.
As far as I'm aware `unique_fields` should be required when `supports_update_conflicts_with_target` is `True`, so there is no need to use `unique_fields or ()`. Moreover, we should raise an exception when it's not provided.
This method implementation could be simplified by doing: ```python if on_conflicts == ON_CONFLICTS_IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflicts == ON_CONFLICTS_UPDATE: ... return result ... ``` This would also let you eliminate the `if-else` below and initializing `result` to `''`.
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
A list comprehension is preferable here as `str.join()` converts to list internally anyway. ```suggestion ', '.join([ f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields) ]), ```
Spaces around `=` and PostgreSQL docs have `EXCLUDED`. ```suggestion ', '.join(f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields or ())), ```
Please revert these unrelated whitespace changes.
please use this style: ``` post = models.ForeignKey( Post, ..., ) ```
Unnecessary -> ```suggestion def __str__(self): ```
Do we need to change `related_name` here? We could add `note` with `related_name='owner'` instead.
It'd be great we if we could avoid creating 5 new tables to reproduce the issue. Existing ones should be reusable somehow.
Our convention is to include a trailing comma in places like this so if more items to the list later, we don't have to modify this line again.
reword: "force_login() skips authentication backends without a get_user() method."
Unless I'm missing the purpose of the rest of the test, it seems sufficient to replace from here down with `self.assertEqual(self.u1.backend, 'django.contrib.auth.backends.ModelBackend')`.
prefer `setUpTestData` since that executes once per test class instead of once for every method
is this meant to test the `except TypeError` branch in `contrib.auth.authenticate()`? It would be clearer to call that function directly.
omitting the ellipsis seems okay to me. Do we need to include 'id__max' twice, e.g. `Cannot compute Max(): 'id__max' is an aggregate`
Generally we don't include the ticket numbers unless the issue is an obscure one that benefits from additional context that the ticket provides. If so "Sentence.... (#19513, #18580)." is the usual format
Ah! Of course, sorry I missed that.
Shouldn't be part of this PR, but it looks like redundancy in `__repr__()` methods would be a good candidate for a refactor.
Passing `filter` to kwarg will cause it to be in `self.extra` as well which could interfere `as_sql()` formatting.
I think it would be helpful if this were instead named `invalid_token_re`. The reason is that I coincidentally happened to be reading `csrf.py` and was confused by these lines: https://github.com/django/django/blob/b746596f5f0e1fcac791b0f7c8bfc3d69dfef2ff/django/middleware/csrf.py#L111-L112 The reason this was confusing is that this isn't a regex that matches tokens. It matches invalid tokens. And then I saw this was changed in this PR only a few days ago.
Good catch :dart: , I missed this :facepalm:. Please feel-free to send a patch
Grrr... I think I probably preferred the `if PY38` version then. (Let me confer with Mariusz.)
📖 I think we could add a docstring to this explaining why `__init__` was overridden. This and `CaseInsensitiveMapping.__init__` looks pretty similar
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
I'd drop the intermediate variable
```suggestion path = '%s/' % request.path ``` :thinking:
IMHO, it's clearer if you use: ``` python if not prefixed_default_language and language == settings.LANGUAGE_CODE: language_path = '/%s' % (request.path_info) else: language_path = '/%s%s' % (language, request.path_info) ```
The URL may be incorrectly encoded....
immediatelly -> immediately
I don't think it's worth having two options here. I understand that the Django version is less likely to change but my point is that for the rare cases where the header content causes issues (you have to admit your setup is uncommon) one can do without a complete header. Adding two options only makes the code more complex for little benefits.
It feels like having non-negated arguments defaulting to `True` would be more appropriate ```python include_header=True ```
`self.include_header` once the double negation logic is handled by `argparse`.
We don't often use the `msg` param with `subTest()`. Maybe: `"Migration file includes header: %s." % include_header` or just: `include_header=include_header`
Can you reference the ticket number in the docstring, please.
If initial_forms=3 and min_num=4 and extra=3 I'd expect total_forms to be 6 and not 7 EDIT:// oh, I see below that this would probably be a change in backwards compat; in that case never mind ;)
`assertEquals()` is deprecated, please don't use it.
I'm not sure if this assertions have value.
This used to be in an `else` clause, now it is not. Meaning that calling `self._extract_initial_form_count()` was pointless, because it will be overridden anyway.
Could switch to single quotes as long as this is being modified.
Please update your patch.
I would call `clean()` in validation tests, we should also move it to a separate tests, e.g. ```python def test_invalid_value(self): field = models.DecimalField(max_digits=4, decimal_places=2) msg = '“%s” value must be a decimal number.' tests = [ (), [], {}, set(), object(), complex(), 'non-numeric string', b'non-numeric byte-string', ] for value in tests: with self.subTest(value): with self.assertRaisesMessage(ValidationError, msg % (value,)): field.clean(value, None) ```
I'd probably use `if six.PY2` here, so we remember to remove this branch when we drop Python 2 compatability
Chop blank line.
This line and `os.mkdir(bad_target)` are unnecessary, we don't need to create directories for this test.
Perhaps a nice alternative is: ``` result = json.loads(Question.answer_set.field.value_to_string(question)) self.assertCountEqual(result, [answer1.pk, answer2.pk]) ```
I don't think you can assume ordering here.
``` @mock.patch('django.contrib.contenttypes.management.update_contenttypes') def test_remove_contenttypes(self, mocked_update_func): management.remove_contenttypes(self.app_config.name) self.assertEqual(mocked_update_func.call_count, 1) ```
assertEqual -- the version with "s" is a deprecated alias.
Need to test how many times `update_contenttypes` was called and test arguments which passed to it.
The second set of single quotes look odd to me.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
This should be `models.E028` as `E020` maps to ``The `<model>.check()` class method is currently overridden.``.
I feel like `obj` should be `db_table` here, `model` is a reference to the last value of the `for model in models` loop above and is completely unrelated.
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
I'd order the test with the other `check_html()` tests (above `test_use_required_attribute`).
The expected value should be a second argument in `assertEqual()` and `assertHTMLEqual()` assertions.
Maybe: ```suggestion template_name_label = 'forms_tests/cyclic_context_boundfield_render.html' ```
```suggestion form.render(), '<div><label for="id_field">Field:</label>' '<input id="id_field" name="field" required type="checkbox"></div>', ```
```suggestion form.render(), '<div><fieldset><legend>Field:</legend><div id="id_field">' '<div><label for="id_field_0"><input type="checkbox" ' 'name="field" value="J" id="id_field_0"> John</label></div>' '<div><label for="id_field_1"><input type="checkbox" ' 'name="field" value="P" id="id_field_1">Paul</label></div>' '<div><label for="id_field_2"><input type="checkbox" ' 'name="field" value="G" id="id_field_2"> George</label></div>' '<div><label for="id_field_3"><input type="checkbox" ' 'name="field" value="R" id="id_field_3">' "Ringo</label></div></div></fieldset></div>", ```
We should also test for `events = Event.objects.filter(group__in=groups.query)` to test both `isinstance(self.rhs, QuerySet)` branches.
Where in the process of replacing these constructs with `self.assertSequenceEqual`, see #7226.
Just state the expected behavior such as "Pickling a QuerySet with an `__in=inner_qs` lookup, shouldn't evaluate inner_qs." We're reserving ticket references for obscure issues that can't be easily described in docstrings (the above tests aren't a good example, unfortunately).
Chop blank line.
I think this test would be fine without the blank lines, it's fairly short.
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
> Is there any specific reason why we would prefer using the operation in this case? Yes, because we have it. Using a RAW SQL is the last option, we're developing the ORM in order not to use them.
IMO it's enough to test that `CreateExtension` honor `allow_migrate()`, creating extension is already tested in `postgres_tests`.
I think we usually avoid _should_ wording in test docstrings.
This should likely be `'%s_validate_%s'`
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
We can remove `bases` from all `migrations.CreateModel()`.
I'm reminded of #21381 (removing contrib.redirects dependency on contrib.sites), but not sure that should block this.
```suggestion # Validate app_label. ```
removing unnecessary multilines like this will make it nicer.
Use hanging indent: ``` python RangesModel.objects.create( ints=None, dates=(cls.dates[0], cls.dates[3]), timestamps=(cls.timestamps[0], cls.timestamps[3])) ) ```
Is the first element here meant to be a 1-tuple? You're missing the required comma.
You can drop this assertion, the way `from_date` is constructed and that this branch is behind the `if day` one makes it impossible to reach.
Ah, sorry. Misread these. One gets the quarter number, the other gets the first month of the quarter. Ignore me.
This could be simplified to match the implementation in `_sqlite_datetime_extract()`: ```suggestion month_in_quarter = ceil(dt.month / 3) ```
Do we need this mapping? We could redirect to a `HttpResponse` with the `status_code`, e.g. `HttpResponse(status_code=r.redirect_type)`.
Please rewrite `@override_settings` into a single line: ```python @override_settings(STATICFILES_DIRS="a string") ```
Since most of the logic related to field referencing will be used by `django.db.migration.state` I think it would make sense to fold/merge `django.db.migrations.operations.utils` into `django.db.migrations.utils`.
Might be worth moving theses utils to `django.db.migrations.utils` instead since they are used outside of `.operations` now.
please alphabetize with the rest of the django imports
`hasattr` is a more idiomatic approach to this (also saves a couple lines of code), unless there is a specific reason for using an object like this.
> Although... _Does_ TextInput support datetimes? Yes, with TextInput, the date is serialized like this: 2014-05-09 14:08:21.805873 and you can manually edit any part, including microseconds.
I think that `ValidationError` is only raised out of `Field.to_python()`, not `Widget.value_from_datadict()`, so this can be simplified: ```suggestion widget = field.hidden_widget() value = self.form._widget_data_value(widget, self.html_initial_name) try: initial_value = field.to_python(value) ```
This used to be in an `else` clause, now it is not. Meaning that calling `self._extract_initial_form_count()` was pointless, because it will be overridden anyway.
while touching this line, could you replace w/ -> with
chop blank line
I envisioned something like this: ``` python content = None with open(path, read_mode) as f: try: content = f.read() except UnicodeDecodeError: # If mimetype suggests the file is text but it's actually binary, # read() will raise a UnicodeDecodeError on Python 3. pass # If the previous read in text mode failed, try binary mode. if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE ```
I think this line isn't needed, tests seem to work fine without it.
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
chop blank lines
No as `User` and `Person` are registered to the global `apps` instance. The creation of the class is supposed to fail anyway so the `apps` cache won't get polluted.
I could be missing something, but I don't see a need for the function. ``` msg = "Proxy model 'MultipleAbstract' has more than one non-abstract model base class." with self.assertRaisesMessage(TypeError, msg): class MultipleAbstract(User, Person): class Meta: proxy = True ``` should be okay, I think? If so, we can make a separate commit to clean up the existing tests (and make them use `assertRaisesMessage` instead of just `assertRaises` too.
Heh. This line was an `assertRaisesMessage` before, I recommended that it be changed to assertRaises to make the test less prone to break on trivial code changes. The message's content is essentially just "Not supported" anyway, so I think we should leave it this way.
I would test for the complete error message.
Assuming you use `NotSupportedError`, I think checking for the exception class is enough and is more robust.
```suggestion 'ignore_conflicts and update_conflicts are mutually exclusive' ```
You can move the line above to an `else` clause below.
Was already highlighted [here](https://github.com/django/django/pull/13065#discussion_r684521409) but was missed.
We try to avoid accessing the database connections when not necessary, so I'd move `db_features`: ```suggestion if ignore_conflicts and update_conflicts: raise ValueError( 'ignore_conflicts and update_conflicts are mutually exclusive.' ) db_features = connections[self.db].features ```
```suggestion def _select_on_conflict(self, ignore_conflicts, update_conflicts, update_fields, unique_fields): ```
There is no need to define `Error` in the module. I would move it to the check.
I thinking removing APP_DIRS from TEMPLATES (since it defaults to False) is a better suggestion than setting it to False.
We thought that for some unexpected non-string data types if may be better to return their representation. I think it is not necessary.
Good point :+1: @pope1ni All tests pass with `{}` instead of `{!r}`, so I think we can simplify messages and use `{}`.
.get() falls back to None to `False` isn't really needed I think.
I moved this check to the `DurationExpression`.
This is not covered by tests, also raising an exceptions in user-defined functions is not really helpful for users: ```python django.db.utils.OperationalError: user-defined function raised exception ``` I think we should return `None` instead.
I would add a separate hook for this (in a separate commit), e.g. ```python def _sqlite_prepare_dtdelta_param(conn, param): if conn in ['+', '-']: if isinstance(param, int): return datetime.timedelta(0, 0, param) else: return backend_utils.typecast_timestamp(param) if conn in ['*', '/'] and not isinstance(param, (int, float)): raise TypeError return param @none_guard def _sqlite_format_dtdelta(conn, lhs, rhs): """ LHS and RHS can be either: - An integer number of microseconds - A string representing a datetime - A scalar factor (e.g. float) """ conn = conn.strip() try: real_lhs = _sqlite_prepare_dtdelta_param(conn, lhs) real_rhs = _sqlite_prepare_dtdelta_param(conn, rhs) if conn == '+': # typecast_timestamp returns a date or a datetime without timezone. # It will be formatted as "%Y-%m-%d" or "%Y-%m-%d %H:%M:%S[.%f]" out = str(real_lhs + real_rhs) elif conn == '-': out = str(real_lhs - real_rhs) elif conn == '*': out = int(real_lhs * real_rhs) else: out = int(real_lhs / real_rhs) except (ValueError, TypeError): return None else: return out ```
Annoying that `datetime.time` cannot be subtracted from each other to give a `datetime.timedelta`, so we cannot use `duration_microseconds()` as in `_sqlite_timestamp_diff()` below.
I don't think we need the `re_` prefix to the arguments? And perhaps `text` instead of `string` for consistency? We should also avoid coercing to `str` unless we need to: ```python In [1]: text = "This is some text" In [2]: %timeit str(text) 54.7 ns ± 4.28 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) In [3]: %timeit isinstance(text, str) 33.8 ns ± 0.106 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) ``` It might make the non-`str` case slower, but, unless I'm mistaken, we're expecting `text` to be `str` in the majority of cases. ```suggestion def _sqlite_regexp(pattern, text): if pattern is None or text is None: return None if not isinstance(text, str): text = str(text) return bool(re_search(pattern, text)) ``` As an aside, I wonder whether we can do something to compile and cache patterns? This could make a significant difference if the function is called for a large number of rows.
I think we want to avoid altering `self.extra` here and pass `db_type` as a kwag to `super().as_sql()`.
It looks like we usually uppercase the function name (e.g. `CAST({} as {})`).
Is this check correct? A `Coalesce` can still result in a null value (if all of its arguments are null), so even if the expression is already a `Coalesce` ISTM it needs to be wrapped again (or have `Value('')` added to the end of its `source_expressions`, but just wrapping in another `Coalesce` seems cleaner).
Ah! Of course, sorry I missed that.
Won't this result in a confusing SQL-level error if you pass in `None` for `expression` or `pos` by accident? I'm assuming `length` is the only one we actually expect to possibly be `None`. If that's true, I think it would be better to do something like: ``` expressions = [expression, pos] if length is not None: expressions.append(length) ``` Or, if you prefer: `expressions = (expression, pos, length) if length is not None else (expression, pos)`
has very high precision so we can test this on...
minor improvement ```suggestion now = datetime.now() a = DBArticle.objects.create() ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
`).order_by('name')` on next line
```suggestion now = datetime.utcnow() a = DBArticle.objects.create() ```
`TRADITIONAl` → `TRADITIONAL` (You let go of your shift key too early!) Perhaps reword to `# Add TEXT as an alias of TRADITIONAL for consistency with other backends.`
Please position this up near `has_native_uuid_field` and `has_native_duration_field`. You also need to add `has_native_serial_field = False` to `django/db/backends/base/features.py`.
This test fails: `(1235, "This version of MySQL doesn't yet support 'FORMAT=JSON with EXPLAIN ANALYZE'")`.
I think this line isn't needed, tests seem to work fine without it.
Trailing space in string not required.
The issue here is that we can't do the proper permission check (`if not self.has_perm(request) ...`) until after we've assigned `self.model_admin`, which we return from this method. _Maybe_ it's OK. But… it seems like we have the exact kind of _"Folks can probe the autocomplete view to find out the structure of the application"_ issue that we spend a lot of time thinking about and trying to avoid. If we just raise `PermissionDenied` for all of these cases we don't leak any info. Such exceptions are logged and a developer can use that to debug. Given that this is an ajax view, they're not going to see the debug output page anyway (without taking steps). I'm not convinced the different status code is worth the additional exposure (or even the effort justifying why it's OK). > 🤷 Yes. 🙂
"Django" doesn't add much: ```suggestion # Retrieve objects from parameters. ```
Hey @codingjoe — so I think I would restructure this section slightly, through to line 59. * I'd create a method to configure three attributes on self: `source_field`, `model_admin`, and `to_field_name`. It'd need to take the `request`. In there I'd include all the `try:except:` blocks and raise an `AutoCompleteSetupError` (or similar) if any of them occur. * Outside that method I would have a single `try:except:` to log the error, and return the JSON 403 response. (I'm thinking about how I'd debug this if there's no logging, and all I have to go on is a 403...) I think we should also move the `has_perm() -> 403` check **above** the `get_search_fields() -> 404`. (That last if nicely informative for users but we shouldn't hand out that info to someone without the permissions to access the modeladmin at all… 🤔)
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
@MarkusH Such a request should not change any state, so it should be `GET`. Using `POST` and `CSRF` wouldn't help against DoS there anyways (unless I miss something). If you are worried about querying the database, you can do the same with a normal request to the list views in the admin…
Should be ``self.weight``
This should be: ``params = config_params + params``
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
I would prefer to wrap value with `Value()` and compile `options` separately.
`copy()` in unnecessary.
Might be worth moving theses utils to `django.db.migrations.utils` instead since they are used outside of `.operations` now.
Since most of the logic related to field referencing will be used by `django.db.migration.state` I think it would make sense to fold/merge `django.db.migrations.operations.utils` into `django.db.migrations.utils`.
I can't make a meaningful difference between this name and the other `is_in_memory_db` method. Do you intentionally name the methods differently? Should we make it a `@staticmethod` since `self` isn't used? Prefer single quotes for the strings.
built-in imports like unittest should go above django imports, separate by a newline. e.g. ``` from __future__ import unicode_literals import unittest from django ... ```
chop blank line
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
Use outer double quotes to avoid backslashes.
I suggest you skip the check (`return []` early) if the intermediary model (`self.remote_field.through`) is not resolved. That is `isinstance(self.remote_field.through, six.string_types)`. Also I would store `m2m_db_table` in a variable as you'll need to reuse it to lookup `registered_tables` below.
You should use `self.m2m_db_table` instead of `self.db_table`.
Could you please follow the previous indentation style :)
A bit unrelated, but I would move the closing parenthesis to improve readability: ``` statement.parts['extra'] = ' WITH (pages_per_range={})'.format( schema_editor.quote_value(self.pages_per_range) ) + statement.parts['extra'] ```
`remove_index()` accepts `concurrently`, moreover `self.allow_migrate_model()` check `self.allow_migrate_model()` check is missing, IMO we should use ```python if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.remove_index(model, self.index, concurrently=True) ```
Add trailing comma.
```python hanging = ( indentation, has, a, newline, after, opening, bracket, ) ```
This won't work when `empty_aggregate_value` is `NotImplemented`.
I thought `empty_result_set_value` was meant to be a literal or whatever you'd pass to `Value` ```suggestion empty_result_set_value = value = getattr(arg, 'empty_result_set_value', NotImplemented) if empty_result_set_value is NotImplemented: raise arg_sql, arg_params = '%s', (empty_result_set_value,) ``` Or alternatively ```suggestion empty_result_set_value = getattr(arg, 'empty_result_set_value', NotImplemented), () if empty_result_set_value is NotImplemented: raise arg_sql, arg_params = compiler.compile(Value(empty_result_set_value)) ``` Which allows for better placeholder and `NULL` interoperability on Oracle which might have been the reason `Query.empty_result_set_value = 'NULL'` instead of `None` https://github.com/django/django/blob/06f5c22ea5907295f2360dc83e17b89aa84ae2fe/django/db/models/expressions.py#L754-L770
After looking at #6271, I think I'm seeing the use case for subclasses of `Func`.
I think it would make sense.
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
I'd use a more descriptive name like `test_logout_doesnt_cache`.
I'd suggest to check `response.context[REDIRECT_FIELD_NAME]` instead.
there's no need to "cleanup" by logging out as each test creates a new test client
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
Actually you should use `assertNotContains(response, '"/test_admin/admin/r/%s/1/"' % content_type_pk)` to also account for `byte` response content on py3.
IMO it's enough to test that `CreateExtension` honor `allow_migrate()`, creating extension is already tested in `postgres_tests`.
> Is there any specific reason why we would prefer using the operation in this case? Yes, because we have it. Using a RAW SQL is the last option, we're developing the ORM in order not to use them.
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
Good catch, I will remove it before final squash.
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
Quote from [PEP-257](https://www.python.org/dev/peps/pep-0257/): > The docstring is a phrase ending in a period. It prescribes the function or method's effect as a command ("Do this", "Return that"), not as a description; e.g. don't write "Returns the pathname ...".
"tuple: (set of model classes, set of app_configs)"
no comma needed
`CommandError` -> CommandError (no markup)
`always_text` is gone.
This can be single-lined.
I don't think that this test is required.
This also can be simplify: ```python call_command( 'createsuperuser', interactive=False, username='test_superuser', email='joe@somewhere.org', stdout=StringIO(), ) user = User.objects.get(username='test_superuser') self.assertEqual(user.email, 'joe@somewhere.org') self.assertFalse(user.has_usable_password()) ```
``` # Environment variables are ignored in non-interactive mode, if provided. ```
Ahh, I see! Thank you for the quick reply! Learning a lot from these PRs! :)
Okay, I'll drop that point, however, it seems odd to me to reject an empty scheme even if someone specifies `schemes=['']` (which seems unlikely anyway). I don't know that rejecting this case is important.
What's the relevance of this test for ssh://? It seems to already pass before this commit.
Chop blank line.
I think we should include `*args, **kwargs` and pass them to the super `__init__`
Like so: ``` EXCLUDE_FROM_PACKAGES = ['django.conf.project_template', 'django.conf.app_template', 'django.bin'] ```
You're calling `model_name.lower()` twice in most cases
Yes, this should be taken care of before.
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
The same amount of caching would be happening in the approach I'm suggesting. It's just that you would be calling `self.resolve_fields_and_relations() / self.all_relations = ...` (e.g. in a method) instead of accessing a cached property. It just seems like the usage in the PR doesn't really match `@cached_property`'s use case. In addition to what I mentioned above, the calls to `self.all_relations` in the PR aren't using the return value, it's just doing that for the caching side effect, which you could do more simply / explicitly.
> Would that be fine? Or is there something I am missing? `else` is not necessary, there is no need to resolve relations at this point.
Reading below, I see that Flask has an "any" converter that does something more complicated. Creating a converter with the same name but a different behavior doesn't sound good.
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
(same pattern as above, if you change it)
Use single quotes consistently.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
Yes, we'd need a separate test for check registration. Possibly https://github.com/django/django/pull/7781 will come up with a template to use.
I think this line isn't needed, tests seem to work fine without it.
This should be `WXXX` instead of `EXXX` since it's a Warning, not an Error.
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
These lines should be removed; it's possible for `databases` to be an empty list during tests and when no `--database` is passed to `manage.py` check as you've mentioned. When this happens this check should be entirely skipped.
Sorry about that, I was looking at the imports and forgot they are subclassed in that same file.
```suggestion return "<%s vendor='%s' alias='%s'>" % ( ```
This can cause credential leaks on crash :fire: , e.g. in Sentry. I would leave only `alias` and `vendor`.
you can collapse, `with self.assertRaises(Exception), connection.cursor() as cursor:`, and in a few places below.
You don't need to wrap a connection, you should be able to use `CaptureQueriesContext()` with `commit()` and `rollback()` and test captured queries.
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
`print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-'))`
IMO `else`is unnecessary i.e. ```python if '.' in opt_val: ... setattr(options, opt_name, os.path.normpath(opt_val)) ```
@hramezani I think you removed `setattr(options, opt_name, os.path.normpath(opt_val))` by mistake. My proposition was to remove only `else`, i.e. ```python if '.' in opt_val: print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-')) sys.exit(1) setattr(options, opt_name, os.path.normpath(opt_val)) ```
Please add trailing comma.
We should support `--shuffle` with `--bisect` and `--pair`, i.e. handle it in `get_subprocess_args()`.
I think we can avoid creating a temporary var here ```suggestion self.defaults.update(self._transform_headers(headers) ```
What about using keyword-only args? ```python def __init__(self, *, json_encoder=DjangoJSONEncoder, **defaults): ```
Same as above use keyword-only args ```python def __init__(self, enforce_csrf_checks=False, *, json_encoder=DjangoJSONEncoder, **defaults): ```
The kwarg name should probably be more generic given this will surface _middleware_ exceptions as well.
I like it!
Including falsy is a user's mistake and we don't remove them from the source lists, so I think we shouldn't change this.
@felixxm I was thinking about only specifying `css` OR `js` – the default values are empty datastructures which are falsy as well. There's no point in iterating through `_js_lists` or `_css_lists` to find whether an empty datastructure already exists in there. But it's probably a pointless microoptimization.
This isn't quite right. Now the lists in `combined` are assigned to those in `self` by reference. That means that the lists in `self` will also be modified. We can also avoid the unnecessary tuple construction. ```suggestion combined._css_lists = self._css_lists[:] combined._js_lists = self._js_lists[:] ``` I'm not sure how this extra copying will affect performance.
~Is this only required for the specifics of the test cases, or is it required to satisfy the merging and sorting in `Media` itself? If the former, all well and good, if the latter, would that need to be part of the `Paths as objects` interface contract?~ Oh I guess it's the `and be hashable` part already. My bad, ignore!
You are also filtering empty lists in your merge method. That double trouble, isn't it ;)
I don't see much value in this check.
I would rather create a custom model with field that has `db_column`, e.g. ```python project_state = self.apply_operations('test_rfwdbc', ProjectState(), operations=[ migrations.CreateModel('Pony', fields=[ ('id', models.AutoField(primary_key=True)), ('field', models.IntegerField(db_column='db_field')), ]), ]) operation = migrations.RenameField('Pony', 'field', 'renamed_field') new_state = project_state.clone() operation.state_forwards('test_rfwdbc', new_state) ```
This docstring is unnecessary.
Trailing comma: ```suggestion migrations.RunPython.noop, ```
should be `first_state`, not `project_state`, I suspect.
This changes such behavior: ``` In [18]: RandomUUID(1, output_field=None) --------------------------------------------------------------------------- TypeError Traceback (most recent call last) <ipython-input-18-7594cbdb3c8e> in <module>() ----> 1 RandomUUID(1, output_field=None) TypeError: __init__() got multiple values for argument 'output_field' ```
The problem is not about `output_field`. `RandomUUID` didn't accept any source expressions previously, but it accepts any number of them now. I think that behavior should be preserved here. Also I think it could make sense to inherit directly from `Expression` and define `as_sql()` to simply return `'GEN_RANDOM_UUID()'`.
That's how it works after the change: ``` In [8]: expr = RandomUUID(1, 2, TextField()) In [9]: expr.output_field Out[9]: <django.db.models.fields.UUIDField> In [10]: expr.source_expressions Out[10]: [Value(1), Value(2), Value(<django.db.models.fields.TextField>)] ```
Then it's settled, I think. Thanks :)
@felixxm yes that's what I'm thinking.
@morganwahl yes please!
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
`pk` is twice. I think the last `and pk` can be removed.
Exception seems okay, but I've investigated possible failure scenarios
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
We can chop this docstring.
This test should catch `IntegrityError`, e.g. ```python def test_order_by_update_on_unique_constraint_annotation(self): # order_by() with annotate references are ignored. with self.assertRaises(IntegrityError): UniqueNumber.objects.annotate( number_inverse=F('number').desc(), ).order_by('number_inverse').update( number=F('number') + 2, ) ```
You could use `self.subTest()`, e.g. ```python def test_order_by_update_on_unique_constraint(self): tests = [ ('-number', 'id'), (F('number').desc(), 'id'), (F('number') * -1,), ] for ordering in tests: with self.subTest(ordering=ordering): updated_count = UniqueNumber.objects.order_by(*ordering).update( number=F('number') + 1, ) self.assertEqual(updated_count, 2) ```
This should be `+1` because `+2` works even without including `ORDER BY` clauses.
The `.all()` is redundant ```suggestion updated_count = UniqueNumber.objects.order_by('-number', 'id').update(number=F('number') + 1) ```
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
@timgraham already pointed the code formatting of the tests. Please don't make newlines at dots, `tests/annotations/tests.py` has good examples of the style.
you don't need `nulls_last=True` here because it's a PK you're ordering by, which is non-nullable
I think we can safely remove this. It was overlooked in the post-deprecation removal of `django.core.cache.get_cache()` in d038c547b5. We should do that in a separate commit w/ `Refs #21012 -- ...`.
Pushed to a separate PR #13753.
You can use `Path.is_absolute()`.
The docstring should explain why such proxy is needed.
We don't need this skip.
Simply deindent and remove the `else`.
We should use a custom storage for this test (instead of mocking).
Right, I would create a "Someday/maybe" ticket and give it a keyword of "2.0" so we remember to start the deprecation then.
Not sure these asserts bring value ... they seem to test that `override_settings` works.
Please use `assertRaisesMessage` for exception checking.
`)` on new line
You turned the arguments into keyword arguments in one other place. Could you also do this here and below? I don't know if it makes sense to also do this in the tests.
I think you can use `django.utils.deconstruct` to decorate the class, the `path` argument can be passed explicitly. Since Django 2.0+ is Python 3 only, you can use keyword-only arguments with `*, arg1=None, arg2=None`.
one line ```py return ( isinstance(other, self.__class__) and self.relation_name == other.relation_name and self.alias == other.alias and self.condition == other.condition ) ``` `and` shortcuts, so it won't try get `other.relation_name` if it's not an instance of the same class 😉
```suggestion raise self.exception_class(f'The connection {alias!r} doesn't exist.') ```
huh, TIL. Transitioning to Python3 from 2.7 for my personal projects and I didn't know they had changed that. Thanks for pointing it out.
This is fine as-is. It is well known that iterating over a dictionary iterates over the keys. Also this is explicitly returning a `list` and not an iterator (as is the case with Python 3). Try out `type({}.keys())` to see the difference.
Please add a trailing comma to this line.
Use literals please - `[]` for `list()` and `{}` for `dict()`. Also, something like `result` would be a better name than `return_dict`.
Use literals rather than functions, i.e. `{}` not `dict()`. This should come at the top of the function as the stuff before it does not need to happen if it is empty.
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
`_combine()` is unnecessary since its introduction, I moved it to a separate commit b62c58d5fccaeedc7bc4a064b4678e4ed1e77581.
`copy()` in unnecessary.
This makes me wonder why `SearchQuery` is a `Value` in the first place given it needs to resolve `config` and `value` now.
The usual pattern is to implement `get_source_expressions` and `set_source_expressions`. ```python def get_source_expressions(self): return [self.config] def set_source_expressions(self, expressions): self.config, = expressions
I think a list comprehension would be more readable.
longer lines here are okay, we try to avoid non-multiple of 4 indents
This is inconsistent but I think the patch can land as is and the test be modified later on based on the direction of [#24082](https://code.djangoproject.com/ticket/24082).
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
I think we'd want more details about why this hack is needed.
won't work if `sep` is more than a single character.
As django 3.0 is only compatible Python ≥ 3.7, maybe we could start having some type hints? ```suggestion def make_token(self, payload: dict, valid_for=None): ``` Same for `valid_for`, would be nice if we had a direct hint that is a timedelta!
Type hints are not coming to Django (yet) https://groups.google.com/d/topic/django-developers/C_Phs05kL1Q/discussion
```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
please use single quotes for consistency
You can reuse `resolve_model_field_relations()`.
Are you sure this branch is ever skipped? AFAIK `auto_created` models are not part `ProjectState.models` entries.
You can have a flatter function (less nesting) by doing: ```python if not remote_field: continue ```
The 4 lines above look identical to the `remote_model_key` lines a few lines before, except with `through` instead of `remote_field.model`. Maybe that can be a helper method accepting that argument.
We can take `model_state` from `self.models`, there is no need to pass `model_state`.
I try to avoid "we", e.g. The check allows a double slash, presuming the user knows....
Is this line correct? Above it's `subTest(url=url_name)` but then we `reverse(url_name,...)`
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
Should use `assertRaisesMessage()` to verify the string also.
Please remove trailing newlines in files (check code with flake8).
Maybe we should move this directly to the `RelatedLookupMixin` :thinking:, I don't have a ready answer.
Have you checked ticket-7488? If admin filters by nonexistent objects then we need to fix this in advance.
Are both of these going through the `__radd__` path? At a glance, I'd have _guessed_ that both are using `__add__` because the LHS is a `SimpleLazyObject` which now has that magic method? I could be wrong, it has been a _long_ time since I filed the ticket, so I may be misremembering.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
If we remove this will the tests run on Jenkins? It might be fine.
As long as you use `except Exception` and not a bare `except` this should be good.
Don't think we need to worry about duplicates.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
The benefit of the extra tests is they make the HTML structure clear, but the CSS selector perhaps does that... We should use hanging indent for the wrapping, so maybe pull the CSS selector into a variable, so it's easy read/see, and then the lines would be shorter too, and we can just have the two assertions.
I think the `lambda` could go on this line.
Hanging indent looks like this: ``` msg = ( "Filtered relation 'alice_favourite_books' cannot operate on " "foreign key 'author__favourite_books__author'." ) ``` In general, indentation should always be a multiple of four.
Check existing tests for the style to use for `assertRaisesMessage`.
no blank lines needed
you don't need `nulls_last=True` here because it's a PK you're ordering by, which is non-nullable
prefer hanging style: ``` return { self.fk_field: ..., } ```
Overall, the changes are mostly fine, I just wonder if we might use this as an opportunity to tighten up large try blocks and use try/except/else instead (such as here).
no blank line please
Merged in 1e0dcd6c8bfa4519c21014c73eb510620dd1a000.
> I've noticed that these "internal" names leak into migrations. Making this change will cause migrations to be generated when users upgrade. Are you sure? I didn't notice this in a sample project.
``` @mock.patch('django.contrib.contenttypes.management.update_contenttypes') def test_remove_contenttypes(self, mocked_update_func): management.remove_contenttypes(self.app_config.name) self.assertEqual(mocked_update_func.call_count, 1) ```
Need to test how many times `update_contenttypes` was called and test arguments which passed to it.
I would say, "A ContentType shouldn't be created..."
assertEqual -- the version with "s" is a deprecated alias.
I'd be great to assert the permission and content types were appropriately created as well!
I find binary operators very legible for set operations: `self.keys - keys`
I'm pretty sure someone will complain that this check is assymetrical, and as a consequence equality isn't symmetrical. Equality must always be reflexive (a == a) symmetrical (a == b iff b == a) and transitive (a == c if a == b and b == c).
My proposed way is definitely broken. Maybe isinstance(other, KeysValidator)? This might be another instance of things we should do globally, not just in this patch.
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
While I realize we cannot change that now, do we remember why we added `django.http.cookies` here? The salt alone should make sure that we do not clash with other signatures.
Maybe `map()`: ```suggestion fallback_keys=map(_cookie_signer_key, settings.SECRET_KEY_FALLBACKS), ```
```suggestion # SECRET_KEYS items may be str or bytes. return b'django.http.cookies' + force_bytes(key) ```
According to the [docs](https://docs.djangoproject.com/en/2.0/ref/settings/#std:setting-SECRET_KEY) and ticket https://code.djangoproject.com/ticket/24994 the type of `SECRET_KEY` can be either bytes or str. > Uses of the key shouldn’t assume that it’s text or bytes. Every use should go through force_text() or force_bytes() to convert it to the desired type. So a call to `.encode()` may not always work.
Unfortunately, I don't have a good answer for that. I think now that Django is Python3 only, the project is in a better position to decide if SECRET_KEY is always either bytes or str. That would require some consensus from interested people, though. As long as both types are allowed, some utility function is required. I guess at the moment that is force_bytes/force_text.
This change isn't needed and adds a bit of noise.
Right (actually there's a bug in that code, the `ImproperlyConfigured` can never be raised).
param -> params
To keep the diff a bit cleaner, I wouldn't make this unrelated whitespace change.
I'd chop this blank line since the } on its own line is providing whitespace.
you need to drop the `__class__`, the `object` itself should be an instance of `Author`
this can be a single line (we prefer longer lines when it improves readability)
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
start docstring on next line and "Create..."
I think this is implied by the underscore prefix.
suggested wording: "Yield each item in iterable at most once and exclude those that appear in skip_set."
I don't see a reason we can't use Python's `hash()` builtin, which is even faster and cached on strings I also don't think we need a class here - a single function to do the shuffling would do.
Minor but this could have likely be simplified by using `reduce` to avoid the private `_connector` usage ```python condition = reduce( (Q(app_label=app_label, model__in=models) for app_label, models in needed_models) , operator.or_) ``` In all cases `Q(("app_label", app_label), ("model__in", models), _connector=Q.AND)` can be simplified to `Q(app_label=app_label, model__in=models)` since `_connector` defaults to `Q.AND`.
Really? Surely in this context it should be fine as it is an argument to `getattr()`… (Personally I don't like that check at it leads to cases like this where we have five lines of code instead of a single readable line.)
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
OK , thanks @codingjoe, @cjerdonek both. On reflection, I think it's OK as-is.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There should be a sane API through `schema` ( A SchemaEditor, I presume) to do this.
`'utf-8'` is the default. We can remove it.
Name corrections should be moved into `set_name_with_model()`, e.g. ```python if self.name[0] == '_' or self.name[0].isdigit(): self.name = 'D%s' % self.name[1:] ```
Ok, I don't think it needs to be skipped on sqlite (since it passes). A note in the docstring that it's only a problem on certain databases would be helpful.
I added a small hook for this.
A note about code length, because some users may say "using self.client.get() is more straightforward"... We can also write the lines above (297-301) like this: ``` python view = views.CustomTemplateView.as_instance( RequestFactory().get('/dummy'), foo='bar') ``` That said, the way they are written right now is fine too.
chop blank line
We need to remove these blank lines which were added
variable could be omitted
Could be reduced to a list comprehension ```python return [ value for key, value in request.POST.items() if regexp.match(key) ] ```
```suggestion cls.to_wsgi_name(header_name): value ```
Not sure whether it's worth having a `to_asgi_name()` for completeness? 🤔
Now that I've been looking at the ASGI equivalent below, I feel that we should perhaps call this `to_wsgi_name()` instead... Also, for this helper method we're only using it in one place and I think we could push that loop in here and call it `to_wsgi_names()` instead (or provide that in addition).
again, only used in one place, inline it
since there's no validation here and `get_port()` is relying on this code I would think you'd need to consider other malformed cases, such as `example.com:abc` or `1.1.1.1:443]`
`date=rfc850date` isn't needed in the `subTest()` -- since will appear if the assertion fails.
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
I would move mocking `datetime` to a decorator, after that we will be able to test different dates, e.g. ```python @mock.patch('django.utils.http.datetime.datetime') def test_parsing_rfc850(self, mocked_datetime): mocked_datetime.side_effect = lambda *args, **kw: datetime(*args, **kw) utcnow_first_fifty = datetime(2019, 11, 6, 8, 49, 37) utcnow_second_fifty = datetime(2051, 11, 6, 8, 49, 37) date = ( ('Tuesday, 31-Dec-69 08:49:37 GMT', datetime(2069, 12, 31, 8, 49, 37), utcnow_first_fifty), ('Monday, 10-Nov-70 18:49:37 GMT', datetime(1970, 11, 10, 18, 49, 37), utcnow_first_fifty), ('Wednesday, 31-Dec-71 18:49:37 GMT', datetime(1971, 12, 31, 18, 49, 37), utcnow_first_fifty), ('Thursday, 31-Dec-99 08:49:37 GMT', datetime(2099, 12, 31, 8, 49, 37), utcnow_second_fifty), ('Thursday, 10-Nov-50 18:49:37 GMT', datetime(2050, 11, 10, 18, 49, 37), utcnow_second_fifty), ('Sunday, 31-Dec-00 18:49:37 GMT', datetime(2000, 12, 31, 18, 49, 37), utcnow_second_fifty), ) for rfc850str, expected_date, utcnow in date: mocked_datetime.utcnow = mock.Mock(return_value=utcnow) with self.subTest(string=rfc850str): parsed = parse_http_date(rfc850str) self.assertEqual(datetime.utcfromtimestamp(parsed), expected_date) ```
I don't think the number of tests is an issue, but since the check depends on a variable, the test should also reflect this, or it'll break at some point.
I'd use .objects.create
If POSTGIS_TEMPLATE exists, it will be a string, not a tuple. So you'd better make the tuple in the execute method below instead.
It would be more elegant, and possibly more efficient, to use: ``` template_postgis = getattr(settings, 'POSTGIS_TEMPLATE', 'template_postgis') cursor.execute('SELECT 1 FROM pg_database WHERE datname = %s LIMIT 1;', template_postgis) if cursor.fetchone(): return template_postgis ``` This is how `QuerySet.exists()` is implemented.
I don't think it's accurate to query the database at init time, as we are not even sure yet that we will need this info. I'd rather have a cached property, so it will only get fetched when we really need it.
This makes we wonder if passing `expressions` as a list of 2-element tuples would be more appropriate. I guess the current break down of `expressions` and `operators` is more coherent with the actual expressions interface and the exclusion constraint syntax.
From https://www.postgresql.org/docs/12/sql-createtable.html#SQL-CREATETABLE-EXCLUDE only GiST and SP-GiST are supported in practice.
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
Can we adjust the test name. We know this is `modelchoicefield`, because the whole `TestCase` is called that, so we can drop that. Maybe... `test_initial_accepts_model_instance_for_validation_when_field_disabled`? It's a bit long and horrible but... (???: suggestions welcome!)
It's better to use `assertIs(..., False)` since `assertFalse` will also pass if `bool(result) is False`.
These assertions are not related with a bugfix, please move them to a separate commit.
I will move this test to the `model_forms/tests.py`.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
```suggestion self.assertEqual(value, b'text/plain') ```
```suggestion # Windows registry may not be configured with correct # mimetypes. ```
This behavior doesn't exist in the current implementation of `HttpResponse`.
But now the imports aren't alphabetized anymore... :)
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
should use `RemovedInDjango110Warning`
You can use `type='choice'` with `choices=['ipython', 'bpython']` for options with a predefined set of choices: http://docs.python.org/library/optparse.html#optparse-standard-option-types
I suggested this realiasing for tests only, I'd prefer a `if six.PY3 unquote_to_bytes() else unquote()` in the actual function. It helps with comprehension.
I think we should revert this change (we reverted similar change in `django.core.cache.backends.basedefault_key_func()` in the past) because it will create a regression for non string values. The following example works in the current master: ``` >>> Signer('some_key').sign(1) '1:gJ9gvYHWvcR2rrXTSANB5b-IhU8' ``` but with this change it raises `TypeError`: ``` File "django/django/core/signing.py", line 162, in sign return self.sep.join([value, 'sha1', self.signature(value)]) TypeError: sequence item 0: expected str instance, int found ```
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
Fair warning, I don't know nearly enough about things of this nature to be actually valuable, except possibly to ask questions which might be dumb or might be previously unconsidered. So please take it with a grain of salt... If an adversary is making use of the fact a secret key has been compromised, which scenario gives them less information when the key is subsequently discovered and rotated and they want to stop trying to make use of it (to fly under the radar as much as possible); one constant time compare, or multiple? Layman's gut feeling says you'd want the time comparison to be actually roughly constant, which would probably require always doing either 1 or 2 (I think, it's murky in my brain now) always, regardless of number of keys in the corpus? (ie: if there's only one key, always compare as if there are 2...) And does that kind of scenario _actually_ matter? IDK.
Interesting thought. But if a key is compromised one would switch from one key in the list to still one key (the new one) because you wouldn't want to keep the compromised key active. So in the case of a compromise I'd always expect the list to stay constant in length because the offending key would be replace with a new one (independent of other keys probably). Either way for the majority of cases (ie under normal operation) I'd expect just one key in there (or always two if one rotates a key every $x weeks)
Does it change anything? :thinking: The previous solution works fine for a dictionary on the RHS.
`COT` doesn't exist on Oracle, please emulate it by `1 / TAN(%s)`.
You're right :+1:. I missed that.
@JunyiJ My previous suggestion was to use the `TAN` database function on Oracle, i.e. ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='1 / TAN(%(expressions)s)') ```
You should use the `CEIL` function instead of `CEILING` on Oracle.
`PI` doesn't exist on Oracle. It is a constant, therefore we can use `math.pi`.
Personally yes. (But maybe the examples in the docs will be enough)
Perhaps dropping this blank line.
This is already tested in `test_args_kwargs_request_on_self()`, I'm going to remove these assertions.
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
This test is not related with the patch, so I'll move it to a separate commit.
The easiest solution might be to duplicate the warning in `OneToOneField`.
stacklevel 2 isn't useful when the warning is raised for OneToOneField. Ideally we could have stacklevel=3 for that case to give `question = models.OneToOneField(Question)` instead of `super(OneToOneField, self).__init__(to, on_delete, to_field=to_field, **kwargs)`.
Sounds okay. The warning should be updated to say something like "Pass to_field as a kwarg instead of as an arg."
Thanks for the clarity, Tim :-) In that case, I think we may as well still go ahead and provide the deprecation shim and warning that we are able to provide (for `ForeignKey(SomeModel, 'to_field')`, which is likely much more common) by shortening this line to just `if not callable(on_delete)`. And we'll just have to rely on a backwards-incompatibility note in the release notes (that you should no longer pass `to_field` positionally, and you can pass `on_delete` as the positional second arg) to help anyone who is doing `ForeignKey(SomeModel, 'to_field', on_delete=models.WHATEVER)`.
Could be useful to say `Pass to_field='{2}' as a....` and add `on_delete` to the format
The system check framework will throw an error if a model uses `DecimalField` without those arguments. I'm not sure if there's a use case for instantiating `DecimalField` outside of a model (perhaps in `output_field`, but don't think validators are used there). All in all, I think the current version is okay.
You don't need to break this line, if it's below <=119 characters. It's better readable in my eyes.
This must also take the sign into account. What about: ``` python max_length = self.max_digits + 1 # for the sign if self.decimal_places is None or self.decimal_places > 0: max_length += 1 # for the dot ``` We could also make the sign check conditional based on `min_value` and `max_value` but it would be a mess.
We might want to avoid doing this if `self.localize is True` since `DECIMAL_SEPARATOR` and `THOUSAND_SEPARATOR` should be taken into account in this case.
`to_python()` (add parens)
Use single quotes.
Why is the middleware check here? It seems to me that `AUTH_VERIFY_SESSION = False` should be deprecated regardless of whether you have the middleware in your settings or not.
Bad rebase? `PASSWORD_RESET_TIMEOUT_DAYS` was removed in 4.0. ```suggestion ```
(That is, the already-existing "upgrade considerations" section.)
This would set `SECRET_KEYS` to `[None]` if `SECRET_KEY` was `None` which again gives me the impression that using `is_overriden` is the wrong approach here.
I think we can simplify this, e.g. ```python dump_cmd = ['mysqldump', *dump_args[:-1], '--routines', '--events', source_database_name] ```
My proposition keeps all arguments.
Previously we always changed the last option to `source_database_name`, see ```python dump_args[-1] = source_database_name ``` so it keeps this behavior.
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
To keep the diff a bit cleaner, I wouldn't make this unrelated whitespace change.
What about `prefetch_related()`? It's a new method so we should raise `ValueError` when `aiterator()` is used after `prefetch_related()`, e.g. ```python async def aiterator(self, chunk_size=2000): if chunk_size is None: if self._prefetch_related_lookups: raise ValueError( "chunk_size must be provided when using QuerySet.iterator() after " "prefetch_related()." ) elif chunk_size <= 0: .... ```
```python async with contextlib.aclosing(aiter(self._iterable_class(...))) as agen: async for item in agen: yield item ``` You should explicitly aclose your async generators when you create them: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators
We'll want to do something with regards to the newly added support for `iterator`'s `prefetch_related` here.
> We'll want to do something with regards to the newly added support for iterator's prefetch_related here. That looks like a _moderate_ task in itself (to implement) — `islice`, `prefetch_related_objects`, ... — it might be that adjusting the PR here match the new interface, but emitting a warning if prefetches are set would let us get this in, to work on async prefetches later. (Would be equivalent to the sync behaviour before edbf930287cb72e9afab1f7208c24b1146b0c4ec — of _either prefetch or iterator_.) 🤔
Shouldn't we handle these situations? ``` >>> class TestForm(Form): ... my_field = forms.ChoiceField(choices=[['', 'zero']]) ... >>> t = TestForm() >>> print(t['my_field']) <select id="id_my_field" name="my_field" required> <option value="" selected="selected">zero</option> </select> ``` Or this: ``` >>> class TestForm(Form): ... my_field = forms.ChoiceField(choices=[(None, 'zero')]) ... >>> t = TestForm() >>> print(t['my_field']) <select id="id_my_field" name="my_field" required> <option value="" selected="selected">zero</option> </select> ```
I think it would make sense.
put the closing parenthesis on the next line
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
This and one above, replace `self.function = ..` with `function=...` in as_sql method call.
I added warning to docs.
suggestion: "commands that don't need settings succeed if settings file doesn't exist"
It's not obvious to me that the template approach is the best solution for readability as opposed to just creating another test settings file.
would be fine to use double quotes so you don't have to escape the single
Nitpicking: I would have reused the test_invalid_project_name test, looping on "for project_name in ('7testproject', '../testproject'):". This would allow us to test more names with less code duplication.
Here's how I would have written it: https://gist.github.com/3911240. Hopefully it's not worse than the previous version.
`... Using multi as True` and `...imports as multi`
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Good, thanks. Maybe `Note setting ` -> `Set `
Don't add a blank line.
Chop blank line.
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
Put the close ] on the next line.
`"""Return the index at which the ordering expressions start."""`
Chop "Helper function that" "Return ..." (use PEP 257 verb style)
Turn (capitalize) add period. sql -> SQL
Please move [standard library imports](http://www.python.org/dev/peps/pep-0008/#imports) with the [other ones](https://github.com/ezequielsz/django/blob/90a9140051aeeb84ab9d46c6209f42c5c3820908/tests/regressiontests/mail/tests.py#L4-L11).
I'm not sure about the `backend` terminology here. I think naming this function `get_password_validators` would be more consistent with the rest of the the code.
built-in imports go first (after `__future__` and before django)
Use `gettext` instead of `ugettext`
It used to be that way (in Python 2 era). Now gettext is an alias to ugettext and the latter will be deprecated in the future.
I have a feeling something else if off here. The outer query's joining strategy should not have to special case inner queries as they are self contained expressions. My guess is that something is getting mixed up wrt to aliases because the same model is being involved in the outer and inner queries.
Could be reduced to a list comprehension ```python return [ value for key, value in request.POST.items() if regexp.match(key) ] ```
This was noted in another PR that I closed to avoid creating a merge conflict: "upper" -> "earlier"
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
I guess these could be merged by doing a ```python self.assertEqual( qstr.count("LIMIT 1"), 3 if connection.features.supports_limiting_in_compound else 1 ) ```
I'd suggest to check `response.context[REDIRECT_FIELD_NAME]` instead.
This docstring should be customized for the purpose of this test (it looks to me like it's copied from the other test).
there's no need to "cleanup" by logging out as each test creates a new test client
I think you could simplify this a bit by using `self.client.login(self.super_login)` and the ORM to create the initial objects instead of the add view.
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
I thought about it, but it has some value to test this explicitly.
I'm not even sure we really need the extension to be created in this test, checking the SQL command correctness might be sufficient.
Exactly, it's not **related**. That's why we should fix it separately in advance.
preferred format is "#15346, #15573 - Issue description"
argument ordering should be reversed
To verify this is the expected import error, I'd do something like: `self.assertRaisesMessage(ImportError, 'nonexistent')`
Please don't make unrelated whitespace changes.
While I realize we cannot change that now, do we remember why we added `django.http.cookies` here? The salt alone should make sure that we do not clash with other signatures.
I think debug logging would be fine here.
I couldn't find a valid way of making the `Exception` catching cloak possible misconfiguration but I wonder if it wouldn't be better to make session serializers re-raise a common `DeserializationError` and catch it here.
How about more simply: "Found duplicate <field/base/manager> '%s' in CreateModel operation." Maybe you could create a helper function so we don't have to repeat a similar loop 3 times.
I think we want to crash here if `bases` is not iterable.
, -> . (for consistency with same message in operations/models.py)
what if two mixins have the same name (from different packages)? hypothetically: `facebook.models.UserMixin` and `twitter.models.UserMixin`
Use: ``` python raise ValueError( "Indexes passed to ModelState require a name attribute, " "%r doesn't have one." % index ) ``` While we allow longer lines, we typically break up long strings like this.
We should also use `quote()` because non-integer primary keys may not work properly, e.g. `_40`. Fixed.
```suggestion return format_html('<a href="{}">{}</a>', url, remote_obj) ```
Still I think `'&nbsp;<strong>%s</strong>'` could be factored as a variable and `<a href=...` interpolated inside that. Let's use `format_html` instead of `escape`. This return could go in the `else` block of `try/except/else`.
Could you try to improve this so that there isn't duplication of the HTML and `escape(Truncator(obj)....`
This could be replaced by `self.remote_field.model._meta.label_lower` https://github.com/django/django/blob/c1b24718e05ea474955777d7bc4d9d5634560cd5/django/db/models/options.py#L136-L138
`quote_name` is a temporary variable that's used only once, therefore I think we can remove it and use `schema_editor.quote_name` directly, i.e.: ```python 'name': schema_editor.quote_name(self.name), ```
I think this would be slightly cleaner: ```python if self.condition is None: return '' query = Query(model=model) query.add_q(self.condition) compiler = query.get_compiler(connection=schema_editor.connection) # Only the WhereNode is of interest for the partial index sql, params = query.where.as_sql(compiler=compiler, connection=schema_editor.connection) # The base schema editor does the same map on the params, but since it's # handled outside of that class, the work is done here return ' WHERE ' + (sql % tuple(map(schema_editor.quote_value, params))) ```
You can also drop the parentheses :wink:
Please check test coverage carefully. I didn't spot a test for this change.
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
We can reuse existing objects.
```suggestion For encryption and other more advanced use cases, you can use third-party packages like PyJWT. ```
decorate the class instead
I'm not sure this is needed since class doesn't have a custom `__repr__()`, we're just testing the base class.
I added `Square` without a sequence to show that delete is used in such case.
```suggestion for table_name, table_rows in rows: ```
Perhaps it isn't worth breaking consistency. For sure it can wait and be done separately.
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
[This is only an estimate on InnoDB tables](https://dev.mysql.com/doc/refman/5.7/en/tables-table.html) which is the default table engine and what's used on CI. > The number of rows. Some storage engines, such as MyISAM, store the exact count. For other storage engines, such as InnoDB, this value is an approximation, and may vary from the actual value by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate count. In short that means this value could report 0 while there's actually rows in the table and cause errors similar to the one you are experiencing.
This test is also already in the `backends.base.test_creation` and it's unrelated with this fix. Please remove it.
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
```suggestion elif databases[DEFAULT_DB_ALIAS] == {}: ```
As the checks are performed against `model_class._default_manager` the `connections[router.db_for_read(model_class)]` connection should be used.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
Maybe you've missed `if summarize` branch (below).
We used the same message as in other places that's why I don't want to add a period only in this case.
Add a period to the end of the exception message.
is it possible to make the try/except block a bit smaller? try/except/else maybe? That will help to show where the error is expected.
You can drop the `.contains_column_references` as it's wasteful in this case because of the way it walks the expression tree given we'll have to walk it anyway below.
Ok, but please ensure that there is at least one test testing if the redirect works properly too.
I am not really convinced that we need a specialitzed client like this, the normal test client can follow redirects, and I'd rather have the tests explicit instead of emulating part of the feature in the test client.
I didn't look at the tests yet when I wrote that, so if there are already tests covering that, it should be fine.
@romgar If you find the time that would be great!
It might be smarter to validate the token first and only modify the session + redirect if it's valid. Otherwise it makes it really easy to create a session just by GET'ing a url (possible DoS vector). It also means you can't pass `accounts/password_reset` as the token and take advantage of our `request.path.replace()` code. It probably means validating the token twice, which is slightly slower. Seems fine to me if an invalid token gets leaked.
won't work if `sep` is more than a single character.
```suggestion SECRET_KEY_FALLBACKS=['oldsecret'], ```
Interesting thought. But if a key is compromised one would switch from one key in the list to still one key (the new one) because you wouldn't want to keep the compromised key active. So in the case of a compromise I'd always expect the list to stay constant in length because the offending key would be replace with a new one (independent of other keys probably). Either way for the majority of cases (ie under normal operation) I'd expect just one key in there (or always two if one rotates a key every $x weeks)
Fair warning, I don't know nearly enough about things of this nature to be actually valuable, except possibly to ask questions which might be dumb or might be previously unconsidered. So please take it with a grain of salt... If an adversary is making use of the fact a secret key has been compromised, which scenario gives them less information when the key is subsequently discovered and rotated and they want to stop trying to make use of it (to fly under the radar as much as possible); one constant time compare, or multiple? Layman's gut feeling says you'd want the time comparison to be actually roughly constant, which would probably require always doing either 1 or 2 (I think, it's murky in my brain now) always, regardless of number of keys in the corpus? (ie: if there's only one key, always compare as if there are 2...) And does that kind of scenario _actually_ matter? IDK.
Type hints are not coming to Django (yet) https://groups.google.com/d/topic/django-developers/C_Phs05kL1Q/discussion
@MarkusH Such a request should not change any state, so it should be `GET`. Using `POST` and `CSRF` wouldn't help against DoS there anyways (unless I miss something). If you are worried about querying the database, you can do the same with a normal request to the list views in the admin…
I think `GET` is fine for that.
Both `has_perm()` and `has_change_permission()` take an optional `obj=None` argument for object-level permission checks as implemented by e.g. django-guardian. I think we should provide this here as well.
Unused or untested according to coverage report.
It's not obvious to me where limit_choices_to comes into play.
Include a trailing comma so if more items are added later, we don't have to modify this line again.
I think I would not mix the tests and better create a separate test, if possible.
I'm not sure this line belongs here
Add a trailing comma so if more items are added later we don't have to modify this line again.
follow -> following
include a trailing comma
please remove `on_delete=` from these FKs.
(inadvertence revert here too)
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
That's not "cruft" -- that's making user code look like it was written after Python 2.4 was released. And also, ``` python @classmethod @queryset_only def as_manager(... ``` does work.
This would be more readable as a one-liner: `predicate = inspect.isfunction if six.PY3 else inspect.ismethod`
Might be nice to copy `__doc__` here as well
I don't think you need this check here. This case will be handled in the for loop. Otherwise you can skip the first item in `cls.mro()` as well.
I think `base_mgr` would be more clear/consistent with the rest of the code
Probably it could be reworked this way: ``` sql, params = super().as_sql(connection, lookup, template_params, sql_params) return '%s > 0' % sql, params ```
It might be worth adding some sort of hook to the superclass so that so much copy/paste from the parent `as_sql()` is required.
By the way, [looking up `SpatialOperator`'s implementation](https://github.com/django/django/blob/31a2af1c0101081a3950dab0e66fa41bbbf6d34f/django/contrib/gis/db/backends/utils.py#L7-L27) I think you could probably go away by simply overriding `default_template` instead. ```python class SpatialiteNullCheckOperator(SpatialOperator): @property def default_template(self): return '%s > 0' % super().default_template ```
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
I would deindent these ] and also include a trailing comma in case more items are added later
missing some trailing commas
removing unnecessary multilines like this will make it nicer.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
That's what we keep in the commit message. `git blame` is your friend to find the commit and thus the commit message.
Style: We can write this in one line like the other create_user examples in test_tokens.py.
missing point at the end
Use double quotes and wrap docstrings at 79 characters.
Per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/ these could use `assertIs(..., True)`. I've done this for existing `.check_token()` tests in #12380.
You can skip this test on MySQL with `@skipUnlessDBFeature('allows_auto_pk_0')`.
Ahh ok nevermind :smile: I misunderstood. It will work for primary keys that are not auto fields on MySQL :+1:
Maybe just :thinking: : ```python falsy_pk = 0 if connection.features.allows_auto_pk_0 else '' ```
The `Order` model should do https://github.com/django/django/blob/594cf9bff82e4d840862c2526c29d725d5bf07f0/tests/queries/models.py#L592-L599
IMO we can remove this line.
should this be used? (with a test too) arguments -> options
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
As multiple addresses are allowed, I suggest "to one or more addresses specified ...".
'--version argument does not yet exist'
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
> Is there any reason to explicitly prefer lowercase? Well, not really anything critical. Elements, attributes, etc. in HTML tend to be case insensitive and I tend to lowercase the lot - more similarity leads to better compression in transit. Granted this isn't going to make much difference for such a short string, and your point about implementation detail is fair. (Hence I didn't press for it...)
This can be single-lined, e.g. ```python return HttpResponseServerError( ERROR_PAGE_TEMPLATE % {'title': 'Server Error (500)', 'details': ''}, content_type='text/html', ) ``` The same in `bad_request()` and `permission_denied()`.
```suggestion The message from the exception which triggered the 403 (if one was supplied). ```
You don't need the trailing \ here. EDIT: I see you just moved that code, that's fine.
no u'' prefixes please (use `from __future__ import unicode_literals` if needed)
> It just happens to pretty straightforward here as you can directly call `Constraint.validate` without the `exclude` on the constraint you are interested in validating. That's a suitable workaround, but I feel like it should not be necessary. FWIW before Django 4.1 where this feature was added I added manual validation already, since there constraints with conditions where just skipped.
This message shouldn't be used when constraint is defined with `expressions`.
We should pass `using` to `check()`.
`FieldError` is untested. Do we need it? It looks unnecessary.
We should make use of `self.message`.
I think we can reuse `rels_to_update`.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Check constraints don't seem to be related with this issue, moreover `unique` is `False` for all check constraints. Please revert this unrelated change.
It appears to me that, since this previously returned an iterator (`zip()`'s return value), you don't need to construct an intermediate list here and can simply `yield` the tuples directly.
Yes, `_is_relevant_relation` should return the same result :thinking:
I'd suggest something like `'example@atm.%s' % 'a' * 63` (and 64 for the invalid one)
Do we really need this test? seems it doesn't relate to this change.
I hope it won't adversely affect readability, but if you can limit line lengths to 119 characters that would be good (see ticket #23395).
How about: ``` r"""LIKE BINARY CONCAT('%%%%', REPLACE( REPLACE( REPLACE(%s, '\\', '\\\\'), '%%%%', '\%%%%'), '_', '\_'), '%%%%')""" ```
We run `createsuperuser` in non-interactive mode so `@mock_inputs` is unnecessary.
You could use `for else` construct here. ``` python for fixture_label in fixture_labels: if len(self.find_fixtures(fixture_label)) > 0: break else: return ```
Ah I see, okay then.
```suggestion RuntimeWarning, ```
Do we need a separate variable? I would include it directly in the `compression_formats`: ```python compression_formats['lzma'] = (lzma.open, {'format': lzma.FORMAT_ALONE}, mode) ```
As far as I'm aware we don't need to iterate twice over the same list: ```suggestion return { '%s.%s' % ( fixture_name, '.'.join([ext for ext in combo if ext]), ) for combo in product(databases, ser_fmts, cmp_fmts) } ```
It seems like a lot of complexity can be stripped out of this: ```python if self.base_field.choices and "choices_form_class" not in kwargs: obj = self.base_field defaults = { "choices_form_class": forms.TypedMultipleChoiceField, "coerce": self.base_field.to_python, # XXX: Do we actually need this? } else: obj = super() defaults = { "form_class": SimpleArrayField, "base_field": self.base_field.formfield(), "max_length": self.size, } if self.choices: warnings.warn("Choices should be defined in base field.", RemovedInDjango51Warning) return obj.formfield(**{**defaults, **kwargs}) ``` Obviously the behaviour of this post-deprecation also needs to be decided: - Does it throw an exception? - Does it silently ignore choices on the `ArrayField`? (Might need to actively strip them out?) - If we promote a system check warning to error, does it matter which approach we choose? (Not everyone uses the checks though.)
Sorry - typo. Fixed.
IMO we can simplify condition: ```not self.blank or (self.blank and not self.null)``` to: ```not (self.blank and self.null)```
The nested if statements seem excessive. Could this whole thing just be simplified to the following: ```python def formfield(self, **kwargs): if self.choices: include_blank = not (self.has_default() or 'initial' in kwargs) defaults = {'choices': self.get_choices(include_blank=include_blank)} else: form_class = forms.NullBooleanField if self.null else forms.BooleanField # In HTML checkboxes, 'required' means "must be checked" which is different # from the choices case ("must select some value"). # required=False allows unchecked checkboxes. defaults = {'form_class': form_class, 'required': False} return super().formfield(**{**defaults, **kwargs}) ```
I wonder if the `isinstance()`condition results in any performance savings? I tend to think always casting might be simpler.
You can simply use `assertRedirect(response, obj.get_absolute_url(), ...)` here. No need for string formatting.
You should use `fetch_redirect_response=False` instead of `target_status_code=404`. It seems to be an outdated pattern used in a few places and I'll probably clean it up soon.
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
Is there a need to hardcode pks? This is generally to be avoided, I think.
I would use `%s` formatting consistently.
```suggestion 'Accept': '*', 'Host': 'example.com', ```
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
Chop blank lines.
blank line not needed
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
Reading below, I see that Flask has an "any" converter that does something more complicated. Creating a converter with the same name but a different behavior doesn't sound good.
You asked me about the `lru_cache` here; I don't think it matters one way or another :-)
(same pattern as above, if you change it)
TBH, I don't think we need this test. I will chop it.
Use `assertEqual()`, e.g. ```python self.assertEqual( conf_url(r'^regex/(?P<pk>[0-9]+)/$', empty_view, name='regex'), re_path(r'^regex/(?P<pk>[0-9]+)/$', empty_view, name='regex'), ) ```
Use a similar logging to what we do for robust signals? See `django.dispatch.dispatcher.Signal.send_robust` and ``` try: response = receiver(signal=self, sender=sender, **named) except Exception as err: logger.error( "Error calling %s in Signal.send_robust() (%s)", receiver.__qualname__, err, exc_info=err, ) ``` Something like ```suggestion logger.error("Error calling {func.__qualname__} on_commit() ({e}).", exc_info=True) ```
When calling `on_commit` there are basically two modes: - there is no transaction in progress, so we execute the function right away - we are in an atomic block, so we register the function to execute it later (`self.run_on_commit.append(`) The first case is handled by the PR, but not the second one. And I'd think that we would need to handle a robust execution in the second case too. Does that make it clearer? :)
I'd revert the logic i.e. check `execute` first: ```suggestion if execute: if is_robust: try: callback() except Exception as e: logger.error( f"Error calling {callback.__qualname__} on_commit() " f"during transaction (%s).", e, exc_info=True, ) else: callback() ```
`func` is called even if no transaction is in progress, so we should move this to the first line. Fixed.
This will become a performance issue for the database before it becomes one for the Python process :-)
`run_keeper` → `time_keeper` for consistency? It feels like a hangover from when the class was called `time_keeper` before it changed to `TimeKeeper`. Are we also not still using single quotes? ```suggestion time_keeper = TimeKeeper() if options['timing'] else NullTimeKeeper() ```
Since this is only being used in one test case class, I would put it right before that test case class. If it turns out to be useful for other tests, it could always be moved to a more central location and modified as needed, etc.
```suggestion time_keeper.results() ```
```suggestion time_keeper = TimeKeeper() if options.timing else NullTimeKeeper() with time_keeper.timed('Total run'): ```
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
append(...), not append[...].
it would help readability if description[5] and description[4] were assigned local variables describing what they represent
missing whitespace around ==
`WEEKOF` is not defined in the `Oracle`. You should use `TO_CHAR` with `IW` param ``` diff --- a/django/db/backends/oracle/operations.py +++ b/django/db/backends/oracle/operations.py @@ -84,6 +84,9 @@ WHEN (new.%(col_name)s IS NULL) if lookup_type == 'week_day': # TO_CHAR(field, 'D') returns an integer from 1-7, where 1=Sunday. return "TO_CHAR(%s, 'D')" % field_name + elif lookup_type == 'week': + # TO_CHAR(field, 'IW') returns an integer from 1-52 or 1-53, week of the year based on the ISO standard + return "TO_CHAR(%s, 'IW')" % field_name else: # http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions050.htm return "EXTRACT(%s FROM %s)" % (lookup_type.upper(), field_name) ```
Yeah, multicolumn case is what I am interested in, the results will not be correct for cases where the first column match, the second is smaller and we use __lt. So, error out in multicolumn case for now, then lets think if we can make this work properly (for some DBs the DB itself knows how to implement (a, b) < (val1, val2)).
@sir-sigurd `output_field` could also work, I suggested using `_output_field` because I knew it would work from my past experience implementing `Func` subclasses.
Crap, I assume this is caused by `IntegerField.validators` computation.
Are you planning to remove these lines in the same PR? It looks to me that this whole `__init__` could be replaced by a simple `_output_field = fields.IntegerField()`.
I would use the same order as the previous two classes (`TrigramSimilarity` and `TrigramDistance`): ```suggestion class TrigramWordSimilarity(TrigramWordBase): function = 'WORD_SIMILARITY' class TrigramWordDistance(TrigramWordBase): function = '' arg_joiner = ' <<-> ' ```
Is that removal related to 5f7035cec7d5? If yes, we might commit it separately with an appropriate message.
No blank lines needed (try to follow the style of nearby tests)
Try to state the expected behavior rather than "Ensure that" or "Test that" since all tests do that. Ticket references are only needed for obscure issues that can't be explained in the docstring. I'm not sure that's the case here.
please chop the rest of the blank lines
State the expected behavior rather than "Test ...." (all tests test things). No need for a selenium test as no JavaScript is involved. See 3aad955ea8db1592fad0012155eaa25b72e50dc5 for similar changes.
Use the following indentation ```python authors = Author.objects.filter( name__in=[self.author1, self.author2, self.author3], ).prefetch_related('bio') ```
I understand. Although I'm wondering if this is something that can just be configured by passing something in `OPTIONS` that is passed to the client class such that you don't need two separate client classes? (Failing that, a separate backend, e.g. `RedisShardedCache`, might make more sense? I know we are implementing the client class here, but for all other backends we are using an existing client class from a third-party package - we are never exposing knowledge of the client class to the end user.) Either way, if that sharded implementation is coming later (whether in another commit or PR), let's not add this client class loading stuff now. It doesn't add any benefit to this initial implementation other than making it more complex to review.
Do we need to allow customisation of the client class via a setting? That seems like bikeshedding. If someone wanted to write and provide a custom client they can subclass `RedisCache` themselves.
I think this is a typo: ```suggestion def _cache(self): ``` There is only one cache client class instance returned, cf. `BaseMemcachedCache._cache`
Don't use `.items()` if you don't need the values. ```suggestion # Set timeout for each key individually as .mset() doesn't support # setting the timeout for all keys at the same time. for key in data: if timeout is None: client.persist(key) else: client.expire(key, timeout) ```
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
Use single quotes.
Why is the middleware check here? It seems to me that `AUTH_VERIFY_SESSION = False` should be deprecated regardless of whether you have the middleware in your settings or not.
Bad rebase? `PASSWORD_RESET_TIMEOUT_DAYS` was removed in 4.0. ```suggestion ```
(That is, the already-existing "upgrade considerations" section.)
This would set `SECRET_KEYS` to `[None]` if `SECRET_KEY` was `None` which again gives me the impression that using `is_overriden` is the wrong approach here.
This has come up in the past when we were looking at removing unnecessary list comprehensions in favour of generators. IIRC, `str.join()` converts input to a list if it isn't already.
~~You don't need to create a list, actually. You can just pass the generator expression through (no surrounding parentheses are needed). So `...join(key.encode(...`.~~ Never mind, I learned that this is slower (what @pope1ni was probably saying in the first place).
For future reference, [here is the line](https://github.com/python/cpython/blob/aaa83cdfab6817446285e631232f64b394ac6791/Objects/unicodeobject.c#L10022) of interest. And here are the docs for [`PySequence_Fast()`](https://docs.python.org/3/c-api/sequence.html#c.PySequence_Fast) which states: > The `PySequence_Fast*` functions are thus named because they assume `o` is a `PyTupleObject` or a `PyListObject` and access the data fields of `o` directly. > > As a CPython implementation detail, if `o` is already a sequence or list, it will be returned.
When using `str.join()` it is preferable to pass a `list` as it is slightly faster.
I think the interfaces should be the same. It's probably the right (more forgiving) behaviour for a response, which isn't a dict. Folks will `s/response[/response.headers[/` not the least. But the docs also say this is the behaviour.
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
Since `SmallAutoField` extends `SmallIntegerField` this can be reduced to ```suggestion elif isinstance(self.lhs.output_field, models.SmallIntegerField): ```
a misspell? SQLFuncMixn -> SQLFuncMixin
Similarly, I don't see much advantage to creating indirection with a method.
I guess I was thinking something like example SQL would be useful.
Heh. This line was an `assertRaisesMessage` before, I recommended that it be changed to assertRaises to make the test less prone to break on trivial code changes. The message's content is essentially just "Not supported" anyway, so I think we should leave it this way.
`if it encounter` => `if it encounters`
Assuming you use `NotSupportedError`, I think checking for the exception class is enough and is more robust.
`mentionned` => `mentioned`
Why cast to a tuple? We could just check if it's falsey...
I partly restored `dates_or_datetimes` (removed in e88d2dfcf4daa2b4ee451f518085413bb3b8deeb), it looks simpler IMO.
Use the indentation style of the other tests. Actually, you can use `assertCountEqual()` instead. Maybe it makes sense to create another Article with a different year to test that the results are correct and not just returning everything.
Use `django.utils.timezone.make_aware` instead.
You can drop this assertion, the way `from_date` is constructed and that this branch is behind the `if day` one makes it impossible to reach.
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
All tests ensure expected behavior ;-). Our preference is to use test docstrings to state and explain the expected behavior.
You can simplify this with `assertLogs()`: ```suggestion url = reverse('test_with_sidebar:auth_user_changelist') with self.assertRaisesMessage(AssertionError, 'no logs'): with self.assertLogs('django.template', 'DEBUG'): self.client.get(url) ```
Jinja raises `jinja2.TemplateSyntaxError` in `render()` not in `get_template()` when an error is in the included template, so that's the real usage. We don't need to mock anything here.
IMO, it might be better to harcode the expected HTML rather than generating it programatically as it would be more clear what's expected.
Yes, I know. I'll leave it to Aymeric for a second opinion.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
`clean` is not only for validation, but also for data modification in a form.
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
Use unpacking generalisations and remove arguments to `super()`: ```python super().__init__(*args, **{ 'editable': False, **kwargs, 'blank': True, 'default': Default(), 'unique': True, }) ```
Perhaps we should continue to test the simpler case where we don't provide a `name` or `condition`.
As above -- it seems somewhat useless to implement this test for every subclass. At the least, maybe there could be a base test class that implements some common tests if that's warranted.
`self.assertTrue` -> `self.assertIn` above and below as well.
Given that the index is named `title_lower_id` this `LOWER` check could check against that as well as `lower(xxx)` -- please rename the index so there is only one match for `LOWER` (same for `TITLE`)
You need to wrap the second instantiation in its own assertRaises to actually test it.
That's not true, `return` is to avoid setting new migrations.
I thought you wanted to remove `return`. Nevertheless I'd also leave the `else` as it increases readability.
I prefer the following one rather than the above one ```py def greet(): condition = False if condition: return "Hi" return "Hello" ``` Feel free whether follow the things I point out.
```suggestion sys.exit(1) ```
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
Not a huge deal, but it might be nice to have this user-configurable, defaulting to 191, because some people may configure mysql to have a longer maximum length.
`items = value.split(self.delimiter) if value else []` is slightly faster.
Do we need to call `list(fields)` here? :thinking:
I'd move this line to the top of `__init__()` so it isn't lost below all the conditional logic.
This will not work for `OuterRef()` :disappointed: because we don't resolve it properly, so it generates: ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING(U0."name", 3, 1)) LIMIT 1 ) ``` instead of ```sql EXISTS ( SELECT (1) AS "a" FROM "expressions_company" U0 WHERE SUBSTRING(U0."name", 8, 1) = (SUBSTRING("expressions_company"."name", 3, 1)) LIMIT 1 ) ``` see `test_slicing_of_outerref`.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
the link for Python 3 might be https://docs.python.org/3/library/io.html#io.IOBase
Workaround is one word, no dash needed.
Please add a docstring explaining this.
``` # Cache namedtuple() with @lru_cache() since it's too slow to be # called for every QuerySet evaluation. ```
Did you consider using `queryset.model` instead of 'Row'? I don't know if that would cause confusion with model instances.
I'm still not sure what "tuple_class._make() is inlined here" means.
😁 ```suggestion while results := list(islice(iterator, chunk_size)): ```
Yes. We already do it in a few places.
I don't think `except Exception` is appropriate here - it's too broad. This should probably be under a type check
remove pdb stuff
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
This is better. I didn't think about the problem with variables that can change values. I have one concern, though. The same `render_context` instance is shared across nodes in the `Template.render()` call, so `template_name` isn't a very safe key to use. The potential arises to clash with other nodes. Maybe we could adjust the approach a bit? My thought is to create a cache dict in the `render_context` using `self` as a key. For example: ``` cache = context.render_context.setdefault(self, {}) template = cache.get(template_name) cache[template_name] = template ``` Alternatively, you could use a unique, uncommon key rather than `self`. The benefit here is that multiple `IncludeNode` instances could share the same cache. That means a template like below would only parse `template.html` once: ``` {% include "template.html" %} {% include "template.html" %} {% include "template.html" %} ``` That seems appropriate in this case.
This is mainly to avoid edge cases. Here's an example: Imagine a 3rd-party node sets a value with key `include.html` in `context.render_context`. It's not probable, but perfectly possible. Later `IncludeNode` runs and happens to also use `include.html` as a key. It will pull whatever is already in `render_context` from that previous node when it shouldn't. Using a custom key won't eliminate the edge case completely, but it does reduce the probability of edge cases. The `ExtendsNode` uses a key value of `extends_context`. `IncludeNode` could do something similar.
Removing `url_markup_template` breaks the customization use case in #19464.
Why not showing list of links here? Like this you don't actually know what files you're clearing...
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
Same here: ``` py self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> custom</p>\n' 'rest of the HTML' ) ```
```suggestion """Render as <p> elements.""" ```
Using `int` is untested and doesn't work as expected, because it uses 1-based indexing instead of 0-based indexing.
please use longer/more descriptive names than `f` and `k`, like `f_obj` and `slice`
Casting `int` to `int` is not necessary.
I think it will be more readable to keep `int` and `slice` in separate branches, e.g.: ```python def __init__(self, f_obj, slice_obj): if isinstance(slice_obj, int): if slice_obj < 0: raise ValueError('Negative indexing is not supported.') self.low = slice_obj self.length = 1 elif isinstance(slice_obj, slice): if ( (slice_obj.start is not None and slice_obj.start < 0) or (slice_obj.stop is not None and slice_obj.stop < 0) ): raise ValueError('Negative indexing is not supported.') if slice_obj.step is not None: raise ValueError('Step argument is not supported.') self.low = 1 if slice_obj.start is None else int(slice_obj.start) + 1 self.length = None if slice_obj.stop is None else int(slice_obj.stop) - self.low + 1 else: raise TypeError('Argument to slice must be either int or slice instance.') self.expression = f_obj ```
Please use f-strings as Python 3.6+ is now the requirement More information is available including some benchmarks. https://cito.github.io/blog/f-strings/
Where is it taken care of that a `Ref` will already exist in the inner query? Might be nice to have that information here.
Oh, of course, sorry. Totally missed the loop somehow. Ignore this, I think it's fine as-is.
Use hanging indentation: ```suggestion raise exceptions.FieldError( "Cannot compute %s('%s'): '%s' is an aggregate" % (annotation.name, name, name) ) ```
```suggestion if expr.contains_aggregate and isinstance(expr, Ref) and expr.refs in kwargs: ```
We can also go faster by using a list comprehension instead of a generator - they're cheaper to create: ```suggestion obj.combined_queries = tuple([query.clone() for query in self.combined_queries]) ``` Simple benchmark: ``` In [2]: items = [1, 2, 3, 4] In [3]: %timeit tuple(x*2 for x in items) 508 ns ± 10 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [4]: %timeit tuple([x*2 for x in items]) 358 ns ± 14.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
Yes it should be `R.p`, we didn't take into account nested protected relations in the ab3cbd8b9a315911248227208630a020cedca08f (probably my fault). Also casting to list is not necessary anymore after this change.
Do we need to use `self.restricted_objects` multiple times? I would simplify this, e.g. ```python for model, fields in self.restricted_objects.items(): for field, objs in fields.items(): for obj in objs: raise RestrictedError( "Cannot delete some instances of model '%s' " "because they are referenced through a restricted " "foreign key: '%s.%s'" % ( model.__name__, obj.__class__.__name__, field.name, ), objs, ) ```
I'd use `assertRaisesMessage()` with `Cannot resolve keyword 'foo' into field. Choices are:` -- there's not much value in a regex for the choices, I think.
I'm always wary of putting assertions inside loops and if-statements because you're never certain they are executed. If you added a counter and an assertion that `count==1` after the loop, that would be defensive.
I find binary operators very legible for set operations: `self.keys - keys`
don't need variables here
It would be fine to put this in a separate test class so it can have a `setUpTestData` method to avoid the delete() and redundant object creation
You could avoid the delete query with: `AggregateTestModel.objects.none().aggregate(...)`. (I guess the other tests could use the same pattern, not for this PR though.)
This test doesn't fail with or without the patch applied so it's likely unnecessary.
`assertEqual` the 's' version is a deprecated alias
That's what `inspect.iscoroutinefunction(getattr(Foo, '__call__', None))` does above. What I mean is that it's probably an abuse of Python data model. For example, ```python def Test: async def __iter__(self): pass assert inspect.iscoroutinefunction(Test.__iter__) ``` Won't fail but `__aiter__` should be used for this purpose. There's no analogous `__acall__` for `__call__` and it's not clear to me whether `async def __call__` is an abuse or not.
Sorry, wasn't trying to request a change, was thinking about how async middleware would be written and just seeking clarification.
use a single line
Is this possible? If so, it will be good to cover this scenario with tests.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
This should be changed also in the `PostgresIndex`.
Add trailing comma.
A bit unrelated, but I would move the closing parenthesis to improve readability: ``` statement.parts['extra'] = ' WITH (pages_per_range={})'.format( schema_editor.quote_value(self.pages_per_range) ) + statement.parts['extra'] ```
I think this would be slightly cleaner: ```python if self.condition is None: return '' query = Query(model=model) query.add_q(self.condition) compiler = query.get_compiler(connection=schema_editor.connection) # Only the WhereNode is of interest for the partial index sql, params = query.where.as_sql(compiler=compiler, connection=schema_editor.connection) # The base schema editor does the same map on the params, but since it's # handled outside of that class, the work is done here return ' WHERE ' + (sql % tuple(map(schema_editor.quote_value, params))) ```
Please check test coverage carefully. I didn't spot a test for this change.
This should be Django's vendored copy `from django.utils import six`
sort mock before override_settings to fix isort build failure
But now the imports aren't alphabetized anymore... :)
Yes, it looks good.
In general, this utility is long overdue. In detail, I think error_prefix is odd here -- you're essentially mixing a piece of error formatting (or even logging) with the function.
You can have a flatter function (less nesting) by doing: ```python if not remote_field: continue ```
This should only be performed if the `relations` registry is already computed; `if 'relations' in self.__dict__`
```suggestion self.resolve_model_field_relations(model_key, name, old_field) ```
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
`output_format` → `format` `**kwargs` → `**options`
Trailing space in string not required.
Trailing space in string not required.
Isn't this equivalent? ``` if (start and start < 0) and (end and end > 0): raise ... ```
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Using `clashing_pair` in a hint is misleading. We should use appropriate model names not field names or table names.
Chop blank line.
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
Add a trailing comma.
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
Lastly we should mention what the specific issue is about the link in the helptext 🙂 ```suggestion def test_bug_34066_link_to_password_reset_in_helptext(self): # The password reset link should always refer to the primary key even when accessed via a to_field ```
sss :snake: ```suggestion password_help_text = form.fields["password"].help_text ```
Yes, f-strings should use only plain variable and property access as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
On second thoughts creating a URL with to_field isn't required to test this issue – so the string interpolation can simply be removed: ```suggestion admin_user_change_url = reverse( "admin:%s_%s_change" % (user._meta.app_label, user._meta.model_name), args=(user.username,), ) ```
Just got a typo here 😁 ```suggestion # assert joined_url and pw_change_url are identical ```
Is this possible? If so, it will be good to cover this scenario with tests.
I fixed this issue in fe0ddbc84e4d8836ce8d27a1218d360c5482c2be.
`# Store ... warning message.`
A system check seems a good option if the warning would be too noisy.
This wouldn't happen on every request, just on server restart (when `load_middleware()` is called)
more than one automatically generated field.? sounds better and more natural with the changes.
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
`form_class` is defined in `RangeField.formfield()` so this is redundant.
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
It might be worth compiling the regexp in the class or [module level and reuse](https://github.com/django/django/blob/master/django/contrib/localflavor/ca/forms.py#L16-L17).
I think this should work: ``` python connection = connections[db] if connection.settings_dict['ENGINE'] != 'django.db.backends.dummy': loader.check_consistent_history(connection) ```
Not sure if this might mask some exceptions, but here's what I came up with for now: ``` python for db in connections: connection = connections[db] try: connection.cursor() except ImproperlyConfigured: # Raised by the dummy backend. pass else: loader.check_consistent_history(connection) ```
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
You can rebase your branch and target it for Django 2.0. Since master no longer supports Python 2, you can make a few updates such as using `super().`.
Just make it: ``` if len(expressions) < 2: ``` That avoids problems with sqlite and mysql. GREATEST(x) is always x on backends that support single arguments anyway.
Please add trailing commas to all of these new assertions, e.g. ```suggestion )['sum_awards'], None, ```
This assertion is not related with the patch. Please remove it.
`Count(..., distinct=True)` is already tested in `test_count()` and it is not related with this patch, so we can refactor tests but in a separate commit, e.g. - 1st commit: _"Moved test for distinct Count() to a separate test case."_: ```diff diff --git a/tests/aggregation/tests.py b/tests/aggregation/tests.py index ea11c02edc..2f667a0fe1 100644 --- a/tests/aggregation/tests.py +++ b/tests/aggregation/tests.py @@ -388,9 +388,6 @@ class AggregateTestCase(TestCase): vals = Book.objects.aggregate(Count("rating")) self.assertEqual(vals, {"rating__count": 6}) - vals = Book.objects.aggregate(Count("rating", distinct=True)) - self.assertEqual(vals, {"rating__count": 4}) - def test_count_star(self): with self.assertNumQueries(1) as ctx: Book.objects.aggregate(n=Count("*")) @@ -403,6 +400,10 @@ class AggregateTestCase(TestCase): ) self.assertEqual(aggs['distinct_ratings'], 4) + def test_distinct_on_aggregate(self): + books = Book.objects.aggregate(Count('rating', distinct=True)) + self.assertEqual(books, {'rating__count': 4}) + def test_non_grouped_annotation_not_in_group_by(self): """ An annotation not included in values() before an aggregate should be ``` - 2nd commit, fix and extra test cases (with `self.subTest`), e.g. ```python def test_distinct_on_aggregate(self): for aggregate, expected_result in ( (Count, 4), (Sum, 16.5), (Avg, 4.125), ): with self.subTest(aggregate=aggregate): books = Book.objects.aggregate(ratings=aggregate('rating', distinct=True)) self.assertEqual(books['ratings'], expected_result) ``` Also, I think that `Book.rating` would be better for testing `distinct` argument.
I don't think that we need `Approximate()`.
Explicit cast to `str` is unnecessary.
`to_python()` (add parens)
Please update your patch.
I would call `clean()` in validation tests, we should also move it to a separate tests, e.g. ```python def test_invalid_value(self): field = models.DecimalField(max_digits=4, decimal_places=2) msg = '“%s” value must be a decimal number.' tests = [ (), [], {}, set(), object(), complex(), 'non-numeric string', b'non-numeric byte-string', ] for value in tests: with self.subTest(value): with self.assertRaisesMessage(ValidationError, msg % (value,)): field.clean(value, None) ```
I noticed a different behavior for floats lower than `1`, they aren't rounded e.g.: ```python >>> f = models.DecimalField(max_digits=4, decimal_places=2) >>> f.to_python(0.0625) Decimal('0.0625') >>> f.to_python(0.00625) Decimal('0.006250') >>> f.to_python(0.000625) Decimal('0.0006250') >>> f.to_python(0.0000625) Decimal('0.00006250') ``` Maybe that's ok and I missed something.
You can drop this line.
I remember looking at this test when merging 233c70f0479beb3bff9027e6cff680882978fd4d. I just tested this now and if you use `with register_lookup(field, Exactly, lookup_name='exact'):`, then this is the state at the end of the test: ``` >>> Author._meta.get_field('birthdate').get_lookup('exact') <class 'custom_lookups.tests.Exactly'> ``` With the current code, the output is `<class 'django.db.models.lookups.Exact'>` which looks correct to me. So I'd leave this as is and remove the unused `CustomExactLookup`.
Hmm it's not clear to me what this test is trying to accomplish, what's the purpose of `CustomExactLookup` in the first place since it's `Exactly` that is registered.
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
I'd omit the blank line since it's hard to get confused in 3 lines of code. Also the commit message could describe the issue being fixed instead of the implementation of the fix.
Black won't mind. 😀
Remove as `empty_strings_allowed = False` is inherited from `IntegerField`.
Yes, `override_settings_tags()` should no longer be necessary. Please change it to the `override_settings()`.
drop the new line please
The form class is configuration too, is it not? You can group class attributes using a blank line, but this attribute is inherited from `BaseModelAdmin` where it is not separated. It just seemed odd.
Could everything from here be extracted into a helper function? So we'd just pass in the `ordering` and return whatever came back. (This would give a hook for opt-out/customisation that both 17198 and 29943 hint at.)
I would multiline: ``` field.attname for field in self.lookup_opts.fields if field.unique and not field.null ```
May as well do the following as a field name can only legally have a single `-` at the start: ```python field_name = part.lstrip('-') ```
```python if ordering_fields.issuperset(field.attname for field in fields): ```
I'd remove this blank line.
True, but they test the behavior of the respective operations. It's true that `test_state.py` has a few tests that check for the correct `state_forwards()` behavior, though those tests are focused on the bigger picture of how `ProjectState` and `ModelState` work. Whereas `test_operations.py` tests for the particular implementations of the different migration operations, and as such should hold (regression) tests that focus on a particular implementation of such an migration operation. Thus, `test_operations.py` sounds like the right choice to me.
I think so -- all code changes should be tested unless it's infeasible to do so.
Yeah, looking at those test modules, I think they deserve some cleanup.
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
is this meant to test the `except TypeError` branch in `contrib.auth.authenticate()`? It would be clearer to call that function directly.
prefer `setUpTestData` since that executes once per test class instead of once for every method
Please use assertRaisesMessage to verify this is the ValueError we expect.
You should be able to pass `is_active=False` to `create_user()`.
reword: "force_login() skips authentication backends without a get_user() method."
no newline between fields (see style of other forms) Also, I don't think `label` and `initial` need to be specified. Try to include only the minimum functionality that's needed to reproduce the error and prove the regression is fixed.
please limit line lengths so horizontal scrolling isn't required, something like: ``` self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> ' '...' ) ```
Please move `)` to a new line: ``` py return self._html_output( normal_row='<p%(html_class_attr)s>%(field)s %(field_name)s</p>', error_row='%s', row_ender='</p>', ) ```
You don't need to use `"""..."""` here: ``` py self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> custom' '<input id="id_hidden1" name="hidden1" type="hidden" />' '<input id="id_hidden2" name="hidden2" type="hidden" /></p>' ) ```
Same here: ``` py self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> custom</p>\n' 'rest of the HTML' ) ```
I'm not sure if it's a good idea to define it in `setUp`, let's define it in the method where it is used.
```suggestion self.rs = GDALRaster(rs_path) ```
```suggestion rs_path = Path(__file__).parent / "data" / "rasters" / "raster.tif" ```
I'd put this in a separate test method.
I think we should have a test and handling for the case where `mimetypes.guess_type()` returns `None` as done in `_create_attachment()`.
missing period the message could be: "Query lookup '%s' is deprecated in favor of Meta.default_related_name '%s'."
Use `warnings.simplefilter('once')` in this case. There has been a lot of stuff moving around lately in the `Field` and `_meta` API andI just want to make sure the backward compatibility shim you added doesn't use deprecated stuff itself.
I would assert `len(warns) == 1`.
no `u''` prefix -- use `from __future__ import unicode_literals` if you need it.
I think we could swap this and the previous `if` over - no reason to do the `has_related` check if we've specified the list. Alternatively, move the `has_related` inside an `if ... is False`
Might be nice to copy `__doc__` here as well
If `cx_oracle` is installed, there's an error: ``` File "/home/tim/code/django/tests/backends/test_cursors.py", line 33, in OracleCursorOptionsTestCase class OracleLoggingCursor(LoggingCursorMixin, Database): TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases ``` Also, is this file doing anything useful? I don't see any test methods.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
An aside: I see the reference to `EggLoader`. Haven't Python "eggs" been pretty much obsolete for ages? Can we remove this or the bits that are related to "eggs"? (Something to create a separate ticket for, if so.)
This check is redundant. `skipUnless` already guarantees that we have MySQL. You can remove the `try ... except` leaving only `import`.
``` 'BinaryField default cannot be a string, use bytes content ' 'instead.' ```
I don't see much value in using `self.subTest()` here.
We can use one model with two fields instead of two models.
Could you rename the field to `RemovedField` given the test case name.
Makes sense. Lets go with `MyField` then.
@NDevox I'd be very happy for you to do that. 🙂 (If it's just a single file cleanup, you can just make a PR, without the Trac ticket)
variable could be omitted
assertEquals is deprecated. Please use assertEqual instead.
I wouldn't include this test in the PR because it's testing existing behavior. But it doesn't seem needed as there's a test in `test_client_regress` that fails if the `isinstance(data, dict)` check is `_encode_json` is removed.
I think this test isn't working as expected -- it's resolving to `RedirectView`, same with `test_inline_urls` -- probably the result of the resolve should be checked.
Please including a trailing comma in the last item of a dictionary so if more items are added we don't need to modify this line again.
You don't need the trailing \ here. EDIT: I see you just moved that code, that's fine.
Include a trailing comma in lists like these to allow adding more items later without having to modify this line again. Also, use single quotes rather than double. (We're using single quotes in new code except if the string contains a single quote.
I'm surprised if `str()` is doing something here since `capfirst()` also has some `str()` calls.
``` is_multipart = context['adminform'].form.is_multipart() or any( admin_formset.formset.form().is_multipart() for admin_formset in context['inline_admin_formsets'] ) ```
I see :/ Well `force_str` should still save you the promise checks.
I think you should use `force_text` here since the regex match can't be a promise and `force_str` aliases it on Py3.
migrations isn't used
As multiple addresses are allowed, I suggest "to one or more addresses specified ...".
You can use `type='choice'` with `choices=['ipython', 'bpython']` for options with a predefined set of choices: http://docs.python.org/library/optparse.html#optparse-standard-option-types
You aren't changing here, except for the style. Please revert.
Maybe: ```suggestion '' if not self.fields else 'fields=%r ' % self.fields, ```
Yes a separate PR with unification sounds good.
We could keep the same format as in indexes: ```suggestion return '<%s: %sname=%r%s%s%s%s%s>' % ( self.__class__.__name__, '' if not self.fields else "fields='%s' " % ', '.join(self.fields), self.name, '' if not self.expressions else " expressions='%s'" % ', '.join([ str(expression) for expression in self.expressions ]), ```
Please check test coverage carefully. I didn't spot a test for this change.
~~I changed this to an assertion for the only file that is affected by the second round of post-processing i.e. `cached/relative.css`.~~
I think we can move `msg` to the assertion, I don't see much value in creating a temporary variable here.
Can you re-warp this block to 79 chars? (First line is too short.)
@slafs non-existing setting names, e.g. `TEST_SETTING=True`
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
I noticed a different behavior for floats lower than `1`, they aren't rounded e.g.: ```python >>> f = models.DecimalField(max_digits=4, decimal_places=2) >>> f.to_python(0.0625) Decimal('0.0625') >>> f.to_python(0.00625) Decimal('0.006250') >>> f.to_python(0.000625) Decimal('0.0006250') >>> f.to_python(0.0000625) Decimal('0.00006250') ``` Maybe that's ok and I missed something.
I think most assertEqual don't include a comma on this line.
chop blank line
Using hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). e.g. ```python self.assertEqual( nformat(Decimal('1e16'), '.', thousand_sep=',', grouping=3, force_grouping=True), '10,000,000,000,000,000' ) ```
chop blank line
Personally if it were happening to me, I'd be **thrilled** if it could tell me what needs applying, and if it couldn't and instead directed me to another command to run I'd _assume_ (and be disappointed) that the information wasn't available at the time the exception occurred. If it is there, I think it's prudent to respect the user's needs and attempt to surface the information. That said, my gut feeling is that the exception output format maybe isn't "right" (for a given value thereof). I can't recall many (any?) places where Django raises with an arg which is multiple lines. Those cases where there's multiple _things_ to enumerate tend to just get comma separated. That does leave the door open to super long lists though, if for whatever reason the partially applied list was big... Maybe because it's related to running migrations, which _are_ line oriented, it's OK? [Edit to add: big thumbs up from me to the information, FWIW. Next step seems much clearer as a result]
State the expected behavior: MigrationLoader.check_consistent_history() should ignore unapplied squashed migrations that have all of their `replaces` applied.
Ahh didn't notice that. I just remembered a recent commit that converted many of those to literals.
You could use a set literal here.
Could you sort those in reverse order (to be applied first: top ; to be applied last: bottom), please. Same for the other cases in this test.
) on next line
should this be super()
@charettes, any reply here? I guess we shouldn't block the patch about the issue with backwards migrations if we can't find a simple solution.
Ah, didn't know this existed yet. I see that this PR is mostly a "copy" of the ContentTypes one. Sounds alright for now, then.
I guess some tests might be needed for the router stuff.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Indexes are not constraints, generally.
This should likely be `'%s_validate_%s'`
`constraint_name` should also be quoted.
I would chop _" on all existing rows"_.
Rather than passing all of `OPTIONS` here we should only pass the protocol: ```suggestion def __init__(self, protocol=None): self._protocol = pickle.HIGHEST_PROTOCOL if protocol is None else protocol def dumps(self, value): return pickle.dumps(value, self._protocol) ```
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
We could flatten this? ```suggestion return default if value is None else self._serializer.loads(value) ```
We avoid backslashes and use this style: ``` msg = ( "Redirection loop for authenticated user detected. Check that " "...." ) ```
Please use assertRaisesMessage to check the message too. We prefer the context manager version usually `with self.assertRaisesMessage(ValueError, msg)`. I think combining the two tests so you can reuse the `msg` variable would be fine.
argument -> a GET parameter
URL should be capitalized
"Stay on ..." (and please be consistent with no spacing around the sentences) Add a period to each sentence too.
We can drop meta ordering and add it to the queryset: ``` self.assert_pickles(c.concrete_events.order_by('event)) ```
You could get away with something a bit more compact than that I think -- you don't need to wrap the text in parentheses, and you probably shouldn't split up the class name just to adhere to PEP8, line length isn't a big worry. Same goes for the other instance. ``` python expected = [ Error( "Field is using a table that has already been " "registered by <class 'invalid_models_tests.test_models.Bar'>.", hint=None, obj=Foo._meta.get_field('bar'), id='fields.E340' ) ] ```
Again, this could be a class level attribute.
Do we expect users to use strings like `&&` and `&` directly anywhere else? It seems like we're exposing an implementation detail we'd usually hide.
It'd be great we if we could avoid creating 5 new tables to reproduce the issue. Existing ones should be reusable somehow.
TBH I don't much value in testing Python's error messages, `self.assertRaises(TypeError)` should be enough.
OK, it was just a shot in the dark :dart:
I think these are too internal, I would rather check that `MultiValueDict` is pickleable: ```python pickle.loads(pickle.dumps(...)) ```
Please use hanging indent here and below in `assertEqual`: ``` data = [ {'0': 'a', '1': '42'}, ] ```
Use `hash()` instead of `__hash__()`, e.g. ```suggestion self.assertNotEqual(hash(exception_str), hash(exception_list)) ```
These assertions are not related with a bugfix, please move them to a separate commit.
use `self.assertIs(..., False)` (`assertFalse` checks `bool(val) is False`)
Can we adjust the test name. We know this is `modelchoicefield`, because the whole `TestCase` is called that, so we can drop that. Maybe... `test_initial_accepts_model_instance_for_validation_when_field_disabled`? It's a bit long and horrible but... (???: suggestions welcome!)
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
No need for the `u` prefix, we're already importing `unicode_literals`.
no dash in "email"
I'd include the min length in the error message
Not sure how much a difference it makes, but it seems better to store this in Python rather than having to read from a text file. Worth it to make the file location customizable? If so, it might be nice to make "common passwords" a separate package so we don't have to include that list in Django. I guess users might not care for the additional setup tasks though.
its so that, for example, a ...
Since the list is in order of most common use, the code detects incorrect passwords slightly faster if you preserve the order. :bikeshed:
suggested wording: "SystemExit is raised if the user answers "no" to the prompt asking if it's okay to delete the test tablespace."
Maybe a `self.patch_execute_statements(self._execute_raise_tablespace_already_exists)` helper method could avoid repetition and long lines requiring unusual indentation.
I'd split this line in two
`len(statements)` => `statements`
I guess we have poor organization where some tests are organized by class (test_creation/features) and others are organized by database (test_mysql). I'm not requiring a change here but it would be nice to think about how we want to do this going forward.
Is this line correct? Above it's `subTest(url=url_name)` but then we `reverse(url_name,...)`
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
Should use `assertRaisesMessage()` to verify the string also.
Prefer the context manager version: ``` self.assertRaises(Resolver404): resolve(url) ```
I try to avoid "we", e.g. The check allows a double slash, presuming the user knows....
This is only used once, so I don't see why it needs to be a method.
I think this can be in single line: ``` url = reverse('admin:auth_user_add', current_app=self.admin_site.name) ```
This one as well
state the expected behavior, e.g. `The last choice is for the None value.`
I removed these assertions.
Why do you continue here? `app_label` might still be invalid.
don't need the trailing comma
@hramezani I think you removed `setattr(options, opt_name, os.path.normpath(opt_val))` by mistake. My proposition was to remove only `else`, i.e. ```python if '.' in opt_val: print('Aborting: --%s must be a top-level module.' % opt_name.replace('_', '-')) sys.exit(1) setattr(options, opt_name, os.path.normpath(opt_val)) ```
IMO `else`is unnecessary i.e. ```python if '.' in opt_val: ... setattr(options, opt_name, os.path.normpath(opt_val)) ```
Looks good, my mistake.
Please rewrite `@override_settings` into a single line: ```python @override_settings(STATICFILES_DIRS="a string") ```
Probably the check functions should be called directly rather than invoking them through `run_checks()` (otherwise, this runs all registered checks across all installed apps which doesn't provide good isolation) -- see `tests/check_framework`.
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
use `reverse()` rather than a hard coded URL.
And I would rename this attribute `superusers` as it's meant to contain multiple users.
suggested wording: `Context.push() with a Context argument should work (#24765).`
`assertEqual` is fine here (also note that we use `assertEqual`, not `assertEquals` in Django)
please insert tests on line 1029, after the `setUp`/`tearDown` helpers `create_table` and `drop_table`
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
I think you can use `with self.assertRaisesMessage` equivalently here (context manager form is much easier to read IMO)
Combining this commit with the next one seems fine. It works the same as override_settings, but you can use `with self.settings`.
Use single quotes unless a string contains double quotes. Also, this looks fine to fine on the line above.
this doesn't seem relevant since we're testing with dry run anyway.
```suggestion backend = self.base_params['BACKEND'] ```
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
I think this check should go before `if keepdb:` in line 40; with the current code, if the database doesn't exist and `keepdb` was specified, and anything went wrong, creation will be silently skipped and this is incorrect.
`will re-opened in to ...` should maybe be something like `will re-open in ...`
`VACUUM INTO` was [added in 3.27.0](https://sqlite.org/releaselog/3_27_0.html). This would bump requirements in `databases.txt` and `check_sqlite_version()` check in `django/db/backends/sqlite3/base.py`
You should try to reuse `connection._connect_string()`.
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
A list comprehension is preferable here as `str.join()` converts to list internally anyway. It is better performance to provide a list up front. - https://stackoverflow.com/questions/9060653/list-comprehension-without-in-python/9061024#9061024 - https://github.com/adamchainz/flake8-comprehensions/issues/156 ```suggestion result = ', '.join([ f'{field} = VALUES({field})' for field in map(self.quote_name, update_fields) ]) ```
`update_fields` should always be passed, so there is no need to use `update_fields or ()`.
```suggestion result = ', '.join(f'{field} = VALUES({field})' for field in map(self.quote_name, update_fields or ())) ```
Use `self.quote_name()` to do the quoting of fields: ```suggestion result = ', '.join(f'{field}=VALUES({field})' for field in map(self.quote_name, update_fields or ())) ```
You don't need to add the brackets with `join()`.
Passing `filter` to kwarg will cause it to be in `self.extra` as well which could interfere `as_sql()` formatting.
I think that you can add `filter` to `kwargs` in `__init__` method and remove redundant `__repr__` (see #8759).
Shouldn't be part of this PR, but it looks like redundancy in `__repr__()` methods would be a good candidate for a refactor.
Please use single quotes.
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
```suggestion def _insert( self, objs, fields, returning_fields=None, raw=False, using=None, on_conflict=None, update_fields=None, unique_fields=None, ): ```
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
```suggestion unique_fields=unique_fields, ```
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
This hook is unnecessary, IMO. I would move the logic to `_select_on_conflict()`.
I guess Article/Category deletes aren't doing anything since you already asserted exists() -> False. Anyway, I think I'd put this in a separate method. `test_loading_with_exclude_app` / `test_loading_with_exclude_model`
Does `serializers.serialize` write bytes or text to the stream? In the case of the later we should probably use codecs.open or similar (for py2 at least)
It looks like this test is failing when run alongside other test apps with invalid models. I think you can change this assertion to check for the presence of at least the expected error: ```suggestion errors = checks.run_checks() expected = checks.Error(msg='SITE_ID must be an integer', obj='sites.E101') self.assertIn(expected, errors) ```
`stream=open(output, 'w') if output else self.stdout`
`pk` is twice. I think the last `and pk` can be removed.
```suggestion category=RemovedInDjango51Warning, ```
@pahko `2` , `3` and non-empty lists and objects also will be valid case. Only check for boolean is needed here.
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
This warning should be tested.
Another option could be to refactor into 3 separate test methods that call a common helper method to run the logic currently in the loop. This can be easier to debug than assertions that run within a loop.
The only place I can vaguely remember `repr` being used is during the migrations. If you have the `AddIndex/RemoveIndex` operation in your migrations file, it shows this representation when the migrations are run. Since it is very common that a dev might want to create multiple gin indexes in the same table, it is necessary to have the `fields` of the index as well to distinguish the representation of these indexes. So, my decision would be based on how commonly devs have two gin indexes in the same model with the same fields but with different values of `fastupdate` or `gin_pending_list_limit`. If it is a very common case we might want to keep them in `repr`.
It looks like there will be a SQL syntax error due to a trailing comma if gin_pending_list_limit is used without fastupdate. Maybe `with_params` should be a list and joined with `', '`.
Tests for this method seem missing. It seems like we need a better way to build these reprs that's not so complicated and repetitive for each index.
Do you see much value in Django validating this? The error message from PostgreSQL seems clear: `django.db.utils.DataError: value 1 out of bounds for option "gin_pending_list_limit" DETAIL: Valid values are between "64" and "2147483647".
I think that `2**31 - 1` instead of `2147483647` is more readable.
I guess we could go with just ._clone() and ._chain(). If we want to allow for "in place" querysets, we could just add `clone` argument to chain. If set to False, it effectively does what ._pre_next_op() does right now.
This should be called first, i.e. ```suggestion def __getstate__(self): state = super().__getstate__() for attr in self.meta_non_picklable_items: if attr in state["META"]: del state["META"][attr] return state ```
Thanks, the current approach LGTM. Please uncheck "Patch needs improvement" flag on the ticket after local testing.
I think we should copy `fields_cache`: ```suggestion state['_state'].fields_cache = state['_state'].fields_cache.copy() ``` because a copy of model instance can use the same values and we don't need to fetch it again.
My concern with adding `copy()` is that it is adding in redundant work for most cases to appease a small subset of very specific use cases.
Maybe you've missed `if summarize` branch (below).
You can drop the `.contains_column_references` as it's wasteful in this case because of the way it walks the expression tree given we'll have to walk it anyway below.
All `Col` should have an `alias`.
Add a period to the end of the exception message.
We used the same message as in other places that's why I don't want to add a period only in this case.
This can be moved outside of `try...except...`.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Do we need an inner import? `from . import urls` should work fine.
Use single quotes.
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
You changed the first `_` to capture `field`, but it's not subsequently used.
Maybe: _"Ensure the last element is a field or a transform."_ :thinking:
Maybe you've missed `if summarize` branch (below).
We used the same message as in other places that's why I don't want to add a period only in this case.
Add a period to the end of the exception message.
You can use `super()`: ```suggestion return super().migration_name_fragment + '_not_valid' ```
Chop blank line.
I would chop _" on all existing rows"_.
Do we need to call `str()` on `contraint_sql`? ```suggestion if contraint_sql: schema_editor.execute(constraint_sql + ' NOT VALID') ```
Maybe: ```'Create not valid constraint %s on model %s'```
You're writing to the database. You need those changes to be reset. You need to be using Django's `TestCase`, rather than `unittest.TestCase`.
@slafs non-existing setting names, e.g. `TEST_SETTING=True`
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
> Or should I just check that those settings doesn't exist outside the context? I think that'd work.
There's no need for the `disconnect` function. ```suggestion self.addCleanup(signals.post_init.disconnect, post_signal, sender=Book) ```
I _think_ that `Ref` will also need to return True, since it is a named reference to an existing `Col`.
F() expressions aren't the only ones that can refer to other columns in the query. How about Q(other_field__isnull=True). Also, expressions are free to resolve columns of the query without using F-expressions. We need some other way to know if the expression refers to columns of the query. Maybe we could first resolve the expression, the check for Col references? That might be better. The check should be done in the expression, so that the expression tells Django if it is referring to any columns. Making the compiler guess this is the wrong way in my opinion.
Just a thought -- would an `expression.flatten()` method be useful? The check below would then be `any(expr for expr in expression.flatten() if isinstance(expr, F))`. Might need to look more closely at other places in the ORM to figure out if it'd be a useful construct.
Inner functions are slow, especially for pypy - best to extract this!
You aren't changing here, except for the style. Please revert.
We need to add the same check to `remove_index()`.
I would add a flag to `Index`, e.g. `is_functional` that could be used here together with `supports_expression_indexes` to skip such indexes, e.g. ```python if not index.is_functional or self.connection.features.supports_expression_indexes: output.append(index.create_sql(model, self)) ``` Also we should return `None` in `_create_index_sql()` and `_delete_index_sql` if `index.is_functional` and `self.connection.features.supports_expression_indexes`
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Not a blocker or anything but `concurrently` seems more appropriate than `concurrent` for the kwarg name to me. e.g. `add_index(model, index, concurrently=True)`
Here we also should call `super` and not copy-paste code
We don't need to add `named` branches everywhere. I'd return `m` in the tuple and use it when needed. Moreover, we could use a generator instead of list. IMO, `_find_group()` is unnecessarily complicated and unreadable. I'd move `get_group_start_and_end_indices()` to a module hook `_get_group_start_end()`: ```python def _get_group_start_end(start, end, pattern): unmatched_open_brackets, prev_char = 1, None for idx, val in enumerate(pattern[end:]): if val == '(' and prev_char != '\\': unmatched_open_brackets += 1 elif val == ')' and prev_char != '\\': unmatched_open_brackets -= 1 prev_char = val if unmatched_open_brackets == 0: return start, (end + idx + 1) ``` and simplify `_find_groups()` to a few lines generator: ```python def _find_groups(pattern, group_matcher): prev_end = None for m in group_matcher.finditer(pattern): if indices := _get_group_start_end(m.start(0), m.end(0), pattern): start, end = indices if prev_end and start > prev_end or not prev_end: yield start, end, m prev_end = end ``` now you can use `m` when needed, e.g.: ```python def replace_named_groups(pattern): group_pattern_and_name = [ (pattern[start:end], match[1]) for start, end, match in _find_groups(pattern, named_group_matcher) ] for group_pattern, group_name in group_pattern_and_name: pattern = pattern.replace(group_pattern, group_name) return pattern ... def replace_unnamed_groups(pattern): group_start_end_indices = _find_groups(pattern, unnamed_group_matcher) final_pattern, prev_end = '', None for start, end, _ in group_start_end_indices: if prev_end: final_pattern += pattern[prev_end:start] final_pattern += pattern[:start] + '<var>' prev_end = end return final_pattern + pattern[prev_end:] ... ```
Such an extensive docstring is not necessary, IMO.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
This code is almost the same as in `replace_unnamed_groups()`, the only difference is that the beginning of non-capturing group is longer i.e. `'(?:'` instead of `'('`. We could add an internal hook and use it in both places, e.g. ```python def _find_groups(pattern, group_matcher): group_indices = [ (m.start(0), m.end()) for m in non_capturing_group_matcher.finditer(pattern) ] # Loop over the groups. for start, end in unnamed_group_indices: ... for idx, val in enumerate(pattern[end:]): ... if unmatched_open_brackets == 0: group_indices.append((start, end + idx + 1)) break # Remove unnamed group matches inside other unnamed capture groups. group_start_end_indices = [] prev_end = None for start, end in group_indices: if prev_end and start > prev_end or not prev_end: group_start_end_indices.append((start, end)) prev_end = end return group_start_end_indices ``` Moreover, with some boolean flags (e.g. `named=True/False`) this could also be reused in `replace_named_groups()` :thinking: .
In the pattern I provided, the `'Z'` is a plain `'Z'` (because the backslash preceding it is escaped), but your substitution line is removing it.
Happy with that. As long as the all of the `.as_*()` methods are tested independently then we can switch to the `<div>` output for the default case and not worry.
Can we drop this change, using `silence_checks` with `override_settings` just on specific tests? (We're not removing the current approach no?) — It leads to a lot of noise on the PR. 🤔
```suggestion # RemovedInDjango50Warning: When the deprecation ends, revert to # FORM_RENDERER="django.forms.renderers.Jinja2", ```
We could simplify this and also be explicit rather than assuming that the Django renderer is the default? ```suggestion import inspect from django.test.utils import override_settings TEST_SETTINGS = [ { 'FORM_RENDERER': 'django.forms.renderers.DjangoTemplates', 'TEMPLATES': {'BACKEND': 'django.template.backends.django.DjangoTemplates'}, }, { 'FORM_RENDERER': 'django.forms.renderers.Jinja2', 'TEMPLATES': {'BACKEND': 'django.template.backends.jinja2.Jinja2'}, }, ] def test_all_form_renderers(): def wrapper(func): def inner(*args, **kwargs): for settings in TEST_SETTINGS: with override_settings(**settings): func(*args, **kwargs) return inner def decorator(cls): for name, func in inspect.getmembers(cls, inspect.isfunction): if name.startswith('test_'): setattr(cls, name, wrapper(func)) return cls return decorator ``` (I've not tested this, but it should give you an idea.)
Please add trailing comma.
You can reuse `resolve_model_field_relations()`.
```suggestion self.resolve_model_field_relations(model_key, name, old_field) ```
Are you sure this branch is ever skipped? AFAIK `auto_created` models are not part `ProjectState.models` entries.
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
That's not "cruft" -- that's making user code look like it was written after Python 2.4 was released. And also, ``` python @classmethod @queryset_only def as_manager(... ``` does work.
This would be more readable as a one-liner: `predicate = inspect.isfunction if six.PY3 else inspect.ismethod`
Might be nice to copy `__doc__` here as well
This inner import is a syndrom of the circular dependency between `Manager` and `QuerySet`. Could we avoid it by moving this code inside `_Manager`? `Manager` would know how to create a subclass of itself with the methods of a given `QuerySet`.
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
dependency graph (no dash) I think you mean "intra-app" rather than "in-app"
is the helper method a stylistic change only? makes review difficult.
use dict comprehension: `{op: set() for op in ops}` (although maybe you could use defaultdict too)
I'd keep this on one line for better readability
Could you please keep the cross-app reference that we had before.
URL patterns may change over time, so we can restore the different match :thinking:
I think we should copy `fields_cache`: ```suggestion state['_state'].fields_cache = state['_state'].fields_cache.copy() ``` because a copy of model instance can use the same values and we don't need to fetch it again.
Thanks, the current approach LGTM. Please uncheck "Patch needs improvement" flag on the ticket after local testing.
I learned a bit from this about memoryviews. Thank you! It might not be worth it, since it's premature optimization, but if you are in the mood, here are a few ideas: 1. Assign the copied bytes to a local variable list and only add them to the state if the list is non-empty. This saves a dictionary entry if no memoryviews exist, and it saves a hash lookup into the state for each memoryview (when appending to the list). 2. Pop entries from the state after creating the local variable list. This would allow iterating over state's items without copying them into a list.
We should be able to iterate now though `state.items()` directly without making a copy because state is no longer being mutated in the body of the loop.
`t` is unnecessary, IMO.
True, thanks :+1:
I know but it's not worth complexity, we can use ```python stream = open_method(output, 'wt', **kwargs) if output else None ``` in `dumpdata` and ```python with open_method(filename, 'rt') as f: ``` in tests.
Do we need a separate variable? I would include it directly in the `compression_formats`: ```python compression_formats['lzma'] = (lzma.open, {'format': lzma.FORMAT_ALONE}, mode) ```
This check is also redundant.
Why the `CombinedExpression` and not `Expression`? IMO it's misleading, I know that `CombinedExpression` has the concept of right-hand and left-hand sides but for other purposes.
The SQL function `COALESCE` can be called with a single argument (at least on PostgreSQL). That might not be useful, still I believe Django shouldn't prevent this.
The `L` suffix raise a `SyntaxError` under python3. This should be `lambda: long(9999999999999999999)`.
Improved typography and changed to [%-formatting](https://docs.python.org/3/library/stdtypes.html#old-string-formatting) to be consistent with other error messages.
please alphabetize with the rest of the django imports
In cases like this, we prefer to include a trailing comma so if more items are later added, we don't need to modify this line again.
Use `setUpTestData` now that two models will be used by two methods.
Need to test that result is as expected, not only calling it.
We can add a control assertion to confirm that a `house` is cached for the `room`: ```suggestion self.assertIs(Room.house.is_cached(self.room), True) with self.assertNumQueries(0): ```
I think verifying the results wouldn't hurt, e.g. `self.assertSequenceEqual(groups2.filter(id__gte=0), [g])`
It would be better to loop over key-value pairs here instead of using `initial[k]` numerous times below.
Compile the regular expression here as it'll be used multiple times below. Prefer `[0-9]` to `\d`. Expression should be anchored to avoid risk of partial matches. (Granted, you are using `re.match()` below, but it is always safer to be explicit.) ```python formset_query_regex = re.compile(r'^inlinemode_set-([0-9]+)-([0-9]+)-(.*)$') ```
chop blank line
This regex looks wrong. If you're not extracting components of the regex, then why use it when you could just check that the string starts with `prefix_name`? But given that you are then using `args_list` which is `k` split up it suggests that you do actually want a proper regex with capturing groups. (Also note that when substituting a string into a regex, `re.escape()` should be used.)
With the change above this becomes: ```python match_obj = formset_query_regex.match(k) ```
Maybe? ```suggestion def _field_non_database_attrs(self): ```
> `how I would overwrite the non_db_attrs in the sqllite3 case` This doesn't need to be overwrite for SQLite when we move it to the field, because custom fields as `EnumField` from `django-mysql` will be able to remove `"choices"` on their own from `EnumField.non_db_attrs`, so we could add `"choices"` to the `Field.non_db_attrs` for all databases. > within the _field_should_be_altered function, I need to reference the non_db_attrs. There are both an old_field and a new_field in this function, would I pick one of these in order to be the non_db_attrs or would it be better to loop through them separately (unsure if that makes sense) We should do this separately because a field type can change.
Are both branches tested here? Otherwise this looks good.
Could we change this (and other similar places that check for string references) to directly call lazy_related_operation. The idea is that the calling code doesn't need to care if the reference is by string, and it doesn't need to care if the referenced model is already loaded. In all cases, it is OK to just call lazy_related_operation.
Wouldn't be required if you subclasses `IntegerField`.
consider calling this variable simply "title" (that's what the admin uses)
i think this would be cleaner as ```py if not hasattr(request, 'META'): return {} return {k: cleanse_setting(... ```
I had suggested doing this before computing `good_origin`: https://github.com/django/django/pull/13829#discussion_r579863426 That way you can avoid the two method calls and string construction in favor of a set membership check.
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
I'd suggest this style: ```python has_meta = hasattr(request, 'META') return {k: cleanse_setting(k, v) for k, v in request.META.items()} if has_meta else {} ```
``` return datetime.datetime(1970, 1, 1, tzinfo=timezone.utc) ```
I wouldn't have reflowed this line since you didn't make any other changes and it would simplify the diff.
Yes, maybe: "... time-related format specifiers (found 'a')."
Is it possible to include the invalid specifiers in the message? That would probably make it easier to debug.
`getattr()` rather than calling a dunder method
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
Most likely this will not work on Windows because files created with `NamedTemporaryFile` cannot be reopened on Windows (which defeats the whole purpose of naming them in the first place -- I have no idea why `NamedTemporaryFile` even exists on Windows). I'm not saying this is blocking the merge because I don't think we have that many users of PostgreSQL on Windows, but I thought I'd bring it up in case someone wants to check.
I was close to restore a regexp :wink:, but let's leave it as it is. Thanks :+1:
Why? IMO using regexp is less readable. This is not a really complicated comparison, I can imagine only one case when this can be broken in the future i.e. when Oracle unify their implementation with other dbs. Honestly I would like to catch this.
Same style as above.
Not from the top of my head, but since Python 3 provides better traceback for these kind of failures I'm not sure it's worth silently failing here.
Shouldn't this be along the lines of ```python def iterator(self, chunked_fetch=None): if chunked_fetch is None: chunked_fetch = connections[self.db].settings_dict.get('ENABLE_SERVER_SIDE_CURSORS', True) return iter(self._iterable_class(self, chunked_fetch=chunked_fetch)) ```
Citing @holvianssi on Trac. > The complex solution is to add both the opt-in flag and database settings. The default for the opt-in flag is None, meaning use the default from database settings. True forces this feature on, and False forces the feature off.
This conditional clause can be dropped once we perform an initial `not self._prefetch_related_lookups` as described above.
We'll want to do something with regards to the newly added support for `iterator`'s `prefetch_related` here.
I would move this docstring to the class: ```python class MySQLUpdateOrderByTest(TestCase): """Update field with a unique constraint using an ordered queryset.""" ```
```suggestion Update a queryset using order_by on a unique constraint. ```
This should be `+1` because `+2` works even without including `ORDER BY` clauses.
The `.all()` is redundant ```suggestion updated_count = UniqueNumber.objects.order_by('-number', 'id').update(number=F('number') + 1) ```
You could use `self.subTest()`, e.g. ```python def test_order_by_update_on_unique_constraint(self): tests = [ ('-number', 'id'), (F('number').desc(), 'id'), (F('number') * -1,), ] for ordering in tests: with self.subTest(ordering=ordering): updated_count = UniqueNumber.objects.order_by(*ordering).update( number=F('number') + 1, ) self.assertEqual(updated_count, 2) ```
Use single quotes.
Do we need to call `set()` in all tests? it seems unnecessary.
FWIW in #9383 this is handled by the `RenameField` operation -- no `AlterField` operation will be generated by the auto-detector just like none are generated on a model and `to` rename.
I'd drop it, and reintroduce the test later on in branches where we'll be able to backport #9383.
@atombrella Do we need inner imports here? Imports at the top works fine for me.
I don't believe so, this does seem unneeded. As a whole, this and the two lines below are pretty performance critical to the reloader but I don't see how removing `list()` would cause any issues with that.
Single quote strings ```suggestion module = types.ModuleType('test_module') ```
You can remove the unnecessary assignment here: ```python return _format_modules_cache[lang] ```
extra space after [
Not all implementations of Python have even the standard library in files. `os.__file__` may not exist.
I envisioned something like this: ``` python content = None with open(path, read_mode) as f: try: content = f.read() except UnicodeDecodeError: # If mimetype suggests the file is text but it's actually binary, # read() will raise a UnicodeDecodeError on Python 3. pass # If the previous read in text mode failed, try binary mode. if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE ```
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
I think this line isn't needed, tests seem to work fine without it.
seems like a helper method to get the attachment path would save some repetition
chop blank line
Is there any reason we are using the name `compiler` here rather than `qn`. I think compiler is definitely clearer, but compilers are generally referred to as `qn` in django (note in particular in the signature of `Lookup.as_sql()`). I think there is clarity to be gained by using `compiler` instead, but I'd also like consistency between the signatures.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
Constructing the entire string within the as_sql method departs from how other functions work. Is it possible to do something like: ``` class BaseCaseExpression(Func): function = None template = 'CASE %(simple)s %(conditions)s ELSE %(default)s END' ``` Then build up the dict required to fill in that template, and construct/return at the end? It may flow nicer, and allow 3rd party backends to modify the template without overriding the entire method.
You are right! I assumed `render_option` was always converting falsy values to an empty string. It might be worth keeping the method in this case.
I don't think it's worth adding a method for this purpose. `first_choice is not None and first_choice[0]` should do.
No need for an `else` branch as the `if` returns.
This is a bit unclear to me. When you say "for select itself" do you mean the `Select` widget class? Does "its children" mean subclasses? `NullBooleanSelect` seems to be at least one subclass that doesn't pass these checks.
In the case of an empty select (`choices = []`), this will still output the `required` attribute, which is still not valid: ``` >>> class TestForm(Form): ... some_field = forms.ChoiceField(choices=[]) ... >>> t = TestForm() >>> print(t['some_field']) <select id="id_some_field" name="some_field" required> </select> ``` ``` html <!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <title>Validation test</title> </head> <body> <select id="id_some_field" name="some_field" required> </select> </body> </html> ``` Check it here: https://validator.w3.org/nu/#textarea
Might want to squeeze all lines to follow the _style_ of the test module.
Could this test be moved to `BaseCacheTests` under `test_empty_cull` to make sure the implementation works on all backends instead of only the database one? https://github.com/django/django/blob/0bebe5266f2e52a76fcf6d23b76942399d087bf2/tests/cache/tests.py#L601-L622
This test runs on database cache only
please insert tests on line 1029, after the `setUp`/`tearDown` helpers `create_table` and `drop_table`
We should convert column name i.e. `connection.introspection.identifier_converter('large_field')`.
Sorry, wasn't trying to request a change, was thinking about how async middleware would be written and just seeking clarification.
That's what `inspect.iscoroutinefunction(getattr(Foo, '__call__', None))` does above. What I mean is that it's probably an abuse of Python data model. For example, ```python def Test: async def __iter__(self): pass assert inspect.iscoroutinefunction(Test.__iter__) ``` Won't fail but `__aiter__` should be used for this purpose. There's no analogous `__acall__` for `__call__` and it's not clear to me whether `async def __call__` is an abuse or not.
I think that you need to increase `stacklevel` to `3`.
Is this possible? If so, it will be good to cover this scenario with tests.
You can use `@modify_settings`, e.g. ```suggestion @modify_settings(MIDDLEWARE={ 'prepend': 'test_client.tests.urlconf_override_middleware', }) def test_resolver_match_when_urlconf_modified_by_middleware(self): response = self.client.get('/') ```
I think you could use `self.assertSequenceEqual` rather than this.
Please add a trailing comma.
Collapse this decorator into a single line.
First we should verify this passes before we toggle `is_active` to False.
I was thinking to assign the group permissions at the beginning of the test case so you can check all three together and not need the second round of tests along with setting the user back to `is_active=True`. Also, `codename='test_(user|group)'` would be helpful.
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
I'd omit the blank lines.
I suggested that because `annotation_select` now contains expressions other than aggregates. But I didn't notice the method was in the AggregateCompiler, so it probably is just aggregates in that dict. Not worth worrying about I guess.
I think it's a bit neater to invert the check for `node.as_sql` and return early: ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) sql, params = compiler.compile(node) return sql, tuple(params) ```
We expect compileable to always have an `as_sql` method. e.g. see `effective_default`'s implementation. ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) return compiler.compile(node) ```
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
Will this statement will fit on a single line? (119 characters is permitted.)
Will this statement will fit on a single line? (119 characters is permitted.)
Extra wrapping and `str()` call are unnecessary: `… for city "%s".' % city`
I think reorganization of the admin views tests deserves its own patch outsie of this ticket.
Also `django.core.checks.migrations` should be imported in `django/core/checks/__init__.py`.
```suggestion # Validate app_label. ```
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
```suggestion sys.exit(1) ```
I thought you wanted to remove `return`. Nevertheless I'd also leave the `else` as it increases readability.
Add a message please.
Unused or untested according to coverage report.
It's not obvious to me where limit_choices_to comes into play.
I think `GET` is fine for that.
@MarkusH Such a request should not change any state, so it should be `GET`. Using `POST` and `CSRF` wouldn't help against DoS there anyways (unless I miss something). If you are worried about querying the database, you can do the same with a normal request to the list views in the admin…
It's not obvious to me that the template approach is the best solution for readability as opposed to just creating another test settings file.
Please use the same order as in `--help` output, i.e. `--version`, `--verbosity`, `--settings`, `--pythonpath`, `--traceback`, `--no-color`, and `--force-color`.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
I would move it to the `ManageRunserver` class.
think we can chop the blank lines in the last 3 tests
Maybe ```suggestion ).filter(same_sized_fields__len__gt=1), ```
We don't need to call `ArrayLenTransform()`: ```suggestion sibling_count=models.Max('sibling_ids__len') ```
Maybe ```suggestion [len(self.objs) - 1] * len(self.objs), ```
Why not `first()`? :thinking: ```suggestion ).first().ids, ```
```suggestion ).values_list("siblings_json", flat=True).first() ```
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
`assertEquals` is deprecated and should be replaced by `assertEqual`. In a more personal-taste spirit, is it really useful to make 4 separate tests instead of consolidating them into one? The fact that the last 3 are identically named is an error, for sure.
This should probably be: ``` try: duplicate_path = os.path.join(test_dir, 'file.txt') .... finally: if os.path.exists(duplicate_path): ``` so if something fails, we still cleanup. Alternatively, could refactor to use setUp/tearDown methods.
(And round-tripping of the messages is already tested in other tests)
We should use a custom storage for this test (instead of mocking).
As long as you use `except Exception` and not a bare `except` this should be good.
If we remove this will the tests run on Jenkins? It might be fine.
Don't think we need to worry about duplicates.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
You could do this setup in Python. `self.school.students.add(...)`
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
Two tests i.e. `test_sqlmigrate_ambigious_squashed_migration_name()` and `test_sqlmigrate_squashed_migration()` work without this patch. It's fine to increase coverage but we should move them to a separate commit.
This must use `mock.patch` else it will leak between tests as the connection. Also it should be `connection.features.can_rollback_ddl` and not `connection.can_rollback_ddl`.
```suggestion self.assertEqual(err.getvalue(), 'No statements found.\n') ```
We can reuse an existing migration: ```suggestion MIGRATION_MODULES={"migrations": "migrations.test_migrations_manual_porting"} ```
Please wrap at 79 chars.
Please wrap at 79 chars.
Please wrap at 79 chars.
I think we can move `msg` to the assertion, I don't see much value in creating a temporary variable here.
* `--force_color`? (i.e. with `--`) * ~~Re-wrap?~~ (Sorry diff view confused me: you already did this.)
The docstring should state the expected behavior rather than including preambles like "Tests that", "Verfies that..." (that is the purpose of all tests).
Please follow the test docstring guidelines in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style
Is this line correct? Above it's `subTest(url=url_name)` but then we `reverse(url_name,...)`
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
This is redundant with an existing assertion, IMO we can drop it.
chop blank line
Up to you but I think we usually put error cases in a separate method.
I wouldn't include this test in the PR because it's testing existing behavior. But it doesn't seem needed as there's a test in `test_client_regress` that fails if the `isinstance(data, dict)` check is `_encode_json` is removed.
This can be dropped since `connection` is already imported in the context of the module. ```suggestion ```
I think a specialized class is not required for this test case as you can rely on `.args` ```python try: raise Exception(2) except Exception as e: try: raise Exception(1) from e except Exception: exc_info = sys.exc_info() ... self.assertEqual(cm.exception.args[0], 1) self.assertEqual(cm.exception.__cause__.args[0], 2)
Also here: ```python if self.index_type.lower() != 'gist': ```
It will be `django.contrib.postgres.constraints.XXX` but I don't think that's an issue for core constraints we return `django.db.models.XXX`.
I would move it to `_init__()`: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ... self.index_type = index_type or `GIST` self.condition = condition super().__init__(name=name) ``` and skip the default in `deconstruct()` and `__str__()`: ```python def deconstruct(self): ... if self.index_type != 'GIST': kwargs['index_type'] = self.index_type ```
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
Maybe `_parse_where()` -> `_get_condition_sql()`, I would return condition and add `WHERE` in `constraint_sql()`, e.g. ```python def _get_condition_sql(self, compiler, schema_editor, query): if self.condition is None: return None where = query.build_where(self.condition) sql, params = where.as_sql(compiler, schema_editor.connection) return sql % tuple(schema_editor.quote_value(p) for p in params) def constraint_sql(self, model, schema_editor): ... condition = self._get_condition_sql(compiler, schema_editor, query) return self.template % { ... 'where': ' WHERE (%s)' % condition if condition else '', } ```
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
I feel like this boiler-plate could be handled more nicely. For example, what about defining a function above that looks something like-- ```python def add_argument(parser, name, *args, help=None, **kwargs): if name in self.suppressed_base_arguments: help = argparse.SUPPRESS parser.add_argument(*args, help=help, **kwargs) ``` Then each `parser.add_argument(...)` would become `add_argument(parser, name, ...)`. I also think it would be better if the convention were for the string in `suppressed_base_arguments` to match the first option string passed to `parser.add_argument()` (e.g. `--force-color` instead of `force-color`). I think it would be easier to remember. Also, if that were done, the name wouldn't have to be passed a second time, or manipulated in any way inside the helper function above before checking for membership in `self.suppressed_base_arguments`.
I think we can leave the list of exceptions.
What do you think about using `argparse.SUPPRESS` instead (as suggested in the previous patch)? e.g. ```suggestion parser.add_argument( '-v', '--verbosity', default=1, type=int, choices=[0, 1, 2, 3], help=argparse.SUPPRESS if 'verbosity' in self.suppressed_arguments else ( 'Verbosity level; 0=minimal output, 1=normal output, ' '2=verbose output, 3=very verbose output' ), ) ``` This way the list of options will not be misleading anymore and at the same time default values will be available for subcommands :thinking: This should increase backward compatibility.
Do we need to check if `token` is an instance of `Mailbox`? I couldn't find an example that needs this check.
Per new code guidelines, can we use `assertIs`? :)
@felixxm that's a tricky one for sure. We could adjust MySQL's `allows_group_by_pk` feature to be based of `not ONLY_FULL_GROUP_BY` but that would likely incur a large performance hit which is definitely not suitable for a backport. I guess we could always skip the test on MySQL for now.
Could do `self.assertEqual(qs.get()['float'], 1.2)`
This assertion is not related with the patch. Please remove it.
chop blank line
Chop blank line
Merged overridden settings into one decorator.
Double checking the commit, this change, in this form leaks some state across migrations. Testing on CI right now. ``` python ERROR: test_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) psycopg2.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/markus/Coding/django/django/test/utils.py", line 182, in inner return test_func(*args, **kwargs) File "/home/markus/Coding/django/tests/migrations/test_executor.py", line 401, in test_alter_id_type_with_fk executor.migrate([("author_app", "0002_alter_id")]) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 94, in migrate self.apply_migration(states[migration], migration, fake=fake, fake_initial=fake_initial) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 131, in apply_migration state = migration.apply(state, schema_editor) File "/home/markus/Coding/django/django/db/migrations/migration.py", line 118, in apply operation.database_forwards(self.app_label, schema_editor, old_state, project_state) File "/home/markus/Coding/django/django/db/migrations/operations/fields.py", line 201, in database_forwards schema_editor.alter_field(from_model, from_field, to_field) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 482, in alter_field old_db_params, new_db_params, strict) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 635, in _alter_field params, File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 106, in execute cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 79, in execute return super(CursorDebugWrapper, self).execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/utils.py", line 95, in __exit__ six.reraise(dj_exc_type, dj_exc_value, traceback) File "/home/markus/Coding/django/django/utils/six.py", line 658, in reraise raise value.with_traceback(tb) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) django.db.utils.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. ``` However, integrating this with the second commit on my PR fixes the issue. I thus squash those commits there and close your PR here.
We've been using "Take / apply" verb-style in new docstrings.
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
This method returns a list and not a dict.
This can go away now, but needs a new test that the warning is raised in the base hashers `decode`
For simplicity I think it would be better to revert this to the previous code, ie simply https://github.com/django/django/blob/69e0d9c553bb55dde8d7d1d479a78bfa7093f406/django/contrib/auth/hashers.py#L425-L427 -- I understand your motivation behind using `decode` here, but simplicity wins especially in security relevant code.
I am currently giving the PR a full final review and I think we can drop those assertions now that they are done in decode already, what do you think? (same for the assertion in `safe_summary` and other hashers)
I'd call this `work_factor` as dictionary key and only in `safe_summary` it would be `work_factor`
This doesn't work with many conditions, e.g. `a ^ b ^ c` see `XorLookupsTests.test_filter_negated()`.
```suggestion # Convert `A XOR B` to `(A OR B) AND NOT (A AND B)`. lhs = self.__class__(self.children, OR) rhs = self.__class__(self.children, AND, negated=True) return self.__class__((lhs, rhs), AND, self.negated).as_sql(compiler, connection) ```
One space after period.
I typically use this style to avoid such long strings near the length limit: ``` raise NotSupportedError( '...' '...' ) ``` (could also be applied in the other file)
This seems problematic. What happens if you do this: ``` reused_f = F('pk') qs1 = Model1.objects.filter(pk=reused_f) qs2 = Model2.objects.filter(pk=reused_f) ``` By my reading the reused_f will be first prepared for qs1, getting Model1.pk as col. Then the same object is reused and prepared for qs2, this time the reused_f's col is overwritten with Model2.pk. The ExpressionNodes must be either stateless, or they must be copied on prepare(). Doing the latter will be easier. A basic copy method could do the following: ``` def copy(self): copy = Empty() copy.__class__ = self.__class__ copy.__dict__ = self.__dict__.copy() return copy ```
`parallell` => `parallel` `get_upodated_models` => `get_updated_models`
I'd say `on Python < 3.6`
I also still don't understand why it's useful to allow writing code that doesn't work.
I would consider that as not working
I think silently failing to cache the property should be considered not working.
It's not resolved.
When considering my above point please now target 4.1.
```suggestion def insert_statement(self, on_conflict=None): ``` Also ensure that this change of signature, from `ignore_conflicts=False` → `on_conflict=None`, is mentioned in backward incompatible changes to database backends in the release notes.
Chop blank line.
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
Seems fine to rename everywhere, but it seems out of the scope of this PR to touch `BoundField.__init__`.
Return ... (I think this can be flowed onto the previous line too)
I was thinking: ``` python def bind_to_form(self, form, name, **kwargs): return BoundField(form, self, name, **kwargs) ``` but I'm not convinced this is a good practice for a "just in case" scenario, so we can probably drop the idea.
I wonder if we might add `**kwargs` to the signature of this method and `BoundField` to allow for future expansion? (In the past, there have been some instances where we've wanted to add additional parameters and we have to add non-trivial backwards compatibility shims to allow that.)
Do you envision more complex behavior than returning a custom class? If not, I wonder if `get_bound_field_class()` would be simpler.
I don't think it's worth changing elsewhere.
I guess most test classes have a blank line after the class and before the first test method.
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
I wonder if we can just set `default_time_format` attribute.
I think it's fine to make them a bit inconsistent (at least for now). I opened an [issue](https://bugs.python.org/issue40300) in Python.
Actually a relation is hidden if it ends with a `'+'`. Here `rel` has a `is_hidden` method that abstract this check.
Should we check explicitly only for name '+'. I'm not sure if users can define some other hidden related name if they want to. In that case we shouldn't override the user's hidden name with an auto generated name.
I think this approach is too naïve. `related_model` can be a model class.
no blank line
Should this be `r.field.name` so the error in the example of the ticket is: ``` myapp.specialdetail: Accessor for field 'parent' clashes with accessor for field 'SpecialDetail.target'. Add a related_name argument to the definition for 'parent'. ``` instead of: ``` myapp.specialdetail: Accessor for field 'parent' clashes with accessor for field 'SpecialDetail.myapp:specialdetail'. Add a related_name argument to the definition for 'parent'. ```
Adding a reference to the ticket number (in the docstring for example) would be helpful here.
Technically, `name` should be a string, not an integer. For brevity, you could use `[Person(name=name, person_country=self.usa) for name in 'abcde']`
It's helpful to describe the issue with a few words, e.g. "Inserting non-ASCII values longer than X characters (#22144)." (I'm not certain that's a correct description of the issue).
This is already covered by `tests.queries.test_db_returning.ReturningValuesTests.test_bulk_insert`, that's why `ReturningValuesTests` tests crash on SQLite 3.35+ (see #14227).
However, I think it's worth to keep it for backends without built-in converters.
Perhaps the full list could be a class attribute so it doesn't have to be repeated several times.
This could become a class attribute so it needn't be repeated.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
chop blank line
I tried with 'Path' on the advanced search dialog but it didn't seem to allow inverse, thanks for showing me the right syntax @jarshwah one of the uses is actually in kogan/django-lrucache-backend 😉
We don't often use the `msg` param with `subTest()`. Maybe: `"Migration file includes header: %s." % include_header` or just: `include_header=include_header`
I think maybe ```py dummy = object() def get(self, key, default=None, version=None, acquire_lock=dummy): if acquire_lock is not dummy: warnings.warn( ``` I still think this arg fits in the grey area for deprecation timeline, would like someone to weigh in e.g. @jarshwah
`acquire_lock` was added for internal usage in 6448dd833524ac3fc503506b624841c9d642de8a, so I don't see a need for a deprecation.
Ok thanks Tim
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
Could we patch a StringIO instead of devnull and then verify the contents of log_message()? See tests/check_framework/tests.py for an example. Also the patching should be in setUp/tearDown or in a try/finally so if something goes wrong the unpatching still happens.
And I would rename this attribute `superusers` as it's meant to contain multiple users.
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
There is in theory a chance of hitting a TOCTTOU case here anyway, in which case it is better to handle the exception to avoid a crash.
Maybe: ```python "File '%s' is already compiled and up to date." % po_path ```
return directly, no need for `path` variable.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
I’m not comfortable with how this is calculated. There ought to be a better way to handle this, e.g. by inspecting `sys.path` for common ancestors.
I don't think this is completely correct. Models with a `Meta.ordering` can still make use of explicit `order_by` and when it's the case it should be honored.
That makes sense, using `get_source_expressions` here was only performing a `contains_aggregate` check for the outer level expression while `get_group_by_cols` does it recursively as the expression tree is walked. https://github.com/django/django/blob/c1b24718e05ea474955777d7bc4d9d5634560cd5/django/db/models/expressions.py#L346-L352
We should test with a different expression since this might be fixed in the future ```suggestion expr = ExpressionWrapper(Lower('field'), output_field=IntegerField()) self.assertEqual(expr.get_group_by_cols(alias=None), [expr.expression]) ```
This unfortunately won't work if the subquery refers to any outer references as these must be included in the group by clause.
I don't have a strong opinion here as that's probably the only type of non-`Expression` wrapper supported in `ExpressionWrapper` but the previous `if isinstance(self.expression, Expression)` felt more correct.
As multiple addresses are allowed, I suggest "to one or more addresses specified ...".
'--version argument does not yet exist'
should this be used? (with a test too) arguments -> options
```suggestion # Validate app_label. ```
There is no need to resolve replaced/applied migrations so I would pass `None` instead of the default connection: ```suggestion loader = MigrationLoader(None) ```
`for (old_field,new_field) in zip(old_model._meta.local_many_to_many, new_model._meta.local_many_to_many):` makes the code in the loop simpler and removes the need for the hack.
OK we can revert my suggestion, sorry. `RenameModel()` doesn't change `db_table` so `old_db_table` can be different from `new_db_table` only when `db_table` is not defined.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Indexes are not constraints, generally.
`constraint_name` should also be quoted.
```suggestion """Render as <p> elements.""" ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
As `BaseFormSet` is inheriting from `Renderable` we can ditch this as the definition is the same: ```suggestion ``` You can also remove `.as_table()`, `.as_p()`, and `.as_ul()`.
```suggestion """Render as <p> elements.""" ```
You could skip these, but I thought that the rewording read better. I guess if you go for the proposed `Renderable` then they'd be moved anyway and then it doesn't hurt to update them. (Also note that the docstring for `BaseFormSet.as_ul()` neglected to mention that it isn't wrapped in `<ul>`.) 🤷🏻‍♂️
Maybe `_parse_where()` -> `_get_condition_sql()`, I would return condition and add `WHERE` in `constraint_sql()`, e.g. ```python def _get_condition_sql(self, compiler, schema_editor, query): if self.condition is None: return None where = query.build_where(self.condition) sql, params = where.as_sql(compiler, schema_editor.connection) return sql % tuple(schema_editor.quote_value(p) for p in params) def constraint_sql(self, model, schema_editor): ... condition = self._get_condition_sql(compiler, schema_editor, query) return self.template % { ... 'where': ' WHERE (%s)' % condition if condition else '', } ```
I think we can use the same check like in `UniqueConstraint`: ``` if not isinstance(condition, (type(None), Q)): raise ValueError('ExclusionConstraint.condition must be a Q instance.') ```
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
I would move it to `_init__()`: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ... self.index_type = index_type or `GIST` self.condition = condition super().__init__(name=name) ``` and skip the default in `deconstruct()` and `__str__()`: ```python def deconstruct(self): ... if self.index_type != 'GIST': kwargs['index_type'] = self.index_type ```
`The expressions argument is mandatory.` -> `At least one expression is required to define an exclusion constraint.`
Mhm that is what I was trying to avoid, because for most hasher a salt length is just that and `must_update` should easily be able to handle that globally if it is returned from `decode`. What this PR certainly misses (and what will show you the existing problems) is a test for the behavior of the `bcrypt` hasher. I think now it's `must_update` will *always* return `True` and set a salt *every* time.
IMO, we should use `self.decode` here.
I would put "decode" into quotes or so (@felixxm can certainly tell us what the proper syntax is)
Throught your patch, please use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Should also include `block_size` and `parallelism`
What do you think about using the same conditions as in `ModelAdmin`? https://github.com/django/django/blob/97e9a84d2746f76a635455c13bd512ea408755ac/django/contrib/admin/options.py#L1035 For example: ```suggestion has_quotes = relative_name.startswith(('"', "'")) and relative_name[0] == relative_name[-1] ```
We don't typically use this style of docstring. I prefer if you restructure it as a sentence.
Usually just sentences.
please put imports at the top of the file
Wouldn't it be easier to put this check in `StaticNode.handle_simple()`? Also, you seem to have occluded the `do_static()`, which was previously the actual `static` template tag…this means that you aren't handling the `{% static PATH as VAR %}` case any more, I think.
For new code, we're using single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Please use single quotes.
Unfortunately this doesn't work well for formsets. I get `order.OrdersProducts.ordersproducts_set-15-product`.
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
If so, I think a separate commit would be better.
It's unused for empty results, so maybe we can move it below the `try...except` block: ```python try: sql, params = self.compile(col) except EmptyResultSet: empty_result_set_value = getattr( col, "empty_result_set_value", NotImplemented ) if empty_result_set_value is NotImplemented: # Select a predicate that's always False. sql, params = "0", () else: sql, params = self.compile(Value(empty_result_set_value)) else: sql, params = col.select_format(self, sql, params) if alias is None and with_col_aliases: alias = f"col{col_idx}" col_idx += 1 ret.append((col, (sql, params), alias)) ```
This isn't safe unfortunately. Consider the following test results (which fail): ``` def test_empty_expression_char(self): books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value('Empty')), default=Value('Not Empty'), output_field=CharField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, 'Not Empty') def test_empty_expression_datetime(self): from django.utils import timezone from datetime import timedelta now = timezone.now() then = now + timedelta(days=1) books = Book.objects.annotate( selected=Case( When(pk__in=Book.objects.none(), then=Value(now)), default=Value(then), output_field=DateTimeField() ) ) self.assertGreater(len(books), 0) self.assertEqual(books[0].selected, then) ``` Depending on whether or not there are dbconverters run, these will fail with one of the following kinds of errors: 1. `TypeError: expected string or buffer` 2. `AssertionError: 0 != datetime.datetime(2016, 5, 23, 18, 59, 26, 409777)` For what it's worth, both of these tests fail without your patch too, except they fail during the count just like the report on the ticket says. This certainly needs fixing in some way, but we can't just use 0 as a value all of the time.
Case expressions use Q internally which led me to writing the above tests. I think you're right that EmptyResultSet might be able to be caught directly, and then it could use the `default` argument in place of the static `'0'` you have above. The changes need to be made in tandem though.
You can remove the whole `else:` branch as `None` will be returned by the function implicitly.
Dot is missing: `'Choices are: %s.'`.
same thing here about assuming `is_active` exists and `not user.is_active` -- probably need some tests for that case.
Please don't make unrelated whitespace changes.
as above, state expected behavior in a docstring
You should be able to pass `is_active=False` to `create_user()`.
I'm almost sure the "smart" is not needed here. Just use force_text. However, do we know what type of encoding is expected here? If it is UTF-8 encoded string, we should use force_bytes instead.
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
The thing is that even if the ORM doesn't have support for it yet using `distinct()` to implement `(UNION|INTERSECT) ALL` might prevent us from adding proper support in the future. What I suggest doing here is setting `query.combinator.all = kwargs['all']` and preventing using `distinct()` on `CombinedQuerySet`. The difference between ordering and combination operation is that the former operates on the _combined_ set of rows while the latter operates on how these rows are combined. I would suggest that options related to combination be passed as `kwargs` (such as `all`) and actions operating of the combined result (`CombinedQuerySet` instances) be added as methods (`order_by`, _slicing_).
We can also go faster by using a list comprehension instead of a generator - they're cheaper to create: ```suggestion obj.combined_queries = tuple([query.clone() for query in self.combined_queries]) ``` Simple benchmark: ``` In [2]: items = [1, 2, 3, 4] In [3]: %timeit tuple(x*2 for x in items) 508 ns ± 10 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [4]: %timeit tuple([x*2 for x in items]) 358 ns ± 14.7 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
I'd omit the blank lines.
Ah, good point. I don't think it's cleaner in general, I was just trying to keep `QuerySet` / `Query` fast like my optimization efforts. Since it's a fairly small here I don't feel that strongly about the global, you can leave it as-is
Focusing in only on the point around 'slightly faster' (because whilst I can't think of additional syntax to disallow, that's much of the point around extensibility you bring up ;)). IM(limited)E, for any '_sensible_' length string, `x in mystr` (at least where `x` is a constant) is well-optimised, and usually performs better than the equivalent regex, even needing 2 passes, and accounting for compiling the regex beforehand. For the lengths of strings we might _expect_ here, the difference is probably still measured in nanoseconds. If performance were the _only_ consideration (vs. the aforementioned extensibility) it'd be worth checking.
a regex check for `/\*|\*/` could be slightly faster, avoiding two passes over the string and being more extensible in the future in case we find other syntax that shouldn't be allowed
avoid "we" to simplify, e.g. "Copy the subquery because it'll be modified."
This could fit on a single line: `# Subqueries must use a different set of aliases than the outer query.`
I think an explicit loop that mutates the dict might be clearer here, and avoid the overhead of a function creation and call. I believe we already do this elsewhere (but I haven't double checked).
This will overwrite an explicitly given message if you use ``` python validator = DomainNameValidator(accept_idna=True, message='Only IDNA domain allowed') ```
Not sure if ``` def check(self): return self._check_pattern_startswith_slash() ``` is better or not.
`elif` might be clearer (I understand it's not necessary)
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
How about omitting it until we have a use case? That will save writing tests and docs for a theoretical feature. :-) From a readability point of view, writing a `re_path()` that mixes regexes and converters in the string, and then has to initialize and pass converters in the URLconf sounds nasty and not something to encourage!
This line can go in "else" of try/except/else since it isn't expected to raise an exception.
This branch doesn't seem to be tested.
the wording used for similar options is simply "Can be used multiple times."
Please add trailing comma.
Since this is only being used in one test case class, I would put it right before that test case class. If it turns out to be useful for other tests, it could always be moved to a more central location and modified as needed, etc.
you need to drop the `__class__`, the `object` itself should be an instance of `Author`
this can be a single line (we prefer longer lines when it improves readability)
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
IPAddressField is removed from Django so shouldn't be listed.
I think all the defaults here should be mappings to the same type (e.g. `'PositiveIntegerField': 'PositiveIntegerField'`), so that backends have to specify the types they introspect differently.
I don't like this suggestion. What do you see as the advantage? Here's why I'm concerned: - It's more verbose - typos in the key name are silently ignored - by implementing a mapping in the base features, it shows which fields are implemented in Django's tests (I don't think we should try to implement all fields proactively but accept PRs if a third party backends needs it)
I was just about to suggest this too :+1:
I would leave it empty (`introspected_field_types = {}`) by default and use `.get()` in tests, e.g. ```python connection.features.introspected_field_types.get('BooleanField') or 'BooleanField'` ```
I'm not sure that it makes any sense checking the registry. There is no guarantee that you are using a terminal that uses this. So it could just result in a blanket "on" if this is set. It would be better to take the `ctypes` approach mentioned to check whether currently enabled for the actual terminal in use.
It is also "Windows Terminal", not "Microsoft Terminal".
```suggestion reg_key_value, _ = winreg.QueryValueEx(reg_key, 'VirtualTerminalLevel') ```
`Determines` -> `Determine` `will support` -> `supports` This docstring can be single-lined.
Do we really need this inner function? We could just shortcut out early if not a TTY.
```suggestion "import datetime\nfrom django.db import migrations, models\n", ```
Can you reference the ticket number in the docstring, please.
That's a double negation the writer shouldn't have to deal with as it's a side effect of the fact the CLI facts are negated.
Instead of this file dance, it would be easier to use a `tempfile.NamedTemporaryFile`. It is also safer wrt parallel test runs.
Can you reference the ticket number in the docstring, please.
Is this condition necessary? Surely all backends will support a default `TEXT` format? (Even if it can't be explicitly provided in the query...)
What about erroring if `options` is non-empty at this point? Subclasses should have already consumed their arguments from it, and if there's anything left it's probably a mistake, like `explain(formatt='json')`
In the current implementation if ``supported_formats`` evaluates to ``False``, then there would be a trailing space at the end of the error message. Probably it would be better to remove it from this string and add it to the string below: ``` msg += ' Allowed formats: {0}'.format(', '.join(supported_formats)) ```
`NotSupportedError`, and please use single-quotes, and add a dot at the end.
`output_format` → `format` `**kwargs` → `**options`
Unnecessary trailing comma and white space.
avoid _we_ usage as well ``` SystemCheckError is surfaced when run_checks raises SystemCheckError and teardown databases raises ValueError
No reason to use `dict.update()` anymore.
Please test the entire message.
I would make the test of `build_suite()` and `run_tests()` separate test methods.
IMO we should check options against PostreSQL names.
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
This is precisely this inconsistency in the expressions API about `params: list | tuple` that forces the usage of `tuple` here. Some `lhs.as_sql` return `params: list` and but the backend expects layer only expects `tuples` to be provided. Without this `tuple` some tests crash and I think we want to avoid this expression API inconsistency leak into the backends layer as it could be considered as low level as the compiler which only deals with `params` in tuples.
is it strictly required to cast params to a tuple? I thought it was understood that `params` may be a list or a tuple throughout the ORM code.
I don't think extending `Subquery.__init__` to allow any `QuerySet` some method (e.g. `filter`, `order_by`, ...) is desirable.
As an example. The method signature should be ```python def rename_model(self, app_label, old_model_name, new_model_name): ... ``` And be called from `RenameModel.state_forwards` as `state.rename_model(app_label, self.old_name_lower, self.new_name_lower)` instead of passing the `Operation` instance along.
```suggestion self.remove_model(app_label, old_name) self.reload_model(app_label, new_name, delay=True) ```
I think we can abstract away the need to _lower_ the name here. ```suggestion def alter_model_options(self, app_label, model_name, options, alter_option_keys=[]): ```
```suggestion def alter_model_managers(self, app_label, model_name, managers): ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
`if not getattr(reffed_expression, 'filterable', True):` Although you should probably be able to just check filterable. If non-resolved F expressions get here, consider adding the filterable attribute onto the F expression class so that you can assume it's always available.
Moving this line is not related with a bugfix. Please revert it and add ```python if check_filterable: ... ``` in both places.
Hadn't considered this.
I think the original `reffed_expression.__class__.__name__` should be used.
We can do the same for `reffed_expression`: ```diff diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index b3d92d786c..21bc0aea7a 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -1286,11 +1286,9 @@ class Query(BaseExpression): if check_filterable: self.check_filterable(value) - clause = self.where_class() if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) - clause.add(condition, AND) - return clause, [] + return self.where_class([condition], connector=AND), [] opts = self.get_meta() alias = self.get_initial_alias() @@ -1333,7 +1331,7 @@ class Query(BaseExpression): condition = self.build_lookup(lookups, col, value) lookup_type = condition.lookup_name - clause.add(condition, AND) + clause = self.where_class([condition], connector=AND) require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None: ```
if kept as a separate class, I'd copy the `setUpClass` method from `NodelistTest`
`str(` seems unnecessary.
Could move `executable = '/usr/bin/python'` to a class attribute.
assertEqual(..., True) -> assertTrue(...)
I think the suggestion is to maintain the "Invalid field name(s) for model ..." error message a property that doesn't have a `setter`.
In the current state, it's not reusable for other lists of expressions, so I would rename it to the `IndexExpressions`
That looks awesome @hannseman 💯 🏅 Regarding `django.contrib.postgres.indexes.OpClass` I guess we could add a `IndexedExpressionWrapper.register_wrapper` and have `django.contrib.postgres.apps.PostgresApp.ready` register `OpClass` to avoid coupling there.
I think that most of the expression special casing and resolving should be done at the `Index.create_sql` level. The only purpose of `ddl_references` is to hold references to identifiers and allow renaming if necessary, it shouldn't have any knowledge about `django.db.models` abstractions.
This seems out of place. Is this branch really specific to MySQL? Is there a way we could avoid the `Col` import in the first place.
You want to avoid altering `self` here as subsequent calls will reuse this attribute even if this branch's conditions don't match.
Same style as above.
State the expected behavior rather than "Checks that" or "Tests that" since all tests have that purpose.
chop blank lines
seems like a helper method to get the attachment path would save some repetition
chop blank line
Might want to move the `)` to the next line and add a trailing comma while you are around.
I'm not sure splitting this out to a separate function makes the code easier to follow.
Correctly indent the bracket to match the `return` indentation.
`frozenset` makes a lot of sense and doesn't get enough use IMHO, as long as we're careful to remember we need to use `|` rather than `+` on any subclasses that want to extend the data.
Current implementation of `get_prefetch_queryset()` assumes that all instances have the same content type (there is an issue), but the fix is not optimal IMO because object IDs can be the same in different content types, e.g. we have two related objects: - object ID 1 with content type ID 1, - object ID 2 with content type ID 2, this query will return also: - object ID 2 with content type ID 1, - object ID 1 with content type ID 2, which is not correct. I know that we are matching them below but still I think we can limit the no. of objects only to actually needed.
This isn't triggered until the input queue is read at least once.
Could omit the `email_field_name` variable and inline `UserModel.get_email_field_name()` instead.
More importantly I think our wsgi handler currently has the oddity to always normalize to at least /, you will never get an empty path_info iirc
You are leaking information about whether somebody has access or something doesn't exist.
Raising a 404 with the same message as in the previous check would mask the issue. Then again I think we already leak a lot like that in other admin pages, will have to double check.
Adding hooks in `as_sql` in the different compilers to check whether the query should be executed or explained might be an option? I think it's necessary to do changes in those methods.
Hanging indent please, and it should be possible to remove the temporary `prefix`.
Use hanging indent and remove temporary variable: ```python result.append(self.connection.ops.explain_query_prefix( self.query.explain_format, **self.query.explain_options )) ```
I don't think we need the extra assignment here as this is only used once.
Remove the blank line.
Maybe: ```python self.assertEqual(len(self.selenium.find_elements( By.CSS_SELECTOR, '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]', )), 1) ``` or ```python selector = '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]' self.assertEqual(len(self.selenium.find_elements(By.CSS_SELECTOR, selector)), 1) ```
This should go to the 2nd commit :pick:
This should go to the 2nd commit :gem:
The benefit of the extra tests is they make the HTML structure clear, but the CSS selector perhaps does that... We should use hanging indent for the wrapping, so maybe pull the CSS selector into a variable, so it's easy read/see, and then the lines would be shorter too, and we can just have the two assertions.
```suggestion # Even the third inline should have the correct verbose_name ```
I would do what the other tests do and pass `test_labels` as a positional argument. Also, to be clearer what `foo` and `bar` are doing, it might be better to call them something like `notfound1` and `notfound2`. I'm assuming it's finding two failed test instances for labels not found. Alternatively, you could find real tests by passing something starting with `'test_runner_apps...'`.
Since `verbosity=1` is the default, you can leave this out. (It's good to be testing the default behavior.)
Please test the entire message.
single line looks okay here and in the next test (it's shorter than the previous line, at least)
if no app*
I would either use `self.assertTrue(Carrot.objects.filter(tags__tag='orange').exists())` or `self.assertEqual(Carrot.objects.get(tags__tag='orange'), bear)` but otherwise LGTM.
First we should verify this passes before we toggle `is_active` to False.
I removed it.
in most places you have a blank line after the function before the assert, but not all
I think the `@property` syntax would be more readable here.
... also we cannot use `User` in the `BaseBackend` so it will be hard to return something consistent.
This seems overly simplistic, we should at least be sure to the extend that we should check the signature of the function on whether or not it supports more than two arguments.
You should be able to pass `is_active=False` to `create_user()`.
Please use assertRaisesMessage to verify this is the ValueError we expect.
We can move the test that involves `login()` to the other pull request.
Believe it or not, we're importing this one at work. (wasn't me this time :). I'm actually not sure what you've done to replace it.
You turned the arguments into keyword arguments in one other place. Could you also do this here and below? I don't know if it makes sense to also do this in the tests.
If `formfield.queryset` is already filtered both the outer query and the subquery will have this filter applied which is unnecessary ```suggestion Exists(formfield.queryset.model._base_manager.filter(complex_filter)), ```
We use line lengths up to 119 characters when it helps readability. I wouldn't reformat this line when it doesn't have any other changes.
I see before: `to_fields=[], from_fields=[self.object_id_field_name]` after: `to_fields=[object_id_field], from_fields=[]` I could very well be missing something...
It works with my proposition so we should have both assertions.
We should keep both assertions: ```suggestion self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='ar').exists(), False) self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='bar').exists(), True) ```
We should check the behavior with bytestrings too. I'm not sure how PostgreSQL stores them and if the change to force them to unicode will have any practical consequences.
I think `force_text()` isn't needed but rather adding `from __future__ import unicode_literals` to this file.
Yes -- does this change affect that case.
All `Col` should have an `alias`.
You can drop the `.contains_column_references` as it's wasteful in this case because of the way it walks the expression tree given we'll have to walk it anyway below.
Add a period to the end of the exception message.
We used the same message as in other places that's why I don't want to add a period only in this case.
Maybe you've missed `if summarize` branch (below).
tests aren't entirely consistent, but I prefer omitting a newline after the docstring.
was referring to `call_command`. the `os.path.join` is okay.
if no app*
Yes, please rebase the branch and remove the try/fail pattern as done in 6729b96d8a15048b2295c916c5b881a59d9417a0. If you're unfamiliar with the process you might find https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/working-with-git/#rebasing-branches helpful.
This should be defined outside the `try` - if `call_command` raises, `merge_file` won't be defined in the `finally` clause.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
According to [Wolfram Alpha](http://bit.ly/29bAENj) that's the same as this and slightly more understandable? ``` python (not old_field.db_index and not old_field.unique and new_field.db_index) or (not old_field.unique and new_field.unique) ```
Oh are we creating the `_like` indexes even when `unique=True`? I wasn't expecting that.
Not a blocker or anything but `concurrently` seems more appropriate than `concurrent` for the kwarg name to me. e.g. `add_index(model, index, concurrently=True)`
Did you consider using `queryset.model` instead of 'Row'? I don't know if that would cause confusion with model instances.
``` # Cache namedtuple() with @lru_cache() since it's too slow to be # called for every QuerySet evaluation. ```
I'm still not sure what "tuple_class._make() is inlined here" means.
We should try cache the `namedtuple` classes that come out of this, they can take about half a millisecond to instantiate, which is a lot of time - if a view invokes 10 queries that's 5ms, or 10% of a tight performance budge, gone: ``` In [14]: %timeit namedtuple('Row', ['a', 'b', 'c', 'd']) 1000 loops, best of 3: 417 µs per loop ``` If you make `names` a tuple (so it's hashable) then you can just have: ```python @lru_cache() # using default maxsize, i don't think it would need tweaking really def create_namedtuple(names): return namedtuple('Row', names) ``` Also the temp name `rows` isn't needed, I'd move it into the map call, leaving: ```python return map( create_namedtuple(names)._make, super().__iter__(), ) ```
Citing @holvianssi on Trac. > The complex solution is to add both the opt-in flag and database settings. The default for the opt-in flag is None, meaning use the default from database settings. True forces this feature on, and False forces the feature off.
use: `any(name for app, name ... )`
Could you replace "create model" and "add field" with "CreateModel" and "AddField" respectively, please.
You also need to get the name of the table column from the respective field
Is `plan` meant as the second argument? Looks like we're missing a test for this branch.
Thanks for addressing this.
If `cx_oracle` is installed, there's an error: ``` File "/home/tim/code/django/tests/backends/test_cursors.py", line 33, in OracleCursorOptionsTestCase class OracleLoggingCursor(LoggingCursorMixin, Database): TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases ``` Also, is this file doing anything useful? I don't see any test methods.
`e` is unnecessary. Maybe it will be better to refactor these tests and put `class` inside `try` e.g. ```python @unittest.skipUnless(connection.vendor == 'postgresql', 'Postgresql specific test.') class PostgreSQLCursorOptionsTestCase(TestCase): try: from psycopg2.extensions import cursor class PostgresLoggingCursor(LoggingCursorMixin, cursor): pass except ImportError: pass ```
That seems unfortunate. Not sure I have any good suggestions though.
This check is also redundant.
This check is also redundant.
Thank-you for the explanation. I'd guess the warning it `__init__` is probably not needed for most use cases, but it doesn't hurt and is only for 1 version. We can keep all the `permanent=True` stuff to silence warnings for now and remove them in 1.9. I'll add a TODO so we don't forget.
Yes, that's better.
I think it's fine to make them a bit inconsistent (at least for now). I opened an [issue](https://bugs.python.org/issue40300) in Python.
I wonder if we can just set `default_time_format` attribute.
I thought the change in `postgis/operations.py` is meant to alias `ForcePolygonCW` to `ST_ForceRHR` on older PostGIS versions to avoid the problem you described.
I moved `check_none_response()` to a separate PR #12474 and renamed it to the `check_response()`. I'm going to rebase this patch after merging.
This refactoring of this logic out into out into `check_none_response` is a nice bonus cleanup!
Maybe change that into a `try/execpt AttributeError`. It's kinda nitpicky, but given that if you want to use session-based CSRF you will most likely have a session object on the request and then try/except would be faster (And even if not, it seems more natural and shows a nice chained error on python3).
Why would you need to sanitize something that's already in your session? Seems a bit late...
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
I would use `DJANGO_SUPERUSER_PASSWORD`.
Yeah, good point.
I think we can simplify this: ```python if username is None: username = os.environ.get('DJANGO_SUPERUSER_' + self.UserModel.USERNAME_FIELD.upper()) ```
You can replace the if condition and branch with this one liner. Set `username` to the value of the environment variable defined by `username_env_var` or to its current value. ```python username = os.environ.get(username_env_var, username) ```
Ahh, I see! Thank you for the quick reply! Learning a lot from these PRs! :)
I don't usually include a blank line here.
I don't think it's necessary to create new files for this test. We could use for example `django.contrib.auth.models.Group` for a simple model with a name, and the test could be appended to the `TemplateRegressionTests` class, for example.
I think we should avoid writing new test suites that use fixtures. Fixture loading is extremely slow, and it's actually harder, IMO, to follow what the data should look like once you've aggregated it. I would suggest either creating all the data in a setUp method, or creating the data you need at the top of each test.
Please wrap docstring at 79 chars.
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
I see you've simply moved this, but I'd cleanup "template source loader" -> "template loader" to use consistent terminology.
It seems we can probably move deprecation warning handling to the actual test cases now. We can make it a follow-up item after merging the first version of this if you like.
We can keep them together ```suggestion with self.subTest(DEBUG=debug), self.settings(DEBUG=debug): ```
can omit these two newlines
Oh, right, of course; it's because of the default behavior of FS loader to look back at the engine's dirs.
IMO we can remove `_repetitive_name_errors()` hook, and move entire logic into `check_all_models()`, e.g. ```python for index_name, model_labels in indexes.items(): if model_labels: model_labels = set(model_labels) errors.append( Error( "index name '%s' is not unique %s %s." % ( index_name, 'amongst models:' if len(model_labels) > 1 else 'for model', ', '.join(model_labels), ), id='models.E030' if len(model_labels) > 1 else 'models.E029', ) ) for constraint_name, model_labels in constraints.items(): if model_labels: model_labels = set(model_labels) errors.append( Error( "constraint name '%s' is not unique %s %s." % ( constraint_name, 'amongst models:' if len(model_labels) > 1 else 'for model', ', '.join(model_labels), ), id='models.E032' if len(model_labels) > 1 else 'models.E031', ) ) ```
Might want to avoid `id` shadowing.
No need to create a `dict` if you're simply iterating over values.
Use a set here to perform containment checks.
I would use the same mechanism as for the `E020` and models' labels instead of `__name__`'s, i.e. ```python indexes = defaultdict(list) constraints = defaultdict(list) ... for model_index in model._meta.indexes: indexes[model_index.name].append(model._meta.label) for model_constraint in model._meta.constraints: constraints[model_constraint.name].append(model._meta.label) ```
RawSQL needs to be added to the group by clause, we can't know if it refers to something that doesn't have an existing alias. Getting CombinedExpression and Date here seems curious. These should be fixable, but lets not do it in this patch.
Instead of "set expressions to that field" maybe it would be better to say, "group by that field, HAVING expressions, and ..." since it's more useful to explain what the assignment means.
I'd chop "Note that"
@codingjoe unless I'm missing something that would require stopping to use a list comprehension. I guess the `alias` checking could be broken to a new line ```python expressions = [pk] + [ expr for expr in expressions if expr in having or ( getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases ) ] ```
I don't think this is completely correct. Models with a `Meta.ordering` can still make use of explicit `order_by` and when it's the case it should be honored.
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
We prefer hanging indent style like this: ``` self.assertEqual( res.context_data["form"].errors["__all__"], ['You must confirm the delete.']) ) ``` Also please drop the u prefix on strings.
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
this can be a single line (we prefer longer lines when it improves readability)
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
Chop blank line.
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
As far as I'm aware `unique_fields` should be required when `supports_update_conflicts_with_target` is `True`, so there is no need to use `unique_fields or ()`. Moreover, we should raise an exception when it's not provided.
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
{0} -> {} (I prefer the less verbose %s, actually) recognised -> recognized
In the current implementation if ``supported_formats`` evaluates to ``False``, then there would be a trailing space at the end of the error message. Probably it would be better to remove it from this string and add it to the string below: ``` msg += ' Allowed formats: {0}'.format(', '.join(supported_formats)) ```
What about erroring if `options` is non-empty at this point? Subclasses should have already consumed their arguments from it, and if there's anything left it's probably a mistake, like `explain(formatt='json')`
`getattr()` rather than calling a dunder method
I think we usually avoid _should_ wording in test docstrings.
Either add `self` or make it `@staticmethod`
Use single quotes consistently.
I don't think that we need 3 authors and 6 books for this test. I will remove the last author.
Please revert all unrelated changes from single to double quotes.
I would raise a `ValueError`: ```suggestion if not isinstance(perm_list, (list, tuple)): ValueError('perm_list must be a list or tuple.') ```
I think `include_superusers`, even if longer, would be more clear.
At some point, I wondered if it would be easier to just let users do `.exclude(is_superuser=True)` when they need to.
The replacement of the `hasattr` check by a `try`/`except AttributeError` can mask `AttributeError`s within `backend.has_perm`.
Any case where the method raises a `TypeError` which is not caused by the missing argument
Can you describe the reason for using 'singular' here and (as an example) not 'plural'? Code looks fine style-wise; I'm trying to understand the issue a bit more since translation isn't my expertise (If you want a review about that).
It'd be interesting to see some numbers for doing it this way[^1], as it may be 'good enough' to obviate #14849 entirely, which would be nice from a simplicity point of view. [^1]: and indeed I'll try and check the numbers against my own at some point.
I think most assertEqual don't include a comma on this line.
no comma since the stuff after "and" couldn't be a sentence on its own
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
Can we adjust the test name. We know this is `modelchoicefield`, because the whole `TestCase` is called that, so we can drop that. Maybe... `test_initial_accepts_model_instance_for_validation_when_field_disabled`? It's a bit long and horrible but... (???: suggestions welcome!)
please multiline the string ``` '<select id="id_f" name="f" disabled><option value="J">John</option>' '<option value="P">Paul</option></select>') ```
It's better to use `assertIs(..., False)` since `assertFalse` will also pass if `bool(result) is False`.
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
`# Values provided in the form's data are ignored.` Might be good to have a test for `Form(data, initial=...)` too.
Keeping the try block limited to just the code you expect to throw the exception is a good practice. It prevents a situation where there's some other bug than what you expected. For example, if `warnings.warn(` somehow threw a `KeyError` and it was in the try block, you would unexpectedly hide that bug.
to minimize size of try: ``` try: m2m = kwargs['many_to_many'] except KeyError: pass else: warnings.warn(.... ```
The approach you've taken here is: - Cache the result of get_fields() for a specific set of arguments - look up a name in that list; - Raise FieldDoesNotExist if the name is not found. The other obvious approach I can think of would be: - Cache a list of _all_ fields - Look up the name in that list - Raise FieldDoesNotExist if the name is not found - Raise FieldDoesNotExist if the field doesn't have the requested properties. I'd be interested to see the "memory vs speed" tradeoff for these two approaches.
True about the ML. Regarding the naming for `related_objects/related_m2m` vs `reverse_rel/reverse_m2m`, that's a new API so there isn't historical names to preserve (unlike `many_to_many` vs `m2m`), we just need to pick the best names to represent the relations.
The style I prefer is ``` options = { 'include_parents': include_parents, .... } ``` It's somewhat of a pain to indent additional items if your editor doesn't do it automatically with the other style.
```suggestion self.assertSequenceEqual(qs2, [self.objs[4]]) ```
```suggestion char_value=KeyTextTransform(1, KeyTransform("bar", "value")) ```
I _think_ this one will fail on Postgres at least since `->>` returns text natively. ```suggestion char_value=KeyTextTransform(1, KeyTransform("bar", "value")), ```
NVM, I forgot that `KeyTransform` aggregated instances of `KeyTransform` independently of their actual types https://github.com/django/django/blob/aed60aee38215e293d6ec2f3c96ec55bb9a62fc2/django/db/models/fields/json.py#L321-L323
It works with my proposition so we should have both assertions.
I've changed it to a deploy check because it's not really an issue in a local environment.
but OK let's have it.
You can use `Path.is_absolute()`.
Wrap at 79 chars.
```suggestion id='caches.W003', ```
No, `max_length` shouldn't be a required argument. I can think of multiple situations where I don't care about the maximum length.
I would use `os.path.splitext()`, e.g. ```python def get_available_name(self, name, max_length=None): """ Append numbers to duplicate files rather than underscores, like Trac. """ basename, *ext = os.path.splitext(name) number = 2 while self.exists(name): name = ''.join([basename, '.', str(number)] + ext) number += 1 return name ```
You can have a look at 9bf652dfd6a738fd841471f6abd71cba1b206d9f as an example of how we introduced object level permission to authentication backends.
Use PEP257 verb style for new docsrings: "Create... use..., etc."
I'm talking specifically about `index_together = 42`.
Please check with Python 3.6, no exception is raised here (see a7a7ecd2b026c61a39a46d2d7eced0e06a92c970).
See also my recent Trac ticket suggesting to normalize behavior across Python versions.
``` python # the following time is equivalent to UTC 2014-03-13 05:34:23.24000 ```
Try to minimize the test that demonstrates the regression. I think this part isn't important -- assigning a value when creating the model should work just as well.
``` python # but in UTC, the __date only matches one of them ```
Looks like this could be a 1 line docstring.
This check is also redundant.
This check is also redundant.
I think `GET` is fine for that.
`items = value.split(self.delimiter) if value else []` is slightly faster.
```python objs_to_clear = {field: items - objs for field, items in self.restricted_objects.get(model, {}).items()} ```
Invert the logic of the if statement and indent the two lines above, as the implicit return will be fine here. (Other cases of this should only be done in a separate clean up commit if you get tempted.)
IMO it's more readable without `get(model, {})` I would also collect `ID`'s in the first step, e.g. ```python def clear_restricted_objects_from_queryset(self, model, qs): if model in self.restricted_objects: ids = [ obj.pk for objs in self.restricted_objects[model].values() for obj in objs ] self.restricted_objects[model] = { field: items - set(qs.filter(pk__in=ids)) for field, items in self.restricted_objects[model].items() } ```
chop blank line
This doesn't feel very efficient - there will be a query per loop. You should be able to fetch all objects in a single query, grouping by the field.
I wonder if we could support running `runtests.py` from different directories :thinking: like we do for dotted module names, e.g. ```bash ~/repo/django> ./tests/runtests.py backends.postgresql ``` works fine, but ```bash ~/repo/django> ./tests/runtests.py backends/postgresql/ .... File "./tests/runtests.py", line 155, in get_label_module rel_path = path.relative_to(RUNTESTS_DIR) File "/usr/lib/python3.8/pathlib.py", line 904, in relative_to raise ValueError("{!r} does not start with {!r}" ValueError: '/repo/django/backends/postgresql' does not start with '/repo/django/tests' ``` crashes. I tried to fix this with: ```python # Otherwise, interpret the label as a path. if not path.is_absolute(): return path.parts[0] else: path = path.absolute() rel_path = path.relative_to(RUNTESTS_DIR) return rel_path.parts[0] ``` but it crashes with `ModuleNotFoundError` (like without this patch): ``` ====================================================================== ERROR: backends/postgresql (unittest.loader._FailedTest) ---------------------------------------------------------------------- ImportError: Failed to import test module: backends/postgresql Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 154, in loadTestsFromName module = __import__(module_name) ModuleNotFoundError: No module named 'backends/postgresql' ```
Yeah it works for me, sorry again. The current version looks good :+1: , we could only raise a more descriptive error when a relative path is not correct (as proposed in https://github.com/django/django/pull/14507#discussion_r648186310).
Maybe this could be a module constant so as not to repeat it 3 times.
Any idea what the "cost" of this is? ie: because all template output runs through `render_value_in_context` -> `localize` which then dispatches to any of `number_format` / `date_format` / `time_format` each of which _may_ call `settings.USE_L10N` depending on if the `context.use_l10n` value (and I confess I can't remember when/where the details of _that_), each of those values (decimals/ints/floats/datetime.*) is unavoidably going to be slower (if/when `use_l10n` is `None`), and I wonder by how much? And is it avoidable? (eg: `cached_property` or what-have-you)
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
Well, mariadb support in the mysql backend. Will get on to that soonish.
I think we should add this to the opclasses as well then.
I think this can be single lined: ```python # Does the backed support window expressions (aggregate OVER (expression))? ```
> That seems good. My only concern is that it's unclear if the flags that apply to a single database are truly generalizable. For example, there's also: Yes, but we have at least a few less vendor checks, and it seems better than three feature flags `supports_geojson_(crs/bbox/precision)`. > I feel like we'll have to continue some vendor checks. Unfortunately, yes.
We have two more options that are not supported on Oracle, co maybe we should add a set with supported options and handle all of cases in a single feature, e.g. ```python supported_geojson_options = {'bbox', 'crs', 'precision'} ```
~~Maybe a list comprehension here too.~~ EDIT: Forget it, I misread the double for-loop.
~~Maybe a list comprehension here too.~~
That's why I wrote "maybe" ;)
Forget it, I misread the double for-loop.
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
I noted this too and wasn't sure if it was an error or not. Can you 'save' an aggregate? ``` Model.objects.update(salary=Max('salary')) # would this work? ```
Careful, you're mutating `self.config` rather than a copy of it. If you hang onto an instance of `SearchVector` and reuse it then resolve_expression will be called on it twice. You'd be better off figuring out a way to add `config` via `self.set_source_expressions()` rather than overriding resolve_expression and `as_sql`. Even if that means using private expressions to build the components.
The flake8 error is due to missing a space after the comma here. Please use single quotes instead of double.
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
I don't think that we should change anything in the `resolve_expression()`, IMO the easiest way to implement this is to override `filterable` property for `CombinedExpression` and `Func`, e.g. ```diff --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -454,6 +454,10 @@ class CombinedExpression(SQLiteNumericMixin, Expression): c.rhs = c.rhs.resolve_expression(query, allow_joins, reuse, summarize, for_save) return c + @property + def filterable(self): + return self.lhs.filterable and self.rhs.filterable + class DurationExpression(CombinedExpression): def compile(self, side, compiler, connection): @@ -630,6 +634,10 @@ class Func(SQLiteNumericMixin, Expression): copy.extra = self.extra.copy() return copy + @property + def filterable(self): + return all(expr.filterable for expr in self.get_source_expressions()) + ```
`with self.assertRaisesMessage('Needle HTML does not have a root element'):`
`clean()` works without this patch. The issue is in rendering a bound field. We should check `errors` and `as_p()`.
> I guess the behaviour of the field informs what the widget/form render? Yes.
`Final exception` doesn't appear in a template. I added check for `During handling of the above exception`.
Does it also work if you leave away the wrapping DIV? It isn't obvious to me that the issue from the ticket (`'<a/><b/>'` should be contained by `'<a/><b/><c/>'`) is being addressed by this change.
Use `self.username_field` instead.
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
Please don't make unrelated whitespace changes.
```suggestion timeout=60, ``` "60" on its own looks a bit weird. Also, it surely doesn't need to be as long as 60 seconds if `DELAY_AFTER_FAILED_LOGIN` is so much smaller? What if `DELAY_AFTER_FAILED_LOGIN > 60`? Maybe this should be: ```suggestion timeout=self.DELAY_AFTER_FAILED_LOGIN + 10, ```
same thing here about assuming `is_active` exists and `not user.is_active` -- probably need some tests for that case.
Use `settings.ALLOWED_HOSTS = settings.ALLOWED_HOSTS + ['testserver']` to avoid altering the original list assigned to `request._original_allowed_hosts` above.
I think I'd make this an `Error` - I don't think translation works at all if this is wrong.
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
this line should be: `def __init__(self, *args, **kwargs):`
Please use assertRaisesMessage to verify this is the ValueError we expect.
There's a typo 24278 should be 24279 -- if you put some thought into it, you'd see this has nothing to do with squashmigrations.
Docstrings should state the expected behavior. It doesn't need to describe an old, incorrect behavior.
no ticket reference needed
Chop blank line.
This needs an order_by clause so that the results are guaranteed to come back in the right order.
I think a simple `django.template.Context` will do here.
I see, thanks for your answer. I really don't want to hold the template based widget stuff from landing any longer. I suppose this is something we could refactor later on.
Please don't change all the other unaffected lines.
.get() falls back to None to `False` isn't really needed I think.
It seems we can probably move deprecation warning handling to the actual test cases now. We can make it a follow-up item after merging the first version of this if you like.
comma after tuple
flake8 complains about missing spaces around `*`
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Oh, I just meant to suggest the `value` to `values` (plural) renaming, not more...
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
This usage looks a bit magic to me, but I think it can stay as it is. The module level deprecation warnings in https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01 are different than this, so stacklevel=2 can be removed in the following locations: - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-9e264d0b47bfdd60be1698bca9bae281R19 - https://github.com/django/django/commit/f59fd15c4928caf3dfcbd50f6ab47be409a43b01#diff-68395a4996a48dd1b3cd34ddd9efe762R12
should use `RemovedInDjango110Warning`
isort rewrites this to `convert_exception_to_response, get_exception_response,`
Why the `CombinedExpression` and not `Expression`? IMO it's misleading, I know that `CombinedExpression` has the concept of right-hand and left-hand sides but for other purposes.
I thought about this. It's a much bigger change, just for a deprecation. Inserting a deprecation is one thing. Adjusting method calls is something else: `MiddlewareMixin.__init__()` calls `super()` so there's a potential logic change. Don't know where exactly, but I didn't want to risk a regression just to save the extra lines here implementing this deprecation.
Sounds, good thanks for giving this ticket a shot by the way. It's a tricky problem with a few edge cases but you'll certainly learn a lot of things along the way.
Hey guys, `index_together` and `unique_together` have been fixed before in this BR: https://code.djangoproject.com/ticket/24757
Here we also should call `super` and not copy-paste code
What about indexes and constraints based on `expressions`? For example: ```python Index(F('author'), F('title'), name='author_title_index') ```
This formatting change is not related with a bug fix, please revert.
Please use hanging indents here, too: ``` python self.assertEqual( list(...), [...], ) ```
`fix_this` is misleading, because there is nothing to fix here.
Please us single quotes.
Single line here is fine (as the style guide says, we allow up to 119 characters if it improve readability).
Blank line not needed.
```suggestion Call clean_fields(), clean(), validate_unique(), and validate_constraints() on the model. ```
As far as I'm aware, for backward compatibility we should assigned errors from `UniqueConstraint`s with a single field to this field :thinking:
Maybe we could test that `name_color_uniq` is also in the message? ```suggestion with self.assertRaisesMessage(ValidationError, 'name_color_uniq'): ```
Thanks for these tests, they look great!
This message shouldn't be used when constraint is defined with `expressions`.
No need to have empty lines, see the code above
We can move the test that involves `login()` to the other pull request.
prefer `setUpTestData` since that executes once per test class instead of once for every method
You should be able to pass `is_active=False` to `create_user()`.
I'd only use mock as a last resort and instead pass some email that will be affected by the normalization.
Here's the style we usually use for long messages: ``` msg = ( '....' '....' ) with self.assertRaisesMessage(ImproperlyConfigured, msg): ```
are the Meta classes necessary? the test fails and passes before and after the fix without them
No need to multiline statements like this which will fit on a single line.
`self.assertFalse()` -> `self.assertIs(..., False)` `self.assertTrue()` -> `self.assertIs(..., True)`
The note should be generic -- describe the sort problem as it could happen to any app -- a reference to contrib.postgres isn't needed.
You can remove semicolon.
Please use hanging indentation and capitalize `SQL` syntax, e.g.: ```python cursor.execute( 'CREATE VIEW inspectdb_people_view AS ' 'SELECT name FROM inspectdb_people' ) ```
Please use single quotes. You can use directly `out.getvalue()` instead of a temporary variable, e.g.: ```python self.assertNotIn('class InspectdbPeopleView(models.Model):', out.getvalue()) ```
You don't have to initialize `out` twice. This line can be removed.
If the line length bothers you, I think dropping "database" would be fine.
I would move it to `_init__()`: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ... self.index_type = index_type or `GIST` self.condition = condition super().__init__(name=name) ``` and skip the default in `deconstruct()` and `__str__()`: ```python def deconstruct(self): ... if self.index_type != 'GIST': kwargs['index_type'] = self.index_type ```
We can use `compiler = query.get_compiler(connection=schema_editor.connection)`
Also here: ```python if self.index_type.lower() != 'gist': ```
It will be `django.contrib.postgres.constraints.XXX` but I don't think that's an issue for core constraints we return `django.db.models.XXX`.
Maybe `_parse_where()` -> `_get_condition_sql()`, I would return condition and add `WHERE` in `constraint_sql()`, e.g. ```python def _get_condition_sql(self, compiler, schema_editor, query): if self.condition is None: return None where = query.build_where(self.condition) sql, params = where.as_sql(compiler, schema_editor.connection) return sql % tuple(schema_editor.quote_value(p) for p in params) def constraint_sql(self, model, schema_editor): ... condition = self._get_condition_sql(compiler, schema_editor, query) return self.template % { ... 'where': ' WHERE (%s)' % condition if condition else '', } ```
no newline between fields (see style of other forms) Also, I don't think `label` and `initial` need to be specified. Try to include only the minimum functionality that's needed to reproduce the error and prove the regression is fixed.
Please move `)` to a new line: ``` py return self._html_output( normal_row='<p%(html_class_attr)s>%(field)s %(field_name)s</p>', error_row='%s', row_ender='</p>', ) ```
You don't need to use `"""..."""` here: ``` py self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> custom' '<input id="id_hidden1" name="hidden1" type="hidden" />' '<input id="id_hidden2" name="hidden2" type="hidden" /></p>' ) ```
Same here: ``` py self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> custom</p>\n' 'rest of the HTML' ) ```
please limit line lengths so horizontal scrolling isn't required, something like: ``` self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> ' '...' ) ```
I think that `BaseForm.get_context()` describes this perfectly well: ```suggestion ``` But if we must keep it, it should be collapsed onto one line: ```suggestion """Returns context for form rendering.""" ```
```suggestion """Render as <p> elements.""" ```
I know this is the sort of layout that `black` would generate, but it's one of the more ugly choices it doesn't get right in my opinion. Perhaps we should `+=` instead of `.extend()`: ```suggestion top_errors += [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
Yes, that sounds good to me.
Are there situations in which this can happen other than "too many subqueries"? If not, I'd suggest an error message that might be more helpful to the end user would be "Maximum recursion depth exceeded: too many subqueries."
I may be missing something, but it seems this line could be bumped out one indent - no point in re-setting `prefix` to None on every product, when it won't be used again until the next outer (count) loop.
I think a docstrings explaining what `prefix_gen` generates would be good.
This now raises a warning, so I adjusted to use a view.
Ah, good point. I don't think it's cleaner in general, I was just trying to keep `QuerySet` / `Query` fast like my optimization efforts. Since it's a fairly small here I don't feel that strongly about the global, you can leave it as-is
I think this should be a `ValueError`
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
@coldmind I think @charettes was suggesting change the original `_parse_expressions` to differentiate between strings and numbers, and I think that's a great idea. Rather than define the method above on `StatFunc`, we should change the method directly on `Func` which will then propagate to StatFunc through inheritance. It may be a little magical, but the rules can be defined quite clearly. "string is a field ref", "resolve_expression passed verbatim", everything else is a "Value(value)". I like this enough to write a patch today for inclusion in 1.8beta - and update all the applicable tests. Will land it today hopefully, and then we can rebase this PR here.
"Both Y and X must be provided". Switch the Y and X in the error.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
Abort early if `self.db_table is None`
You should use `self.m2m_db_table` instead of `self.db_table`.
I suggest you skip the check (`return []` early) if the intermediary model (`self.remote_field.through`) is not resolved. That is `isinstance(self.remote_field.through, six.string_types)`. Also I would store `m2m_db_table` in a variable as you'll need to reuse it to lookup `registered_tables` below.
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
> Is there any specific reason why we would prefer using the operation in this case? Yes, because we have it. Using a RAW SQL is the last option, we're developing the ORM in order not to use them.
This message is different on PostgreSQL 13+, it should be enough to check that a constraint name is in the message.
IMO it's enough to test that `CreateExtension` honor `allow_migrate()`, creating extension is already tested in `postgres_tests`.
I think we usually avoid _should_ wording in test docstrings.
`constraint_name` should also be quoted.
`redirect_to_login()` is a helper function, not a view.
OK, that sounds/looks interesting. Let me have a play. Thanks @jdufresne!
This will _break_ the debug page I think: instead of a list of routed URL patterns, we'll get a plain 404 error response. (Would like to do something at the resolver level, but we don't have the request... Can we limit it just to `DEBUG=False`? 🤔)
Don't add a blank line.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Please wrap these lines at 79 characters.
) goes on the next line.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
The word `generally` doesn't add any value in my opinion.
I'm not certain `Warn` is the best word now that this is an `Error`, but I'm not sure how to phrase it instead.
Well, we _could_ make `on_delete` an actually-required arg to `ForeignObject` right now, and move it even before `from_fields` and `to_fields`, but that would require duplicating the deprecation warning in both `ForeignKey` and `OneToOneField`.
I think this second sentence could be removed
This is a nitpick, but `on_delete` is not an attribute you set, it is an argument you pass. I think that second sentence could just be removed. What might be more useful here is a stable link to the `on_delete` docs.
Well, there are a number of existing cases of docs URLs in user-facing messages (especially in migrations, but other places as well). I think there is a lot to recommend them from a UX perspective; someone who gets this warning is quite likely to in short order need a reference of the available `on_delete` options. I don't think the URL-going-stale issue is that big for a deprecation warning, which has a limited lifespan anyway. If someone does happen to rearrange those docs in the next couple years, we'd just update the message. (Like the ones in migrations, the message should use a Django-version-specific docs link, not the `stable` redirect, so that for a given Django version the link shouldn't ever go stale.)
Please do not change formatting
```suggestion from django.utils.deprecation import RemovedInDjango50Warning ```
This will target Django 4.0, where after #13915, Python 3.8 will be the lowest supported version, so we can use `functools.cached_property` I think.
In general, this utility is long overdue. In detail, I think error_prefix is odd here -- you're essentially mixing a piece of error formatting (or even logging) with the function.
Discussion of this function is outside of the scope of this ticket, this is merely a backport of what's already in master and 1.6: https://github.com/django/django/blob/master/django/utils/module_loading.py#L12
I'd order "django.utils import (X)" stuff before any `django.utils.(foo)`
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
A docstring describing the purpose of this test may be useful.
Please use assertRaisesMessage to check the message too. We prefer the context manager version usually `with self.assertRaisesMessage(ValueError, msg)`. I think combining the two tests so you can reuse the `msg` variable would be fine.
I had a similar thought though I wasn't sure if the change would be an improvement or not. "pr" me think "pull request". I haven't reviewed this in detail yet.
argument -> a GET parameter
I would use ```python exc_type, *_ = sys.exc_info() ``` or ```python exc_type, _, _ = sys.exc_info() ``` :thinking:
is `str()` needed? I assume `%s` takes care of that.
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
Single quotes please.
a one -> one
Maybe e.g. `Calling exclude() is not supported after union().`
Clever use of the integer nature of `bool`, first time I've seen this pattern. It kind of hurts readability though IMO.
I think we also need to exclude [conditional constraints](https://docs.djangoproject.com/en/3.0/ref/models/constraints/#condition) here.
It might help readability to pass `method_name='aggregate'` -- otherwise the meaning of that string isn't so clear without looking up the method's signature.
Should we also have a pointer here of the form ```suggestion with self.assertRaisesMessage(FieldError, "Cannot distinct on 'other_rating' alias. Use annotate to promote it"): ```
It allows many new schemes that weren't allowed before.
I think we should include `*args, **kwargs` and pass them to the super `__init__`
Also forgot to mention, I don't think I've seen many regex'es written this way before (using string constant concatenation and continuation lines), and I find it pretty neat.
My point wasn't the r prefix (I just copied that from above), it was moving the dash next to the close-bracket. But now that you mentioned it -- yes, the first and last (`'\.'` and `'\.?'`) need an r prefix, because without it the strings don't have a backslash in them and these expressions will just match anything. I think a test for this could use some invalid punctuation as the separator for the tld -- e.g. `http://unquoted~dot!`
This allows `xn----nx` and even `xn-----`. Are they valid? (edit: FWIW, my IceWeasel seems to think they are)
I would have been interested in something closer to werkezeug's. That takes encoding as a parameter, etc. **Edit**: TL;DR skip to https://github.com/django/django/pull/2932/files#r15440287
The latin1 encoding mess is a WSGI thing, Django wasn't always a WSGI framework, and who knows what will be the next best thing in the future. When these things were contained in the WSGIHandler that made sense, but if we extract a reusable function it shouldn't be tied to such specifics.
Interesting! I guess we could implement it at some point, but that seems like a fair amount of work.
`repercent` is a confusing name, maybe `repercent_broken_unicode`? Also it needs a docstring with pointers to the RFC etc.
Fair enough, I assumed it was a small tweak to the stdlib version.
However the `zoneinfo.ZoneInfo("UTC")` vs `timezone.utc` thing shakes out, it might make sense to support `timezone.utc` anyway, which has a `repr` of `datetime.timezone.utc`? Or is the idea that you only want to capture the situation where someone has used `django.utils.timezone.utc` specifically, and you want to always give them `django.utils.timezone.utc` in the event of migrations between Django instances with different values for `settings.USE_DEPRECATED_PYTZ`? If that's the case, do you want special-case logic for handling the more generic case of time zones? Presumably the `repr` can be rewritten to use something like `django.backends.db.timezone_constructor` instead? (Though there may be a performance hit from this, which may or may not be acceptable).
Not sure if changes to these check methods are required -- was there a discussion somewhere about it? At least tests are missing for these changes.
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
`frozenset` is missing.
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
well, it's not functionally equivalent. if some imports succeed `site._registry` won't reflect those that succeed before the failure. I was thinking you could add a `registry` keyword to `autodiscover_modules` to allow passing in an optional `registry`.
I'd call the keyword and variable "registry" and pass in `registry=site._registry` as another application may have a different convention for how it wants to define a registry.
Good point, I guess we can keep it as is. Maybe just rename `site` to `register_to`, i.e. `autodiscover_modules('admin', register_to=site)`
site -> register_to
True, I missed this.
Could this test be moved to `BaseCacheTests` under `test_empty_cull` to make sure the implementation works on all backends instead of only the database one? https://github.com/django/django/blob/0bebe5266f2e52a76fcf6d23b76942399d087bf2/tests/cache/tests.py#L601-L622
check flake8 ("missing whitespace around operator" here)
I checked locally. It should pass for other backends.
suggested wording: "SystemExit is raised if the user answers "no" to the prompt asking if it's okay to delete the test tablespace."
If you could give a try at rewriting this docstring to conform to our guidelines about stating the expected behavior, that would be nice.
Invert the logic of the if statement and indent the two lines above, as the implicit return will be fine here. (Other cases of this should only be done in a separate clean up commit if you get tempted.)
```python objs_to_clear = {field: items - objs for field, items in self.restricted_objects.get(model, {}).items()} ```
chop blank line
This doesn't feel very efficient - there will be a query per loop. You should be able to fetch all objects in a single query, grouping by the field.
IMO it's more readable without `get(model, {})` I would also collect `ID`'s in the first step, e.g. ```python def clear_restricted_objects_from_queryset(self, model, qs): if model in self.restricted_objects: ids = [ obj.pk for objs in self.restricted_objects[model].values() for obj in objs ] self.restricted_objects[model] = { field: items - set(qs.filter(pk__in=ids)) for field, items in self.restricted_objects[model].items() } ```
```suggestion backend = self.base_params['BACKEND'] ```
```suggestion with self.subTest(location), self.settings(CACHES=settings): ```
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
I think that we should unpack `self._options` here and make them arguments of `RedisCacheClient.__init__()`. ```suggestion return self._class(self._servers, **self._options) ``` This is how we approach this for all of the memcached backends using client classes implemented in third-party packages.
Please move `add()` above `get()` to keep the order consistent with the definition in `BaseCache` and other backends. (It's probably worth ordering the methods in `RedisCacheClient` in the same way.)
up with Django imports
unused import (please check code with flake8 as there are some "expected 2 blank lines" warnings as well).
The blank lines in this method aren't needed.
The `L` suffix raise a `SyntaxError` under python3. This should be `lambda: long(9999999999999999999)`.
Add a trailing comma.
I think a list comprehension would be more readable.
longer lines here are okay, we try to avoid non-multiple of 4 indents
This is inconsistent but I think the patch can land as is and the test be modified later on based on the direction of [#24082](https://code.djangoproject.com/ticket/24082).
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
What about using an `elif isinstance(m2m_relation, ManyToManyRel)` clause instead and issuing a `continue` in an `else` branch? This looks more safe in regard to third party fields that might exposed them as `many_to_many = True`.
use a single line here -- lines up to 119 characters are preferred when it helps readability.
Use capitalization and periods
ATM is -> than with
fixme -> TODO
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
`clean` is not only for validation, but also for data modification in a form.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
drop the new line please
These check should respect `required_db_features`, so we need to omit checking conditions for `UniqueConstraint`\`s if `connection.features.supports_partial_indexes or 'supports_partial_indexes' in cls._meta.required_db_features`.
This duplicates logic from `_check_local_fields()` and added unnecessary error `models.E042` which is already covered by `models.E012` in `_check_local_fields()`. I think we should pass fields from `references` to the `_check_local_fields()` and remove redundant logic, e.g. ```python for field_name, *lookups in references: fields.add(field_name) if not lookups: # If it has no lookups it cannot result in a JOIN. continue try: field = cls._meta.get_field(field_name) if not field.is_relation or field.many_to_many or field.one_to_many: continue except FieldDoesNotExist: continue # JOIN must happen at the first lookup. first_lookup = lookups[0] if field.get_transform(first_lookup) is None and field.get_lookup(first_lookup) is None: errors.append( checks.Error( "'constraints' refers to '%s' which results a JOIN attempt, " "JOIN is not permitted in 'constraints'." % LOOKUP_SEP.join([field_name] + lookups), obj=cls, id='models.E042', ) ) errors.extend(cls._check_local_fields(fields, 'constraints')) ```
This would be more readable and consistent with our indentation style with something like: ``` foo_constraints = [ name for name, details in constraints.items() if details['columns'] == ['name'] and details['unique'] and name != custom_constraint_name] ] self.assertEqual(len(foo_constraints), 1) ``` (choosing a different name than "foo"
What about m2m and reverse relationships? Something like `Q(cities=3)` will also produce the join.
Looks like we just need to use `_meta._get_fields(reverse=False)`.
Yeah, the import itself is very likely non-necessary, too.
This doesn't seem correct as `SimplePoFileTests` no longer has any tests in it so now this subclass doesn't do anything.
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
In the suggested command list, `'python'` should be `sys.executable` to ensure the same Python that is running the tests is used in the subprocess.
an app containing a locale folder
And I would rename this attribute `superusers` as it's meant to contain multiple users.
use `reverse()` rather than a hard coded URL.
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
You can use `mock.atomic.assert_called_with(using=db)` here instead.
should this be a cached property? seems to do a fair bit of work
it's weird to me that we have to copy managers both here and in `ManagerDescriptor`. why couldn't the descriptor find the appropriate manager from `model._meta.managers` instead of re-copying it at runtime? Would require tracking managers by name in `Options`, but that doesn't seem like a big deal.
Seems like a context manager would be good here so the cache can be cleared regardless of whether or not the test passes (also we could simply decorate the test method).
```suggestion self.assertDoesNotOptimize( ```
Rather than `get_num_test_processes()`, I wonder if something like `get_max_test_processes()` might be a better name. This is because the number of test processes can wind up being smaller, e.g. if there are fewer `TestCase` classes. (You also assign to `max_parallel` elsewhere, so there is an awareness of this meaning / caveat.)
ticket-30949 is currently not accepted due to some performance issues, so we should use `cached_property` from `django.utils.functional`. We can swap all uses of `cached_property` when implementing ticket-30949.
Wrap docstrings at 79 characters.
I think this change should be undone. Python 3 (normally) defaults to `utf-8`... and when it doesn't, this change introduces the chance of a regression. The default file isn't the only possible gzipped file.
Right, sorry, forget about `encoding`, should be `gzip.open(str(password_list_path), mode='rt')` according to [the doc](https://docs.python.org/3.7/library/gzip.html#gzip.open). (Notice it's `rt`, not the usual `r`).
If anything is raised besides `OSError`, it will propagate, it won't continue to the `with` part. This is the same as the existing behavior.
Doesn't exist in 1.5, be careful when backporting
I'd move all `django.utils.encoding` import to one line.
This import should be alphabetized, but we can fix that up when committing.
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
📖 I think we could add a docstring to this explaining why `__init__` was overridden. This and `CaseInsensitiveMapping.__init__` looks pretty similar
The size of self.MEDIA_TYPES won't be large, but it would be good to pre-compute this.
`type(self)(...)` looks more Pythonic to me.
I don't know if you need to actually create all the Medias. At this point a unit tests calling merge is sufficient. What I would like to see is: ```python assert list(merge([1,2],[1,3],[2,3], [5,7], [5,6], [6,7,9], [8,9])) == [1,2,3,5,6,7,8,9] ```
This is the same test as above.
Use a single quote.
Thanks. Good point.
The current form is consistent with messages in similar checks. Also, we use here `display_name`, e.g. `MySQL does not support indexes on expressions.` so I don't think that `Database` adds much value here.
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
These check should respect `required_db_features`, so we need to omit checking conditions for `UniqueConstraint`\`s if `connection.features.supports_partial_indexes or 'supports_partial_indexes' in cls._meta.required_db_features`.
The wording is a bit inconsistent with the one for check constraints, here there is some duplicate info between the warning and the hint, and it talks about "The constraint" without naming it. I would suggest: ``` checks.Warning( "%s does not support unique constraints with conditions." % connection.display_name, hint=( "A constraint won't be created. Silence this " "warning if you don't care about it." ```
The tests are failing with: ``` + flake8 ./django/core/management/__init__.py:320:16: F821 undefined name 'ModuleNotFoundError' ``` and rightly so. I think the exception is removed in Python 3 from what I can see on Google.
Seems wrong to hard code this list when Django fully supports user-written commands.
`Final exception` doesn't appear in a template. I added check for `During handling of the above exception`.
I'd change this to: `If the database should be kept, ignore "database already exists".`
`', '` (since quotes)
Might want to only test for `JOIN` presence as this wouldn't fail if `LEFT JOIN` was used.
``` """ QuerySet.count() on a many-to-many relation doesn't include an unnecessary JOIN. """ ``` Ticket references should be reserved for obscure issues (not needed here, I think).
Move the exists assertions to another test.
The fact only a single result is returned is a strong enough assertion here. Some database backend could translate `__isnull` to some different SQL.
Oh I realize that asserting against the results is problematic given all the engines we're testing against support foreign keys. In this case yes, using the same `JOIN` check against `captured_query` should do!
I think we can abstract away the need to _lower_ the name here. ```suggestion def alter_model_options(self, app_label, model_name, options, alter_option_keys=[]): ```
```suggestion self.remove_model(app_label, old_name) self.reload_model(app_label, new_name, delay=True) ```
```suggestion def alter_model_managers(self, app_label, model_name, managers): ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
missing quote after `modelname` which should also be `model_name`
I suggest to add a line break and list models one per line with 2 spaces indentation.
I'd certainly be tempted to get rid of this branch, unless someone can identify a case that hits it.
I think you can simply decorate the method with `@contextmanager`. Also, a docstring for the method would be good to add.
is there a need to store `self._ready` on self instead of simply using a local variable (besides for checking it in tests)? `del self._ready` seems a bit ugly.
`type_` -> `invalid_type`
These assertions are not related with this patch. Personally I don't see much value in adding them.
This is probably worth it's own test-case. (For ref: there are similar tests on ln70)
```suggestion *_, kwargs = obj._meta.get_field('storage_callable').deconstruct() ```
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
I wasn't familiar with `assertFormError` actually. Guess the main difference is that `assertFormError` is a single field. Happy to leave that though, the nicer `assertFormValid` is useful in itself.
Yes, exactly. However, if the value is truthy but not `True`, I think the current message could be confusing. So perhaps some alternate failure message should be used when the method doesn't return a `bool`. Same idea should be applied to `assertFormNotValid`.
I think it would be nice if these methods verified the value is identical to either `True` or `False` and not some other truthy/falsey value. This would align with recommendation in the [coding style guildelines](https://docs.djangoproject.com/en/3.0/internals/contributing/writing-code/coding-style/): > Use assertIs(…, True/False) for testing boolean values, rather than assertTrue() and assertFalse(), so you can check the actual boolean value, not the truthiness of the expression. As well as stdlib [unittest](https://docs.python.org/3/library/unittest.html#unittest.TestCase.assertTrue): > Note that this is equivalent to bool(expr) is True and not to expr is True (use assertIs(expr, True) for the latter).
Also, I don't think we should collect this in `to_report`. We can fail immediately with `self.fail('Form is valid')`.
I think we should build an `ErrorDict` of expected errors and use `assertEqual()` to compare it with `form.error`. This way we will avoid building a custom message. See also ticket-24782 that should be fixed in advance.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
I think `GET` is fine for that.
@MarkusH Such a request should not change any state, so it should be `GET`. Using `POST` and `CSRF` wouldn't help against DoS there anyways (unless I miss something). If you are worried about querying the database, you can do the same with a normal request to the list views in the admin…
Good point :)
It would be clearer to the end-user if the help was "Shows output from passing tests."
Unrelated, but I wonder if we need '-k', '-r', '-d' for the new options rather than only their verbose counterparts. Seems like we are going to run into a conflict a some point with two options with the same first letter if we keep doing that.
Remove spaces around the equal sign. It should be ```default=False``` to match PEP8.
I feel like this boiler-plate could be handled more nicely. For example, what about defining a function above that looks something like-- ```python def add_argument(parser, name, *args, help=None, **kwargs): if name in self.suppressed_base_arguments: help = argparse.SUPPRESS parser.add_argument(*args, help=help, **kwargs) ``` Then each `parser.add_argument(...)` would become `add_argument(parser, name, ...)`. I also think it would be better if the convention were for the string in `suppressed_base_arguments` to match the first option string passed to `parser.add_argument()` (e.g. `--force-color` instead of `force-color`). I think it would be easier to remember. Also, if that were done, the name wouldn't have to be passed a second time, or manipulated in any way inside the helper function above before checking for membership in `self.suppressed_base_arguments`.
They can be empty for subclasses, I think we can leave it that way.
Please don't change all the other unaffected lines.
`expressions` should be before the `name` like in other classes.
I added the comma to be consistent with the `include` and `condition` attributes. Also, on `ExclusionConstraint` we separate attributes by comma but not on `UniqueConstraint`, so 🤷 indeed..
~~Also use `%r` and not `repr()`.~~
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Hah. Had the same thought before I got here. See the caveats mentioned above.
Annoying that `datetime.time` cannot be subtracted from each other to give a `datetime.timedelta`, so we cannot use `duration_microseconds()` as in `_sqlite_timestamp_diff()` below.
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
This will overwrite an explicitly given message if you use ``` python validator = DomainNameValidator(accept_idna=True, message='Only IDNA domain allowed') ```
Not sure if ``` def check(self): return self._check_pattern_startswith_slash() ``` is better or not.
`elif` might be clearer (I understand it's not necessary)
This check is only necessary in `URLResolver._populate()`, since `URLPattern._populate()` can never be called recursively.
How about omitting it until we have a use case? That will save writing tests and docs for a theoretical feature. :-) From a readability point of view, writing a `re_path()` that mixes regexes and converters in the string, and then has to initialize and pass converters in the URLconf sounds nasty and not something to encourage!
Test -> Tests (and I suggest a new `test_history_view.py` file since this file is quite large already.
Adding new code in a good location is fine.
I think reorganization of the admin views tests deserves its own patch outsie of this ticket.
I think this test should be in its own class so it can have a setUp/tearDown with the "old_warn_override_settings" logic. If the assertions fail, COMPLEX_OVERRIDE_SETTINGS won't be restored to its original values which would cause the test to leak state.
Please use hanging indent here and below in `assertEqual`: ``` data = [ {'0': 'a', '1': '42'}, ] ```
This one seems ok to me.
Indeed this one looks fine. It will have beneficial performance effects if: - ATOMIC_REQUESTS is not in use - `update_or_create` ends up creating an object - the `save` method of that objects does long things like sending email _after_ the write (i.e. once it holds an exclusive lock on the database)
You'd need to either include both `f.name` and `f.attname` or use `self.model._meta.get_field(name)` for each `defaults` which I think supports both form e.g. ```python get_field = self.model._meta.get_field update_defaults = True for default in defaults: try: field = get_field(default) except FieldError: break if not field.concrete: break else: update_defaults = False ```
> And yes it feels wasteful, but what are the options? I guess `Options` could have a private `cached_property(_concrete_field_names -> frozenset)`. It seems niche enough to be kept private but worth it given this set is computed on every `Model.save(update_fields)` call and on every `QuerySet.update_or_create` call after this PR.
I think this should include non-concrete local field as well since `select_for_update` will lock at tables involved in MTI and `Model.save` handles it just fine.
The problem is that an expression like extract(year from datefield) = 2015, then the DB will not be able to use indexes on datefield. But if you instead have datefield >= '2015-01-01' and datefield < '2016-01-01', then the db can use indexes. This is the underlying reason why we have the special year lookups.
I was asking as major databases support year extract functions, so year comparing can be done as consequent joining of a transform and standard comparison lookup. So, creating YearGt and etc lookups will become really unnecessary if year transform will just convert datetime to a year representation using EXCTRACT, YEAR or STRFTIME calls (depending on database).
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
You'll want to make this a set as well ```suggestion existing_table_names = {name.casefold() for name in existing_table_names} ```
[I'd use `casefold()`](https://docs.python.org/3/library/stdtypes.html?highlight=casefold#str.casefold) and it looks we're not performing `lower()` in the `model._meta.db_table` and `field.remote_field.through._meta.db_table` containment checks below either. The `through` case is also untested.
Not related to these changes but we should probably turn the `existing_table_names` iterable to a `set` if it's only used for containment checks.
Use `assertIs(..., False)` to check for boolean attributes.
We can revert changes in `alter_index_together()`.
Usually `__getattr__` is paired with `__dir__`, so that the lazy-loaded stuff is still exposed to `dir()`. My go-to implementation is: ```python def __dir__(): return sorted(list(globals()) + ["utc"]) ```
I find this a mildly counter-intuitive name, since this is the *answer* to the question "is DST passed?" (or, worse, it's a statement "`isdst` passed", which is the opposite of the actual meaning of this sentinel!), but it is named as the question. I'd probably call it something like `IS_DST_SENTINEL` or `DST_NOT_SPECIFIED`.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
I would chop the blank line.
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
`max_age` is not being passed into `signing.loads()`, nor is `self.serializer`. `session_dict` should be `session_data`.
I think we want to avoid altering `self.extra` here and pass `db_type` as a kwag to `super().as_sql()`.
I'm a little concerned about the loss of `constant_time_compare()` here which sounds like it was added as a potential mitigation against timing attacks.
This is confusing: ```suggestion connection.settings_dict.update(initial_settings[str(alias)]) if serialized_contents and alias in serialized_contents.keys(): connection._test_serialized_contents = serialized_contents[str(alias)] ``` Can aliases be anything other than `str` type? If so, then perhaps something is wrong elsewhere. It seems to have been done all over this patch. And this is broken anyway because the second line should have been `... str(alias) in ...`. The `.keys()` call is unnecessary as `in` will work on the keys of a dict anyway. ```suggestion connection.settings_dict.update(initial_settings[str(alias)]) if value := serialized_contents.get(str(alias)): connection._test_serialized_contents = value ```
I'm confused. Is there something incorrect here or can this just be: ```suggestion self.connection.settings_dict['NAME'] = worker_db ``` If the intent was to avoid mutating the original then do this (although I'm not sure it's required): ```python self.connection.settings_dict = {**self.connection.settings_dict, 'NAME': worker_db} ```
I'm slightly confused that were taking `source_db` from disk here with the same `_worker_id` value as the `worker_db` target. Maybe I'm missing something, but I thought we're trying to make copies for different processes, so the source and target cannot share the same `_worker_id`? 😕
Everywhere else uses an f-string, not sure why this doesn't: ```suggestion f"file:{alias}_{_worker_id}.sqlite3", uri=True ```
Is it too late to move the conversion of `auto` to an integer to a post-processing step (e.g. your `get_num_test_processes()` function)? I feel like the `parallel_type` function's job here should only be to check that the value equals `auto` if the value is a string, but not to apply the environment-dependent business logic to convert `auto` to a number. (I also see that `get_num_test_processes()` is already calling `multiprocessing.cpu_count()`, so there may be some duplication of logic with the way things are currently structured.)
I moved this to the `test()` method to avoid code duplication.
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
```suggestion """Render as <p> elements.""" ```
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
has a -> is of a
I'd include the min length in the error message
its so that, for example, a ...
`Exception as e`
Looks like Windows isn't happy with the dots. I think something like 'nonexistent' should work.
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
You didn't want to capture the response content and assert that here? (Just wondering your thoughts...)
argument -> a GET parameter
Moved fail_on_restricted to the next line and use hanging indentation.
You might have thought of this already, but it might be helpful to try to pass along the first error message, though it wouldn't be quite as clean, and it gets caught anyway.
```python objs_to_clear = {field: items - objs for field, items in self.restricted_objects.get(model, {}).items()} ```
This doesn't feel very efficient - there will be a query per loop. You should be able to fetch all objects in a single query, grouping by the field.
chop blank line
Avoid calling `get_model()` twice here.
My thought was caching the return value in someway (in a dict eg. `self.cache[cls]`) to speedup by not looping over the bases each time a inherited manager is accessed. I would like to hear from other devs what they think on this.
I think some caching would make sense here.
@poleha why do you say so. `MangerDescriptor.__get__` will run on each access to `Model.objects`.
I don't think you need this check here. This case will be handled in the for loop. Otherwise you can skip the first item in `cls.mro()` as well.
Oh. Interesting :-| Bisecting the regression on Django's master branch with your test will show where the regression happened. Depending on what this reveals, a backport could be in order, even if the regression is old.
Bisected to 388bb5bd9aa3cd43825cd8a3632a57d8204f875f. I didn't finish investigating to understand why that's relevant here.
The deliberate error in the reproduction script (`u.is_active = False, # assigning a tuple to a boolean field`) doesn't raise a `ValidationError` until that commit.
State the expected behavior in test docstrings and wrap docstrings at 79 chars per [Python style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ``` """ ORM queries are allowed after an error and a rollback in non-autocommit mode (#27504). """ ```
This flag is ignored when `ensure_durability` is `False`, so we should inform users that is not allowed, e.g. ```diff (django-test) git:pr/13708 felixx@felixx-A555:~/repo/django/tests> git diff diff --git a/django/db/transaction.py b/django/db/transaction.py index c6ba346a99..8a84b97237 100644 --- a/django/db/transaction.py +++ b/django/db/transaction.py @@ -172,6 +172,11 @@ class Atomic(ContextDecorator): self.using = using self.savepoint = savepoint self.durable = durable + if self.durable and not self.ensure_durability: + raise ValueError( + 'A durable atomic block is not allowed. If you are running ' + 'tests, you must use TransactionTestCase, not TestCase.' + ) def __enter__(self): connection = get_connection(self.using) ``` We can be descriptive here.
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
The same amount of caching would be happening in the approach I'm suggesting. It's just that you would be calling `self.resolve_fields_and_relations() / self.all_relations = ...` (e.g. in a method) instead of accessing a cached property. It just seems like the usage in the PR doesn't really match `@cached_property`'s use case. In addition to what I mentioned above, the calls to `self.all_relations` in the PR aren't using the return value, it's just doing that for the caching side effect, which you could do more simply / explicitly.
> Would that be fine? Or is there something I am missing? `else` is not necessary, there is no need to resolve relations at this point.
I don't see much value in renaming this method. This wouldn't make it a public API as explicit docs are also required. Also, there is a separate ticket-25671 and #13918 that propose to change related methods. I think we can revert this change for now.
Yes, this should be taken care of before.
looks to me like it could actually be a set comprehension for more speed again since it's only used for N `not in` checks below
To match `django.db.models.sql.compiler` behavior, as_sql() should probably be replaced by `self.compile(annotation)`.
I'd chop the blank lines around `for_update_part`.
remove first comma (also as someone not intimately familiar with the ORM, I'm not quite sure what "default select" means (I assume it's a reference to `default_cols` -- maybe no further explanation is needed).
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
Yes please, for further reusability of the `decode` function it makes sense to use `int` where the underlying data is actually an `int`. As for consistency that imo went away once we switched `iterations` to `int`. And I still think this switch makes sense since we do not have to call `int` all over the place where we use it. If you think of our endgoal (ie something like a `salt_len` as result of `decode`) so we can update `must_update` to account for the salt, it makes even more sense to have integers. Imo the key->value relation is well defined and with python being as dynamic as it is, let's make use of that.
I'd call this `work_factor` as dictionary key and only in `safe_summary` it would be `work_factor`
For simplicity I think it would be better to revert this to the previous code, ie simply https://github.com/django/django/blob/69e0d9c553bb55dde8d7d1d479a78bfa7093f406/django/contrib/auth/hashers.py#L425-L427 -- I understand your motivation behind using `decode` here, but simplicity wins especially in security relevant code.
I am currently giving the PR a full final review and I think we can drop those assertions now that they are done in decode already, what do you think? (same for the assertion in `safe_summary` and other hashers)
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
I moved this to a separate PR, see #15426.
`# Store ... warning message.`
This refactoring of this logic out into out into `check_none_response` is a nice bonus cleanup!
I moved `check_none_response()` to a separate PR #12474 and renamed it to the `check_response()`. I'm going to rebase this patch after merging.
Please use single quotes. You can use directly `out.getvalue()` instead of a temporary variable, e.g.: ```python self.assertNotIn('class InspectdbPeopleView(models.Model):', out.getvalue()) ```
I think that: ```python return 'FOR UPDATE%s%s%s' % ( ' OF %s' % ', '.join(of) if of else '', ' NOWAIT' if nowait else '', ' SKIP LOCKED' if skip_locked else '', ) ``` is more readable.
Please add trailing comma.
If ...., the locked row is skipped resulting in Person.DoesNotExist.
DatabaseError is raised if a ....
Nit-pick: I think Django generally favors the syntax with parens instead of the `\` continuation char.
Yes, I think we should be able to distinguish between automatic indexes and manual indexes. It might not be possible to cover all possible cases (inspectdb doesn't aim for perfect output), but let's try our best. For example, a single-column GIST index on a geometry field is considered as the default index.
There's a lambda called `strip_prefix` in `inspectdb.py` that should be of use.
actually I think the preferred solution is to omit the u'' prefix, even on Python 2. The output already includes `from __future__ import unicode_literals` so there shouldn't be a problem without it.
Test failure is because this is missing `geography=True` on PostGIS.
n.b. just noticed these tests could also use `assertIn` / `assertNotIn` rather than `find()`. But it seems the tests in this file mix the two, so no worries.
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
~~I changed this to an assertion for the only file that is affected by the second round of post-processing i.e. `cached/relative.css`.~~
Not sure these asserts bring value ... they seem to test that `override_settings` works.
or just `# CSS files shouldn't be touched...`
can import go at top of file? also, `test_utils` seems like an odd place for these tests. Generally that module is for testing `django.utils`.
I think reorganization of the admin views tests deserves its own patch outsie of this ticket.
Test -> Tests (and I suggest a new `test_history_view.py` file since this file is quite large already.
Adding new code in a good location is fine.
See if you can find an existing test case to use. There should be existing tests for log entries that this test could be located with.
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
You can simply use `assertRedirect(response, obj.get_absolute_url(), ...)` here. No need for string formatting.
Is it correct that this `args` is different from the previous test? I'd expect the same test for both Python 2 and 3 with something like `self.assertEqual(response.status_code, 200 if six.PY3 else 404)` but maybe I missed something.
You should use `fetch_redirect_response=False` instead of `target_status_code=404`. It seems to be an outdated pattern used in a few places and I'll probably clean it up soon.
A docstring describing the purpose of this test may be useful.
This is the unauthenticated case yes? What's the story for the authenticated user? (Ah, I see the release note...)
Assuming you use `NotSupportedError`, I think checking for the exception class is enough and is more robust.
"Reinhardt" (the name of the first user here) is the last name of Django (the guitarist). Use `name="Grappeli"` (Stephane, who used to play with Reinhardt).
Heh. This line was an `assertRaisesMessage` before, I recommended that it be changed to assertRaises to make the test less prone to break on trivial code changes. The message's content is essentially just "Not supported" anyway, so I think we should leave it this way.
`get()` adds redundant noise here IMO (outside of Oracle, `get()` adds its own slicing IIRC). I'd prefer: ``` qset = Person.objects.all().order_by('pk').select_for_update()[1:2] person = list(qset)[0] ```
I'd move `'defaults': 'testing'` to the next line and include a trailing comma per our usual style.
We avoid backslashes and use this style: ``` msg = ( "Redirection loop for authenticated user detected. Check that " "...." ) ```
Please use assertRaisesMessage to check the message too. We prefer the context manager version usually `with self.assertRaisesMessage(ValueError, msg)`. I think combining the two tests so you can reuse the `msg` variable would be fine.
argument -> a GET parameter
URL should be capitalized
"Stay on ..." (and please be consistent with no spacing around the sentences) Add a period to each sentence too.
Please move `)` to a new line: ``` py return self._html_output( normal_row='<p%(html_class_attr)s>%(field)s %(field_name)s</p>', error_row='%s', row_ender='</p>', ) ```
```suggestion return '<div class="errorlist">%s</div>' % ''.join( f'<div class="error">{error}</div>' for error in self ) ```
please limit line lengths so horizontal scrolling isn't required, something like: ``` self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> ' '...' ) ```
I know this is the sort of layout that `black` would generate, but it's one of the more ugly choices it doesn't get right in my opinion. Perhaps we should `+=` instead of `.extend()`: ```suggestion top_errors += [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ```
You don't need to use `"""..."""` here: ``` py self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> custom' '<input id="id_hidden1" name="hidden1" type="hidden" />' '<input id="id_hidden2" name="hidden2" type="hidden" /></p>' ) ```
`codename %= ...`
`cls.__name__.lower()` is the same as `self.model_name`. I guess `model_name` would probably be a better placeholder name.
The main question is what to do with these tests? We should analyze them one by one and prepare alternative versions only with `unique_together` (if necessary). I'm afraid that we cannot simply remove them when deprecation ends because we will end with many not covered scenarios. For example: ```python diff --git a/tests/migrations/test_autodetector.py b/tests/migrations/test_autodetector.py index 547e0b32c5..4c19a34d7f 100644 --- a/tests/migrations/test_autodetector.py +++ b/tests/migrations/test_autodetector.py @@ -2441,10 +2441,10 @@ class AutodetectorTests(TestCase): self.assertNumberMigrations(changes, "testapp", 1) self.assertOperationTypes(changes, "testapp", 0, ["AlterField"]) + # RemovedInDjango51Warning: When deprecation ends rename to + # test_empty_unique_together(). + @ignore_warnings(category=RemovedInDjango51Warning) def test_empty_foo_together(self): - """ - #23452 - Empty unique/index_together shouldn't generate a migration. - """ # Explicitly testing for not specified, since this is the case after # a CreateModel operation w/o any definition on the original model model_state_not_specified = ModelState( @@ -2457,7 +2457,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": None, + "index_together": None, # RemovedInDjango51Warning "unique_together": None, }, ) @@ -2468,7 +2468,7 @@ class AutodetectorTests(TestCase): "model", [("id", models.AutoField(primary_key=True))], { - "index_together": set(), + "index_together": set(), # RemovedInDjango51Warning "unique_together": set(), }, ) ```
We should mark all tests and model states that use `index_together` in `tests/migrations/test_autodetector.py` for removal. We can also move them to a common class for easier remove when deprecation ends.
A note in `docs/internals/deprecation.txt` is missing.
There is no need to `append()` because we have a single error: ```suggestion return [ ```
```suggestion 'SITE_ID must be an integer', ```
I would use `sites.E101` to separate them from checks related with `CurrentSiteManager`.
I suggest you use the `hint` kwarg for the `'perhaps you forgot a trailing comma?'` part.
"The SESSION_COOKIE_NAME and LANGUAGE_COOKIE_NAME settings must be different." (don't think the hint is needed as it's just repetitive)
These are unnecessary ```suggestion ```
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
This line is horrible. 😄 Simon mentioned this in his review before but, maybe leaving up until the `and\n` as is and putting the new check on the next line, to keep the diff that bit smaller...? (I don't mind this as it is per se — whichever way we do it, it is long and horrible.)
This change isn't correct as it will disable the check unless testing. Maybe this would work: `if 'django.contrib.auth.backends.ModelBackend' in settings.AUTHENTICATION_BACKENDS`
Our convention is to include a trailing comma in places like this so if more items to the list later, we don't have to modify this line again.
I think this would be more readable if they were on one line each. It's fine if they are longer than 79 characters
is this meant to test the `except TypeError` branch in `contrib.auth.authenticate()`? It would be clearer to call that function directly.
`server_name` is unused.
```suggestion The message from the exception which triggered the 403 (if one was supplied). ```
Please add a period: ```suggestion """Display server name and port after server bind.""" ```
We could just use f-strings here: ```suggestion errno.EACCES: f"You don't have permission to access port {self.port}.", errno.EADDRINUSE: f"Port {self.port} is already in use.", errno.EADDRNOTAVAIL: f"IP address {self.addr!r} can't be assigned to.", ``` (I know this means generating three strings when we'll only show one, but it isn't really going to add any significant overhead.)
Is this possible? If so, it will be good to cover this scenario with tests.
I guess Article/Category deletes aren't doing anything since you already asserted exists() -> False. Anyway, I think I'd put this in a separate method. `test_loading_with_exclude_app` / `test_loading_with_exclude_model`
assertEqual -- the version with "s" is a deprecated alias.
it's a separate item, but I wonder if we could patch override_settings to handle DATABASE_ROUTERS like is done below
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
The interesting test case is this: ``` season_2009 = Season.objects.create(year=2009, gt=111) season_2009.games.create(home="Houston Astros", away="St. Louis Cardinals") season_2009.games.create(home="Houston Astros", away="Chicago Cubs") season_2009.games.create(home="St. Louis Cardinals", away="Houston Atros") season_2010 = Season.objects.create(year=2010, gt=222) season_2010.games.create(home="Houston Astros", away="Chicago Cubs") qs1 = Season.objects.exclude(games__home__contains='Houston') qs2 = Season.objects.exclude(lookups.Contains(F('games__home'), 'Houston')) ``` where the qs1 and qs2 objects should match. The encouraging thing is that the code is trying to call split_exclude(). It might be hard to make this test actually work, the split_exclude() code is pretty big hack, and especially if the expression creates joins to multiple different relations it will be hard to make the current code work properly. But, if I recall correctly, we don't support .filter(games__away__contains=F('games__home')) either.
without any arguments
I think we also need to exclude [conditional constraints](https://docs.djangoproject.com/en/3.0/ref/models/constraints/#condition) here.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
Do we need to call `list(fields)` here? :thinking:
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
was referring to `call_command`. the `os.path.join` is okay.
tests aren't entirely consistent, but I prefer omitting a newline after the docstring.
Can you reference the ticket number in the docstring, please.
This should be defined outside the `try` - if `call_command` raises, `merge_file` won't be defined in the `finally` clause.
move to finally
The common CPython message format for `TypeError` is `'to' argument must be a list or tuple, not 'foo'`.
Please use 4 space hanging indent as done in other tests.
This should use a variant on the `check_isseq` used elsewhere in the file. At present this does restrict you to a list or a tuple, but we may as well keep this consistent.
flake8 complains about missing spaces around `*`
comma after tuple
add trailing comma so if more items are later added, we don't have to modify this line again.
```suggestion 'After a failed login, you need to wait for %s second before trying a new login.', 'After a failed login, you need to wait for %s seconds before trying a new login.', ```
this can be super().clean() only as python 3 don't need this explicitness
unchecked -> unselected
Do you think it would make sense to test a real use case form intead? ``` python class ConfirmDeleteForm(forms.Form): confirm = models.BooleanField() ``` And update the tests accordingly to delete/post `confirm=1`.
Add trailing comma.
Pep257 says, "Triple quotes are used even though the string fits on one line. This makes it easy to later expand it."
As far as I'm concerned this should impact only `307` and `308` redirects, so maybe: ```diff diff --git a/django/test/client.py b/django/test/client.py index b26504f762..e4201bead4 100644 --- a/django/test/client.py +++ b/django/test/client.py @@ -827,7 +827,10 @@ class Client(ClientMixin, RequestFactory): if response.status_code in (HTTPStatus.TEMPORARY_REDIRECT, HTTPStatus.PERMANENT_REDIRECT): # Preserve request method post-redirect for 307/308 responses. - request_method = getattr(self, response.request['REQUEST_METHOD'].lower()) + request_method = response.request['REQUEST_METHOD'].lower() + if request_method != 'get': + extra['QUERY_STRING'] = url.query + request_method = getattr(self, request_method) else: request_method = self.get data = QueryDict(url.query) ```
Flatten to a single line.
I think this line isn't needed, tests seem to work fine without it.
```suggestion @ignore_warnings(category=RemovedInDjango50Warning) ```
I'm not sure this should be committed.
Please test for all of the extra registered range types - you should be able to make use of `self.subTest()`.
You can move it to the top, because we have an alias.
You might want to write some tests to prove that the new query search subclasses combine correctly with SearchQuery.
@graingert `cls` is passed here.
I think it's the right class: ``` In [38]: class desc: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: return instance.__dict__['_%s__mangled' % cls.__name__] In [39]: class A: ...: d = desc() ...: ...: def __init__(self): ...: self.__mangled = 42 ...: In [40]: A().d Out[40]: 42 ```
I'd say `on Python < 3.6`
I think silently failing to cache the property should be considered not working.
I also still don't understand why it's useful to allow writing code that doesn't work.
We should add parentheses only on MySQL > 8.0.13 and only for `_limited_data_types`. I don't think that a new class variable/property is a good solution. I would rather add a method ```python def _column_default(self, field): return '%s' ``` that can be override in a MySQL backend, e.g. ```python def _column_default(self, field): if ( not self.connection.mysql_is_mariadb and self._supports_limited_data_type_defaults and self._is_limited_data_type(field) ): return '(%s)' return super()._column_default(field) ``` This can easily be reused in `_alter_column_default_sql()`.
Isn't the `s` at the end of support redundant? ```suggestion # MariaDB >= 10.5.2 and MySQL >= 8.0.4 support an ```
We shouldn't use the same chain on `replace()` in multiple places, use `quote_value()` instead.
Perhaps it isn't worth breaking consistency. For sure it can wait and be done separately.
This should likely be `'%s_validate_%s'`
Not sure which of `defer` or `deferrable` makes more sense. The latter might be preferable if we choose the `Deferrable(Enum)` solution.
Sorry yes I meant `transaction` 🤦‍♂. I think there's `connections[using].in_atomic_block` or something like that.
Something along these lines would break on tables that haven't been rebuilt and still have `IMMEDIATE` foreign key constraints: ```python with transaction.atomic(): # The following line will immediately fail now that foreign key # constraints are enforced and were created as IMMEDIATE # instead of INITIALLY DEFERRED. Book.objects.create(author_id=1) Author.objects.create(id=1) ``` We might want to mention that constraints used to be built as `DEFERRABLE IMMEDIATE` in the _Foreign keys are now created with ``DEFERRABLE INITIALLY DEFERRED``_ section and might require a rebuild to allow the above pattern to be used.
I wonder how this will play with existing SQLite tables that don't have `DEFERRABLE INITIALLY DEFERRED` constraints. At this point I think the best course of action would be to mention it in the release notes.
returns->return (use PEP257 verb style for new docstrings)
What if `self.to` is empty and `self.extra_headers` contains a `To` header? Weird use case, but still…
This test is passing without any changes.
I would add: ``` self.assertIn('<div id="traceback">', htmls[0]) ```
might as well use `setdefault` in the test as well
chop blank line
This seems overly complicated and probably also wrong with tables that are JOIN'ed more than once as the following JOINs will have aliases that are not `db_table`. ```python > from django.contrib.auth.models import User > User.objects.filter(groups__name='foo').query.alias_refcount {'auth_group': 1, 'auth_user': 1, 'auth_user_groups': 1} > User.objects.filter(groups__name='foo').filter(groups__name='bar').query.alias_refcount {'T4': 1, 'T5': 1, 'auth_group': 1, 'auth_user': 2, 'auth_user_groups': 1} ``` Also you probably don't need to build the `from_to_tables` set as it's really inneficent. You should use a loop and exit the function as soon as a matching alias is found.
You changed the first `_` to capture `field`, but it's not subsequently used.
You turned the arguments into keyword arguments in one other place. Could you also do this here and below? I don't know if it makes sense to also do this in the tests.
a nice line to see gone
no blank line
This could be simplified to match the implementation in `_sqlite_datetime_extract()`: ```suggestion month_in_quarter = ceil(dt.month / 3) ```
Ah, sorry. Misread these. One gets the quarter number, the other gets the first month of the quarter. Ignore me.
We can remove the `elif`s and `else here: ```suggestion if lookup_type == 'week_day': return (dt.isoweekday() % 7) + 1 if lookup_type == 'iso_week_day': return dt.isoweekday() if lookup_type == 'week': return dt.isocalendar()[1] if lookup_type == 'quarter': return ceil(dt.month / 3) if lookup_type == 'iso_year': return dt.isocalendar()[0] return getattr(dt, lookup_type) ``` We'll have to wait until we're Python 3.9+ only to use `.week` and `.year` on the result of `dt.isocalendar()`.
Annoying that `datetime.time` cannot be subtracted from each other to give a `datetime.timedelta`, so we cannot use `duration_microseconds()` as in `_sqlite_timestamp_diff()` below.
I don't think we need the `re_` prefix to the arguments? And perhaps `text` instead of `string` for consistency? We should also avoid coercing to `str` unless we need to: ```python In [1]: text = "This is some text" In [2]: %timeit str(text) 54.7 ns ± 4.28 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) In [3]: %timeit isinstance(text, str) 33.8 ns ± 0.106 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) ``` It might make the non-`str` case slower, but, unless I'm mistaken, we're expecting `text` to be `str` in the majority of cases. ```suggestion def _sqlite_regexp(pattern, text): if pattern is None or text is None: return None if not isinstance(text, str): text = str(text) return bool(re_search(pattern, text)) ``` As an aside, I wonder whether we can do something to compile and cache patterns? This could make a significant difference if the function is called for a large number of rows.
I think a list comprehension would be more readable.
We can add `Foo.objects.create()` to ensure that primary key and sequence are still valid.
We should move `Foo.objects.create()` outside the context manager, i.e. ```python with connection.schema_editor() as editor: editor.alter_field(Foo, old_field, new_field, strict=True) Foo.objects.create() ```
missing trailing comma
Chop the ticket number `(#25253)`.
We could list the columns names.
Use capitalization and periods
chop blank line
fixme -> TODO
ATM is -> than with
chop "Tests that" prefixes, otherwise LGTM. I'm slightly nervous this will create weird edge cases that haven't been tested but I guess that's why it's alpha. :-) (I suggested a simpler commit message in the PR title too).
You can safely join this an the next line. You have up to 119 chars per line. ;)
You can safely join this an the next line. You have up to 119 chars per line. ;)
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
usual style is to put the ticket number in parenthesis at the end of the sentence
If it has some readability benefits, it could be done in a separate PR. This looks okay for now.
You don't like f-strings at all, do you? :-)
```suggestion """ Parse a Content-type like header. Return the main content-type and a dictionary of options. """ ```
Ideally this would be passed as a parameter instead of being baked into the SQL. Maybe adding a `%%s` placeholder and inserting the format string at `params[0]` would work? ```python template = "strftime(%%s, %(expressions)s)" sql, params = self.as_sql(compiler, connection, template=template, **extra_context) format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' params.insert(0, format_string) return sql, params ```
I think we should drop the space after "function" through this file (can be a separate commit).
```suggestion def sequence_reset_by_name_sql(self, style, sequences): return [ '%s %s %s %s = 1;' % ( style.SQL_KEYWORD('ALTER'), style.SQL_KEYWORD('TABLE'), style.SQL_FIELD(self.quote_name(sequence_info['table'])), style.SQL_FIELD('AUTO_INCREMENT'), ) for sequence_info in sequences ] ```
Tests are failing for a different reason due to qwirks with our CI system; notice that SQLite tests are failing as well.
Is this necessary to get tests passing? I think it's already handled by `self.sequence_reset_by_name_sql(style, sequences)` below when `sequences` is specified. ```suggestion ``` Tests that require sequences to be reset should explicitly set [`reset_sequences=True`](https://docs.djangoproject.com/en/3.0/topics/testing/advanced/#django.test.TransactionTestCase.reset_sequences).
```suggestion with self.connection.cursor() as cursor: cursor.execute(""" SELECT table_name, table_rows FROM information_schema.tables WHERE table_schema = %s AND table_name IN %s """, (schema_name, tables)) rows = cursor.fetchall() ```
In MySQL introspection we use `table_schema = DATABASE()`, I think we should use it here.
This should be converted to backend generic way of figuring out that a session doesn't exist anymore.
chop "Check that"
To verify this is the expected import error, I'd do something like: `self.assertRaisesMessage(ImportError, 'nonexistent')`
Define a `CookieSessionTests.test_session_save_does_not_resurrect_session_logged_out_in_other_context` method decorated with `unittest.skip` instead to keep `SessionTestsMixin` backend agnostic. See #6203.
Please drop that new line
IMO, it might be better to harcode the expected HTML rather than generating it programatically as it would be more clear what's expected.
Yes, I know. I'll leave it to Aymeric for a second opinion.
`AttributeError: 'PosixPath' object has no attribute 'with_suffic`
And there: ``` work_file = os.path.join(self.dirpath, '%s.c' % self.file) ```
And use `work_file` here.
I think I'd have this as: ```python try: import colorama colorama.init() except ImportError: colorama = None ``` Then below check `colorama is not None`.
```suggestion try: from aiosmtpd.controller import Controller except ImportError: HAS_AIOSMTPD = False else: HAS_AIOSMTPD = True ```
Maybe `LoggingCursorMixin` instead of `LoggingCursor`.
extra space after [
This check is also redundant.
Use `self.assertCountEqual()` when ordering is not specified and we have more than one expected result.
Please revert this unrelated cleanup and add: ``` CharField._unregister_lookup(TrigramStrictWordSimilar) TextField._unregister_lookup(TrigramStrictWordSimilar) ``` ``` CharField.register_lookup(TrigramStrictWordSimilar) TextField.register_lookup(TrigramStrictWordSimilar) ``` directly.
Can we test this with nested context processors to see that unregistering also works? e.g. ```python with register_lookup( models.CharField, CustomStartsWith, lookup_name="start") ): with register_lookup(Company.place.field, StartsWith4Char, lookup_name="start"): self.assertCountEqual( Company.objects.filter(place__start="f"), [self.obj1, self.obj3], ) self.assertCountEqual( Company.objects.filter(name__start="a"), [self.obj1, self.obj2, self.obj4], ) self.assertCountEqual( Company.objects.filter(place__start="f"), [self.obj1, self.obj3, self.obj4], ) ```
Use `try ... finally` and unregister this lookup to keep tests isolated.
Should this override an instance lookup? As far as I'm aware "instance" lookups should always have a precedence as lookups with bigger granularity :thinking: (\cc @charettes).
Was already highlighted [here](https://github.com/django/django/pull/13065#discussion_r684521409) but was missed.
```suggestion 'ignore_conflicts and update_conflicts are mutually exclusive' ```
You can move the line above to an `else` clause below.
```suggestion name = self.model._meta.pk.attname ```
We try to avoid accessing the database connections when not necessary, so I'd move `db_features`: ```suggestion if ignore_conflicts and update_conflicts: raise ValueError( 'ignore_conflicts and update_conflicts are mutually exclusive.' ) db_features = connections[self.db].features ```
This should only be performed if the `relations` registry is already computed; `if 'relations' in self.__dict__`
You can have a flatter function (less nesting) by doing: ```python if not remote_field: continue ```
```suggestion self.resolve_model_field_relations(model_key, name, field) ```
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
use `unittest.skipIf` decorator on the class
I think there are enough tests about forms using the formats machine to sanitize input values. I'd rather specifically tests `sanitize_separators` in a separate `test_sanitize_separators` test.
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
```suggestion errors_on_separate_row=True, ```
You could skip these, but I thought that the rewording read better. I guess if you go for the proposed `Renderable` then they'd be moved anyway and then it doesn't hurt to update them. (Also note that the docstring for `BaseFormSet.as_ul()` neglected to mention that it isn't wrapped in `<ul>`.) 🤷🏻‍♂️
the call with the `0.01` timeout in `check_availability` does fail for me sometimes on startup :)
Is this a separate change? (I've left it for now but... 🤔)
Do we need these changes? :thinking: `Path.absolute()` raises `FileNotFoundError`, so why not catch it in `watch_for_translation_changes()`, e.g. ```python for path in directories: try: absolute_path = path.absolute() sender.watch_dir(absolute_path, '**/*.mo') except FileNotFoundError: logger.debug('Skipping watching file %s as it cannot be resolved.', path, exc_info=True) ```
Great, thanks! I will merge #11590 and rebase this PR :+1:
I'm just afraid that we're changing a current behavior that works properly :thinking:, but I'm fine with your proposition. Off-topic: Do we need `watch_file()` at all? It looks unused :thinking: .
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
this doesn't look right
It's done on purpose. We modify `attrs` in this loop so `list()` is used to create a copy.
True, it's unnecessary since 58ad030d05fa50cfed327368ab61defca3303e02. It's not a copy&paste code in was done on purpose in the original patch, see a68ea231012.
A test is missing for this change.
suggested format: #19820 - Deserializer should give a helpful error message ....
To avoid creating an extra table, it seems you could use a local test model without any trouble. `s.serialize([ScoreDecimal(score=decimal.Decimal(1.0))], cls=CustomJSONEncoder)`
Instead of simply `list(....)`, use this: ``` with self.assertRaisesMessage(serializers.base.DeserializationError, expected): objects = serializers.deserialize('json', test_string) for obj in objects: obj.save() ``` You could also just omit the `CategoryMetaData` object from the fixture and create it with the ORM.
I didn't get a deserialization error with this test_string: ``` test_string = """[{ "pk": 1, "model": "serializers.article", "fields": { "author": 1, "headline": "Unknown many to many", "pub_date": "2014-09-15T10:35:00", "meta_data": [ ["author", "meta1"] ] } }, { "pk": 1, "model": "serializers.author", "fields": { "name": "Agnes" } }, { "pk": 1, "model": "serializers.categorymetadata", "fields": { "kind": "author", "name": "meta1", "value": "Agnes" } }]""" ```
> I had avoided using ObjectReference, since its ForeignKey has db_constraint=False which I assumed would prevent the problem from triggering. Did you try your new testcase without the fix applied? Yes, it fails without this patch with an `IntegrityError`.
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
Good catch, I think it might be worth doing and testing for yes.
I removed it.
Add an exception message similar to the other methods.
This must be an inner skip, please revert (ticket-31888).
I think wrapping in `Point()` is causing the test crash.
I'm in the habit of including an trailing , for all QuerySet filter kwargs.
Is it required to make transform available with standard underscored syntax? If yes, such common words may interfere with field names. Anyway, is it really necessary to register specific transforms if they are available as classes? By the way, will class-based transforms work without registration? If not, it will be not a good architecture.
Valid point. Feel free to change the decorator in a separate commit.
Wrap at 79 chars, please.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
which must return True if the current user can access the view.
Maybe: ```suggestion template_name_label = 'forms_tests/cyclic_context_boundfield_render.html' ```
This is the same as the previous assertion. I'd think only 1 assertionis needed since all the `as_*` methods use `_html_output()`.
The expected value should be a second argument in `assertEqual()` and `assertHTMLEqual()` assertions.
```suggestion form.render(), '<div><fieldset><legend>Field:</legend><div id="id_field">' '<div><label for="id_field_0"><input type="checkbox" ' 'name="field" value="J" id="id_field_0"> John</label></div>' '<div><label for="id_field_1"><input type="checkbox" ' 'name="field" value="P" id="id_field_1">Paul</label></div>' '<div><label for="id_field_2"><input type="checkbox" ' 'name="field" value="G" id="id_field_2"> George</label></div>' '<div><label for="id_field_3"><input type="checkbox" ' 'name="field" value="R" id="id_field_3">' "Ringo</label></div></div></fieldset></div>", ```
```suggestion '<div class="fieldBox field-position hidden">' '<label class="inline">Position:</label>' '<div class="readonly">0</div></div>', ```
You don't like f-strings at all, do you? :-)
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
Using elif is slightly clearer
i think you should use `NotImplementedError` instead on `NotImplemented`, moreover this proves that it's untested 😞.
Similarly, I don't see much advantage to creating indirection with a method.
I'd only use mock as a last resort and instead pass some email that will be affected by the normalization.
Copy the style of other warnings in the code base ```suggestion warnings.warn( 'BaseUserManager.normalize_email() is deprecated in favor of ' 'AbstractUser.normalize_email() and will be removed in Django 4.1.', RemovedInDjango41Warning, stacklevel=2, ) ```
To avoid duplication, this could call the method in its new location with `AbstractUser.normalize_email`.
What about using the global user model's `normalize_username` method while returning an instance of `self.model`? ```python GlobalUserModel = apps.get_model(self.model._meta.app_label, self.model._meta.object_name) username = GlobalUserModel.normalize_username(username) password = GlobalUserModel.hash_password(password) user = UserModel(username=username, email=email, **extra_fields) user.password = password user.save(using=self._db) return user ```
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
Would it be enough to check `form.fields`? This might make the test a bit easier to follow instead of having to parse the HTML to see what's expected..
We use `assertHTMLEqual()` so newlines don't matter, I would use single quotes: ```python self.assertHTMLEqual( p.as_table(), '<tr><th><label for="id_username">Username:</label></th><td>' '<input type="text" name="username" maxlength="10" required ' 'aria-describedby="id_username_helptext" id="id_username">' ... ) ```
This assertions are now redundant with `test_help_text_aria_describedby()` and can be removed.
Can we move it to a separate test method? We already have so many HTML assertions here.
I think that `BaseForm.get_context()` describes this perfectly well: ```suggestion ``` But if we must keep it, it should be collapsed onto one line: ```suggestion """Returns context for form rendering.""" ```
I suggest you use the `for`/`else` construct here. ``` python for validator in validators: if isinstance(validator, validators.MinValueValidator) and validator.limit_value <= min_value: break else: validators.append(validators.MinValueValidator(min_value)) ```
consider assertRaisesMessage to make the test a bit more specific.
Ditto about the `for`/`else` construct.
Simply return `validators`.
`items = value.split(self.delimiter) if value else []` is slightly faster.
This message shouldn't be used when constraint is defined with `expressions`.
We should pass `using` to `check()`.
> It just happens to pretty straightforward here as you can directly call `Constraint.validate` without the `exclude` on the constraint you are interested in validating. That's a suitable workaround, but I feel like it should not be necessary. FWIW before Django 4.1 where this feature was added I added manual validation already, since there constraints with conditions where just skipped.
We should make use of `self.message`.
`FieldError` is untested. Do we need it? It looks unnecessary.
Use `self.addCleanup(...)` in `setUp` to avoid overriding `tearDown`
I think something like `SETTING_BOTH` will be fine. No need to memorialize the bug number.
> Or should I just check that those settings doesn't exist outside the context? I think that'd work.
@slafs non-existing setting names, e.g. `TEST_SETTING=True`
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
IMO `, got...` is not necessary.
Positional arguments cannot follow keyword arguments.
For simplicity I think it would be better to revert this to the previous code, ie simply https://github.com/django/django/blob/69e0d9c553bb55dde8d7d1d479a78bfa7093f406/django/contrib/auth/hashers.py#L425-L427 -- I understand your motivation behind using `decode` here, but simplicity wins especially in security relevant code.
I think this got copied from somewhere else by mistake and should be dropped (including the following line)
I'm a little concerned about the loss of `constant_time_compare()` here which sounds like it was added as a potential mitigation against timing attacks.
Both approaches work but I wonder if we'd want to be a bit more liberal here and simply return `copy` if no `output_field` can be retrieved. ```suggestion field = getattr(copy.lhs, 'output_field', None) if field is None: return copy ``` It would also avoid having to specify an explicit `output_field` when using a `Func` and `RawSQL` when users usually know what they are doing.
Good catch :dart:
The flake8 error is due to missing a space after the comma here. Please use single quotes instead of double.
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
Careful, you're mutating `self.config` rather than a copy of it. If you hang onto an instance of `SearchVector` and reuse it then resolve_expression will be called on it twice. You'd be better off figuring out a way to add `config` via `self.set_source_expressions()` rather than overriding resolve_expression and `as_sql`. Even if that means using private expressions to build the components.
We're a couple months away (Jan. 15) from dropping Python 2 so it would be nice to avoid adding more work to do when dropping it. Have an invalid secret key seems like such an obscure issue, I don't know if it justifies all the time we're spending on it. Maybe we can just update the docs and be done with it.
This should be a new warning, W021.
Use the `hint` parameter for listing valid values, e.g. ```python E023 = Error( 'You have set the SECURE_REFERRER_POLICY setting to an invalid value.', hint='Valid values are: {}.'.format(', '.join(sorted(REFERRER_POLICY_VALUES))), id='security.E023', ) ``` Also, the current convention is to not have independent numbering for warnings and errors, so use `E023` instead of `E001`.
So, I've been hemming and hawing on whether to mention it, because it conceptually works when in the error message, but it still seems slightly _'off'_ to me that the warning would say `SECRET_KEY_FALLBACK` when the setting is `SECRET_KEY_FALLBACKS` (plural). I guess if we're not going to say _which_ one errored (which _we could_, using hints) I think it'd make more sense to say `One of your SECRET_KEY_FALLBACKS has less ...`
`it's django-generated` --> `it's a Django-generated`
You don't like f-strings at all, do you? :-)
We currently prefer single quotes. The wrapping parentheses are not required.
~~You don't need to create a list, actually. You can just pass the generator expression through (no surrounding parentheses are needed). So `...join(key.encode(...`.~~ Never mind, I learned that this is slower (what @pope1ni was probably saying in the first place).
This has come up in the past when we were looking at removing unnecessary list comprehensions in favour of generators. IIRC, `str.join()` converts input to a list if it isn't already.
When using `str.join()` it is preferable to pass a `list` as it is slightly faster.
Maybe: ```python "File '%s' is already compiled and up to date." % po_path ```
There is in theory a chance of hitting a TOCTTOU case here anyway, in which case it is better to handle the exception to avoid a crash.
Not the greatest variable name...
You can avoid `thefile` by adding here: ``` work_file = orig_file ```
I think we are missing the `call_command()` here.
Not a huge deal, but it might be nice to have this user-configurable, defaulting to 191, because some people may configure mysql to have a longer maximum length.
Are we considering defaulting to using utf8mb4 for the connection? I wonder if it would make sense just to assume 191 if mysql_version < (5, 7, 7) and 767 if newer.
Yeah, thinking about it more, I think either approach makes sense.
I think we can change `rast_index_wrapper` instead.
We can pass `opclasses` to the `super()._create_index_sql()`.
Would it be better to raise `NotImplementedError()` so backends don't overlook implementing it? They can always return an empty list if it's not supported.
Using tuple unpacking such as `... for a, b, ... in cursor.fetchall()` rather than indexing should help readability.
```suggestion for table_name, table_rows in rows: ```
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
[This is only an estimate on InnoDB tables](https://dev.mysql.com/doc/refman/5.7/en/tables-table.html) which is the default table engine and what's used on CI. > The number of rows. Some storage engines, such as MyISAM, store the exact count. For other storage engines, such as InnoDB, this value is an approximation, and may vary from the actual value by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate count. In short that means this value could report 0 while there's actually rows in the table and cause errors similar to the one you are experiencing.
could you use the same doc string style as above? ``` """ ... """ ``` Also should be "Transforms... " to match coding style guidelines.
append(...), not append[...].
I would like a test that fails if this is removed from the try block.
suggested wording: ``` Strip quotes off of quoted table names to make them safe for use in index names, sequence names, etc. For example '"USER"."TABLE"' (an Oracle naming scheme) becomes 'USER"."TABLE'. ```
Please remove this unrelated change.
`str(self.band)` doesn't seem like a realistic value for the message.
my preferred style is: "#17903 -- Inactive users shouldn't have permissions..."
I don't think it's terribly important as both checks use the same code path (although this could obviously be refactored later at which point that argument would fail...).
First we should verify this passes before we toggle `is_active` to False.
would be nicer to output some attribute of `entry` I think
This is nice. Worth the change.
I'd use `assertRaisesMessage()` with `msg = 'backend does not support timezone-aware datetimes when USE_TZ is False.'`. There's a small chance that messages from third-party backends might not match the `connection.vendor` convention and I don't think it's a critical part of the assertion.
``` return datetime.datetime(1970, 1, 1, tzinfo=timezone.utc) ```
We should also test the nonexistent time with `is_dst=True` and `is_dst=False`
Indeed, simply setting get_default_timezone() like this doesn't work for pytz timezones that have DST.
Is `text` used? If unused, you can remove.
Please use single quote. `message` can be single lined.
I would say: _"""Validate that the string does not contain null characters."""_
You can drop `(object)` as master only supports Python3.
Maybe: `if '\x00' in str(value):`
> Is there any reason to explicitly prefer lowercase? Well, not really anything critical. Elements, attributes, etc. in HTML tend to be case insensitive and I tend to lowercase the lot - more similarity leads to better compression in transit. Granted this isn't going to make much difference for such a short string, and your point about implementation detail is fair. (Hence I didn't press for it...)
This can be single-lined, e.g. ```python return HttpResponseServerError( ERROR_PAGE_TEMPLATE % {'title': 'Server Error (500)', 'details': ''}, content_type='text/html', ) ``` The same in `bad_request()` and `permission_denied()`.
```suggestion The message from the exception which triggered the 403 (if one was supplied). ```
You don't need the trailing \ here. EDIT: I see you just moved that code, that's fine.
no u'' prefixes please (use `from __future__ import unicode_literals` if needed)
Use `django.utils.string_types` instead of `str` here.
No need for an `else` branch as the `if` returns.
In the case of an empty select (`choices = []`), this will still output the `required` attribute, which is still not valid: ``` >>> class TestForm(Form): ... some_field = forms.ChoiceField(choices=[]) ... >>> t = TestForm() >>> print(t['some_field']) <select id="id_some_field" name="some_field" required> </select> ``` ``` html <!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <title>Validation test</title> </head> <body> <select id="id_some_field" name="some_field" required> </select> </body> </html> ``` Check it here: https://validator.w3.org/nu/#textarea
You are right! I assumed `render_option` was always converting falsy values to an empty string. It might be worth keeping the method in this case.
I don't think it's worth adding a method for this purpose. `first_choice is not None and first_choice[0]` should do.
I had suggested doing this before computing `good_origin`: https://github.com/django/django/pull/13829#discussion_r579863426 That way you can avoid the two method calls and string construction in favor of a set membership check.
👍 Here's a random example if you needed one: ``` >>> urlparse('http://[') ValueError: Invalid IPv6 URL ```
I don't mind, but I'm not 100% sure why this method has the `_` prefix where others don't. 🤔 (This may have been covered in the discussion.)
This just occurred to me, but would it make sense to structure things so the `CSRF_TRUSTED_ORIGINS` processing can be done just once instead of with each request? (There is similar parsing / processing [below](https://github.com/django/django/pull/13829/files#diff-eaa105f5b436e20dd838c27c7a753ef4cf888edcc8f868c084600f6cb7343166R314-R317) in the referer checking.)
Yeah the settings dependent part could be moved into the `__init__` of the middleware I guess.
The import usually goes at the top of the method.
I'm fine with core.exceptions then. Docs go in docs/ref/exceptions.txt.
I think exceptions in `django.core.exceptions` are mostly things that a user might need to import. I don't think `EmptyResultSet` meets that criteria, at least in my experience I never needed it in a project.
Good point, I didn't think of that module as being user facing. Perhaps django.db.utils would be a better place? It already contains various DatabaseError exceptions, so it wouldn't be totally out of place.
I'm torn whether or not this copy is necessary. When we resolve the expression we do a copy of the subquery anyway. Even if the queryset was cached and evaluated, the resolving will copy a new queryset anyway. ```python qs = Model.objects.whatever() sq = SubQuery(qs) list(qs) # this evaluates the queryset that subquery is holding onto OtherModel.objects.annotate(subq=sq) # queryset is copied here anyway, previous eval doesn't matter ``` Let me know if you can poke holes in my reasoning (it is new years day after all...).
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
I think you mean `ByteType`
Can you please rename it to `ModelManagerSerializer`. I think you just missed it.
Can you please rename this one to `ModelManagerSerializer` and let it inherit from `DeconstructableSerializer`.
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
Oh I realize that asserting against the results is problematic given all the engines we're testing against support foreign keys. In this case yes, using the same `JOIN` check against `captured_query` should do!
I guess you could use `self.assertIs(child.parent, parent)` to make sure the object was not recreated as well.
you can use `a` here again.
To save a line: "is not ready; refs ##24146."
It's the "app registry" (no 's')
I tried a similar approach while working on acfaec3db5ba39de52f6e607e74343dccf72fba1 and came to the conclusion that this approach can't work (due to something like module caching). As far as I know, you'll have to register the admin to a separate `AdminSite`.
I think there isn't much organization there. Using an existing site should be fine.
chop newline for consistency with other tests
Yes please remove unnecessary blank lines.
Do we need to call `list(fields)` here? :thinking:
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
Careful - Value only works with basic types that the adapter itself knows how to convert to SQL. You could try passing the fields Field as the `output_field` param to `Value` which will get it to translate the value using the fields get_db_prep_* methods. Unfortunately Fields are not themselves Expressions, which is why you've chosen to wrap the field in a Value. We could consider the following options: 1. Implement the Expression API on fields directly 2. Add a FieldExpression that wraps a field and translates the Expressions API onto the Field API Personally, I've been thinking about 1 being useful a lot. Fields should just be another type of expression. If I were doing fields from scratch, they would be. If just passing the fields Field instance to output_field doesn't work for more complex types, then you might need to consider the options above.
We could directly check that `name` is in `annotations`: ```python if isinstance(field.expression, F) and not self.query.combinator: col = field.expression.name if col in self.query.annotations: field.set_source_expressions([Ref(col, self.query.annotations[col])]) yield field, True ```
`field` is always an `OrderBy` instance so we can use `.expression`: ```suggestion if isinstance(field.expression, F): ```
Please revert. ```suggestion ```
perhaps `ordering_sql` is better name
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
I made a few edits and squashed commits but before I push those updates I wanted to ask if this test is really needed. None of the changes seem related to verbosity so this test seems unnecessary to me.
Why's that? It's non-obvious at first glance.
non existing -> nonexistent
Copy / paste? I would have expected the ordering to change for the `duth1` and `duth2` arguments.
You could use single quotes in all strings for consistency (don't worry about existing tests).
Great catch :+1:
The transform function is not only to re-project a raster. It can also be used to change its driver (by providing the same srs but a different driver name than the original). Admitedly, for that purpose the `warp` function might be more appropriate, but people might be using transform as well as "filetype change function" convenience. So before going into "clone mode", we might have to check for the equal drivers as well? I.e. `if diver is not None and driver == self.driver.name` or something along those lines.
This cleanup is not related with a patch please move it to a separate commit/PR.
Wrap docstring at 79 chars.
Chop blank line.
I wouldn't be shocked, but it really goes against "there should be one way of doing things". So all in all if anyone has ideas to finish what we started with the middleware move I'd happily use that over the status quo. Is the code of your efforts online somewhere? Maybe we find a way to fix decorators :)
I don't see much value in this docstring.
Is this possible? If so, it will be good to cover this scenario with tests.
This wouldn't happen on every request, just on server restart (when `load_middleware()` is called)
A system check seems a good option if the warning would be too noisy.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
Can this be simplified to ```suggestion # Collation change? elif getattr(old_field, 'db_collation', None) != getattr(new_field, 'db_collation', None): new_collation = getattr(new_field, 'db_collation', None) fragment = self._alter_column_collation_sql(new_field, new_type, new_collation) actions.append(fragment) ``` Or maybe we want to keep the old code to support field type and collation change at the same time (e.g. `CharField(db_collation='foo') -> TextField(db_collation='bar')`).
```suggestion new_field.get_internal_type() in ('CharField', 'TextField')): ```
I'd say "Return a (sql, params) fragment to set a column to null or non-null as required by new_field, or None if no changes are required."
Using the version number should be fine!
I haven't run the tests, so I could be off here, but if having the _change_ permission effectively grants you the _view_ permission for backwards compatibility, is having the same criteria here a good idea? It could potentially mask problems with the new _view_ permission in the tests as the user would always have both.
I think you missed this one in your recent updates.
Move this above `has_add_permission` for consistency.
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
please limit line length to 119 chars so horizontal scrolling isn't required to view the patch.
:thinking: ```suggestion collector = Collector(using=del_query.db, origin=self) ```
:thinking: ```suggestion collector = Collector(using=using, origin=self) ```
Do we need this change? If yes then tests are missing. IMO it is not necessary.
" for docstring consistency
Please put the test in `AdminActionsTest`.
Return (chop 's')
I don't know if this is a "must", it might not be the case that all cache backends out there can sensibly support it
Shouldn't django allow lazy-evaluation function as default value? (Calculate the default value as needed)
Remove the blank line here.
isn't this still subject to the race condition discussed in implementation on the base backend? something else could `set` the key in between the `get` and `set`.
I feel similarly. Maybe it's better just to add support for list and tuple as originally proposed. It's unclear to me if other types would actually be used.
I think this line isn't needed, tests seem to work fine without it.
I think we can simplify this: ```python def json_script(value, element_id=None, json_encoder=None): from django.core.serializers.json import DjangoJSONEncoder json_str = json.dumps(value, cls=json_encoder or DjangoJSONEncoder).translate(_json_script_escapes) ```
It might be better to put the content type check in _encode_json for consistency with _encode_data and to avoid duplicating that in every put/patch/etc. method.
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
I think we prefer a different indentation style in docstrings, i.e.: ```python """ A Q object with an empty condition should be rejected as the conditional expression in a Case(). """ ```
What if `default` is not a constant but a field reference? e.g. `F('integer')`
"Boolean Expression object" looks a bit unusual to me. What do you think of "a boolean expression"? I assume this means an expression with output_field=BooleanField.
prefer this style for multilined docstrings: ``` """ Text """ ```
Manipulating `second` here is not strictly necessary, `first.save()` raises the `IntegrityError`. I believe the reason for `second` to be manipulated here is to show the difference with initially deferred constraints behavior. If that's the case, perhaps a function could show that the same code passes under initially deferred constraints but not under immediate constraints. Something like: ```diff diff --git a/tests/constraints/tests.py b/tests/constraints/tests.py index 067b38cfb6..b3257b6789 100644 --- a/tests/constraints/tests.py +++ b/tests/constraints/tests.py @@ -196,17 +196,17 @@ class UniqueConstraintTests(TestCase): first = Product.objects.create(name='First', shelf='Front') second = Product.objects.create(name='Second', shelf='Back') + def swap(): + first.shelf = 'Back' + second.shelf = 'Front' + first.save() + second.save() + with self.assertRaises(IntegrityError): with set_constraints(unique_shelf=IMMEDIATE): - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() - first.shelf = 'Back' - second.shelf = 'Front' - first.save() - second.save() + swap() first.refresh_from_db() self.assertEqual(first.shelf, 'Back') ```
There's no assertion for `created_date`. You could check that is `datetime.date`and maybe also that `created_date == created.date()`? Alternatively you could drop `created_date`.
[`assertEquals` is a deprecated alias](https://docs.python.org/3/library/unittest.html?highlight=assertequals#deprecated-aliases) ```suggestion self.assertEqual(obj.pi, 3.14159265358979) ```
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
Please use single quotes everywhere in this method.
> Is there any specific reason why we would prefer using the operation in this case? Yes, because we have it. Using a RAW SQL is the last option, we're developing the ORM in order not to use them.
Use single quotes consistently.
chop extra space after period
Not sure how much a difference it makes, but it seems better to store this in Python rather than having to read from a text file. Worth it to make the file location customizable? If so, it might be nice to make "common passwords" a separate package so we don't have to include that list in Django. I guess users might not care for the additional setup tasks though.
This would be better as a set rather than a list.
Oh I missed that. Sorry!
This assertion is not related with this fix so I would move it to a separate commit.
`assertNotIn` may pass from many reasons. I think it is better to check field value with `self._get_field_values()` hook, e.g. ```python self.assertEqual(self._get_field_values(child_data, 'parent_m2m'), []) ```
You might want to `assertIsInstance(serializer.stream, File)` to make sure the `stream_class` attribute was actually used.
No need to have empty lines, see the code above
you need to drop the `__class__`, the `object` itself should be an instance of `Author`
But if someone set `SECRET_KEY` to `None` and `SECRET_KEYS` to a valid list shouldn't that be allowed? I'd actually go backwards here and not use `is_overridden`. This way you'd error out if both has a usable value…
This would set `SECRET_KEYS` to `[None]` if `SECRET_KEY` was `None` which again gives me the impression that using `is_overriden` is the wrong approach here.
Could you write the test without using fixtures? I think it would be a lot simpler.
This test won't pass when pytz isn't installed. For consistency with the timezone tests, you should declare: ``` python requires_pytz = skipIf(pytz is None, "this test requires pytz") ``` and then decorate it with `@requires_pytz`. This is a minor concern since the docs now encourage installing all optional dependencies before running the test suite, but I suppose it could save some headaches to people running the test suite without a virtualenv. on or systems that don't have `time.tzset` (that is, Windows). Have
FWIW I didn't find pytz required, except on Windows, but I might have gotten lucky with my particular configuration.
Nothing specific, it's just a pattern commonly used in Django. Probably because it was not the same in Python2.
So I'm fine to leave `type()` calls.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
I think we can use the same check like in `UniqueConstraint`: ``` if not isinstance(condition, (type(None), Q)): raise ValueError('ExclusionConstraint.condition must be a Q instance.') ```
I think the variable names have nothing to do with this regression. Also it's much easier to fix a regression introduced in commit with a small diff, that's why we prefer small diffs for patches that will be backported. P.S. Note that we're not all "guys" so please use gender neutral greetings, https://heyguys.cc/
I think this is good, but wonder if we can also change to the following in `django.db.backends.postgresql.client.DatabaseClient.settings_to_cmd_args_env()`: ```python return args, (env or None) ``` This seems to fit with the expectation that `None` is returned when nothing is being added to the environment.
```suggestion service = options.get('service') ```
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
FWIW, mysql "masks" the password on the command line by replacing it with `X` for every character -- at least on system where it is possible. Since a cmd line argument usually leaks on every system I'd consider cmd line arguments highly insecure (no matter what). But even if the replacing of the password works properly on every system the error python raises would still contain it. An environment variable is usually somewhat secure (ie other users are generally not able to view them). A file would even fix those remaining issues but can be hard to implement -- one should just use a (non-swapping) ram-fs backed tempfile, otherwise you would persist the password on disk where it might be recoverable. But I'd argue that the last issue is not really such an issue because the password has to be on the disk already (settings file ;)) or somehow passed into it (and even if it comes as env variable into the settings file it usually is coming from yet another file on this PC). All in all I do not think that dbshell is used that much on production systems (or at least should not be), but making sure that we have no obvious leaks like in exceptions is worth it.
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
`transform.lookup_name` isn't needed (same in unregister)
Could drop the `alias` in `setUpTestData` and `order_by('pk')` or simply use `assertCountEqual` since ordering isn't that important.
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
This can be single-lined ```suggestion '<ul class="errorlist nonform"><li>Please submit at most 1 form.</li></ul>', ```
chop newline for consistency with other tests
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
chop first comma
Prefer this indent style: ``` response = self.client.post(reverse('...'), { .... }) ```
Ah, I hadn't looked at #15179 in detail. Even better! 😁
Also, I don't think we should collect this in `to_report`. We can fail immediately with `self.fail('Form is valid')`.
You can use the new `self._bound_items()` here, which is now in `main`.
I wasn't familiar with `assertFormError` actually. Guess the main difference is that `assertFormError` is a single field. Happy to leave that though, the nicer `assertFormValid` is useful in itself.
Thanks :+1: , IMO a separate ticket is not necessary, we can `Refs #33348 -- ...`.
Here you have a choice between `bytes` and `bytearray`. I ran this crude benchmark (Python 3.7, Linux, glibc): ```python import time CHUNK = b'\x00' * 1000 NUM_ITERS = 1000000 print('num_chunks,bytes_time,bytearray_time') for num_chunks in range(1, 21): start = time.monotonic() for i in range(NUM_ITERS): body = b'' for i in range(num_chunks): body += CHUNK finish = time.monotonic() bytes_time = time.monotonic() - start start = time.monotonic() for i in range(NUM_ITERS): body = bytearray() for i in range(num_chunks): body += CHUNK body = bytes(body) bytearray_time = time.monotonic() - start print(f'{num_chunks},{bytes_time},{bytearray_time}') ``` The result is: ![bench](https://user-images.githubusercontent.com/1223550/56269664-d69ab900-60fc-11e9-9393-ba4fd3998b87.png) At least with the parameters I used, bytearray is slower for a small number of chunks, but looks linear, while bytes looks quadratic.
I would remove `else` since it is unnecessary after `raise`.
Any reasons for such `chunk_size`? (`2^19`) why not `2 ^ 16` or `2 ^ 31 - 4`.
Chop blank line.
Maybe: ```python return self.scope.get('scheme') or super()._get_scheme() ```
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
How about omitting it until we have a use case? That will save writing tests and docs for a theoretical feature. :-) From a readability point of view, writing a `re_path()` that mixes regexes and converters in the string, and then has to initialize and pass converters in the URLconf sounds nasty and not something to encourage!
I'm going to be a +1 to just dropping `converters`
I think the formatted pattern should be wrapped in quotes. "Your URL pattern '{}' uses..".
I would revert this change. We want to add a system check so this seems redundant.
Personally yes. (But maybe the examples in the docs will be enough)
Perhaps dropping this blank line.
This is already tested in `test_args_kwargs_request_on_self()`, I'm going to remove these assertions.
This test is not related with the patch, so I'll move it to a separate commit.
Turn (capitalize) add period. sql -> SQL
I know but it's not worth complexity, we can use ```python stream = open_method(output, 'wt', **kwargs) if output else None ``` in `dumpdata` and ```python with open_method(filename, 'rt') as f: ``` in tests.
True, thanks :+1:
`t` is unnecessary, IMO.
Do we need a separate variable? I would include it directly in the `compression_formats`: ```python compression_formats['lzma'] = (lzma.open, {'format': lzma.FORMAT_ALONE}, mode) ```
could chop "Make sure to" without any loss of meaning.
I think `warnings.filterwarnings('always')` is unneeded.
it's helpful to use assertRaisesMessage to ensure this is the exception we expect
I think it's better to omit the try/except and instead say `Settings(settings_module) # should not raise an exception`. See 071801ccff970682a799ce754431a3c3ce3d6902
think we can chop the blank lines in the last 3 tests
ImproperlyConfigured should be raised if DEBUG=False and ALLOWED_HOSTS is empty.
If we skip sub-parsers as actions then all tests still pass and `if opt.option_strings` condition is not required anymore, e.g. ```python # Parser actions and actions from sub-parser choices. def get_actions(parser): for opt in parser._actions: if isinstance(opt, _SubParsersAction): for sub_opt in opt.choices.values(): yield from get_actions(sub_opt) else: yield opt parser_actions = list(get_actions(parser)) ``` That's because `dest` for sub-parsers is not a valid option and don't need to be in `dest_parameters`.
Is this required? I think we should collect parsers and choices from sub-parsers, e.g. ```python if isinstance(opt, _SubParsersAction): for sub_opt in opt.choices.values(): actions += get_actions(sub_opt) else: actions.append(opt) ``` After that we can remove `if opt.option_strings` from `parse_args += [...`
I don't think that we need an internal hook.
Maybe something like "call_command() received unrecognized option(s) for the <foo> command: .... " I think listing all the options in the message might not be a bad idea either if it doesn't look too cluttered.
put the closing ) on the next line
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
e.g. I think this should either be a warning or an error.
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
@aaugustin, hopefully you aren't using such responses in your projects?! :smile:
I'd tend toward checking at the boundaries rather than some random value.
Let me put this differently :-) Is this required to make the test suite pass? If not, I'd prefer we do not include it. If yes, I'd like to look at the failing tests, because they must be weird.
`if kwargs['setting'] in ('INSTALLED_APPS', 'STATICFILES_DIRS')` The later is fixed at initialization time too I think
Call `clear_url_caches()` instead. It's more likely to stay up to date when the code lives on, and it resets the `get_callable` cache which is missing from your patch.
No need to use `in` here, `kwargs['settings] == 'ROOT_URLCONF'`.
I suggest you use the `hint` kwarg for the `'perhaps you forgot a trailing comma?'` part.
I'd omit the blank line since the ) on its own line provides space.
The current idiom might be required because some backends (perhaps third-party ones) choke on empty `params`. I'd keep it.
Rather than implementing a special CursorWrapper for Oracle to do this, it is better to include the change in the general CursorWrapper. This has two immediate advantages over doing it in the Oracle backend: 1) The new feature can be shared with any other backend which supports it (3rd party backends included) 2) The new feature is automatically included in CursorDebugWrapper (which your version of make_cursor disables) The disadvantage -- exposing the interface to backends which do not support it -- is a small price to pay in comparison.
You could, just seemed easier not to have nested if statements.
It's clearer to me.
Yes, I know. I was suggesting that to parallel `localdate`, `localtime` with no `value` when `USE_TZ=False` should return `datetime.datetime.now()` (the naive current local time). I think this may still be a valuable parallel, even though calling `localtime` with a naive `value` does not work. But I don't feel strongly about it. Curious what @aaugustin thinks.
As noted above, `localtime` only works when `USE_TZ` is `True` at this time. There is even a test for this. A straightforward implementation of `localdate` as `localtime(...).date()` will have the same restriction and thus be consistent. It may be useful to make these functions fallback reasonably when `USE_TZ` is `False` for the benefit of pluggable applications. In that case, `localtime()` should return: 1. `datetime.datetime.now()` if no `value` is provided 2. `value` if it is provided and it is naive 3. (probably) an exception if `value` is provided and it is aware The third point is debatable. I tend to be strict in what my code accepts, which may not be a best practice in Python but prevents silent data corruption. It's easy to slip and manipulate the wrong type accidentally when time zones are involved... No changes will be needed in `localdate`; it'll get a consistent behavior automatically if we make these changes to `localtime`. In any case, that should happen in a separate commit.
Looking at the parallels between `localtime` and `localdate` again, I wonder how `localtime` ought to behave when `settings.USE_TZ` is `False`. Seems like it ought to just return `datetime.datetime.now()` (that is, the naive current local time) when `value=None`. I think this could easily be accomplished by just calling `now()` instead of the new `_now_utc()` helper. When `value` is set and `USE_TZ=False`, I guess perhaps `localtime` should just have no effect? Or just raise an error? But any change here would be backwards-incompatible, so perhaps not worth it.
If it's changed to return naive current local time when `USE_TZ=False` (as discussed above) that should also be mentioned here.
I wouldn't have reflowed this line since you didn't make any other changes and it would simplify the diff.
I think we should revert the logging changes as it appears we're adding additional logging calls where they didn't exist before.
My mistake on 500, but "NOT FOUND" is different from "Not Found"
I think `get_exception_response` would be a better name for the method.
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
I would prefer to omit it for now.
I would keep `if not ...` in the same line.
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
Wrap strings at 79: ``` 'You have provided values in the LANGUAGES_BIDI setting that are not in ' 'the LANGUAGES setting.', ```
Ah, ok so maybe we can check both in one call, i.e. ```python self.assertEqual(check_language_settings_consistent(None), [ Error( ... ), Warning( ... ), ]) ```
chop "should" (just state the behavior)
setUp/tearDown should go at the top of the class.
please use periods
seems to be missing a placeholder at the end
Yeah, only on the first load if possible, otherwise maybe pass in verbosity from the runserver command and only show it if a higher verbosity is passed in. I think it would also be neat if instead of saying "Watching for file changes with StatReloader" it could figure out the common error and just say something like "Watchman client not available, watching for file changes with StatReloader". That way it's more clear what's going on, but not spamming the console either.
And add `obj.normal.close()` at the end to fix the failure on Windows.
We should fix this side-effect, probably by providing a custom `Round._resolve_output_field()` method, .e.g. ```python class Round(FixDecimalInputMixin, Transform): ... def _resolve_output_field(self): source = self.get_source_expressions()[0] return source.output_field ```
This test and `test_special_prefix` might not be self-evident so a docstring wouldn't hurt, e.g. `"""No URLs are served if DEBUG=False."""`
Due to hanging indent, `).first()` should be on the next line.
These assertions are not related with this patch. Personally I don't see much value in adding them.
Two things to note here: 1. I don't like much the dependence on settings.DEBUG. Either unconditionally raise, as done in other parts of this file, or make usage of the logging infrastructure (getLogger('django.template'), logger.error(...)). 2. I'd like to keep the return statement at the end, if possible
I know that logging is currently not used, but it might/should in the future. Let us forget this now, this should be the subject of a separate ticket anyway. But then I'd advocate for unconditionally raising the TemplateSyntaxError.
The added blank lines aren't needed.
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
I think you can use `with self.assertRaisesMessage` equivalently here (context manager form is much easier to read IMO)
`tempfile.TemporaryDirectory()` can be used as a context manager: ```suggestion with tempfile.TemporaryDirectory() as temp_dir: ``` The other tests were cleaned up in #13211.
Okay then, no worries. As context managers are a regular, routine Python idiom, even outside tests, I find them quite readable (even with the indentation) and I find it makes the clenaup extremely explicit. Both forms work, though.
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
Maybe it would be nice to put the shared test logic into a helper method.
Please add a trailing comma: ```suggestion [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver'], ```
I think a simple `django.template.Context` will do here.
I don't think you should re-number the existing tests.
Unless I'm missing something you don't need to define a class and nest an instance of it in a list to reproduce your use case. Simply passing a callable that throws an exception should do. e.g. ``` python engine = Engine(loaders=[ ('django.template.loaders.locmem.Loader', { 'child': '{{ raises }}', }), ], debug=False) def raises(): raise Exception engine.from_string('{% include "child" %}').render(Context({'raises': raises})) ```
can omit these two newlines
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
Make `__str__` return `self.string_rep` and nuke `__unicode__`.
I think `var_repr` is more explanatory than just `rep`. Also, use single quotes rather than double quotes unless the string contains a single quote.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
no dash in "email"
Not sure how much a difference it makes, but it seems better to store this in Python rather than having to read from a text file. Worth it to make the file location customizable? If so, it might be nice to make "common passwords" a separate package so we don't have to include that list in Django. I guess users might not care for the additional setup tasks though.
Repeating would be quite rare situation, only for classes with multiple metaclasses, so defining new value used only once in 98% of time would be slower in the end.
Nitpick but metaclass should be one word.
Now that we know exactly which base lookup failed we could adjust the `InvalidBasesError` message.
The note should be generic -- describe the sort problem as it could happen to any app -- a reference to contrib.postgres isn't needed.
could switch to single quotes for consistency
```suggestion renderer=renderer, ```
I renamed the test and removed the docstring.
Use single quotes.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
Chop blank line.
This doesn't look correct... Did you mean something like: ```python ctypes.add(None) searched_perms.extend((None, perm) for perm in getattr(settings, 'GLOBAL_PERMS', [])) ```
I think it's enough to reference #24100 since that's relevant to do todo: ``` # TODO: Remove when migration plan / state is passed (#24100). ```
On thing to keep in mind is that this is going to be introducing double work.
Two things here: * The `s/klass/Model/` change is unrelated/unnecessary. It's arguably more readable but if we revert it, it reduces this diff to just this line. * This can be single-lined: it's 101 chars, or 100 with `klass`. (You don't need the trailing comma.)
I don't think this is necessary - this is a developer only message - it will never be displayed to end users.
no blank line needed
Shouldn't mixins be to the left of the base class `models.Model`? This is my understanding of how mixins on class-based views work anyway.
Can you use `with self.assertRaisesMessage()` here instead of a bare try-except, please.
I don't see much value in this check.
Correct, but if me change `ModelState` at some point, this will work automatically or fail, telling us we did something wrong ;)
Not if you're using a client subclass with an overridden default `SERVER_NAME` which is a common pattern when testing projects using `django-hosts`. I suggest we use `response.client.defaults.get('SERVER_NAME', 'testclient')`.
I think raising an exception like `ValueError` might be more appropriate.
... remote URLs (got %s).
"Use assertRedirects(..., fetch_redirect_response=False) instead."
put the closing parenthesis on the next line
Actually you should use `assertNotContains(response, '"/test_admin/admin/r/%s/1/"' % content_type_pk)` to also account for `byte` response content on py3.
Use `assertNotIn` instead.
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
This test isn't properly acting as a regression test as it passes even if the second change in options.py isn't made.
could we make more specific assertions here using `assertFormSetError` - I think that'll make the test more readable.
`items = value.split(self.delimiter) if value else []` is slightly faster.
~~A list comprehension would be a little faster.~~ EDIT: Forgive me, I misread the code.
That's why I wrote "maybe" ;)
Forget it, I misread the double for-loop.
~~Maybe a list comprehension here too.~~
`Final exception` doesn't appear in a template. I added check for `During handling of the above exception`.
You can use `self.fail('Cyclic reference in Exception Reporter.get_traceback_frames()')`
Single quotes please.
We want to change whitespaces in the traceback, so we should test these changes e.g. ```python self.assertIn( ' File "generated", line 2, in funcName\n' ' <source code not available>', text, ) ```
I would add: ``` self.assertIn('<div id="traceback">', htmls[0]) ```
That part looks confusing, as `cr` and `lf` will potentially be used on `buffer_`, not only `chunk`. Instead, I would define two simple helpers `endswith_cr` / `endswith_lf` within `__iter__` — maybe there is some simpler way to do that but I couldn't find one: ``` Python def endswith_cr(line): return line.endswith('\r' if isinstance(line, six.text_type) else b'\r') ```
I think you should use `six` to support both Python 2 and Python 3. ``` py from django.utils.six.moves import xrange ```
What about `prefetch_related()`? It's a new method so we should raise `ValueError` when `aiterator()` is used after `prefetch_related()`, e.g. ```python async def aiterator(self, chunk_size=2000): if chunk_size is None: if self._prefetch_related_lookups: raise ValueError( "chunk_size must be provided when using QuerySet.iterator() after " "prefetch_related()." ) elif chunk_size <= 0: .... ```
Yes. We already do it in a few places.
😁 ```suggestion while results := list(islice(iterator, chunk_size)): ```
Those -> These
Correct, warnings and errors are collected together.
It looks like we should call super() here as the other fields do.
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
I thought the change in `postgis/operations.py` is meant to alias `ForcePolygonCW` to `ST_ForceRHR` on older PostGIS versions to avoid the problem you described.
OK, good. Thanks. I think it's fine as it is. 👍
I might handle the `if not hasattr(self, 'lastmod')` as a guard first, to get it out of the way: ```suggestion def get_latest_lastmod(self): if not hasattr(self, 'lastmod'): return None if callable(self.lastmod): try: return max([self.lastmod(item) for item in self.items()]) except TypeError: return None else: return self.lastmod ```
As the Python `urlencode()` already handles scalars, I think this could be slightly simplified to: ```py if isinstance(value, (list, tuple)): query_val = [ item if isinstance(item, bytes) else str(item) for item in value ] else: query_val = value ```
is this message an accurate improvement? `Using an aggregate in order_by() without also including it in annotate() is not allowed:` I'll also update the test to use `assertRaisesMessage` as suggested by Simon when merging.
What's the point of switching to outer double quotes if you have to escape them? Stick to single quote and use `%r` instead of double quote wrapping ```suggestion raise FieldError('Infinite loop caused by ordering (%r on %s).' % (join_tuple, field)) ```
We should make use of `self.message`.
A bit unrelated, but I would move the closing parenthesis to improve readability: ``` statement.parts['extra'] = ' WITH (pages_per_range={})'.format( schema_editor.quote_value(self.pages_per_range) ) + statement.parts['extra'] ```
Either add `self` or make it `@staticmethod`
`remove_index()` accepts `concurrently`, moreover `self.allow_migrate_model()` check `self.allow_migrate_model()` check is missing, IMO we should use ```python if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.remove_index(model, self.index, concurrently=True) ```
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
A cached property on the Operations class becomes problematic when migrations enter the scene (and there are tests with migrations, so the interaction is likely to exist already with the first use-case).
That's actually the last name of a character in the comic these tests are based upon :-)
Oh. Interesting :-| Bisecting the regression on Django's master branch with your test will show where the regression happened. Depending on what this reveals, a backport could be in order, even if the regression is old.
Bisected to 388bb5bd9aa3cd43825cd8a3632a57d8204f875f. I didn't finish investigating to understand why that's relevant here.
The deliberate error in the reproduction script (`u.is_active = False, # assigning a tuple to a boolean field`) doesn't raise a `ValidationError` until that commit.
Can we remove the `email` field and the tests around it? It looks to me like that's not important for the issue that's solved.
Just missed one `.get()` here.
Please remove unnecessary space i.e. `(validator,)`.
Maybe we could test that `name_color_uniq` is also in the message? ```suggestion with self.assertRaisesMessage(ValidationError, 'name_color_uniq'): ```
Per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/ these could use `assertIs(..., True)`. I've done this for existing `.check_token()` tests in #12380.
```suggestion with self.subTest(location), self.settings(CACHES=settings): ```
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
I think that we should unpack `self._options` here and make them arguments of `RedisCacheClient.__init__()`. ```suggestion return self._class(self._servers, **self._options) ``` This is how we approach this for all of the memcached backends using client classes implemented in third-party packages.
Please move `add()` above `get()` to keep the order consistent with the definition in `BaseCache` and other backends. (It's probably worth ordering the methods in `RedisCacheClient` in the same way.)
```suggestion backend = self.base_params['BACKEND'] ```
I think it would be helpful if this were instead named `invalid_token_re`. The reason is that I coincidentally happened to be reading `csrf.py` and was confused by these lines: https://github.com/django/django/blob/b746596f5f0e1fcac791b0f7c8bfc3d69dfef2ff/django/middleware/csrf.py#L111-L112 The reason this was confusing is that this isn't a regex that matches tokens. It matches invalid tokens. And then I saw this was changed in this PR only a few days ago.
Good catch :dart: , I missed this :facepalm:. Please feel-free to send a patch
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
Actually I think it might be possible to reuse most of `super()._create_index_sql` by using `expressions=[RawSQL(...)]` instead of `columns` to avoid heavy duplication between both methods.
I don't think that a separate ticket is necessary, using `super()._create_index_sql()` will fix described issue.
> Current PR (Allows user to specify suffix - consistent with posgresql backend): Users cannot specify `prefix` it is an option that Django uses internally. I think we should keep the current prefix `_id` for backward compatibility.
We can pass `opclasses` to the `super()._create_index_sql()`.
You can't assume the presence of `self.name` here
I would keep the previous name for a class attribute: ``` self.ignorenonexistent = ignorenonexistent ```
This can be single-lined.
I don't think we want to subclass `base.Deserializer`. Instead, we can just do `self.object_list = object_list` and use that instead of `self.stream` below.
`else` is unnecessary, I think we can leave: ```python if self.ignorenonexistent: continue raise ```
returning `None` isn't perfectly equivalent to `continue`. I think it might be cleaner to move some or all of `_handle_object` back into `__iter__`. This allows us to use `continue` again.
Never mind, just read the whole ticket :) Maybe the initial `assertIsInstance(p.restaurant.serves_pizza, bool)` would make more sense here. Else it might end up being refactored.
`assertTrue` would be appropriate here.
One space after period.
IMO introspecting generated SQL is unnecessary, maybe: ```python def test_order_by_f_expression_to_constant_value(self): qs = Article.objects.annotate(constant=Value(42)).order_by( F("constant"), F("headline") ) self.assertSequenceEqual(qs, [self.a1, self.a2, self.a3, self.a4]) ```
could we inspect `query.order_by` instead? Maybe it's fine as-is, but that seems a bit less fragile.
`assertTrue(value)` will pass for `bool(value) is True` which is different than checking for `True`.
I think at least the latter is worth it - it's confusing to submit two files and be told "the" file is empty.
These assertions are not related with this patch. Personally I don't see much value in adding them.
`try/finally` should be a bit smaller. If there's an exception before `form.save()` the photo won't exist so there's no need to cleanup. I'll make this change and merge it.
You don't need to mock, it will return `False` for a bad file descriptor.
this line should be: `def __init__(self, *args, **kwargs):`
might as well use `setdefault` in the test as well
`assertEqual` (the version you have now is a deprecated alias)
This whole `try`/`except` logic can be replaced by a `self.assertRaises(SSLError, backend.open)`.
Instead of putting timeout in the `__init__` method, make it a class attribute. Here's an example change where we use this same technique: 8b0014869f666b44cd20692e38073ec0a0a8cb08
Does the next patch use the fifth `Author`? If so, it might be more maintainable to replace this hardcoded list with something like `list(range(1, Author.objects.count() + 1))`
could we inspect `query.order_by` instead? Maybe it's fine as-is, but that seems a bit less fragile.
Probably, I don't think the benefit is worth the cognitive load of someone looking at the test and wondering about it.
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
I would multiline: ``` field.attname for field in self.lookup_opts.fields if field.unique and not field.null ```
This assertion is not related with the patch. Please remove it.
Any disadvantage to making it a separate test method instead? I guess the signal connecting might be better is `setUpClass` at that point.
I guess these could be merged by doing a ```python self.assertEqual( qstr.count("LIMIT 1"), 3 if connection.features.supports_limiting_in_compound else 1 ) ```
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
We should convert column name i.e. `connection.introspection.identifier_converter('large_field')`.
We can use here `assertEqual` instead of `assertCountEqual`.
`obj=None` -> `obj`
There should also be an assertion for the output of the new `get_inlines()` method.
This can be single-lined. Please use `tuple`.
I think we want a test with some actual content.
I think we should keep the original type.
Can we move this branch into the `is_sensitive` check above? ``` is_sensitive = ( self.hidden_settings.search(key) or key == settings.SESSION_COOKIE_NAME ) ```
I think an example with `tuple` would be more realistic, e.g. `{('localhost', 8000): {....}`.
This could be simplified as `{k: cleanse_setting(k, v) for k, v in meta.items()}`.
i think this would be cleaner as ```py if not hasattr(request, 'META'): return {} return {k: cleanse_setting(... ```
It's not safe in general, as there's nothing to reset `content_type` back - really a subclass would be needed here, and in the other places this has been dnoe
chop newline for consistency with other tests
please include the trailing comma on the last item in a dictionary so if more items are added we don't have to modify this line again
chop first comma
`assertNotContains` is a bit fragile; instead I'd like if you could check `response.context` variables.
Use single quotes
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
I don't think it's important to mention PostgreSQL version details in the docstring.
This should probably be the default for postgresql's `schema_editor.sql_create_index`.
I would manipulate `names` in `__init__()` instead of doing this on every `get_context()` or `value_from_datadict()` calls, e.g. ```python def __init__(self, widgets, attrs=None): if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] self.widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = widgets self.widgets = [w() if isinstance(w, type) else w for w in self.widgets] super().__init__(attrs) ... def get_context(self, name, value, attrs): ... for i, widget in enumerate(self.widgets): ... widget_name = name + self.widgets_names[i] ... def value_from_datadict(self, data, files, name): return [ widget.value_from_datadict(data, files, name + widget_name) for widget_name, widget in zip(self.widgets_names, self.widgets) ] ``` What do you think? It looks simpler, IMO.
Any thoughts about allowing `widgets` to be a `dict` mapping names to widgets now that we assume that `dict`s are ordered? That seems more elegant than introducing a `names` kwarg and _zip_'ing it with `widgets`.
This needs to incorporate `name` somehow else it will break when form prefixes are involved or on top level field names collisions.
You could zip here as well ```python for i, (widget_name, widget) in enumerate(self.widget_names, self.widgets): if input_type is not None: widget.input_type = input_type widget_name = name + self.widgets_names[i] ```
* We're still preferring single quotes, please use those throughout, unless there's a nested single quote. * This change is unrelated, please revert.
`git pull --rebase` on your branch should be enough.
It looks that this change is not required. All tests pass without it.
I don't think this is needed (probably accidentally copied from line 327).
This code ignores the value of `readonly_fields`. I noticed this because it breaks an inline with a field which is defined as a method in the inline itself (and, thus, needs to be in `readonly_fields`). I'm currently using this workaround (there might be a more clever way to solve it): ```python return [field.name for field in self.opts.local_fields] + \ [field.name for field in self.opts.local_many_to_many] + \ list(self.get_readonly_fields(request, obj)) ```
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
It's usually best to do cleanup changes in a separate commit or pull request. I recommend only touching the imports you need to for now.
I don't think you need `dispatch_uid` here. AFAIK `dispatch_uid` is largely a workaround for the duplicate import problem that was mostly eliminated by the project structure refactor in 1.4 and completely eliminated by the app loading refactor in 1.7.
I would probably allow an additional parameter to allow using `CREATE EXTENSION IF NOT EXISTS` to handle legacy databases where the extension has been installed by hand. I don't see a way how Django could just automatically fake the migration otherwise.
This is `verbose_name` and you should make it translatable. Look at how other contrib apps do it.
don't remove double newline and imports should be alphabetized (`from django.core` would be above `from django.db.models.signals`)
Relying on pk might be problematic since we shouldn't assume the values that the database might assign.
`first()` is not crucial for this regression, so I've changed this to the `order_by()`.
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
This could be a single line: [...]
Could use `assertSequenceEqual` to avoid the `itemgetter`
Chop blank line.
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
As far as I'm aware `unique_fields` should be required when `supports_update_conflicts_with_target` is `True`, so there is no need to use `unique_fields or ()`. Moreover, we should raise an exception when it's not provided.
This method implementation could be simplified by doing: ```python if on_conflicts == ON_CONFLICTS_IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflicts == ON_CONFLICTS_UPDATE: ... return result ... ``` This would also let you eliminate the `if-else` below and initializing `result` to `''`.
A list comprehension is preferable here as `str.join()` converts to list internally anyway. ```suggestion ', '.join([ f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields) ]), ```
What was the importing done for inside method? Looks like a hack, should import django.db.models.lookups module instead if having cross importing problem.
Seems like it would result in less confusing code in the long run. If you do defer it and leave the TODO, I'd suggest to use your GitHub username instead of first name.
For clarity here, shouldn't we use `Func` rather than `Transform`, since they are equivalent and the latter is a back-compat-only name? It seems like using `Transform` might suggest to someone reading this code that there's something distinct about `Transform` as opposed to `Func`.
for new code, we are going for PEP 0257 verb style "Find ..."
Since the existence of instance lookups will be rare I suggest we avoid an unncessary dict creation when `instance_lookups` is missing ```suggestion if not (instance_lookups := self.__dict__.get("instance_lookups"): return class_lookups return {**class_lookups, **instance_lookups} ```
`ChoiceFormSet` -> `ArticleFormSet` You mixed `Article` with `Choice` in few places.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
Please chop unnecessary blank lines.
Ah, good. Widgets... I think something like `formset_class=formset_class.__name__` would be clearer than the HTML string. Then at least you'd get this: ``` FAIL: test_formsets_with_order_custom_widget (tests.forms_tests.tests.test_formsets.FormsFormsetTestCase) [<object object at 0x10456f0a0>] (formset_class='OrderingMethodFormSet') ``` ... which clearly tells you which case went wrong.
`CURRENT_DIR` is already a `Path` object, so we could join this with the `/` operator. ```suggestion html_template_path = CURRENT_DIR / 'templates' / 'technical_500.html' ```
We can safely assume `hasattr(self, 'view_on_site')` will always be `True` here.
on_conflict_suffix_sql? When I see "postfix" I think of a mail server.
The only allowed values for `view_on_site` are a boolean or a callable thus you can safely use the `self.view_on_site` conditional here.
`NotSupportedError`, and please use single-quotes, and add a dot at the end.
Not sure about the status here given the referenced commit had to be reverted, but this at least needs a rebase to merge cleanly.
I would omit the blank line above each "with", up to you though.
no comma since the stuff after "and" couldn't be a sentence on its own
couldn't -> can't
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
I know that tests in `queries` are mixed up, however I would move it to the `Queries6Tests` class.
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
Should we also have a pointer here of the form ```suggestion with self.assertRaisesMessage(FieldError, "Cannot distinct on 'other_rating' alias. Use annotate to promote it"): ```
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
set default `step_size=None` instead of `"any"` and only render that attribute if it's `not None`.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
Please revert this whitespace change.
No need to define another attribute. The form class should be accessible as `self.TestForm`.
under what circumstances do we need this? My system has 'UTF-8', so it's not very exciting as that's the default for these functions.
I am currently giving the PR a full final review and I think we can drop those assertions now that they are done in decode already, what do you think? (same for the assertion in `safe_summary` and other hashers)
You can drop `int` here now (you already are doing it in `decode`), same for other hashers/methods probably.
Should also include `block_size` and `parallelism`
> My main worry here is: Is this correct and does it make sense to implement for such a complex hasher (notably we already have others where we argue it is simply not possible in a sensible way). > > Since scrypt can raise errors like this: > > > ValueError: Invalid parameter combination for n, r, p, maxmem. > > I am wondering if `must_update` couldn't also trigger this condition. Or can we always calculate `extra_iterations` and `extra_block` and be sure that the combinations are valid? You're right parameters may no be valid, e.g. ``` self.work_factor = 2 **14 decoded['work_factor'] = 2 ** 11 ``` both are a power of 2, however `extra_iterations = 14336` is not and raises `ValueError: n must be a power of 2`.
Is there a good reason to order the data like this? I'd personally expect the hash to be at the end, so it could include a `$` .
This method implementation could be simplified by doing: ```python if on_conflicts == ON_CONFLICTS_IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflicts == ON_CONFLICTS_UPDATE: ... return result ... ``` This would also let you eliminate the `if-else` below and initializing `result` to `''`.
You don't need to add the brackets with `join()`.
This looks rather complex and could be simplified: ```suggestion def on_conflict_suffix_sql(self, opts, fields, on_conflict=None, update_fields=None, unique_fields=None): if on_conflict == OnConflict.UPDATE: result = ', '.join(f'{field}=VALUES({field})' for field in update_fields or ()) return 'ON DUPLICATE KEY UPDATE ' + result return super().on_conflict_suffix_sql(opts, fields, on_conflict, update_fields, unique_fields) ``` We should probably also be quoting the field names properly (which I haven't done in the above).
And here. (Also no brackets no needed.)
```suggestion def on_conflict_suffix_sql(self, opts, fields, on_conflict=None, update_fields=None, unique_fields=None): if on_conflict == OnConflict.IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflict == OnConflict.UPDATE: return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ', '.join(unique_fields or ()), ', '.join(f'{field}=excluded.{field}' for field in update_fields or ()), ) return super().on_conflict_suffix_sql(opts, fields, on_conflict, update_fields, unique_fields) ``` If we have `unique_fields` in the signature here, then it should also be in the signature of the super class, not falling back to `**kwargs`. As mentioned in https://github.com/django/django/pull/13065#discussion_r668635778 we should probably be quoting identifiers here properly too.
Remove this line as `is_popup` is already added by `ctx = Context(context)`. The local variable is just for convenience.
Except the message displayed isn't quite right in this case: ``` The X "Great new X" was added successfully. You may edit it again below. ``` It's not true that it may be edited.
Remove this line as `opts` is already added by `ctx = Context(context)`.
Please remove the added blank line.
no need to reformat
Single quotes please.
I think we want a test with some actual content.
There should also be an assertion for the output of the new `get_inlines()` method.
You can reuse `CountryInlineAdmin` and `StateAdmin` instead of defining extra classes: ```suggestion ``` Add `get_formset_params()` to `StateAdmin`.
```suggestion '<div class="fieldBox field-position hidden">' '<label class="inline">Position:</label>' '<div class="readonly">1</div></div>', ```
Shouldn't this be `return isinstance(x, collections.Iterator)` instead? Actually we should replace all reference to this function by a `collection.Iterator` instance check.
I'd remove this docstring, it no longer has much to do with python's version at all
Personally I'd just completely inline it into the function, it's not that much code anymore…
How about using "parent" here instead of "master"? Seems like a better fit with "child processes".
Can we move subclassing `unittest.TestResult` to a separate commit? Is it a valuable optimization on its own? or it's strictly related with supporting `--buffer` with `--parallel`.
Oh, it's because `SEARCH_VAR`, etc. are variables.
I'm not quite following the BC concern...
Backticks are unnecessary, IMO: ``` # Populate "fields" dynamically because SEARCH_VAR is a variable. ```
[This validator is added by default, no need to specify it](https://github.com/django/django/blob/ac956dae1d06ce2ebff7a2966bcaf8a5ecdbb861/django/forms/fields.py#L219). We'll probably want to pass `strip=False` as well to preserve backward compatiblity. Given you have to branch on `var == PAGE_VAR` anyway I don't think there's much value in using a loop here. You could define fields by directly assigning to `self.fields` ```python def __init__(self, *args, **kwargs): self.fields = { SEARCH_VAR: forms.CharField(required=False, strip=False, initial=''), PAGE_VAR: forms.IntegerField(required=False, min_value=0, initial=0), TO_FIELD_VAR: forms.CharField(required=False), } super(ChangeListForm, self).__init__() ``` The `initial` usage will make the `clean()` below unnecessary. ```
Using messages might work.
I think we are missing the `call_command()` here.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
Rephrase: `# Normalize locale strings input by the user.`
Given these methods are all wrapped in `assertTrue` calls they should probably be converted to `assert_all_exists` and `assert_none_exists` that perform the assertion themselves. e.g. ```python def assert_all_exists(self, dir, langs): self.assertTrue(all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ))
I think it's worth, re-added.
Surely you want all of the password hashes in the list of available ones so that people can log in with them? Of course argon2 is unlikely to be out there in the wild, but if someone tried it and then decided to switch back they wouldn't be able to do so by deleting the settings, they'd have to copy/paste the default and re-add it. There's little harm in including it by default afaik. You might not want to have something other than PBKDF2 to be the default though, people might accidently have bcrypt or argon2 installed and not realize it and end up unable to log in if they deploy. Not sure if that's a big worry or not though.
Our code currently requires the first hasher to be usable, putting it as first and not installing the extension will break (look at `get_hasher('default')`)
From a security stand point, argon2 is better than PBKDF2 because it's memory hard as well as CPU hard. Security wise argon2 > scrypt > PBKDF2 ~= bcrypt.
Presumably at some point this change will be released.
`with self.subTest(value=value):` is sufficient -- if a test fails, `expected` will appear in the exception.
Could you switch this around so it's `value, expected` -- that's consistent with other tests.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
Please "rebase" to pickup the changes in 44c0ecdd9226d039a8c666b36ae320af2046a1c1.
This is supposed to be the most used Accept content, however I don't think it contains those added spaces.
Can you use `with self.assertRaisesMessage()` here instead of a bare try-except, please.
Correct, but if me change `ModelState` at some point, this will work automatically or fail, telling us we did something wrong ;)
Can you use `ModelState.from_model()` here, please, as this is what the migration framework will use internally.
If you want to respect the user ability to choose their failureException ( https://github.com/python/cpython/blob/master/Lib/unittest/case.py#L357 ), you can use ``` python self.fail("Not resolved metaclass conflict") ``` instead of forcing the AssertionError. Other thought : by doing this, you may lose all the details of the original `TypeError` exception which might prove useful for debugging when the test fail (but I'm less sure about this one since I'm not sure what might trigger the `TypeError` in the first place).
Shouldn't mixins be to the left of the base class `models.Model`? This is my understanding of how mixins on class-based views work anyway.
f-strings should not contain function calls. This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Can we raise `ValueError` for consistency with what `SchemaEditor` do? ```suggestion if len(matching_index_name) != 1: raise ValueError( f"Found wrong number (%s) of indexes for fields ..." ) ```
Also these error messages are untested.
Should we add `reduce()` for `RenameIndex` on the same model with `self.new_name_lower == operation.old_name_lower`? :thinking:
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
might be nice to revert the ordering changes to keep the diff cleaner
Can you combine the model states to have 3 fields: `DateField`, `DateTimeField`, and `TimeField`.
Per pep8, this should be `max_length=10` (note the lack of whitespace around the equal sign).
I'd do: ``` kwargs['separators'] = kwargs.get('separators', (',', ':')) ``` On Wed, Aug 21, 2013 at 8:06 PM, Tim Graham notifications@github.comwrote: > In django/contrib/messages/storage/session.py: > > > ``` > > else: > > self.request.session.pop(self.session_key, None) > > return [] > > ``` > > > > + > > - def serialize_messages(self, messages): > > - encoder = MessageEncoder(separators=(',', ':')) > > look ok? https://gist.github.com/timgraham/dc1cc1abe202d3830eab > > — > Reply to this email directly or view it on GitHubhttps://github.com/django/django/pull/1488/files#r5903355 > .
I'd move the `separators=(',', ':')` into `__init__` of `MessageEncoder`, so we always get "efficient" (having '__json_message' as key doesn't look to efficient ;)) json without having to specify it everywhere. But we can do this in a 1.6 cleanup commit after committing this.
If you want to use a new name, that's okay with me, but I think `'has_file_field'` should remain for backwards compatibility.
Move `has_view_permission` above `has_add_permission` for consistency.
``` is_multipart = context['adminform'].form.is_multipart() or any( admin_formset.formset.form().is_multipart() for admin_formset in context['inline_admin_formsets'] ) ```
Store the result of `self.get_view_on_site_url(obj)` as a local variable to avoid two function calls.
Except the message displayed isn't quite right in this case: ``` The X "Great new X" was added successfully. You may edit it again below. ``` It's not true that it may be edited.
`annotations` is spelled incorrectly here.
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
Prefer wrapping the expression in parentheses rather than using a backslash
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
please check flake8, I believe this is a warning because the line identation isn't distinguished from the next (fix by add 4 more spaces to this line)
I think this can be in single line: ``` url = reverse('admin:auth_user_add', current_app=self.admin_site.name) ```
This one as well
Same here. And I'd remove the `info` variable completely.
Still I think `'&nbsp;<strong>%s</strong>'` could be factored as a variable and `<a href=...` interpolated inside that. Let's use `format_html` instead of `escape`. This return could go in the `else` block of `try/except/else`.
Could you try to improve this so that there isn't duplication of the HTML and `escape(Truncator(obj)....`
repetitive with method docstring
Thanks @ivorbosloper now it makes sense to me and works fine. I got confused with upper and lower bits wording. Interesting that bits are counted from right to left from that point of view, and that the mask operation works. It would not work the same way with the `BANDTYPE_FLAGS_MASK` as my example shows.
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
comma after tuple
I came across `numpy.testing.assert_array_equal`. Maybe it would be worth using that.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
Same here. And I'd remove the `info` variable completely.
I'll take the time to write one later today but we could use a `@property`: ``` python @property def widget(self): if self.localize: return TextInput else: return NumberInput ``` One of the con here is that `NumberField.widget` will be an instance of `property`. We could also write a descriptor to maintain backward compatibilty: ``` python class WidgetDescriptor(object): def __init__(self, widget, localized_widget): self.widget = widget self.localized_widget = localized_widget def __get__(self, instance, owner): if instance and instance.localize: return self.localized_widget return self.widget class IntegerField(Field): widget = WidgetDescriptor(NumberInput, TextInput) ``` Maybe I'm just over-complicating this whole thing.
I would also consider turning that into an instance method called something like `get_runner()` and starting each test method with `runner = self.get_runner()`. The reason is that instantiating a runner is "cheap." You also don't have to think / worry about whether the runner has state that you might unwittingly be carrying from one test to the other (e.g. attributes set when a method is executed).
With this change, can the entire `clean()` method be removed from `EmailField` and `URLField`? The parent implementation already [calls `to_python()`](https://github.com/django/django/blob/415ae960bb9f1bdae798023fdce3247d2c938eec/django/forms/fields.py#L158).
`targets` is an empty list when `MIGRATE` is `False`: ```suggestion executor.migrate([], plan=[]) ```
I don't like how this entire if block looks. Is `plan` allowed to be `None` considering the check/assignment on line 73 and 74? I'd prefer to call out that it can not be forwards and backwards by doing something like: ``` if all_forwards == all_backards: raise.. # this may not be correct if `plan` can be `None` elif all_forwards: migrate_forwards() else: migrate_backwards() ``` I feel this highlights the invariant, and avoids potential problems of misreading the bool combinations in the original code.
Double checking the commit, this change, in this form leaks some state across migrations. Testing on CI right now. ``` python ERROR: test_alter_id_type_with_fk (migrations.test_executor.ExecutorTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) psycopg2.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. The above exception was the direct cause of the following exception: Traceback (most recent call last): File "/home/markus/Coding/django/django/test/utils.py", line 182, in inner return test_func(*args, **kwargs) File "/home/markus/Coding/django/tests/migrations/test_executor.py", line 401, in test_alter_id_type_with_fk executor.migrate([("author_app", "0002_alter_id")]) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 94, in migrate self.apply_migration(states[migration], migration, fake=fake, fake_initial=fake_initial) File "/home/markus/Coding/django/django/db/migrations/executor.py", line 131, in apply_migration state = migration.apply(state, schema_editor) File "/home/markus/Coding/django/django/db/migrations/migration.py", line 118, in apply operation.database_forwards(self.app_label, schema_editor, old_state, project_state) File "/home/markus/Coding/django/django/db/migrations/operations/fields.py", line 201, in database_forwards schema_editor.alter_field(from_model, from_field, to_field) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 482, in alter_field old_db_params, new_db_params, strict) File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 635, in _alter_field params, File "/home/markus/Coding/django/django/db/backends/base/schema.py", line 106, in execute cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 79, in execute return super(CursorDebugWrapper, self).execute(sql, params) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) File "/home/markus/Coding/django/django/db/utils.py", line 95, in __exit__ six.reraise(dj_exc_type, dj_exc_value, traceback) File "/home/markus/Coding/django/django/utils/six.py", line 658, in reraise raise value.with_traceback(tb) File "/home/markus/Coding/django/django/db/backends/utils.py", line 64, in execute return self.cursor.execute(sql, params) django.db.utils.ProgrammingError: foreign key constraint "book_app_book_author_id_93532c48_fk_author_app_author_id" cannot be implemented DETAIL: Key columns "author_id" and "id" are of incompatible types: integer and character varying. ``` However, integrating this with the second commit on my PR fixes the issue. I thus squash those commits there and close your PR here.
Chop blank line
We've been using "Take / apply" verb-style in new docstrings.
I think so, btw please do `resolver.kwargs.copy()` to leave the original kwargs in place on the resolver object.
You should fetch the arguments and url name from `request.resolver_match` here to ensure that we redirect to the same view, if someone hooks up `password_reset_confirm` with a different name you'd get an error here.
yeah, `request.session.get` would return none for the token and this wouldn't pass the comparision (which would be perfectly fine)
This throws a 500 if the token is not set!
immediatelly -> immediately
This check is also redundant.
This check is also redundant.
This check is redundant. `skipUnless` already guarantees that we have MySQL. You can remove the `try ... except` leaving only `import`.
If `cx_oracle` is installed, there's an error: ``` File "/home/tim/code/django/tests/backends/test_cursors.py", line 33, in OracleCursorOptionsTestCase class OracleLoggingCursor(LoggingCursorMixin, Database): TypeError: metaclass conflict: the metaclass of a derived class must be a (non-strict) subclass of the metaclasses of all its bases ``` Also, is this file doing anything useful? I don't see any test methods.
`e` is unnecessary. Maybe it will be better to refactor these tests and put `class` inside `try` e.g. ```python @unittest.skipUnless(connection.vendor == 'postgresql', 'Postgresql specific test.') class PostgreSQLCursorOptionsTestCase(TestCase): try: from psycopg2.extensions import cursor class PostgresLoggingCursor(LoggingCursorMixin, cursor): pass except ImportError: pass ```
If we don't and `USE_TZ=True` the default datetime used on column creation will be in the system timezone instead of UTC like Django assumes datetime are stored in the database.
I'd probably change this hunk in the diff to: ``` python if getattr(field, 'auto_now', False) or getattr(field, 'auto_now_add', False): default = timezone.now() internal_type = field.get_internal_type() if internal_type == 'DateField': default = default.date() elif internal_type == 'TimeField': default = default.time() # DateTimeField already has correct default now ```
Since the ticket you referenced hasn't moved forward for 11 months, I rather see a fix for this issue here and a deprecation sometime in the future (maybe 1.9 if somebody does it), than having broken code for the next 2 or 3 releases.
Did you see that `TimeField` uses `datetime.datetime.now().time()` and `DateField` `datetime.date.today()`? I guess there might be a discrepancy with using `timezone.now()` in some cases.
Yea, that change doesn't make sense. Thanks for explaining timezones to me, Aymeric :wink:
I had the same idea with the test location, but then realized that the serializers already test the UUIDs use case and handle them differently (through `value_to_string`). So I think the test is correct.
) on next line
I think `queryset` would be a more natural name.
f-strings shouldn't contain function calls. This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
`f-string`s should not contain function calls. This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Yeah, multicolumn case is what I am interested in, the results will not be correct for cases where the first column match, the second is smaller and we use __lt. So, error out in multicolumn case for now, then lets think if we can make this work properly (for some DBs the DB itself knows how to implement (a, b) < (val1, val2)).
I don't think you can do it like this for multicolumn lt, gt constraints. The natural constraint is: a < val1 or (a == val1 and b < val2) at least that is what PostgreSQL gives you. EDIT: We can just throw an error in multicolumn non-exact lookups here for now.
I don't know of this particular case, but I wonder if we will have a fun time ahead regarding NULL handling in general - partial match foreign keys etc, and what it in general means for a composite field to be null... There are some similar cases in Query.add_filter() negated handling.
I like your option 2 of `get_lookups`, I think it improves clarity over what we already have. You could also introduce some caching within the `get_lookups` to improve perf for classes that are looked up multiple times.
> @felixxm in my view, below test code is our expected result. No, it's not. `1 != NULL` so why it's expected that `number` is excluded? see 512da9d5855 and ticket-23797 for more details.
AdminSelect used to take the related model. It now takes the field.
Cannot this information solely be extracted from the model itself? ie `.model._meta.app_label`.
Damn it, there is clear way to get this working. Ie there is no reliable way to determine the source_model_admin for a given URL :( I think we might have to relax permissions a bit and provide the autocomplete to any user for every model which has search fields defined and where the user has any permissions on it.
Will do, fwiw I think ``` url(r'^autocomplete_inline/%s/%s/(?P<field_name>.+)/$' % inline_info, ``` is not enough, two models could use the same inlines with different configs. EDIT: Or also in cases where the same model is registered as inline to multiple models.
It seems this URL doesn't work anymore.
It would clear ambiguity if you added some parentheses here and on the next line: `(' LIMIT %d' % limit) if limit ...`. Initially, I thought the grouping was `% (limit if limit else '')`.
I would remove a temporary variable (`clauses`), e.g. ```python return ' '.join(sql for sql in ( ('LIMIT %d' % limit) if limit else None, ('OFFSET %d' % offset) if offset else None, ) if sql) ```
append(...), not append[...].
`join()` accepts generators, you don't need to create a list `[...]`.
`SELECT * FROM (SELECT "_SUB".*, ROWNUM AS "_RN" FROM (%s) "_SUB" %s) WHERE` ... (`ROWNUM AS "_RN"` should be part of the SELECT clause, not FROM clause).
This docstring is unnecessary.
tests for the `repr`s of `HttpResponseNotAllowed` and `HttpResponseRedirect` already exist in `httpwrappers/tests`, please move these tests there
Why this error is raised? This should return an empty list without raising an exception.
``` python # the following time is equivalent to UTC 2014-03-13 05:34:23.24000 ```
@aaugustin, hopefully you aren't using such responses in your projects?! :smile:
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
wrap docstrings at 80 chars
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
could you limit line length to 120 characters so horizontal scrolling isn't required in GitHub? missing whitespace for: `{% autoescape on%}`
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
I'm a bit confused, but how it will work for multiple aggregations :thinking: ? e.g. ```python Book.objects.none().aggregate(pages_count=Count('pages'), rating_sum=Sum('rating')) ```
in case of -> if
It's not actually a comprehension - this could just use a tuple literal.
remove first comma (also as someone not intimately familiar with the ORM, I'm not quite sure what "default select" means (I assume it's a reference to `default_cols` -- maybe no further explanation is needed).
Other tests use naming like: `test_json_agg_empty`
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Might be simpler without intermediate variables: ``` self.assertIsInstance( Paginator([1, 2, 3], 2).page_range, type(six.moves.range(0)) ) ```
Okay, super, thanks for the clarification @pope1ni. I shall take another look tomorrow and hopefully that's job done! Good work, as ever. 😉
I'm not sure if it's correct. What about static methods that have no args: ```python @staticmethod def item_description(): return "Overridden item description" ```
I'd revert this reformatting to make diff smaller: ```suggestion if code.co_argcount == 2: # one argument is 'self' return attr(obj) else: return attr() ```
This can be outside of `try..`.
I'm not sure I'm a big fan of this error message. "Shadowing" has a specific meaning that may not be clear to everyone. Perhaps something along the lines of "You cannot use the name ... as the to_attr argument, as the model already has a field with this name"
This should be called on re-wrapped `obj`.
`HTTPS` is not necessary, so I removed this line.
Please use single quotes as in other tests.
I find this docstring a bit confusing (copied from elsewhere, I know). I think something like "settings.CSRF_HEADER_NAME can be used to customize the CSRF header name" would be simpler
I'd prefer to decorator the test with `@override_settings` so we don't need to indent the entire test.
It might be helpful to explain: "Invalid - urlparse() raises ValueError", or following the other examples: ``` >>> urlparse('https://[') ValueError: Invalid IPv6 URL ```
This will become a performance issue for the database before it becomes one for the Python process :-)
`on_commit` can be used directly by 3rd-party database backends, that's why we should add a default value to `is_robust.`
```suggestion def on_commit(self, func, is_robust=False): ``` Add default value for better backward compatibility.
`func` is called even if no transaction is in progress, so we should move this to the first line. Fixed.
I would raise a `TypeError`, e.g.: ```suggestion if not callable(func): raise TypeError("on_commit()'s callback must be a callable.") ```
We can revert changes in `_delete_unique_sql()`.
IMO we don't need a `NOT_DEFERRABLE` constant. I would remove it and use `''` here and `None` in `UniqueConstraint.__init__()`), e.g. ```python constraint = self.sql_unique_constraint % { 'columns': ', '.join(map(self.quote_name, fields)), 'defer': defer or '', } ``` ```python class UniqueConstraint(BaseConstraint): def __init__(self, *, fields, name, condition=None, defer=None) ```
You can reuse `self.connection.ops.deferrable_sql()`.
Okay, as before, the other cleanups can be in a separate commit.
Should it be `condition=None` or `condition=''` in all signatures (currently some inconsistency)? I'd lean toward the former.
This needs an order_by clause so that the results are guaranteed to come back in the right order.
Chop blank line.
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
I guess these could be merged by doing a ```python self.assertEqual( qstr.count("LIMIT 1"), 3 if connection.features.supports_limiting_in_compound else 1 ) ```
Sure. Sometimes I mark a ticket RFC if only relatively trivial updates remain. Then I'll just make those updates myself if the contributor doesn't do so.
We don't want to allow database queries in `SimpleTestCase` as the user will leak outside of the test case. I think creating a mock user like this should suffice: ``` class User(object): def __str__(self): return 'jacob' request.user = User() ```
you can drop the `False` to getattr here, `None` is also not true.
chop blank line
I wonder if we want a database feature here for which backends support limiting within a combined query could be useful.
There is no need to split this into multiple assertions: ```suggestion self.assertEqual(check_url_config(None), [ Error( 'URL route ...', id='urls.E009', ), ]) ```
Looks like this could be a single line.
How about omitting it until we have a use case? That will save writing tests and docs for a theoretical feature. :-) From a readability point of view, writing a `re_path()` that mixes regexes and converters in the string, and then has to initialize and pass converters in the URLconf sounds nasty and not something to encourage!
I'm going to be a +1 to just dropping `converters`
As above, wrap the format in quotes. "Your URL pattern '{}' has .."
This might either throw errors or block forever (dunno how field_stream is implemented) if field_stream is empty at this point. Not sure, but something to check!
Also, what if we have a huge number of very short 'name=value's? This will create a dictionary with lots of small strings -- again lots of memory.
What if the 'field_name' is huge? It seems to me that it still goes into memory.
This check seems to be done after the WHOLE field has been read into memory, am I right? The goal was to prevent this.
This is fine as is.
Not sure which of `defer` or `deferrable` makes more sense. The latter might be preferable if we choose the `Deferrable(Enum)` solution.
Perhaps only override for older Pythons? ```suggestion if not PY310: def __repr__(self): return '%s.%s' % (self.__class__.__qualname__, self._name_) ```
Sorry yes I meant `transaction` 🤦‍♂. I think there's `connections[using].in_atomic_block` or something like that.
```suggestion # A similar format was proposed for Python 3.10. ```
returns->return (use PEP257 verb style for new docstrings)
Yeah, that's what I had guessed, just didn't look into it. So the only thing that's new here is a more specific error message for that case. Nothing to see here then, all good.
Yes, we should definitely reject HTTPS requests with no referrer; otherwise we may as well just remove the referrer-checking entirely. I don't think this PR changes that.
This looks odd. If `CSRF_USE_SESSIONS`, then the `CSRF_COOKIE_DOMAIN` should be irrelevant, and `SESSION_COOKIE_DOMAIN` should be used instead. We shouldn't get more good referrers then we had before.
But now it will never fall back to the referer check if the Origin header exists (no matter if the origin header validated fine or not)…
Right, my bad.
a separate model (and same note as above about spaces at end of string)
think we should say 'for database "%s".'
The blank space for the string usually goes at the end of the line instead of the start of the next line.
remove "for this"
use `and` and parenthesis rather than nesting if statements
I'm wondering if this should be within the `DATABASES` setting
I think we should catch `ImportError` and return appropriate message, e.g. ```python try: pk_class = import_string(pk_setting) except ImportError: msg = 'The module %r could not be imported.' if hasattr(self.app_config, 'default_auto_field' ): msg += 'Check your %s.default_auto_field attribute.' % self.app_config else: msg += 'Check your DEFAULT_AUTO_FIELD setting.' raise ImproperlyConfigured(msg % pk_setting) ``` We could also add a cached hook, `get_default_auto_field()`.
I believe this should included in the `_check_default_pk()` with a different check, e.g. `fields.E102`.
include trailing comma in kwargs
I'd order the test with the other `check_html()` tests (above `test_use_required_attribute`).
Can you use `['indexes']` here? If not, the list comprehensions in the next lines have a `not in None` and will fail.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
I think you want `options['indexes'].remove(idx_name)` here. That would simplify this code, and I think together with the change in signature mentioned above, remove the need for `get_index_by_name` as well. [List.remove](https://docs.python.org/3/tutorial/datastructures.html#more-on-lists)
Indexes are not constraints, generally.
this seems to hang on PostgreSQL/MySQL: Error: group instance with pk 1 does not exist.
Yea, it seems a bit unusual, but I don't have an alternative to suggest.
I think 1 needs to be '1'. Try it calling `manage.py createsuperuser`: ``` Username: 1 Error: email instance with pk '1' does not exist. ``` even though: ``` >>> Email.objects.values('pk') [{'pk': 1}] ```
shorten line (rule of thumb I'm using is ~120 characters so I don't have scroll horizontally in github review)
Only `test_fields_with_m2m_by_env` fails on a fresh branch without any of your changes in `django/contrib/auth/management/commands/createsuperuser.py` and `tests/auth_tests/models/with_foreign_key.py`,
`else: assertFieldType('time_field', "models.DateTimeField()")`
There's a lot of repetitions of ``` python if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): ``` in this function now. Also, for Oracle, it doesn't check things it could check (e.g. that `ip_address_field` is a CharField). I think both issues could be addressed with a smarter field-type-asserter; perhaps this is out of scope for the PR, and should be done separately.
Ah, I realized these are E128 which we are ignoring in the flake8 section of setup.cfg. I don't mind the changes, but we are ignoring it because there are 2K+ violations and seemingly not a lot of value in fixing them.
This if (lines 114--123 as I write this) can be folded into the previous one (109--112).
I believe you can simplify all this stuff to lines like: ``` assertFieldType('pos_big_int_field', 'models.%s() % connection.features.introspected_field_types['PositiveBigIntegerField']) ``` I don't think the if statements are needed anymore (similar elsewhere in this file).
I think the wording could be improved a little here: ```suggestion if not self.protocol and not protocol: warnings.warn( "The default protocol will be changed from 'http' to 'https' " "in Django 5.0. Explicitly pass 'protocol' to this method or " "to the constructor to silence this warning.", category=RemovedInDjango50Warning, ) ``` Don't forget to update the tests too.
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
Sorry, was thinking of something else.
You don't know what a docstring is? Trying googling "python docstring".
What's this call for here? 🤔
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
Hah. Had the same thought before I got here. See the caveats mentioned above.
Unlike `_sqlite_lpad()`, I'm not sure we can really improve this. `fill_text * length` is likely to be too long in most cases, and even worse if `fill_text` is multiple characters, but any alternative will probably be slower in general.
I don't think we need the `re_` prefix to the arguments? And perhaps `text` instead of `string` for consistency? We should also avoid coercing to `str` unless we need to: ```python In [1]: text = "This is some text" In [2]: %timeit str(text) 54.7 ns ± 4.28 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) In [3]: %timeit isinstance(text, str) 33.8 ns ± 0.106 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) ``` It might make the non-`str` case slower, but, unless I'm mistaken, we're expecting `text` to be `str` in the majority of cases. ```suggestion def _sqlite_regexp(pattern, text): if pattern is None or text is None: return None if not isinstance(text, str): text = str(text) return bool(re_search(pattern, text)) ``` As an aside, I wonder whether we can do something to compile and cache patterns? This could make a significant difference if the function is called for a large number of rows.
Add a trailing comma so if more items are added later we don't have to modify this line again.
Should use `assertRaisesMessage()` to verify the string also.
Wrap docstring at 79 chars
prefer if you use hanging indent style for this assertion to match the other tests
Could you switch this around so it's `value, expected` -- that's consistent with other tests.
I think we'd normally call this `check_cached_property` or similar Also I'd prefer a longer class name than `A` whilst we're refactoring these tests
We typically follow the camel casing of unittest assertions, e.g. `assertCachedPropertyWorks`. Try to split out test refactoring in a separate PR to ease review.
I feel like this _helper_ is making the assertion harder to reason about. Inlining `getattr(source, attr)` calls would be easier to read IMO.
What's the rationale for changing this test class name? It looks like unnecessary noise to me.
Same style as above.
Can you please choose a new error code that is otherwise unused.
no blank line
True about the ML. Regarding the naming for `related_objects/related_m2m` vs `reverse_rel/reverse_m2m`, that's a new API so there isn't historical names to preserve (unlike `many_to_many` vs `m2m`), we just need to pick the best names to represent the relations.
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
if include_parents is False, this line generates a result that isn't used. Move it inside the if for a minor performance boost.
```suggestion id='templates.E003', ```
I thinking removing APP_DIRS from TEMPLATES (since it defaults to False) is a better suggestion than setting it to False.
`str` -> `six.string_types` for compatibility with Python 2.
```suggestion '{} is used for multiple template tag modules: {}.', ```
.get() falls back to None to `False` isn't really needed I think.
Maybe a `self.patch_execute_statements(self._execute_raise_tablespace_already_exists)` helper method could avoid repetition and long lines requiring unusual indentation.
suggested wording: "SystemExit is raised if the user answers "no" to the prompt asking if it's okay to delete the test tablespace."
I'd split this line in two
`len(statements)` => `statements`
I guess we have poor organization where some tests are organized by class (test_creation/features) and others are organized by database (test_mysql). I'm not requiring a change here but it would be nice to think about how we want to do this going forward.
The proposed text makes sense but leaves me wondering where I can read more about this limitation and if it might be addressed someday.
is this needed? no tests are failing with it removed.
I don't think this needs to live here - it could just live under the definition of `GeometryField` - the `ready` method would be perfect if we were adding this to something which lives outside of `contrib.gis`.
For clarity here, shouldn't we use `Func` rather than `Transform`, since they are equivalent and the latter is a back-compat-only name? It seems like using `Transform` might suggest to someone reading this code that there's something distinct about `Transform` as opposed to `Func`.
Seems like it would result in less confusing code in the long run. If you do defer it and leave the TODO, I'd suggest to use your GitHub username instead of first name.
This won't work either. The tests run, but they're marked as skipped. @felixxm is adjusting.
This will skip Django templates tests also...
```suggestion # RemovedInDjango50Warning: When the deprecation ends, revert to # FORM_RENDERER="django.forms.renderers.Jinja2", ```
This will become a performance issue for the database before it becomes one for the Python process :-)
We could simplify this and also be explicit rather than assuming that the Django renderer is the default? ```suggestion import inspect from django.test.utils import override_settings TEST_SETTINGS = [ { 'FORM_RENDERER': 'django.forms.renderers.DjangoTemplates', 'TEMPLATES': {'BACKEND': 'django.template.backends.django.DjangoTemplates'}, }, { 'FORM_RENDERER': 'django.forms.renderers.Jinja2', 'TEMPLATES': {'BACKEND': 'django.template.backends.jinja2.Jinja2'}, }, ] def test_all_form_renderers(): def wrapper(func): def inner(*args, **kwargs): for settings in TEST_SETTINGS: with override_settings(**settings): func(*args, **kwargs) return inner def decorator(cls): for name, func in inspect.getmembers(cls, inspect.isfunction): if name.startswith('test_'): setattr(cls, name, wrapper(func)) return cls return decorator ``` (I've not tested this, but it should give you an idea.)
What values would this condition have a different outcome than the current one? `is_active or self.allow_inactive_users or is_active is None`
I'd make this a separate test and then you can decorator the test method instead of using `with ....`.
There are a couple assertions like this one that maybe should be updated to assertEqual/NotEqual
What about using the global user model's `normalize_username` method while returning an instance of `self.model`? ```python GlobalUserModel = apps.get_model(self.model._meta.app_label, self.model._meta.object_name) username = GlobalUserModel.normalize_username(username) password = GlobalUserModel.hash_password(password) user = UserModel(username=username, email=email, **extra_fields) user.password = password user.save(using=self._db) return user ```
Could omit the `email_field_name` variable and inline `UserModel.get_email_field_name()` instead.
case -> cast in all test names
Since `fan_since` is None at this point, the test cannot pass! Same below.
I'd make it a separate method: `test_cast_to_char_field_without_max_length`
Clarify "might"? Or simply say `# Silence "Truncated incorrect CHAR(1) value: 'Bob'".`
I don't understand your rationale -- `assertIsInstance` does the same check but throws a more helpful error message.
The size of self.MEDIA_TYPES won't be large, but it would be good to pre-compute this.
`type(self)(...)` looks more Pythonic to me.
I don't know if you need to actually create all the Medias. At this point a unit tests calling merge is sufficient. What I would like to see is: ```python assert list(merge([1,2],[1,3],[2,3], [5,7], [5,6], [6,7,9], [8,9])) == [1,2,3,5,6,7,8,9] ```
This is the same test as above.
Use a single quote.
These two could be `and`ed.
```suggestion skip_empty=True) ```
If we do it the other way around by using an identity transformer `if isinstance(values[0], qs.model)` we would work around the `QuerySet.values_list('charfield', flat=True)` use case.
I think we should `warnings.warn('...', category=RemovedInDjango40Warning)` here.
Maybe test it in `tearDownClass()` then? That method is executed after all tests.
Seems wrong to hard code this list when Django fully supports user-written commands.
Please use the same order as in `--help` output, i.e. `--version`, `--verbosity`, `--settings`, `--pythonpath`, `--traceback`, `--no-color`, and `--force-color`.
Wrap at 79 chars.
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
I'd combine w/previous line for better readability
```suggestion def _select_on_conflict(self, ignore_conflicts, update_conflicts, update_fields, unique_fields): ```
```suggestion 'ignore_conflicts and update_conflicts are mutually exclusive' ```
We try to avoid accessing the database connections when not necessary, so I'd move `db_features`: ```suggestion if ignore_conflicts and update_conflicts: raise ValueError( 'ignore_conflicts and update_conflicts are mutually exclusive.' ) db_features = connections[self.db].features ```
You can move the line above to an `else` clause below.
Was already highlighted [here](https://github.com/django/django/pull/13065#discussion_r684521409) but was missed.
Yes only `BigInteger` breaks alphabetical order (in all backends), I don't want to break it more.
add trailing comma
I think that this will make it hard to override for third-party backends that run the test suite (e.g. see the recent commits of @timgraham for Cockroach DB).
missing whitespace around ==
it would help readability if description[5] and description[4] were assigned local variables describing what they represent
I would suggest integrating this code into `_check_constraints` above, since then the duplicate code up to here can be shared. The name of that function implies that it is expected to check *all* constraints (I' reading it as "check all constraints", not "do something about check-constraints"). There might even be some code sharing in the error generating (e.g. if the constraint-specific check code sets a `message` and `code` variable, some common code could fill in the rest of the warning (especially if the hints are made equal as I suggest below).
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
The wording is a bit inconsistent with the one for check constraints, here there is some duplicate info between the warning and the hint, and it talks about "The constraint" without naming it. I would suggest: ``` checks.Warning( "%s does not support unique constraints with conditions." % connection.display_name, hint=( "A constraint won't be created. Silence this " "warning if you don't care about it." ```
These lines should be removed; it's possible for `databases` to be an empty list during tests and when no `--database` is passed to `manage.py` check as you've mentioned. When this happens this check should be entirely skipped.
The reason for this is that your for loop is running on both dbs, at first `allow_migrate()` returns `True` for the first db (`default`) thus setting `connection`, `allowed_len`, `db_alias` accordingly, but you are not terminating the loop, making it try `other` db with `allow_migrate()`, returning `True` and setting the variables again.
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
I guess these could be merged by doing a ```python self.assertEqual( qstr.count("LIMIT 1"), 3 if connection.features.supports_limiting_in_compound else 1 ) ```
In the original review of this file, I missed the fact (unless I'm missing something now) that there's no need to call `list()` inside of `len()`.
Ditto, I'd remove.
You could use `subtest()` for the loop.
I would manipulate `names` in `__init__()` instead of doing this on every `get_context()` or `value_from_datadict()` calls, e.g. ```python def __init__(self, widgets, attrs=None): if isinstance(widgets, dict): self.widgets_names = [ ('_%s' % name) if name else '' for name in widgets ] self.widgets = widgets.values() else: self.widgets_names = ['_%s' % i for i in range(len(widgets))] self.widgets = widgets self.widgets = [w() if isinstance(w, type) else w for w in self.widgets] super().__init__(attrs) ... def get_context(self, name, value, attrs): ... for i, widget in enumerate(self.widgets): ... widget_name = name + self.widgets_names[i] ... def value_from_datadict(self, data, files, name): return [ widget.value_from_datadict(data, files, name + widget_name) for widget_name, widget in zip(self.widgets_names, self.widgets) ] ``` What do you think? It looks simpler, IMO.
Any thoughts about allowing `widgets` to be a `dict` mapping names to widgets now that we assume that `dict`s are ordered? That seems more elegant than introducing a `names` kwarg and _zip_'ing it with `widgets`.
You also need to update `SplitHiddenDateTimeWidget.__init__()` to add and pass `date_attrs` and `time_attrs` so that attributes can be correctly altered for that widget too. You mentioned this widget in the ticket but didn't make the changes in this PR.
`u'` prefix in unnecessary, please use also hanging indentation.
I think leave the original `widget = widget or self.field.widget` here. Then do the `isinstance()` check, so that we're no repeating ourselves in the `else` block. `widgets` might then be clearer as `subwidgets`. (Or such.)
You can remove also lines [161-163](https://github.com/django/django/pull/13052/files#diff-77d4793905e702bfe9a8fabac708dcc7L161-L163).
I'd be great if we could avoid calling `get_ancestor_link` if `not has_value` given it will be unused anyway.
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
Maybe the problem is that field_name refers to field.name when field.attname should be used. I'm not sure how to get field.attname. It seems val.pk is wrong for two reasons, first the relation might be pointing to some other field than pk, and also it might be that retrieving the val instance might require executing a queryset.
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
```suggestion if not isinstance(perm_list, (list, tuple)): ValueError('perm_list must be a list or tuple.') ```
```suggestion raise ValueError('perm_list must be a list or tuple.') ```
Please compare to the expected value, e.g. `PermWrapper(...)`.
> Wouldn't we have to change the tests, if by any chance we change the class name? Yes and it's expected, we will be aware which tests are affected by our change to the base class. IMO it's also more readable.
prefer this style for multilined docstrings: ``` """ Text """ ```
`no_faulthandler=False` -> `enable_faulthandler=True`
I would suggest changing the code so you're able to use the simpler `faulthandler=True` as the argument name. This will also simplify the code below that reads `if not no_faulthandler`. (You can still keep `--no-faulthandler` as the exposed option though.)
Doc changes required in `topics/testing/advanced.txt`.
Please revert removing blank line.
You can join this line with the previous.
@knbk I do think keeping everything related to url under a singe module does make the most sense as Aymeric say's.
Is there a reason to keep the URL-related APIs split between `django.conf.urls` and `django.urls`? I believe everything should be moved to `django.urls`.
has been -> is
URLconf chop trailing space
I don't think it needs any more logic.
I'm surprised if `str()` is doing something here since `capfirst()` also has some `str()` calls.
Please including a trailing comma in the last item of a dictionary so if more items are added we don't need to modify this line again.
Actually a relation is hidden if it ends with a `'+'`. Here `rel` has a `is_hidden` method that abstract this check.
I don't see much value in added prefixes: `(cached property)`, `(property)`, and putting them in the `name` column can be misleading. We don't include prefixes for `classmethods`, `staticmethods` etc. If it's important for someone they can always add such information to the docstring.
Put the } on the next line and add a trailing comma on this line. That's our convention to ease later adding more items to a dictionary, tuple, etc., if needed.
This docstring isn't necessary as the method name is should be clear enough. ```suggestion ```
Also `4x8.png` is left on the file system when the tests conclude.
The commas aren't necessary in the docstring sentences.
Maybe: `if '\x00' in str(value):`
Please move the `close = True` out of the `try:` block and remove the unused local `e`. ```suggestion try: file = open(file_or_path, 'rb') except OSError: return (None, None) close = True ```
```suggestion """ ```
From what I understand, the point of being able to turn off durability checking (via `ensure_durability`) is that durable atomic blocks _will_ be able to be run within a `TestCase`. So I think it's correct that it should ignore, rather than error.
This flag is ignored when `ensure_durability` is `False`, so we should inform users that is not allowed, e.g. ```diff (django-test) git:pr/13708 felixx@felixx-A555:~/repo/django/tests> git diff diff --git a/django/db/transaction.py b/django/db/transaction.py index c6ba346a99..8a84b97237 100644 --- a/django/db/transaction.py +++ b/django/db/transaction.py @@ -172,6 +172,11 @@ class Atomic(ContextDecorator): self.using = using self.savepoint = savepoint self.durable = durable + if self.durable and not self.ensure_durability: + raise ValueError( + 'A durable atomic block is not allowed. If you are running ' + 'tests, you must use TransactionTestCase, not TestCase.' + ) def __enter__(self): connection = get_connection(self.using) ``` We can be descriptive here.
That's actually the last name of a character in the comic these tests are based upon :-)
should lock -> locks
Drop the blank lines in this function - there are really only five lines which isn't hard to read.
Flatten to a single line - code wraps at 119 characters.
Use a single line (we allow up to 119 characters when it helps readability
Yes, you could do that, too. It's a little confusing because `_get_databases()` functions more like "update" (the provided argument) when a dict is provided. The return value isn't really used in that case.
FYI, I could be wrong, but it looks like this `update()` line could wind up overwriting the special `update()` precedence logic you include in the other branch. A possible fix for this would be to change `_get_databases()` to accept a required dict of databases and initialize the dict outside the first call. That way the update will only be happening in one place, and to the same dict. A second option would be to have these recursive calls build a list of pairs, and combine them to a dict only at the very end, in an outer call.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
GZipMiddleware doesn't modify a weak ETag.
`aiter` is new in Python 3.10. https://docs.python.org/3.10/library/functions.html#aiter Django 4.2 will support Python 3.8, and 3.9 too.
Your solution honestly isn't _that_ much more complex, so I'm not saying we shouldn't do it, I was just curious how you ended up here! I think the resulting patch is pretty nice - I will need to take more time to properly review it but I like it on first glance.
There is not need for an extra variable (`expected_repr_response`), also, we should call `__repr__` directly: ```suggestion self.assertEqual(repr(r), '<StreamingHttpResponse status_code=200>') ```
Can you check for `is not None` here, please. At least on SQLite an empty string is a suitable way to be passed to `reverse_sql` to give `RunSQL` a noop backwards migration. (PostgreSQL fails with `django.db.utils.ProgrammingError: can't execute an empty query`)
``` if name is None: name = self._create_index_name(*args, **kwargs) return self.quote_name(name) ```
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
Collations are not the same as extensions, they are not determine by names. IMO we shouldn't use `IF (NOT) EXISTS` syntax but fail loudly instead. It can create a tricky issues when we will omit creating collations just because the collation with the same name already exists.
We should also remove `self.collation_exists(schema_editor, self.name)` checks.
"Test checks MySQL query syntax"
Small nitpick, I would use `bulk_create` here. ``` python Article.objects.bulk_create( Article(pub_date=pub_datetime.date(), pub_datetime=pub_datetime) for pub_datetime in pub_datetimes ) ```
I'd use `Article.objects.create()` instead of `.save()`
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
Do we need the `tzinfo` bit for the test? I'm worried relying on `get_current_timezone` could make the test flaky.
personal preference: I think `'_language' not in request.session` reads a bit clearer.
this could be modified similar to the below for backwards compatibility I think.
It would be fine to call the function with `None` since `r` isn't used. Again, use `self.settings` to verify that `settings.LANGUAGE_CODE` is returned.
unclear if this is `'name' not in lang_info` or `not ('name' in lang_info ...` (I think the first) would be helpful to restructure or adds parens so it's easily readible
This is also wrong, `LANGUAGE_COOKIE_NAME` is the name of the cookie, not the name used in the session.
with -> the
`msg = None` then only warn if msg is set.
version -> pickled_version `current_version = get_version()` (so we don't have to call it multiple times) check `if version:` first so we can skip `get_version()` if no version on pickled model.
Just state the expected behavior such as "Pickling a QuerySet with an `__in=inner_qs` lookup, shouldn't evaluate inner_qs." We're reserving ticket references for obscure issues that can't be easily described in docstrings (the above tests aren't a good example, unfortunately).
huh, TIL. Transitioning to Python3 from 2.7 for my personal projects and I didn't know they had changed that. Thanks for pointing it out.
Testing `prepare_database()` is difficult (a lot of mocking is needed to get a proper isolation). IMO we can push this without tests.
Creating and isolating new connections in tests are tricky. > if we don't have yet good mocking structure for ORM-database operations Testing database operations is not difficult, but here we want to test a low-level operations related with preparing a database before using ORM.
We don't use `assert ` in tests. Please use `unittest` assertions: ```suggestion self.assertIs(self._extension_exists(), False) ```
Ahh, yes, sorry :facepalm: Good catch :dart:
`get_table_collation()` is missing for Oracle, I added it to the main query.
Remove unused import.
Please change to inner imports.
Propose to clean this up in https://github.com/django/django/pull/8008.
This looks unexpected per isort.
But now the imports aren't alphabetized anymore... :)
We don't need this skip.
Yes, I know. I'll leave it to Aymeric for a second opinion.
IMO, it might be better to harcode the expected HTML rather than generating it programatically as it would be more clear what's expected.
```suggestion elif databases[DEFAULT_DB_ALIAS] == {}: ```
reword: "force_login() skips authentication backends without a get_user() method."
Could we maybe put this logic in a context manager or decorator? It'd be nice not to duplicate it from `render_annotated`. Quick example: ``` python from contextlib import contextmanager @contextmanager def annotate_exception(context, token): try: yield except Exception as e: if context.template.engine.debug and not hasattr(e, 'template_debug'): e.template_debug = context.template.get_exception_info(e, token) raise def stream_annotated(self, context): with annotate_exception(context, self.token): for chunk in self.stream(context): yield chunk ```
rather than silenced and rendered as an empty string.
This is better. I didn't think about the problem with variables that can change values. I have one concern, though. The same `render_context` instance is shared across nodes in the `Template.render()` call, so `template_name` isn't a very safe key to use. The potential arises to clash with other nodes. Maybe we could adjust the approach a bit? My thought is to create a cache dict in the `render_context` using `self` as a key. For example: ``` cache = context.render_context.setdefault(self, {}) template = cache.get(template_name) cache[template_name] = template ``` Alternatively, you could use a unique, uncommon key rather than `self`. The benefit here is that multiple `IncludeNode` instances could share the same cache. That means a template like below would only parse `template.html` once: ``` {% include "template.html" %} {% include "template.html" %} {% include "template.html" %} ``` That seems appropriate in this case.
This is mainly to avoid edge cases. Here's an example: Imagine a 3rd-party node sets a value with key `include.html` in `context.render_context`. It's not probable, but perfectly possible. Later `IncludeNode` runs and happens to also use `include.html` as a key. It will pull whatever is already in `render_context` from that previous node when it shouldn't. Using a custom key won't eliminate the edge case completely, but it does reduce the probability of edge cases. The `ExtendsNode` uses a key value of `extends_context`. `IncludeNode` could do something similar.
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
Please revert this unrelated change.
I've noticed that `None` from `flatchoices` should update `Unknown` not `All`. I fixed this.
I think using a semantic name would help here, e.g. `lookup_kwarg_null`
I don't think you can depend on a None choice being defined for a nullable field, necessarily. I don't think you need to make a change here.
this hanging indent is intentional, you'll see it throughout Django
I see your point and can't think of anything sensible either. Assertion-less tests just seem pointless other than to put a tick in the coverage box.
The following should be tested as well ```python .update(field__c='Test Value', field__b='Other Value') ```
You can use `self.assertXMLEqual`, e.g. ```python def test_xml_serialization(self): test_xml_data = ( '<django-objects version="1.0">' '<object model="postgres_tests.jsonmodel">' '<field name="field" type="JSONField">%s' '</field></object></django-objects>' ) for value, serialized in self.test_values: with self.subTest(value=value): ... self.assertXMLEqual(data, test_xml_data % serialized) ... ```
This test is not related with the patch, so I'll move it to a separate commit.
```suggestion res = self.client.get('/dates/books/2008/week/40/iso_week_format/') ```
Following the existing docstring pattern of wording like "Hook for..." seems useful.
Maybe `By default, return the django.contrib.admin.utils.get_deleted_objects.` instead of `By default this just returns django.contrib.admin.utils.get_deleted_objects.`.
" allowed to be deleted permissions" seems like a typo.
This can be single lined.
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
It allows many new schemes that weren't allowed before.
I think we should include `*args, **kwargs` and pass them to the super `__init__`
Also forgot to mention, I don't think I've seen many regex'es written this way before (using string constant concatenation and continuation lines), and I find it pretty neat.
My point wasn't the r prefix (I just copied that from above), it was moving the dash next to the close-bracket. But now that you mentioned it -- yes, the first and last (`'\.'` and `'\.?'`) need an r prefix, because without it the strings don't have a backslash in them and these expressions will just match anything. I think a test for this could use some invalid punctuation as the separator for the tld -- e.g. `http://unquoted~dot!`
This allows `xn----nx` and even `xn-----`. Are they valid? (edit: FWIW, my IceWeasel seems to think they are)
:+1: We could really use some clearer naming there :)
Is there a reason not to favor the previous approach and pass `returning_fields=self._meta.returning_fields` instead? That seems like a better separation of concerns to me than having the insert compiler lookup `returning_fields`.
I tried to address Simon's request in the da4dd37f5fbb4bf9489f45803ffc0a91d0ac0592, this change also replaces some misleading variables' names.
```python return value if isinstance(value, list) else [value] ```
Single quotes please.
Was this intentional? Doesn't seem to be related to the task...
Drop the comma/space in `[FakeFieldFile(), ]`
```suggestion form.render(), '<div><label for="id_field">Field:</label>' '<input id="id_field" name="field" required type="checkbox"></div>', ```
Likewise, it seems odd to keep `'point'` here: ```suggestion context = widget.get_context('geometry', None, None) ```
```suggestion # The Widget.get_context() attrs argument overrides self.attrs. ```
Do we need a new form? I would reuse `Choice` in both tests: ```python ChoiceFormFormset = formset_factory(Choice, can_delete=True, extra=2) ```
Please use hanging indentation: ```python GenericFormFormset = formset_factory( form=GenericForm, can_delete=True, extra=2, ) ```
I renamed the test and removed the docstring.
```suggestion renderer=renderer, ```
`assertEquals()` is deprecated, please don't use it.
Please check test coverage carefully. I didn't spot a test for this change.
I would move it to `_init__()`: ```python def __init__(self, *, name, expressions, index_type=None, condition=None): ... self.index_type = index_type or `GIST` self.condition = condition super().__init__(name=name) ``` and skip the default in `deconstruct()` and `__str__()`: ```python def deconstruct(self): ... if self.index_type != 'GIST': kwargs['index_type'] = self.index_type ```
We could keep the same format as in indexes: ```suggestion return '<%s: %sname=%r%s%s%s%s%s>' % ( self.__class__.__name__, '' if not self.fields else "fields='%s' " % ', '.join(self.fields), self.name, '' if not self.expressions else " expressions='%s'" % ', '.join([ str(expression) for expression in self.expressions ]), ```
Yes a separate PR with unification sounds good.
Also here: ```python if self.index_type.lower() != 'gist': ```
You might also test the user agent string in `mail.outbox[0].body`.
I think that this can be replaced with the following as above: ```python @unittest.skipIf(geos_version_tuple() < (3, 7), 'GEOS >= 3.7.0 is required') ``` I think we only need to worry about testing the GEOS behaviour if it is actually supported; even if this is only testing the exception-raising behaviour.
The `u` prefix is not necessary (as unicode_literals is imported at the top of the file). `self.assertIn` can be used here.
Wrap docstring at 79 chars.
Great catch :+1:
don't need to assign these to self.
I moved this test to the `tests/messages_tests/tests.py`.
Unnecessary trailing comma and white space.
It looks to me like you can use just `len(self._fields) + len(aliased_fields)` for this, we dont' really need to make a whole list.
I'm not sure what this sentence means
We could add a note about `OSMGeoAdmin`, e.g. ```suggestion 'django.contrib.gis.admin.GeoModelAdmin and OSMGeoAdmin are ' 'deprecated in favor of django.contrib.gis.admin.GISModelAdmin.', ```
`admin.admin` is not so smart, let's add a convenient import in `admin.__init__`
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
I've submitted patch https://github.com/django/django/pull/11490.
OK, so after #11490 `add_select_col()` works properly because `self.query` is created by a compiler so it is not reuse and doesn't mutate combined queries.
You should use tuple deconstruction in a number of places, starting with `query, params = super().as_sql()`. See other SQLCompiler methods. Also you seem to have replicated a bit of logic from `SQLCompiler.get_order_by()`. You shouldn't do that, but find a way to reuse it. `order_by()` supports many forms beyond the asc/desc field name form you've compiled here.
Also I think that `is_ref` will need to be handled in a special way. The reference will need to be resolved to inline the expression. This can be tested by with the following code ```python updated_count = UniqueNumber.objects.annotate( number_inverse=F('number') * -1 ).order_by('number_inverse').update( number=F('number') + 2, ) self.assertEqual(updated_count, 2) ``` In this case `number_inverse` will yield `is_ref=True` and `expr` will be an instance of `Ref` if I'm not mistaken.
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
Add a space before `M2M`.
I guess renaming the `fields` variable to `columns` wouldn't hurt here. At first I assumed `fields` was a list of `db.models.Field` and thought there could be an issue with the use of `f.name` instead of `f.column`
This is the only use of cursor in this block.
We might want to remove this dead branch.
While you're here, please remove the comma.
`date=rfc850date` isn't needed in the `subTest()` -- since will appear if the assertion fails.
I don't think the number of tests is an issue, but since the check depends on a variable, the test should also reflect this, or it'll break at some point.
I would move mocking `datetime` to a decorator, after that we will be able to test different dates, e.g. ```python @mock.patch('django.utils.http.datetime.datetime') def test_parsing_rfc850(self, mocked_datetime): mocked_datetime.side_effect = lambda *args, **kw: datetime(*args, **kw) utcnow_first_fifty = datetime(2019, 11, 6, 8, 49, 37) utcnow_second_fifty = datetime(2051, 11, 6, 8, 49, 37) date = ( ('Tuesday, 31-Dec-69 08:49:37 GMT', datetime(2069, 12, 31, 8, 49, 37), utcnow_first_fifty), ('Monday, 10-Nov-70 18:49:37 GMT', datetime(1970, 11, 10, 18, 49, 37), utcnow_first_fifty), ('Wednesday, 31-Dec-71 18:49:37 GMT', datetime(1971, 12, 31, 18, 49, 37), utcnow_first_fifty), ('Thursday, 31-Dec-99 08:49:37 GMT', datetime(2099, 12, 31, 8, 49, 37), utcnow_second_fifty), ('Thursday, 10-Nov-50 18:49:37 GMT', datetime(2050, 11, 10, 18, 49, 37), utcnow_second_fifty), ('Sunday, 31-Dec-00 18:49:37 GMT', datetime(2000, 12, 31, 18, 49, 37), utcnow_second_fifty), ) for rfc850str, expected_date, utcnow in date: mocked_datetime.utcnow = mock.Mock(return_value=utcnow) with self.subTest(string=rfc850str): parsed = parse_http_date(rfc850str) self.assertEqual(datetime.utcfromtimestamp(parsed), expected_date) ```
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
Please swap the order in the assertions and put `response` on the left, `self.assertEqual(response['Expires'], 'Sun, 17 Jul 2016 10:00:02 GMT')`
Don't use a mutable default: `{}`. Should default to `None` and then add : ``` if json_dumps_params is None: json_dumps_params={} ```
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
chop trailing newline (check code with flake8 to see a couple other minor formatting things)
Here I think we just should just default to `json.dumps` if no encoder is specified. No need for an extra setting.
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
I don't think we need to check all rows, probably sth like this: ```python self.assertEqual(list(qs.values_list('lead_default', flat=True).distinct()), [60000]) ``` will be sufficient. We have a similar situation in the `test_nth_returns_null`.
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
Maybe better named as `health_check_enabled` or `_configured`
```suggestion return "<%s vendor='%s' alias='%s'>" % ( ```
This can cause credential leaks on crash :fire: , e.g. in Sentry. I would leave only `alias` and `vendor`.
Please leave 1 blank line between summary line and description: ```suggestion Deserialize simple Python objects back into Django ORM instances. ```
Fine, but not as part of this PR. If you can change these cases systemically, that would be great.
no dash in "email"
its so that, for example, a ...
I'd include the min length in the error message
Not sure how much a difference it makes, but it seems better to store this in Python rather than having to read from a text file. Worth it to make the file location customizable? If so, it might be nice to make "common passwords" a separate package so we don't have to include that list in Django. I guess users might not care for the additional setup tasks though.
Scanning a list will not be faster than a membership test of a set (unless the list of words is very small).
Any required changes in this file should have corresponding test changes. For example, I reverted this change and didn't see any test failures.
We use line lengths up to 119 characters when it helps readability. I wouldn't reformat this line when it doesn't have any other changes.
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
We can remove `'book_join'` from `order_by()`.
For test doc strings, rather than "Test X" I try to describe the desired behavior: `A ValueError is raised when the incorrect object type is passed to a query lookup."
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
We prefer hanging indent style like this: ``` self.assertEqual( res.context_data["form"].errors["__all__"], ['You must confirm the delete.']) ) ``` Also please drop the u prefix on strings.
this can be a single line (we prefer longer lines when it improves readability)
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
Why would you need to sanitize something that's already in your session? Seems a bit late...
Maybe change that into a `try/execpt AttributeError`. It's kinda nitpicky, but given that if you want to use session-based CSRF you will most likely have a session object on the request and then try/except would be faster (And even if not, it seems more natural and shows a nice chained error on python3).
Merge with the line below since you are not using `session_token` later on. Is it actually needed to sanitize the session token? After all the user cannot change it.
Again single quotes
add trailing comma
Yup, good point.
Set literals are Python 2.7+ only, so this won't work for now. It would need to be a list or similar at the moment.
IMO, it might be better to harcode the expected HTML rather than generating it programatically as it would be more clear what's expected.
Yes, I know. I'll leave it to Aymeric for a second opinion.
.get() falls back to None to `False` isn't really needed I think.
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
The same amount of caching would be happening in the approach I'm suggesting. It's just that you would be calling `self.resolve_fields_and_relations() / self.all_relations = ...` (e.g. in a method) instead of accessing a cached property. It just seems like the usage in the PR doesn't really match `@cached_property`'s use case. In addition to what I mentioned above, the calls to `self.all_relations` in the PR aren't using the return value, it's just doing that for the caching side effect, which you could do more simply / explicitly.
> Would that be fine? Or is there something I am missing? `else` is not necessary, there is no need to resolve relations at this point.
I don't see much value in renaming this method. This wouldn't make it a public API as explicit docs are also required. Also, there is a separate ticket-25671 and #13918 that propose to change related methods. I think we can revert this change for now.
Yes, this should be taken care of before.
> This pattern is common to all backends. Note that the `filebased` backend doesn't follow this pattern. It puts the `make_key()` / `validate_key()` lines in a single place: https://github.com/django/django/blob/3445c50a3affc5ae7b1c2712a139d4a5105aeaf5/django/core/cache/backends/filebased.py#L130-L131
I wouldn't say it's a separate PR since this is new code being added for the first time, and one can evaluate what is being added on its own merits. The method I'm proposing would be specific to this class, so it wouldn't affect other backends.
FWIW +1 to doing it as a separate clean up. IMO it'll be much clearer what change was where looking back that way.
This pattern is common to all backends. Maybe it makes sense to merge them together? If there is reason to call `make_key()` without validation it could learn `validate=False()`. Either way, it's a separate PR.
See #14802 and ticket-33060.
Using messages might work.
Simply access `form.cleaned_data` instead.
The output here is suboptimal. e.g.`* p * Ensure this value is greater than or equal to 0` We need to provide custom error messages that make sense when displayed as `messages`. We should maybe add the individual messages, in a loop, rather than the list.
Ahh, right, so :wink: : ```python for error in _search_form.errors.values(): ```
And this to `self.queryset`.
Put the `not field.many_to_many` first and the `isinstance()` second, please.
If changing the messages, please update them in `docs/ref/checks.txt` as well.
As noted elsewhere, put the trailing space on this line rather than the next (and in the message below).
Was going to suggest the same, but see that @charettes got there first. > Yes, but IMHO it's worse for readability. Fair enough.
Can you please choose a new error code that is otherwise unused.
As `BaseFormSet` is inheriting from `Renderable` we can ditch this as the definition is the same: ```suggestion ``` You can also remove `.as_table()`, `.as_p()`, and `.as_ul()`.
```suggestion return {'formset': self} ```
```suggestion """Render as <p> elements.""" ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
Chop blank lines.
You can encapsulate `tuple`: ```python for target, expected_name in test_args: ```
This line and `os.mkdir(bad_target)` are unnecessary, we don't need to create directories for this test.
Chop blank line.
would be fine to use double quotes so you don't have to escape the single
Ah, you're right. makes sense, then.
You should be able to skip that line
Please use hanging indents here, too: ``` python self.assertEqual( list(...), [...], ) ```
Might be worth renaming this to `self.root_queryset`.
Please use single quotes.
Use a single line here.
This test is not related with the patch, I will move it to a separate commit.
`CharFieldModel` -> `RangeLookupsModel`. You don't need to create new objects.
Maybe ```suggestion [len(self.objs) - 1] * len(self.objs), ```
We should keep both assertions: ```suggestion self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='ar').exists(), False) self.assertIs(NullableJSONModel.objects.filter(value__foo__contains='bar').exists(), True) ```
I think you can remove the blank lines as the helpers for checking HTML should ignore whitespace between tags.
please multiline the string ``` '<select id="id_f" name="f" disabled><option value="J">John</option>' '<option value="P">Paul</option></select>') ```
```python self.assertHTMLEqual( field.widget.render('name', []), ( '<ul>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="entertainment">Entertainment</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="test">A test</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="third-test">Third</label></li>' '</ul>' ) % (self.c1.pk, self.c2.pk, self.c3.pk), ) ```
I think there are enough tests about forms using the formats machine to sanitize input values. I'd rather specifically tests `sanitize_separators` in a separate `test_sanitize_separators` test.
```suggestion self.assertEqual( ```
Remove this line as `is_popup` is already added by `ctx = Context(context)`. The local variable is just for convenience.
Except the message displayed isn't quite right in this case: ``` The X "Great new X" was added successfully. You may edit it again below. ``` It's not true that it may be edited.
Remove this line as `opts` is already added by `ctx = Context(context)`.
Please remove the added blank line.
no need to reformat
It's orthogonal to this PR but this `self._db` in place of just `db` looks wrong.
Use hanging indent: ``` raise ValueError( '"%r" needs to have a value for field "%s" before ' ... ) ```
Current implementation of `get_prefetch_queryset()` assumes that all instances have the same content type (there is an issue), but the fix is not optimal IMO because object IDs can be the same in different content types, e.g. we have two related objects: - object ID 1 with content type ID 1, - object ID 2 with content type ID 2, this query will return also: - object ID 2 with content type ID 1, - object ID 1 with content type ID 2, which is not correct. I know that we are matching them below but still I think we can limit the no. of objects only to actually needed.
I would leave it as a `lambda`.
Same as below, you should be able to call `self.using()` directly.
objects. It may take...
Use PEP 0257 verb style, "Return True.."
Most of Django could be updated, but I'm torn about whether or not we should do it (increased chance of backport conflicts / less useful git blame).
"is used to specify" -> specifies
If there's GEOS 3.1 (as on Ubuntu 10.04), however you'll need to raise a `NotImplementedError`.
```suggestion self.add_error(None, ValidationError('A non-field error')) ```
Chop blank line.
Use list and remove unnecessary whitespace ```suggestion fields = [('name', 'position')] ```
This can be single-lined.
please include a trailing comma in cases like this so if we add more items later, we don't have to modify the line again
move this to the previous line (we favor longer lines over non-hanging indent)
this line should be: `def __init__(self, *args, **kwargs):`
use same indent style as previous item
For easier typing and consistency with elsewhere, I'd omit the dash in the domains and names.
yeah I don't see a reason why the imports are not top-level and we don't call the functions directly.
should be -> is "if the database supports it."
Given that the index is named `title_lower_id` this `LOWER` check could check against that as well as `lower(xxx)` -- please rename the index so there is only one match for `LOWER` (same for `TITLE`)
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
Yeah - that was the source of my confusion about the `setdefault` thing. My original test case was wrong, but the same problem manifests if you use `ErrorDict()`.
These three lines are essentially doing the fix - not the change to `update_error_dict`. Prior to these calls, printing `self._errors` shows that each "value" in self._errors is a `ValidationError()` instance; this converts the ValidationError instance into an ErrorList, which has the right behaviour when printed.
As far as I'm aware, for backward compatibility we should assigned errors from `UniqueConstraint`s with a single field to this field :thinking:
In `_handle_m2m_field()` and `_handle_foreign_key_field()` we can avoid of temporary variables (`value`) and return directly, e.g. ```python def _handle_foreign_key_field(self, field, field_value): return base.deserialize_fk_value(field, field_value, self.using, self.handle_forward_references) ```
We should make use of `self.message`.
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
I don't think you need `list()` here.
You're calling `model_name.lower()` twice in most cases
I don't think we need an explicit `if` here. `_pending_lookups` is `{}` by default and thus the for-loop body isn't run anyways.
> Would that be fine? Or is there something I am missing? `else` is not necessary, there is no need to resolve relations at this point.
I'd certainly be tempted to get rid of this branch, unless someone can identify a case that hits it.
Yes, fine with me.
is there a need to store `self._ready` on self instead of simply using a local variable (besides for checking it in tests)? `del self._ready` seems a bit ugly.
I think you can simply decorate the method with `@contextmanager`. Also, a docstring for the method would be good to add.
Can you put the `\n`s at the end of the previous line.
The `__init__()` method? There are ~15 lines below `super()` that seem to be used.
If you set the class attribute `arity = 1` you can remove the `__init__` altogether. Actually, if you do that, then you can drop this base class and just set `arity` on the subclasses.
Dots are missing i.e.: `..., e.g. Count('id').` On the other hand I think we can remove an example.
Use single quotes.
`arity = 1`
I think it should be quoted in all cases.
We can simplify this with changing a template: ```python sql = self.sql_alter_column_collate if new_field.db_collation else self.sql_alter_column_no_collate return sql % { 'column': self.quote_name(new_field.column), 'type': new_type, 'collation': self.quote_name(new_collation), }, [], } ```
Can this be simplified to ```suggestion # Collation change? elif getattr(old_field, 'db_collation', None) != getattr(new_field, 'db_collation', None): new_collation = getattr(new_field, 'db_collation', None) fragment = self._alter_column_collation_sql(new_field, new_type, new_collation) actions.append(fragment) ``` Or maybe we want to keep the old code to support field type and collation change at the same time (e.g. `CharField(db_collation='foo') -> TextField(db_collation='bar')`).
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
Indeed this one looks fine. It will have beneficial performance effects if: - ATOMIC_REQUESTS is not in use - `update_or_create` ends up creating an object - the `save` method of that objects does long things like sending email _after_ the write (i.e. once it holds an exclusive lock on the database)
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
This exception message is different from that in `related.py` though the logic/intention surrounding it seems to be the same. Is this intentional? (FWIW, I find the message in `related.py` to be clearer)
Same as below, you should be able to call `self.using()` directly.
Welcome to the wonderful world of `contenttypes` where clearing a GFK (even an optional one) actually deletes the objects.
I think you could merge the two `if` statements into one: ``` if (lang_code not in supported and lang_code in deprecated_locales and deprecated_locales[lang_code] in supported): return deprecated_locales[lang_code] ```
That docstring doesn't add much info. It isn't useful to paraphrase a function's signature!
unclear if this is `'name' not in lang_info` or `not ('name' in lang_info ...` (I think the first) would be helpful to restructure or adds parens so it's easily readible
This is also wrong, `LANGUAGE_COOKIE_NAME` is the name of the cookie, not the name used in the session.
This is wrong, `SESSION_COOKIE_NAME` is the name used in the cookie, not an attribute name on the `request` object. Besides it isn't equal to `'session'` by default.
please avoid non-4 space indentation
Do we need such a large try/except block? That makes it difficult to spot what statement(s) might throw an exception and could hide other bugs.
Besides, this change doesn't improve speed. From experience, any change will slow down reviews and hinder this from being merged ;)
IMHO I don't think you should use 0 values as boolean. If you want boolean, use boolean. Besides, `grouping` may have too many types now. I can be an integer, a tuple and boolean. I would stick with a separate variable called `use_grouping` here. It's more descriptive.
`as defined by the arguments` is not really telling me anything. I would either add a longer more descriptive doc string or none.
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
Maybe `By default, return the django.contrib.admin.utils.get_deleted_objects.` instead of `By default this just returns django.contrib.admin.utils.get_deleted_objects.`.
" allowed to be deleted permissions" seems like a typo.
Following the existing docstring pattern of wording like "Hook for..." seems useful.
This can be single lined.
Wrap docstrings at 79 characters. Try to avoid "we... " (often this results in simpler language).
`Final exception` doesn't appear in a template. I added check for `During handling of the above exception`.
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
please limit line lengths so horizontal scrolling isn't required, something like: ``` self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> ' '...' ) ```
IMO, it might be better to harcode the expected HTML rather than generating it programatically as it would be more clear what's expected.
Same here: ```suggestion with self.assertRaisesMessage(ValidationError, 'Enter a valid duration.'): ```
This can be dropped since `connection` is already imported in the context of the module. ```suggestion ```
(same pattern as above, if you change it)
Both `with` should fit on the same line, `with self.subTest(value=value), self.assertRaisesMessage(ValidationError, "'Enter a number.'"):`
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
How about # View is not a callable (string import; arbitrary Python object)
How about `# View is not a callable (explicit import; arbitrary Python object)`
It would probably be less confusing if this were `dict(greeting='Hello!')` so we don't have so many parts called "extra_email_context".
URL seems to be unused
Let's be consistent about whether `app_name` appears above or below `urlpatterns`.
What about: ```py for secret in self.secrets: if constant_time_compare(self._make_token_with_timestamp(user, ts, secret), token): break else: return False ``` EDIT: f'uped the indendation. First time I think I am using for … else
Same as below, I think I'd prefer a loop that breaks early.
Use `assertIs(…, True/False)` for testing boolean values, rather than `assertTrue()` and `assertFalse()` as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion self.assertIs(p1.check_token(user, tk), True) self.assertIs(p2.check_token(user, tk), True) ```
```suggestion self.assertIs(p2.check_token(user, tk), False) ```
```suggestion self.assertIs(p2.check_token(user, tk), True) ```
```suggestion def loads( s, key=None, salt='django.core.signing', serializer=JSONSerializer, max_age=None, fallback_keys=None, ): ```
This is unrelated, please revert.
I'm a little concerned about the loss of `constant_time_compare()` here which sounds like it was added as a potential mitigation against timing attacks.
Please don't make unrelated whitespace changes.
Positional arguments cannot follow keyword arguments.
Use outer double quotes to avoid backslashes.
As far as I'm aware, for backward compatibility we should assigned errors from `UniqueConstraint`s with a single field to this field :thinking:
This could be replaced by `self.remote_field.model._meta.label_lower` https://github.com/django/django/blob/c1b24718e05ea474955777d7bc4d9d5634560cd5/django/db/models/options.py#L136-L138
I suggest you skip the check (`return []` early) if the intermediary model (`self.remote_field.through`) is not resolved. That is `isinstance(self.remote_field.through, six.string_types)`. Also I would store `m2m_db_table` in a variable as you'll need to reuse it to lookup `registered_tables` below.
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
_"Use single quotes for strings, or a double quote if the string contains a single quote. Don’t waste time doing unrelated refactoring of existing code to conform to this style."_
Use single quotes.
Please chop all unnecessary blank lines.
A bit simpler could be "Clear cached, stale oids."
I'm not exactly sure what "straight away" means here. I wonder if something like this could be an improvement: ``` # Registering new type handlers cannot be done before the extension is # installed, otherwise a subsequent data migration would use the same # connection. ```
```python self.assertHTMLEqual( field.widget.render('name', []), ( '<ul>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="entertainment">Entertainment</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="test">A test</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="third-test">Third</label></li>' '</ul>' ) % (self.c1.pk, self.c2.pk, self.c3.pk), ) ```
Calling `is_valid()` in `__repr__` is not an option (as it triggers validation).
In each of the three cases, can you change `False` to `None` and add a trailing comma. (I think we *could* also move the placeholder line to the top to allow it to be overridden by the context, but it may not be worth it as I'm not sure the attributes passed down can be specified for each select individually...)
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
no restructured text (:class:) in docstrings please
In `_handle_m2m_field()` and `_handle_foreign_key_field()` we can avoid of temporary variables (`value`) and return directly, e.g. ```python def _handle_foreign_key_field(self, field, field_value): return base.deserialize_fk_value(field, field_value, self.using, self.handle_forward_references) ```
`else` is unnecessary, I think we can leave: ```python if self.ignorenonexistent: continue raise ```
I would keep the previous name for a class attribute: ``` self.ignorenonexistent = ignorenonexistent ```
This can be single-lined.
returning `None` isn't perfectly equivalent to `continue`. I think it might be cleaner to move some or all of `_handle_object` back into `__iter__`. This allows us to use `continue` again.
You could do this setup in Python. `self.school.students.add(...)`
The benefit of the extra tests is they make the HTML structure clear, but the CSS selector perhaps does that... We should use hanging indent for the wrapping, so maybe pull the CSS selector into a variable, so it's easy read/see, and then the lines would be shorter too, and we can just have the two assertions.
This should go to the 2nd commit :pick:
```suggestion # Even the third inline should have the correct verbose_name ```
Maybe: ```python self.assertEqual(len(self.selenium.find_elements( By.CSS_SELECTOR, '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]', )), 1) ``` or ```python selector = '.dynamic-profile_set#profile_set-0 input[name=profile_set-0-first_name]' self.assertEqual(len(self.selenium.find_elements(By.CSS_SELECTOR, selector)), 1) ```
It might be helpful to explain: "Invalid - urlparse() raises ValueError", or following the other examples: ``` >>> urlparse('https://[') ValueError: Invalid IPv6 URL ```
The test should probably use `subTest()` similar to 272f685794de0b8dead220ee57b30e65c9aa097c so that all HTTP methods are tested (at least if the change to every method is required).
I'm not sure why we pass `data` and build a query string in tests views :thinking: I would simplify this: ```python def test_follow_307_and_308_no_get_preserves_query_string(self): methods = ('post', 'head', 'options', 'put', 'patch', 'delete', 'trace') codes = (307, 308) for method, code in itertools.product(methods, codes): with self.subTest(method=method, code=code): req_method = getattr(self.client, method) response = req_method('/redirect_query_%s/' % code, follow=True) self.assertRedirects(response, '/post_view/?hello=world', status_code=code) ``` and in `views.py`: ```python def method_saving_307_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=307) def method_saving_308_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=308) ``` Maybe I'm missing sth.
@lothemar I realized that previous assertions were correct. The current tests work even without this patch. I will restore them, sorry.
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
```suggestion path = '%s/' % request.path ``` :thinking:
This will _break_ the debug page I think: instead of a list of routed URL patterns, we'll get a plain 404 error response. (Would like to do something at the resolver level, but we don't have the request... Can we limit it just to `DEBUG=False`? 🤔)
OK, that sounds/looks interesting. Let me have a play. Thanks @jdufresne!
I don't see much value in renaming this method. This wouldn't make it a public API as explicit docs are also required. Also, there is a separate ticket-25671 and #13918 that propose to change related methods. I think we can revert this change for now.
The check here should include `is_staff`. If you don't have permission to access the admin at all then we don't need to apply the redirect.
single line looks okay here
We define the same class in the `django.contrib.sessions.serializers`. Maybe we could move it (in a separate PR/commit) to the `django/core/serializers/base.py` and re-use in both places :thinking:
I think this test would be fine without the blank lines, it's fairly short.
Running `test_incorrect_field_expression_in_join()` without a fix, doesn't behave like it's described in the ticket on the PostgreSQL database. It raises: _"django.db.utils.ProgrammingError: operator does not exist: character varying = integer"_ IMO using `ceo__pk` instead of `ceo_firstname` should fix this issue.
But it's already covered by the first assertions. Moreover `assertEqual()` uses `assertTupleEqual()` internally.
To catch this as a `IntegrityError` on Oracle we need to add `ORA-00001` to the wrapper: ```diff --git a/django/db/backends/oracle/base.py b/django/db/backends/oracle/base.py index 4d2f5b51f1..3908aebda1 100644 --- a/django/db/backends/oracle/base.py +++ b/django/db/backends/oracle/base.py @@ -73,7 +73,7 @@ def wrap_oracle_errors(): # _C00102056) violated - parent key not found' # Convert that case to Django's IntegrityError exception. x = e.args[0] - if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and 'ORA-02291' in x.message: + if hasattr(x, 'code') and hasattr(x, 'message') and x.code == 2091 and ('ORA-02291' in x.message or 'ORA-00001' in x.message): raise IntegrityError(*tuple(e.args)) raise ```
I don't see much value in this check.
Please use this style to limit lines to 120 characters so we don't have to scroll to review it: ``` self.assertEqual( ..., ... ) ```
I'd like to have some actual tests for the underlying foreign keys: see the `self.assertFKExsits()` and `self.assertFKNotExists` usage in `test_rename_model_with_self_referential_fk()`
Please use shorter name (less than 30 chars), e.g. `deferrable_pink_constraint`.
Yeah, that's what I had guessed, just didn't look into it. So the only thing that's new here is a more specific error message for that case. Nothing to see here then, all good.
Yes, we should definitely reject HTTPS requests with no referrer; otherwise we may as well just remove the referrer-checking entirely. I don't think this PR changes that.
This looks odd. If `CSRF_USE_SESSIONS`, then the `CSRF_COOKIE_DOMAIN` should be irrelevant, and `SESSION_COOKIE_DOMAIN` should be used instead. We shouldn't get more good referrers then we had before.
But now it will never fall back to the referer check if the Origin header exists (no matter if the origin header validated fine or not)…
Right, my bad.
Didn't you have a version of your patch where you called a method to get the labels? I guess we might have the same issues here than above (label=None or field name not in fields).
This `except` block is never tested in the `formsets` case.
This seems incorrect -- we aren't using any data from the formset.
I suggest to call the variable `changed_fields_labels`.
Use form.changed_data directly and remove the alias as recommended by Tim.
We're using PEP 257 verbs for new code "Return ..."
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
``` return datetime.datetime(1970, 1, 1, tzinfo=timezone.utc) ```
I think that this part can be dropped: ```diff diff --git a/tests/db_functions/test_datetime.py b/tests/db_functions/test_datetime.py index 51dbcb6..3560a76 100644 --- a/tests/db_functions/test_datetime.py +++ b/tests/db_functions/test_datetime.py @@ -211,12 +211,6 @@ class DateFunctionTests(TestCase): self.create_model(end_datetime, start_datetime) self.assertQuerysetEqual( - DTModel.objects.annotate(extracted=Extract('duration', 'epoch')).order_by('start_datetime'), - [(start_datetime, int((end_datetime - start_datetime).total_seconds())), - (end_datetime, int((start_datetime - end_datetime).total_seconds()))], - lambda m: (m.start_datetime, m.extracted) - ) - self.assertQuerysetEqual( ```
Likely want to raise `FieldDoesNotExist` or `FieldError` here instead.
Use `self.remoted_field.model._meta.concrete_model` below instead
Are these two conditions really necessary? It feels like they could be removed.
This can happen also for `OneToOneField` so we shouldn't put `ForeignKey` in a message, maybe: ```python exceptions.FieldError( "'%s.%s' refers to field '%s' which is not local to model " "'%s'." % ( self.model._meta.label, self.name, to_field.name, self.remote_field.model._meta.concrete_model._meta.label, ) ) ```
This should be `self.remote_field.model._meta.concrete_model._meta.label` as [pointed by Simon](https://github.com/django/django/pull/12383#discussion_r372421836).
remove extra newline
remove extra newline
Please check code with flake8 as described in the patch review checklist and correct the "no newline at end of file" warning here.
I'd omit this blank line.
I thinking removing APP_DIRS from TEMPLATES (since it defaults to False) is a better suggestion than setting it to False.
@lothemar I realized that previous assertions were correct. The current tests work even without this patch. I will restore them, sorry.
I'm not sure why we pass `data` and build a query string in tests views :thinking: I would simplify this: ```python def test_follow_307_and_308_no_get_preserves_query_string(self): methods = ('post', 'head', 'options', 'put', 'patch', 'delete', 'trace') codes = (307, 308) for method, code in itertools.product(methods, codes): with self.subTest(method=method, code=code): req_method = getattr(self.client, method) response = req_method('/redirect_query_%s/' % code, follow=True) self.assertRedirects(response, '/post_view/?hello=world', status_code=code) ``` and in `views.py`: ```python def method_saving_307_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=307) def method_saving_308_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=308) ``` Maybe I'm missing sth.
It is not the status code that needs to preserve the request method. Perhaps the following reads better: `# Preserve request method post-redirect for 307 and 308 responses.`
assertEquals is deprecated. Please use assertEqual instead.
It's a small detail, but I think the variable naming could be improved here. `request_method` and `req_method` are very similar names (one is just a shortening of the other) but they mean very different things. I might rename `request_method` to `req_method_name` or something. Or you could probably just turn this into a single line and avoid a temporary variable.
:+1: We could really use some clearer naming there :)
`related_manager_name` not `related_model_name`
In general, I think the `get` / `set` style APIs are familiar enough that we don't need to use keyword arguments with every call. But I don't feel strongly about it.
Fine by me. I think we could probably omit the keywords in a lot of places and include them only where it's potentially confusing, but probably that's already what you're doing.
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
@InvalidInterrupt is right, this should map `params` using `quote_value` just like it's done on other backends.
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
We expect compileable to always have an `as_sql` method. e.g. see `effective_default`'s implementation. ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) return compiler.compile(node) ```
```python hanging = ( indentation, has, a, newline, after, opening, bracket, ) ```
I think it's a bit neater to invert the check for `node.as_sql` and return early: ```suggestion if not hasattr(node, 'as_sql'): return None, (node,) compiler = self.connection.ops.compiler('SQLCompiler')( query=None, connection=self.connection, using=None ) sql, params = compiler.compile(node) return sql, tuple(params) ```
We should use a custom storage for this test (instead of mocking).
Wouldn't it be easier to put this check in `StaticNode.handle_simple()`? Also, you seem to have occluded the `do_static()`, which was previously the actual `static` template tag…this means that you aren't handling the `{% static PATH as VAR %}` case any more, I think.
Not sure these asserts bring value ... they seem to test that `override_settings` works.
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
Maybe it could be worth to introduce a new type of DeprecationWarning ? Something like `WillBeDeprecatedInFuture`, that would be visible only to Django developers (did not check if it was possible with the `warnings` module though)...
Ahh, yes, sorry :facepalm: Good catch :dart:
Please use single quotes. You can use directly `out.getvalue()` instead of a temporary variable, e.g.: ```python self.assertNotIn('class InspectdbPeopleView(models.Model):', out.getvalue()) ```
You don't have to initialize `out` twice. This line can be removed.
We don't use `assert ` in tests. Please use `unittest` assertions: ```suggestion self.assertIs(self._extension_exists(), False) ```
There is not need to wrap `CursorWrapper.execute`, we should be able to use `CaptureQueriesContext()`, e.g. ```python def test_has_key_query_columns_quoted(self): with CaptureQueriesContext(connection) as captured_queries: cache.has_key('key') self.assertEqual(len(captured_queries), 1) sql = captured_queries[0]['sql'] # Column names are quoted. self.assertIn(connection.ops.quote_name('expires'), sql) self.assertIn(connection.ops.quote_name('cache_key'), sql) ``` There is also no need to check a table name because it contains spaces, so it's already tested.
No need to have empty lines, see the code above
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
why an empty string? might as well use assertRaises at that point.
I think this test isn't working as expected -- it's resolving to `RedirectView`, same with `test_inline_urls` -- probably the result of the resolve should be checked.
`.all()[0]` -> `.first()`
I think these are too internal, I would rather check that `MultiValueDict` is pickleable: ```python pickle.loads(pickle.dumps(...)) ```
This docstring is unnecessary.
We can keep them together ```suggestion with self.subTest(DEBUG=debug), self.settings(DEBUG=debug): ```
Why this error is raised? This should return an empty list without raising an exception.
I don't see much value in this docstring.
Is this a separate change? (I've left it for now but... 🤔)
In this case, I think a ternary is more complicated to read than: ``` if srid == -1: srid = None ```
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
Maybe `_parse_where()` -> `_get_condition_sql()`, I would return condition and add `WHERE` in `constraint_sql()`, e.g. ```python def _get_condition_sql(self, compiler, schema_editor, query): if self.condition is None: return None where = query.build_where(self.condition) sql, params = where.as_sql(compiler, schema_editor.connection) return sql % tuple(schema_editor.quote_value(p) for p in params) def constraint_sql(self, model, schema_editor): ... condition = self._get_condition_sql(compiler, schema_editor, query) return self.template % { ... 'where': ' WHERE (%s)' % condition if condition else '', } ```
`assertEquals` is deprecated and should be replaced by `assertEqual`. In a more personal-taste spirit, is it really useful to make 4 separate tests instead of consolidating them into one? The fact that the last 3 are identically named is an error, for sure.
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
Add an exception message similar to the other methods.
`self.each_context` actually already contains a fully populated app list, under `available_apps`. We could make this more efficient by extracting `app_list` from `available_apps` rather than calculating it twice. ``` context = self.each_context(request) app_list = context['available_apps'].get(app_label) if not app_list: raise Http404('The requested admin page does not exist.') context.update({'app_list': [app_List], ...}) ```
I don't understand why we have methods with a double underscores prefix which are copies from `SessionBase`, e.g. `__hash()`, `__legacy_encode()`, `__legacy_decode()` :thinking:
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
can return directly, no need for intermediate variable
format parameters as described above
I wonder if it would be better to include `.send()` in the new method and call it `send_mail()`. That gives some additional flexibility if the user doesn't want to actually send an email for some reason.
Both `response` vars are unused.
import should go at the top of the file unless it causes a circular import
No need for `Value` wrapping since 1e38f1191de21b6e96736f58df57dfb851a28c1f ```suggestion is_book=1, ``` Ditto for all `Values` uses below.
Ahh looks like you'll need to keep passing `Value` in this case but you can drop the `output_field`. ```suggestion is_book=Value(1) ```
What about ```suggestion self.assertNotIn('is_book', books.values().first()) ```
We can keep it in the same file.
I think we should move all new tests to a separate class, e.g. `AliasTests`.
We can remove `'book_join'` from `order_by()`.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
I think the `lambda` could go on this line.
basestring isn't Python 3 compatible. Please use `six.text_type` instead.
Looks good, my mistake.
don't need the trailing comma
You can remove the unnecessary assignment here: ```python return _format_modules_cache[lang] ```
We might as well lose the unnecessary string formatting while we're at it: ```suggestion old = repr(list(reversed(get_format_modules()))) new = repr(list(reversed(get_format_modules()))) # second try ```
Ah right. You noted on the ticket that's not the case with the 'spawn' mode, but I guess we shouldn't concern ourselves with that right now, as the test runner doesn't support that. @Valze - maybe make a note for your spawn-mode GSoC project? 😉
`file` supports file descriptors so we can use the same workaround like `pytest`: ```python try: faulthandler.enable(file=sys.stderr.fileno()) except (AttributeError, io.UnsupportedOperation): faulthandler.enable(file=sys.__stderr__.fileno()) ```
I think we should check if it's not already enabled: ```python if not faulthandler.is_enabled() and enable_faulthandler: ```
`no_faulthandler=False` -> `enable_faulthandler=True`
I would suggest changing the code so you're able to use the simpler `faulthandler=True` as the argument name. This will also simplify the code below that reads `if not no_faulthandler`. (You can still keep `--no-faulthandler` as the exposed option though.)
This is only used once. Can we move it back to the `color` module? (That way `termcolors` is still only ever used by `color`)
Usually we camel case assertions to match the unittest style. Maybe assertFieldsInModel (considering field_outputs is a list).
Can we move this function up by `get_traceback_highlighter`. (That way we keep the two related helper functions next to each other.)
`unittest._TextTestResult` is deprecated. You can use `unittest.TextTestResult` directly.
I thought about this. It's a much bigger change, just for a deprecation. Inserting a deprecation is one thing. Adjusting method calls is something else: `MiddlewareMixin.__init__()` calls `super()` so there's a potential logic change. Don't know where exactly, but I didn't want to risk a regression just to save the extra lines here implementing this deprecation.
And a another alternative in #11642
Here's what I came up with https://github.com/django/django/pull/11641.
No, they are not supported, because `BOOLEAN` datatype is available only in PL/SQL on Oracle, so `SELECT` clause cannot return it.
You should use `1` instead of `True`, sorry for misleading. If you will use `True` as a param than it will be automatically converted into `1`.
That's what I thought. Thanks for the clarification 👍 The patch is fine to me 🚀
I would use f-strings for these messages.
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
```suggestion sys.exit(1) ```
That's not true, `return` is to avoid setting new migrations.
I thought you wanted to remove `return`. Nevertheless I'd also leave the `else` as it increases readability.
If `lookup_params_all` is an instance of `dict` you can iterate over its keys directly: `for key in lookup_params_all`. You can also remove the extra spacing inside any: `any(field_path in lookup_param for lookup_param in lookup_params_all)`. You can detect whitespace issues by running `flake8` from the source.
I'd write this block a little differently: ```python if isinstance(list_filter, (tuple, list)): # This is a custom FieldListFilter class for a given field. field, field_list_filter_class = list_filter if isinstance(field_list_filter_class, str): title = field_list_filter_class field_list_filter_class = FieldListFilter.create else: ... ```
Please revert this unrelated change.
We use line lengths up to 119 characters when it helps readability. I wouldn't reformat this line when it doesn't have any other changes.
It would probably be better to check `cl.queryset.query.distinct`
I'd be inclined to reflow this so it fits on three lines: ``` 'AsGML', 'AsKML', 'AsSVG', 'BoundingCircle', 'ForceRHR', 'MakeValid', 'MemSize', 'Perimeter', 'PointOnSurface', 'Reverse', 'Scale', 'SnapToGrid', 'Transform', 'Translate', ```
Please order this in the same way as the import above.
Same as above (including the `prefix`)
Up to you, but I think the tests are short enough that the blank lines don't help much.
These should be sorted alphabetically, i.e., `'Chr', 'Concat' ...` and wrapped at 79 chars.
This block looks ordered alphabetically (although that may be a fluke when compared to the blocks below): ```suggestion geos_makevalid = GeomOutput('GEOSMakeValid', argtypes=[GEOM_PTR]) geos_normalize = IntFromGeom('GEOSNormalize') ```
Number prefix could be done separately as other files are affected. (And I think `init` (method name) is fine rather than `initialization`.)
I think this test is obsolete now.
Interesting. I just tried it. This returns 2. ``` def func(): try: return 1 finally: return 2 ```
Anyway, good practices include: - keeping the try clause as small as possible - avoiding multiple returns Hence the correct idiom is: ``` try: import autopep8 except ImportError: pass else: prepared_migration_statement = autopep8.fix_code(prepared_migration_statement, ...) return prepared_migration_statement ```
Do we need to do this? it is confusing (at least for me) to split and then join by `','`, maybe: ```python response.setdefault( 'Referrer-Policy', self.referrer_policy if isinstance(self.referrer_policy, str) else ','.join(self.referrer_policy), ) ```
Please wrap at 79 chars.
(Grrr. Always miss one... Done now.)
It should be possible to specify multiple values to allow for fallback where a value is not supported by a user agent: https://www.w3.org/TR/referrer-policy/#policy-token
Are you sure you want to skip if the header already exists? Another option is to append it (by setting the header twice -- don't know if Django/WSGI supports that -- or manually).
I'm favoring contractions lately, e.g. "Don't", "shouldn't".
`attrs['class'] += ' ' + self.form.required_css_class`
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
no restructured text (:class:) in docstrings please
Please try to stay near 80 char per line…
```suggestion form.render(), '<div><fieldset><legend>Field:</legend><div id="id_field">' '<div><label for="id_field_0"><input type="checkbox" ' 'name="field" value="J" id="id_field_0"> John</label></div>' '<div><label for="id_field_1"><input type="checkbox" ' 'name="field" value="P" id="id_field_1">Paul</label></div>' '<div><label for="id_field_2"><input type="checkbox" ' 'name="field" value="G" id="id_field_2"> George</label></div>' '<div><label for="id_field_3"><input type="checkbox" ' 'name="field" value="R" id="id_field_3">' "Ringo</label></div></div></fieldset></div>", ```
This is the same as the previous assertion. I'd think only 1 assertionis needed since all the `as_*` methods use `_html_output()`.
Chop blank line.
The expected value should be a second argument in `assertEqual()` and `assertHTMLEqual()` assertions.
```suggestion form = PartiallyRequiredForm({'f_0': '', 'f_1': ''}) ```
Do you checked if there is a way to use other models? It will be good to inherit one and add only needed field that reproduces your changes
`default=uuid.uuid4,` is generally the correct way to set the default for a uuid field. It will get called automatically whenever a new instance is created.
`uuid.uuid4` is a function, and, as understand, you want to set some random data for it, so you must call it. But I don't think that default is needed there though.
single line here should be fine
You don't need to specify `app_label`.
I think an explicit loop that mutates the dict might be clearer here, and avoid the overhead of a function creation and call. I believe we already do this elsewhere (but I haven't double checked).
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
I don't think we need the extra assignment here as this is only used once.
Ok. Thought it was worth asking the question. Better safe than sorry. :man_shrugging:
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
Might want to only run `replace` on `str` params or use `str(param).replace('-', '')`.
Should `params` be a tuple? i.e. ```python params = tuple(param.replace('-', '') for param in params) ``` Just want to make sure we avoid issues such as the one in #11784.
> Just so I'm clear then, sorry, would filter(foo__trigram_distance=("Test", 0.5)) be the same as filter(foo=TrigramDistance("Test", 0.5))? If so, then that's fine, I just thought they differed somehow. Until [#25367](https://code.djangoproject.com/ticket/25367) is fixed you have to rely on annotate. Should be along the lines of: ``` python annotate( foo_distance=TrigramDistance(F('foo'), 'Test') ).filter(foo_distance__lte=0.5)` ```
We definitely want to have a way of saying `.filter(TrigramDistance(F('foo'), 'test') > 0.7)` or something, but we haven't been able to come up with the right syntax yet so annotate is the compromise. I wasn't aware of the geo lookups, they were written a long time before expressions existed when that would have been the only way of implementing them. GeoDjango in general is in need of a lot of tidy up in a post-expressions world.
I'm not completely convinced we should have this as a lookup. The API feels very strange, and we have the `TrigramDistance` expression which feels more similar to other things. `trigram_similar` is fine.
I suggest: ``` self.assertEqual( csrf_cookie.value, self._csrf_id_cookie, '.....' ) ```
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
Use single quotes to stay consistent with the code above.
`getattr(request, 'csrf_processing_done')` would suffice since `None` is not true.
`getattr` raises an exception when the attribute doesn't exist and no default is given
I feel similarly. Maybe it's better just to add support for list and tuple as originally proposed. It's unclear to me if other types would actually be used.
I think this line isn't needed, tests seem to work fine without it.
`json_dumps_params` should be after `safe` (reordering keywords could be backwards incompatible if passing them by argument).
Don't use a mutable default: `{}`. Should default to `None` and then add : ``` if json_dumps_params is None: json_dumps_params={} ```
I think we can simplify this: ```python def json_script(value, element_id=None, json_encoder=None): from django.core.serializers.json import DjangoJSONEncoder json_str = json.dumps(value, cls=json_encoder or DjangoJSONEncoder).translate(_json_script_escapes) ```
Isn't this going to be really slow to create a `sync_to_asyc` instance and go through the sync-to-sync barrier for each item of the collection? Shouldn't we refactor iterables to separate their data-fetching (I/O) and data-massaging phases instead and only have `__aiter__` do `sync_to_async` for the fetching phase? By looking at `ModelIterable.__iter__` that seems doable.
chop extra space after period
```suggestion elif databases[DEFAULT_DB_ALIAS] == {}: ```
Is this possible? If so, it will be good to cover this scenario with tests.
`yield from` is not allowed in async functions.
```suggestion script_with_inline_function = ( 'import django\n' 'def f():\n' ' print(django.__version__)\n' 'f()' ) ```
You can drop that line since you are no initializing `self.indention` in `__init__()`.
no need for a class-level attribute here, push this down into the function
Is the complexity of testing with a logger needed? I think a print statement and passing `stdout=StringIO()` to `call_command()` in order to check the value would be sufficient.
Usually we're using single quotes for strings unless the string contains single quotes.
I'm not sure whether it should be considered part of a separate clean up across all cases of this in the code base or whether we can handle this here for all of the adjacent lines, but it would be nice to fix the indentation: ```python self.management_form_html + ( '<tr><th>Choice:</th><td><input type="text" name="choices-0-choice" value="Calexico"></td></tr>' '<tr><th>Votes:</th><td><input type="number" name="choices-0-votes" value="100"></td></tr>' ) ```
Please chop unnecessary blank lines.
Tests for `formset_factory()` and `formset_factory()` are missing.
IMO a single test with custom `too_many_forms` and `too_few_forms` is enough.
I'm unsure the purpose of `ugettext_lazy` here.
Hmmm. `start` was unused anyway...
No need to cast the set into a list. You can iterate over sets.
I like to include a trailing comma in cases like this, so if more items are added, we don't need to modify that line again. Will make this change and commit.
similar to the hanging indent for messages, for string interpolation I like: ``` return "Graph: %s nodes, %s edges" % ( len(self.nodes), sum(len(x) for x in self.dependencies.values())), ) ```
use parentheses to avoid backslashes and I would also try to keep the comprehension on a single line as breaking it up like this makes readability more difficult IMO.
`has_key` is deprecated, use `if 'origin' in ds_input:` instead. Also please replace other occurrences in the patch.
`band_input`, you don't get much by saving one char :-)
I think `enumerate` would work here
prefer hanging indent style with 1 arg per line
I prefer putting the closing ) on the next line
I would chop `simply`.
```suggestion 'Django now detects this configuration automatically. ' 'You can simply remove default_app_config.' ```
Wrap at 79 chars.
Chop trailing space.
This is here for appending to the follow-ups later. One or other is always appended so...
Use a similar logging to what we do for robust signals? See `django.dispatch.dispatcher.Signal.send_robust` and ``` try: response = receiver(signal=self, sender=sender, **named) except Exception as err: logger.error( "Error calling %s in Signal.send_robust() (%s)", receiver.__qualname__, err, exc_info=err, ) ``` Something like ```suggestion logger.error("Error calling {func.__qualname__} on_commit() ({e}).", exc_info=True) ```
When calling `on_commit` there are basically two modes: - there is no transaction in progress, so we execute the function right away - we are in an atomic block, so we register the function to execute it later (`self.run_on_commit.append(`) The first case is handled by the PR, but not the second one. And I'd think that we would need to handle a robust execution in the second case too. Does that make it clearer? :)
I'd revert the logic i.e. check `execute` first: ```suggestion if execute: if is_robust: try: callback() except Exception as e: logger.error( f"Error calling {callback.__qualname__} on_commit() " f"during transaction (%s).", e, exc_info=True, ) else: callback() ```
`func` is called even if no transaction is in progress, so we should move this to the first line. Fixed.
This will become a performance issue for the database before it becomes one for the Python process :-)
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
That came from my suggestion. Originally it was `DB creation, DB cloning, DB teardown and total test run time` and, aside from `DB` → `database`, it seemed unnecessary to repeat `database` multiple times. Semicolons can be used in complex lists where there are commas used within the list items themselves. I perceived there to be two list items here: - database creation, cloning, and teardown - total test run time Your suggested wording now no longer makes it clear that "cloning" and "teardown" are database-related.
I'm not sure why we have here a semicolon :thinking:, please use also hanging indentation: ```suggestion help=( 'Output timings such as database creation, cloning, teardown, ' ' total test run time.', ), ```
This should match the updated version in `runtests.py`.
if no app*
Great, I just change this line to check the message in calls rather than simply its length.
use `with self.assertRaisesMessage(PermissionDenied, 'Forbidden user agent'):`
No `self` parameter, just the exception class.
You might also test the user agent string in `mail.outbox[0].body`.
The `u` prefix is not necessary (as unicode_literals is imported at the top of the file). `self.assertIn` can be used here.
Same here? ```suggestion __T = r'(?P<hour>[01][0-9]|2[0-3]):(?P<min>[0-5][0-9]):(?P<sec>[0-5][0-9])' ``` Maybe this is a bad idea because of leap seconds 🤷🏻‍♂️
I don't think we should go so deep into validation, we opt out from numbers but at the same time we allow the whole unicode range. Unicode numbers like `๑` would happily validate therefore it's an uphill battle. I'd opt for a vastly simplified regex to validate FQDN: `'(?:[a-z0-9\u00a1-\uffff-]+\.?)+'`. Sure it'll let some invalid segments go through (e.g. leading/trailing hyphens) but at least it doesn't pretend of being exhaustive. Proper validation requires a parser anyway.
Forgot to mention earlier, but on first look I found `[a-z-' + ul` a little confusing because of the dash between two ranges that actually serves as a dash and not a range separator. I think it would be more readable as `[a-z' + ul + r'-]` (similar to how it is in `domain_re` above).
My point wasn't the r prefix (I just copied that from above), it was moving the dash next to the close-bracket. But now that you mentioned it -- yes, the first and last (`'\.'` and `'\.?'`) need an r prefix, because without it the strings don't have a backslash in them and these expressions will just match anything. I think a test for this could use some invalid punctuation as the separator for the tld -- e.g. `http://unquoted~dot!`
This allows `xn----nx` and even `xn-----`. Are they valid? (edit: FWIW, my IceWeasel seems to think they are)
`Bar.bar` isn't a field. The message should be `Field is using a table that has already been registered by 'invalid_models_tests.Bar'` as the `db_table` is declared on a non-`auto_created` model (`_meta.auto_created is False`).
This assertion will fail on Python 2 as the `repr`esentation of locally defined classes is not the same.
You could get away with something a bit more compact than that I think -- you don't need to wrap the text in parentheses, and you probably shouldn't split up the class name just to adhere to PEP8, line length isn't a big worry. Same goes for the other instance. ``` python expected = [ Error( "Field is using a table that has already been " "registered by <class 'invalid_models_tests.test_models.Bar'>.", hint=None, obj=Foo._meta.get_field('bar'), id='fields.E340' ) ] ```
As the `db_table` is attached to an `auto_created` model the message should be `Field is using a table that has already been registered by 'invalid_models_tests.Baz.foos'.`. The intermediary model `Baz_foos` is an implementation detail and shouldn't be referred to, plus it has no `foos` field.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
Wouldn't it be a bit more helpful for this error message to specifically note that the module with the given path couldn't be imported? "Invalid" is a very vague term, which could mean all sorts of things - it seems unhelpful to silence an `ImportError` and replace it with a much vaguer message.
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
please check code with flake8 (`E231 missing whitespace after ','`)
don't add this blank line.
My question would be: do you need to define a set of allowed characters? Does not just base64 encoding (with the URL-safe character set) the output of secure random not achieve the same goal? On Mon, Aug 4, 2014 at 9:52 AM, Curtis Maloney notifications@github.com wrote: > In django/middleware/csrf.py: > > > @@ -25,6 +25,7 @@ > > REASON_BAD_TOKEN = "CSRF token missing or incorrect." > > > > CSRF_KEY_LENGTH = 32 > > +VALID_CHARS = 'abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789' > > This same set of chars is defined in django.utils.crypto as the default > for "allowed_chars" for the get_random_string function. > > Should we consider making this a more accessible constant? > > — > Reply to this email directly or view it on GitHub > https://github.com/django/django/pull/1477/files#r15738414.
`string.letters + string.digits`
Hehe :D Thanks, I'll approve now and merge later today after a final testrun
Chop " we"
I personally generate the NONCE's on the client side using javascript (so I don't need the token in the response body). It would be nice to continue long term to accept the raw cookie value as a valid csrf token.
Another vote for moving this logic into apps as a private method.
Thanks for the link, would be nice to have a ticket for it, probably.
Yes, this should be taken care of before.
a nice line to see gone
I don't think we need an explicit `if` here. `_pending_lookups` is `{}` by default and thus the for-loop body isn't run anyways.
IMO, this is not related with `index_xinfo` but with naive parsing in introspection on SQLite. I added `_get_index_columns_orders` to fix this issue.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
`self.assertTrue` -> `self.assertIn` above and below as well.
Given that the index is named `title_lower_id` this `LOWER` check could check against that as well as `lower(xxx)` -- please rename the index so there is only one match for `LOWER` (same for `TITLE`)
I don't know much about the tablespace feature, but I'd expect to see an assertion that interacts with it somehow.
Please check test coverage carefully. I didn't spot a test for this change.
Have you tried subclassing `Expression` instead of redefining all of these methods? Looks like a lot the `Lookup` boilerplate could go away with ```python class Lookup(Expression): ... def __init__(self, lhs, rhs): self.lhs, self.rhs = lhs, rhs super().__init__(lhs, rhs) ... @cached_property def output_field(self): return BooleanField() ... ```
no blank line
```python hanging = ( indentation, has, a, newline, after, opening, bracket, ) ```
I think you can use `django.utils.deconstruct` to decorate the class, the `path` argument can be passed explicitly. Since Django 2.0+ is Python 3 only, you can use keyword-only arguments with `*, arg1=None, arg2=None`.
Please revert this, it's not worth changing existing code.
Should we remove the object from a cache? :thinking:
As far as I'm aware it's unneeded, because a reverse relation `GenericRelation` returns multiple objects, so a single `tag` is not assigned to an `object`.
```suggestion "%s() prohibited to prevent data loss due to unsaved " "related object '%s'." % (operation_name, field.name) ```
This is a separate issue and we should move it to a separate commit (together with `test_save_generic_foreign_key_after_parent`) e.g. > _"Refs #28147 -- Fixed loss of assigned parent when saving GenericForeignKey after parent."_ Maybe even a separate PR to make it easier for review.
Use single quotes (unless a string contains a single quote) as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Docstrings should state the expected behavior. It doesn't need to describe an old, incorrect behavior.
`self.oc` doesn't appear to be used
chop newline for consistency
For test doc strings, rather than "Test X" I try to describe the desired behavior: `A ValueError is raised when the incorrect object type is passed to a query lookup."
To my mind the real issue here is that we shouldn't be using `update_wrapper` at all (here or above in line 76). `view` is not in any way wrapped by `cls.dispatch` or `cls`. We just happen to want to achieve something similar to what we would want to achieve if we were wrapping a function. By using `update_wrapper` we're setting the `__wrapped__` attribute, so when we call `inspect.signature` it thinks that this function is the decorator, and that the function we're actually interested in is `cls.dispatch`. That's the reason why it returns the signature from `dispatch`. We should just do the thing we want to do directly. Something along the lines of: ``` for attr in functools.WRAPPER_ASSIGNMENTS: # I'm not sure which of these we actually want try: value = getattr(cls, attr) except AttributeError: pass else: setattr(view, attr, value) view.__dict__.update(cls.dispatch.__dict__) ```
I looked into why the tests are failing. It's because some internals of the URL resolver and admindocs rely on the `__name__` set here. But they could also, more accurately, use the `view_class` atttribute. Therefore I've made PR #14138 to change that. If we go that route then I think we shouldn't even set `__name__` / `__qualname__`. Leaving them as their defaults is sensible and doesn't lie (`__name__ = 'view'` , `__qualname__ = '...View.as_view.<locals>.view'`). One can differentiate class-based views with the `view_class` attribute.
Excellent. Happy with that. So, as I have above, without any `__qualname__`-mangling, should do the trick.
@pope1ni Sorry it took a while to get back to you - it's been a hectic 24 hours. But yes, the above seems good to me.
```suggestion # the dispatch method. Note that __name__ and __qualname__ are # intentionally left unchanged, as view_class should be used to robustly ``` A slight change of word order here makes this read more naturally.
would be fine to use double quotes so you don't have to escape the single
```suggestion content = app_path.joinpath("apps.py").read_text(encoding="utf8") ```
Ditto ```suggestion return all( not os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
```suggestion content = app_path.joinpath("apps.py").read_text() ```
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
I would add: ``` self.assertIn('<div id="traceback">', htmls[0]) ```
Ticket number and a note about antivirus are not necessary, maybe: ``` """HTML email doesn't contain forms.""" ```
Same style as above.
can return directly, no need for intermediate variable
format parameters as described above
Chop blank line.
```suggestion elif ( on_conflict == OnConflict.Update and not self.connection.features.supports_update_conflicts_with_target ): ```
You can do what I suggested above here as well.
You should use `supports_update_conflicts_with_unique_fields`.
Using `self.connection.features`: ```suggestion elif ( on_conflict == OnConflict.Update and self.connection.features.supports_update_conflicts_with_target ): ```
you don't need `nulls_last=True` here because it's a PK you're ordering by, which is non-nullable
Check existing tests for the style to use for `assertRaisesMessage`.
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
Hanging indent looks like this: ``` msg = ( "Filtered relation 'alice_favourite_books' cannot operate on " "foreign key 'author__favourite_books__author'." ) ``` In general, indentation should always be a multiple of four.
no blank lines needed
This could go in an else block of try/except to keep the try block minimal.
Maybe `By default, return the django.contrib.admin.utils.get_deleted_objects.` instead of `By default this just returns django.contrib.admin.utils.get_deleted_objects.`.
This should probably be: ``` try: duplicate_path = os.path.join(test_dir, 'file.txt') .... finally: if os.path.exists(duplicate_path): ``` so if something fails, we still cleanup. Alternatively, could refactor to use setUp/tearDown methods.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
" allowed to be deleted permissions" seems like a typo.
The other benefit of reversing the sense of this flag is that it makes the "normal" case be `False` and the unusual case `True`, which I think is generally preferable for boolean flags.
I see thanks, I missed it because of the `is_cached` removal.
Would be fine I guess. I'm not too sure about the safety margin aspect in the first place, but it's SQLite so whatever works, I guess.
I'm not sure I'm a big fan of this error message. "Shadowing" has a specific meaning that may not be clear to everyone. Perhaps something along the lines of "You cannot use the name ... as the to_attr argument, as the model already has a field with this name"
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
This is a separate issue, can we move it to a separate PR/commit? Also, test is required.
`file` -> `temp_file`
+1 to a public method on the handler
`# Sendfile is used only when file_wrapper has been used.`
Trailing dot is missing.
How about changing `second` to args/kwargs like `cols, primary_key=False, 'unique=False, ...` and then the assertion becomes `assertDetails(constraint, ['up_votes'], check=True)`. No need to repeat all the other values.
I beleive `skipUnlessDBFeature` is appropriate here.
This test should use `@skipUnless(connection.vendor == 'sqlite', "This is an sqlite-specific issue")` because it is specifically testing a regex in the sqlite backend's introspection.
@manfre knows better than me here :)
Hi, this name should be assert_foreign_key_exists
I think the values provided need to be validated. It would also be nice to accept and parse a string containing both bounds... But that gets me thinking that this current approach is rather verbose...
Most of these operators overlap with range lookups, I think we should use the same names for consistency, i.e. - `LESS_THAN` -> `LT`, - `GREATER_THAN` -> `GT`, - `LESS_THAN_EQUAL` -> `LTE`, - `GREATER_THAN_EQUAL` -> `GTE`, - `IS_CONTAINED_BY` -> `CONTAINED_BY`, - `NOT_EXTEND_LEFT_OF` -> `NOT_LT`, - `NOT_EXTEND_RIGHT_OF` -> `NOT_GT`, - `STRICTLY_NOT_EXTEND_LEFT` -> `FULLY_LT`, - `STRICTLY_NOT_EXTEND_RIGHT` -> `FULLY_GT`, - `IS_ADJACENT_TO` -> `ADJACENT_TO`. Maybe we can also reuse this operators in lookups :thinking: , e.g. ```python @RangeField.register_lookup class FullGreaterThan(lookups.PostgresSimpleLookup): lookup_name = 'fully_gt' operator = RangeOperators.FULLY_GT ```
`COT` doesn't exist on Oracle, please emulate it by `1 / TAN(%s)`.
I think `Sqrt` needs `output_field = fields.FloatField()`.
@JunyiJ My previous suggestion was to use the `TAN` database function on Oracle, i.e. ```python def as_oracle(self, compiler, connection): return super().as_sql(compiler, connection, template='1 / TAN(%(expressions)s)') ```
It looks to me like this test should verify the SQL rather than verifying that there isn't any deferred SQL.
Could be simplified to `self.assertFalse(editor.deferred_sql)`.
SimpleTestCase should be fine. I would use a separate test file so it can be deleted when the deprecation ends.
I think a list comprehension would be more readable.
longer lines here are okay, we try to avoid non-multiple of 4 indents
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
Use single quotes
I don't think it's important to mention PostgreSQL version details in the docstring.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Can you please run `pages_per_range` through `quote_value()` (internal function on the schema editor).
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
Some checks require database access e.g. mysql.W002 ( https://docs.djangoproject.com/en/3.0/ref/checks/#database ) , django-mysql's checks ( https://django-mysql.readthedocs.io/en/latest/checks.html ). Those I've linked to don't strictly need access to an existing schema but I think changing this could be considered a breaking change.
> We could rewrite it so cloning happens after system checks are run If that's easy enough I think it's a good idea. It means that check errors will be displayed and stop the test process sooner, speeding up feedback.
There is no need to create a random suffix. We should also test all described scenarios, e.g. ```suggestion test_connection = copy.copy(connections[DEFAULT_DB_ALIAS]) test_connection.settings_dict = copy.deepcopy( connections[DEFAULT_DB_ALIAS].settings_dict, ) tests = [ ('test.sqlite3', 'test_1.sqlite3'), ('test', 'test_1'), ] for test_db_name, expected_clone_name in tests: with self.subTest(test_db_name=test_db_name): test_connection.settings_dict['NAME'] = test_db_name test_connection.settings_dict['TEST']['NAME'] = test_db_name creation_class = test_connection.creation_class(test_connection) clone_settings_dict = creation_class.get_test_db_clone_settings('1') self.assertEqual(clone_settings_dict['NAME'], expected_clone_name) ```
I think we should `warnings.warn('...', category=RemovedInDjango40Warning)` here.
If we do it the other way around by using an identity transformer `if isinstance(values[0], qs.model)` we would work around the `QuerySet.values_list('charfield', flat=True)` use case.
These two could be `and`ed.
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
`self.assertSequenceEqual(qs.values_list('field', flat=True), [(['hello', 'goodbye'])])`
This unfortunately won't work if the subquery refers to any outer references as these must be included in the group by clause.
```suggestion return super().get_group_by_cols() ```
We should test with a different expression since this might be fixed in the future ```suggestion expr = ExpressionWrapper(Lower('field'), output_field=IntegerField()) self.assertEqual(expr.get_group_by_cols(alias=None), [expr.expression]) ```
not sure we really need backwards compatibility here
I wonder if this could be addressed by adding a `MultiColSource` method that returns `self`
While moving this, chop "we".
Remove `self.function = ..` and move it to a kwarg of the `as_sql` call below: ``` return super(Length, self).as_sql(compiler, connection, function='CHAR_LENGTH') ```
This and one above, replace `self.function = ..` with `function=...` in as_sql method call.
"Postgres'" looks odd to me. Use "PostgreSQL's" instead.
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
Wrap at 79 chars.
You can use `Path.is_absolute()`.
```suggestion id='caches.W003', ```
Chop all blank lines in `check_file_based_cache_is_absolute()`.
but OK let's have it.
As far as I see, this change is unrelated to this PR, so please remove it.
Avoid calling `self.get_source_expressions()` twice and it becomes clearer: ```python ... expression1 = self.get_source_expressions()[0] if isinstance(expression1, Value) and expression1.value is None: raise ValueError('Oracle does not allow Value(None) for expression1.') ... ``` I've also tweaked the exception message to make it based on the argument provided in Python.
This and one above, replace `self.function = ..` with `function=...` in as_sql method call.
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
put the closing parenthesis on the next line
yeah, as long as we don't create a function on every single call.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
This is a bit unclear to me. When you say "for select itself" do you mean the `Select` widget class? Does "its children" mean subclasses? `NullBooleanSelect` seems to be at least one subclass that doesn't pass these checks.
In the case of an empty select (`choices = []`), this will still output the `required` attribute, which is still not valid: ``` >>> class TestForm(Form): ... some_field = forms.ChoiceField(choices=[]) ... >>> t = TestForm() >>> print(t['some_field']) <select id="id_some_field" name="some_field" required> </select> ``` ``` html <!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <title>Validation test</title> </head> <body> <select id="id_some_field" name="some_field" required> </select> </body> </html> ``` Check it here: https://validator.w3.org/nu/#textarea
No need for an `else` branch as the `if` returns.
Error is raised only on PostreSQL. On Oracle and MySQL we simply return the same date. Even if we want to raise an exception on SQLite, `NotImplementedError` is probably not the best choice. It's not sth that will or may be implemented in the feature. I'd use `ValueError` as we do in similar cases.
I'm not sure about raising these exceptions (here, in `_sqlite_datetime_trunc()` and in`_sqlite_datetime_trunc()`), user will get rather unhelpful `OperationalError`: ``` django.db.utils.OperationalError: user-defined function raised exception ``` and we don't do this on other backends.
Sure, perhaps `ValueError` is better. I think PostgreSQL does the nice thing here - silently returning the value unchanged is ugly. Given this is our own implementation, having a third way - returning `NULL` - isn't great. We should align to one of the other two behaviours, and raising an error seems best.
We can remove the `elif`s and `else here: ```suggestion if lookup_type == 'week_day': return (dt.isoweekday() % 7) + 1 if lookup_type == 'iso_week_day': return dt.isoweekday() if lookup_type == 'week': return dt.isocalendar()[1] if lookup_type == 'quarter': return ceil(dt.month / 3) if lookup_type == 'iso_year': return dt.isocalendar()[0] return getattr(dt, lookup_type) ``` We'll have to wait until we're Python 3.9+ only to use `.week` and `.year` on the result of `dt.isocalendar()`.
Ah, sorry. Misread these. One gets the quarter number, the other gets the first month of the quarter. Ignore me.
This can be a single line.
I think a few basic types are enough to test. This isn't testing anything particular in Django as far as I can tell.
assertEquals is deprecated. Please use assertEqual instead.
I wouldn't include this test in the PR because it's testing existing behavior. But it doesn't seem needed as there's a test in `test_client_regress` that fails if the `isinstance(data, dict)` check is `_encode_json` is removed.
I'm not sure why we pass `data` and build a query string in tests views :thinking: I would simplify this: ```python def test_follow_307_and_308_no_get_preserves_query_string(self): methods = ('post', 'head', 'options', 'put', 'patch', 'delete', 'trace') codes = (307, 308) for method, code in itertools.product(methods, codes): with self.subTest(method=method, code=code): req_method = getattr(self.client, method) response = req_method('/redirect_query_%s/' % code, follow=True) self.assertRedirects(response, '/post_view/?hello=world', status_code=code) ``` and in `views.py`: ```python def method_saving_307_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=307) def method_saving_308_query_view(request): return HttpResponseRedirect('/post_view/?hello=world', status=308) ``` Maybe I'm missing sth.
This behavior doesn't exist in the current implementation of `HttpResponse`.
Am not sure all this is necessary as the same object is referenced... Just add the one line to call the method that wraps `close()`.
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
> this test is checking the support for a possible object that is seekable but has no `.tell()`. > `tempfile.NamedTemporaryFile()` has `.tell()`. Just as an aside, whether there is any change here or not, but you could do: ```python with tempfile.NamedTemporaryFile() as tmp: del tmp.tell # Emulate seekable file handle without .tell(). ... ```
seems like we could use `super()` instead.
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
should this be used? (with a test too) arguments -> options
I feel like this boiler-plate could be handled more nicely. For example, what about defining a function above that looks something like-- ```python def add_argument(parser, name, *args, help=None, **kwargs): if name in self.suppressed_base_arguments: help = argparse.SUPPRESS parser.add_argument(*args, help=help, **kwargs) ``` Then each `parser.add_argument(...)` would become `add_argument(parser, name, ...)`. I also think it would be better if the convention were for the string in `suppressed_base_arguments` to match the first option string passed to `parser.add_argument()` (e.g. `--force-color` instead of `force-color`). I think it would be easier to remember. Also, if that were done, the name wouldn't have to be passed a second time, or manipulated in any way inside the helper function above before checking for membership in `self.suppressed_base_arguments`.
In the usual case for using this, it wouldn't be because "an initial migration has been applied before,", it'd be because the database pre-existed any (Django) migrations at all. Also, it's really the contents of your initial migration file that you need to compare to, not your model definitions. Suggested wording: "Detect if tables already exist and fake-apply initial migrations if so. Make sure that the current database schema matches your initial migration before using this flag!" As a bonus, this also hints at the fact that the automated check here is no more sophisticated than just checking if tables exist.
the wording used for similar options is simply "Can be used multiple times."
Do we need to swap arguments? IMO we want to keep the same order as in `SIMILARITY()` calls. ```suggestion class TrigramWordSimilarity(TrigramBase): function = 'WORD_SIMILARITY' ``` e.g. - `TrigramWordSimilarity('Cat sat on mat.', 'cat')` should be equal to `0.30769232` instead of `1` - `TrigramWordDistance('Cat sat on mat.', 'cat')` should be equal to `0.6923077` instead of `0`
> .. i'll follow your decision :) Just asking, I'm not an expert :shrug:. We can wait for the second opinion from Paolo.
> Paolo, Can you take a look? (\cc @pauloxnet) point_up Sorry, I totally missed the notification of this. I'll take a look
@felixxm yes that's what I'm thinking.
Paolo, Can you take a look? (\cc @pauloxnet) :point_up:
The `__init__()` method? There are ~15 lines below `super()` that seem to be used.
If you set the class attribute `arity = 1` you can remove the `__init__` altogether. Actually, if you do that, then you can drop this base class and just set `arity` on the subclasses.
Dots are missing i.e.: `..., e.g. Count('id').` On the other hand I think we can remove an example.
Use single quotes.
`arity = 1`
My code sucks. Feel free to change in other places.
Considering this change isn't targeted specifically at CharField and should work for a variety of fields, it might be good to have some number/integer based tests as well.
Using interpolation here would make it more readable IMO. e.g. `"%s::%s" % (sql, self.lhs.output_field.db_type(connection))`
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
Similarly, I don't see much advantage to creating indirection with a method.
I'm not sure is this really helpful and needed :thinking: because it'll catch only checks with the same order of conditions, so only copy&paste issues. For example, it will not raise a warning for: ```python models.CheckConstraint(check=models.Q(models.Q(id__gt=0) | models.Q(id=0)) models.CheckConstraint(check=models.Q(models.Q(id=0) | models.Q(id__gt=0)) ``` (that's of course only a simple example). In the same time I would not like to add any complicated logic here.
Check constraints can add significant overhead to insert/update queries. Adding duplicates (whether identical or in a different form) compounds that and is probably worth highlighting. I wouldn't have thought that dealing with ordering and logical equivalence was a deal breaker. Yes, it requires some thought, but a well-defined `simplify_q()` function that can normalize a `Q()` object would make sense. I also don't see this being limited to check constraints - partial indexes can also make use of `Q()` objects for the `condition`. Duplicate indexes also have an impact on insert/update as well as wasting valuable disk space.
Honestly, I'm not in favor of another system check, but I'll try to confirm this with Carlton tomorrow (who accepted this ticket).
> Is that something that might appear some time soon, or is it just a thought? 🙂 At the moment just a thought… 🙂
I would use the same mechanism as for the `E020` and models' labels instead of `__name__`'s, i.e. ```python indexes = defaultdict(list) constraints = defaultdict(list) ... for model_index in model._meta.indexes: indexes[model_index.name].append(model._meta.label) for model_constraint in model._meta.constraints: constraints[model_constraint.name].append(model._meta.label) ```
Remove the blank line.
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
We can reuse an existing migration: ```suggestion MIGRATION_MODULES={"migrations": "migrations.test_migrations_manual_porting"} ```
usual style is to put the ticket number in parenthesis at the end of the sentence
You can safely join this an the next line. You have up to 119 chars per line. ;)
single line here is okay (lines up to 119 chars are fine when it improves readability)
I guess you probably want `from django.test.utils import requires_tz_support` instead.
There should never be a reason to encode ascii to something else. While technically valid it makes mails bigger (especially if at one point we decide to call sanitize address for all addresses)
Use single quotes consistently.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
; -> ,
I typically use this style to avoid such long strings near the length limit: ``` raise NotSupportedError( '...' '...' ) ``` (could also be applied in the other file)
It's not used only for combined queries so we should call it only in `not combinator` branch.
`s/allowed/supported/` -- and coming to think of it, use `django.db.NotSupportedError`.
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
"Make sure" is a phrase to avoid
I think this change really indicates the need for a second test for wrapping a non-string object.
`parent_data` and `child_data` are `CharField`\`s, so maybe `'a'`, `'b'`, ... etc.
`assertNotIn` may pass from many reasons. I think it is better to check field value with `self._get_field_values()` hook, e.g. ```python self.assertEqual(self._get_field_values(child_data, 'parent_m2m'), []) ```
Blank lines aren't needed.
We should use `pathlib.Path.cwd()` instead, also there is no need to define a constant.
Maybe: ```suggestion setting = getattr(settings, 'FILE_UPLOAD_TEMP_DIR', None) if setting and not Path(setting).is_dir(): return [Error( f"The FILE_UPLOAD_TEMP_DIR setting refers to the nonexistent " f"directory '{setting}'.", id='files.E001', )] ```
`assertEquals` is deprecated and should be replaced by `assertEqual`. In a more personal-taste spirit, is it really useful to make 4 separate tests instead of consolidating them into one? The fact that the last 3 are identically named is an error, for sure.
You can combine these tests.
```suggestion self.assertIs(self.temp_dir.joinpath(f_name).exists(), True) ```
add trailing comma
Use single quotes for consistency.
You could avoid the delete query with: `AggregateTestModel.objects.none().aggregate(...)`. (I guess the other tests could use the same pattern, not for this PR though.)
Perhaps some refactoring using `subTest` as done in https://github.com/django/django/pull/7822 would be better.
I don't think `list()` is needed. `self.assertEqual(sorted(values['arrayagg'], ['Bar', 'Foo', 'Foo'])` looks good to me.
Do we need to be so restrictive? There are many language tags in the [IANA](http://www.iana.org/assignments/language-subtag-registry/language-subtag-registry) registry that don't match this regex, e.g. `i-mingo`, `de-CH-1996`, `de-1996`, or `kl-tunumiit`.
Indeed, we do not need to be so specific. The downside I see when being permissive is a bit more computation by going more often in `get_supported_language_variant` and possible `get_supported_language_variant` lru cache exhaustion. But I don't see a nice alternative.
Forgot to mention earlier, but on first look I found `[a-z-' + ul` a little confusing because of the dash between two ranges that actually serves as a dash and not a range separator. I think it would be more readable as `[a-z' + ul + r'-]` (similar to how it is in `domain_re` above).
This allows `xn----nx` and even `xn-----`. Are they valid? (edit: FWIW, my IceWeasel seems to think they are)
My point wasn't the r prefix (I just copied that from above), it was moving the dash next to the close-bracket. But now that you mentioned it -- yes, the first and last (`'\.'` and `'\.?'`) need an r prefix, because without it the strings don't have a backslash in them and these expressions will just match anything. I think a test for this could use some invalid punctuation as the separator for the tld -- e.g. `http://unquoted~dot!`
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
could you limit line length to 120 characters so horizontal scrolling isn't required in GitHub? missing whitespace for: `{% autoescape on%}`
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
Wrap docstrings at 79 characters. Try to avoid "we... " (often this results in simpler language).
This isn't related to your changes, but I'm intrigued by Django's behavior here. I would expect `|escape` to give `&amp;` and `|escape|force_escape` to give `&amp;amp;`. Not that this construct makes much sense anyway...
This seems wrong because it would only mask an issue with STATIC_ROOT not existing.
The slashes are stripped off by `pathlib`: ```suggestion STATIC_ROOT=self.test_dir / "static", MEDIA_ROOT=self.test_dir / "media_root", ```
```suggestion cached_files = Path(settings.STATIC_ROOT).joinpath("cached").iterdir() ```
The slashes are stripped off by `pathlib`: ```suggestion STATIC_ROOT=self.test_dir / "static", MEDIA_ROOT=self.test_dir / "media_root", ```
Jenkins doesn't do anything specific, and yes this test passes locally for me without a fix.
Can we display a similar message with the test results? It can be helpful when you have plenty of errors, .e.g. ``` ... FAILED (errors=206, skipped=1094, expected failures=4) Used shuffle seed: 556738431 (generated) ```
I don't see any need for this attribute.
Nit: I would call this "saved" or "original" patterns, because technically it might not be the default.
I would also consider turning that into an instance method called something like `get_runner()` and starting each test method with `runner = self.get_runner()`. The reason is that instantiating a runner is "cheap." You also don't have to think / worry about whether the runner has state that you might unwittingly be carrying from one test to the other (e.g. attributes set when a method is executed).
```suggestion # RemovedInDjango50Warning class NoOpTestRunner(DiscoverRunner): def setup_test_environment(self, **kwargs): return def setup_databases(self, **kwargs): return def run_checks(self, databases): return def teardown_databases(self, old_config, **kwargs): return def teardown_test_environment(self, **kwargs): return class DiscoverRunnerExtraTestsDeprecationTests(SimpleTestCase): msg = 'The extra_tests argument is deprecated.' def setUp(self): self.runner = NoOpTestRunner(verbosity=0, interactive=False) def test_extra_tests_build_suite(self): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.build_suite(extra_tests=[]) def test_extra_tests_run_tests(self): with captured_stderr(): with self.assertWarnsMessage(RemovedInDjango50Warning, self.msg): self.runner.run_tests( test_labels=['test_runner_apps.sample.tests_sample.EmptyTestCase'], extra_tests=[], ) ```
If there's GEOS 3.1 (as on Ubuntu 10.04), however you'll need to raise a `NotImplementedError`.
It looks like this pattern would benefit to be applied as a method decorator, as that would limit code duplication.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
`self.fields[self._meta.model.USERNAME_FIELD]`? I think it's a mandatory field.
Please use single quotes everywhere in this method.
`return self.get_database_version() >= self.features.minimum_database_version`
I think it's preferred to wrap this at 79 chars: ``` f'{self.display_name} {min_db_version} or later is required ' f'(found {db_version}).' ```
Also, if you are using a context manager, it seems like you want to assert calling `is_usable()` right before you close (so after the context manager closes).
This is always truthy: ```suggestion mocked_check_database_version_supported.assert_called_once() ```
This can be dropped since `connection` is already imported in the context of the module. ```suggestion ```
This won't work in many cases on Oracle :disappointed:
```suggestion query.add_annotation(Value(1), "_check") ```
If `Q(IsNull(self, True))` doesn't work then surely `Exact(Case(When(Q(IsNull(self, True)), 1)), 1)` will.
@shangxiao thanks for the investigation on Oracle. Another alternative worth considering is doing something along the lines of (assuming we added the `supports_coalesce_condition` feature flag) ```suggestion if connections[using].features.supports_coalesce_condition: check = Q(Coalesce(self, True, output_field=BooleanField())) else: check = self | Q(IsNull(self, True)) query.add_q(check) ``` I don't have Oracle setup to figure out if this works but it seemed like it should from reading a few resources online.
No sure about which parts should remain in `Q.checks` instead. Current separation seems relatively good but I'd be curious about input from others.
Remove the unused import.
This test passes when testing against an SQLite or MySQL backend as long as psycopg2 is also installed. For this test case, I think the check `connection.vendor == 'postgresql'` skips the test too aggressively.
Did you consider using `PostgreSQLSimpleTestCase`? I would favor that for consistency.
I would reduce indentation: ```python WARNING = """ A problem arose migrating proxy model permissions for {old} to {new}. Permission(s) for {new} already existed. Codenames Q: {query} Ensure to audit ALL permissions for {old} and {new}. """ ```
This fails when running from the root directory rather than the tests directory (i.e. `$ ./tests/runtests.py postgres_tests`). Also, the output doesn't make debugging very easy (`AssertionError: 1 != 0`) -- if that could be improved that could be nice.
Not for a single line, the idea is to add one for things like multi-line dicts/tuples so that if more lines are added later, we don't have to modify the last line and add a comma.
I added the comma to be consistent with the `include` and `condition` attributes. Also, on `ExclusionConstraint` we separate attributes by comma but not on `UniqueConstraint`, so 🤷 indeed..
`expressions` should be before the `name` like in other classes.
I would revert these changes, a string representation of `condition` and `deferrable` doesn't need and extra quotes.
If it has some readability benefits, it could be done in a separate PR. This looks okay for now.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
`form_class` is defined in `RangeField.formfield()` so this is redundant.
Feels like this should be handled at the database backend level.
It would work but it would be a kind of implementation detail abuse since `value` is not an SQL identifier but an expression. This whole method should likely live on `connection.ops` instead.
Can `schema_editor.quote_name` be used here instead? ```suggestion schema_editor.quote_name(value) if isinstance(value, str) else value ```
Maybe it should go in `django.contrib.mysql`...
The fact you have to special case `DefaultNow` makes it look like a code smell to me, this logic should be completely abstracted by whatever is allowed to be passed to `db_default`.
Django doesn't currently use f-strings, but 3.0 will certainly be capable of doing so. @felixxm, @carltongibson - are we happy to start allowing use of f-strings, or do we want to hold off? Perhaps this could be: ```python except ValueError as e: raise e.__class__(...) from e ```
This reassignment is pointless as `source_value` is not reused later. Perhaps: ```python value = classdict[key] if isinstance(value, (list, tuple)): try: value, display = value except ValueError as e: ... else: display = ...
Please use single quotes.
Please remove blank line.
Please remove blank line.
Minor but the `'%%Y-%%m-01 00:00:00'` could likely by appended to params as well.
`WEEKOF` is not defined in the `Oracle`. You should use `TO_CHAR` with `IW` param ``` diff --- a/django/db/backends/oracle/operations.py +++ b/django/db/backends/oracle/operations.py @@ -84,6 +84,9 @@ WHEN (new.%(col_name)s IS NULL) if lookup_type == 'week_day': # TO_CHAR(field, 'D') returns an integer from 1-7, where 1=Sunday. return "TO_CHAR(%s, 'D')" % field_name + elif lookup_type == 'week': + # TO_CHAR(field, 'IW') returns an integer from 1-52 or 1-53, week of the year based on the ISO standard + return "TO_CHAR(%s, 'IW')" % field_name else: # http://docs.oracle.com/cd/B19306_01/server.102/b14200/functions050.htm return "EXTRACT(%s FROM %s)" % (lookup_type.upper(), field_name) ```
Oh I missed the fact `datetime_trunc_sql` was used by `datetimes()`. This is fixing the reported use case where `'field'` is a `DateField` but wouldn't it break in the case of `dates('field', 'day')` where `'field'` is a `DateTimeField`? It looks like it wouldn't get truncated at all in this case.
This is really hacky, moving to the previous day should work as expected ```python return "TO_CHAR(%s - 1, 'D')" % field_name ```
This could be simplified to match the implementation in `_sqlite_datetime_extract()`: ```suggestion month_in_quarter = ceil(dt.month / 3) ```
Hmm, I think if it's not an instance of the model I'd expect it to raise an exception, not just ignore it, but I'm not sure.
I _think_ there's the potential for a slight discrepancy here - if the `_result_cache` is not None (it's an evaluated queryset) and you fall back to doing `__contains__` on the underlying list, you'd be comparing using `Model.__eq__` right? Ignoring the possibility that the user has overridden the method (and thus there's unavoidably nothing you can do), that method also checks the `concrete_model` meta attribute, for reasons I expect are nuanced but important (my guess: proxy models)
Why are you copying the `QuerySet`s? Shouldn't be necessary as all their attributes are immutable except outside of other operations, and the result cache doesn't seem to affect their use in the combined qs.
yes I think the `values.contains` point should be discussed on the mailing list if we don't want to explicitly error out in this case. I would personally expect `values.contains` to only accept `dict` instances and `values_list.contains` to only accept `tuple` instances.
This a O(n) scan in `self._result_cache`, not sure this is desirable.
chop trailing ", " in list
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
I don't think you should re-number the existing tests.
`from django.utils.six import range` for consistent testing on py2/3 (or `list(range(5))` to test what's being tested on py2 now).
`%`-formatting is called anyway: https://github.com/django/django/blob/f71b0cf769d9ac582ee3d1a8c33d73dad3a770da/django/db/models/expressions.py#L965 Do you think an extra value can cause a performance regression? :thinking: I was thinking about readability.
Good idea, I will implement it :+1:
Again, the inheritance chain looks questionable to me if this is needed.
I added warning to docs.
We try to avoid altering expressions during the compilation phase as it can lead to hard to diagnose issues what about ```suggestion self.collation = collation def as_sql(self, compiler, connection, **extra_context): extra_context.setdefault('collation', connection.ops.quote_name(self.collation) ```
TBH, I couldn't find a better wording.
I had to read it 3 times to understand it, maybe the wording could be improved here. Alias and aliased is just very similar.
is `db_rhs and` needed? `None` is okay to compare to strings.
The current form is fine, IMO. I don't think that ```python is_join = isinstance(table, Join) is_base_table = isinstance(table, BaseTable) clone.external_aliases[alias] = ( (is_join and table.join_field.related_model._meta.db_table != alias) or (is_base_table and table.table_name != table.table_alias) ) ``` is more readable.
I guess it would be easier to understand, if you'd name the separate boolean expression first before combining them, eg: ```python is_join = isinstance(table, Join) is_base_table = isinstance(table, BaseTable) clone.external_aliases[alias] = is_join and not is_base_table ``` Something along those lines.
```python msg = ... with self.assertRaisesMessage(ValueError, msg): ```
```suggestion res = self.client.get('/dates/books/2008/week/40/iso_week_format/') ```
Do we need to re-fetch an author? ```suggestion self.assertEqual(res.context['object'], self.author) self.assertEqual(res.context['author'], self.author) ```
this can be a single line (we prefer longer lines when it improves readability)
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
@timgraham wilco. As new contributors, it's difficult to know which direction so I appreciate the explanation.
Chop blank line.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python error = PermissionError(errno.EPERM, 'message') with mock.patch('django.core.files.move.copystat', side_effect=error): ```
Chop blank line.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python with mock.patch('django.core.files.move.os.rename', side_effect=OSError()): ```
passed to query relations.
I moved this check to a separate helper.
UnqiueConstraint is suggested instead of unique_togather in newer versions [2.2+]
no blank line
"Checks the type of the object..." (The fact that it's a method and that it calls check_query_object_type is readily apparent)
I think the `_module_exists` and argument name could be improved. What about ```suggestion def _contains_subclass(subclass_path, candidate_paths): ```
Chop trailing space.
This is here for appending to the follow-ups later. One or other is always appended so...
True, I missed this.
I would chop `simply`.
```suggestion squashed_migrations_with_deleted_replaced_migrations = [ migration_key for migration_key, migration_obj in executor.loader.replacements.items() if any(replaced in to_prune for replaced in migration_obj.replaces) ] ```
This should be display when `verbosity > 0`.
```suggestion if squashed_migrations_with_deleted_replaced_migrations: msg = ( " Pruning cannot take place until the following squashed " "migrations are recorded as applied (re-run 'manage.py migrate') " "and have their replaces attribute removed:" ) self.stdout.write(msg, self.style.NOTICE) for migration_to_warn in squashed_migrations_with_deleted_replaced_migrations: app, name = migration_to_warn self.stdout.write(f' {app}.{name}') else: to_prune = sorted(migration for migration in to_prune if migration[0] == app_label) if to_prune: for migration in to_prune: app, name = migration if self.verbosity > 0: self.stdout.write(f' Pruning {app}.{name}', ending='') executor.recorder.delete(app, name) if self.verbosity > 0: self.stdout.write(self.style.SUCCESS(' OK')) elif self.verbosity > 0: self.stdout.write(' No migrations to prune.') ```
`--prune` is ignored when `--plan` is used. Maybe we should raise an error that they're mutually exclusive.
I would add `OK`: ```suggestion executor.recorder.delete(app, name) self.stdout.write(self.style.SUCCESS(' OK')) ```
I don't see a test for this method and I don't see that it's actually called unless there's some magic going on.
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
``` When the object has a ManyToManyField to Site, redirect to the current site only if it's attached to the object.
This should use a variant on the `check_isseq` used elsewhere in the file. At present this does restrict you to a list or a tuple, but we may as well keep this consistent.
Alright let's keep it as it is then. I just wanted to make sure this case was covered by a test.
Looking at it we should also pass `obj` to this method and cache its results, just like we do with `get_group_permissions`: ``` python def get_user_permissions(self, user_obj, obj=None): """ Returns a set of permission names the user has. """ if user_obj.is_anonymous() or obj is not None: return set() if not hasattr(user_obj, '_user_perm_cache'): if user_obj.is_superuser: perms = Permission.objects.all() else: perms = usr_obj.user_permissions.all() perms = perms.values_list('content_type__app_label', 'codename').order_by() user_obj._user_perm_cache = set("%s.%s" % (ct, name) for ct, name in perms) return user_obj._user_perm_cache ```
Move this above `has_add_permission` for consistency.
I think you missed this one in your recent updates.
same thing here about assuming `is_active` exists and `not user.is_active` -- probably need some tests for that case.
`obj` is not passed to `get_(user|group)_permissions` since it's always equals to `None` at this point; expand the diff and look at the full body of `get_all_permissions`.
Might be better to define this as separate method like this: ``` def window_frame_start(self, start): if isinstance(start, int): if start < 0: return '%d %s' % (abs(start), self.PRECEDING) elif start == 0: return self.CURRENT_ROW elif start is None: return self.UNBOUNDED_PRECEDING raise ValueError('Illegal argument for start, must be either a negative integer, zero or None') ```
Similarly, I don't see much advantage to creating indirection with a method.
I was asking as major databases support year extract functions, so year comparing can be done as consequent joining of a transform and standard comparison lookup. So, creating YearGt and etc lookups will become really unnecessary if year transform will just convert datetime to a year representation using EXCTRACT, YEAR or STRFTIME calls (depending on database).
The problem is that an expression like extract(year from datefield) = 2015, then the DB will not be able to use indexes on datefield. But if you instead have datefield >= '2015-01-01' and datefield < '2016-01-01', then the db can use indexes. This is the underlying reason why we have the special year lookups.
same issue as with obj_refs_aggregate
Most likely this will not work on Windows because files created with `NamedTemporaryFile` cannot be reopened on Windows (which defeats the whole purpose of naming them in the first place -- I have no idea why `NamedTemporaryFile` even exists on Windows). I'm not saying this is blocking the merge because I don't think we have that many users of PostgreSQL on Windows, but I thought I'd bring it up in case someone wants to check.
Unindent by one level, please.
can you explicitly wrap them in brackets: `args += ["-U", user]` please. That makes it clearer to understand the code.
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
Only this parameter is unnecessary, rest of them is necessary to hide std outputs.
`'bar'` is already in `out` from the first execution of `call_command()`. You should reinstantiate or use `out.truncate(0)` before the second call.
This can be single-lined.
`verbosity=0` is not necessary.
I'd combine w/previous line for better readability
```suggestion """runserver doesn't support --verbosity and --trackback options.""" ```
Please add a trailing comma: ```suggestion [sys.executable, '-Xutf8', '-Xa=b', __file__, 'runserver'], ```
```suggestion @mock.patch('sys._xoptions', {'utf8': True, 'a': 'b'}) ```
Please add a trailing comma.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python error = PermissionError(errno.EPERM, 'message') with mock.patch('django.core.files.move.copystat', side_effect=error): ```
I feel the test could be slightly improved to better underline the problem that was reported and to prevent future regression. Something like: ```suggestion encoded_url = '/test-setlang/%C3%A4/?foo=bar&baz=alpha%26omega' # (%C3%A4 decodes to ä, %26 to &) ```
I don't know that the ticket reference is necessary. We try to reserve it for obscure issues that can't be easily captured in a docstring.
It might be helpful to explain: "Invalid - urlparse() raises ValueError", or following the other examples: ``` >>> urlparse('https://[') ValueError: Invalid IPv6 URL ```
Here we need ``` python elif settings.CSRF_COOKIE_DOMAIN is not None and settings.CSRF_USE_SESSIONS: raise ImproperlyConfigured("When CSRF uses sessions, use SESSION_COOKIE_DOMAIN instead of CSRF_COOKIE_DOMAIN") ``` This, to make sure people don't just forget such settings, which probably express some security assumptions about their deployment.
Yes, we should definitely reject HTTPS requests with no referrer; otherwise we may as well just remove the referrer-checking entirely. I don't think this PR changes that.
1. Given that we have `pylibmc` below, is `memcached` the right key here? 2. Given that there are choices here, is this something we want to have an opinion on? (It doesn't seem as clear to me as e.g. databases.)
`tests_require` is deprecated in [setuptools](https://setuptools.readthedocs.io/en/latest/setuptools.html#new-and-changed-setup-keywords) since [41.5.0](https://setuptools.readthedocs.io/en/latest/history.html#v41-5-0) (27 Oct 2019). (It is also being unused by Django anyway.)
For Pillow it would make sense to specify version `>= 5.2.0` as the [support matrix](https://pillow.readthedocs.io/en/latest/installation.html#notes) for that version lines up with Django pretty well.
I left a reply on the trac ticket addressing some of your questions. It might be worthwhile to post your questions there as well.
You need to wrap the second instantiation in its own assertRaises to actually test it.
This and similar assertions added for `bloom`, `btree`, `hash`, `gist`, and `spgist` are not related with this patch, and they're unnecessary. Index types are already checked in ``` self.assertEqual(constraints[index_name]["type"], ...) ``` Please remove them.
single line looks okay here
To have more balanced line length, I think I prefer: ``` python constraints = self.get_constraints(IntegerArrayModel._meta.db_table) self.assertEqual(constraints['integer_array_model_field_gin']['type'], 'gin') ```
"its" (but could chop "and it's type" I think)
single line looks okay here
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
seems like we could use `super()` instead.
```suggestion # Windows registry may not be configured with correct # mimetypes. ```
I envisioned something like this: ``` python content = None with open(path, read_mode) as f: try: content = f.read() except UnicodeDecodeError: # If mimetype suggests the file is text but it's actually binary, # read() will raise a UnicodeDecodeError on Python 3. pass # If the previous read in text mode failed, try binary mode. if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE ```
```suggestion self.assertEqual(value, b'text/plain') ```
I would rename `self.model_name` -> `self.name` (like in `CreateModel`, `DeleteModel`, or `RenameModel`).
The previous return value was `not operation.references_field` which meant 1. `not True -> False`, if the operation refers to the field block optimizations through. 2. `not False -> True`, if the operation doesn't refer to the field allow optimizations through. You proposed change makes it the other way around.
I think the _through_ test failure has more to do with how `RemoveField.references_field` deals with through. For example, not saying this is the right solution here, but the following diff happens to make the tests pass as well ```diff diff --git a/django/db/migrations/operations/fields.py b/django/db/migrations/operations/fields.py index 41c389f79f..d6cbd6b9c6 100644 --- a/django/db/migrations/operations/fields.py +++ b/django/db/migrations/operations/fields.py @@ -36,7 +36,7 @@ class FieldOperation(Operation): return field_references_model(self.field, ModelTuple(app_label, name_lower)) return False - def references_field(self, model_name, name, app_label=None): + def references_field(self, model_name, name, app_label=None, reference_through=True): model_name_lower = model_name.lower() # Check if this operation locally references the field. if model_name_lower == self.model_name_lower: @@ -53,11 +53,12 @@ class FieldOperation(Operation): (not hasattr(self.field, 'to_fields') or name in self.field.to_fields or None in self.field.to_fields)): return True - through = getattr(remote_field, 'through', None) - if (through and ModelTuple.from_model(through) == model_tuple and - (getattr(remote_field, 'through_fields', None) is None or - name in remote_field.through_fields)): - return True + if reference_through: + through = getattr(remote_field, 'through', None) + if (through and ModelTuple.from_model(through) == model_tuple and + (getattr(remote_field, 'through_fields', None) is None or + name in remote_field.through_fields)): + return True return False def reduce(self, operation, app_label=None): @@ -186,6 +187,11 @@ class RemoveField(FieldOperation): def describe(self): return "Remove field %s from %s" % (self.name, self.model_name) + def references_field(self, model_name, name, app_label=None): + return super().references_field( + model_name, name, app_label=app_label, reference_through=False + ) + def reduce(self, operation, app_label=None): from .models import DeleteModel if isinstance(operation, DeleteModel): ```
should this be super()
What about ```python def can_reduce_through(self, operation, app_label): return not operation.references_model(self.name, app_label) def reduce(self, operation, app_label): return ( super().reduce(operation, app_label) or self.can_reduce_through(self, operation, app_label) ) ```
you can remove ticket reference
``` py self.assertRaisesMessage( ImproperlyConfigured, '...', ) ```
you can remove ticket reference
an app containing a locale folder
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
it would help readability if description[5] and description[4] were assigned local variables describing what they represent
missing whitespace around ==
To be consistent, BigIntegerField should be qualified with `if c.f.can_introspect_big_integer_field`
append(...), not append[...].
Use double quote docstrtings.
And now I look at the implementation for get_field, I see that @PirosB3 has implemented the backward compatibility approach with kwargs already.
This change is concerning - it indicates that there's a backwards incompatible change in the API. If existing users are invoking with `many_to_many=False`, we should _at least_ preserve that usage.
The old options look pretty easy to deprecate. We just accept `**kwargs`, and alias any older `kwarg` to the new one + deprecation warning.
ideally this bit would be in the `else:` branch of the try/except.
To prevent unexpected `FieldDoesNotExist` exceptions raised in `if field.attname == field_name:` to be silennced. It's generally good practice to restrict the `try` body to the only parts expected to raise the exception.
FWIW the `TypeError` raised here would be backward incompatible. Such a pattern is even used in Django core. https://github.com/django/django/blob/0ce2ad9ca4623cfd6dc2515430c0ae8a1717a607/django/db/backends/postgresql/features.py#L56-L74
Yea, as Sergey said above, there's a bug where such attributes aren't cached.
@graingert `cls` is passed here.
I think it's the right class: ``` In [38]: class desc: ...: def __get__(self, instance, cls): ...: if instance is None: ...: return self ...: return instance.__dict__['_%s__mangled' % cls.__name__] In [39]: class A: ...: d = desc() ...: ...: def __init__(self): ...: self.__mangled = 42 ...: In [40]: A().d Out[40]: 42 ```
I'd say `on Python < 3.6`
what if two mixins have the same name (from different packages)? hypothetically: `facebook.models.UserMixin` and `twitter.models.UserMixin`
How about more simply: "Found duplicate <field/base/manager> '%s' in CreateModel operation." Maybe you could create a helper function so we don't have to repeat a similar loop 3 times.
I think we want to crash here if `bases` is not iterable.
My gut feeling is that it's normal that these test assertions lost a bit of their original _intent_ now we're not using rendered models anymore. The reason for that is that `.field_name` gets assigned on model rendering which we completely avoid doing here. The fact _rendered_ model fields were making their way into operations breaks the `ModelState.__init__` expectations and was really just an implementation detail. Looking more at the ticket-23415 and the resulting patch 215aa4f53b6bbd07d5c1eecfa94e7fcd00da813e these particular assertions had little to do with the issue of unmanaged models not including their fields in the first place. It's true that the symptom that the reporter mentioned was improper foreign key references by models pointing at the unmanaged model but the true bug there was that unmanaged model fields were not tracked in migration state. TL;DR I think this is fine.
I guess this needs to be something like `inherited_attributes |= set(base.__dict__.keys())` to work on Python 2.
I think a simple `django.template.Context` will do here.
Unless I'm missing something you don't need to define a class and nest an instance of it in a list to reproduce your use case. Simply passing a callable that throws an exception should do. e.g. ``` python engine = Engine(loaders=[ ('django.template.loaders.locmem.Loader', { 'child': '{{ raises }}', }), ], debug=False) def raises(): raise Exception engine.from_string('{% include "child" %}').render(Context({'raises': raises})) ```
I was thinking you could instantiate `VariableDoesNotExist` directly rather than creating it indirectly with `Variable/resolve()`. Not sure about a better place for this test considering there's no logging involved at this point. Maybe `tests.py` is for miscellaneous tests.
If you make this: ```python with self.assertRaises(VariableDoesNotExist) as exception_ctx: ``` then later on when you need the exception you can just do: ```python self.assertEqual( str(exception_ctx.exception), ... ) ``` which looks a bit cleaner than the `exc_info[1]` stuff.
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
Can we wrap this line after the comma.
Makes sense. Lets go with `MyField` then.
Could you rename the field to `RemovedField` given the test case name.
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
more than one automatically generated field.? sounds better and more natural with the changes.
Same note goes here.
The reason for this is that your for loop is running on both dbs, at first `allow_migrate()` returns `True` for the first db (`default`) thus setting `connection`, `allowed_len`, `db_alias` accordingly, but you are not terminating the loop, making it try `other` db with `allow_migrate()`, returning `True` and setting the variables again.
`long_field_name = 'a' * (allowed_len + 1)`
Yes, but there we are testing behavior on TestCase so it makes more sense. Maybe it's fine here, but it seems fishy. In any case, I haven't looked into alternatives.
I don't think nesting the test cases is the correct approach to avoid the errors you encountered.
It's unclear to me why you need this `try / finally` block. If an exception happens `populate()` in an "inner" call — and any inner call will raise an exception just below — `_populate_running` shouldn't be reset to `False` until the "outer" call terminates. In fact I don't think we need to reset `_populate_running` at all. I think it will be just as easy to make it a simple boolean that starts at `False` and moves to `True` when `populate()` is called for the first time. That will be consistent with `(apps_|models_|)ready`. I'd just call it `loading` or `started` and not bother reset it.
it's a separate item, but I wonder if we could patch override_settings to handle DATABASE_ROUTERS like is done below
a nice line to see gone
This is here for appending to the follow-ups later. One or other is always appended so...
Chop trailing space.
Furthermore, why do you construct `unapplied_parents` at all? Can't you just loop over `self.graph.node_map[migration].parents` and on raise an exception when the first one has an inconsistent history? That would safe some time in bigger projects. ``` python for x in self.graph.node_map[migration].parents: if x is unapplied # use the condition from above raise InconsistentMigrationHistory(...) ```
I don't think this is correct. `settings.MIGRATION_MODULES` only contains user-defined migration modules -- presumably want the detection to work regardless of whether or not that setting is defined.
"its" add period
Ahh, that's gonna be more interesting. You'd need to look at `self.migrations_module(x[0]) is not None` for whether there are migrations for that particular app or if they are disabled.
use PEP 257 verb style "Check ... Raise .."
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
And I would rename this attribute `superusers` as it's meant to contain multiple users.
please include a trailing comma in cases like this so if we add more items later, we don't have to modify the line again
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
This is fine as is.
This is fine as is.
This is fine as is.
This is fine as is.
An unhandled `SuspiciousOperation` will result in a `400 Bad Request` response which is ok since it is a client error. However, `413 Request Entity Too Large` would be the correct status code for this error.
Please wrap at 79 chars.
```suggestion # - MySQL < 8.0.13 doesn't accept default values and implicitly treats them ```
Perhaps the tuple should be a module constant somewhere so it can be reused in `validation.py`.
We can pass `opclasses` to the `super()._create_index_sql()`.
How about: ``` r"""LIKE BINARY CONCAT('%%%%', REPLACE( REPLACE( REPLACE(%s, '\\', '\\\\'), '%%%%', '\%%%%'), '_', '\_'), '%%%%')""" ```
Please add `urls.W004` to the `ref/checks.txt`.
I think we should return a list of all warnings, e.g.: ```python def check(self): warnings = self._check_pattern_startswith_slash() if self._route.startswith('^') or self._route.endswith('$'): warnings.append(Warning(...)) return warnings ```
Dot is missing _"... for Django 2.x."_.
Not sure if ``` def check(self): return self._check_pattern_startswith_slash() ``` is better or not.
This message should include some helpful information to debug the error. Currently it gives no information as to where the problem is. This is the idea behind the existing `describe_pattern()` function.
I don't think this is correct. `settings.MIGRATION_MODULES` only contains user-defined migration modules -- presumably want the detection to work regardless of whether or not that setting is defined.
Furthermore, why do you construct `unapplied_parents` at all? Can't you just loop over `self.graph.node_map[migration].parents` and on raise an exception when the first one has an inconsistent history? That would safe some time in bigger projects. ``` python for x in self.graph.node_map[migration].parents: if x is unapplied # use the condition from above raise InconsistentMigrationHistory(...) ```
Ahh, that's gonna be more interesting. You'd need to look at `self.migrations_module(x[0]) is not None` for whether there are migrations for that particular app or if they are disabled.
"its" add period
use PEP 257 verb style "Check ... Raise .."
IMO `if extra_fields.get('is_staff') is not True:` represents what need to be checked here more clearly.
@pahko `2` , `3` and non-empty lists and objects also will be valid case. Only check for boolean is needed here.
> This is fine because managers are by definition working on the real model. I thought adding the `use_in_migrations` flag to managers was done specially to allow working on models created in migrations? This is going to break any migration that uses the return value of `create_user` as it will no longer be an instance of the user model class at the particular state the operation is run at. e.g. ```python def forwards(apps, schema_editor): UserModel = apps.get_model('auth', 'User') user = UserModel.objects.create_user('Ms X', password='secure') assert isinstance(user, UserModel) ``` This is really problematic for migrations that use the returned user instance to assign foreign key values as they'll fail with `TypeError`.
Exactly as @charettes says.
As `clean()` can also raise `ValidationError` if overridden I would avoid calling it here and stick to calling `normalize_username()`.
I suggest you use a constant to refer to the default `template_name`. Have a look at how it was dealt with in #5577.
I think we shouldn't silence the exception in all cases here, only when `template_name != 'csrf_failure.html'`. Changing the default value of `template_name` to `None` and actually raising the exception `if template_name is not None` should do.
This can be single-lined, e.g. ```python return HttpResponseServerError( ERROR_PAGE_TEMPLATE % {'title': 'Server Error (500)', 'details': ''}, content_type='text/html', ) ``` The same in `bad_request()` and `permission_denied()`.
`# Render template (even though there are no substitutions) to allow inspecting the context in tests.`
Testing `load_template` should be enough.
The change is fine, I'm just asking that it be a be separate commit similar to 31098e3288595c13f165935f2579f1af744e5240 so that the refactoring isn't mixed in with the new feature.
Please make this change and the test changes unrelated to the bug fix in a separate commit for clarity.
Do we need this change? it looks unnecessary.
```suggestion # - MySQL < 8.0.13 doesn't accept default values and implicitly treats them ```
Would `functools.partial` work here? ```python from functools import partial bound_method = partial(method.__get__(self, type(self))) ```
As noted elsewhere, put the trailing space on this line rather than the next (and in the message below).
Can you please choose a new error code that is otherwise unused.
Can you please choose a new error code that is otherwise unused.
If changing the messages, please update them in `docs/ref/checks.txt` as well.
Put the `not field.many_to_many` first and the `isinstance()` second, please.
I'd rename that to "target". See `root_nodes()` for an explanation of what we consider root nodes.
Can you issue a `RuntimeWarning` here telling the user that Django falls back and it might be time to clean up using `squashmigrations` and link to https://docs.djangoproject.com/en/dev/topics/migrations/#squashing-migrations.
Don't need parentheses around `self._nodes_and_edges()` Also check flake8 errors, otherwise LGTM. Also Refs -> Fixed in the commit message.
I think we can get rid of `self.nodes` when we add `implementation` to the node itself: `node = Node(key, implementation)`
Well, I guess we should take the node instances then.
Please move `)` to a new line: ``` py return self._html_output( normal_row='<p%(html_class_attr)s>%(field)s %(field_name)s</p>', error_row='%s', row_ender='</p>', ) ```
```suggestion errors_on_separate_row=True, ```
please limit line lengths so horizontal scrolling isn't required, something like: ``` self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> ' '...' ) ```
I know this is the sort of layout that `black` would generate, but it's one of the more ugly choices it doesn't get right in my opinion. Perhaps we should `+=` instead of `.extend()`: ```suggestion top_errors += [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
Thanks for looking that up @timgraham, as long as have tests asserting that this is working as expected it should be fine.
Rename this variable to `readonly_fields`. Let's not pollute the code with three things that mean the same thing, i.e. the `uneditable_fields` here and the aforementioned `viewonly_fields`.
Same as below, you should be able to call `self.using()` directly.
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
This exception message is different from that in `related.py` though the logic/intention surrounding it seems to be the same. Is this intentional? (FWIW, I find the message in `related.py` to be clearer)
What @shaib said: `makemigrations` and `migrate` should fail, `showmigrations` should work.
I guess so.
The reason `makemigrations` should fail is that the more likely reason for inconsistent history is a change in the migrations code (in particular, dependencies), rather than direct manipulation of the database. If the code of existing migrations is suspicious, we should avoid building more migrations on it.
migrations isn't used
no need of inheriting from object
Yes it should be `R.p`, we didn't take into account nested protected relations in the ab3cbd8b9a315911248227208630a020cedca08f (probably my fault). Also casting to list is not necessary anymore after this change.
Please put the test in `AdminActionsTest`.
Implementation looks okay but should still check the response here and check that the "protected" page is displayed.
I don't think this test is needed. The default implementation is already tested as well as overriding the method.
I think a specialized class is not required for this test case as you can rely on `.args` ```python try: raise Exception(2) except Exception as e: try: raise Exception(1) from e except Exception: exc_info = sys.exc_info() ... self.assertEqual(cm.exception.args[0], 1) self.assertEqual(cm.exception.__cause__.args[0], 2)
It would be safer to assertEqual with False/True since these assertions pass on any truthy/falsey value.
This test doesn't fail with or without the patch applied so it's likely unnecessary.
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
Could we patch a StringIO instead of devnull and then verify the contents of log_message()? See tests/check_framework/tests.py for an example. Also the patching should be in setUp/tearDown or in a try/finally so if something goes wrong the unpatching still happens.
please check code with flake8 (`E231 missing whitespace after ','`)
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
It would probably be better to check `cl.queryset.query.distinct`
"cannot" is one word. add period.
I'm not sure if there are lookups where it's not the case, but comparisons such as `Choice.objects.filter(votes__gte='2')` seem to work fine with the value as a string so the "transform" stuff seems unnecessary, at this for the first version of this.
And this to `self.queryset`.
This ticket is about recommending a `fk_name`, so we should rewrite this message, e.g. ```python raise ValueError( "'%s' has more than one ForeignKey to '%s'. You must specify " "a 'fk_name'." % ( model._meta.label, parent_model._meta.label, ) ) ```
I think tests for `filtered_relation` and `GenericRelation` are missing. I don't see any failures if this is changed to `filtered_relation=None`.
We're checking `get_parent_list()` in a loop so I would cache it in the variable: ```python parent_list = parent_model._meta.get_parent_list() fks_to_parent = [ f for f in opts.fields if isinstance(f, ForeignKey) and ( f.remote_field.model == parent_model or f.remote_field.model in parent_list or ( f.remote_field.model._meta.proxy and f.remote_field.model._meta.proxy_for_model in parent_list ) ) ] ```
recopied (no dash) get a different
no blank line
chop blank line
chop blank line
could probably omit some blanks lines
chop blank line
omit "Tests that" prefix in favor of just stating the expected behavior
explicit -> specified
Maybe: ```suggestion setting = getattr(settings, 'FILE_UPLOAD_TEMP_DIR', None) if setting and not Path(setting).is_dir(): return [Error( f"The FILE_UPLOAD_TEMP_DIR setting refers to the nonexistent " f"directory '{setting}'.", id='files.E001', )] ```
Maybe a helper method would help eliminate the redundancy of these methods? e.g. `return self._value_or_setting(self._location, settings.MEDIA_ROOT)`
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
`assertEquals` is deprecated and should be replaced by `assertEqual`. In a more personal-taste spirit, is it really useful to make 4 separate tests instead of consolidating them into one? The fact that the last 3 are identically named is an error, for sure.
I feel like there should be some dependencies declared on the operation here - the one that comes to mind is that it should depend on creation of its model, and delete model should depend on it.
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
I think this test can be entirely removed if `test_nested_subquery_outer_ref_with_function` covers the usage case appropriately.
The thing is that even if the ORM doesn't have support for it yet using `distinct()` to implement `(UNION|INTERSECT) ALL` might prevent us from adding proper support in the future. What I suggest doing here is setting `query.combinator.all = kwargs['all']` and preventing using `distinct()` on `CombinedQuerySet`. The difference between ordering and combination operation is that the former operates on the _combined_ set of rows while the latter operates on how these rows are combined. I would suggest that options related to combination be passed as `kwargs` (such as `all`) and actions operating of the combined result (`CombinedQuerySet` instances) be added as methods (`order_by`, _slicing_).
Why are you copying the `QuerySet`s? Shouldn't be necessary as all their attributes are immutable except outside of other operations, and the result cache doesn't seem to affect their use in the combined qs.
I'll quickly check if an idea I'm having works here.
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
I would leave only `The django.utils.datetime_safe module is deprecated.`. This a private API, we don't see to provide an alternative.
Good catch :dart: , I missed this :facepalm:. Please feel-free to send a patch
I think it would be helpful if this were instead named `invalid_token_re`. The reason is that I coincidentally happened to be reading `csrf.py` and was confused by these lines: https://github.com/django/django/blob/b746596f5f0e1fcac791b0f7c8bfc3d69dfef2ff/django/middleware/csrf.py#L111-L112 The reason this was confusing is that this isn't a regex that matches tokens. It matches invalid tokens. And then I saw this was changed in this PR only a few days ago.
A small oversight I noticed in an old Python 3.7.0 virtualenv: https://github.com/django/django/pull/13393
prefer including a trailing comma in kwargs so if more items are added in the future we don't have to modify this line again
The only issue I can see here is that `UPDATE` is the rows/table locking statement, so we will lock a table even if not necessary :thinking:
Do we need this change? If yes then tests are missing. IMO it is not necessary.
Do we need to use `self.restricted_objects` multiple times? I would simplify this, e.g. ```python for model, fields in self.restricted_objects.items(): for field, objs in fields.items(): for obj in objs: raise RestrictedError( "Cannot delete some instances of model '%s' " "because they are referenced through a restricted " "foreign key: '%s.%s'" % ( model.__name__, obj.__class__.__name__, field.name, ), objs, ) ```
You might have thought of this already, but it might be helpful to try to pass along the first error message, though it wouldn't be quite as clean, and it gets caught anyway.
Any reason to use `chain` here? Both `match.groups()` and `sub_match.args` are tuples, so a simple `match.groups() + sub_match.args` should suffice. Other than that, LGTM.
I would filter that first, via a generator. I think this might be more readable. ```python lists = (lst for lst in lists if lst) ``` or ```python lists = filter(None, lists) ```
Use `django.utils.datastructures.OrderedSet` to make it clear what you are using this datastructure for.
You could do solve this recursively, but I don't know if this better readable really. meh
Why don't you make unique_items a `set` too? This would save you the whole `not in` clause. You just do `Set.add` which will add the item if it's not in the present anyways ;) That being said, since you are adding all items of the list to a set. Just create a set from the list. This will be a lot faster, since the `in` clause performs only at `O(n)`.
why cast this into a list, normal brackets (generator) will do
I think using a semantic name would help here, e.g. `lookup_kwarg_null`
If `lookup_params_all` is an instance of `dict` you can iterate over its keys directly: `for key in lookup_params_all`. You can also remove the extra spacing inside any: `any(field_path in lookup_param for lookup_param in lookup_params_all)`. You can detect whitespace issues by running `flake8` from the source.
Perhaps something like `allows_not_any`, `allows_empty_choice`? The distinction here isn't "this has a python `None` value", it's a "none of these are included, because the relation is an empty set". Perhaps a docstring along those lines would make sense here, too? Eg. ``` """ Return `True` if a "(None)" choice should be included, which filters out everything except empty relationships. """ ```
I'd write this block a little differently: ```python if isinstance(list_filter, (tuple, list)): # This is a custom FieldListFilter class for a given field. field, field_list_filter_class = list_filter if isinstance(field_list_filter_class, str): title = field_list_filter_class field_list_filter_class = FieldListFilter.create else: ... ```
Please use single quotes.
is this message an accurate improvement? `Using an aggregate in order_by() without also including it in annotate() is not allowed:` I'll also update the test to use `assertRaisesMessage` as suggested by Simon when merging.
What's the point of switching to outer double quotes if you have to escape them? Stick to single quote and use `%r` instead of double quote wrapping ```suggestion raise FieldError('Infinite loop caused by ordering (%r on %s).' % (join_tuple, field)) ```
There's a space between `.` and `_meta`.
`OrderBy` expression can be more complicated e.g. it can contain different kind of expressions e.g. `Value()`, `Case()` etc. We will not be able to predict all use cases with regexp. Moreover IMO we don't need to provide message that can be copy & paste directly into queryset. Using `repr()` should be enough for clear message, e.g. ```diff diff --git a/django/db/models/sql/compiler.py b/django/db/models/sql/compiler.py index 23bc339e78..83c10183a3 100644 --- a/django/db/models/sql/compiler.py +++ b/django/db/models/sql/compiler.py @@ -553,9 +553,9 @@ class SQLCompiler: # order_by = None warnings.warn( "%s QuerySet won't use Meta.ordering in Django 3.1. " - "Add .order_by('%s') to retain the current query." % ( + "Add .order_by(%s) to retain the current query." % ( self.query.model.__name__, - "', '".join(self._meta_ordering) + ', '.join(repr(f) for f in self._meta_ordering), ), RemovedInDjango31Warning, stacklevel=4, ``` ```
could we inspect `query.order_by` instead? Maybe it's fine as-is, but that seems a bit less fragile.
Oh `value` is used, I can't read! (There are some methods that don't use the passed arguments, but perhaps they should all be specified for consistency)
no brackets required
Remove the blank line here.
ditto no need for `else`
FWIW +1 to doing it as a separate clean up. IMO it'll be much clearer what change was where looking back that way.
I think `get_exception_response` would be a better name for the method.
I think we should revert the logging changes as it appears we're adding additional logging calls where they didn't exist before.
My mistake on 500, but "NOT FOUND" is different from "Not Found"
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
I would prefer to omit it for now.
RawSQL needs to be added to the group by clause, we can't know if it refers to something that doesn't have an existing alias. Getting CombinedExpression and Date here seems curious. These should be fixable, but lets not do it in this patch.
Instead of "set expressions to that field" maybe it would be better to say, "group by that field, HAVING expressions, and ..." since it's more useful to explain what the assignment means.
I'd chop "Note that"
@codingjoe unless I'm missing something that would require stopping to use a list comprehension. I guess the `alias` checking could be broken to a new line ```python expressions = [pk] + [ expr for expr in expressions if expr in having or ( getattr(expr, 'alias', None) is not None and expr.alias not in pk_aliases ) ] ```
I don't have a strong opinion here as that's probably the only type of non-`Expression` wrapper supported in `ExpressionWrapper` but the previous `if isinstance(self.expression, Expression)` felt more correct.
Sorry, the return value should be an iterator, not an `OrderedSet`. It might be good to check that.
> I also considered testing OrderedSets with miscellaneous data types (like user-defined class instances) rather than just integers. You don't need to check with other data types, or modify other tests. Using integers is fine.
> Well, I considered checking that, but I discarded it because that's actually just testing the native python implementation No, it would be useful because it's checking what `OrderedSet. __reversed__()` returns. It's just that the answer is in terms of a Python dict.
Before checking the return value's contents, you should check that its type is `OrderedSet`.
Before this line, you can add `s = reversed(s)`, and then check `s` in the following lines instead of `reversed(s)`.
put the closing parenthesis on the next line
`%(expressions)s)` not `%(expression)s)`. You're missing the `s` at the end of `expressions`
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
I would handle this in `as_sql()`, i.e. ```python def as_sql(self, compiler, connection, template=None, **extra_context): sql, params = super().as_sql(compiler, connection, template, **extra_context) if self.invert: sql = '!!({})'.format(sql) return sql, params ```
This should be set only for values.
Let me put this differently :-) Is this required to make the test suite pass? If not, I'd prefer we do not include it. If yes, I'd like to look at the failing tests, because they must be weird.
(This is also more "food for thought" than an actual request for change - whatever you prefer is fine.)
`hasattr` is ugly because of its propensity to silently hide `AttributeError`, and because of its look-before-you-leap inefficiency. I would avoid it and instead use something like: ``` password_changed = getattr(validator, 'password_changed', lambda *a: None) password_changed(password, user) ```
Wouldn't it be a bit more helpful for this error message to specifically note that the module with the given path couldn't be imported? "Invalid" is a very vague term, which could mean all sorts of things - it seems unhelpful to silence an `ImportError` and replace it with a much vaguer message.
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
Ahhh, yes, thanks!
Maybe: ```python for name, value in self.scope.get('headers', []): corrected_name = name.decode('latin1').upper().replace('-', '_') if corrected_name not in ('CONTENT_LENGTH', 'CONTENT_TYPE') corrected_name = 'HTTP_%s' corrected_name ```
FYI: we have also [`HttpHeaders`](https://github.com/django/django/blob/fc2536fe66c519b306f673672b795d16f87ed57d/django/http/request.py#L359-L374) class that have reserve logic, I'm not sure if we can reuse it somehow :thinking:
I wouldn't have thought so as `request.GET` is immutable in the WSGI implementation? At least I recall having to `.copy()` it first...
Should this be mutable? (`mutable=True`). `QueryDicts` handles `None` so `self.scope.get('query_string')` should work.
I think reorganization of the admin views tests deserves its own patch outsie of this ticket.
Test -> Tests (and I suggest a new `test_history_view.py` file since this file is quite large already.
Adding new code in a good location is fine.
See if you can find an existing test case to use. There should be existing tests for log entries that this test could be located with.
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
use a single line instead
rephrase: Don't continue if ...
rephrase: "Don't continue if..."
Unrelated: this might be obsolete after 8f97413faed5431713c034897cda486507bf0cc3.
`except Exception` unless we really have a good reason for a bare except.
Oh, I thought it was referring to two separate issues. Alright then, I'll make a new PR and we can proceed from there
I think we should use `local_concrete_fields` :thinking: Also, the current solutions doesn't work with recursive parents, e.g. ```python Pizzeria.objects.bulk_create([ Pizzeria(name='Vegan Pizza House', rank=33), ]) ``` crashes when we add the `Ranked` model: ```python class Place(models.Model): name = models.CharField(max_length=100) class Meta: abstract = True class Ranked(models.Model): rank = models.IntegerField(null=True) class Restaurant(Ranked, Place): pass class Pizzeria(Restaurant): pass ```` ```
```suggestion on_conflict=on_conflict, ```
```suggestion on_conflict=on_conflict, ```
`RETURNING` from `UPDATE` is out of this ticket scope.
It's not used only for combined queries so we should call it only in `not combinator` branch.
I'd chop the blank lines around `for_update_part`.
`SELECT * FROM (SELECT "_SUB".*, ROWNUM AS "_RN" FROM (%s) "_SUB" %s) WHERE` ... (`ROWNUM AS "_RN"` should be part of the SELECT clause, not FROM clause).
`get_for_update_part()` -> `get_for_update_sql()`. We could move this hook in to a separate commit/PR.
One space after period.
I think we shouldn't silence the exception in all cases here, only when `template_name != 'csrf_failure.html'`. Changing the default value of `template_name` to `None` and actually raising the exception `if template_name is not None` should do.
Since we would be shipping the default `.txt` template, it would never be missing, even if the user had previously overridden the old `.html` template, so this exception would never be raised, so their override would never be picked up.
Why would you need to sanitize something that's already in your session? Seems a bit late...
`getattr` raises an exception when the attribute doesn't exist and no default is given
`getattr(request, 'csrf_processing_done')` would suffice since `None` is not true.
Either _all_ fields should have an m2m property (because m2m is a fundamental property that a field can have), or none of them do. A hasattr check doesn't make sense here. Same goes for is_gfk a few lines earlier. m2m is probably a fundamental property of fields, but gfk is masking something more abstract.
I think splitting this to more lines would increase readability. Probably the same for the above with `self.relname`.
`hasattr(field, "is_gfk")` - what's the underlying use case here? We shouldn't be hard-coding a concept like GFK into the API.
I see before: `to_fields=[], from_fields=[self.object_id_field_name]` after: `to_fields=[object_id_field], from_fields=[]` I could very well be missing something...
Use single quotes consistently (could be done above and below also).
If I were writing these tests from scratch, I wouldn't use a separate `expected` variable everywhere (this is related to our preference for longer lines rather than a historical more strict adherence to 79 chars, I think).
I think `assertRaisesMessage` should work here and works on py2/3.
Possibly. In general we've been moving toward `SimpleTestCase` but I don't know if requiring it is worth the effort.
Ah ofcourse, my bad, you're right. Looks good to me.
@timgraham that's neat but that looks really fragile. Think `return Signal(providing_args=["app_config", "verbosity", "interactive", "using", "apps", "plan"])` where the name would end up being `'return Signal(providing_args'`) which can lead to more confusion than the actual situation. We could also make `assertSignalSent` accept a `msg` argument (like other `assert` methods do) to allow the user to disambiguate the origin of the failure. From my point of view the traceback is explicit enough to point the users at the correct location in their code base and figure out which signal was unexpectedly sent or not.
I don't think we need to check all rows, probably sth like this: ```python self.assertEqual(list(qs.values_list('lead_default', flat=True).distinct()), [60000]) ``` will be sufficient. We have a similar situation in the `test_nth_returns_null`.
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
It's weird, because Oracle interprets empty strings as nulls.
Fair enough, I assumed it was a small tweak to the stdlib version.
Is this code based on an existing implementation? If that's the case, we should specify it / link to it.
I think this line isn't needed, tests seem to work fine without it.
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
I'd not use the ternary: ```suggestion if filtered_relation: pathinfos = field.get_path_info(filtered_relation) else: pathinfos = field.path_infos ```
missing period the message could be: "Query lookup '%s' is deprecated in favor of Meta.default_related_name '%s'."
Drop the unneeded parentheses.
```python if not hasattr(final_field, 'resolve_expression'): final_field = final_field.get_col(alias) try: final_field = self.try_transform(final_field, name) ... ```
I think we prefer the closing paren on a newline
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
You can pass `verbosity=0` instead to completely silence the command instead of creating an unused `StringIO` container.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
Given these methods are all wrapped in `assertTrue` calls they should probably be converted to `assert_all_exists` and `assert_none_exists` that perform the assertion themselves. e.g. ```python def assert_all_exists(self, dir, langs): self.assertTrue(all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ))
We used the same message as in other places that's why I don't want to add a period only in this case.
Add a period to the end of the exception message.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
I would move this out of the `Statement`: ```python if columns: columns = self._index_columns(table, columns, col_suffixes=(), opclasses=opclasses) else: columns = Expressions(model._meta.db_table, expressions, compiler, self.quote_value) ```
The idea is that `InlineModelAdmin` is always used with a `ModelAdmin`, so we don't need to include the files again.
IMO, it might be better to harcode the expected HTML rather than generating it programatically as it would be more clear what's expected.
Yes, I know. I'll leave it to Aymeric for a second opinion.
And there: ``` work_file = os.path.join(self.dirpath, '%s.c' % self.file) ```
Use a single quote.
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
Use single quotes
This should probably be the default for postgresql's `schema_editor.sql_create_index`.
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
Can you please run `pages_per_range` through `quote_value()` (internal function on the schema editor).
Please make this `IntegerField` instead of `PositiveIntegerField`. Similar to `AutoField`, which uses `serial`, although the field usually increments from `1`, it is not forbidden to store zero or negative values. Indeed, this is sometimes useful.
Remove as `empty_strings_allowed = False` is inherited from `IntegerField`.
Use unpacking generalisations and remove arguments to `super()`: ```python super().__init__(*args, **{ 'editable': False, **kwargs, 'blank': True, 'default': Default(), 'unique': True, }) ```
Not necessary if you subclass `IntegerField`.
`serial` columns in PostgreSQL have a `NOT NULL` constraint. You may want to force `null` to be `False`
Please add trailing comma.
We can ignore `name`, `path`, and `args`, e.g. `*_, kwargs = field.deconstruct()`
We should test with a different expression since this might be fixed in the future ```suggestion expr = ExpressionWrapper(Lower('field'), output_field=IntegerField()) self.assertEqual(expr.get_group_by_cols(alias=None), [expr.expression]) ```
I think that we can squash this to two cases, i.e.: ```python if not self and other: return copy.deepcopy(other) elif not other: return copy.deepcopy(self) ```
We should have a more generic solution and deep-copy all non-picklable attributes, e.g. ```python for attr in self.non_picklable_attrs: if hasattr(self, attr): setattr(obj, attr, copy.deepcopy(getattr(self, attr), memo)) ```
Join aliases are reused in order. This shouldn't non-deterministically raise AssertionError because change_map contains a circular reference (#26522).
No, it would be admin specific so it doesn't belong there. Just a private API mixin for the Django tests is that I was thinking. It might live in this file, for example.
It's ugly either way, but this way might make it slightly easier to debug if the test fails at some later point. ``` python plot_details_field = list(list(list(response.context['adminform'])[0])[3])[0] self.assertEqual(plot_details_field.field['name'], 'plotdetails') self.assertTrue(plot_details_field.is_readonly) self.assertEqual(plot_details_field.contents(), 'Brand New Plot') ``` I guess it we used the pattern more widely, it might be worth some helper functions to make it easy to extract fields without using magic numbers in the indexing.
Probably, I don't think the benefit is worth the cognitive load of someone looking at the test and wondering about it.
This should be converted to backend generic way of figuring out that a session doesn't exist anymore.
I'd go with separate methods for each of the different combinations.
I don't see a strong argument for accepting case-insensitively.
Is there any cases of `not f.is_relation and f.many_to_many`? If not then `f.many_to_many` should be sufficient.
I think you can use `batch_objs` instead of `objs`, because we update only a single batch.
Pre-computing the updates by moving lines 501-513 before line 500 would reduce the length of a time the transaction is open for, which is a good thing for database throughput
You shouldn't need the extra parentheses inside `extend()`, FYI.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
The test won't run if it's in the database router.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
similar to `get()` above, I appreciate the code reuse, but I personally would prefer if `get()` and `delete()` were not touched.
Oh, no, OK, the nextval will always return a different value. It's just that we might have gaps if one value is not saved.
Wouldn't be required if you subclasses `IntegerField`.
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
I saw that you're now handling this at the database level. It makes more sense to me.
Python2 does not support `super()`.
Mapping allowing case-insensitive key lookups. Original case of keys is preserved for iteration and string representation.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
this class has a bunch of details of WSGI environ so I think it more accurately belongs in `django.http.request`
No tests fail if I remove this change. I presume it was to avoid calling `tuple()` unnecessarily? For that matter, we can just change to the following as we're always unpacking into key-value pairs: ```suggestion yield elem ``` I don't think we need any guarantees that this will return a `tuple`. Loosely it only needs return an iterable of two elements with the first being a string.
There are only two uses of `_destruct_iterable_mapping_values()` and we use this same pattern exactly. I think that you could push the `isinstance(..., Mapping)` check into that function.
This will crash on Oracle: ```python @skipUnlessDBFeature('supports_subqueries_in_group_by') ```
This assertion is not related with the patch. Please remove it.
I would assert `len(warns) == 1`.
Use `warnings.simplefilter('once')` in this case. There has been a lot of stuff moving around lately in the `Field` and `_meta` API andI just want to make sure the backward compatibility shim you added doesn't use deprecated stuff itself.
@felixxm that's a tricky one for sure. We could adjust MySQL's `allows_group_by_pk` feature to be based of `not ONLY_FULL_GROUP_BY` but that would likely incur a large performance hit which is definitely not suitable for a backport. I guess we could always skip the test on MySQL for now.
`context.exception.message` -> `six.text_type(context.exception)`
I feel worried about keeping a `while True` loop here. I will lead to an infinite test run if the implementation of the code to be tested is broken. Can you change that into a for loop. You are already counting `i` upwards, but aren't using it.
You can maybe remove the `i` here: ``` python for _ in xrange(20): x = Tag.objects.filter(pk__in=x) ```
The failures on MySQL, PostgreSQL and likely Oracle seems to be an indicator that it should not work on SQLite either. There's only so much that Django can do when coercing types in a database agnostic way and I'm not sure trying to support cases where `float` are implicitly properly converted to `Decimal` at the ORM level is a pattern we should encourage. If you're filtering against decimal/numeric data with floats you're better off defining your coercion rules explicitly at the application level and pass _stable_ numeric data to the database to avoid surprises down the road when a specific float value happens to take an unexpected rounding/loss of precision path along the way to the query executor.
Where in the process of replacing these constructs with `self.assertSequenceEqual`, see #7226.
This can happen also for `OneToOneField` so we shouldn't put `ForeignKey` in a message, maybe: ```python exceptions.FieldError( "'%s.%s' refers to field '%s' which is not local to model " "'%s'." % ( self.model._meta.label, self.name, to_field.name, self.remote_field.model._meta.concrete_model._meta.label, ) ) ```
This should be `self.remote_field.model._meta.concrete_model._meta.label` as [pointed by Simon](https://github.com/django/django/pull/12383#discussion_r372421836).
Use `self.remoted_field.model._meta.concrete_model` below instead
Are these two conditions really necessary? It feels like they could be removed.
Likely want to raise `FieldDoesNotExist` or `FieldError` here instead.
`raise NotImplementedError("ValuesQuerySet does not implement `only()`")`
Arf, this is also not optimal either. `pre_save` can have side-effects, like `django.db.models.fields.files.FileField.pre_save` does 😕 We probably don't want to trigger those here. I mean, serendipitously it would work for the `FileField` because even if the returned value is still the same (so we don't add the `field.name` to `updated_fields`), we actually triggered the side-effect committing the file 😂 However, that seems pretty brittle 😅 I'm not sure what the cleanest/Djangoest approach would be here 🤔 We could add an attribute on the Field class, like `Field.has_pre_save: bool`, but that creates a precedent and users/libs must update their code accordingly. But at least, we would know _for sure_ which fields need to be added and which don't. Any other suggestion is very welcome!
You could use RenameMethodsBase.
The point of `RenameMethodsBase` is to insure that if someone overloads the method then the custom method still gets called. But that's only useful if the implementation of the underlying method hasn't changed. I believe using `RenameMethodsBase` doesn't buy us much here.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
You also have to pass `'number'` as the last argument to `npgettext_lazy`, and in each line below.
this line should be: `def __init__(self, *args, **kwargs):`
I see the idea, but for me if a function is called only once and only contains some simple lines, the function call overhead is not worth it. You can let this for now and wait for the Django fellows opinion.
Annoying that `datetime.time` cannot be subtracted from each other to give a `datetime.timedelta`, so we cannot use `duration_microseconds()` as in `_sqlite_timestamp_diff()` below.
Hah. Had the same thought before I got here. See the caveats mentioned above.
I think an explicit loop that mutates the dict might be clearer here, and avoid the overhead of a function creation and call. I believe we already do this elsewhere (but I haven't double checked).
```suggestion def _insert( self, objs, fields, returning_fields=None, raw=False, using=None, on_conflict=None, update_fields=None, unique_fields=None, ): ```
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
```suggestion unique_fields=unique_fields, ```
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
Looks like `self.model_name_lower` could be passed here and we could avoid all the `.lower()` handling in `.rename_field`. ```suggestion state.rename_field(app_label, self.model_name_lower, self.old_name, self.new_name) ```
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
Lets have the argument follow a namespace based ordering ```suggestion def add_field(self, app_label, model_name, name, field, preserve_default): ```
I don't think this is the best way to address this issue. We will always have to keep this list of fields updated. Instead we could change `_alter_field` field to do nothing when the constraint hasn't changed. We could just compare the old and new field. This is the `if` that drops the constraint. https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L590 and the one that adds it back https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L810
This is not only about constraints but also about noop `ALTER FIELD` operations. Field alteration can cause many DDL changes. > We could just compare the old and new field. That's exactly what we're doing here, we compare fields but without attributes that don't impact schema changes.
I guess `name` would be another one.
I think we missed some attributes e.g. `related_query_name`, `limit_choices_to`, or `validators`.
Maybe? ```suggestion def _field_non_database_attrs(self): ```
Could probably use an f-string here and in the following branches. ```suggestion return f'{lhs}[%s:%s]', params + [self.start, self.end] ```
Mistake? Looks like test coverage is missing… ```suggestion return '%s[:%%s]' % lhs, params + [self.end] ```
You can rebase your branch and target it for Django 2.0. Since master no longer supports Python 2, you can make a few updates such as using `super().`.
`abs()` is redundant since `end` is greater than 0.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
The log message makes no sense. You are trying to normalize (or rather kludge) something that should be a locale to be a language code/tag, to then convert to a locale. But you are saying the locale has been normalized to a language code/tag which is incorrect. A language code/tag is not a locale, and here we *should be providing a locale*, hence my misgivings already stated about this whole thing. Regardless, you probably want to do this: ```python def normalize_locale(original, stdout): """ Normalizes incorrect locale strings, e.g. zh-cn, zh_cn, ZH-CN are converted to zh_CN. """ corrected = to_locale(original.lower().replace('_', '-')) if original != corrected: stdout.write('Normalized %s to %s.' % (original, corrected)) return corrected ```
I think we can remove `tearDown()` and `setUp()` and use ```python with translation.override(language): ``` instead of `activate()`.
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
Thanks both :+1: I pushed edits.
While longer, this avoids creating the extra list, string building and "complex" range calculations: ```suggestion i = None try: while i := lang_code.rindex('-', 0, i): possible_lang_codes.append(lang_code[:i]) except ValueError: pass ``` I know it also uses the walrus operator, but Django 4.0 is targeting Python 3.8+, so it is available to us. It seems much more readable to me. (If this isn't a performance critical path then `contextlib.suppress()` could be used to shave off two lines.)
`clean` is not only for validation, but also for data modification in a form.
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
The form class is configuration too, is it not? You can group class attributes using a blank line, but this attribute is inherited from `BaseModelAdmin` where it is not separated. It just seemed odd.
Could we possibly skip the detection feature `if Database.sqlite_version_info >= (3, 29, 0)`? Since this is only present on macOS [could we branch off `platform.platform`](https://docs.python.org/3/library/platform.html?highlight=darwin#platform.platform)? I think this would partially address @claudep's concerns.
```suggestion supports_update_conflicts_with_target = supports_update_conflicts ```
`0` is unnecessary: ```suggestion return (10, 2) else: return (5, 7) ```
Could use `charset` over `character_set`? It's a well-known "word" and losing the underscore might make this less noisy visually, especially in the f-strings. Only a suggestion, feel free to ignore.
Is this supposed to be `sqlite_version_info` rather than `version_info`? I guess other usages in this file might be incorrect also.
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
blank line not needed
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
It might be a tiny bit faster to create `TEST_RANGE - Author.objects.count()` objects rather than deleting the existing ones.
Yeah, it's fine.
```suggestion raise NotSupportedError( 'This database backend does not support ignoring conflicts.' ) ```
`RETURNING` from `UPDATE` is out of this ticket scope.
There is no need to pass `on_conflict`, `update_fields`, or `unique_fields` when `on_conflict` is None.
```suggestion item, fields=fields, using=self.db, ```
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
`# Sendfile is used only when file_wrapper has been used.`
I'm not sure if this remains an appropriate test if it doesn't hit this block anymore? https://github.com/django/django/blob/d4eefc7e2af0d93283ed1c03e0af0a482982b6f0/django/core/handlers/wsgi.py#L161-L168
Trailing dot is missing.
We should clean `FILE_RESPONSE_HOLDER` in `finally` to ensure tests isolation, e.g.: ```python try: # Verify that sendfile was used which only happens if file_wrapper got # used. self.assertTrue(handler._used_sendfile) # Fetch the original response object self.assertIn('response', FILE_RESPONSE_HOLDER) response = FILE_RESPONSE_HOLDER['response'] # The response should have been closed ... self.assertIs(response.closed, True) # ... as well as all individual file buffers buf1, buf2 = FILE_RESPONSE_HOLDER['buffers'] self.assertIs(buf1.closed, True) self.assertIs(buf2.closed, True) finally: FILE_RESPONSE_HOLDER.pop('response', None) FILE_RESPONSE_HOLDER.pop('buffers', None) ```
please use `assertRaisesMessage` to verify this is the `TypeError` we expect (also helps for tracking which tests map to which code).
I don't think both tests are required.
Would `functools.partial` work here? ```python from functools import partial bound_method = partial(method.__get__(self, type(self))) ```
Move to the top.
You could, just seemed easier not to have nested if statements.
Ticket reference isn't needed.
```suggestion kwargs['storage'] = getattr(self, '_storage_callable', self.storage) ```
Need to use six.assertRaisesRegex for Python 3 compatibility
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
`UniqueConstraint` not `Index`.
`u'` prefix in unnecessary, please use also hanging indentation.
This needs tests in `tests/validators/tests.py`.
Maybe this inheritance should be refactored a bit as it's not obvious if `PostgreSQLWidgetTestCase` is now using `TestCase` from `PostgreSQLTestCase` or `SimpleTestCase` from `WidgetTest`? e.g. `PostgreSQLTestCase.tearDownClass()` might be moved to a mixin that `PostgreSQLTestCase` and `PostgreSQLWidgetTestCase` can use.
@smithdc1 it does thanks!
This PR looks good. It would be slightly more consistent with `SelectDate` and `Multiwidget` if this render was handled in the template. The `SelectDate` widget does something similar where the widget type is instantiated for each subfield, `get_context` is called, and the `widget` return value is added to `subwidgets`: https://github.com/django/django/blob/3e91850dccecd13dde8cef7b81c798217f74a301/django/forms/widgets.py#L961
Unneeded empty line.
Unneeded empty line.
Unneeded empty line.
Unneeded empty line.
@sdil Thanks for checking :+1:
```suggestion attrgetter('pk'), ```
Please break this down into a couple of lines to make it easier to read. Also, the `distinct` call should be unnecessary for this bug, and only introduces extra work that distracts from the main problem.
This crashes on MySQL: ``` "You have an error in your SQL syntax; check the manual that corresponds to your MySQL server version for the right syntax to use near '.`id` FROM ((SELECT `queries_number`.`id`,`queries_number`.`num` FROM `queries_n' at line 1") ```
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
I have some nitpicks to these tests but I can push them later after the final review.
I should have been clearer but `firstname` and `lastname` can be omited as they'll default to `''` if missing.
You can drop all the `firstname`, `lastname` above and default to `''`. Also could create a single `Employee` and use `cnt__gt=0` below.
~~Are you sure the `Value` wrapping and the `output_field` are necessary here? As long as you pass an `output_field=models.BooleanField()` to `Case.__init__` you should be good to go.`~~ _Edit: Well it looks like passing `output_field=models.BooleanField()` to `Case.__init__` doesn't work yet._
FWIW `Q(Exists(is_ceo)) | Q(Exists(is_poc))` already works and `Exists(is_ceo) | Exists(is_poc)` doesn't require much changes. ```diff diff --git a/django/db/models/expressions.py b/django/db/models/expressions.py index 5b82ae97a7..d18de75e9a 100644 --- a/django/db/models/expressions.py +++ b/django/db/models/expressions.py @@ -101,6 +101,8 @@ class Combinable: return self._combine(other, self.BITRIGHTSHIFT, False) def __or__(self, other): + if getattr(self, 'conditional', False) and getattr(other, 'conditional', False): + return Q(self) | Q(other) raise NotImplementedError( "Use .bitand() and .bitor() for bitwise logical operations." ) diff --git a/tests/expressions/tests.py b/tests/expressions/tests.py index 6c00f813d9..d3d75f1ce1 100644 --- a/tests/expressions/tests.py +++ b/tests/expressions/tests.py @@ -595,11 +595,9 @@ class BasicExpressionsTests(TestCase): def test_case_valid_in_filter_if_boolean_output_field(self): is_ceo = Company.objects.filter(ceo=OuterRef('pk')) is_poc = Company.objects.filter(point_of_contact=OuterRef('pk')) - outer_1 = Employee.objects.filter(Case( - When(Exists(is_ceo), then=Value(True)), - When(Exists(is_poc), then=Value(True)), - default=Value(False, output_field=models.BooleanField()) - )) + outer_1 = Employee.objects.filter( + Exists(is_ceo) | Exists(is_poc) + ) self.assertQuerysetEqual( outer_1, ['<Employee: Joe Smith>', '<Employee: Frank Meyer>', '<Employee: Max Mustermann>'], ```
Not necessary AFAIK; `values('cnt')` infers it.
This is clearly incorrect: * This will blow up if you don't have exactly two parameters. * If you had two, the output would probably be something like `?['a', 1]=['b', 2]` * The issue is due to the generator in the arguments to `str.join()`. * Why a list comprehension? I think it should remain a generator expression. A correct fix would be: ```python ('%s=%s' % (k, v) for k, v in params.items()), ```
this class has a bunch of details of WSGI environ so I think it more accurately belongs in `django.http.request`
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
This branch in untested :thinking:
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
Can we use `subTest()` for these three tests? ```python with self.subTest(http_host=http_host, http_origin=http_origin): ... ```
add trailing comma
`getattr(request, 'csrf_processing_done')` would suffice since `None` is not true.
`getattr` raises an exception when the attribute doesn't exist and no default is given
Use single quotes to stay consistent with the code above.
I couldn't came up with a test case. I suggest to be extra safe and `return (value.pk,)` immediately instead of appending to `value_list` just in case it end up containing values from other iterations (e.g. a model instance that happen to have a field/attribute with the same name as one of the looked up by `source.attname`).
I'm not sure this is correct when there's multiple sources as the the `pk` will be appended twice.
What do you think about this: ``` python try: key = getattr(value, source.attname) value_list.append(key) except AttributeError: value_list.append(value.pk) break ```
Yeah I also gave it a try by replacing the `return (value.pk,)` by `return tuple(getattr(value, field) for field in lhs.output_field.to_fields)` but the `place=restaurant_instance` test was failing. I suppose we'll require input from @akaariai.
I don't know of this particular case, but I wonder if we will have a fun time ahead regarding NULL handling in general - partial match foreign keys etc, and what it in general means for a composite field to be null... There are some similar cases in Query.add_filter() negated handling.
I wonder if it would be simpler and more efficient to filter out all empty querysets. from self and other_qs, then use `qs[0].self._combinator_query('union', qs[1:], all=all)`, accounting for the case where qs might have zero or one elements.
Why are you copying the `QuerySet`s? Shouldn't be necessary as all their attributes are immutable except outside of other operations, and the result cache doesn't seem to affect their use in the combined qs.
The thing is that even if the ORM doesn't have support for it yet using `distinct()` to implement `(UNION|INTERSECT) ALL` might prevent us from adding proper support in the future. What I suggest doing here is setting `query.combinator.all = kwargs['all']` and preventing using `distinct()` on `CombinedQuerySet`. The difference between ordering and combination operation is that the former operates on the _combined_ set of rows while the latter operates on how these rows are combined. I would suggest that options related to combination be passed as `kwargs` (such as `all`) and actions operating of the combined result (`CombinedQuerySet` instances) be added as methods (`order_by`, _slicing_).
It's a bit :scream: to me. `filter()` doesn't change anything for combined queries so I think we should handle this in `get()`, e.g. ```python def get(self, *args, **kwargs): clone = self._chain() if self.query.combinator else self.filter(*args, **kwargs) ```
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
```suggestion with self.assertRaises((OperationalError, ProgrammingError)): ```
I'm not sure why these tests raises a `ProgrammingError` :thinking:
`field` variable is unnecessary: ```suggestion msg = "TwoFields has no field named 'nonexistent'" with self.assertRaisesMessage(FieldDoesNotExist, msg): TwoFields.objects.bulk_create(self.data, update_conflicts=True, update_fields=['nonexistent']) ```
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ```suggestion msg = ( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ```
You could use `self.subTest()`, e.g. ```python def test_order_by_update_on_unique_constraint(self): tests = [ ('-number', 'id'), (F('number').desc(), 'id'), (F('number') * -1,), ] for ordering in tests: with self.subTest(ordering=ordering): updated_count = UniqueNumber.objects.order_by(*ordering).update( number=F('number') + 1, ) self.assertEqual(updated_count, 2) ```
Please don't use double spaces here.
Having `self.validate_number` being called twice doesn't matter too much, I think.
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
The original code made use of unpacking generalizations rather than excessive use of `list.append()` and `list.extend()`. Please restore this.
Also I think that `is_ref` will need to be handled in a special way. The reference will need to be resolved to inline the expression. This can be tested by with the following code ```python updated_count = UniqueNumber.objects.annotate( number_inverse=F('number') * -1 ).order_by('number_inverse').update( number=F('number') + 2, ) self.assertEqual(updated_count, 2) ``` In this case `number_inverse` will yield `is_ref=True` and `expr` will be an instance of `Ref` if I'm not mistaken.
```suggestion pass ```
You should use tuple deconstruction in a number of places, starting with `query, params = super().as_sql()`. See other SQLCompiler methods. Also you seem to have replicated a bit of logic from `SQLCompiler.get_order_by()`. You shouldn't do that, but find a way to reuse it. `order_by()` supports many forms beyond the asc/desc field name form you've compiled here.
`quote_name` is a temporary variable that's used only once, therefore I think we can remove it and use `schema_editor.quote_name` directly, i.e.: ```python 'name': schema_editor.quote_name(self.name), ```
Please chop all unnecessary blank lines.
I think we can abstract away the need to _lower_ the name here. ```suggestion def alter_model_options(self, app_label, model_name, options, alter_option_keys=[]): ```
```suggestion self.remove_model(app_label, old_name) self.reload_model(app_label, new_name, delay=True) ```
```suggestion def alter_model_managers(self, app_label, model_name, managers): ```
Not sure why `option_name` is passed here? Isn't it always `'indexes'`? ```suggestion def add_index(self, app_label, model_name, index): ```
Ditto, also it feels like only `index_name` is necessary for the operation to properly take place. ```suggestion def remove_index(self, app_label, model_name, index_name): ```
We might want to use `field.one_to_one` rather than `isinstance`. Maybe it depends on where the "it will be considered as editable" comes from.
please chop the rest of the blank lines
The reason was that we’d end up with a 500 server error in this case, whereas now we get a validation error. An alternative that we could use here is the old approach ‘cl.result_list’, which we know is sensibily limited to just one page. Either that, or since it's invalid POST data, bail out here and report the error to the user. (That's a little bit more work though; I haven't yet thought what that looks like.)
Ah yes. It no doubt will. (That's too much DRF that is. 🙂) We need to handle this. 👍
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
I'd remove this check, otherwise tuples of other lengths will be silently ignored. Better for an exception to be thrown.
I'd go with `elif empty_label is not None:` and remove the next line
comma after "list" chop "selects box" (or rephrase... currently it doesn't make sense to me)
actually I think we should set these 3 values from `none_value` in an else after the new elif I suggested above and then remove them as class attributes. There's an issue if someone has subclassed the widget and set `none_value` -- that value would be ignored with this change.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
I think this should work: ``` python connection = connections[db] if connection.settings_dict['ENGINE'] != 'django.db.backends.dummy': loader.check_consistent_history(connection) ```
Not sure if this might mask some exceptions, but here's what I came up with for now: ``` python for db in connections: connection = connections[db] try: connection.cursor() except ImproperlyConfigured: # Raised by the dummy backend. pass else: loader.check_consistent_history(connection) ```
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
You can rebase your branch and target it for Django 2.0. Since master no longer supports Python 2, you can make a few updates such as using `super().`.
Just make it: ``` if len(expressions) < 2: ``` That avoids problems with sqlite and mysql. GREATEST(x) is always x on backends that support single arguments anyway.
`This test` is unnecessary. Please write `skipUnless` in one line e.g. `@unittest.skipUnless(connection.vendor == 'mysql', 'MySQL specific test.')`.
Yes thanks for the answer!
`e` is unnecessary. Maybe it will be better to refactor these tests and put `class` inside `try` e.g. ```python @unittest.skipUnless(connection.vendor == 'postgresql', 'Postgresql specific test.') class PostgreSQLCursorOptionsTestCase(TestCase): try: from psycopg2.extensions import cursor class PostgresLoggingCursor(LoggingCursorMixin, cursor): pass except ImportError: pass ```
you can collapse, `with self.assertRaises(Exception), connection.cursor() as cursor:`, and in a few places below.
maybe create_and_call -> "test" to be a bit shorter
since there's no validation here and `get_port()` is relying on this code I would think you'd need to consider other malformed cases, such as `example.com:abc` or `1.1.1.1:443]`
Not sure whether it's worth having a `to_asgi_name()` for completeness? 🤔
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
I tried to fix these in #12645 but clearly that hasn't carried over to docstrings 🤔
Since this is a new arg, we can enforce kwarg-only on it: ```suggestion *, headers=None, ``` (in all places) I think this is a good idea to avoid overly long positional argument lists
Perhaps I misunderstood Anssi's original intent somehow, but the fact that your filter expression uses INNER joins seems like you're maintaining the status quo at the minimum. @charettes I've just pinged you on IRC but if you've got some thoughts on this I'd like to hear them.
Include a trailing comma so that if more items are added later, so we don't need to modify this line again.
omit the blank line
We want to get rid of `repr` in `assertQuerysetEqual()`, can we change to the `self.assertSequenceEqual()`, e.g. ```python @classmethod def setUpTestData(cls): ... cls.c5 = Company.objects.create(name='99300 Ltd', num_employees=99, num_chairs=300, ceo=ceo) def test_range_lookup_namedtuple(self): EmployeeRange = namedtuple('EmployeeRange', 'minimum maximum') qs = Company.objects.filter( num_employees__range=EmployeeRange(minimum=51, maximum=100), ) self.assertSequenceEqual(qs, [self.c5]) ```
I think the `= true` is a byproduct of filter requiring a left and right hand side. This can be fixed when that restriction is removed via filter/expressions.
```suggestion if val is not self._missing_key: ``` Can you rebase and check other methods? they should be synchronized with sync variants.
Shouldn't django allow lazy-evaluation function as default value? (Calculate the default value as needed)
I think @chicheng means doing the equivalent of: cache.get_or_set('some-timestamp-key', datetime.datetime.now)
```suggestion await self.aadd(key, default, timeout=timeout, version=version) # Fetch the value again to avoid a race condition if another caller # added a value between the first get() and the add() above. return await self.aget(key, default, version=version) ```
```suggestion return await self.aget(key, version=version) is not self._missing_key ``` Please check all new methods.
We're using PEP 257 verbs for new code "Return ..."
See the messages for the methods above and add them these here too
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
Ah, sorry. Misread these. One gets the quarter number, the other gets the first month of the quarter. Ignore me.
Chop this link.
`display_name` is missing, we want to raise a warning with `display_name`, not `%s`.
unique_together-> index? (or something more generic like unique|index_together
We can use `display_name` instead of `MySQL`. I would keep the previous wording, e.g.: ``` %s may not allow unique CharFields to have a max_length > 255. ```
We should update `id` to the `mysql.W003`. Please update also `docs/ref/checks.txt`.
This won't work when `empty_aggregate_value` is `NotImplemented`.
I thought `empty_result_set_value` was meant to be a literal or whatever you'd pass to `Value` ```suggestion empty_result_set_value = value = getattr(arg, 'empty_result_set_value', NotImplemented) if empty_result_set_value is NotImplemented: raise arg_sql, arg_params = '%s', (empty_result_set_value,) ``` Or alternatively ```suggestion empty_result_set_value = getattr(arg, 'empty_result_set_value', NotImplemented), () if empty_result_set_value is NotImplemented: raise arg_sql, arg_params = compiler.compile(Value(empty_result_set_value)) ``` Which allows for better placeholder and `NULL` interoperability on Oracle which might have been the reason `Query.empty_result_set_value = 'NULL'` instead of `None` https://github.com/django/django/blob/06f5c22ea5907295f2360dc83e17b89aa84ae2fe/django/db/models/expressions.py#L754-L770
```suggestion pass ```
You should use `self.connection.set_operators['union']` instead of `UNION` constant.
Also I think that `is_ref` will need to be handled in a special way. The reference will need to be resolved to inline the expression. This can be tested by with the following code ```python updated_count = UniqueNumber.objects.annotate( number_inverse=F('number') * -1 ).order_by('number_inverse').update( number=F('number') + 2, ) self.assertEqual(updated_count, 2) ``` In this case `number_inverse` will yield `is_ref=True` and `expr` will be an instance of `Ref` if I'm not mistaken.
response (no cap) unless you mean to write HttpResponse
I think `request` should be optional.
Or in some cases (e.g. CSRF) it's because we want to log the response under a particular non-default logger. But even in those cases, we never want to double-log a response.
What if we make `level` default to "info" or "debug" instead? That way if you call `log_response` on a non-error response you'd just get an info/debug log, instead of getting a confusing "module logger has no attribute None" error (or whatever the wording actually would be)
I'm omit the intermediate extra variable in favor of: ``` getattr(logger, level)( message, *args, extra={...}, exc_info=exc_info, ) ```
same thing here about assuming `is_active` exists and `not user.is_active` -- probably need some tests for that case.
Please don't make unrelated whitespace changes.
as above, state expected behavior in a docstring
You should be able to pass `is_active=False` to `create_user()`.
I'm almost sure the "smart" is not needed here. Just use force_text. However, do we know what type of encoding is expected here? If it is UTF-8 encoded string, we should use force_bytes instead.
You don't need to use `make_hashable()` for primitives: ```suggestion return hash((self.message, self.code, self.params)) ```
I noticed that we missed keys comparison, e.g. `exception_a` and `exception_b` are equal: ```python exception_a = ValidationError({'field1': 'field error', 'field2': 'err'}) exception_b = ValidationError({'field2': 'err', 'field1': 'field error'}) ``` we should fix this, maybe: ```suggestion if hasattr(self, 'error_dict'): return hasattr(other, 'error_dict') and self.error_dict == other.error_dict return sorted(list(self)) == sorted(list(other)) ``` a test is also needed.
We should take keys into account (like in `__eq__()`), so maybe: ```suggestion if hasattr(self, 'error_dict'): return hash(tuple(sorted(make_hashable(self.error_dict)))) return hash(tuple(sorted(self))) ```
We also have to provide `__hash__()` because without it `ValidationError` instances are not hashable anymore.
I think we can simplify this: ```suggestion def __eq__(self, other): if not isinstance(other, ValidationError): return NotImplemented if hasattr(self, 'message'): return ( hasattr(other, 'message') and self.message == other.message and self.code == other.code and self.params == other.params ) return ( hasattr(self, 'error_list') == hasattr(other, 'error_list') and hasattr(self, 'error_dict') == hasattr(other, 'error_dict') and sorted(self.messages) == sorted(other.messages) ) ```
We cannot make serial pk assumption: ```diff diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py index 8b54611010..ea68a105d6 100644 --- a/tests/model_forms/tests.py +++ b/tests/model_forms/tests.py @@ -1765,10 +1765,12 @@ class ModelMultipleChoiceFieldTests(TestCase): f.clean([c6.id]) def test_model_multiple_choice_field_validate_choices_called_properly(self): + c1 = self.c1 + class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField, TestCase): def validate_choices(self, queryset, field_name, selected_choices): self.assertIsInstance(queryset, models.QuerySet) - self.assertQuerysetEqual(queryset.order_by('id'), [1], lambda a: a.id) + self.assertSequenceEqual(queryset, [c1]) self.assertIsInstance(field_name, str) self.assertEqual(field_name, 'pk') self.assertIsInstance(selected_choices, frozenset) ```
Maybe `**kwargs` instead of `subindex=None, attrs=None`.
```python self.assertHTMLEqual( field.widget.render('name', []), ( '<ul>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="entertainment">Entertainment</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="test">A test</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="third-test">Third</label></li>' '</ul>' ) % (self.c1.pk, self.c2.pk, self.c3.pk), ) ```
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
Can we use "0" instead? ```suggestion f.clean(["0"]) ```
Do you have a traceback or the name(s) of test that fails with the set(). I ran the sqlite suite with the set() without problems.
Why the obscure `dict.fromkeys` with a list comprehension that could be just `list(queryset)`? IMHO the clearest code that wouldn't require a new method for clarification would be... ```python for obj in set(queryset): ... ``` If you feel the need to clarify why the `set` is used, maybe be more verbose in the unittest and/or commit message and squash the commits into one neat commit.
@tchaumeny reverted fa534b9 here.
If `formfield.queryset` is already filtered both the outer query and the subquery will have this filter applied which is unnecessary ```suggestion Exists(formfield.queryset.model._base_manager.filter(complex_filter)), ```
Do we need to use a dict? It seems unnecessary complicated. Model classes that we pass in the keys must match the base models from querysets. We also don't protect against incorrect values e.g. ```python queryset={ Animal: Bookmark.objects.all() } ``` I would use a list/tuple instead and raise an error when a queryset for the specific model is already resolved, e.g. ```python for qs in querysets: ct_id = self.get_content_type(model=qs.query.model, using=qs.db).pk if ct_id in custom_queryset_dict: raise ValueError(...) custom_queryset_dict[ct_id] = qs ``` We should also add a new argument (maybe `querysets`) because it's misleading to pass list of querysets in the argument called `queryset`.
Ah. It is because we are pre-populating `self.records` before the `yield` in the context manager. Changing to `defaultdict` means that the key only gets added after when the context manager is exiting and we do `self.records[name].append(end_time)`. This means that nested uses of `time_keeper.timed()` - as we do in the database setup -- end up being out of order.
I think this should be instantiated by the runner, rather than a global instance. Otherwise multiple runs in the same process share state (imagine a script that calls `call_command('test')` in a loop).
```suggestion new_record = '%s took %.3fs' % (record, record_time) ```
Yes this would be a good idea
Should we name this `print_results` or move the `sys.stderr.write()` call outside? (I don't know if there would be a use for returning the generated text for something other than printing it out.)
IMO this is not a proper fix because `CustomPK` doesn't appear in a `FOR UPDATE OF` statement, so this can cause a data loss. Both models should be included.
I wouldn't use so many intermediate variables, e.g. `self.assertEqual(qs.update(another_value='foo'), 3)` seems fine. Also, you might include the tests that already pass on master in a separate commit so it's more clear exactly what's fixed.
For test doc strings, rather than "Test X" I try to describe the desired behavior: `A ValueError is raised when the incorrect object type is passed to a query lookup."
Generally we don't include the ticket numbers unless the issue is an obscure one that benefits from additional context that the ticket provides. If so "Sentence.... (#19513, #18580)." is the usual format
If I understand correctly a `FieldError` should be raised in this case? You can use `self.assertRaisesMessage` to assert it's the case.
The idea is that `InlineModelAdmin` is always used with a `ModelAdmin`, so we don't need to include the files again.
Use a single quote.
Yes, I know. I'll leave it to Aymeric for a second opinion.
And there: ``` work_file = os.path.join(self.dirpath, '%s.c' % self.file) ```
Both `keys()` calls are unnecessary, `dict.__iter__` yields keys. Also not sure why the `filter(None, ...)` is required.
In the current state, it's not reusable for other lists of expressions, so I would rename it to the `IndexExpressions`
That looks awesome @hannseman 💯 🏅 Regarding `django.contrib.postgres.indexes.OpClass` I guess we could add a `IndexedExpressionWrapper.register_wrapper` and have `django.contrib.postgres.apps.PostgresApp.ready` register `OpClass` to avoid coupling there.
This seems out of place. Is this branch really specific to MySQL? Is there a way we could avoid the `Col` import in the first place.
I think that most of the expression special casing and resolving should be done at the `Index.create_sql` level. The only purpose of `ddl_references` is to hold references to identifiers and allow renaming if necessary, it shouldn't have any knowledge about `django.db.models` abstractions.
You want to avoid altering `self` here as subsequent calls will reuse this attribute even if this branch's conditions don't match.
stacklevel 2 isn't useful when the warning is raised for OneToOneField. Ideally we could have stacklevel=3 for that case to give `question = models.OneToOneField(Question)` instead of `super(OneToOneField, self).__init__(to, on_delete, to_field=to_field, **kwargs)`.
The easiest solution might be to duplicate the warning in `OneToOneField`.
Sounds okay. The warning should be updated to say something like "Pass to_field as a kwarg instead of as an arg."
Thanks for the clarity, Tim :-) In that case, I think we may as well still go ahead and provide the deprecation shim and warning that we are able to provide (for `ForeignKey(SomeModel, 'to_field')`, which is likely much more common) by shortening this line to just `if not callable(on_delete)`. And we'll just have to rely on a backwards-incompatibility note in the release notes (that you should no longer pass `to_field` positionally, and you can pass `on_delete` as the positional second arg) to help anyone who is doing `ForeignKey(SomeModel, 'to_field', on_delete=models.WHATEVER)`.
Could be useful to say `Pass to_field='{2}' as a....` and add `on_delete` to the format
What values would this condition have a different outcome than the current one? `is_active or self.allow_inactive_users or is_active is None`
I'd make this a separate test and then you can decorator the test method instead of using `with ....`.
Could omit the `email_field_name` variable and inline `UserModel.get_email_field_name()` instead.
Use `self.username_field` instead.
Not sure it makes a difference but before it looks like we got `form=None` in the context.
Wrap docstring at 79 chars
This test seems correct. I think the class (or this method) docstring should call out the exception case.
URL should be capitalized
You don't know what a docstring is? Trying googling "python docstring".
Sorry, was thinking of something else.
Reduce to 20% of the lines and avoid multiple updates to the set: ```python return {loader.get_dirs() for loader in self.loaders if loader is not None} ```
Please don't change all the other unaffected lines.
Seems okay to me. I guess the alternative would to vary the message based on OS. Not sure that complexity is required though.
This test is problematic on Windows: ``` ====================================================================== FAIL: test_notafile_error (template_tests.test_loaders.FileSystemLoaderTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\template_tests\test_loaders.py", line 266 , in test_notafile_error self.engine.get_template('first') AssertionError: "Is\ a\ directory" does not match "[Errno 13] Permission denied: u'c:\\Users\\Tim\\code\\django\\tests\\template_tests\\templates\\first'" ```
Oh, right, of course; it's because of the default behavior of FS loader to look back at the engine's dirs.
The easiest solution might be to duplicate the warning in `OneToOneField`.
stacklevel 2 isn't useful when the warning is raised for OneToOneField. Ideally we could have stacklevel=3 for that case to give `question = models.OneToOneField(Question)` instead of `super(OneToOneField, self).__init__(to, on_delete, to_field=to_field, **kwargs)`.
Sounds okay. The warning should be updated to say something like "Pass to_field as a kwarg instead of as an arg."
Thanks for the clarity, Tim :-) In that case, I think we may as well still go ahead and provide the deprecation shim and warning that we are able to provide (for `ForeignKey(SomeModel, 'to_field')`, which is likely much more common) by shortening this line to just `if not callable(on_delete)`. And we'll just have to rely on a backwards-incompatibility note in the release notes (that you should no longer pass `to_field` positionally, and you can pass `on_delete` as the positional second arg) to help anyone who is doing `ForeignKey(SomeModel, 'to_field', on_delete=models.WHATEVER)`.
Could be useful to say `Pass to_field='{2}' as a....` and add `on_delete` to the format
"Return" instead of "Returns"
`response_class = StreamingHttpResponse if stream else HttpResponse`
Please remove the deprecated parameters from `stream()`: context_instance, current_app, dirs, dictionary. Similarly for `stream_to_response()`.
I think we can remove this sentence.
It probably makes sense to remove the helper methods that are now used only once.
It also says: > It may also be known that project A follows semantic versioning, and that v2 of ‘A’ will indicate a break in compatibility, so it makes sense to not allow v2: I guess the real question is then whether `sqlparse` really uses semantic versioning, and since it's "Development Status :: 5 - Production/Stable" at 0.2.4 potentially not. You're probably right to err this way, let's leave it as-is. :)
`tests_require` is deprecated in [setuptools](https://setuptools.readthedocs.io/en/latest/setuptools.html#new-and-changed-setup-keywords) since [41.5.0](https://setuptools.readthedocs.io/en/latest/history.html#v41-5-0) (27 Oct 2019). (It is also being unused by Django anyway.)
Prefer a set to a tuple here and order elements alphabetically.
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
1. Given that we have `pylibmc` below, is `memcached` the right key here? 2. Given that there are choices here, is this something we want to have an opinion on? (It doesn't seem as clear to me as e.g. databases.)
`return self.get_database_version() >= self.features.minimum_database_version`
add docstring: Return a tuple of the database's version.
My intuition would be to make this raise `NotImplemented` instead.
I think it's preferred to wrap this at 79 chars: ``` f'{self.display_name} {min_db_version} or later is required ' f'(found {db_version}).' ```
Creating two objects should not be necessary. ```suggestion ```
This needs an order_by clause so that the results are guaranteed to come back in the right order.
```suggestion now = datetime.utcnow() a = DBArticle.objects.create() ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
We can reuse existing objects.
While my tests suggest that iterating a set is ~8% slower in this case, it is a negligible difference once you look at the whole `_expire_cache` function.
to minimize size of try: ``` try: m2m = kwargs['many_to_many'] except KeyError: pass else: warnings.warn(.... ```
Keeping the try block limited to just the code you expect to throw the exception is a good practice. It prevents a situation where there's some other bug than what you expected. For example, if `warnings.warn(` somehow threw a `KeyError` and it was in the try block, you would unexpectedly hide that bug.
The approach you've taken here is: - Cache the result of get_fields() for a specific set of arguments - look up a name in that list; - Raise FieldDoesNotExist if the name is not found. The other obvious approach I can think of would be: - Cache a list of _all_ fields - Look up the name in that list - Raise FieldDoesNotExist if the name is not found - Raise FieldDoesNotExist if the field doesn't have the requested properties. I'd be interested to see the "memory vs speed" tradeoff for these two approaches.
True about the ML. Regarding the naming for `related_objects/related_m2m` vs `reverse_rel/reverse_m2m`, that's a new API so there isn't historical names to preserve (unlike `many_to_many` vs `m2m`), we just need to pick the best names to represent the relations.
1 line too many.
might as well use `setdefault` in the test as well
this line should be: `def __init__(self, *args, **kwargs):`
There is no need to provide a value for `max_pages_num` - I think it should be calculated automatically: ```python (self.on_each_side + self.on_ends) * 2 ``` Otherwise developers can provide values that are incompatible with each other...
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
Maybe? ```suggestion def _field_non_database_attrs(self): ```
> `how I would overwrite the non_db_attrs in the sqllite3 case` This doesn't need to be overwrite for SQLite when we move it to the field, because custom fields as `EnumField` from `django-mysql` will be able to remove `"choices"` on their own from `EnumField.non_db_attrs`, so we could add `"choices"` to the `Field.non_db_attrs` for all databases. > within the _field_should_be_altered function, I need to reference the non_db_attrs. There are both an old_field and a new_field in this function, would I pick one of these in order to be the non_db_attrs or would it be better to loop through them separately (unsure if that makes sense) We should do this separately because a field type can change.
Are both branches tested here? Otherwise this looks good.
Could we change this (and other similar places that check for string references) to directly call lazy_related_operation. The idea is that the calling code doesn't need to care if the reference is by string, and it doesn't need to care if the referenced model is already loaded. In all cases, it is OK to just call lazy_related_operation.
Wouldn't be required if you subclasses `IntegerField`.
This doesn't seem correct as `SimplePoFileTests` no longer has any tests in it so now this subclass doesn't do anything.
Does it work if you use `override_settings` for this too? That would be cleaner.
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
an app containing a locale folder
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Водка')) ```
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
I moved a cleanup part to a separate commit.
Similarly, I don't see much advantage to creating indirection with a method.
`resolve_expression_parameter` maybe? You're not really dealing with combinables here (even though they are also combinable), so just go with expression based names I think.
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
these aren't necessary, you can pass `StringIO`s for `stdout` and `stdin` to `call_command` instead. there are lots of examples in existing tests e.g. https://github.com/django/django/blob/master/tests/i18n/test_compilation.py#L41
Aha I found what you should be using for both: `django.utils.captured_stdin` and `django.utils.captured_stdout` 😉 You could also open a second PR removing the hack from `createsuperuser` and change its tests to use `captured_stdin` 👍 Presumably
```suggestion def test_stdin_read_inline_function_call(self, select): ```
Smart... This only works because `shell.py` does inner imports, but that does seem unlikely to be refactored
I think we can chop it.
I think using a semantic name would help here, e.g. `lookup_kwarg_null`
I don't think you can depend on a None choice being defined for a nullable field, necessarily. I don't think you need to make a change here.
this hanging indent is intentional, you'll see it throughout Django
how about: `*[x for x in self.field.flatchoices if x[0] is not None]):`
I've noticed that `None` from `flatchoices` should update `Unknown` not `All`. I fixed this.
It's mostly consistent with other copies in the same file, but `clone =` and `copy =` is also used. I think it's probably better to use `copy`.
I guess the only disadvantage is the possibility to shadow the Python's built-in `copy`. If it's used elsewhere in the file, I'm okay with it.
The problem here is that you can't just use `Value('')` for the default. If you're doing `GREATEST(date_field, other_date_field)` then coalescing a date type with a char type is going to produce an error. The type itself will probably have to accept a default. ``` sentinel = object() def __init__(self, *expressions, **kwargs): ifnull = kwargs.pop('ifnull', sentinel) if ifnull == sentinel: raise ValueError('ifnull is required') if ifnull is None: # user has asked NOT to use coalesce else: self.ifnull = self._parse_expression(ifnull) ``` And then you would use `Coalesce(expression, self.ifnull)` in the coalesce method, or completely skip calling the coalesce method if `ifnull is None`. This is just one idea, but probably the best one I have right now. I don't really like forcing a user to provide an `ifnull` though, because it feels like we're disadvantaging the user. Another idea would be to use a backend feature. Something like `greatest_least_uses_nulls`, and then the tests could switch on that feature flag to provide different test results. I'd probably like to get a rough consensus on which way to go here.
Is this check correct? A `Coalesce` can still result in a null value (if all of its arguments are null), so even if the expression is already a `Coalesce` ISTM it needs to be wrapped again (or have `Value('')` added to the end of its `source_expressions`, but just wrapping in another `Coalesce` seems cleaner).
Defining `__init__()` to specify a default `output_field` is required until we re-arrange `runtests.py` to avoid importing settings dependant modules before calling `django.setup()`.
Here we also should call `super` and not copy-paste code
Sounds, good thanks for giving this ticket a shot by the way. It's a tricky problem with a few edge cases but you'll certainly learn a lot of things along the way.
Hey guys, `index_together` and `unique_together` have been fixed before in this BR: https://code.djangoproject.com/ticket/24757
What about indexes and constraints based on `expressions`? For example: ```python Index(F('author'), F('title'), name='author_title_index') ```
This formatting change is not related with a bug fix, please revert.
ATM is -> than with
use a single line here -- lines up to 119 characters are preferred when it helps readability.
What about using an `elif isinstance(m2m_relation, ManyToManyRel)` clause instead and issuing a `continue` in an `else` branch? This looks more safe in regard to third party fields that might exposed them as `many_to_many = True`.
fixme -> TODO
chop blank line
I see what you mean - with tests being run so often it's only a matter of time. To resolve it we can call `random.seed(seed + i)` in the for loop before the string is created. And set `seed = 42`(or some other int) outside the loop. This way we'll have a set of known good random strings that aren't the same. Since if they are the same the zlib compression will detect the duplication and compress them efficiently, since the messages are stored in a single cookie which is processed all at once. BTW I tested with the initial `seed =42` and it passes the messages tests.
New PR #13800 with tests
(And round-tripping of the messages is already tested in other tests)
I guess we could remove the mention of Oracle and just say "for databases which limit..."
I wonder if 25 should be defined in the [SQL constants module](https://github.com/django/django/blob/master/django/db/models/sql/constants.py)? I am afraid changing 25 in the code might not be changed here, so the test would silently become obsolete.
We might as well lose the unnecessary string formatting while we're at it: ```suggestion old = repr(list(reversed(get_format_modules()))) new = repr(list(reversed(get_format_modules()))) # second try ```
I think this can go in `NewDatabaseTests` rather than a new class.
Try to minimize the test that demonstrates the regression. I think this part isn't important -- assigning a value when creating the model should work just as well.
You can remove the unnecessary assignment here: ```python return _format_modules_cache[lang] ```
basestring isn't Python 3 compatible. Please use `six.text_type` instead.
field.remote_field here too (you may squash your commits when updating, thanks)
Isn't there a risk of this doing a database query? That doesn't seem acceptable. Can't we first check the plain FK attribute (i.e. `field_id`), and only check further if it is `None`? If it's not `None` then clearly the assigned object had an ID. If it is `None` then we just need to see if there's an unsaved object in the "main" attribute or not.
`Grab` -> `Use`.
I see, thanks!
```suggestion "%s() prohibited to prevent data loss due to unsaved " "related object '%s'." % (operation_name, field.name) ```
No, I have only reviewed the code on it's own, haven't tried it yet, sorry.
You could also just raise a `ValidationError` should the site's domain and the entered domain not match or make the exclusive.
`clean` is not only for validation, but also for data modification in a form.
The form class is configuration too, is it not? You can group class attributes using a blank line, but this attribute is inherited from `BaseModelAdmin` where it is not separated. It just seemed odd.
drop the new line please
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
we're now using pep8 style for docstrings "Validate whether ..." "return None", "raise ValidationError", etc.
Wouldn't it be a bit more helpful for this error message to specifically note that the module with the given path couldn't be imported? "Invalid" is a very vague term, which could mean all sorts of things - it seems unhelpful to silence an `ImportError` and replace it with a much vaguer message.
`unordered_list` handles nesting which you don't seem to need here. A pedestrian implementation with `format_html` would be more readable: ``` help_items = [format_html('<li>{}</li>', help_text) for help_text in help_texts] return format_html('<ul>{}</ul>', ''.join(help_items)) ``` Furthermore, this implementation marks the result as safe, which is useful here. (Truth be told, I'm reluctant to use template tags or filters in Python code, for ideological reasons.)
has a -> is of a
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
Constructing the entire string within the as_sql method departs from how other functions work. Is it possible to do something like: ``` class BaseCaseExpression(Func): function = None template = 'CASE %(simple)s %(conditions)s ELSE %(default)s END' ``` Then build up the dict required to fill in that template, and construct/return at the end? It may flow nicer, and allow 3rd party backends to modify the template without overriding the entire method.
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Ah! Of course, sorry I missed that.
Please use single quotes.
They can only be decoded if these bytes were previously encoded in this encoding.
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
move this to an else block in (try/except/else)
`repercent` is a confusing name, maybe `repercent_broken_unicode`? Also it needs a docstring with pointers to the RFC etc.
suggested wording: ``` Strip quotes off of quoted table names to make them safe for use in index names, sequence names, etc. For example '"USER"."TABLE"' (an Oracle naming scheme) becomes 'USER"."TABLE'. ```
Chop blank line.
could you use the same doc string style as above? ``` """ ... """ ``` Also should be "Transforms... " to match coding style guidelines.
Please remove this unrelated change.
This must also take the sign into account. What about: ``` python max_length = self.max_digits + 1 # for the sign if self.decimal_places is None or self.decimal_places > 0: max_length += 1 # for the dot ``` We could also make the sign check conditional based on `min_value` and `max_value` but it would be a mess.
The recommendation is to double indent in this particular case so as to avoid visual confusion with the contents of the block.
```suggestion new_field.get_internal_type() in ('CharField', 'TextField')): ```
nitpicking: could you swap these two checks: `old_default != new_default and not self.skip_default(new_field)`
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
Maybe `null_actions` for consistency with `post_actions`? And move it to where we init `actions` and `post_actions`? L581.
I think it would be better to use the same parameter formatting style as the `save()` method below.
import should go at the top of the file unless it causes a circular import
Chop blank line.
You can probably use `assertSequenceEqual` here which might be a bit nicer.
`add()` accepts IDs so we can simplify this, e.g. ```python ... user.save(using=self._db) user.orgs.add(*orgs.split()) ```
Nitpick, you could have used `MAX_GET_RESULTS` here to avoid breakage if we ever change this constant.
This needs an order_by clause so that the results are guaranteed to come back in the right order.
```suggestion now = datetime.utcnow() a = DBArticle.objects.create() ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
you can use `a` here again.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
In Thailand it’s customary to use the [Thai solar calendar](https://en.wikipedia.org/wiki/Thai_solar_calendar) system (as it’s the official legal calendar in Thailand). Dates and months are the same as the common Gregorian Calendar, but years are in Buddhist Era instead of the Christian/Common Era. Just add 543 to the year number when displaying, and subtract 543 from the year number when parsing.
Is it possible to convert year type? (e.g. 2006 &rarr; 2549)
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
, or None...
```suggestion with with self.subTest(tag), self.settings(LANGUAGE_CODE=tag): ```
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
I think we can remove `tearDown()` and `setUp()` and use ```python with translation.override(language): ``` instead of `activate()`.
seems like a helper method to get the attachment path would save some repetition
@akulakov `passed_check` is to check if list is not empty. if it is not empty, method will return no error, otherwise error will be returned (`[] if passed_check else [W020]`).
`not statement` is used several times above, so need to be consistent in code style.
@MarkusH - that looks good to me.
@coldmind With the current code, `passed_check` will be `True` if `settings.ALLOWED_HOSTS` IS empty. That is backwards. `passed_check` should be `True` if `settings.ALLOWED_HOSTS` is NOT empty.
Since this is just a type check which should apply to all environments, not just production ones, it doesn't need the `deploy` flag
1: I'm definitely happy with this. I'm not sure why I didn't go for it myself. 2: Fine by me, I don't feel strongly.
`quote_name` is a temporary variable that's used only once, therefore I think we can remove it and use `schema_editor.quote_name` directly, i.e.: ```python 'name': schema_editor.quote_name(self.name), ```
```python hanging = ( indentation, has, a, newline, after, opening, bracket, ) ```
I think you can use `django.utils.deconstruct` to decorate the class, the `path` argument can be passed explicitly. Since Django 2.0+ is Python 3 only, you can use keyword-only arguments with `*, arg1=None, arg2=None`.
`path` is unused, so we can use a `_` instead.
We allow lines up to 119 characters if it helps readability, or we use hanging indent like this: ``` return "<%s: %s>" % ( self.__class__.__name__, ..., ) ```
no `u''` prefixes on strings please
return directly, no need for `path` variable.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
I think we are missing the `call_command()` here.
`has_select_for_no_key_update` -> `has_select_for_update_no_key`
Please add trailing comma.
DatabaseError is raised if a ....
I think that: ```python return 'FOR UPDATE%s%s%s' % ( ' OF %s' % ', '.join(of) if of else '', ' NOWAIT' if nowait else '', ' SKIP LOCKED' if skip_locked else '', ) ``` is more readable.
If ...., the locked row is skipped resulting in Person.DoesNotExist.
Use single quotes.
This can be removed because we will get a field error from `Form.clean()`.
I don't use login rate limiting myself at the moment, but I can see that people might want to use more sophisticated schemes (e.g. exponential delays). So I think it would be good to allow people to opt-out of this feature.
Please use assertRaisesMessage to verify this is the ValueError we expect.
Please don't make unrelated whitespace changes.
We can raise a single error.
Same style as above.
I envisioned something like this: ``` python content = None with open(path, read_mode) as f: try: content = f.read() except UnicodeDecodeError: # If mimetype suggests the file is text but it's actually binary, # read() will raise a UnicodeDecodeError on Python 3. pass # If the previous read in text mode failed, try binary mode. if content is None: with open(path, 'rb') as f: content = f.read() mimetype = DEFAULT_ATTACHMENT_MIME_TYPE ```
I guess this means that the line below could be replaced when only Python 3.5+ is supported. It would be nice to be more explicit about that.
chop blank lines
_Ideally_, unless you are testing a failure condition, you don't want tests to result in an error. So the test case which ensures that an error is raised when the target directory does not exist will be the one in which that error should occur. In this case, the test should ensure that running `$ ... startapp app directory/` works successfully given that everything else is in place. Consider this hypothetical scenario during a refactor: - Code is moved around such that `if not os.path.exists(top_dir): raise Error` occurs before `self.validate_name` - `.rstrip(os.sep)` is deleted. The test case will still pass but the command will fail at that point.
Can we also assert that `startapp` created some files?, e.g. ```python def test_trailing_slash_in_target_app_directory_name(self): app_dir = os.path.join(self.test_dir, 'apps', 'app1') os.makedirs(app_dir) _, err = self.run_django_admin(['startapp', 'app', os.path.join('apps', 'app1', '')]) self.assertNoOutput(err) self.assertIs(os.path.exists(os.path.join(app_dir, 'apps.py')), True) ```
I think it's enough to check `apps.py`. Also, `assertEquals()` is a deprecated alias of `assertEqual()`.
Chop blank lines.
```suggestion self.assertIs(app_dir.joinpath("apps.py").exists(), True) ```
The rest of the patch is using f-strings. Hopefully we can make a final decision on that in #13214 soon. `original_settings_dict` feels a bit clunky. Also note that unpacking a dictionary works like a shallow copy, so modifying the value of the `'TEST'` sub-ditctionary will affect the original. Perhaps this would be simpler: ```suggestion original = self.connection.settings_dict user = original['USER'] password = original['PASSWORD'] return { **original, 'USER': f'{user}_{suffix}', 'PASSWORD': f'{password}_{suffix}', 'TEST': { **original['TEST'], 'USER': f'{user}_{suffix}', 'PASSWORD': f'{password}_{suffix}', }, } ```
It's rather rare that folks have the Oracle database engine installed locally, so it crashes because `expdp` and `impdp` are not available.
You should try to reuse `connection._connect_string()`.
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
To keep the diff a bit cleaner, I wouldn't make this unrelated whitespace change.
You could replace the `resolve_method` variable with `elif getattr(resolver, 'resolve', False)` here.
Prefer single quotes unless the string has single quotes in it.
You're still iterating over `resolver.url_patterns`. Another URL resolver might not have an `url_patterns` attribute.
I would avoid cloaking the `resolver` variable, I like your `sub_resolver` naming above.
For future reference, we are using PEP 257 style verbs for new docstrings "Format...", etc.. Also, it's nice to be consistent with trailing punctuation.
I would keep this on multiple lines. IMO, readability is better with the multiline version.
Can we pass it in params? ```suggestion """, [self.index_name, table_name]) ```
Would it make sense to exclude check constrains from this query and get rid of the `elif` blocks? ```suggestion c.table_schema = kc.table_schema AND c.constraint_name = kc.constraint_name AND c.constraint_type != 'CHECK' AND ```
If you're slicing `[1:-1]` just to remove backticks (`` ` ``) around column names, I think you need to find some other way. While working on https://github.com/django/django/pull/11452, I tried this function to get the `JSON_VALID` constraint for introspection. After some debugging, I found out that it gets sliced into `son_vali`. Perhaps using ``.strip('`')`` is enough, but I'm not really sure...
I think we can remove `unqote_name` and always add `token.value[1:-1]`.
could move this to the previous line
Having `not full_path or full_path` in the middle of this expression is extremely confusing. Could you add parentheses instead of relying on operator precedence? `(a and b) or (c and d)` takes significantly less effort to parse than `a and b or c and d`.
Won't `symlink_path` and `original_path` be removed automatically as part of the cleanup? `tempfile.TemporaryDirectory` says "On completion of the context or destruction of the temporary directory object the newly created temporary directory and all its contents are removed from the filesystem."
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Водка')) ```
I think we are missing the `call_command()` here.
This docstring doesn't have any value, IMO.
You can reuse `CountryInlineAdmin` and `StateAdmin` instead of defining extra classes: ```suggestion ``` Add `get_formset_params()` to `StateAdmin`.
This can be single-lined. Please use `tuple`.
`obj=None` -> `obj`
There should also be an assertion for the output of the new `get_inlines()` method.
The optimization should also be disabled `if not connections[db].features.supports_foreign_keys`.
I think `base_mgr` would be more clear/consistent with the rest of the code
I would do: ``` def check_and_update_obj(obj): if not isinstance(obj, self.model): raise TypeError("'%s' instance expected" % self.model._meta.object_name) if obj._state.adding or obj._state.db != db: raise ValueError("%r instance isn't saved. You must save the object first." % obj) setattr(obj, self.content_type_field_name, self.content_type) setattr(obj, self.object_id_field_name, self.pk_val) ```
This exception message is different from that in `related.py` though the logic/intention surrounding it seems to be the same. Is this intentional? (FWIW, I find the message in `related.py` to be clearer)
Same as below, you should be able to call `self.using()` directly.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
Given that the index is named `title_lower_id` this `LOWER` check could check against that as well as `lower(xxx)` -- please rename the index so there is only one match for `LOWER` (same for `TITLE`)
I don't think we need to have a strict policy on `/` vs. `.joinpath()`. I'd prefer `/` but when readability hurts we can also use `.joinpath()` :shrug:
_Ideally_, unless you are testing a failure condition, you don't want tests to result in an error. So the test case which ensures that an error is raised when the target directory does not exist will be the one in which that error should occur. In this case, the test should ensure that running `$ ... startapp app directory/` works successfully given that everything else is in place. Consider this hypothetical scenario during a refactor: - Code is moved around such that `if not os.path.exists(top_dir): raise Error` occurs before `self.validate_name` - `.rstrip(os.sep)` is deleted. The test case will still pass but the command will fail at that point.
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
Do we need these changes? :thinking: `Path.absolute()` raises `FileNotFoundError`, so why not catch it in `watch_for_translation_changes()`, e.g. ```python for path in directories: try: absolute_path = path.absolute() sender.watch_dir(absolute_path, '**/*.mo') except FileNotFoundError: logger.debug('Skipping watching file %s as it cannot be resolved.', path, exc_info=True) ```
Great, thanks! I will merge #11590 and rebase this PR :+1:
You'll want to use `force_text` here.
built-in imports like unittest should go above django imports, separate by a newline. e.g. ``` from __future__ import unicode_literals import unittest from django ... ```
This should be replaced with `@isolate_apps()` as done in a08fda2111d811aa53f11218fa03f3300dfff4cb.
Since most of the logic related to field referencing will be used by `django.db.migration.state` I think it would make sense to fold/merge `django.db.migrations.operations.utils` into `django.db.migrations.utils`.
Might be worth moving theses utils to `django.db.migrations.utils` instead since they are used outside of `.operations` now.
I guess I would say something like "The inner CharField is missing a max_length."
It should be fine to check the complete warning similar to: https://github.com/django/django/blob/4d60261b2a77460b4c127c3d832518b95e11a0ac/tests/check_framework/test_model_field_deprecation.py#L17-L23 I forget if there was a reason the existing test doens't use that approach.
No, at least not part of this PR.
No trailing comma (see also 83a36ac49a98d5d8801ed8428612e9a56aeb8699).
I'm thinking it might be better to use the approach in `test_caches.py` rather than repeating the error message here twice.
Can you use `['indexes']` here? If not, the list comprehensions in the next lines have a `not in None` and will fail.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
Indexes are not constraints, generally.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
How about omitting it until we have a use case? That will save writing tests and docs for a theoretical feature. :-) From a readability point of view, writing a `re_path()` that mixes regexes and converters in the string, and then has to initialize and pass converters in the URLconf sounds nasty and not something to encourage!
I'm going to be a +1 to just dropping `converters`
I think the formatted pattern should be wrapped in quotes. "Your URL pattern '{}' uses..".
I would revert this change. We want to add a system check so this seems redundant.
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
They can only be decoded if these bytes were previously encoded in this encoding.
move this to an else block in (try/except/else)
Interesting! I guess we could implement it at some point, but that seems like a fair amount of work.
Nope. In the second case `sub_message['changed']['fields']` is fetched again. This could certainty be made less clunky though as `sub_message['changed']['fields']` is referenced 4 times in 6 lines...
This seems incorrect -- we aren't using any data from the formset.
Looks like in English the period is inside the quotes (see grammar sites).
Yes, consistency matters :-) Maybe @timgraham can bring his expertise here.
please revert whitespace addition
We can reuse `self.user`: ```suggestion request.user = self.user ```
```suggestion Question.objects.create(question='Not a question.') ```
Please put the test in `AdminActionsTest`.
Implementation looks okay but should still check the response here and check that the "protected" page is displayed.
No need to use `get_user_model()` (don't think any of the other tests do that?), I think.
Oh, not sure. I'm not a micro-optimizer. :-)
@sjoerdjob let's remove the `db` optimization to keep the patch concise. On the other hand I still think we should use `zip`.
Is this just a stylistic thing? If so, I don't see much advantage to it.
I think it should be `model._meta.local_concrete_fields`.
I think we can move `pks` into `self.filter()`, e.g. `self.filter(pk__in=[obj.pk for obj in batch_objs])`. I do not see much value in creating a temporary variable here.
The word `generally` doesn't add any value in my opinion.
I'm not certain `Warn` is the best word now that this is an `Error`, but I'm not sure how to phrase it instead.
Since `LOCALE_FILENAMES` defaults to an empty list I'd suggest you make `domains` unconditional append it to `['django']`.
I think I'd make this an `Error` - I don't think translation works at all if this is wrong.
```suggestion if field_name == '_order': field_name = self.options.get('order_with_respect_to', field_name) ```
FYI, `errno.EPERM` maps to errno 1 so this is the errno we will check for instead of an integer like we originally submitted in the PR.
@djackson-saa and I investigated the `PermissionError` and it was only added to Python in version 3.3 as a subclass of `OSError` and **not** available in Python2.7. In order to make this Python2.7 compatible, we are going to change the class we are excepting to `OSError` to cover all bases.
Ok, will do.
I think it would be safe to access `e.errno` directly in this case. The `winerr` attribute is only present on Windows platform hence the `getattr()`.
OSError will happen... os.rename()
Fair, that's me misunderstanding what the tag actually does. Looks great then!
chop trailing ", " in list
please multiline these strings so they aren't longer than 120 chars. ``` row_html = ( '...' '...' ) ```
As above, leave the docstring and change to deprecation to 2.0.
I think you can use `with self.assertRaisesMessage` equivalently here (context manager form is much easier to read IMO)
Feels like this should be handled at the database backend level.
It would work but it would be a kind of implementation detail abuse since `value` is not an SQL identifier but an expression. This whole method should likely live on `connection.ops` instead.
Can `schema_editor.quote_name` be used here instead? ```suggestion schema_editor.quote_name(value) if isinstance(value, str) else value ```
The fact you have to special case `DefaultNow` makes it look like a code smell to me, this logic should be completely abstracted by whatever is allowed to be passed to `db_default`.
Maybe it should go in `django.contrib.mysql`...
I think we should add this check only if `enable_nav_sidebar` is enabled on any site and raise an error instead of warning :thinking:
OK. I'll adjust this now on that basis, so we can get it in this morning. Thanks both!
I was thinking about leaving it as a warning and disabling the sidebar when `request` is not provided, so about a soft requirement: - raise a warning (that will remain a warning in the future) if `enable_nav_sidebar`, e.g. ```python checks.Warning( "'django.template.context_processors.request' must be enabled " "in DjangoTemplates (TEMPLATES) in order to use the navigation " "sidebar in the admin application." id='admin.W411', ) ``` - disable a navigation sidebar (even in a template) when `request` is not provided.
This could work: it's only the `current-app`, `current-model`, `current-page` attribute values that are dependent on `request`, and for the index page app list they're always not set anyway, so it's only when the side bar is set that `request` is serving any purpose.
This line is horrible. 😄 Simon mentioned this in his review before but, maybe leaving up until the `and\n` as is and putting the new check on the next line, to keep the diff that bit smaller...? (I don't mind this as it is per se — whichever way we do it, it is long and horrible.)
Since `fan_since` is None at this point, the test cannot pass! Same below.
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
No brackets needed again.
This method implementation could be simplified by doing: ```python if on_conflicts == ON_CONFLICTS_IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflicts == ON_CONFLICTS_UPDATE: ... return result ... ``` This would also let you eliminate the `if-else` below and initializing `result` to `''`.
```suggestion def on_conflict_suffix_sql(self, opts, fields, on_conflict=None, update_fields=None, unique_fields=None): if on_conflict == OnConflict.IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflict == OnConflict.UPDATE: return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ', '.join(unique_fields or ()), ', '.join(f'{field}=excluded.{field}' for field in update_fields or ()), ) return super().on_conflict_suffix_sql(opts, fields, on_conflict, update_fields, unique_fields) ``` If we have `unique_fields` in the signature here, then it should also be in the signature of the super class, not falling back to `**kwargs`. As mentioned in https://github.com/django/django/pull/13065#discussion_r668635778 we should probably be quoting identifiers here properly too.
As far as I'm aware `unique_fields` should be required when `supports_update_conflicts_with_target` is `True`, so there is no need to use `unique_fields or ()`. Moreover, we should raise an exception when it's not provided.
```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ```
good point, this avoids my laziness on the ticket :)
Wouldn't be required if you subclasses `IntegerField`.
Oh, no, OK, the nextval will always return a different value. It's just that we might have gaps if one value is not saved.
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
I saw that you're now handling this at the database level. It makes more sense to me.
Also forgot to mention, I don't think I've seen many regex'es written this way before (using string constant concatenation and continuation lines), and I find it pretty neat.
My point wasn't the r prefix (I just copied that from above), it was moving the dash next to the close-bracket. But now that you mentioned it -- yes, the first and last (`'\.'` and `'\.?'`) need an r prefix, because without it the strings don't have a backslash in them and these expressions will just match anything. I think a test for this could use some invalid punctuation as the separator for the tld -- e.g. `http://unquoted~dot!`
This allows `xn----nx` and even `xn-----`. Are they valid? (edit: FWIW, my IceWeasel seems to think they are)
Forgot to mention earlier, but on first look I found `[a-z-' + ul` a little confusing because of the dash between two ranges that actually serves as a dash and not a range separator. I think it would be more readable as `[a-z' + ul + r'-]` (similar to how it is in `domain_re` above).
Every day I get to learn something new. Thanks.
"is_required=False and an initial value that's a file, renders..."
Drop the comma/space in `[FakeFieldFile(), ]`
TextInput -> Input? I suppose a `test_input.py` file would be better. I wasn't sure about the `test_no_trailing_newline_in_attrs` test -- it's meant to test a template rather than Python code -- probably I could have clarified that. `strict=True` isn't needed since the newline isn't being tested.
```suggestion self.assertFormError(response, 'form', 'field', 'invalid value') ```
Use `self.assertIs(wrapper.is_hidden, True)` since assertTrue passes for bool(value) is True.
I think we can move this under `try ... except`, e.g. ```python try: token, rest = parser.get_mailbox(addr) if rest: # The entire address must be parsed. raise ValueError nm = token.display_name or '' localpart = token.local_part domain = token.domain or '' except (HeaderParseError, ValueError, IndexError): raise ValueError("Invalid address '{}'".format(addr)) ```
Maybe shorter `# The entire email address must be parsed.`.
I think we can leave the list of exceptions.
Do we need to check if `token` is an instance of `Mailbox`? I couldn't find an example that needs this check.
master is only supporting Python 2.7 and 3.4+
For test doc strings, rather than "Test X" I try to describe the desired behavior: `A ValueError is raised when the incorrect object type is passed to a query lookup."
I would separate each `with` statement with a line break. right now it looks like a huge block of stuff.
`self.oc` doesn't appear to be used
As noted in https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style, we're not so strict about it in code.
Can we use custom `date_friended`? and check is it set properly on an intermediary object.
Annoying that `datetime.time` cannot be subtracted from each other to give a `datetime.timedelta`, so we cannot use `duration_microseconds()` as in `_sqlite_timestamp_diff()` below.
I don't think we need the `re_` prefix to the arguments? And perhaps `text` instead of `string` for consistency? We should also avoid coercing to `str` unless we need to: ```python In [1]: text = "This is some text" In [2]: %timeit str(text) 54.7 ns ± 4.28 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) In [3]: %timeit isinstance(text, str) 33.8 ns ± 0.106 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) ``` It might make the non-`str` case slower, but, unless I'm mistaken, we're expecting `text` to be `str` in the majority of cases. ```suggestion def _sqlite_regexp(pattern, text): if pattern is None or text is None: return None if not isinstance(text, str): text = str(text) return bool(re_search(pattern, text)) ``` As an aside, I wonder whether we can do something to compile and cache patterns? This could make a significant difference if the function is called for a large number of rows.
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Ah, sorry. Misread these. One gets the quarter number, the other gets the first month of the quarter. Ignore me.
Use single quotes consistently (could be done above and below also).
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
I'm always wary of putting assertions inside loops and if-statements because you're never certain they are executed. If you added a counter and an assertion that `count==1` after the loop, that would be defensive.
We can add `Foo.objects.create()` to ensure that primary key and sequence are still valid.
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
I would turn this into a docstring.
If I were writing these tests from scratch, I wouldn't use a separate `expected` variable everywhere (this is related to our preference for longer lines rather than a historical more strict adherence to 79 chars, I think).
I think `assertRaisesMessage` should work here and works on py2/3.
Possibly. In general we've been moving toward `SimpleTestCase` but I don't know if requiring it is worth the effort.
Make it a "private" method: `_initialize_signal_car` just to make it obvious it's not a test method.
Not sure I'd consider it "broken" since no one has reported a problem. As I mentioned, it could be bad/confusing for existing users if their timestamps are suddenly shifted when they upgrade Django, but I don't care much about the issue -- just suggesting it's time wasted if we come up with better APIs (like database defaults).
Did you see that `TimeField` uses `datetime.datetime.now().time()` and `DateField` `datetime.date.today()`? I guess there might be a discrepancy with using `timezone.now()` in some cases.
Since the ticket you referenced hasn't moved forward for 11 months, I rather see a fix for this issue here and a deprecation sometime in the future (maybe 1.9 if somebody does it), than having broken code for the next 2 or 3 releases.
Yea, that change doesn't make sense. Thanks for explaining timezones to me, Aymeric :wink:
The diff in MarkusH's above doesn't make auto_now(_add) timezone aware, it hardcodes them to be computed in UTC instead of using `settings.TIME_ZONE`, which doesn't make sense to me.
An error the database
And this: ```suggestion parameters = self._get_test_db_params(suffix) ```
New tests are failing on Oracle. I think we should avoid creating a test database, maybe by mocking `_create_test_db()` :thinking:
I'd chop this blank line since the } on its own line is providing whitespace.
suggested wording: "SystemExit is raised if the user answers "no" to the prompt asking if it's okay to delete the test tablespace."
Use a single line. I think two CharField()s should work just as well and make the line shorter.
Chop blank line.
```suggestion form = PartiallyRequiredForm({'f_0': '', 'f_1': ''}) ```
I think this blank line can be removed.
Add trailing comma.
Why cast to a tuple? We could just check if it's falsey...
I think we could swap this and the previous `if` over - no reason to do the `has_related` check if we've specified the list. Alternatively, move the `has_related` inside an `if ... is False`
Might be worth renaming this to `self.root_queryset`.
These tests should be moved to a separate commit.
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
Sorry, wasn't trying to request a change, was thinking about how async middleware would be written and just seeking clarification.
That's what `inspect.iscoroutinefunction(getattr(Foo, '__call__', None))` does above. What I mean is that it's probably an abuse of Python data model. For example, ```python def Test: async def __iter__(self): pass assert inspect.iscoroutinefunction(Test.__iter__) ``` Won't fail but `__aiter__` should be used for this purpose. There's no analogous `__acall__` for `__call__` and it's not clear to me whether `async def __call__` is an abuse or not.
I think that you need to increase `stacklevel` to `3`.
Is this possible? If so, it will be good to cover this scenario with tests.
You can use `@modify_settings`, e.g. ```suggestion @modify_settings(MIDDLEWARE={ 'prepend': 'test_client.tests.urlconf_override_middleware', }) def test_resolver_match_when_urlconf_modified_by_middleware(self): response = self.client.get('/') ```
Just came here to suggest the exact same thing!
could this instead go before the try/except? ``` if isinstance(value, float): context = decimal.Context(prec=self.max_digits, rounding=decimal.getcontext().rounding) return context.create_decimal_from_float(value) ```
I'll take the time to write one later today but we could use a `@property`: ``` python @property def widget(self): if self.localize: return TextInput else: return NumberInput ``` One of the con here is that `NumberField.widget` will be an instance of `property`. We could also write a descriptor to maintain backward compatibilty: ``` python class WidgetDescriptor(object): def __init__(self, widget, localized_widget): self.widget = widget self.localized_widget = localized_widget def __get__(self, instance, owner): if instance and instance.localize: return self.localized_widget return self.widget class IntegerField(Field): widget = WidgetDescriptor(NumberInput, TextInput) ``` Maybe I'm just over-complicating this whole thing.
With this change, can the entire `clean()` method be removed from `EmailField` and `URLField`? The parent implementation already [calls `to_python()`](https://github.com/django/django/blob/415ae960bb9f1bdae798023fdce3247d2c938eec/django/forms/fields.py#L158).
(same pattern as above, if you change it)
I guess there is a fair amount of wasted effort for the majority(?) of projects that aren't using admindocs, so perhaps we could have a ticket for it to investigate the possibility of moving the admindocs specific-stuff out.
This test is not related with the patch, so I'll move it to a separate commit.
```suggestion caller = f'{obj.__module__}.{caller}' ```
Ok, I see. Makes it useful for the rare case you want the function both decorated and un-decorated.
I would assert against `url_name`, e.g. ```suggestion self.assertEqual(response.resolver_match.url_name, 'overridden_urlconf_view') ```
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
move this to an else block in (try/except/else)
They can only be decoded if these bytes were previously encoded in this encoding.
Fair enough, I assumed it was a small tweak to the stdlib version.
Just a nitpick: The test name looks already readable to me so I'd drop the docstring.
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
```suggestion self.assertEqual(res.context['week'], datetime.date(2008, 9, 29)) ```
We don't refer tickets in tests anymore, please chop `#9762`, also maybe: ``` # Changing the locale doesn't change the "r" format. ```
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
This line can be removed :thinking:.
IMO this line is unnecessary, and above `iter()` call can be removed.
`seprate` -> `Separate`, also trailing dot is missing.
It seems that we have two issues here, i.e. you can use fields from the same model multiple times, e.g. `parent__field1__field2__pk__field1`, and you cannot use `pk`. I think we should clean `_cls` if a field is not relation, e.g. ```python if part == 'pk': fld = _cls._meta.pk else: fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` I would split this into two fixes, first for using multiple times fields from the same model (with test): ``` fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` and second to handle `pk` (with test).
As with `@raise_deprecation`, this should be a module-level utility, not a method on the class.
Chop blank line.
Please remove trailing comma and space.
To match other model `check()` tests, use `self.assertEqual(TestJSONModel.check(), [])`
I think these names are more often of the form "OperationTestCase".
Do we need this change? it looks unnecessary.
According to the coverage report, this line isn't executed.
I would either remove this or add a helpful exception message.
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
```suggestion self, objs, fields, batch_size, on_conflict=None, update_fields=None, unique_fields=None, ```
returning `None` isn't perfectly equivalent to `continue`. I think it might be cleaner to move some or all of `_handle_object` back into `__iter__`. This allows us to use `continue` again.
In the suggested command list, `'python'` should be `sys.executable` to ensure the same Python that is running the tests is used in the subprocess.
This fails when running from the root directory rather than the tests directory (i.e. `$ ./tests/runtests.py postgres_tests`). Also, the output doesn't make debugging very easy (`AssertionError: 1 != 0`) -- if that could be improved that could be nice.
Test -> Tests (for future expansion)
`e` is unnecessary. Maybe it will be better to refactor these tests and put `class` inside `try` e.g. ```python @unittest.skipUnless(connection.vendor == 'postgresql', 'Postgresql specific test.') class PostgreSQLCursorOptionsTestCase(TestCase): try: from psycopg2.extensions import cursor class PostgresLoggingCursor(LoggingCursorMixin, cursor): pass except ImportError: pass ```
Why is `Vary: Cookie` in this list? Doesn't that contradict the stated goal of the test? (I realize that it won't pass without that, until #3672 is merged).
I think the norm is to use `apps` instead of `app_registry` to designate `Apps()` instances around the codebase.
Unlike an "app", I wouldn't say that a model is "installed". Two solutions: - check if the app is installed and adjust the error message accordingly: "app X isn't installed" or "app X doesn't provide model Y" - just rephrase do "which doesn't exist"
missing quote after `modelname` which should also be `model_name`
It would have been more appropriate if `run_checks()` took an `Apps` instance as a parameter instead of a list of `AppConfig`s.
Indeed, you are right.
Please including a trailing comma in the last item of a dictionary so if more items are added we don't need to modify this line again.
or use dict comprehension: ``` py {color_names[x]: '3%s' % x for x in range(8)} ```
might as well make these dict comprehensions (and in the next two files)
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Водка')) ```
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
It seems like `name` is never stored. Are you missing a `self.name = name or func.__name__`.
You'll want to branch off `< 3.6`.
I think silently failing to cache the property should be considered not working.
I would consider that as not working
Might make sense to check explicitly set name too, because '__name' obviously will not work.
Do we need this mapping? We could redirect to a `HttpResponse` with the `status_code`, e.g. `HttpResponse(status_code=r.redirect_type)`.
Can you sort those attributes please
isort rewrites this to `convert_exception_to_response, get_exception_response,`
I think we can remove this sentence.
`cls.staff_user = User.objects.create_user(username='user', password='secret', email='user@example.com', is_staff=True)`
Maybe: ```suggestion def test_order_by_f_expression_to_constant_value(self): ```
`asc()` is unnecessary: ```suggestion .order_by(F("test")) ```
```suggestion self.assertSequenceEqual(qs, []) ```
I think we can reuse `Parent` instead of `Author` and maybe add `ChildNullableParent` instead of `Book`.
IMO introspecting generated SQL is unnecessary, maybe: ```python def test_order_by_f_expression_to_constant_value(self): qs = Article.objects.annotate(constant=Value(42)).order_by( F("constant"), F("headline") ) self.assertSequenceEqual(qs, [self.a1, self.a2, self.a3, self.a4]) ```
Alternatively, you could handle this where `fields` is updated with `new_class.declared fields` like so: ``` for field_name, field in new_class.declared_fields.iteritems(): if opts.exclude and field_name in opts.exclude: continue if opts.fields and field_name not in opts.fields: continue fields[field_name] = field ```
I would structure this like this: ```python fields = fields_for_model( opts.model, opts.fields, opts.exclude, opts.widgets, formfield_callback, opts.localized_fields, opts.labels, opts.help_texts, opts.error_messages, opts.field_classes, # limit_choices_to will be applied during ModelForm.__init__(). apply_limit_choices_to=False, ) ```
These args could be wrapped closer to 79 chars.
Why is this on two lines? Why not just...? ```python data_altering_methods = getattr(cls, 'data_altering_methods', ()) ```
Is `test_doesnt_work_with_init_subclass` meant to test this change? I still don't see any test failures if this change is reverted.
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
OK, good. Thanks. I think it's fine as it is. 👍
I might handle the `if not hasattr(self, 'lastmod')` as a guard first, to get it out of the way: ```suggestion def get_latest_lastmod(self): if not hasattr(self, 'lastmod'): return None if callable(self.lastmod): try: return max([self.lastmod(item) for item in self.items()]) except TypeError: return None else: return self.lastmod ```
```suggestion path( 'lastmod/get-latest-lastmod-none-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_none_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/get-latest-lastmod-sitemap.xml', views.index, {'sitemaps': get_latest_lastmod_sitemaps}, name='django.contrib.sitemaps.views.index', ), path( 'lastmod/latest-lastmod-timezone-sitemap.xml', views.index, {'sitemaps': latest_lastmod_timezone_sitemaps}, name='django.contrib.sitemaps.views.index', ), ```
```suggestion path( 'generic-lastmod/index.xml', views.index, {'sitemaps': generic_sitemaps_lastmod}, name='django.contrib.sitemaps.views.index', ), ```
We try to avoid altering expressions during the compilation phase as it can lead to hard to diagnose issues what about ```suggestion self.collation = collation def as_sql(self, compiler, connection, **extra_context): extra_context.setdefault('collation', connection.ops.quote_name(self.collation) ```
Perhaps this could be a docstring? You might elaborate a bit more -- as someone not familiar with MySQL, it's not clear to me what "improved" means.
We can pass `opclasses` to the `super()._create_index_sql()`.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
Is that removal related to 5f7035cec7d5? If yes, we might commit it separately with an appropriate message.
Might want to avoid `id` shadowing.
IMO we can remove `_repetitive_name_errors()` hook, and move entire logic into `check_all_models()`, e.g. ```python for index_name, model_labels in indexes.items(): if model_labels: model_labels = set(model_labels) errors.append( Error( "index name '%s' is not unique %s %s." % ( index_name, 'amongst models:' if len(model_labels) > 1 else 'for model', ', '.join(model_labels), ), id='models.E030' if len(model_labels) > 1 else 'models.E029', ) ) for constraint_name, model_labels in constraints.items(): if model_labels: model_labels = set(model_labels) errors.append( Error( "constraint name '%s' is not unique %s %s." % ( constraint_name, 'amongst models:' if len(model_labels) > 1 else 'for model', ', '.join(model_labels), ), id='models.E032' if len(model_labels) > 1 else 'models.E031', ) ) ```
No need to create a `dict` if you're simply iterating over values.
Use a set here to perform containment checks.
I would use the same mechanism as for the `E020` and models' labels instead of `__name__`'s, i.e. ```python indexes = defaultdict(list) constraints = defaultdict(list) ... for model_index in model._meta.indexes: indexes[model_index.name].append(model._meta.label) for model_constraint in model._meta.constraints: constraints[model_constraint.name].append(model._meta.label) ```
We should pass `using` to `check()`.
This message shouldn't be used when constraint is defined with `expressions`.
> It just happens to pretty straightforward here as you can directly call `Constraint.validate` without the `exclude` on the constraint you are interested in validating. That's a suitable workaround, but I feel like it should not be necessary. FWIW before Django 4.1 where this feature was added I added manual validation already, since there constraints with conditions where just skipped.
`FieldError` is untested. Do we need it? It looks unnecessary.
We should make use of `self.message`.
preferred style, also "catched" -> "caught" ``` raise Exception( 'Exception... that should be caught' '...' ) ```
I think you can safely remove this.
Also please keep it as HttpResponseNotFound as bug only occurs when that view throws 404.
This should use longer lines (up to 119 characters) or hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
use snake case, please: `test_login_required()`
It would be better to move these two into a separate test method.
We try to avoid non-4 space indent like this. You could move this to `msg = "..."` instead.
I guess Article/Category deletes aren't doing anything since you already asserted exists() -> False. Anyway, I think I'd put this in a separate method. `test_loading_with_exclude_app` / `test_loading_with_exclude_model`
The interesting test case is this: ``` season_2009 = Season.objects.create(year=2009, gt=111) season_2009.games.create(home="Houston Astros", away="St. Louis Cardinals") season_2009.games.create(home="Houston Astros", away="Chicago Cubs") season_2009.games.create(home="St. Louis Cardinals", away="Houston Atros") season_2010 = Season.objects.create(year=2010, gt=222) season_2010.games.create(home="Houston Astros", away="Chicago Cubs") qs1 = Season.objects.exclude(games__home__contains='Houston') qs2 = Season.objects.exclude(lookups.Contains(F('games__home'), 'Houston')) ``` where the qs1 and qs2 objects should match. The encouraging thing is that the code is trying to call split_exclude(). It might be hard to make this test actually work, the split_exclude() code is pretty big hack, and especially if the expression creates joins to multiple different relations it will be hard to make the current code work properly. But, if I recall correctly, we don't support .filter(games__away__contains=F('games__home')) either.
I would use `%s` formatting consistently.
+1 (in separate patch)
This is hard to parse visually. I suggest: ``` return '{} @> {}'.format(lhs, rhs), params ``` or even: ``` sql = '{} @> {}'.format(lhs, rhs) params = lhs_params + rhs_params return sql, params ``` The same pattern occurs several times in the file.
This is the way lookups (and SQL in general throughout the ORM) is written currently. We could pick some other way (and the latter one is clearly more readable), but it is best to keep this file consistent with the rest of the code base.
I saw that you're now handling this at the database level. It makes more sense to me.
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
this would be better as a multiline if
Might as well switch these to hanging indent while you're changing them: ``` pre_save.send( sender=origin, instance=self, raw=raw, using=using, update_fields=update_fields, ) ```
Sorry, these parameters are already checked in `save()` so there is no need to change these assertions.
I tried to address Simon's request in the da4dd37f5fbb4bf9489f45803ffc0a91d0ac0592, this change also replaces some misleading variables' names.
Is there a reason not to favor the previous approach and pass `returning_fields=self._meta.returning_fields` instead? That seems like a better separation of concerns to me than having the insert compiler lookup `returning_fields`.
I don't think we should go so deep into validation, we opt out from numbers but at the same time we allow the whole unicode range. Unicode numbers like `๑` would happily validate therefore it's an uphill battle. I'd opt for a vastly simplified regex to validate FQDN: `'(?:[a-z0-9\u00a1-\uffff-]+\.?)+'`. Sure it'll let some invalid segments go through (e.g. leading/trailing hyphens) but at least it doesn't pretend of being exhaustive. Proper validation requires a parser anyway.
`localhost` or rather `localhost.` is a FQDN, that shouldn't require a special case.
The optional trailing dot may "protect" an ending dash -- `xn--.` passes this. Is this intended? If not, switch the last two lines.
Forgot to mention earlier, but on first look I found `[a-z-' + ul` a little confusing because of the dash between two ranges that actually serves as a dash and not a range separator. I think it would be more readable as `[a-z' + ul + r'-]` (similar to how it is in `domain_re` above).
This allows `xn----nx` and even `xn-----`. Are they valid? (edit: FWIW, my IceWeasel seems to think they are)
Fine, you persuaded me :smile: :speaker:
A list comprehension is preferable here as `str.join()` converts to list internally anyway. ```suggestion ', '.join([ f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields) ]), ```
As far as I'm aware `unique_fields` should be required when `supports_update_conflicts_with_target` is `True`, so there is no need to use `unique_fields or ()`. Moreover, we should raise an exception when it's not provided.
Spaces around `=` and PostgreSQL docs have `EXCLUDED`. ```suggestion ', '.join(f'{field} = EXCLUDED.{field}' for field in map(self.quote_name, update_fields or ())), ```
Ditto ```suggestion return all( not os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
Current implementation of `get_prefetch_queryset()` assumes that all instances have the same content type (there is an issue), but the fix is not optimal IMO because object IDs can be the same in different content types, e.g. we have two related objects: - object ID 1 with content type ID 1, - object ID 2 with content type ID 2, this query will return also: - object ID 2 with content type ID 1, - object ID 1 with content type ID 2, which is not correct. I know that we are matching them below but still I think we can limit the no. of objects only to actually needed.
Do we need to use a dict? It seems unnecessary complicated. Model classes that we pass in the keys must match the base models from querysets. We also don't protect against incorrect values e.g. ```python queryset={ Animal: Bookmark.objects.all() } ``` I would use a list/tuple instead and raise an error when a queryset for the specific model is already resolved, e.g. ```python for qs in querysets: ct_id = self.get_content_type(model=qs.query.model, using=qs.db).pk if ct_id in custom_queryset_dict: raise ValueError(...) custom_queryset_dict[ct_id] = qs ``` We should also add a new argument (maybe `querysets`) because it's misleading to pass list of querysets in the argument called `queryset`.
could chop "Make sure to" without any loss of meaning.
We should pass `using` from the queryset ```suggestion ct_id = self.get_content_type(model=model_cls, using=ct_queryset.db).pk ```
slightly simpler could be: "asking the user what ..."
This needs an entry in `deprecation.txt`
Because we use `-Wall` on Jenkins, so it's already consumed. I don't think there is a reliable way to test this.
I thought about this. It's a much bigger change, just for a deprecation. Inserting a deprecation is one thing. Adjusting method calls is something else: `MiddlewareMixin.__init__()` calls `super()` so there's a potential logic change. Don't know where exactly, but I didn't want to risk a regression just to save the extra lines here implementing this deprecation.
I'd move the entire `geoadmin` folder to the `geoadmin_depracated`.
```suggestion @ignore_warnings(category=RemovedInDjango50Warning) ```
Chop blank line.
How about using "parent" here instead of "master"? Seems like a better fit with "child processes".
Can we move subclassing `unittest.TestResult` to a separate commit? Is it a valuable optimization on its own? or it's strictly related with supporting `--buffer` with `--parallel`.
I don't think it would make a difference in memory efficiency. Seems fine to keep it as it is.
Try to avoid `We` in docstrings.
prefer hanging indent: ``` self.assertEqual( len(calls), 1, "..." ) ```
Add a trailing comma so if more items are added later we don't have to modify this line again.
`Exception as e`
Please use assertRaisesMessage to check the message too. We prefer the context manager version usually `with self.assertRaisesMessage(ValueError, msg)`. I think combining the two tests so you can reuse the `msg` variable would be fine.
You can simplify this with `assertLogs()`: ```suggestion url = reverse('test_with_sidebar:auth_user_changelist') with self.assertRaisesMessage(AssertionError, 'no logs'): with self.assertLogs('django.template', 'DEBUG'): self.client.get(url) ```
Indexes are not constraints, generally.
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Looks like `self.model_name_lower` could be passed here and we could avoid all the `.lower()` handling in `.rename_field`. ```suggestion state.rename_field(app_label, self.model_name_lower, self.old_name, self.new_name) ```
Do we need to check `removal_value`? It should be enough to check that `new_value` is not en empty set, I cannot imagine a different scenario :thinking: ```suggestion if new_value: ```
Nitpick but `dict.get` default value for a missing key is already `None`.
If it has some readability benefits, it could be done in a separate PR. This looks okay for now.
longer line is fine so you can use same style/indentation as others
I know it was already like this, but I prefer including the trailing comma in dictionaries so that if more items are added later, we don't have to modify the line again (keeps diffs and git blame cleaner)
Collapse into the line below to avoid the temporary variable.
tests for the `repr`s of `HttpResponseNotAllowed` and `HttpResponseRedirect` already exist in `httpwrappers/tests`, please move these tests there
We should make sure the `YearLookup` subclasses are registered to the `ExtractYear` transform as they perform operations that can use indexes.
`# Check that ...`
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
I was asking as major databases support year extract functions, so year comparing can be done as consequent joining of a transform and standard comparison lookup. So, creating YearGt and etc lookups will become really unnecessary if year transform will just convert datetime to a year representation using EXCTRACT, YEAR or STRFTIME calls (depending on database).
The problem is that an expression like extract(year from datefield) = 2015, then the DB will not be able to use indexes on datefield. But if you instead have datefield >= '2015-01-01' and datefield < '2016-01-01', then the db can use indexes. This is the underlying reason why we have the special year lookups.
This will become a performance issue for the database before it becomes one for the Python process :-)
`on_commit` can be used directly by 3rd-party database backends, that's why we should add a default value to `is_robust.`
```suggestion def on_commit(self, func, is_robust=False): ``` Add default value for better backward compatibility.
`func` is called even if no transaction is in progress, so we should move this to the first line. Fixed.
I would raise a `TypeError`, e.g.: ```suggestion if not callable(func): raise TypeError("on_commit()'s callback must be a callable.") ```
You could skip these, but I thought that the rewording read better. I guess if you go for the proposed `Renderable` then they'd be moved anyway and then it doesn't hurt to update them. (Also note that the docstring for `BaseFormSet.as_ul()` neglected to mention that it isn't wrapped in `<ul>`.) 🤷🏻‍♂️
I think that `BaseForm.get_context()` describes this perfectly well: ```suggestion ``` But if we must keep it, it should be collapsed onto one line: ```suggestion """Returns context for form rendering.""" ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
```suggestion """Render as <p> elements.""" ```
I know this is the sort of layout that `black` would generate, but it's one of the more ugly choices it doesn't get right in my opinion. Perhaps we should `+=` instead of `.extend()`: ```suggestion top_errors += [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ```
I guess this needs to be something like `inherited_attributes |= set(base.__dict__.keys())` to work on Python 2.
I don't think that we need this check. I would rather remove from docs [note](https://github.com/django/django/blob/77d335e5abec889b15323975187a8d5b10bfcb0f/docs/topics/db/queries.txt#L965-L979) about setting `id` to `None`. That is outdated after this patch. \cc @spookylukey
> I was under the impression that only `AutoField`'s were to be made `None`. You can also set `pk` that is an `AutoField` to a string value, in all such cases Django raises `ValueError`, so I don't see any issue in it. Moreover we can have a primary key that is not an `AutoField` but has a default value, e.g. `UUIDField(default=uuid.uuid4)` and this should also work.
I think this test is sufficient, no need for the other one. Can you rename it to `test_delete_keep_parents()` though.
Are you using PROXY_PARENTS as some type of flag? We already went through the "flags" path throughout the Meta API refactor and ended by removing it because it required imports. Even though this is an internal function, I would advise to find a better solution because, personally, I don't think it's good practice to have one argument that can be of different types (in this case, boolean or object) as it increases the risk of bugs, and it also can be confusing to other people. But that's just me.
please limit docstrings to 79 characters and add period
I think you could simplify this a bit by using `self.client.login(self.super_login)` and the ORM to create the initial objects instead of the add view.
I'm unsure the purpose of `ugettext_lazy` here.
I think the test is not in the right class (`AdminViewPermissionsTest` should be limited to test permission-related stuff). We may need a new test class.
I think this test isn't working as expected -- it's resolving to `RedirectView`, same with `test_inline_urls` -- probably the result of the resolve should be checked.
Improved typography and changed to [%-formatting](https://docs.python.org/3/library/stdtypes.html#old-string-formatting) to be consistent with other error messages.
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
It seems we can probably move deprecation warning handling to the actual test cases now. We can make it a follow-up item after merging the first version of this if you like.
Rename to `BaseSequenceSerializer`, make the `_format()` raise a `NotImplementedError` similar to the `BaseSerializer`. Then add a `ListSerializer` along `TupleSerializer` etc. that implements the `_format()` method. ``` python class BaseSequenceSerializer(BaseSerializer): def _format(self): raise ... class ListSerializer(BaseSequenceSerializer): def _format(self): return "[%s]" class TupleSerializer(BaseSequenceSerializer): # as already implemented ```
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
Yes, we'd need a separate test for check registration. Possibly https://github.com/django/django/pull/7781 will come up with a template to use.
The lines below do not belong into the try block, since they don't raise the exception. ```python try: errors = checks.run_checks() else: expected = [] self.assertEqual(errors, expected) finally: admin.site.unregister(Book) admin.site.unregister(Author) ```
Add a trailing comma in kwargs so if more items are added later, we don't have to modify this line again.
use a hanging indent style: ``` INSTALLED_APPS=[ 'django.contrib.admin', ] ```
```suggestion def test_repr(self): admin_site = CustomAdminSite(name='other') self.assertEqual(repr(admin_site), "CustomAdminSite(name='other')") ```
Please add `default=False`.
`--ignore-app-config` is unclear for me, maybe `--include-stale-apps`.
Can you add a period at the end, please.
I think "ordered" is also unnecessary (i.e. why would they be out of order ;-) ).
I think you could write `self.program_options.append('-f')` here. This way you won't need to add a new parameter to `compile_messages`.
I don't think we need to check all rows, probably sth like this: ```python self.assertEqual(list(qs.values_list('lead_default', flat=True).distinct()), [60000]) ``` will be sufficient. We have a similar situation in the `test_nth_returns_null`.
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
It's weird, because Oracle interprets empty strings as nulls.
Trailing zeros are stripped on PostgreSQL, so I changed to ```suggestion self.assertRegex(now_string, rf"^.*\.\d{{1,{precision}}}") ```
Could be a little more precise by using exactly 3 or 6, not between 3 and 6 ```suggestion self.assertRegex(now_string, r"^.*\.(\d{3}|\d{6})") ```
The default should be the most common I think. So set the default, then change it in the postgres features.
Yes it was Ian, but my example used joined fields for an update which isn't (yet) allowed. How about something like: ``` Author.objects.update(alias=Greatest('name', 'goes_by') ``` Which will also test the handling of varchars in a Greatest.
`).values()` on next line
base class (StatAggregate)
Perhaps some refactoring using `subTest` as done in https://github.com/django/django/pull/7822 would be better.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ``` values = AggregateTestModel.objects.aggregate( arrayagg=ArrayAgg('char_field', ordering=ordering) ) ```
don't need variables here
All the `all().aggregate()` calls can be replaced by `aggregate()` calls.
I guess I would single line this for now.
You don't need to pass `None` (in all tests).
This change looks unrelated :thinking: Please revert.
The signal approach would hopefully eliminate the need to call `reload()` manually.
I'm a bit worried about this `reload()` with overridden settings to trigger the `UserCreationForm` to be recreated with a custom model. It obviously works for this test case, but I think it will leave the customised `UserCreationForm` loaded at the end of the test, won't it? Doesn't this mean that we will potentially have dependencies between this test and other ones that also use the `UserCreationForm`? If so, I think we should find a way to do a `reload()` at the end of the test (in `tearDown()`?) after the settings have been put back to the default.
`if not relations:` is a sufficient check here I think
```suggestion self.resolve_model_field_relations(model_key, name, old_field) ```
I don't think you need `list()` here.
Use more significant variable names here and take advantage of `.pop` return value ```suggestion for model_relations in relations.values(): if old_name_key in model_relations: model_relations[new_name_key] = model_relations.pop(old_name_key) ```
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
This is not only about constraints but also about noop `ALTER FIELD` operations. Field alteration can cause many DDL changes. > We could just compare the old and new field. That's exactly what we're doing here, we compare fields but without attributes that don't impact schema changes.
I don't think this is the best way to address this issue. We will always have to keep this list of fields updated. Instead we could change `_alter_field` field to do nothing when the constraint hasn't changed. We could just compare the old and new field. This is the `if` that drops the constraint. https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L590 and the one that adds it back https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L810
I guess `name` would be another one.
I think we missed some attributes e.g. `related_query_name`, `limit_choices_to`, or `validators`.
Maybe? ```suggestion def _field_non_database_attrs(self): ```
Please alphabetize imports.
This wrapper is used in several methods so I've increased `max_size` a bit.
This is an internal wrapper so I changed it to `_get_signature()`.
I initially thought it would be an issue for `boundmethod` instances but it looks like they hash to the same value even if they are bound to different instances ```python class Foo: def __init__(self): pass >>> Foo().__init__ == Foo().__init__ False >>> hash(Foo().__init__) == hash(Foo().__init__) True ``` In all cases I don't see a compelling reason for setting `maxsize=None` and allowing the cache to grow unbounded.
I don't think it's important to mention PostgreSQL version details in the docstring.
`'bar'` is already in `out` from the first execution of `call_command()`. You should reinstantiate or use `out.truncate(0)` before the second call.
This can be single-lined.
I think that such iterables like `[None, False]` should be tuples like `(None, False)`, because it's less memory consuming and faster a bit. Anyway, it is not very important, because of small container size.
, -> and
At first sight it could be simplified to: ``` [option not in [None, False] for option in mutually_exclusive_options].count(True) ``` But I have a feeling even more simplification might be possible. Note that we can't simply cast default to bool, which would make this even simpler, as some valid dates evaluate to false: https://mail.python.org/pipermail/python-ideas/2014-March/026446.html
Make sure you reference your ticket number in the docstring (see the other tests in the file).
`assertEqual` the 's' version is a deprecated alias
I think the `TestStringAggregateDistinct` class could be reused considering the setup methods are the same -- just remove `String` from the class name.
Other tests use naming like: `test_json_agg_empty`
You could avoid the delete query with: `AggregateTestModel.objects.none().aggregate(...)`. (I guess the other tests could use the same pattern, not for this PR though.)
That'll create unnecessary empty dicts if empty data is passed.
I'm favoring contractions lately, e.g. "Don't", "shouldn't".
Sorry, I was referring to the `# If necessary, rearrange by field_order.` line, not the docstring.
You are right! I assumed `render_option` was always converting falsy values to an empty string. It might be worth keeping the method in this case.
I don't think it's worth adding a method for this purpose. `first_choice is not None and first_choice[0]` should do.
use set comprehension (I guess it might be better to defer this task to a separate commit)
I was thinking: ``` python def bind_to_form(self, form, name, **kwargs): return BoundField(form, self, name, **kwargs) ``` but I'm not convinced this is a good practice for a "just in case" scenario, so we can probably drop the idea.
I wonder if we might add `**kwargs` to the signature of this method and `BoundField` to allow for future expansion? (In the past, there have been some instances where we've wanted to add additional parameters and we have to add non-trivial backwards compatibility shims to allow that.)
Seems fine to rename everywhere, but it seems out of the scope of this PR to touch `BoundField.__init__`.
reuse initial here and don't call to_python twice
Does this url affect the test in anyway (and ditto below)? If not, I think it should be removed, as test cases should be as simple as possible
That makes sense, but the check itself will already be run many times in Django's test suite with different urlconfs, so it's pretty much guaranteed it passes with plain urls.
Use single quotes for the names.
I think you can safely remove this.
Also please keep it as HttpResponseNotFound as bug only occurs when that view throws 404.
should this be super()
You can use `super()`: ```suggestion return super().migration_name_fragment + '_not_valid' ```
I would rename `self.model_name` -> `self.name` (like in `CreateModel`, `DeleteModel`, or `RenameModel`).
Indexes are not constraints, generally.
`constraint_name` should also be quoted.
Based on the change above to use `**self._options` in `RedisCache._cache()`, we should replace `options` with keys that are expected. As it stands at the moment a key could be misspelled in `OPTIONS` and passed here but not used. Based on the changes requested above, we should at least have `pickle_protocol=None` here.
Rather than passing all of `OPTIONS` here we should only pass the protocol: ```suggestion def __init__(self, protocol=None): self._protocol = pickle.HIGHEST_PROTOCOL if protocol is None else protocol def dumps(self, value): return pickle.dumps(value, self._protocol) ```
Can we make `key` set to `None` by default to avoid needing to pass `None` explicitly below? ```suggestion def get_client(self, key=None, write=False): ```
We could flatten this? ```suggestion return default if value is None else self._serializer.loads(value) ```
Ah, yes. Good observation. 🙂
Ah, ok so maybe we can check both in one call, i.e. ```python self.assertEqual(check_language_settings_consistent(None), [ Error( ... ), Warning( ... ), ]) ```
You could also use `self.settings()` (it's a bit shorter) -- doesn't matter much though.
You can combine these tests.
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
these aren't necessary, you can pass `StringIO`s for `stdout` and `stdin` to `call_command` instead. there are lots of examples in existing tests e.g. https://github.com/django/django/blob/master/tests/i18n/test_compilation.py#L41
Aha I found what you should be using for both: `django.utils.captured_stdin` and `django.utils.captured_stdout` 😉 You could also open a second PR removing the hack from `createsuperuser` and change its tests to use `captured_stdin` 👍 Presumably
I think we can chop it.
no need for breaking this over multiple lines now
I simplified this test with `@mock_inputs()`.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
this doesn't look right
Not sure of the motivation behind these changes but this could be reduced to the following? ```suggestion attrs['declared_fields'] = { key: attrs.pop(key) for key, value in attrs.items() if isinstance(value, Field) } ```
~Never mind, looks it's the other way around. Works on 3.6, fails on 3.8.~ had an old Python 2.7 interpreter lying on my path 🤦
I guess this needs to be something like `inherited_attributes |= set(base.__dict__.keys())` to work on Python 2.
Fair, but then I think a `versionchanged` is missing in the docs + maybe a backwards incompatibility release note.
I'm not fond either of this semantic change of the `is_password_usable()` API. I think we need two APIs for two different use cases: 1. tell if the current user password is usable (as current `is_usable_password`), 2. tell if the current user password is voluntarily disabled.
I would have set `TestUtilsHashPass` as a `SimpleTestCase` subclass, so you can simply use `with self.settings(...)` and remove usage of override_settings (which is rather aimed to decoration).
You can use something like this (wrapping lines at 79 chars): ``` self.assertEqual( encoded, 'scrypt$16384$seasalt$Qj3+9PPyRjSJIebHnG81TMjsqtaIGxNQG/aEB/NYaf' 'TJ7tibgfYz71m0ldQESkXFRkdVCBhhY8mx7rQwite/Pw==$8$1' ) ```
This can go away now, but needs a new test that the warning is raised in the base hashers `decode`
We can remove `'book_join'` from `order_by()`.
What if `default` is not a constant but a field reference? e.g. `F('integer')`
`transform.lookup_name` isn't needed (same in unregister)
`NULL` is interpreted as an empty string on Oracle, you can use: ```suggestion self.asserEqual(author.backward, '' if connection.features.interprets_empty_strings_as_nulls else None) ```
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
You could use `for else` construct here. ``` python for fixture_label in fixture_labels: if len(self.find_fixtures(fixture_label)) > 0: break else: return ```
Would be slightly better to use non-contrib models in case sites is someday removed.
IMO we should revert this change `fixture_file` is an absolute path, so it can contain directories with dots in names, this can cause issues in `parse_name()`.
you can remove ticket reference
What I meant is, to leave the database in a clean state for other tests, we need: ``` self.assertTrue(Car.objects.exists()) Car.objects.delete() ```
The `table` variable is actually a `models.Model` instance so it might be good to rename it to `model`. In the case of auto-created models `model._meta.auto_created` will be pointing at the model at the origin of the creation else it will be `False`. When it's `False` the resulting message should be of the form `(opts.app_label, opts.object_name)` else it should be of the form `(opts.app_label, opts.object_name, field.name)` where `field` is retrieved from iterating over `model._meta.auto_created._meta.many_to_many` where `field.remote_field.through is model`.
You can replace `table._meta.app_label` and `table._meta.object_name` by `table._meta.label`
Use outer double quotes to avoid backslashes.
I suggest you skip the check (`return []` early) if the intermediary model (`self.remote_field.through`) is not resolved. That is `isinstance(self.remote_field.through, six.string_types)`. Also I would store `m2m_db_table` in a variable as you'll need to reuse it to lookup `registered_tables` below.
You should use `self.m2m_db_table` instead of `self.db_table`.
I guess you're right. It will be nice to change these assertions in a separate PR.
I'm not sure if using assert is best since that's ignored when using `python -O`.
I think that `AssertionError` is the most common in the `Query`. It's also used with the same check in other methods e.g. `Query.extra` and `Query._earliest_or_latest`: ```python assert self.query.can_filter(), \ "Cannot change a query once a slice has been taken." ``` therefore it will probably be better to keep consistency.
I see we use assert elsewhere, but I would prefer to raise an exception as asserts are ignored when running with `python -O`.
Maybe e.g. `Calling exclude() is not supported after union().`
```suggestion with ignore_warnings(category=RemovedInDjango50Warning): ```
```suggestion self.assertNotContains(response, '<nav aria-label="Breadcrumbs">') ```
And I would rename this attribute `superusers` as it's meant to contain multiple users.
use `reverse()` rather than a hard coded URL.
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
You don't know what a docstring is? Trying googling "python docstring".
Sorry, was thinking of something else.
I'm not sure if these docstrings are adding much value.
Use single quotes unless the string contains a single quote. Also, this could be combined with the previous line -- we allow up to 119 characters when it helps readability.
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
It is not about the controversy, this is an actual bug that should be fixed. Changing the current behavior for foreign keys/many-to-many fields requires a separate ticket, however without a discussion on the mailing list we will close it immediately as _"wontfix"_, so I'd start from the discussion.
> Thank you. Should I open a Trac ticket for this bug or it's not necessary? For me ticket-33151 is a ticket for this bug we don't need a new one. I've changed the summary to _"createsuperuser doesn't work in non-interactive mode if a ManyToManyField is in REQUIRED_FIELDS"_.
All tests (new and old) pass when we change only these two lines. I don't think that other changes are required.
No need to duplicate all this stuff, just put a conditional in the interpolation: `' (%s') % capfirst(field.rel.field_name)) if field.rel else ''`
Do we need to move these two lines? All tests pass without this change.
`str` -> `six.string_types` for compatibility with Python 2.
You can use `Path.is_absolute()`.
I think we should check it's iterable AND not a string, there's always the possibility of other mistakes than the one that lead to the ticket, e.g. missing brackets on a function call
Looks like this could be a single line.
This can be single-lined. Also, please use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). ```suggestion custom_libraries = conf.get('OPTIONS', {}).get('libraries', {}) ```
IIRC raising CommandError prevents management commands from displaying a stack trace. This doesn't seem very important but I wanted to point out the change in behavior in case it was accidental.
Unless I missed something: - before: all `OSError` exceptions are converted to `CommandError`; in addition a specific message is added when the file already exists - after: only `FileExistsError` is converted to `CommandError`
FYI, `errno.EPERM` maps to errno 1 so this is the errno we will check for instead of an integer like we originally submitted in the PR.
``` # If the filename already exists, generate an alternative filename # until it doesn't exist. ```
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
I think that: ```python return 'FOR UPDATE%s%s%s' % ( ' OF %s' % ', '.join(of) if of else '', ' NOWAIT' if nowait else '', ' SKIP LOCKED' if skip_locked else '', ) ``` is more readable.
Please add trailing comma.
If ...., the locked row is skipped resulting in Person.DoesNotExist.
DatabaseError is raised if a ....
Nit-pick: I think Django generally favors the syntax with parens instead of the `\` continuation char.
I guess the `add_argument` could be `action='store_false', dest='uses_https'`
Yeah, that would certainly be a better idea, rather than using `not` here for negation.
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
```suggestion # Validate app_label. ```
There is no need to resolve replaced/applied migrations so I would pass `None` instead of the default connection: ```suggestion loader = MigrationLoader(None) ```
Although `operator.xor()` has the signature `(a, b)`, it might make sense to stick with `(x, y)` for consistency? ```suggestion def _sqlite_bitxor(x, y): if x is None or y is None: return None return x ^ y ```
I don't think we need the `re_` prefix to the arguments? And perhaps `text` instead of `string` for consistency? We should also avoid coercing to `str` unless we need to: ```python In [1]: text = "This is some text" In [2]: %timeit str(text) 54.7 ns ± 4.28 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) In [3]: %timeit isinstance(text, str) 33.8 ns ± 0.106 ns per loop (mean ± std. dev. of 7 runs, 10000000 loops each) ``` It might make the non-`str` case slower, but, unless I'm mistaken, we're expecting `text` to be `str` in the majority of cases. ```suggestion def _sqlite_regexp(pattern, text): if pattern is None or text is None: return None if not isinstance(text, str): text = str(text) return bool(re_search(pattern, text)) ``` As an aside, I wonder whether we can do something to compile and cache patterns? This could make a significant difference if the function is called for a large number of rows.
Annoying that `datetime.time` cannot be subtracted from each other to give a `datetime.timedelta`, so we cannot use `duration_microseconds()` as in `_sqlite_timestamp_diff()` below.
This seems suboptimal for a number of reasons: - It's doing `len(text)` twice. - If `len(text) == length` it's slicing unnecessarily instead of returning `text`. - Using `fill_text * length` is too much as we'll only ever need `lengrh - len(text)`. Maybe the following would be better: ```suggestion delta = length - len(text) if delta == 0: return text if delta < 0: return text[:length] return (fill_text * delta)[:delta] + text ``` If `fill_text` is more than one character, `fill_text * delta` still generates too much, so we still need to `[:delta]`. Offhand, I'm not sure I can think of anything better that wouldn't be slower.
Hah. Had the same thought before I got here. See the caveats mentioned above.
`verbosity=0` is not necessary.
Just to make sure, the previous behaviour would load the 'django.conf' package if packages is None? With this new change, you will load all installed apps and LOCALE_PATHS files, but 'django.conf' wouldn't be in it, so it may or may not be an issue, I can't really tell, since that package is used for the admin JS, so I don't think anyone would be relying on it for non admin pages. I actually like the change since in this way you don't have to manually specify the packages when all you want is your app's translations.
So the js18n view for admin, why does it still load django.conf on top of django.contrib.admin? Is it there because no one ever noticed there are no longer js ranslations for django.conf? If so it would be good to have it cleared also
Oh yes the tests! You are right then.
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
@timgraham is ordering by the result of an aggregate allowed without subqueries? If ordering by count does not error, then it should be safe to use that ordering. If not, introducing a different field into the orderby will affect the grouping (not that you suggested that), so we'll need to look at comparing the queryset out of order if there's another assert method available that does that. I'm not able to check either of these things at the moment, but I can take a look in about 8 hours if it's not resolved.
It would be fine to put these on a single line `{'publisher': 1, 'count': 1}`
Please break this down into a couple of lines to make it easier to read. Also, the `distinct` call should be unnecessary for this bug, and only introduces extra work that distracts from the main problem.
A style that didn't require so many lines and use non-4-space indent would be more consistent with the rest of the code. Something like: ``` vals = list(Book.objects.annotate(xprice=F('price')).filter(xprice__lte=30) .values('publisher', 'contact').annotate(count=Count('pk')).values('publisher', 'count') .order_by('publisher')) ```
This assertion is not necessary.
What about m2m and reverse relationships? Something like `Q(cities=3)` will also produce the join.
If it's an expression its source expression tree should be walked (recursive `get_source_expressions`) and when the expression `isinstance(expr, str)` then you'd need to use split it using `LOOKUP_SEP`. The first part should be used to retrieve the field (`_meta.get_field(parts[0])`). If it's a related field (`field.remote_field is not None`) then you are trying to `JOIN` and it's disallowed.
Looks like we just need to use `_meta._get_fields(reverse=False)`.
I think the function can be simplified to ```python @classmethod def _get_expr_fields(cls, expr): fields = set() if isinstance(expr, Q): for child in expr.children: if isinstance(child, tuple): lookup, value = child fields.add(lookup.split(LOOKUP_SEP)[0]) fields.add(cls._get_expr_fields(value)) else: fields.update(cls._get_expr_fields(child[1])) elif isinstance(expr, F): fields.add(field.name) elif hasattr(expr, 'get_source_expressions'): for src_expr in expr.get_source_expression(): if isinstance(src_expr, str): fields.add(src_expr.split(LOOKUP_SEP)[0]) else: fields.update(cls._get_expr_fields(src_expr)) return fields ``` And you call it directly with `constraint.condition` and `constraint.check`. An alternative would be to create a `sql.Query` object and try to add the where object while disallowing joins https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/constraints.py#L101-L102 https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1361-L1362 This will raise a `FieldError` if there's an attempt at joining https://github.com/django/django/blob/3bc4240d979812bd11365ede04c028ea13fdc8c6/django/db/models/sql/query.py#L1660-L1684 But the message won't include the name of the culprit which be a blocker here if we want to provide adequate hints.
Something like ```python elif hasattr(child[1], 'get_source_expressions'): for expr in child[1].get_source_expressions(): if isinstance(expr, str): fields.add(expr.split(LOOKUP_SEP)[0]) else: fields.update(self._get_check_or_condition_fields(expr) ```
Could you try to write these tests at a lower level, without the `as_ul()` output methods? They're difficult to debug now.
`# Without form data` seem sufficient.
add period and `# The value from the form's initial data is used.`
`# Values provided in the form's data are ignored.` Might be good to have a test for `Form(data, initial=...)` too.
This is the same as the previous assertion. I'd think only 1 assertionis needed since all the `as_*` methods use `_html_output()`.
I'm not really sure this docstring is necessary as the implementation is obvious.
Since negative years or negative plurals do not make sense, how about limiting number to 0 and 1.
Maybe ```python @skipIf(sys.platform == 'win32' and PY38 and sys.version_info < (3, 8, 1), 'https://bugs.python.org/issue38563') ```
Please wrap at 79 chars.
It's helpful to describe the issue with a few words, e.g. "Inserting non-ASCII values longer than X characters (#22144)." (I'm not certain that's a correct description of the issue).
I guess you probably want `from django.test.utils import requires_tz_support` instead.
There should never be a reason to encode ascii to something else. While technically valid it makes mails bigger (especially if at one point we decide to call sanitize address for all addresses)
I am not exactly sure about that change of mine. It is probably okay that `sanitize_address` returns a long address, but I'll have to double check if actually serializing a message like that rewraps it again.
single line here is okay (lines up to 119 chars are fine when it improves readability)
I think we can leave the list of exceptions.
Could everything from here be extracted into a helper function? So we'd just pass in the `ordering` and return whatever came back. (This would give a hook for opt-out/customisation that both 17198 and 29943 hint at.)
I would multiline: ``` field.attname for field in self.lookup_opts.fields if field.unique and not field.null ```
May as well do the following as a field name can only legally have a single `-` at the start: ```python field_name = part.lstrip('-') ```
```python if ordering_fields.issuperset(field.attname for field in fields): ```
I'd remove this blank line.
I'm not sure if this remains an appropriate test if it doesn't hit this block anymore? https://github.com/django/django/blob/d4eefc7e2af0d93283ed1c03e0af0a482982b6f0/django/core/handlers/wsgi.py#L161-L168
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
Flatten to a single line.
It is not the status code that needs to preserve the request method. Perhaps the following reads better: `# Preserve request method post-redirect for 307 and 308 responses.`
It's a small detail, but I think the variable naming could be improved here. `request_method` and `req_method` are very similar names (one is just a shortening of the other) but they mean very different things. I might rename `request_method` to `req_method_name` or something. Or you could probably just turn this into a single line and avoid a temporary variable.
The primary key attribute can only be retrieved on certain databases, this will not work on Oracle or MySQL.
Tests for `formset_factory()` and `formset_factory()` are missing.
Add trailing comma.
Please chop unnecessary blank lines.
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
Tests are failing for a different reason due to qwirks with our CI system; notice that SQLite tests are failing as well.
Is this necessary to get tests passing? I think it's already handled by `self.sequence_reset_by_name_sql(style, sequences)` below when `sequences` is specified. ```suggestion ``` Tests that require sequences to be reset should explicitly set [`reset_sequences=True`](https://docs.djangoproject.com/en/3.0/topics/testing/advanced/#django.test.TransactionTestCase.reset_sequences).
[This is only an estimate on InnoDB tables](https://dev.mysql.com/doc/refman/5.7/en/tables-table.html) which is the default table engine and what's used on CI. > The number of rows. Some storage engines, such as MyISAM, store the exact count. For other storage engines, such as InnoDB, this value is an approximation, and may vary from the actual value by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate count. In short that means this value could report 0 while there's actually rows in the table and cause errors similar to the one you are experiencing.
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
```suggestion for table_name, table_rows in rows: ```
Do we need to check this message? `AssertionError` means that no logs were logged (with at least the given level), so I would change this to: ```suggestion pass ``` and add `else`: ```python try: with self.assertLogs(logger_name, level) as cm: yield except AssetionError: pass else: self.fail(f'Unexpected logs found: {cm.output!r}') ```
This is unnecessary if we remove checking the error message.
```suggestion """ Assert no messages are logged on the logger, with at least the given level. """ ```
I think `request` should be optional.
Or in some cases (e.g. CSRF) it's because we want to log the response under a particular non-default logger. But even in those cases, we never want to double-log a response.
`step` attribute should only be added if `self.localized is False`
We might want to avoid doing this if `self.localize is True` since `DECIMAL_SEPARATOR` and `THOUSAND_SEPARATOR` should be taken into account in this case.
This must also take the sign into account. What about: ``` python max_length = self.max_digits + 1 # for the sign if self.decimal_places is None or self.decimal_places > 0: max_length += 1 # for the dot ``` We could also make the sign check conditional based on `min_value` and `max_value` but it would be a mess.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
I'll take the time to write one later today but we could use a `@property`: ``` python @property def widget(self): if self.localize: return TextInput else: return NumberInput ``` One of the con here is that `NumberField.widget` will be an instance of `property`. We could also write a descriptor to maintain backward compatibilty: ``` python class WidgetDescriptor(object): def __init__(self, widget, localized_widget): self.widget = widget self.localized_widget = localized_widget def __get__(self, instance, owner): if instance and instance.localize: return self.localized_widget return self.widget class IntegerField(Field): widget = WidgetDescriptor(NumberInput, TextInput) ``` Maybe I'm just over-complicating this whole thing.
A better name might be: get_constraints_counts
I meant `self.table or '(default)'` seems more neat and intuitive, but this way it is more explicit. :)
missing trailing comma
We use `new_default` only when `old_field.null and not new_field.null` so IMO it's fine to use ```diff diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py index bfccf5e8fb..8cd5e11bbf 100644 --- a/django/db/backends/base/schema.py +++ b/django/db/backends/base/schema.py @@ -675,17 +675,17 @@ class BaseDatabaseSchemaEditor: # 3. Replace NULL constraint with NOT NULL # 4. Drop the default again. # Default change? - old_default = self.effective_default(old_field) - new_default = self.effective_default(new_field) - needs_database_default = ( - old_field.null and - not new_field.null and - old_default != new_default and - new_default is not None and - not self.skip_default(new_field) - ) - if needs_database_default: - actions.append(self._alter_column_default_sql(model, old_field, new_field)) + needs_database_default = False + if old_field.null and not new_field.null: + old_default = self.effective_default(old_field) + new_default = self.effective_default(new_field) + if ( + not self.skip_default(new_field) and + old_default != new_default and + new_default is not None + ): + needs_database_default = True + actions.append(self._alter_column_default_sql(model, old_field, new_field)) # Nullability change? if old_field.null != new_field.null: fragment = self._alter_column_null_sql(model, old_field, new_field) ```
`constraint_name` should also be quoted.
Fair enough if there is precedence for it. I thought `ImproperlyConfigured` was usually used for settings or something affected by a setting being incorrect.
Not sure whether this is the right exception - should be `TypeError`.
Also rephrase to a single sentence to avoid mentioning `QuerySet` twice.
`QuerySet` instead of `queryset` for all instances of it in this exception message.
I'm not sure how much of an issue it is but this will be backward incompatible with `SingleObjectTemplateResponseMixin` subclasses that define a `model` attribute but don't have a `get_model()` method. There is no such class in Django's provided CBVs.
I think it'd work if you put the mixin to the left of the base class where it's used.
You mean `super()`? Seems okay to me.
add trailing comma
Here if a field is not a ForeignKey, but have many_to_one=True then it will go through formfield_for_foreignkey(). If that method returns None, then [None will be returned](https://github.com/django/django/pull/6236/files#diff-3c42de3e53aba87b32c494f995a728dfR168) and [db_field.formfield()](https://github.com/django/django/pull/6236/files#diff-3c42de3e53aba87b32c494f995a728dfR178) won't have a chance to be called. In this case, the formfield [will be ignored by ModelForm](https://github.com/django/django/blob/master/django/forms/models.py#L182-L185). Shouldn't we have a way to use the custom field's formfield() method even if it has many_to_one=True ? Note that this concerned is similar to the one raised in #24227
IMO we can simplify condition: ```not self.blank or (self.blank and not self.null)``` to: ```not (self.blank and self.null)```
This will work only for a simple use case, e.g. ``` python manage.py startapp test_four ../../main_directory/ticket_30618/ticket_30618/other_apps_3 ``` produces `name = '......main_directory.ticket_30618.ticket_30618.other_apps_3'`
IIRC raising CommandError prevents management commands from displaying a stack trace. This doesn't seem very important but I wanted to point out the change in behavior in case it was accidental.
Unless I missed something: - before: all `OSError` exceptions are converted to `CommandError`; in addition a specific message is added when the file already exists - after: only `FileExistsError` is converted to `CommandError`
Given that we're touching this, we should probably [use hanging indent](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Chop blank lines.
Need spaces around `+` sign.
`quote` isn't used anywhere.
I think we can leave the list of exceptions.
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
I do't think these changes are needed, since the empty value can be handled by display_for_value function.
Hey @David-Wobrock — I think I prefer this `try...except` approach. (We're catching a pretty niche error no?) What do you think? (Looks good otherwise.)
can you put `if not value` in the isinstance block below
Could you try to improve this so that there isn't duplication of the HTML and `escape(Truncator(obj)....`
Still I think `'&nbsp;<strong>%s</strong>'` could be factored as a variable and `<a href=...` interpolated inside that. Let's use `format_html` instead of `escape`. This return could go in the `else` block of `try/except/else`.
chop newline for consistency
Perhaps a nice alternative is: ``` result = json.loads(Question.answer_set.field.value_to_string(question)) self.assertCountEqual(result, [answer1.pk, answer2.pk]) ```
I don't think you can assume ordering here.
Please put the test in `AdminActionsTest`.
Implementation looks okay but should still check the response here and check that the "protected" page is displayed.
Please use f-strings as Python 3.6+ is now the requirement More information is available including some benchmarks. https://cito.github.io/blog/f-strings/
Chop blank line.
We can remove this check after fixing the `Field.slice_expression()`.
I think it will be more readable to keep `int` and `slice` in separate branches, e.g.: ```python def __init__(self, f_obj, slice_obj): if isinstance(slice_obj, int): if slice_obj < 0: raise ValueError('Negative indexing is not supported.') self.low = slice_obj self.length = 1 elif isinstance(slice_obj, slice): if ( (slice_obj.start is not None and slice_obj.start < 0) or (slice_obj.stop is not None and slice_obj.stop < 0) ): raise ValueError('Negative indexing is not supported.') if slice_obj.step is not None: raise ValueError('Step argument is not supported.') self.low = 1 if slice_obj.start is None else int(slice_obj.start) + 1 self.length = None if slice_obj.stop is None else int(slice_obj.stop) - self.low + 1 else: raise TypeError('Argument to slice must be either int or slice instance.') self.expression = f_obj ```
Casting `int` to `int` is not necessary.
I would revert this change, the previous version is clearer to me.
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
Period ```suggestion 'Quit and manually define a default value in models.py.', ```
Yup, that sounds good too. :)
`later` is a bit misleading, since the expectation is that the dev will update models.py (immediately) after quitting so that they can continue to create their migrations.
I would use the same message like in similar exceptions: ``` Joined field references are not permitted in this query ```
All `Col` should have an `alias`.
You can drop the `.contains_column_references` as it's wasteful in this case because of the way it walks the expression tree given we'll have to walk it anyway below.
Maybe you've missed `if summarize` branch (below).
We used the same message as in other places that's why I don't want to add a period only in this case.
I would rather keep the current behavior, but other opinions are welcome. It could be the target of a different ticket.
Tests are failing because you dropped the `]`.
You lost a ] in here.
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
We should use a custom storage for this test (instead of mocking).
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python error = PermissionError(errno.EPERM, 'message') with mock.patch('django.core.files.move.copystat', side_effect=error): ```
State the expected behavior as per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style. Also wrap docstrings at 79 chars.
I think it would be better to move `side_effect` to the `mock.patch`, i.e.: ```python with mock.patch('django.core.files.move.os.rename', side_effect=OSError()): ```
That's what `inspect.iscoroutinefunction(getattr(Foo, '__call__', None))` does above. What I mean is that it's probably an abuse of Python data model. For example, ```python def Test: async def __iter__(self): pass assert inspect.iscoroutinefunction(Test.__iter__) ``` Won't fail but `__aiter__` should be used for this purpose. There's no analogous `__acall__` for `__call__` and it's not clear to me whether `async def __call__` is an abuse or not.
State the expected behavior as per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style. Also wrap docstrings at 79 chars.
use """ for consistency with other docstrings
or just `# CSS files shouldn't be touched...`
Not sure these asserts bring value ... they seem to test that `override_settings` works.
This is the failing assertion on Windows. I think it might have to do with the file being written with Windows vs. Unix line endings. If you remove the assertion, the rest of the test passes.
The `CustomModelBase` class is not an actual `models.Model` subclass but a `models.base.ModelBase` subclass which is `type(models.Model)` (`models.Model`'s metaclass). We should use an actual `models.Model` subclass instead.
I don't see a big advantage to this change. The coding style says to use longer lines if it makes things easier to read -- my taste is to use `msg = '...'` if `with self.assertRaisesMessage(ValueError, '....'):.` is much over 79 chars.
I would rather create a custom model with field that has `db_column`, e.g. ```python project_state = self.apply_operations('test_rfwdbc', ProjectState(), operations=[ migrations.CreateModel('Pony', fields=[ ('id', models.AutoField(primary_key=True)), ('field', models.IntegerField(db_column='db_field')), ]), ]) operation = migrations.RenameField('Pony', 'field', 'renamed_field') new_state = project_state.clone() operation.state_forwards('test_rfwdbc', new_state) ```
I don't see much value in this check.
```suggestion Update a queryset using order_by on a unique constraint. ```
As the method doesn't require anything from the model except its `_meta.db_table` could we alter its signature to accept a `table_name` instead? It would be more consistent with the `column_names` argument instead of an hypothetical `fields` one. This is a change planed in #6643.
We could reuse `_field_should_be_altered()`: ```suggestion if not self._field_should_be_altered(old_field, new_field): ```
put self._create_index_name( on the next line of put the suffix="_check") parenthesis on the next line for balance
I'd move these methods above "def alter_unique_together" so those alter methods aren't separated from their helper, _delete_composed_index.
Please drop this docstring, I don't see much value in copying it from `base/schema.py`.
Drop the docstring I think,
Try to avoid `Check that` and `Check`.
Okay, super, thanks for the clarification @pope1ni. I shall take another look tomorrow and hopefully that's job done! Good work, as ever. 😉
We shouldn't change the context to keep this backward compatible: ```suggestion 'action_list': page_obj, ``` Updated.
I think you meant `get_ellipsized_page_range` here. Use `number` instead of `page_num` which matches the argument name used by `Paginator.get_page()`.
I'm confused. Is there something incorrect here or can this just be: ```suggestion self.connection.settings_dict['NAME'] = worker_db ``` If the intent was to avoid mutating the original then do this (although I'm not sure it's required): ```python self.connection.settings_dict = {**self.connection.settings_dict, 'NAME': worker_db} ```
Everywhere else uses an f-string, not sure why this doesn't: ```suggestion f"file:{alias}_{_worker_id}.sqlite3", uri=True ```
I'm slightly confused that were taking `source_db` from disk here with the same `_worker_id` value as the `worker_db` target. Maybe I'm missing something, but I thought we're trying to make copies for different processes, so the source and target cannot share the same `_worker_id`? 😕
Do we need named db? ```suggestion 'NAME': ':memory:', ```
This code is unreachable, because `get_test_db_clone_settings()` raises an exception for other start methods. ```suggestion ```
I'm not sure about the `backend` terminology here. I think naming this function `get_password_validators` would be more consistent with the rest of the the code.
I'd use `*args, **kwargs` for arguments that are simply passed-on without being accessed or modified, to reduce the number of places that a change in signature would need to be reflected, and to avoid having to repeat the same default values. We've had issues in the past in Django (in forms/formsets, IIRC) where the default value for some parameter to a superclass method changed, or a new optional argument was added, but nobody remembered to update subclass method signatures accordingly, causing bugs.
Can you check explicitly? ``` if tried is None: tried = [] self.tried = tried ``` This is a good practice in general to avoid hard-to-diagnose errors if an unexpected, falsy value of `tried` is passed in.
Should this be cached? The number of times validators are instantiated, and the associated cost with loading in the 1000 most common passwords each time strongly suggests that it should be.
do we need a blank line before each method? seems like it just makes things longer.
PEP 8 requires this blank line
For geometries, the data-source is different from a Geometry instance, as a data-source represents a list/table of geometries and attributes. This difference does not exist for rasters, the data source _is_ the raster. Thats why I named this class GDALRaster, as I suppose that is the more intuitive name. Did you have a second class in mind for the actual raster? If not, all rasters will be instances of RasterSource, which I think is not ideal.
`raster_model` or even just `r` is probably fine.
Would it make sense to add a string version of this too? From a user's point of view, the name of the corresponding data type could be useful. GDAL Pixel data types in source: http://www.gdal.org/gdal_8h.html#a22e22ce0a55036a96f652765793fb7a4 ``` GDAL_PIXEL_TYPES = { 0: 'GDT_Unknown', # Unknown or unspecified type 1: 'GDT_Byte', # Eight bit unsigned integer 2: 'GDT_UInt16', # Sixteen bit unsigned integer 3: 'GDT_Int16', # Sixteen bit signed integer 4: 'GDT_UInt32', # Thirty two bit unsigned integer 5: 'GDT_Int32', # Thirty two bit signed integer 6: 'GDT_Float32', # Thirty two bit floating point 7: 'GDT_Float64', # Sixty four bit floating point 8: 'GDT_CInt16', # Complex Int16 9: 'GDT_CInt32', # Complex Int32 10: 'GDT_CFloat32', # Complex Float32 11: 'GDT_CFloat64' # Complex Float64 } ```
I am not sure if this is the right regex, as it is imported from geometry.regex. I would say it is, thats why I used it here originally. But I am not certain and not very familiar with regexes. Maybe this option could be left away for now until a function to translate from WKB and a capi ptr is included. A related question is what wkb to use for rasters. As far as I know, the definition of a raster wkb is not as established as the WKBs for geometries. I would propose to use the PostGIS definition, but maybe there are others.
`return '%s-%s-%s' % (y or 0, m or 0, d or 0)` can be moved here.
Oh I missed the fact `datetime_trunc_sql` was used by `datetimes()`. This is fixing the reported use case where `'field'` is a `DateField` but wouldn't it break in the case of `dates('field', 'day')` where `'field'` is a `DateTimeField`? It looks like it wouldn't get truncated at all in this case.
Last nit, you don't need to be passing `self.template` here and `super()` will default to it if it's missing.
This is not covered by tests, also raising an exceptions in user-defined functions is not really helpful for users: ```python django.db.utils.OperationalError: user-defined function raised exception ``` I think we should return `None` instead.
I moved this check to the `DurationExpression`.
What @shaib said: `makemigrations` and `migrate` should fail, `showmigrations` should work.
I guess so.
The reason `makemigrations` should fail is that the more likely reason for inconsistent history is a change in the migrations code (in particular, dependencies), rather than direct manipulation of the database. If the code of existing migrations is suspicious, we should avoid building more migrations on it.
migrations isn't used
no need of inheriting from object
It would be great to also have a test with a reverse manager.
I'd rather not pollute the global namespace. Could you use a temporary `Apps` (e.g. https://github.com/django/django/blob/master/tests/migrations/models.py#L24)
Do we need `requires_system_checks` flag? All tests pass without this line.
I'm more inclined to put this in `tests/schema/test_logging.py`.
This is already checked in `user_commands.tests.CommandTests.test_call_command_no_checks()`. I will remove this test.
This can be single-lined.
I think we are missing the `call_command()` here.
We're avoiding the `self.fail()` pattern in favor of letting the entire exception bubble up.
This should be something like `self.assertEqual('migrations\n (no migrations)\n', out.getvalue().lower())` (perhaps adjusted a bit to match the output of showmigrations for other apps) (no SystemExit).
single line looks okay here and in the next test (it's shorter than the previous line, at least)
Make this and new_lookups sets.
Looks like we favor `type` in similar cases in the ORM ```suggestion return type(value)( ```
This could fit on a single line: `# Subqueries must use a different set of aliases than the outer query.`
The check should be inside prepare_lookup_value, not in build_filter.
```python kwargs = {'reuse': can_reuse, 'allow_joins': allow_joins} if isinstance(value, F): kwargs['simple_col'] = simple_col value = value.resolve_expression(self, **kwargs) ```
I don't think it's worth changing elsewhere.
I guess most test classes have a blank line after the class and before the first test method.
Use `six.assertRegex` to avoid the deprecated alias on Python 3.
I moved this test to the `tests/messages_tests/tests.py`.
how about: ``` try: query_that_shouldnt_fail = ... except ..ProgrammingError: self.fail('Appropriate Error Message') ```
```suggestion self.assertEqual([book.rating_count for book in qs], [1]) ```
What about ```suggestion self.assertNotIn('is_book', books.values().first()) ```
No need for `Value` wrapping since 1e38f1191de21b6e96736f58df57dfb851a28c1f ```suggestion is_book=1, ``` Ditto for all `Values` uses below.
Ahh looks like you'll need to keep passing `Value` in this case but you can drop the `output_field`. ```suggestion is_book=Value(1) ```
Per new code guidelines, can we use `assertIs`? :)
We can do the same for `reffed_expression`: ```diff diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index b3d92d786c..21bc0aea7a 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -1286,11 +1286,9 @@ class Query(BaseExpression): if check_filterable: self.check_filterable(value) - clause = self.where_class() if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) - clause.add(condition, AND) - return clause, [] + return self.where_class([condition], connector=AND), [] opts = self.get_meta() alias = self.get_initial_alias() @@ -1333,7 +1331,7 @@ class Query(BaseExpression): condition = self.build_lookup(lookups, col, value) lookup_type = condition.lookup_name - clause.add(condition, AND) + clause = self.where_class([condition], connector=AND) require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None: ```
I really don't like that we increase indentation here, it make code less readable, and it's complicated even without this :disappointed: We could reduce the number of changes significantly with: ```python if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) clause.add(condition, AND) # When col is nullable, add IS NOT NULL. col = self._gen_cols(reffed_expression) if col: lookup_type = condition.lookup_name target = col.target if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None and self.is_nullable(target): lookup_class = target.get_lookup('isnull') col = self._get_col(target, target, alias) clause.add(lookup_class(col, False), AND) return clause, () ``` and reverting related adjustments.
FYI I ran into the same issue of `AttributeError: 'generator' object has no attribute 'target'".` with this test checking if this PR fixed the issue when using exclude with an `alias` (flagged up in duplicate [ticket-32896](https://code.djangoproject.com/ticket/32896)): ```python # ExcludeTests def test_exclude_aliased_nullable_fields(self): number = Number.objects.create(num=1, other_num=1) Number.objects.create(num=2, other_num=2, another_num=2) qs = Number.objects.alias(aliased_num=F('num')) self.assertSequenceEqual( qs.exclude(another_num=F('aliased_num')), [number], ) self.assertSequenceEqual( qs.exclude(aliased_num=F('another_num')), [number], ) ```
yeah having an `Expression.nullable` flag that is also present on `Col` instance based on the `Field.null` they resolve would be useful for a few other things I've worked on in the past.
I'll edit this docstring to remove the references to the removed parameers, but please check my edits.
As far as I'm aware we don't need to iterate twice over the same list: ```suggestion return { '%s.%s' % ( fixture_name, '.'.join([ext for ext in combo if ext]), ) for combo in product(databases, ser_fmts, cmp_fmts) } ```
IMO we should revert this change `fixture_file` is an absolute path, so it can contain directories with dots in names, this can cause issues in `parse_name()`.
May be an easier change for django reviewers if you keep this block in the same format as the one you replaced
You could use `for else` construct here. ``` python for fixture_label in fixture_labels: if len(self.find_fixtures(fixture_label)) > 0: break else: return ```
My code sucks. Feel free to change in other places.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
Can this be simplified to ```suggestion # Collation change? elif getattr(old_field, 'db_collation', None) != getattr(new_field, 'db_collation', None): new_collation = getattr(new_field, 'db_collation', None) fragment = self._alter_column_collation_sql(new_field, new_type, new_collation) actions.append(fragment) ``` Or maybe we want to keep the old code to support field type and collation change at the same time (e.g. `CharField(db_collation='foo') -> TextField(db_collation='bar')`).
You want to avoid altering `self` here as subsequent calls will reuse this attribute even if this branch's conditions don't match.
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
I'd say "Return a (sql, params) fragment to set a column to null or non-null as required by new_field, or None if no changes are required."
`os.chmod` should be before the `try`. It doesn't make a big difference but that's the common pattern in general.
`weak=True` is the default.
The parameter to this method seems odd to me. As it stands, no caller is explicitly using the parameter in a call to the method and I can't see many legitimate uses for it in derived classes. I think you're effectively just using the default value as a space to store a class-scope variable. Would it be simpler to just assign a member on the class? Or on the instance, if you prefer.
Having an overridable method seems like the most orthodox OOP solution (it's what a Java programmer would do :-) ) but I'm not convinced it really gives a useful abstraction: by coincidence it's the right place to make this one change, but I'm not sure there's a useful class of future modifications it opens up, so it feels like overkill to me. My thought with an instance variable was just to set it in the constructor in the base class, and overwrite it in the subclass constructor (not exposing it as a kwarg). I'm not sure there's any advantage to this; I think I was thinking about this because it's what I'd do in C++. I don't have a particularly strong feeling on this. I think if I were writing it I'd go with the class-level attribute.
Maybe a helper method would help eliminate the redundancy of these methods? e.g. `return self._value_or_setting(self._location, settings.MEDIA_ROOT)`
Extract units declared ...
`# GDAL's semiminor calculation.`
no space for "Spatial Reference"? (or no caps if it's not meant to refer to the class)
two spaces before #
This cleanup is not related with a patch please move it to a separate commit/PR.
You won't need to pass `INFO` if the default is `INFO`.
I would do what the other tests do and pass `test_labels` as a positional argument. Also, to be clearer what `foo` and `bar` are doing, it might be better to call them something like `notfound1` and `notfound2`. I'm assuming it's finding two failed test instances for labels not found. Alternatively, you could find real tests by passing something starting with `'test_runner_apps...'`.
Since `verbosity=1` is the default, you can leave this out. (It's good to be testing the default behavior.)
Please test the entire message.
I think the `@property` syntax would be more readable here.
Maybe it should go in `django.contrib.mysql`...
The fact you have to special case `DefaultNow` makes it look like a code smell to me, this logic should be completely abstracted by whatever is allowed to be passed to `db_default`.
It would be more readable to raise an error explicitly (like previously), e.g. ```python db_features = connections[self.db].features if ignore_conflicts and not db_features.supports_ignore_conflicts: raise NotSupportedError('This database backend does not support ignoring conflicts.') if update_conflicts: if not db_feature.supports_update_conflicts: raise NotSupportedError( 'This database backend does not support updating conflicts.' ) if unique_fields and not db_features.supports_update_conflicts_with_target: raise NotSupportedError( 'This database backend does not support updating conflicts with ' 'specifying unique fields that will trigger the upsert.' ) ``` (I used new feature flags.)
Ditto for `[]` → `None` and `ON_CONFLICTS_NONE` → `None`.
This should not be necessary as not reference to non-litteral values should be allowed in here.
Ahh, that's gonna be more interesting. You'd need to look at `self.migrations_module(x[0]) is not None` for whether there are migrations for that particular app or if they are disabled.
Furthermore, why do you construct `unapplied_parents` at all? Can't you just loop over `self.graph.node_map[migration].parents` and on raise an exception when the first one has an inconsistent history? That would safe some time in bigger projects. ``` python for x in self.graph.node_map[migration].parents: if x is unapplied # use the condition from above raise InconsistentMigrationHistory(...) ```
I don't think this is correct. `settings.MIGRATION_MODULES` only contains user-defined migration modules -- presumably want the detection to work regardless of whether or not that setting is defined.
"its" add period
use PEP 257 verb style "Check ... Raise .."
This seems like an odd place to put this... between the logging of test database creation and the actual creation. Actually, it might be possible to call `connection.creation.mark_expected_failures_and_skips()` in `runtests.py`. That would be cleaner and eliminate the need for the environment variable.
An error the database
param -> params
I'd chop this blank line since the } on its own line is providing whitespace.
`BaseDatabaseCreation` shouldn't contain branches for specific backends.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
This seems a bit redundant. I believe that the feature flags should be used as much as possible, instead of checking against vendor names.
`assertRaisesRegex` should be avoided, I believe, cc @timgraham I've seen a pattern in the migration tests where `self.assertIn` is used to check for parts of the message.
`assertRaisesMessage` uses `assertIn` so it works just as well without the need for the `.*`.
`UniqueConstraint` not `Index`.
These assertions are redundant with tests where `qs1.intersection(qs2).exists()` is `False`.
I guess these could be merged by doing a ```python self.assertEqual( qstr.count("LIMIT 1"), 3 if connection.features.supports_limiting_in_compound else 1 ) ```
I would assert that querysets return the expected tag. Also, temporary variables are unnecessary. For example: ```python tag = integration.tags.create() self.assertSequenceEqual(TTag.objects.filter(integration=integration), [tag]) self.assertSequenceEqual(TTag.objects.filter(integration__id=integration.id), [tag]) ```
you can use `a` here again.
Use `ConcreteRelatedModel.objects.get(bases__id=base.id)` here instead of comparing lists.
This is redundant with `test_none_name()`.
Use single-quotes in the new code.
I'm reminded of #21381 (removing contrib.redirects dependency on contrib.sites), but not sure that should block this.
Personally if it were happening to me, I'd be **thrilled** if it could tell me what needs applying, and if it couldn't and instead directed me to another command to run I'd _assume_ (and be disappointed) that the information wasn't available at the time the exception occurred. If it is there, I think it's prudent to respect the user's needs and attempt to surface the information. That said, my gut feeling is that the exception output format maybe isn't "right" (for a given value thereof). I can't recall many (any?) places where Django raises with an arg which is multiple lines. Those cases where there's multiple _things_ to enumerate tend to just get comma separated. That does leave the door open to super long lists though, if for whatever reason the partially applied list was big... Maybe because it's related to running migrations, which _are_ line oriented, it's OK? [Edit to add: big thumbs up from me to the information, FWIW. Next step seems much clearer as a result]
```suggestion # Validate app_label. ```
Now we can call this `test_migrate_app_name_specified_as_label` (and similar for the similar test).
Can you reference the ticket number in the docstring, please.
if no app*
Remove the blank line.
This should be something like `self.assertEqual('migrations\n (no migrations)\n', out.getvalue().lower())` (perhaps adjusted a bit to match the output of showmigrations for other apps) (no SystemExit).
Use hanging indent: ``` raise ValueError( '"%r" needs to have a value for field "%s" before ' ... ) ```
Alternate possibility (tested on SQLite): ``` python try: rel_obj = getattr(instance, self.cache_attr) except AttributeError: rel_obj = None else: if rel_obj and (ct_id != self.get_content_type(obj=rel_obj, using=instance._state.db).id or rel_obj._meta.pk.to_python(pk_val) != rel_obj._get_pk_val()): rel_obj = None if rel_obj is not None: return rel_obj ... ```
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
Is this branch tested? No tests seem to fail (I tired SQLite & PG) if it's removed.
I checked related ticket [30152](https://code.djangoproject.com/ticket/30152) and I'm in favor of [Matthijs' proposition](https://code.djangoproject.com/attachment/ticket/30152/testcase_and_rough_fix.patch) because we don't need to go through all fields.
Yeah, screw that :D in the worst case make it an attribute on the CSRF class, so a user can override it if we go down the route with an extra class.
If we want to change the default we can add a separate ticket and change it in Django 4.0. There is no need to use `VERSION`.
This is the default, it is needed? Perhaps another test for a non-default would be useful.
use a single line
`getattr` raises an exception when the attribute doesn't exist and no default is given
why not define this tuple at import time? `import pytz` seems to already have made the classes accessible.
Typo `separator` instead of `seperator`. I would call it `sign`, TBH.
`value` or `return_value`? or maybe we should swap these lines: ```python if ( not timezone._is_pytz_zone(current_timezone) and timezone._datetime_ambiguous_or_imaginary(value, current_timezone) ): raise ValueError('Ambiguous or non-existent time.') return timezone.make_aware(value, current_timezone) ``` :thinking:
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
Do we need to use a dict? It seems unnecessary complicated. Model classes that we pass in the keys must match the base models from querysets. We also don't protect against incorrect values e.g. ```python queryset={ Animal: Bookmark.objects.all() } ``` I would use a list/tuple instead and raise an error when a queryset for the specific model is already resolved, e.g. ```python for qs in querysets: ct_id = self.get_content_type(model=qs.query.model, using=qs.db).pk if ct_id in custom_queryset_dict: raise ValueError(...) custom_queryset_dict[ct_id] = qs ``` We should also add a new argument (maybe `querysets`) because it's misleading to pass list of querysets in the argument called `queryset`.
Correctly indent the bracket to match the `return` indentation.
Current implementation of `get_prefetch_queryset()` assumes that all instances have the same content type (there is an issue), but the fix is not optimal IMO because object IDs can be the same in different content types, e.g. we have two related objects: - object ID 1 with content type ID 1, - object ID 2 with content type ID 2, this query will return also: - object ID 2 with content type ID 1, - object ID 1 with content type ID 2, which is not correct. I know that we are matching them below but still I think we can limit the no. of objects only to actually needed.
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
I would leave it as a `lambda`.
This should be something like `self.assertEqual('migrations\n (no migrations)\n', out.getvalue().lower())` (perhaps adjusted a bit to match the output of showmigrations for other apps) (no SystemExit).
Use `no_color=True` to about matching against escape sequences. It looks like `verbosity=2` is also unnecessary? ```suggestion call_command("showmigrations", format='list', stdout=out, no_color=True) ```
You could use single quotes in all strings for consistency (don't worry about existing tests).
This leaves a "dummy" SQLite database on the filesystem after running the tests.
```suggestion self.assertEqual(err.getvalue(), 'No statements found.\n') ```
At the point where the instance is created, there is not access to the model or its fields (we are in a nested class in the model class definition). Options and/or the modelbase metaclass, will have to connect the model to the index.
Use single quotes
There should be a sane API through `schema` ( A SchemaEditor, I presume) to do this.
Any problem with allowing `self.model = None`. I think conditional attributes which require `hasattr` isn't the best design.
I think this could be `@cached_property` so it doesn't have to be calculated on every access.
> Not really no.. Now that i think of it this will also address issues where data or keys (delete_many) don't have the expected type.. e.g. keys been None or data been None.. Why? `data`/`keys` are not falsey when they contains `None` :thinking:
Is there a reason to do this with `safe_data` instead of passed `data`? (the same in `delete_many()`), e.g. ```python def set_many(self, data, timeout=DEFAULT_TIMEOUT, version=None): if not data: return [] ... ```
Use a single line (we allow up to 119 characters when it helps readability)
chop blank line
Use a single line (we allow up to 119 chars when it helps readability) or we use hanging indent.
I would remove _"We should"_.
no blank line please
Set the name of _meta.indexes. This can't be done in Options.contribute_to_class() because fields haven't been added to the model yet.
Are we sure a `delete` is required because a truncated value will be set when it overflows? I guess we should also wrap `super().set()` instead of duplicating its body.
you can collapse, `with self.assertRaises(Exception), connection.cursor() as cursor:`, and in a few places below.
This line can be removed :thinking:.
IMO this line is unnecessary, and above `iter()` call can be removed.
`seprate` -> `Separate`, also trailing dot is missing.
Alright let's keep it as it is then. I just wanted to make sure this case was covered by a test.
add trailing comma
Similarly, I don't see much advantage to creating indirection with a method.
a misspell? SQLFuncMixn -> SQLFuncMixin
Since `SmallAutoField` extends `SmallIntegerField` this can be reduced to ```suggestion elif isinstance(self.lhs.output_field, models.SmallIntegerField): ```
It's nice to include a message for the exception (we had a ticket about adding messages to all of them)
I don't like this solution because it creates even more caveats on Oracle. I will try to figure out sth. 2 hours later ... :hourglass_flowing_sand: I found quite small (and clean IMO) workaround that works in "all" cases: ```diff diff --git a/django/db/models/fields/json.py b/django/db/models/fields/json.py index edc5441799..5458fe91d0 100644 --- a/django/db/models/fields/json.py +++ b/django/db/models/fields/json.py @@ -163,7 +163,13 @@ class DataContains(PostgresOperatorLookup): lhs, '.%s' % json.dumps(key), json.dumps({'value': value}), ) for key, value in rhs.items() ]), params - return sql % (lhs, '', json.dumps({'value': rhs})), params + if isinstance(rhs, list): + if not rhs: + return "DBMS_LOB.SUBSTR(%s) LIKE '[%%%%]'" % lhs, params + return sql % (lhs, '', json.dumps({'value': rhs})), params + # Add JSON_EXISTS condition for JSON_ARRAYs. + sql = "%s = %%s OR JSON_EXISTS(%s, '$?(@==%s)')" + return sql % (lhs, lhs, json.dumps(rhs)), (rhs, *params) class ContainedBy(PostgresOperatorLookup): ```
In fact, this should be moved into the definition of `context` above: ```python 'can_view_related': self.can_view_related, ```
Remove unnecessary hanging indent, simplify: `context['can_change_related'] = True`
Remove unnecessary hanging indent, simplify: ```python context['change_related_template_url'] = self.get_related_url(info, 'change', '__fk__') ``` (This makes the line 99 characters, but I think it is clear enough.)
If you want to use a new name, that's okay with me, but I think `'has_file_field'` should remain for backwards compatibility.
Move `has_view_permission` above `has_add_permission` for consistency.
Yes it should be `R.p`, we didn't take into account nested protected relations in the ab3cbd8b9a315911248227208630a020cedca08f (probably my fault). Also casting to list is not necessary anymore after this change.
I don't think that we need 3 authors and 6 books for this test. I will remove the last author.
use single quotes throughout params also, if the params fit on the same line as `Thing.objects.get_or_create(` that's fine. You could change "does_not_exist" to "nonexistent" and "some_value" to "b" to save a few characters if it helps with line length.
I removed it.
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
`raster_model` or even just `r` is probably fine.
These tests are specific for the SQLite back-end. We don't need this hook.
Improved typography and changed to [%-formatting](https://docs.python.org/3/library/stdtypes.html#old-string-formatting) to be consistent with other error messages.
You're calling `model_name.lower()` twice in most cases
Yes, this should be taken care of before.
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
I don't think you need `list()` here.
could switch to single quotes for consistency
Trailing comma: ```suggestion migrations.RunPython.noop, ```
```suggestion 'INSERT INTO test_runsql_pony (pink, weight) VALUES (1, 1)\n', ```
Trailing comma: ```suggestion migrations.RunPython.noop, ```
should be `first_state`, not `project_state`, I suspect.
IMO it's enough to test that `CreateExtension` honor `allow_migrate()`, creating extension is already tested in `postgres_tests`.
Same 'mutually' typo here.
I'd single line these to save lines: `[self.a4, ...]`
Use: ``` msg = '...' with self.assertRaisesMessage(ValueError, msg): ```
This can be single-lined.
Add a trailing comma.
Citing @holvianssi on Trac. > The complex solution is to add both the opt-in flag and database settings. The default for the opt-in flag is None, meaning use the default from database settings. True forces this feature on, and False forces the feature off.
Shouldn't this be along the lines of ```python def iterator(self, chunked_fetch=None): if chunked_fetch is None: chunked_fetch = connections[self.db].settings_dict.get('ENABLE_SERVER_SIDE_CURSORS', True) return iter(self._iterable_class(self, chunked_fetch=chunked_fetch)) ```
Is there a reason you used `None` here rather than `constants.GET_ITERATOR_CHUNK_SIZE`? As I was amending the docs with 'The default of ``None`` uses a value of 100." I thought further explanation about that reasoning might be useful.
We'll want to do something with regards to the newly added support for `iterator`'s `prefetch_related` here.
> We'll want to do something with regards to the newly added support for iterator's prefetch_related here. That looks like a _moderate_ task in itself (to implement) — `islice`, `prefetch_related_objects`, ... — it might be that adjusting the PR here match the new interface, but emitting a warning if prefetches are set would let us get this in, to work on async prefetches later. (Would be equivalent to the sync behaviour before edbf930287cb72e9afab1f7208c24b1146b0c4ec — of _either prefetch or iterator_.) 🤔
This is also a separate issue, but it's not testable without functional constraints so we can leave it here.
Cool I'll do that later tonight.
@Ian-Foote I discovered an issue with this approach is that it will include inlined named foreign key and primary key constraints as well. https://www.sqlite.org/syntaxdiagrams.html#table-constraint Django doesn't create such constraint itself but usually the introspection module is supposed to be able to deal with any form of schema. I'll include the adjustments in a following commit. Thanks for the parsing logic by the way, this is really neat.
Simon, did you fix this issue in your branch? Feel free to push an update here.
Thanks. There might be a bug because when I rebase https://github.com/django/django/pull/10337, `self.assertIn('unique_name', constraints)` fails on SQLite.
We could do that. I had planned to simply fill in the Python 3 message in a few months when Python 2 support is dropped in master.
Including a bit more of the message might help readability to understand exactly what `TypeError` is raised..
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
I think at least the latter is worth it - it's confusing to submit two files and be told "the" file is empty.
I try to avoid "we", e.g. The check allows a double slash, presuming the user knows....
```suggestion on_conflict=on_conflict, ```
```suggestion on_conflict=on_conflict, ```
Oh, I thought it was referring to two separate issues. Alright then, I'll make a new PR and we can proceed from there
I think we should use `local_concrete_fields` :thinking: Also, the current solutions doesn't work with recursive parents, e.g. ```python Pizzeria.objects.bulk_create([ Pizzeria(name='Vegan Pizza House', rank=33), ]) ``` crashes when we add the `Ranked` model: ```python class Place(models.Model): name = models.CharField(max_length=100) class Meta: abstract = True class Ranked(models.Model): rank = models.IntegerField(null=True) class Restaurant(Ranked, Place): pass class Pizzeria(Restaurant): pass ```` ```
Yeah, it's fine.
"leave blank to use" wouldn't be applicable for FKs
use message or input_msg through, no need for two different variables I think
No need to duplicate all this stuff, just put a conditional in the interpolation: `' (%s') % capfirst(field.rel.field_name)) if field.rel else ''`
On second thoughts creating a URL with to_field isn't required to test this issue – so the string interpolation can simply be removed: ```suggestion admin_user_change_url = reverse( "admin:%s_%s_change" % (user._meta.app_label, user._meta.model_name), args=(user.username,), ) ```
Please don't make unrelated whitespace changes.
I wonder if the `isinstance()`condition results in any performance savings? I tend to think always casting might be simpler.
The nested if statements seem excessive. Could this whole thing just be simplified to the following: ```python def formfield(self, **kwargs): if self.choices: include_blank = not (self.has_default() or 'initial' in kwargs) defaults = {'choices': self.get_choices(include_blank=include_blank)} else: form_class = forms.NullBooleanField if self.null else forms.BooleanField # In HTML checkboxes, 'required' means "must be checked" which is different # from the choices case ("must select some value"). # required=False allows unchecked checkboxes. defaults = {'form_class': form_class, 'required': False} return super().formfield(**{**defaults, **kwargs}) ```
It seems like a lot of complexity can be stripped out of this: ```python if self.base_field.choices and "choices_form_class" not in kwargs: obj = self.base_field defaults = { "choices_form_class": forms.TypedMultipleChoiceField, "coerce": self.base_field.to_python, # XXX: Do we actually need this? } else: obj = super() defaults = { "form_class": SimpleArrayField, "base_field": self.base_field.formfield(), "max_length": self.size, } if self.choices: warnings.warn("Choices should be defined in base field.", RemovedInDjango51Warning) return obj.formfield(**{**defaults, **kwargs}) ``` Obviously the behaviour of this post-deprecation also needs to be decided: - Does it throw an exception? - Does it silently ignore choices on the `ArrayField`? (Might need to actively strip them out?) - If we promote a system check warning to error, does it matter which approach we choose? (Not everyone uses the checks though.)
Sorry - typo. Fixed.
Oh, no, OK, the nextval will always return a different value. It's just that we might have gaps if one value is not saved.
`self.real_apps` is always a set, `set()` is unnecessary (here and in many other lines).
`(app_label, model_name)` is also used to get a model state, I'd cache it in a local variable, e.g.: ```python model_key = model_state.app_label, model_state.name_lower self.models[model_key] = model_state if self._relations is not None: concretes, _ = self._get_concrete_models_mapping_and_proxy_models() self.populate_relation_from_model_state(model_state, model_key, concretes) if 'apps' in self.__dict__: # hasattr would cache the property self.reload_model(*model_key) ```
This should only be performed if the `relations` registry is already computed; `if 'relations' in self.__dict__`
> Would that be fine? Or is there something I am missing? `else` is not necessary, there is no need to resolve relations at this point.
The same amount of caching would be happening in the approach I'm suggesting. It's just that you would be calling `self.resolve_fields_and_relations() / self.all_relations = ...` (e.g. in a method) instead of accessing a cached property. It just seems like the usage in the PR doesn't really match `@cached_property`'s use case. In addition to what I mentioned above, the calls to `self.all_relations` in the PR aren't using the return value, it's just doing that for the caching side effect, which you could do more simply / explicitly.
I don't think we need this here. In `disable()` we `raise self.first_exception` (when `not None`) so this line will be unreachable.
One solution here would be to make `enable`/`disable` idempotent by having a class level `enabled = False` attribute that gets set/unset and checked for early return in both methods or to override `__exit__` to deal with `exc_value == self.enable_exception` in a special way.
You are right I missed the fast that exceptions raised during `__enter__` are not going to go through `__exit__` sorry for that. That makes these tests unnecessary.
Use `as e` or as `as exc` to match other code.
I realize it involves creating a `dict` instance to immediately transform it to a `list` but I'm not convince we should support two initialization paths for `SimpleTestCase._pre_setup`.
Again, not related but use `force_raster_creation=True` rather than a tough to decipher plain boolean.
Don't want to add a db feature for that? (Just wondering about you're thinking since I thought we're trying to avoid vendor checks.)
`raster_model` or even just `r` is probably fine.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
I think we can change `rast_index_wrapper` instead.
@charettes, any reply here? I guess we shouldn't block the patch about the issue with backwards migrations if we can't find a simple solution.
Ah, didn't know this existed yet. I see that this PR is mostly a "copy" of the ContentTypes one. Sounds alright for now, then.
I guess some tests might be needed for the router stuff.
chop trailing ", "
It's not required here. It was used in f179113e6cbc8ba0a8d4e87e1d4410fb61d63e75 because we were handling a possible `IntegrityError`.
Note that I didn't plea for keeping the functionality. I just said that if we remove that, it should be done properly (backwards incompatibility note, separate commit).
I'm in the habit of including an trailing , for all QuerySet filter kwargs.
I think wrapping in `Point()` is causing the test crash.
Same as above, (simply `postgis`)
@timgraham is ordering by the result of an aggregate allowed without subqueries? If ordering by count does not error, then it should be safe to use that ordering. If not, introducing a different field into the orderby will affect the grouping (not that you suggested that), so we'll need to look at comparing the queryset out of order if there's another assert method available that does that. I'm not able to check either of these things at the moment, but I can take a look in about 8 hours if it's not resolved.
Nitpick but `dict.get` default value for a missing key is already `None`.
generate_removed_indexes() and generate_added_indexes() (add parentheses)
I don't think so -- the autodetector isn't a public API that's meant to be extended.
The default argument for `pop` should not be necessary. When looking at the definition of `db.models.indexes.Index.deconstruct`, the `name` is always defined
I feel like there should be some dependencies declared on the operation here - the one that comes to mind is that it should depend on creation of its model, and delete model should depend on it.
The `num_args` argument was introduced in b6812f2d9d1bea3bdc9c5f9a747c5c71c764fa0f specifically for `get_callable` (note how it can take two arguments but the `num_args` is 1). I suspect there might be something weird going on but I haven't had time to look into it and unfortunately, we cannot ask the original committer of that change anymore :(
```suggestion (route, view.__name__, view.__name__) ) ```
I would revert this change. We want to add a system check so this seems redundant.
I'd use present tense here: "... is not a callable ..."
Use `six.string_types` from `django.utils.six` (which is already imported).
You don't like f-strings at all, do you? :-)
We currently prefer single quotes. The wrapping parentheses are not required.
~~You don't need to create a list, actually. You can just pass the generator expression through (no surrounding parentheses are needed). So `...join(key.encode(...`.~~ Never mind, I learned that this is slower (what @pope1ni was probably saying in the first place).
This has come up in the past when we were looking at removing unnecessary list comprehensions in favour of generators. IIRC, `str.join()` converts input to a list if it isn't already.
When using `str.join()` it is preferable to pass a `list` as it is slightly faster.
This is exactly the same as the previous case, maybe `('test@example.com',)`
format parameters as described above
Please drop that new line
this line should be: `def __init__(self, *args, **kwargs):`
Can you please unfold this loop. It's hard to check what actually failed if one item in the list fails.
Just a nitpick: The test name looks already readable to me so I'd drop the docstring.
Separate to this PR: Even given ticket-23403, we could perhaps look at deprecating use of `date` here. 🤔
`).values()` on next line
use single quotes
This test will be stronger if you assert that `datetime.now` is called with the time zone you expect (or if you write a little mocking function that returns the specified datetime in the time zone passed to `now`).
`VACUUM INTO` was [added in 3.27.0](https://sqlite.org/releaselog/3_27_0.html). This would bump requirements in `databases.txt` and `check_sqlite_version()` check in `django/db/backends/sqlite3/base.py`
`will re-opened in to ...` should maybe be something like `will re-open in ...`
param -> params
I'd chop this blank line since the } on its own line is providing whitespace.
To keep the diff a bit cleaner, I wouldn't make this unrelated whitespace change.
There should never be a reason to encode ascii to something else. While technically valid it makes mails bigger (especially if at one point we decide to call sanitize address for all addresses)
Please add edge cases to cover caching `IndexError` and `HeaderParseError`: ``` # Other invalid addresses. '@', 'to@', '@example.com', ```
single line here is okay (lines up to 119 chars are fine when it improves readability)
I am not exactly sure about that change of mine. It is probably okay that `sanitize_address` returns a long address, but I'll have to double check if actually serializing a message like that rewraps it again.
I guess you probably want `from django.test.utils import requires_tz_support` instead.
seems like we could use `super()` instead.
`aiter` is new in Python 3.10. https://docs.python.org/3.10/library/functions.html#aiter Django 4.2 will support Python 3.8, and 3.9 too.
There is not need for an extra variable (`expected_repr_response`), also, we should call `__repr__` directly: ```suggestion self.assertEqual(repr(r), '<StreamingHttpResponse status_code=200>') ```
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
I think there's a constant for `'self'` as well somewhere in `django.db`.
I think that `result` should be a tuple `result = ()` rather than list.
I guess `self` probably can't be used as a field name very well, e.g. ``` >>> MyObject.objects.create(data='bar', self=my1) TypeError: manager_method() got multiple values for argument 'self' ```
Dot is missing: `'Choices are: %s.'`.
No need for `keys()` here.
I think we can move `msg` to the assertion, I don't see much value in creating a temporary variable here.
Please wrap at 79 chars.
Please wrap at 79 chars.
* `--force_color`? (i.e. with `--`) * ~~Re-wrap?~~ (Sorry diff view confused me: you already did this.)
Please wrap at 79 chars.
No need for `iter`, a generator expression works just fine.
Ahh right, I forgot about it. Thanks!
@pope1ni no, it's heavily cached as it's using `ContentType.objects.get_for_model`.
Could use `reduce` here. ```python reduce(operator.or_, content_type_queries) ```
Current implementation of `get_prefetch_queryset()` assumes that all instances have the same content type (there is an issue), but the fix is not optimal IMO because object IDs can be the same in different content types, e.g. we have two related objects: - object ID 1 with content type ID 1, - object ID 2 with content type ID 2, this query will return also: - object ID 2 with content type ID 1, - object ID 1 with content type ID 2, which is not correct. I know that we are matching them below but still I think we can limit the no. of objects only to actually needed.
Use hanging indent: ``` msg = ( "..." ) ``` Are the new messages tested? I think you could avoid the repetition of the two branches by interpolating "keyword " in the message and varying args/kwargs in the params with a variable.
Also, see ticket trac, it seems 2396 is obsolete.
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
that's the default in 1.9, but I don't if you want to include it anyway
This too. I meant for both of the checks to be via `check()`.
`repercent` is a confusing name, maybe `repercent_broken_unicode`? Also it needs a docstring with pointers to the RFC etc.
Is there a reason that I'm missing (probably) that the field's length is 36 (and each DB's backend definition is 36, with the exception of postgres, which has the native datatype)? Removing the dashes (if a string) or calling `.hex` turns the value into 32 chars, which both `uuid.UUID()` and postgres' datatype support as a input format, and both use the dash-inclusive output format.
Could you try to improve this so that there isn't duplication of the HTML and `escape(Truncator(obj)....`
Still I think `'&nbsp;<strong>%s</strong>'` could be factored as a variable and `<a href=...` interpolated inside that. Let's use `format_html` instead of `escape`. This return could go in the `else` block of `try/except/else`.
This branch in untested :thinking:
The primary key attribute can only be retrieved on certain databases, this will not work on Oracle or MySQL.
Tests for `formset_factory()` and `formset_factory()` are missing.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
Please chop unnecessary blank lines.
Add trailing comma.
Use `setUpTestData` now that two models will be used by two methods.
In cases like this, we prefer to include a trailing comma so if more items are later added, we don't need to modify this line again.
Need to test that result is as expected, not only calling it.
I think this test would be fine without the blank lines, it's fairly short.
single line looks okay here
You can drop this line.
Please add an empty line above.
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
Ha! So it's actually related to your changes :-) Happy to hear that we'll eventually get the semantics that I would expect.
This isn't related to your changes, but I'm intrigued by Django's behavior here. I would expect `|escape` to give `&amp;` and `|escape|force_escape` to give `&amp;amp;`. Not that this construct makes much sense anyway...
You can reuse `CountryInlineAdmin` and `StateAdmin` instead of defining extra classes: ```suggestion ``` Add `get_formset_params()` to `StateAdmin`.
Chop blank line.
Use list and remove unnecessary whitespace ```suggestion fields = [('name', 'position')] ```
This can be single-lined.
```suggestion self.assertEqual( ```
Are you sure? Should this not be consistent with `SHORT_DATETIME_FORMAT`, i.e. `SHORT_DATE_FORMAT = 'j N Y'`.
My pleasure :)
@sdil Thanks for checking :+1:
@sdil Can you take a look? Thanks!
In Thailand it’s customary to use the [Thai solar calendar](https://en.wikipedia.org/wiki/Thai_solar_calendar) system (as it’s the official legal calendar in Thailand). Dates and months are the same as the common Gregorian Calendar, but years are in Buddhist Era instead of the Christian/Common Era. Just add 543 to the year number when displaying, and subtract 543 from the year number when parsing.
```suggestion self.models[app_label, new_name] = renamed_model ```
```suggestion renamed_model = self.models[app_label, old_name].clone() ```
```suggestion self.remove_model(app_label, old_name) self.reload_model(app_label, new_name, delay=True) ```
I think we can abstract away the need to _lower_ the name here. ```suggestion def alter_model_options(self, app_label, model_name, options, alter_option_keys=[]): ```
```suggestion def alter_model_managers(self, app_label, model_name, managers): ```
Jenkins doesn't do anything specific, and yes this test passes locally for me without a fix.
This test is passing even without a fix.
Just to make sure, this test fails before the change? (It's hard to know with a "negative" test and a hard-coded hash).
I usually just end the sentence with "(#26249)." instead of "Regression test..."
This is the failing assertion on Windows. I think it might have to do with the file being written with Windows vs. Unix line endings. If you remove the assertion, the rest of the test passes.
Thanks for explanation, I just want to minimize test, so your version with `id` looks good :+1:
`Model.__hash__()` returns an object `id`, so by using `self.assertEqual()` I thought that maybe we will partly cover both test lines (`hash(...) self.assertIs(...)`) with single assertion :smile:
```suggestion self.assertEqual(hash(ParentHash(id=1)), 1) ```
I'm not sure if this assertion is necessary :thinking:.
use a msg variable
These check should respect `required_db_features`, so we need to omit checking conditions for `UniqueConstraint`\`s if `connection.features.supports_partial_indexes or 'supports_partial_indexes' in cls._meta.required_db_features`.
This duplicates logic from `_check_local_fields()` and added unnecessary error `models.E042` which is already covered by `models.E012` in `_check_local_fields()`. I think we should pass fields from `references` to the `_check_local_fields()` and remove redundant logic, e.g. ```python for field_name, *lookups in references: fields.add(field_name) if not lookups: # If it has no lookups it cannot result in a JOIN. continue try: field = cls._meta.get_field(field_name) if not field.is_relation or field.many_to_many or field.one_to_many: continue except FieldDoesNotExist: continue # JOIN must happen at the first lookup. first_lookup = lookups[0] if field.get_transform(first_lookup) is None and field.get_lookup(first_lookup) is None: errors.append( checks.Error( "'constraints' refers to '%s' which results a JOIN attempt, " "JOIN is not permitted in 'constraints'." % LOOKUP_SEP.join([field_name] + lookups), obj=cls, id='models.E042', ) ) errors.extend(cls._check_local_fields(fields, 'constraints')) ```
This would be more readable and consistent with our indentation style with something like: ``` foo_constraints = [ name for name, details in constraints.items() if details['columns'] == ['name'] and details['unique'] and name != custom_constraint_name] ] self.assertEqual(len(foo_constraints), 1) ``` (choosing a different name than "foo"
What about m2m and reverse relationships? Something like `Q(cities=3)` will also produce the join.
Looks like we just need to use `_meta._get_fields(reverse=False)`.
Same as above, (simply `postgis`)
It would be safer to assertEqual with False/True since these assertions pass on any truthy/falsey value.
of -> than the
Up to you, but I think the tests are short enough that the blank lines don't help much.
I was close to restore a regexp :wink:, but let's leave it as it is. Thanks :+1:
so i think it would be better if there were actual nested for-loops: ```py for index in cls._meta.indexes: for name, order in index.fields_orders: # avoid the '-' logic in the check, it's already done in Index.__init__ ``` and if we used `obj=index` then the message should be clearer as it shows which index is referred to
```suggestion "index_together": {("bio", "age")}, # RemovedInDjango51Warning. "indexes": [], ```
That's absolutely right. I'm wondering if it might be helpful to implement `Index.clone()` which does a deconstruct/reconstruct a la https://github.com/django/django/blob/master/django/db/models/fields/__init__.py#L463-L469
You need to copy the `model._meta.indexes` list, otherwise you're reusing the same index instance across multiple models which could lead to other errors. I suggest `indexes = model._meta.indexes[:]`.
These changes have to be as separated commit (since unrelated to ticket)
In MySQL introspection we use `table_schema = DATABASE()`, I think we should use it here.
```suggestion for table_name, table_rows in rows: ```
[This is only an estimate on InnoDB tables](https://dev.mysql.com/doc/refman/5.7/en/tables-table.html) which is the default table engine and what's used on CI. > The number of rows. Some storage engines, such as MyISAM, store the exact count. For other storage engines, such as InnoDB, this value is an approximation, and may vary from the actual value by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate count. In short that means this value could report 0 while there's actually rows in the table and cause errors similar to the one you are experiencing.
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
Chop blank line.
Is the complexity of testing with a logger needed? I think a print statement and passing `stdout=StringIO()` to `call_command()` in order to check the value would be sufficient.
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
Yea, good point.
Could we patch a StringIO instead of devnull and then verify the contents of log_message()? See tests/check_framework/tests.py for an example. Also the patching should be in setUp/tearDown or in a try/finally so if something goes wrong the unpatching still happens.
use snake case, please: `test_login_required()`
Please order alphabetically.
DatabaseError is raised if a ....
chop blank line
I think the test fails as it is as you're no longer passing `self.timeout` to `smtplib.SMTP_SSL`. I don't think Django should specify a default of 60. Instead it should be `None` and only passed to the SMTP connection if the user specifies it. Here's a quick sketch of what I have in mind (plus some cleanup): ``` python # If local_hostname is not specified, socket.getfqdn() gets used. # For performance, we use the cached FQDN for local_hostname. connection_class = smtplib.SMTP_SSL if self.use_ssl else smtplib.SMTP connection_params = { 'local_hostname': DNS_NAME.get_fqdn(), } if self.timeout is not None: connection_params['timeout'] = self.timeout self.connection = connection_class(self.host, self.port, **connection_params) # TLS/SSL are mutually exclusive, so only attempt TLS over # non-secure connections. if not self.use_ssl and self.use_tls: self.connection.ehlo() self.connection.starttls() self.connection.ehlo() ``` For the test you'd subclass `EmailBackend` and verify the connection has the timeout use specified.
Instead of putting timeout in the `__init__` method, make it a class attribute. Here's an example change where we use this same technique: 8b0014869f666b44cd20692e38073ec0a0a8cb08
counterclockwise (no dash)
```python """Return whether this linear ring has counterclockwise orientation.""" ```
Is there any need for these separate methods? I could understand if it were required for testing, but that doesn't seem to be the case. If we are to keep them separate, could we not do the following to avoid the nested method calls? ```python is_ccw = property(_is_ccw_py if geos_version_tuple() < (3, 7) else _is_ccw_geos) ```
, or None...
chop blank line
I have to admit that this still feels a bit odd to me 🤔 Especially since the tests above are expecting the initial value to be None, and we are perhaps lacking a bit of explanation why this is the case here.
Add trailing comma.
Please chop unnecessary blank lines.
This test isn't properly acting as a regression test as it passes even if the second change in options.py isn't made.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
Not critical, but I think it better to remove because that makes sure we don't still have code to support the older versions. As a minor point, initialization, although done only once per thread, invokes an expensive stored procedure, so it affects startup time. On the other hand, customization of the Oracle backend does seem to be a relatively popular practice. Your call.
I think this would be a bit more readable: ``` return ( '%(func)s %(op)s %(dist)s' % {'func': sql, 'op': self.op, 'dist': dist_sql}, params + dist_params ) ```
I'd rather raise an exception to account for the fact that assertions are ignored with `python -O` unless there's some reason to prefer the assert.
chop "one of" add comma before "or"
put closing parenthesis on the next line
Use single quotes consistently.
This can be single-lined.
You can reuse `Article`, e.g. ```suggestion Article.objects.filter(headline='Article 1').update(author=self.author_1) Article.objects.filter(headline='Article 2').update(author=self.author_1) Article.objects.filter(headline='Article 3').update(author=self.author_1) Article.objects.filter(headline='Article 4').update(author=self.author_2) articles = Article.objects.values('author').annotate(count=Count('author')) self.assertCountEqual(articles, [ {'author': self.author_1.pk, 'count': 3}, {'author': self.author_2.pk, 'count': 1}, ]) ```
Add a trailing comma.
Add a trailing comma.
Could we change this (and other similar places that check for string references) to directly call lazy_related_operation. The idea is that the calling code doesn't need to care if the reference is by string, and it doesn't need to care if the referenced model is already loaded. In all cases, it is OK to just call lazy_related_operation.
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
I'm usually fairly conscious of higher level abstractions accessing very detailed properties or methods from lower down the stack. I would prefer a method within the `sql/query.py` Query object so that other implementations that may or may not yet exist have access to override this behaviour. I'd consider pushing everything from retrieving the inner query into a method and returning on that. ``` return obj.query.as_subquery_filter(obj) ``` Method name and args probably need work but that's the kind of thing I'm considering.
You turned the arguments into keyword arguments in one other place. Could you also do this here and below? I don't know if it makes sense to also do this in the tests.
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
I'd suggest a name like `_get_sitemap_full_url`
Yeah, that would certainly be a better idea, rather than using `not` here for negation.
I guess the `add_argument` could be `action='store_false', dest='uses_https'`
chop blank line
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
Maybe `**kwargs` instead of `subindex=None, attrs=None`.
```python self.assertHTMLEqual( field.widget.render('name', []), ( '<ul>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="entertainment">Entertainment</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="test">A test</label></li>' '<li><label><input type="checkbox" name="name" value="%d" ' 'data-slug="third-test">Third</label></li>' '</ul>' ) % (self.c1.pk, self.c2.pk, self.c3.pk), ) ```
We cannot make serial pk assumption: ```diff diff --git a/tests/model_forms/tests.py b/tests/model_forms/tests.py index 8b54611010..ea68a105d6 100644 --- a/tests/model_forms/tests.py +++ b/tests/model_forms/tests.py @@ -1765,10 +1765,12 @@ class ModelMultipleChoiceFieldTests(TestCase): f.clean([c6.id]) def test_model_multiple_choice_field_validate_choices_called_properly(self): + c1 = self.c1 + class CustomModelMultipleChoiceField(forms.ModelMultipleChoiceField, TestCase): def validate_choices(self, queryset, field_name, selected_choices): self.assertIsInstance(queryset, models.QuerySet) - self.assertQuerysetEqual(queryset.order_by('id'), [1], lambda a: a.id) + self.assertSequenceEqual(queryset, [c1]) self.assertIsInstance(field_name, str) self.assertEqual(field_name, 'pk') self.assertIsInstance(selected_choices, frozenset) ```
Use `django.utils.string_types` instead of `str` here.
No need for an `else` branch as the `if` returns.
There is no need to `append()` because we have a single error: ```suggestion return [ ```
```suggestion 'SITE_ID must be an integer', ```
I would use `sites.E101` to separate them from checks related with `CurrentSiteManager`.
I suggest you use the `hint` kwarg for the `'perhaps you forgot a trailing comma?'` part.
"The SESSION_COOKIE_NAME and LANGUAGE_COOKIE_NAME settings must be different." (don't think the hint is needed as it's just repetitive)
the try/except needs to be added back
No reason to use `dict.update()` anymore.
this line should be: `def __init__(self, *args, **kwargs):`
might as well use `setdefault` in the test as well
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
actually I think we should set these 3 values from `none_value` in an else after the new elif I suggested above and then remove them as class attributes. There's an issue if someone has subclassed the widget and set `none_value` -- that value would be ignored with this change.
I'd go with `elif empty_label is not None:` and remove the next line
I'd remove this check, otherwise tuples of other lengths will be silently ignored. Better for an exception to be thrown.
comma after "list" chop "selects box" (or rephrase... currently it doesn't make sense to me)
To be consistent with the rest of the codebase, I'd import `from django.utils.six.moves import range` first.
Something like `test_header_omitted_for_no_to_recipients` may be more descriptive.
format parameters as described above
seems like a helper method to get the attachment path would save some repetition
Please drop that new line
might as well use `setdefault` in the test as well
You can reuse existing models, by adding e.g. `Entity`: ```python class Entity(models.Model): pass class Country(Entity): ... ```
Do we need to change `related_name` here? We could add `note` with `related_name='owner'` instead.
You can reuse the `PlotDetails` model instead of defining a new one as it slow downs the test suite execution.
add trailing comma
It'd be great we if we could avoid creating 5 new tables to reproduce the issue. Existing ones should be reusable somehow.
I don't think there's a use case for `settings.AUTHENTICATION_BACKENDS` without any backends that have a `get_user()` method.
Yes, I think Django would be obviously broken in such a configuration anyway.
This values needs to be invalidated on `settings_changed` for `MIDDLEWARE` for testing purposes.
is this meant to test the `except TypeError` branch in `contrib.auth.authenticate()`? It would be clearer to call that function directly.
prefer `setUpTestData` since that executes once per test class instead of once for every method
please remove added newline
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
Don't add a blank line.
Do you think it could be worth deprecating the `host` parameter of `is_safe_url` in favor of an `allowed_hosts` one now that it accepts multiple values? This function is not part of the public API but a lot of third-party applications rely on it.
Wrap at 79 chars, please.
```suggestion with self.time_keeper.timed('Total database setup'): ```
I know I suggested it but I think _shadowing_ is the correct term.
I would move the check to the first line of the function since it's right after receiving the argument.
avoid _we_ usage as well ``` SystemCheckError is surfaced when run_checks raises SystemCheckError and teardown databases raises ValueError
I would also consider turning that into an instance method called something like `get_runner()` and starting each test method with `runner = self.get_runner()`. The reason is that instantiating a runner is "cheap." You also don't have to think / worry about whether the runner has state that you might unwittingly be carrying from one test to the other (e.g. attributes set when a method is executed).
I'll quickly check if an idea I'm having works here.
Could this assignment be moved to the previous `if self._fields is None` check at the beginning of the method? Seems strange to have this down here, even though this is the place you're operating on the query object. Still, a `obj.query._forced_pk = True` would probably help reading.
I'm usually fairly conscious of higher level abstractions accessing very detailed properties or methods from lower down the stack. I would prefer a method within the `sql/query.py` Query object so that other implementations that may or may not yet exist have access to override this behaviour. I'd consider pushing everything from retrieving the inner query into a method and returning on that. ``` return obj.query.as_subquery_filter(obj) ``` Method name and args probably need work but that's the kind of thing I'm considering.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
This join generation concerns me - not that it won't work just that it's kinda magical and ugly. It would be awesome if we could use the relationship name somewhere. Perhaps `SubQuery(rel_name, qs=BLAH)` which is a similar API to `Prefetch`? I don't know how easy that would be to get to work as the `rel` object would probably need to do some of the transformations. It may allow a wider variety of rel objects to work though - e.g. subquery on a M2M field.
chop blank line
What about keeping the old logic and just changing the message to `raise CommandError("Couldn't import the %s interface." % shell)`. The error should only be trigger when specifying a specific shell anyway.
``` Superuser creation skipped due to not running in a TTY. You can run `manage.py createsuperuser` in your project to create one manually. ```
I'm in favor of re-raising `subprocess.CalledProcessError` as a `CommandError`, e.g. ```python def handle(self, **options): connection = connections[options['database']] try: connection.client.runshell(options['parameters']) except OSError: # Note that we're assuming OSError means that the client program # isn't installed. There's a possibility OSError would be raised # for some other reason, in which case this error message would be # inaccurate. Still, this message catches the common case. raise CommandError( 'You appear not to have the %r program installed or on your path.' % connection.client.executable_name ) except subprocess.CalledProcessError as e: raise CommandError( '"%s" returned non-zero exit status %s.' % ( ' '.join(e.cmd), e.returncode), ) ``` which will end with: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: "psql -U djangoticket -h localhost -p 5432 djangoticket --asdasdad" returned non-zero exit status 1. ```
I wonder if we should suppress `subprocess.CalledProcessError` when arguments are not correct, to get e.g. ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. ``` instead of ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. Traceback (most recent call last): File "manage.py", line 22, in <module> main() File "manage.py", line 18, in main execute_from_command_line(sys.argv) File "django/django/core/management/__init__.py", line 401, in execute_from_command_line utility.execute() File "django/core/management/__init__.py", line 395, in execute self.fetch_command(subcommand).run_from_argv(self.argv) File "django/django/core/management/base.py", line 328, in run_from_argv self.execute(*args, **cmd_options) File "django/django/core/management/base.py", line 369, in execute output = self.handle(*args, **options) File "django/django/core/management/commands/dbshell.py", line 25, in handle connection.client.runshell(options['parameters']) File "django/django/db/backends/postgresql/client.py", line 55, in runshell self.runshell_db(self.connection.get_connection_params(), parameters) File "django/django/db/backends/postgresql/client.py", line 49, in runshell_db subprocess.run(args, check=True, env=subprocess_env) File "/usr/lib/python3.6/subprocess.py", line 438, in run output=stdout, stderr=stderr) subprocess.CalledProcessError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ``` We can also re-raise it as a `CommandError`: ``` /usr/lib/postgresql/10/bin/psql: nieznana opcja '--commandasdasd' Try "psql --help" for more information. CommandError: Command '['psql', '-U', 'djangoticket', '-h', 'localhost', '-p', '5432', 'djangoticket', '--commandasdasd']' returned non-zero exit status 1. ```
That looks awesome @hannseman 💯 🏅 Regarding `django.contrib.postgres.indexes.OpClass` I guess we could add a `IndexedExpressionWrapper.register_wrapper` and have `django.contrib.postgres.apps.PostgresApp.ready` register `OpClass` to avoid coupling there.
This seems out of place. Is this branch really specific to MySQL? Is there a way we could avoid the `Col` import in the first place.
I think that most of the expression special casing and resolving should be done at the `Index.create_sql` level. The only purpose of `ddl_references` is to hold references to identifiers and allow renaming if necessary, it shouldn't have any knowledge about `django.db.models` abstractions.
Use hanging indent: ``` return [ e._output_field_or_none for ... ] ```
You aren't changing here, except for the style. Please revert.
I think I would define the additional parameters as keyword parameter, as in `__call__ `. BTW, thanks for fixing this thread issue I created!
docstring with example input/output would be really helpful
```suggestion return ''.join([ self.handle_word(word) for word in words ]) ``` I changed `handle_word` to return `word` in remaining cases.
I think there's also a word missing here: "will **be** truncated".
Passing `lead` and `trail` to the `trim_punctuation()` looks unnecessary. This method is called only here so we always pass `('', word, '')`. Maybe: ```suggestion lead, middle, trail = self.trim_punctuation(word) ``` and ```python def trim_punctuation(self, word): """ Trim trailing and wrapping punctuation from `word`. Return the items of the new state. """ lead, middle, trail = '', word, '' ... return lead, middle, trail ```
I don't think it's important to mention PostgreSQL version details in the docstring.
I'd go with `ValueError` and possibly add a check `isinstance(pages_per_range, int)`: ```python if pages_per_range is not None and not (isinstance(pages_per_range, int) and pages_per_range > 0): raise ValueError('pages_per_range must be None or a positive integer for BRIN indexes') ```
Use single quotes
You might append this to the `using` sql passed to `super()` to fix the test failure on Jenkins (due to usage of TABLESPACE).
This should probably be the default for postgresql's `schema_editor.sql_create_index`.
I think we missed some attributes e.g. `related_query_name`, `limit_choices_to`, or `validators`.
I guess `name` would be another one.
This is not only about constraints but also about noop `ALTER FIELD` operations. Field alteration can cause many DDL changes. > We could just compare the old and new field. That's exactly what we're doing here, we compare fields but without attributes that don't impact schema changes.
I don't think this is the best way to address this issue. We will always have to keep this list of fields updated. Instead we could change `_alter_field` field to do nothing when the constraint hasn't changed. We could just compare the old and new field. This is the `if` that drops the constraint. https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L590 and the one that adds it back https://github.com/django/django/blob/master/django/db/backends/base/schema.py#L810
Maybe? ```suggestion def _field_non_database_attrs(self): ```
Regarding the implementation, I'd rather have some class variable (`max_expressions`?) checked in base class instead of "dumb" `__init__` methods. To be experimented...
I've created https://code.djangoproject.com/ticket/25629 to track this.
Many thanks for the example. I guess this is the same before the patch, is it? Then we might fix that in a separate patch. That would keep this patch a bit smaller.
I added warning to docs.
Avoid calling `self.get_source_expressions()` twice and it becomes clearer: ```python ... expression1 = self.get_source_expressions()[0] if isinstance(expression1, Value) and expression1.value is None: raise ValueError('Oracle does not allow Value(None) for expression1.') ... ``` I've also tweaked the exception message to make it based on the argument provided in Python.
You want to avoid altering `self` here as subsequent calls will reuse this attribute even if this branch's conditions don't match.
This looks a bit odd to me. I wonder if something like this could be a bit more readable? Up to you. ``` return ( (sql_alter % {"column": self.quote_name(new_field.column), "type": new_type}, []), [], ) ```
```suggestion new_field.get_internal_type() in ('CharField', 'TextField')): ```
Can this be simplified to ```suggestion # Collation change? elif getattr(old_field, 'db_collation', None) != getattr(new_field, 'db_collation', None): new_collation = getattr(new_field, 'db_collation', None) fragment = self._alter_column_collation_sql(new_field, new_type, new_collation) actions.append(fragment) ``` Or maybe we want to keep the old code to support field type and collation change at the same time (e.g. `CharField(db_collation='foo') -> TextField(db_collation='bar')`).
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
I don't think it's worth it. Someone using a non-browser name doesn't seem like a common mistake.
Don't think we need to worry about duplicates.
As long as you use `except Exception` and not a bare `except` this should be good.
If we remove this will the tests run on Jenkins? It might be fine.
Can you simplify using `super()`, e.g. something like-- ```python kwargs = super().get_test_runner_kwargs() if hasattr(self, 'stream'): kwargs['stream'] = ... return kwargs ```
It should be enough to use `lru_cache` instead, e.g.: ```python @functools.lru_cache(maxsize=128) def import_string(dotted_path): ... ```
> @kezabelle This method is very good, but there are currently many Django-related modules that reference import_string during operation. If you add a cache_import, you must modify and adjust the module code that references import_string to improve performance. You can add a new hook and use it in `import_string()`, e.g. ```python def cached_import(module_name, item_name): modules = sys.modules if module_name not in modules: import_module(module_name) return getattr(sys.modules[module_name], item_name) def import_string(dotted_path): """ Import a dotted module path and return the attribute/class designated by the last name in the path. Raise ImportError if the import failed. """ try: module_path, class_name = dotted_path.rsplit('.', 1) except ValueError as err: raise ImportError("%s doesn't look like a module path" % dotted_path) from err try: return cached_import(module_path, class_name) except AttributeError as err: raise ImportError('Module "%s" does not define a "%s" attribute/class' % ( module_path, class_name) ) from err ```
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
I wonder if we could support running `runtests.py` from different directories :thinking: like we do for dotted module names, e.g. ```bash ~/repo/django> ./tests/runtests.py backends.postgresql ``` works fine, but ```bash ~/repo/django> ./tests/runtests.py backends/postgresql/ .... File "./tests/runtests.py", line 155, in get_label_module rel_path = path.relative_to(RUNTESTS_DIR) File "/usr/lib/python3.8/pathlib.py", line 904, in relative_to raise ValueError("{!r} does not start with {!r}" ValueError: '/repo/django/backends/postgresql' does not start with '/repo/django/tests' ``` crashes. I tried to fix this with: ```python # Otherwise, interpret the label as a path. if not path.is_absolute(): return path.parts[0] else: path = path.absolute() rel_path = path.relative_to(RUNTESTS_DIR) return rel_path.parts[0] ``` but it crashes with `ModuleNotFoundError` (like without this patch): ``` ====================================================================== ERROR: backends/postgresql (unittest.loader._FailedTest) ---------------------------------------------------------------------- ImportError: Failed to import test module: backends/postgresql Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 154, in loadTestsFromName module = __import__(module_name) ModuleNotFoundError: No module named 'backends/postgresql' ```
Yeah it works for me, sorry again. The current version looks good :+1: , we could only raise a more descriptive error when a relative path is not correct (as proposed in https://github.com/django/django/pull/14507#discussion_r648186310).
Avoid calling `self.get_source_expressions()` twice and it becomes clearer: ```python ... expression1 = self.get_source_expressions()[0] if isinstance(expression1, Value) and expression1.value is None: raise ValueError('Oracle does not allow Value(None) for expression1.') ... ``` I've also tweaked the exception message to make it based on the argument provided in Python.
I might have suggested it, but I don't think arity is useful in this type.
We try to avoid altering expressions during the compilation phase as it can lead to hard to diagnose issues what about ```suggestion self.collation = collation def as_sql(self, compiler, connection, **extra_context): extra_context.setdefault('collation', connection.ops.quote_name(self.collation) ```
`Backend` supports negative precision, `SQLite` does not: ```suggestion raise ValueError('SQLite does not support negative precision.') ```
This looks as though it works, but we can make it much more straightforward: ```python def as_postgresql(self, compiler, connection): # Cast FloatField to DecimalField as PostgreSQL doesn't support # MOD(double precision, double precision) by default. clone = self.copy() clone.set_source_expressions([ Cast(expression, DecimalField()) if isinstance(expression.output_field, FloatField) else expression for expression in clone.get_source_expressions() ]) return clone.as_sql(compiler, connection) ``` The other issue is that your implementation was basing the decision to cast on the `output_field` of this function and not the input source expressions which may be different.
IMO, we can use `assertEqual` instead of `assertAlmostEqual` in all tests.
Due to hanging indent, `).first()` should be on the next line.
Because we use `-Wall` on Jenkins, so it's already consumed. I don't think there is a reliable way to test this.
I think we should test output for different scenarios not only for basic one i.e. _"John Smith"_ , e.g. ```python @classmethod def setUpTestData(cls): cls.john = Author.objects.create(name='John Smith', alias='smithj') cls.elena = Author.objects.create(name='Élena Jordan', alias='elena') cls.python = Author.objects.create(name='パイソン') def test_basic(self): authors = Author.objects.annotate(backward=Reverse('name')).order_by('name') self.assertQuerysetEqual( authors, [ ('John Smith', 'htimS nhoJ'), ('Élena Jordan', 'nadroJ anelÉ'), ('パイソン', 'ンソイパ'), ], lambda a: (a.name, a.backward) ) ```
`).values()` on next line
We usually only include this if there are non-ASCII characters in the file.
only need 'coding' if there are non-ascii chars in the file
no need for this import
remove extra newline
I'm not too keen on beginning each warning with "In your url patterns, ..". How about "Your url patterns .." ? "Your url patterns have used `include` with a regex containing a '$'. " .. "Your url patterns have a regex beginning with a '/'." .. "Your url patterns have a pattern with a name containing a ':'." ..
`~` is not a supported operator, this should be `-`.
To have more balanced line length, I think I prefer: ``` python constraints = self.get_constraints(IntegerArrayModel._meta.db_table) self.assertEqual(constraints['integer_array_model_field_gin']['type'], 'gin') ```
You could use `self.subTest()`, e.g. ```python def test_order_by_update_on_unique_constraint(self): tests = [ ('-number', 'id'), (F('number').desc(), 'id'), (F('number') * -1,), ] for ordering in tests: with self.subTest(ordering=ordering): updated_count = UniqueNumber.objects.order_by(*ordering).update( number=F('number') + 1, ) self.assertEqual(updated_count, 2) ```
This test should catch `IntegrityError`, e.g. ```python def test_order_by_update_on_unique_constraint_annotation(self): # order_by() with annotate references are ignored. with self.assertRaises(IntegrityError): UniqueNumber.objects.annotate( number_inverse=F('number').desc(), ).order_by('number_inverse').update( number=F('number') + 2, ) ```
Good catch, I will remove it before final squash.
I think we should be consistent and use double-quotes.
I'd rename `subminor` to `patch`.
You're right. You know I both saw that and missed it too...
Yes. Adding `?:` makes it a non-capturing group which allows for use of `m.groups()` below. Otherwise it'd need to be `... = m[1], m[2], m[4]`.
TIL that character classes also work inside `[]` :D
Now we can call this `test_migrate_app_name_specified_as_label` (and similar for the similar test).
I was thinking to still keep this as a separate test method, just put that method below this one
``` py self.assertFalse(r.closed) ```
I find `assertEqual` preferable since `asserTrue` checks `bool(expr) is True` which could pass for a result we don't want here. Well, I guess what we actually want is `assertIs(expr, True)` as described in the Python docs.
Since index name generation is deterministic, I don't think this is needed. `test_name_auto_generation` already checks for a specific name. If this index is truncated is some different way, then it would be okay to keep it but check for the actual name rather than testing the length.
Yes, we should use the same approach as in `SimpleArrayField`, e.g. ```python def has_changed(self, initial, data): try: data, _ = self._remove_trailing_nulls(self.to_python(data)) except ValidationError: pass if initial in self.empty_values and data in self.empty_values: return False return super().has_changed(initial, data) ```
That actually makes sense. I forgot `reversed()` is a bit special because you typically have to have consumed the whole iterator to know the last element.
I think `index` will be fine here instead of `null_index`. It would be good to avoid the association with `null` which feels like `None` translated to Python-speak. (Aside from that I could only come up with `first_trailing_empty_value_index` which, while clearly descriptive, is silly... 🙂)
Sorry, I misinterpreted it as a new flag. I also see above that this was all copied so ignore this. While not the best naming, we're stuck with it.
I'd call this `remove_trailing_empty_values` to reflect the containment check on `self.base_field.empty_values` below.
You mean `super()`? Seems okay to me.
I think it'd work if you put the mixin to the left of the base class where it's used.
The `isinstance` check feels a bit dirty but I guess it's simpler than having two transform classes. No strong opinion from me, just something to think about.
Those -> These
Use single quote.
Yeah - that was the source of my confusion about the `setdefault` thing. My original test case was wrong, but the same problem manifests if you use `ErrorDict()`.
These three lines are essentially doing the fix - not the change to `update_error_dict`. Prior to these calls, printing `self._errors` shows that each "value" in self._errors is a `ValidationError()` instance; this converts the ValidationError instance into an ErrorList, which has the right behaviour when printed.
~~Maybe a list comprehension here too.~~ EDIT: Forget it, I misread the double for-loop.
Forget it, I misread the double for-loop.
~~Maybe a list comprehension here too.~~
I think `test_decimal_parameter` would make more sense here.
If possible, it would be nice to verify the query results instead of using this try/except pattern (which hides the traceback and makes a test failure more difficult to debug). Not sure if there's a good reason for the previous test using the pattern. The only thing I can think of is cross-database compatibility.
Do you have a better example of why this would be useful? This can already be achieved in a _safer_ way doing ```suggestion query = "SELECT * FROM raw_query_author WHERE first_name like %s" qset = Author.objects.raw(query, ('J%',)) ```
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
This should be display when `verbosity > 0`.
```suggestion if squashed_migrations_with_deleted_replaced_migrations: msg = ( " Pruning cannot take place until the following squashed " "migrations are recorded as applied (re-run 'manage.py migrate') " "and have their replaces attribute removed:" ) self.stdout.write(msg, self.style.NOTICE) for migration_to_warn in squashed_migrations_with_deleted_replaced_migrations: app, name = migration_to_warn self.stdout.write(f' {app}.{name}') else: to_prune = sorted(migration for migration in to_prune if migration[0] == app_label) if to_prune: for migration in to_prune: app, name = migration if self.verbosity > 0: self.stdout.write(f' Pruning {app}.{name}', ending='') executor.recorder.delete(app, name) if self.verbosity > 0: self.stdout.write(self.style.SUCCESS(' OK')) elif self.verbosity > 0: self.stdout.write(' No migrations to prune.') ```
I would add `OK`: ```suggestion executor.recorder.delete(app, name) self.stdout.write(self.style.SUCCESS(' OK')) ```
```suggestion squashed_migrations_with_deleted_replaced_migrations = [ migration_key for migration_key, migration_obj in executor.loader.replacements.items() if any(replaced in to_prune for replaced in migration_obj.replaces) ] ```
`--prune` is ignored when `--plan` is used. Maybe we should raise an error that they're mutually exclusive.
The extra queries could be generated in this line (199), as this is where the instancies are created, so so you should check the number of queries is one.
Also `4x8.png` is left on the file system when the tests conclude.
Has `refresh_from_db` ever worked properly? From my personal experience we found the built in function buggy. We tend to just reload via `Model.objects.get(id=old_object.id)` in our code.
prefer a longer line for readability
I'm not sure we need to test implementation details of `MultiValueDict`. It seems like the following test should be enough ```python def test_empty_data_files_multivalue_dict(self): form = Person() self.assertIsInstance(form.data, MultiValueDict) self.assertIsInstance(form.files, MultiValueDict)
Same 'mutually' typo here.
Use: ``` msg = '...' with self.assertRaisesMessage(ValueError, msg): ```
I'd single line these to save lines: `[self.a4, ...]`
This can be single-lined.
Add a trailing comma.
"from VERSION if present" seems inaccurate
I wonder if we can just set `default_time_format` attribute.
I think it's fine to make them a bit inconsistent (at least for now). I opened an [issue](https://bugs.python.org/issue40300) in Python.
OK then, thanks for the references.
Are you sure about the commas in the `DATETIME_INPUT_FORMATS` strings? I don't think any other locale has those.
Ah, I realized these are E128 which we are ignoring in the flake8 section of setup.cfg. I don't mind the changes, but we are ignoring it because there are 2K+ violations and seemingly not a lot of value in fixing them.
This if (lines 114--123 as I write this) can be folded into the previous one (109--112).
I believe you can simplify all this stuff to lines like: ``` assertFieldType('pos_big_int_field', 'models.%s() % connection.features.introspected_field_types['PositiveBigIntegerField']) ``` I don't think the if statements are needed anymore (similar elsewhere in this file).
`else: assertFieldType('time_field', "models.DateTimeField()")`
There's a lot of repetitions of ``` python if (connection.features.can_introspect_max_length and not connection.features.interprets_empty_strings_as_nulls): ``` in this function now. Also, for Oracle, it doesn't check things it could check (e.g. that `ip_address_field` is a CharField). I think both issues could be addressed with a smarter field-type-asserter; perhaps this is out of scope for the PR, and should be done separately.
```suggestion for table_name, table_rows in rows: ```
[This is only an estimate on InnoDB tables](https://dev.mysql.com/doc/refman/5.7/en/tables-table.html) which is the default table engine and what's used on CI. > The number of rows. Some storage engines, such as MyISAM, store the exact count. For other storage engines, such as InnoDB, this value is an approximation, and may vary from the actual value by as much as 40% to 50%. In such cases, use SELECT COUNT(*) to obtain an accurate count. In short that means this value could report 0 while there's actually rows in the table and cause errors similar to the one you are experiencing.
I believe you can just drop the `== 0` case here. Doing `DELETE FROM` on 0 rows should be harmless. No need to `SELECT COUNT(*)`. You can also find out if a table has >1000 rows without counting everything using ```sql SELECT COUNT(*) > 1000 FROM (SELECT * FROM table_name LIMIT 1001) SUBQUERY; ``` Which returns '1' (true) only if it does have >1000 rows. But I don't think we need that here for the time being, the approx row count should be fine as a heuristic.
Chop blank line.
Tests are failing for a different reason due to qwirks with our CI system; notice that SQLite tests are failing as well.
Yea, it seems a bit unusual, but I don't have an alternative to suggest.
I think the filename isn't important so I would just use `_, filename = tempfile.mkstemp()`. Since temporary files are created inside a django_XXX directory by runtests.py, I don't think cleaning it up is necessary.
This looks unnecessary.
Manager will raise a different `IntegrityError`, e.g. _"The row in table 'auth_tests_customuserwithfk' with primary key '1' has an invalid foreign key: auth_tests_customuserwithfk.group_id contains a value '-1' that does not have a corresponding value in auth_group.id."._
This is risky, I would use (in all new tests): ```suggestion Group.objects.all().delete() nonexistent_group_id = 1 ```
It's done on purpose. We modify `attrs` in this loop so `list()` is used to create a copy.
True, it's unnecessary since 58ad030d05fa50cfed327368ab61defca3303e02. It's not a copy&paste code in was done on purpose in the original patch, see a68ea231012.
this doesn't look right
A test is missing for this change.
Is `test_doesnt_work_with_init_subclass` meant to test this change? I still don't see any test failures if this change is reverted.
The current form is consistent with messages in similar checks. Also, we use here `display_name`, e.g. `MySQL does not support indexes on expressions.` so I don't think that `Database` adds much value here.
Thanks. Good point.
The wording is a bit inconsistent with the one for check constraints, here there is some duplicate info between the warning and the hint, and it talks about "The constraint" without naming it. I would suggest: ``` checks.Warning( "%s does not support unique constraints with conditions." % connection.display_name, hint=( "A constraint won't be created. Silence this " "warning if you don't care about it." ```
I think this should also check for a condition on the constraint, since UniqueConstraints without conditions are always supported.
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
Sorry, I should have said simply `raise` without the `e`.
Adding something like this before the loop could help: ``` _bit_undefined() = object() [at module level] bit = _bit_undefined() ```
~Never mind, looks it's the other way around. Works on 3.6, fails on 3.8.~ had an old Python 2.7 interpreter lying on my path 🤦
Not sure of the motivation behind these changes but this could be reduced to the following? ```suggestion attrs['declared_fields'] = { key: attrs.pop(key) for key, value in attrs.items() if isinstance(value, Field) } ```
`HTMLParser.error` is removed too. You may want to add an `error` method to `html_parser.HTMLParser`.
Since `separate_logs` seems like a higher-level mode that does multiple things, maybe you can make it so the mode doesn't need to be stored as an attribute. For example, the following line could write to a `self.output_stream` that defaults to `os.devnull`. When running in script mode, it could be set to `self.stdout`. It would also eliminate the need for an `if` statement.
Interesting. I just tried it. This returns 2. ``` def func(): try: return 1 finally: return 2 ```
Can you reference the ticket number in the docstring, please.
Can you reference the ticket number in the docstring, please.
please move this to `except` and return `autopep8` result in `try`
The test name method is self-explanatory, I'd remove the docstring. ```suggestion ```
Do we need an inner import? `from . import urls` should work fine.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
The use of `os.sep` doesn't make sense as this is normalized away by `pathlib`: ```suggestion template_path = custom_templates_dir / "project_template" ```
This one could do with assigning to a variable: ```suggestion path = base_path / f self.assertTrue(path.exists()) with path.open() as fh: ```
@NDevox I'd be very happy for you to do that. 🙂 (If it's just a single file cleanup, you can just make a PR, without the Trac ticket)
A note about code length, because some users may say "using self.client.get() is more straightforward"... We can also write the lines above (297-301) like this: ``` python view = views.CustomTemplateView.as_instance( RequestFactory().get('/dummy'), foo='bar') ``` That said, the way they are written right now is fine too.
assertEquals is deprecated. Please use assertEqual instead.
Remove trailing comma.
`.all()[0]` -> `.first()`
@sdil Can you take a look? Thanks!
@sdil Thanks for checking :+1:
My pleasure :)
I think we should add this format to the `DATE_INPUT_FORMATS` for backward compatibility.
Is it possible to convert year type? (e.g. 2006 &rarr; 2549)
We can drop meta ordering and add it to the queryset: ``` self.assert_pickles(c.concrete_events.order_by('event)) ```
We can chop `FK`.
Again, this could be a class level attribute.
It'd be great we if we could avoid creating 5 new tables to reproduce the issue. Existing ones should be reusable somehow.
Do we expect users to use strings like `&&` and `&` directly anywhere else? It seems like we're exposing an implementation detail we'd usually hide.
I guess there is a fair amount of wasted effort for the majority(?) of projects that aren't using admindocs, so perhaps we could have a ticket for it to investigate the possibility of moving the admindocs specific-stuff out.
*↑* Oh, I'm sorry! 😂
Maybe change that into a `try/execpt AttributeError`. It's kinda nitpicky, but given that if you want to use session-based CSRF you will most likely have a session object on the request and then try/except would be faster (And even if not, it seems more natural and shows a nice chained error on python3).
Why would you need to sanitize something that's already in your session? Seems a bit late...
How about putting this right above where it's first used rather than far about it? (`if csrf_token is None:`)
Please test for all of the extra registered range types - you should be able to make use of `self.subTest()`.
You might want to write some tests to prove that the new query search subclasses combine correctly with SearchQuery.
Usually we camel case assertions to match the unittest style. Maybe assertFieldsInModel (considering field_outputs is a list).
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
Maybe this inheritance should be refactored a bit as it's not obvious if `PostgreSQLWidgetTestCase` is now using `TestCase` from `PostgreSQLTestCase` or `SimpleTestCase` from `WidgetTest`? e.g. `PostgreSQLTestCase.tearDownClass()` might be moved to a mixin that `PostgreSQLTestCase` and `PostgreSQLWidgetTestCase` can use.
I would not recommend any alternatives: ```suggestion f"Cannot update applied migration {migration}." ```
_"f-strings should use only plain variable and property access"_ This guideline is from [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
IMO, it's unnecessary.
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
That's not true, `return` is to avoid setting new migrations.
I think that you can remove brackets `deleted_objects, model_count, perms_needed, protected = ...`
I think a test for this change is missing. This would probably go in `admin_views` whereever the other tests for the `delete_view` are.
Docstrings should state the expected behavior and omit prefixes like "Tests that" since all tests test things.
" allowed to be deleted permissions" seems like a typo.
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Yes, will fix it.
Did you consider `decimal.Decimal(1).scaleb(-abs(p))`? It seems that it could be faster when `p != 0`: ``` In [81]: %timeit decimal.Decimal(10) ** 0 347 ns ± 7.74 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [82]: %timeit decimal.Decimal(1).scaleb(0) 470 ns ± 3.89 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ``` ``` In [83]: %timeit decimal.Decimal(10) ** -1 661 ns ± 5.87 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) In [84]: %timeit decimal.Decimal(1).scaleb(-1) 481 ns ± 4.66 ns per loop (mean ± std. dev. of 7 runs, 1000000 loops each) ```
I think you want: `'{0:f}'.format(d)`
IMO, we can use `assertEqual` instead of `assertAlmostEqual` in all tests.
I couldn't see a reason not to use `super` here, otherwise LGTM.
And a another alternative in #11642
Here's what I came up with https://github.com/django/django/pull/11641.
No, they are not supported, because `BOOLEAN` datatype is available only in PL/SQL on Oracle, so `SELECT` clause cannot return it.
You should use `1` instead of `True`, sorry for misleading. If you will use `True` as a param than it will be automatically converted into `1`.
That's what I thought. Thanks for the clarification 👍 The patch is fine to me 🚀
Generally we would rather expand the docstring with sufficient explanation rather than include a ticket reference (or at least keep the mention limited to a simple "(#18247)" as in tests).
I think we can simplify this: ```python def json_script(value, element_id=None, json_encoder=None): from django.core.serializers.json import DjangoJSONEncoder json_str = json.dumps(value, cls=json_encoder or DjangoJSONEncoder).translate(_json_script_escapes) ```
I guess this is not strictly related to the primary purpose of the commit (as in, the functools case would work without this)? If so, it would be better to make this a separate ticket and pull request for clarity, and it also needs its own test.
Sure, just wanted to be clear
the link for Python 3 might be https://docs.python.org/3/library/io.html#io.IOBase
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
You can use `mock.atomic.assert_called_with(using=db)` here instead.
Small nitpick, please use the following indentation: ``` python User.objects.create_superuser( username='admin', password='something', email='test@test.org' ) ```
And I would rename this attribute `superusers` as it's meant to contain multiple users.
use `reverse()` rather than a hard coded URL.
Could we patch a StringIO instead of devnull and then verify the contents of log_message()? See tests/check_framework/tests.py for an example. Also the patching should be in setUp/tearDown or in a try/finally so if something goes wrong the unpatching still happens.
please check code with flake8 (`E231 missing whitespace after ','`)
`test_jsonfield` looks good to me (since this is InspectDBTests, _introspection seems redundant).
I would add: ``` self.assertIn('<div id="traceback">', htmls[0]) ```
this line should be: `def __init__(self, *args, **kwargs):`
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
I think we can remove `tearDown()` and `setUp()` and use ```python with translation.override(language): ``` instead of `activate()`.
I think I would not mix the tests and better create a separate test, if possible.
I prefer stating the expected behavior rather than "Test that..." since all tests are for testing. e.g. "A language not present in settings.LANGUAGES can be installed/used by a project."
```suggestion with with self.subTest(tag), self.settings(LANGUAGE_CODE=tag): ```
I'm not sure what Aymeric had in mind but I see that `secrets.py` does `from random import SystemRandom` so as far as I can tell, this doesn't change any behavior or add security.
In the long run I think we should deprecate `get_random_string` in favor of similar functions provided by the `secrets` module. I didn't check whether there was a sensible transition plan to make use of `secrets` on Python 3.6 while still supporting older versions. Since this PR adds complexity without changing the behavior, I don't think it's on the right track.
I'm in favor of adding this if the benefits become more than theoretical or when only Python 3.6+ is supported.
This allows for backports to exist and makes the code easier to maintain
``` # If the filename already exists, generate an alternative filename # until it doesn't exist. ```
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
I understand that this is the extra query that @codingjoe is trying to get rid of before trying to merge this is; however, if this block of code does end up being used, "pg_get_serial_sequence" should be used in place using of the implicit Postgres sequence name to enable compatibility with DB migrations.
I saw that you're now handling this at the database level. It makes more sense to me.
more than one automatically generated field.? sounds better and more natural with the changes.
Wouldn't be required if you subclasses `IntegerField`.
You aren't changing here, except for the style. Please revert.
We could keep the same format as in indexes: ```suggestion return '<%s: %sname=%r%s%s%s%s%s>' % ( self.__class__.__name__, '' if not self.fields else "fields='%s' " % ', '.join(self.fields), self.name, '' if not self.expressions else " expressions='%s'" % ', '.join([ str(expression) for expression in self.expressions ]), ```
Yes a separate PR with unification sounds good.
Are we always going too assume a GiST index by default as currently implemented or force people to choose consciously? If the former, then we need not include `index_type` here when it is the default value.
No point in assigning to `path` when used once. Also this doesn't seem right. I think you meant `__qualname__` rather than `__module__`? Which probably also means some tests are lacking...
Error is raised only on PostreSQL. On Oracle and MySQL we simply return the same date. Even if we want to raise an exception on SQLite, `NotImplementedError` is probably not the best choice. It's not sth that will or may be implemented in the feature. I'd use `ValueError` as we do in similar cases.
Sure, perhaps `ValueError` is better. I think PostgreSQL does the nice thing here - silently returning the value unchanged is ugly. Given this is our own implementation, having a third way - returning `NULL` - isn't great. We should align to one of the other two behaviours, and raising an error seems best.
I'm not sure about raising these exceptions (here, in `_sqlite_datetime_trunc()` and in`_sqlite_datetime_trunc()`), user will get rather unhelpful `OperationalError`: ``` django.db.utils.OperationalError: user-defined function raised exception ``` and we don't do this on other backends.
We can remove the `elif`s and `else here: ```suggestion if lookup_type == 'week_day': return (dt.isoweekday() % 7) + 1 if lookup_type == 'iso_week_day': return dt.isoweekday() if lookup_type == 'week': return dt.isocalendar()[1] if lookup_type == 'quarter': return ceil(dt.month / 3) if lookup_type == 'iso_year': return dt.isocalendar()[0] return getattr(dt, lookup_type) ``` We'll have to wait until we're Python 3.9+ only to use `.week` and `.year` on the result of `dt.isocalendar()`.
Ah, sorry. Misread these. One gets the quarter number, the other gets the first month of the quarter. Ignore me.
I'd reverse the ordering and say "use list instead of []"
We can remove quotes around the `default`. Please also wrap at 79 chars.
Maybe `_check_default_is_not_str()` -> `_check_str_default_value()`?. Please remove unused `kwargs`.
I think that such iterables like `[None, False]` should be tuples like `(None, False)`, because it's less memory consuming and faster a bit. Anyway, it is not very important, because of small container size.
"a DeprecationWarning" -> "an Error"
Please use single quotes.
I think that we could make use of a six moved import: `six.http_client` (https://pythonhosted.org/six/#module-six.moves)
Diff will be smaller without this unnecessary change.
This fails when running from the root directory rather than the tests directory (i.e. `$ ./tests/runtests.py postgres_tests`). Also, the output doesn't make debugging very easy (`AssertionError: 1 != 0`) -- if that could be improved that could be nice.
Also keep the style the same in this file.
class attribute `output_field = IntegerField()` * fairly sure that's acceptable Then drop the `__init__`
Defining `__init__()` to specify a default `output_field` is required until we re-arrange `runtests.py` to avoid importing settings dependant modules before calling `django.setup()`.
class attribute `output_field = FloatField()` * fairly sure that's acceptable Then drop the `__init__`
It seems I was wrong - there are so many examples in the code that override init just to force the output field it's not worth worrying about here. Maybe in the future we can make it easier, but not necessary for this patch.
`arity = 1`
Looking at it we should also pass `obj` to this method and cache its results, just like we do with `get_group_permissions`: ``` python def get_user_permissions(self, user_obj, obj=None): """ Returns a set of permission names the user has. """ if user_obj.is_anonymous() or obj is not None: return set() if not hasattr(user_obj, '_user_perm_cache'): if user_obj.is_superuser: perms = Permission.objects.all() else: perms = usr_obj.user_permissions.all() perms = perms.values_list('content_type__app_label', 'codename').order_by() user_obj._user_perm_cache = set("%s.%s" % (ct, name) for ct, name in perms) return user_obj._user_perm_cache ```
Move this above `has_add_permission` for consistency.
I think you missed this one in your recent updates.
same thing here about assuming `is_active` exists and `not user.is_active` -- probably need some tests for that case.
`obj` is not passed to `get_(user|group)_permissions` since it's always equals to `None` at this point; expand the diff and look at the full body of `get_all_permissions`.
Doc changes required in `topics/testing/advanced.txt`.
Adding `time_keeper` as the 3rd argument can cause issues for people that rely on the current signature and do not use keyword args.
`no_faulthandler=False` -> `enable_faulthandler=True`
```suggestion time_keeper.results() ```
Add trailing comma.
I think we always want the input on the `>>` side of the operator to be able to utilise any indexes. So we get the following SQL: ```sql SELECT t, t <->> 'word' AS dist FROM test_trgm ORDER BY dist; ``` That should mean that we want `arg_joiner = ' <->> '`. <details> <summary>Index operator classes query where LHS is the indexed value</summary> <code> SELECT am.amname AS index_method, opf.opfname AS opfamily_name, amop.amopopr::regoperator AS opfamily_operator FROM pg_am am, pg_opfamily opf, pg_amop amop WHERE opf.opfmethod = am.oid AND amop.amopfamily = opf.oid AND opf.opfname IN ('gist_trgm_ops', 'gin_trgm_ops') ORDER BY index_method, opfamily_name, opfamily_operator; </code> </details> ``` index_method | opfamily_name | opfamily_operator --------------+---------------+------------------- gin | gin_trgm_ops | ~(text,text) gin | gin_trgm_ops | ~~(text,text) gin | gin_trgm_ops | ~*(text,text) gin | gin_trgm_ops | ~~*(text,text) gin | gin_trgm_ops | %(text,text) gin | gin_trgm_ops | %>(text,text) gin | gin_trgm_ops | %>>(text,text) gist | gist_trgm_ops | ~(text,text) gist | gist_trgm_ops | ~~(text,text) gist | gist_trgm_ops | ~*(text,text) gist | gist_trgm_ops | ~~*(text,text) gist | gist_trgm_ops | %(text,text) gist | gist_trgm_ops | %>(text,text) gist | gist_trgm_ops | <->(text,text) gist | gist_trgm_ops | <->>(text,text) gist | gist_trgm_ops | %>>(text,text) gist | gist_trgm_ops | <->>>(text,text) (17 rows) ```
Paolo, Can you take a look? (\cc @pauloxnet) :point_up:
Do we need to swap arguments? IMO we want to keep the same order as in `SIMILARITY()` calls. ```suggestion class TrigramWordSimilarity(TrigramBase): function = 'WORD_SIMILARITY' ``` e.g. - `TrigramWordSimilarity('Cat sat on mat.', 'cat')` should be equal to `0.30769232` instead of `1` - `TrigramWordDistance('Cat sat on mat.', 'cat')` should be equal to `0.6923077` instead of `0`
> Paolo, Can you take a look? (\cc @pauloxnet) point_up Sorry, I totally missed the notification of this. I'll take a look
@felixxm yes that's what I'm thinking.
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
prefer if you use hanging indent style for this assertion to match the other tests
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
You can drop this line.
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
I would use `DJANGO_SUPERUSER_PASSWORD`.
You can replace the if condition and branch with this one liner. Set `username` to the value of the environment variable defined by `username_env_var` or to its current value. ```python username = os.environ.get(username_env_var, username) ```
Yeah, good point.
I think we can simplify this: ```python if username is None: username = os.environ.get('DJANGO_SUPERUSER_' + self.UserModel.USERNAME_FIELD.upper()) ```
Ahh, I see! Thank you for the quick reply! Learning a lot from these PRs! :)
```suggestion *app.split("."), "migrations", "0001_initial.py" ```
Do we need to take into account `self.ignore_no_migrations`? I don't see any tests failures after removing this check. IMO it's unnecessary.
OK, it's necessary, see `migrations.test_commands.MigrateTests.test_showmigrations_no_migrations`.
Do we need an indentation in the message? ```suggestion self.stdout.write("No optimizations possible.") ``` We can also leave an indentation and add a heading: ```python if self.verbosity > 0: self.stdout.write(self.style.MIGRATE_HEADING("Optimizing...")) optimizer = MigrationOptimizer() new_operations = optimizer.optimize(migration.operations, migration.app_label) if len(migration.operations) == len(new_operations): if verbosity > 0: self.stdout.write(" No optimizations possible.") ```
```suggestion sys.exit(1) ```
No need for subclassing here. Maybe we should define `django.db.models.sql.compiler.__all__ = ('SQLCompiler', ...)` here and simply change this one to ```suggestion from django.db.models.sql import compiler from django.db.models.sql.compiler import * ```
This is ugly but I can't think of another way of doing that.
the restriction in Oracle 12.1
Oracle specifies restrictions on multi-table inserts: > Restrictions on Multitable Inserts Multitable inserts are subject to the following restrictions: > - You can perform multitable inserts only on tables, not on views or materialized views. > - You cannot perform a multitable insert into a remote table. So if we use this, the result would be "Django cannot do `bulk_create()` if the model is stored in a view on Oracle". I'd rather avoid this limitation unless there are very substantial benefits to be had.
You should use tuple deconstruction in a number of places, starting with `query, params = super().as_sql()`. See other SQLCompiler methods. Also you seem to have replicated a bit of logic from `SQLCompiler.get_order_by()`. You shouldn't do that, but find a way to reuse it. `order_by()` supports many forms beyond the asc/desc field name form you've compiled here.
Do we need to do this? This is untested. Also, as far as I'm aware `default_kwargs` should take precedence: ```suggestion sub_match_extra_dict = { **sub_match.extra_kwargs, **self.default_kwargs, } ```
We can move this hook to the new static method.
Why? you can simply pass `sub_match.capture_kwargs` below
Prefer the context manager version: ``` self.assertRaises(Resolver404): resolve(url) ```
Any reason to use `chain` here? Both `match.groups()` and `sub_match.args` are tuples, so a simple `match.groups() + sub_match.args` should suffice. Other than that, LGTM.
`arity = 1`
class attribute `output_field = IntegerField()` * fairly sure that's acceptable Then drop the `__init__`
`arity = 1`
class attribute `output_field = FloatField()` * fairly sure that's acceptable Then drop the `__init__`
It seems I was wrong - there are so many examples in the code that override init just to force the output field it's not worth worrying about here. Maybe in the future we can make it easier, but not necessary for this patch.
The expected value should be a second argument in `assertEqual()` and `assertHTMLEqual()` assertions.
I would stick with the one line if/else statements. The style guide says, "Don’t limit lines of code to 79 characters if it means the code looks significantly uglier or is harder to read."
```python async with contextlib.aclosing(aiter(self._iterable_class(...))) as agen: async for item in agen: yield item ``` You should explicitly aclose your async generators when you create them: https://vorpus.org/blog/some-thoughts-on-asynchronous-api-design-in-a-post-asyncawait-world/#cleanup-in-generators-and-async-generators
> We'll want to do something with regards to the newly added support for iterator's prefetch_related here. That looks like a _moderate_ task in itself (to implement) — `islice`, `prefetch_related_objects`, ... — it might be that adjusting the PR here match the new interface, but emitting a warning if prefetches are set would let us get this in, to work on async prefetches later. (Would be equivalent to the sync behaviour before edbf930287cb72e9afab1f7208c24b1146b0c4ec — of _either prefetch or iterator_.) 🤔
We'll want to do something with regards to the newly added support for `iterator`'s `prefetch_related` here.
Actually you should use `assertNotContains(response, '"/test_admin/admin/r/%s/1/"' % content_type_pk)` to also account for `byte` response content on py3.
Use `assertNotIn` instead.
We can actually use `assertContains` and `assertNotContains` to simplify things here. I'm making the change and committing this.
This test isn't properly acting as a regression test as it passes even if the second change in options.py isn't made.
could we make more specific assertions here using `assertFormSetError` - I think that'll make the test more readable.
this line should be: `def __init__(self, *args, **kwargs):`
might as well use `setdefault` in the test as well
`assertEqual` (the version you have now is a deprecated alias)
seems like a helper method to get the attachment path would save some repetition
Both `response` vars are unused.
Dot is missing _"... for Django 2.x."_.
please remove the unrelated change
use single quotes throughout params also, if the params fit on the same line as `Thing.objects.get_or_create(` that's fine. You could change "does_not_exist" to "nonexistent" and "some_value" to "b" to save a few characters if it helps with line length.
I think we should return a list of all warnings, e.g.: ```python def check(self): warnings = self._check_pattern_startswith_slash() if self._route.startswith('^') or self._route.endswith('$'): warnings.append(Warning(...)) return warnings ```
Please add `urls.W004` to the `ref/checks.txt`.
Which proves that it doesn't work properly because names of indexes should be `check_framework_model1_index` and `check_framework_model2_index`, currently it is `check_framework_abstractmodel_index` in both cases.
You don't need to specify `app_label`.
This warning ID was not updated after copy-pasting it.
This should use `assertEqual` and not `assertCountEqual`, otherwise there is no point in entirely recreating the expected warning, you could just hardcode 1 or 0.
Might want to avoid `id` shadowing.
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
I don't think you should re-number the existing tests.
slightly prefer this style so lines don't have some non-multiple of 4 indent: ``` msg = ( "..." ) ```
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
The import usually goes at the top of the method.
I'm fine with core.exceptions then. Docs go in docs/ref/exceptions.txt.
I think exceptions in `django.core.exceptions` are mostly things that a user might need to import. I don't think `EmptyResultSet` meets that criteria, at least in my experience I never needed it in a project.
Good point, I didn't think of that module as being user facing. Perhaps django.db.utils would be a better place? It already contains various DatabaseError exceptions, so it wouldn't be totally out of place.
I'm torn whether or not this copy is necessary. When we resolve the expression we do a copy of the subquery anyway. Even if the queryset was cached and evaluated, the resolving will copy a new queryset anyway. ```python qs = Model.objects.whatever() sq = SubQuery(qs) list(qs) # this evaluates the queryset that subquery is holding onto OtherModel.objects.annotate(subq=sq) # queryset is copied here anyway, previous eval doesn't matter ``` Let me know if you can poke holes in my reasoning (it is new years day after all...).
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
What about just adding `**kwargs` here? It should be the same but without the need for the creation of an intermediate dictionary.
`"Script {} does not exist.".format(py_script)` -> `'Script %s does not exist.' % py_script`
Can we reorganize this a bit? ```python exe_entrypoint = py_script.with_suffix('.exe') if exe_entrypoint.exists(): # Should be executed directly, ignoring sys.executable return [exe_entrypoint, *sys.argv[1:]] script_entrypoint = py_script.with_name('%s-script.py' % py_script.name) if script_entrypoint.exists(): # Should be executed as usual return [*args, script_entrypoint, *sys.argv[1:]] raise RuntimeError('Script %s does not exist.'% py_script) ```
`can not` -> `cannot`, or better `may not `
Please wrap docstring at 79 chars.
Diff will be smaller without this unnecessary change.
Using hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
Drop the ` (django-admin.exe on Windows)` (One would just type `django-admin ...` same as elsewhere.)
This fails when running from the root directory rather than the tests directory (i.e. `$ ./tests/runtests.py postgres_tests`). Also, the output doesn't make debugging very easy (`AssertionError: 1 != 0`) -- if that could be improved that could be nice.
I would assert against `url_name`, e.g. ```suggestion self.assertEqual(response.resolver_match.url_name, 'overridden_urlconf_view') ```
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
Ok, I see. Makes it useful for the rare case you want the function both decorated and un-decorated.
Same as above; let's leave it alone for now.
lines can be longer
Can we avoid duplicating this? Maybe define it at the module level as it is used in multiple test cases.
You don't know what a docstring is? Trying googling "python docstring".
Sorry, was thinking of something else.
There is no need to declare `warning_message` or `msg`: ```suggestion self.assertEqual(check_file_based_cache_is_absolute(None), [ Warning( "Your 'default' ...", id='caches.W003', ), ]) ```
format parameters as described above
Let's go with `...cannot contain whitespace.` (I briefly considered that, so it coming up twice, we'll take as a message from the universe.)
```suggestion raise ImproperlyConfigured("URL route '%s' contains invalid whitespace." % route) ```
I don't think we need the blank line here.
Here too -- I'd prefer to see `raw_converter` replace `e` in the exception message
And basically that's how it works even now, because `msg` for `KeyError` contains a nonexistent key. We can use `raw_converter`.
since there's no validation here and `get_port()` is relying on this code I would think you'd need to consider other malformed cases, such as `example.com:abc` or `1.1.1.1:443]`
The `('443' if self.is_secure() else '80')` block is repeated twice - can we extract it to a variable at the start? ``` port_in_x_fw_host = False default_port = ('443' if self.is_secure() else '80') ```
No need to check for `bits.scheme` and `bits.netloc` again as this block is fenced by `if not (bits.scheme and bits.netloc)`
```suggestion port = port or '' ```
Please drop that new line
FWIW I don't think that's quite accurate - a third-party project could support a Python-3-only version of Django, but itself also still support earlier Django versions, and Python 2. (That said, I think the convenience import is still the right thing to do.)
I understand your concern and I'm not convinced either. Maybe the decision would be easier to take after evaluating the probable number of uses of mock.
remove extra newline
I'd omit this blank line.
chop blank line
This is a long list of migrations. I would recommend to try to get as many operations into one migration as you can. Loading a lot of migrations will slow down Django during startup and all migration commands.
```suggestion migrations.RunSQL(sql="", reverse_sql=""), ```
I'd _guess_ is that this was automatically performed by `black` because you had a trailing comma within the list (i.e. `[my_operation,]` rather than `[my_operation]`) which [black will treat as a rule to make the expression multi-line](https://black.readthedocs.io/en/stable/the_black_code_style/current_style.html#trailing-commas) > A pre-existing trailing comma informs Black to always explode contents of the current bracket pair into one item per line.
This can be single-lined.
remove extra newline
Won't `symlink_path` and `original_path` be removed automatically as part of the cleanup? `tempfile.TemporaryDirectory` says "On completion of the context or destruction of the temporary directory object the newly created temporary directory and all its contents are removed from the filesystem."
It would be nice to be consistent: either `temp_dir` or `tmpdir` (although if an existing test is using some other form and is otherwise unmodified, I wouldn't change it).
```suggestion self.assertTrue(tmpdir.joinpath("1").is_file()) self.assertTrue(tmpdir.joinpath("2").is_file()) self.assertTrue(tmpdir.joinpath("foo", "1").is_file()) self.assertTrue(tmpdir.joinpath("foo", "2").is_file()) self.assertTrue(tmpdir.joinpath("foo", "bar", "1").is_file()) self.assertTrue(tmpdir.joinpath("foo", "bar", "2").is_file()) ```
There's no need to define the extra `settings_dir` variable as `pathlib` gives us more flexibility: ```suggestion settings_file_path = self.test_dir / filename / "__init__.py" settings_file_path.parent.mkdir() ```
I don't think we need to have a strict policy on `/` vs. `.joinpath()`. I'd prefer `/` but when readability hurts we can also use `.joinpath()` :shrug:
We should convert column name i.e. `connection.introspection.identifier_converter('large_field')`.
There's no need for the `disconnect` function. ```suggestion self.addCleanup(signals.post_init.disconnect, post_signal, sender=Book) ```
Ah ofcourse, my bad, you're right. Looks good to me.
Can you re-warp this block to 79 chars? (First line is too short.)
I'd use generic setting names to make it clear what's going to raise the exception and to avoid adjusting these settings if we ever get rid/deprecate one of these settings.
`None` is being passed for the `app_configs` argument - even though the check ignores `app_configs`, `[]` should be used as a more valid test value. I think it's worth looking into refactoring these tests in general, as you're write these property inner-imports are a bit confusing, made a note to self.
It's the pattern that django-secure used. Not sure if the reason is still relevant. \cc @carljm
yeah I don't see a reason why the imports are not top-level and we don't call the functions directly.
I don't see much value in this docstring.
Maybe change that into a `try/execpt AttributeError`. It's kinda nitpicky, but given that if you want to use session-based CSRF you will most likely have a session object on the request and then try/except would be faster (And even if not, it seems more natural and shows a nice chained error on python3).
I'm not sure is this really helpful and needed :thinking: because it'll catch only checks with the same order of conditions, so only copy&paste issues. For example, it will not raise a warning for: ```python models.CheckConstraint(check=models.Q(models.Q(id__gt=0) | models.Q(id=0)) models.CheckConstraint(check=models.Q(models.Q(id=0) | models.Q(id__gt=0)) ``` (that's of course only a simple example). In the same time I would not like to add any complicated logic here.
Check constraints can add significant overhead to insert/update queries. Adding duplicates (whether identical or in a different form) compounds that and is probably worth highlighting. I wouldn't have thought that dealing with ordering and logical equivalence was a deal breaker. Yes, it requires some thought, but a well-defined `simplify_q()` function that can normalize a `Q()` object would make sense. I also don't see this being limited to check constraints - partial indexes can also make use of `Q()` objects for the `condition`. Duplicate indexes also have an impact on insert/update as well as wasting valuable disk space.
Honestly, I'm not in favor of another system check, but I'll try to confirm this with Carlton tomorrow (who accepted this ticket).
> Is that something that might appear some time soon, or is it just a thought? 🙂 At the moment just a thought… 🙂
I would use the same mechanism as for the `E020` and models' labels instead of `__name__`'s, i.e. ```python indexes = defaultdict(list) constraints = defaultdict(list) ... for model_index in model._meta.indexes: indexes[model_index.name].append(model._meta.label) for model_constraint in model._meta.constraints: constraints[model_constraint.name].append(model._meta.label) ```
Use `drop=True` rather than an arg for better readability. Use a different var for `sql`here, maybe `changes_sql`? It's a little confusing to have the `sql` name reused in the next line.
nitpicking: could you swap these two checks: `old_default != new_default and not self.skip_default(new_field)`
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
We use `new_default` only when `old_field.null and not new_field.null` so IMO it's fine to use ```diff diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py index bfccf5e8fb..8cd5e11bbf 100644 --- a/django/db/backends/base/schema.py +++ b/django/db/backends/base/schema.py @@ -675,17 +675,17 @@ class BaseDatabaseSchemaEditor: # 3. Replace NULL constraint with NOT NULL # 4. Drop the default again. # Default change? - old_default = self.effective_default(old_field) - new_default = self.effective_default(new_field) - needs_database_default = ( - old_field.null and - not new_field.null and - old_default != new_default and - new_default is not None and - not self.skip_default(new_field) - ) - if needs_database_default: - actions.append(self._alter_column_default_sql(model, old_field, new_field)) + needs_database_default = False + if old_field.null and not new_field.null: + old_default = self.effective_default(old_field) + new_default = self.effective_default(new_field) + if ( + not self.skip_default(new_field) and + old_default != new_default and + new_default is not None + ): + needs_database_default = True + actions.append(self._alter_column_default_sql(model, old_field, new_field)) # Nullability change? if old_field.null != new_field.null: fragment = self._alter_column_null_sql(model, old_field, new_field) ```
I'd say "Return a (sql, params) fragment to set a column to null or non-null as required by new_field, or None if no changes are required."
s/non empty/non-empty/ (twice)
ditto, "alias must be different to relation_name"
Don't inherit from `object`.
one line ```py return ( isinstance(other, self.__class__) and self.relation_name == other.relation_name and self.alias == other.alias and self.condition == other.condition ) ``` `and` shortcuts, so it won't try get `other.relation_name` if it's not an instance of the same class 😉
`)` on new line
Python functions implicitly return `None` if return is not called. I feel being explicit is better for a test.
You don't really need a docstring at all, IMO. The test itself explains it well enough.
this could be 1 line
I'm not sure if a separate test method for each test attribute is needed. IMO, this is making things less readable by separating the sitemap's initialization from where it's tested, especially with the unrelated `test_generic_sitemap` in the middle. There's an option to use `subTest()` if you're worried that one failure in a list of assertions will obscure other failures.
I don't see the need to refetch the object from the database. `self.assertEqual(res.context['object'], self.author)` should work fine for all these assertions. Maybe the original test author didn't realize that model equality only compares primary keys.
I guess `name` would be another one.
I think we missed some attributes e.g. `related_query_name`, `limit_choices_to`, or `validators`.
I'd simplified this test: ```suggestion def test_reverse_inherited_m2m_with_through_fields_list_hashable(self): reverse_m2m = Person._meta.get_field('events_invited') self.assertEqual(reverse_m2m.through_fields, ['event', 'invitee']) inherited_reverse_m2m = PersonChild._meta.get_field('events_invited') self.assertEqual(inherited_reverse_m2m.through_fields, ['event', 'invitee']) self.assertEqual(hash(reverse_m2m), hash(inherited_reverse_m2m)) ```
It's a bit of a shame that we have to resort to full scan of the project state but I'm afraid it's the only solution to detect `to_field` references without rendering the model states.
This is already tested in `tests.migrations/test_operations.OperationTests.test_rename_field_with_db_column`, see 7f4c9222dfe2f28ff8a7ffc56c28ccbadf19cf6f. I will revert this change.
Nope. In the second case `sub_message['changed']['fields']` is fetched again. This could certainty be made less clunky though as `sub_message['changed']['fields']` is referenced 4 times in 6 lines...
This seems incorrect -- we aren't using any data from the formset.
Looks like in English the period is inside the quotes (see grammar sites).
Yes, consistency matters :-) Maybe @timgraham can bring his expertise here.
please revert whitespace addition
There's a class method called `setUpTestData()`. Please use that instead.
use snake case, please: `test_login_required()`
do we need a blank line before each method? seems like it just makes things longer.
`test_changed_message_uses_form_lables`? The test case is already called `...HistoryView...`
And I would rename this attribute `superusers` as it's meant to contain multiple users.
seems there are conflicts here
I'd use a classmethod to provide the default index type (I think that's cleaner than resetting the attribute in the initializer)
I'm not sure if you intentionally reordered the kwargs. Maybe it makes sense to add a `*` in there to catch bugs in case code is passing kwargs as args.
Yeah it's quite inconsistent :disappointed:. I think we should change `columns` to `fields` in a separate PR.
on the model an index
`uuid.uuid4` is a function, and, as understand, you want to set some random data for it, so you must call it. But I don't think that default is needed there though.
`default=uuid.uuid4,` is generally the correct way to set the default for a uuid field. It will get called automatically whenever a new instance is created.
Are you sure that this actually creates a mixed-case column name? In the past, we needed to do things like `'"TeA_iD"'` to get this effect, otherwise the name would be uppercased or lowecased along the way.
```suggestion class Integration(models.Model): ```
Since 21194 was closed as a dupe, you may want to update the references to 19299.
I would organize these methods else (inside of in the middle of the views) and prefix them with an underscore to indicate that they're helpers, not public APIs.
Please revert this unrelated change.
chop blank line
Could be reduced to a list comprehension ```python return [ value for key, value in request.POST.items() if regexp.match(key) ] ```
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
oh that's what i've missed. thats true there is something wrong on that line
Is there a reason that I'm missing (probably) that the field's length is 36 (and each DB's backend definition is 36, with the exception of postgres, which has the native datatype)? Removing the dashes (if a string) or calling `.hex` turns the value into 32 chars, which both `uuid.UUID()` and postgres' datatype support as a input format, and both use the dash-inclusive output format.
Marc, did you try to store by default in a binary column? AFAIK PostgreSQL is using a binary field internally.
remove trailing whitespace to fix flake8 warning
(same pattern as above, if you change it)
I think it would be better to use the same parameter formatting style as the `save()` method below.
import should go at the top of the file unless it causes a circular import
Chop blank line.
Fine. Super. Thanks for the clarification. (In that case, leave it as it is, because we want the test for the issue...)
email_field_name -> email_address to make it more realistic
This docstring is unnecessary.
This docstring is unnecessary.
I don't see much value in this check.
Trailing comma: ```suggestion migrations.RunPython.noop, ```
Please use this style to limit lines to 120 characters so we don't have to scroll to review it: ``` self.assertEqual( ..., ... ) ```
```suggestion # List comprehension ensures is_valid() is called for all formsets. ```
For what reason? Doesn't `all()` work fine on generators? (Typically we still use list comprehensions for `str.join()` as it converts to a list internally anyway.)
Chop blank line.
Tests for `formset_factory()` and `formset_factory()` are missing.
I'm not sure why `get_form_error()` is named as it is. I would find the test more readable if you replaced the method call with the "Please correct the duplicate values below." string, but whatever you think.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
No need to define another attribute. The form class should be accessible as `self.TestForm`.
(same pattern as above, if you change it)
Use single quotes.
Use single quotes.
I think this docstring should also explain the meaning of the three possible values of `include_parents`
What I'd prefer is a proper enum type, but we don't have one that we've adopted for use in Django. Lacking that, I don't think there's really much difference between True/False/PROXY_PARENTS and ALL/NONE/PROXY_PARENTS.
Are you using PROXY_PARENTS as some type of flag? We already went through the "flags" path throughout the Meta API refactor and ended by removing it because it required imports. Even though this is an internal function, I would advise to find a better solution because, personally, I don't think it's good practice to have one argument that can be of different types (in this case, boolean or object) as it increases the risk of bugs, and it also can be confusing to other people. But that's just me.
recopied (no dash) get a different
pep8: no spaces around `options_instance`
repetitive with method docstring
Thanks @ivorbosloper now it makes sense to me and works fine. I got confused with upper and lower bits wording. Interesting that bits are counted from right to left from that point of view, and that the mask operation works. It would not work the same way with the `BANDTYPE_FLAGS_MASK` as my example shows.
It would be nice to be consistent about the ordering in `assertEqual` using it's `(variable, 'expected value')` but here and a couple other places it's opposite.
comma after tuple
I'd reverse this to `if data is None`, to match the structure below (and prevent unnecessary negation).
Not important, but I think it should be `{"key": "value"}` (note the added space after the colon) per pep8.
don't need variables here
Other tests use naming like: `test_json_agg_empty`
You could avoid the delete query with: `AggregateTestModel.objects.none().aggregate(...)`. (I guess the other tests could use the same pattern, not for this PR though.)
No need to define another attribute. The form class should be accessible as `self.TestForm`.
`# Sendfile is used only when file_wrapper has been used.`
Trailing dot is missing.
We should clean `FILE_RESPONSE_HOLDER` in `finally` to ensure tests isolation, e.g.: ```python try: # Verify that sendfile was used which only happens if file_wrapper got # used. self.assertTrue(handler._used_sendfile) # Fetch the original response object self.assertIn('response', FILE_RESPONSE_HOLDER) response = FILE_RESPONSE_HOLDER['response'] # The response should have been closed ... self.assertIs(response.closed, True) # ... as well as all individual file buffers buf1, buf2 = FILE_RESPONSE_HOLDER['buffers'] self.assertIs(buf1.closed, True) self.assertIs(buf2.closed, True) finally: FILE_RESPONSE_HOLDER.pop('response', None) FILE_RESPONSE_HOLDER.pop('buffers', None) ```
single line is okay here (we allow longer lines up to 119 characters if it helps readability)
Wrap at 79 chars.
Well, we _could_ make `on_delete` an actually-required arg to `ForeignObject` right now, and move it even before `from_fields` and `to_fields`, but that would require duplicating the deprecation warning in both `ForeignKey` and `OneToOneField`.
I think this second sentence could be removed
This is a nitpick, but `on_delete` is not an attribute you set, it is an argument you pass. I think that second sentence could just be removed. What might be more useful here is a stable link to the `on_delete` docs.
Well, there are a number of existing cases of docs URLs in user-facing messages (especially in migrations, but other places as well). I think there is a lot to recommend them from a UX perspective; someone who gets this warning is quite likely to in short order need a reference of the available `on_delete` options. I don't think the URL-going-stale issue is that big for a deprecation warning, which has a limited lifespan anyway. If someone does happen to rearrange those docs in the next couple years, we'd just update the message. (Like the ones in migrations, the message should use a Django-version-specific docs link, not the `stable` redirect, so that for a given Django version the link shouldn't ever go stale.)
Please do not change formatting
Please add a docstring: ``` """ ArrayField shouldn't have varchar_patterns_ops or text_patterns_ops indexes. """ ```
conslike -> like_constraint_field_names? also, assertions could be moved out of the "with" statements.
Can you reference the ticket number in the docstring, please.
Can you reference the ticket number in the docstring, please.
You can safely join this an the next line. You have up to 119 chars per line. ;)
Please including a trailing comma in the last item of a dictionary so if more items are added we don't need to modify this line again.
```suggestion return format_html('<a href="{}">{}</a>', url, remote_obj) ```
I would revert this change, the previous version is clearer to me.
This sentence is too long, maybe: ```python choice = self._choice_input( f"It is impossible to add the field '{field_name}' with " f"'auto_now_add=True' to {model_name} without providing a " f"default. This is because the database needs something to " f"populate existing rows.\n", [ ... ```
`form_class` is defined in `RangeField.formfield()` so this is redundant.
```suggestion pass ```
Also I think that `is_ref` will need to be handled in a special way. The reference will need to be resolved to inline the expression. This can be tested by with the following code ```python updated_count = UniqueNumber.objects.annotate( number_inverse=F('number') * -1 ).order_by('number_inverse').update( number=F('number') + 2, ) self.assertEqual(updated_count, 2) ``` In this case `number_inverse` will yield `is_ref=True` and `expr` will be an instance of `Ref` if I'm not mistaken.
You should use tuple deconstruction in a number of places, starting with `query, params = super().as_sql()`. See other SQLCompiler methods. Also you seem to have replicated a bit of logic from `SQLCompiler.get_order_by()`. You shouldn't do that, but find a way to reuse it. `order_by()` supports many forms beyond the asc/desc field name form you've compiled here.
`ordering_params` are overwritten and are not used anywhere :thinking: As far as I'm aware, we should add them to `params` ```suggestion ordering_sql, ordering_params = self.compile(ordering) ordering_sqls.append(ordering_sql) params.extend(ordering_params) ```
i think you should use `NotImplementedError` instead on `NotImplemented`, moreover this proves that it's untested 😞.
I think we can simplify this: ```python def json_script(value, element_id=None, json_encoder=None): from django.core.serializers.json import DjangoJSONEncoder json_str = json.dumps(value, cls=json_encoder or DjangoJSONEncoder).translate(_json_script_escapes) ```
Slightly simpler: ```suggestion passed_check = ( isinstance(settings.ALLOWED_HOSTS, (list, tuple)) and all(isinstance(element, str) for element in settings.ALLOWED_HOSTS) ) ``` `else False` reminds me of: https://adamj.eu/tech/2020/01/17/simplify-your-ifs-that-return-booleans/
I would use: ```python return self.selenium.find_element( By.CSS_SELECTOR, selector, ).get_attribute('class').find(klass) != -1 ```
Few naming suggestions: `ordering_element` -> `expr` `ord_sql` -> `expr_sql` `ord_sql_params` -> `expr_params` `additional_sql_params` -> `ordering_params` `ord_clauses` -> `ordering_expr_sql`
Should we add some context to the message (like part of the HTML snippet) to help identify the needle? I'm a bit worried developers will have a tough time figuring out what the message means.
```suggestion 'ignore_conflicts and update_conflicts are mutually exclusive' ```
You can move the line above to an `else` clause below.
Was already highlighted [here](https://github.com/django/django/pull/13065#discussion_r684521409) but was missed.
We try to avoid accessing the database connections when not necessary, so I'd move `db_features`: ```suggestion if ignore_conflicts and update_conflicts: raise ValueError( 'ignore_conflicts and update_conflicts are mutually exclusive.' ) db_features = connections[self.db].features ```
```suggestion def _select_on_conflict(self, ignore_conflicts, update_conflicts, update_fields, unique_fields): ```
@felixxm OK. Thanks. I will just continue to sharpen the nit-picker then 😃
@felixxm Are you picking these up by eye or linting the diff programatically? If the latter, can I ask your incantation? `flake8` comes out clean with the project config. Ta!
@carltongibson By eye, there is no black magic behind 😃 .
The closing parenthesis should always go on the next line.
I would leave this example as it is, so that the other tests are not affected, and then create a third `Employee` at the beginning of the new test.
> Let me know what do you feel about this? Yes, the `.set()` for non-positive timeouts is pointless. But we still need to expire the key in case it exists. Instead of using `.expire()`, however, we should just go for `.delete()` instead: ```python def set(self, key, value, timeout): client = self.get_client(key, write=True) value = self._serializer.dumps(value) if timeout is None or timeout > 0: client.set(key, value, ex=timeout) else: client.delete(key) ``` Using `.expire(key, 0)` would just cause Redis to perform a delete behind the scenes anyway: > Note that calling EXPIRE/PEXPIRE with a non-positive timeout or EXPIREAT/PEXPIREAT with a time in the past will result in the key being deleted rather than expired (accordingly, the emitted key event will be del, not expired).
I think that we should unpack `self._options` here and make them arguments of `RedisCacheClient.__init__()`. ```suggestion return self._class(self._servers, **self._options) ``` This is how we approach this for all of the memcached backends using client classes implemented in third-party packages.
Do we need to allow customisation of the client class via a setting? That seems like bikeshedding. If someone wanted to write and provide a custom client they can subclass `RedisCache` themselves.
I understand. Although I'm wondering if this is something that can just be configured by passing something in `OPTIONS` that is passed to the client class such that you don't need two separate client classes? (Failing that, a separate backend, e.g. `RedisShardedCache`, might make more sense? I know we are implementing the client class here, but for all other backends we are using an existing client class from a third-party package - we are never exposing knowledge of the client class to the end user.) Either way, if that sharded implementation is coming later (whether in another commit or PR), let's not add this client class loading stuff now. It doesn't add any benefit to this initial implementation other than making it more complex to review.
Don't use `.items()` if you don't need the values. ```suggestion # Set timeout for each key individually as .mset() doesn't support # setting the timeout for all keys at the same time. for key in data: if timeout is None: client.persist(key) else: client.expire(key, timeout) ```
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
Would it be worth emphasising that this straying from pythonic expectation is an _undesirable_ behaviour? In case `ModelBase.__new__()` were to get rewritten in future, and whoever works on it ends up thinking they need to be supporting these testcases? Orr just writing the testcase as an expected failure would imply this.
`test_target_field_may_be_pushed_down` works without the patch. I would move it to a separate commit to make it clear where the behavior has changed.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
It would be nice to be consistent about the ordering in `assertEqual` using it's `(variable, 'expected value')` but here and a couple other places it's opposite.
```suggestion old_name_key = app_label, old_name_lower new_name_key = app_label, new_name_lower ```
This code should only be performed if `relations` are already built. ```suggestion if old_name_key in self.relations: ```
Use more significant variable names here and take advantage of `.pop` return value ```suggestion for model_relations in relations.values(): if old_name_key in model_relations: model_relations[new_name_key] = model_relations.pop(old_name_key) ```
```suggestion self.relations[new_name_key] = self.relations.pop(old_name_key) ```
Again there's a bit of unnecessary work here (alot of unnecessary `.lower()` calls that can be cached in local variables)
I'd suggest: `user_deleted_form` `if user_deleted_form(...)` looks more readable.
Store the result of `self.get_view_on_site_url(obj)` as a local variable to avoid two function calls.
Can we use `cl.result_list` as in the next elif clause below? At any rate there should be a more direct way of getting the objects we're displaying on the page vs. using regex on POST items, which is too brittle and complex.
Hey @rubgombar1, thats right. Thanks for the reference. I take comfort in the fact that I wasent the only one who didn't think about it :)
Hey, if the problem is that the entire queryset is fetched to generate the formset - instead of fetching only the relevent objects using regexp, have you considered fetching just the current page instead? You have the paginator and you have the request. Obviously fetching only the neccesary objects to update is ideal but as @akulakov said, it's a bit brittle. Using the page is not the the best solution but it should contain the performance regression. Hope this makes sense :)
s/non empty/non-empty/ (twice)
ditto, "alias must be different to relation_name"
Don't inherit from `object`.
one line ```py return ( isinstance(other, self.__class__) and self.relation_name == other.relation_name and self.alias == other.alias and self.condition == other.condition ) ``` `and` shortcuts, so it won't try get `other.relation_name` if it's not an instance of the same class 😉
`)` on new line
I think this would be a bit more readable: ``` url = reverse('... show_less_response = self.client.get(url) ```
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
You should fetch the arguments and url name from `request.resolver_match` here to ensure that we redirect to the same view, if someone hooks up `password_reset_confirm` with a different name you'd get an error here.
It might be smarter to validate the token first and only modify the session + redirect if it's valid. Otherwise it makes it really easy to create a session just by GET'ing a url (possible DoS vector). It also means you can't pass `accounts/password_reset` as the token and take advantage of our `request.path.replace()` code. It probably means validating the token twice, which is slightly slower. Seems fine to me if an invalid token gets leaked.
@romgar If you find the time that would be great!
It's weird, because Oracle interprets empty strings as nulls.
I don't think we need to check all rows, probably sth like this: ```python self.assertEqual(list(qs.values_list('lead_default', flat=True).distinct()), [60000]) ``` will be sufficient. We have a similar situation in the `test_nth_returns_null`.
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
The last parenthesis should be moved to the next line (as in the `test_dense_rank`).
Can you use hanging indents and a trailing comma, please: ``` python foo( 1, 2, ) ```
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
Can you sort those attributes please
Valid point. Feel free to change the decorator in a separate commit.
I think "to override the login_url attribute" is more accurate.
It would be better to move these two into a separate test method.
``` py self.assertRaisesMessage( ImproperlyConfigured, '...', ) ```
you can remove ticket reference
IMO we should revert this change `fixture_file` is an absolute path, so it can contain directories with dots in names, this can cause issues in `parse_name()`.
We try to avoid non-4 space indent like this. You could move this to `msg = "..."` instead.
If the `edges.get(None, ())` call above works comparing `key` to `None` here should also be working. I also don't know any other Python object which `str()` representation is `'None'` that are not `None` itself.
A more succinct version might be something like: ``` python for key, subroots in self.edges.items(): if key is not None: for root in subroots: roots.extend(self._nested(root, seen, format_callback)) ```
You don't need to call `keys()` here, iterating over a `dict` yields its keys.
use parentheses to avoid backslashes and I would also try to keep the comprehension on a single line as breaking it up like this makes readability more difficult IMO.
No need to cast the set into a list. You can iterate over sets.
Why does it need to be installed in this migration? This migration doesn't even do anything. It's not given that all new migrations are applied at the same time.
This migration will be very slow. I would recommend using the `F` object to perform the migration in a single update statement rather than looping over all rows.
hm... ok. fair enough, maybe it makes sense to make it swappable, but I don't want to overcomplicate things.
slightly simpler could be: "asking the user what ..."
drop the new line please
Would this be clearer? ``` max_query_params = connection.features.max_query_params if max_query_params is None or max_query_params >= len(numbers): ```
These assertions can be single lined.
You could use `subtest()` for the loop.
Use hanging indent as mentioned before.
Using hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style). e.g. ```python self.assertEqual( nformat(Decimal('1e16'), '.', thousand_sep=',', grouping=3, force_grouping=True), '10,000,000,000,000,000' ) ```
assertEquals is deprecated. Please use assertEqual instead.
You can use `@modify_settings`, e.g. ```suggestion @modify_settings(MIDDLEWARE={ 'prepend': 'test_client.tests.urlconf_override_middleware', }) def test_resolver_match_when_urlconf_modified_by_middleware(self): response = self.client.get('/') ```
I would assert against `url_name`, e.g. ```suggestion self.assertEqual(response.resolver_match.url_name, 'overridden_urlconf_view') ```
I think this test isn't working as expected -- it's resolving to `RedirectView`, same with `test_inline_urls` -- probably the result of the resolve should be checked.
why an empty string? might as well use assertRaises at that point.
Prefer the context manager version: ``` self.assertRaises(Resolver404): resolve(url) ```
can import go at top of file? also, `test_utils` seems like an odd place for these tests. Generally that module is for testing `django.utils`.
single line docstring is okay if it fits
Fine. Yes. (I had a play: there's no actual logic error, since it's pulling the value from the parent scope...) Ta.
Is this line correct? Above it's `subTest(url=url_name)` but then we `reverse(url_name,...)`
Never mind, just read the whole ticket :) Maybe the initial `assertIsInstance(p.restaurant.serves_pizza, bool)` would make more sense here. Else it might end up being refactored.
`assertTrue` would be appropriate here.
It looks like a duplicate of `test_save_unsaved_instance_on_generic_foreign_key` :thinking:
> Shall I also remove `test_target_model_is_unsaved_save` and `test_target_model_is_unsaved_bulk_create`? Yes, they are redundant.
Have you checked ticket-7488? If admin filters by nonexistent objects then we need to fix this in advance.
The main difference is that `integer_validator` is not used internally. `int_list_validator` is used in (deprecated) `CommaSeparatedIntegerField` and it's recommended as a validator for `CharField` that can be used instead. Unfortunately, values are not cast to `int()`, so non-ASCII digits can cause issues. We can change both :thinking:
@apollo13 What do you think? We can change both or neither.
OK, will revert :+1:
I'd rather build regex string with interpolation so as not to repeat the other logic.
more like: `'^%(negative)s\d+(?:%(sep)s%(negative)s?\d+)*\Z' % ({'negative': '(-)?' if allow_negative else '', ...})`
I would probably omit most of the blank lines in these new tests. They are fairly short and straight forward.
NotContains always makes me nervous since it's fragile (a typo or a change in the way we generate the HTML could make it pass). Could we make `class="inlinechangelink">Change</a>` a constant and use it in all 3 of the new tests? That would help alleviate those concerns.
checking the `has_registered_model` attribute in the template context could also be useful.
I've removed an extra newline that caused a flake8 error.
Tests for `formset_factory()` and `formset_factory()` are missing.
```suggestion pass ```
Also I think that `is_ref` will need to be handled in a special way. The reference will need to be resolved to inline the expression. This can be tested by with the following code ```python updated_count = UniqueNumber.objects.annotate( number_inverse=F('number') * -1 ).order_by('number_inverse').update( number=F('number') + 2, ) self.assertEqual(updated_count, 2) ``` In this case `number_inverse` will yield `is_ref=True` and `expr` will be an instance of `Ref` if I'm not mistaken.
You should use tuple deconstruction in a number of places, starting with `query, params = super().as_sql()`. See other SQLCompiler methods. Also you seem to have replicated a bit of logic from `SQLCompiler.get_order_by()`. You shouldn't do that, but find a way to reuse it. `order_by()` supports many forms beyond the asc/desc field name form you've compiled here.
`ordering_params` are overwritten and are not used anywhere :thinking: As far as I'm aware, we should add them to `params` ```suggestion ordering_sql, ordering_params = self.compile(ordering) ordering_sqls.append(ordering_sql) params.extend(ordering_params) ```
i think you should use `NotImplementedError` instead on `NotImplemented`, moreover this proves that it's untested 😞.
I'd call the keyword and variable "registry" and pass in `registry=site._registry` as another application may have a different convention for how it wants to define a registry.
Good point, I guess we can keep it as is. Maybe just rename `site` to `register_to`, i.e. `autodiscover_modules('admin', register_to=site)`
site -> register_to
As the code itself hints, there's no reason to assume the imported attribute is a class.
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
`'rb'` flags are unnecessary.
```suggestion image_data = Path(__file__).parent.joinpath("test.png").read_bytes() image_data2 = Path(__file__).parent.joinpath("test2.png").read_bytes() ```
```suggestion file_path = Path(__file__).parent / 'test.png' ```
You need to specify a type of lock, e.g. `locks.LOCK_NB | locks.LOCK_EX`. Currently it returns `False` because we passed an invalid argument.
You don't need to mock, it will return `False` for a bad file descriptor.
I don't have a strong opinion here as that's probably the only type of non-`Expression` wrapper supported in `ExpressionWrapper` but the previous `if isinstance(self.expression, Expression)` felt more correct.
I have mixed feelings because in other places we check the `resolve_expression` attribute, which we cannot use here 🤔. Neither solution is perfect 😐
I'm not sure about using `Expression` here (see similar doubts in #13165) :thinking: I would rather use `WhereNode`, e.g. ```suggestion if not isinstance(self.expression, WhereNode): ``` \cc @charettes
```suggestion return super().get_group_by_cols() ```
We should test with a different expression since this might be fixed in the future ```suggestion expr = ExpressionWrapper(Lower('field'), output_field=IntegerField()) self.assertEqual(expr.get_group_by_cols(alias=None), [expr.expression]) ```
I'm wondering if this should be within the `DATABASES` setting
I think we should catch `ImportError` and return appropriate message, e.g. ```python try: pk_class = import_string(pk_setting) except ImportError: msg = 'The module %r could not be imported.' if hasattr(self.app_config, 'default_auto_field' ): msg += 'Check your %s.default_auto_field attribute.' % self.app_config else: msg += 'Check your DEFAULT_AUTO_FIELD setting.' raise ImproperlyConfigured(msg % pk_setting) ``` We could also add a cached hook, `get_default_auto_field()`.
I believe this should included in the `_check_default_pk()` with a different check, e.g. `fields.E102`.
include trailing comma in kwargs
I'd order the test with the other `check_html()` tests (above `test_use_required_attribute`).
I'd omit the blank line after the docstring as you've done in most places.
preferred format: "#12554 - Make sure ..."
again, I wonder if there's an advantage to running every single test with `TEMPLATE_DEBUG=True/False` or if we can just use override_settings to modify it for the tests that care.
I figured it out after I reviewed enough of the files. Meaningful test names or classes sounds good. Not a blocker to getting the first version of this merged though.
could you limit line length to 120 characters so horizontal scrolling isn't required in GitHub? missing whitespace for: `{% autoescape on%}`
The test should construct the expected string using `connection.ops.quote_name()` so two variants of the test aren't needed.
Please use `assertSequenceEqual` consistently rather than mixing `assertQuerysetEqual`.
Include a trailing comma in cases like this so that if more items are added later, this line doesn't have to be modified again.
you don't need `nulls_last=True` here because it's a PK you're ordering by, which is non-nullable
@timgraham already pointed the code formatting of the tests. Please don't make newlines at dots, `tests/annotations/tests.py` has good examples of the style.
Please remove this docstring, it doesn't have any value IMO.
Looks like Windows isn't happy with the dots. I think something like 'nonexistent' should work.
```suggestion self.assertContains(response, 'Oh dear, an error occurred!', status_code=500) ```
tests for the `repr`s of `HttpResponseNotAllowed` and `HttpResponseRedirect` already exist in `httpwrappers/tests`, please move these tests there
```suggestion Question.objects.create(question='Not a question.') ```
quote names of objects (`'CREATE INDEX "%(index)s"...'` etc). These parameters are spliced into the statement, not passed as arguments.
Actually, quoting the parameters before interpolation makes _more_ sense on Oracle than other backends, because on Oracle `quote_name` also handles shortening.
I'd use a multiline string and indent it internally. Also, remove the semicolon in the end. Doesn't do any good, and can do harm.
I would expect some explanation on why `quote_name` is used for some names and `geo_quote_name` for others.
Perhaps it isn't worth breaking consistency. For sure it can wait and be done separately.
Do we need this methods? Maybe I'm missing sth but thread's database connections should already by overridden, and we don't pass `connections_override` to the `_create_server()` anywhere in Django :thinking:
> PS - you might ask: why not fix ticket 29062 first? The reason is that fixing ticket 29062 properly would involve properly closing connections. Thus, any correct fix of ticket 29062 would be a superset of this PR, which would make it an even bigger change. Yes that was my first question :smile: Thanks for details :+1: . I'm afraid that it can be still confusing for a future me. I will try to move something to a separate commit e.g. `_make_connections_override()` which should reduce the number of changes and make it easier to bisect and fix potential regression.
Is this possible? If so, it will be good to cover this scenario with tests.
Sorry, wasn't trying to request a change, was thinking about how async middleware would be written and just seeking clarification.
That's what `inspect.iscoroutinefunction(getattr(Foo, '__call__', None))` does above. What I mean is that it's probably an abuse of Python data model. For example, ```python def Test: async def __iter__(self): pass assert inspect.iscoroutinefunction(Test.__iter__) ``` Won't fail but `__aiter__` should be used for this purpose. There's no analogous `__acall__` for `__call__` and it's not clear to me whether `async def __call__` is an abuse or not.
I think this should work: ``` python connection = connections[db] if connection.settings_dict['ENGINE'] != 'django.db.backends.dummy': loader.check_consistent_history(connection) ```
Not sure if this might mask some exceptions, but here's what I came up with for now: ``` python for db in connections: connection = connections[db] try: connection.cursor() except ImproperlyConfigured: # Raised by the dummy backend. pass else: loader.check_consistent_history(connection) ```
The following is just the same as `return spec`: ```python if spec is None: return return spec ``` So: ```python def find_spec(self, path, target=None): return self.importer.find_spec(path, target) ```
You can rebase your branch and target it for Django 2.0. Since master no longer supports Python 2, you can make a few updates such as using `super().`.
Just make it: ``` if len(expressions) < 2: ``` That avoids problems with sqlite and mysql. GREATEST(x) is always x on backends that support single arguments anyway.
Perhaps this could be a docstring? You might elaborate a bit more -- as someone not familiar with MySQL, it's not clear to me what "improved" means.
Add an exception message similar to the other methods.
append(...), not append[...].
This must be an inner skip, please revert (ticket-31888).
returning `b''` for BinaryField (as original code did) should be required under Python 3, IIRC.
it's helpful to use assertRaisesMessage to ensure this is the exception we expect
I think `warnings.filterwarnings('always')` is unneeded.
I think it's better to omit the try/except and instead say `Settings(settings_module) # should not raise an exception`. See 071801ccff970682a799ce754431a3c3ce3d6902
think we can chop the blank lines in the last 3 tests
ImproperlyConfigured should be raised if DEBUG=False and ALLOWED_HOSTS is empty.
Do we need named db? ```suggestion 'NAME': ':memory:', ```
I don't see much value in this docstring, please remove it.
I would use this style to save some lines: ``` msg = '....' with self.assertRaisesMessage(NotSupportedError, msg): ```
There is no need to create a random suffix. We should also test all described scenarios, e.g. ```suggestion test_connection = copy.copy(connections[DEFAULT_DB_ALIAS]) test_connection.settings_dict = copy.deepcopy( connections[DEFAULT_DB_ALIAS].settings_dict, ) tests = [ ('test.sqlite3', 'test_1.sqlite3'), ('test', 'test_1'), ] for test_db_name, expected_clone_name in tests: with self.subTest(test_db_name=test_db_name): test_connection.settings_dict['NAME'] = test_db_name test_connection.settings_dict['TEST']['NAME'] = test_db_name creation_class = test_connection.creation_class(test_connection) clone_settings_dict = creation_class.get_test_db_clone_settings('1') self.assertEqual(clone_settings_dict['NAME'], expected_clone_name) ```
New tests are failing on Oracle. I think we should avoid creating a test database, maybe by mocking `_create_test_db()` :thinking:
`"""Return True if the django_migrations table exists."""`
"Stay on ..." (and please be consistent with no spacing around the sentences) Add a period to each sentence too.
```suggestion def check_allowed_hosts(cls, expected): ```
It's helpful to describe the issue with a few words, e.g. "Inserting non-ASCII values longer than X characters (#22144)." (I'm not certain that's a correct description of the issue).
preferred format is "#15346, #15573 - Issue description"
Is the complexity of testing with a logger needed? I think a print statement and passing `stdout=StringIO()` to `call_command()` in order to check the value would be sufficient.
I see :/ Well `force_str` should still save you the promise checks.
I think you should use `force_text` here since the regex match can't be a promise and `force_str` aliases it on Py3.
Usually we camel case assertions to match the unittest style. Maybe assertFieldsInModel (considering field_outputs is a list).
This looks to be incorrect, there should be if not os.path.exists() protection, or better yet, have _createdir() do (very pseudocodish) try: makedirs(); except: if already-exists: pass; else raise EDIT: Sorry, was reading the old version of _createdir()...
I'd omit the second "inner_method" since it's not meant as a backwards operation and not used as far as I can tell.
create_initial_data and create_big_data below
This implementation is repeated 5 times in this file. I think it should be taken up to Operation (or at least to a new sub-parent "OneModelOperation").
Indexes are not constraints, generally.
should be `first_state`, not `project_state`, I suspect.
Could move `executable = '/usr/bin/python'` to a class attribute.
Maybe it would be nice to put the shared test logic into a helper method.
I don't think we can use `assert_called_once()` yet since that's new in Python 3.6. With the change in `autoreload.py` reverted, both tests fail on Python 3.5 with `AttributeError: assert_called_once` while the first test will pass on Python 3.6.
I prefer stating the expected behavior rather than "Test that..." since all tests are for testing. e.g. "A language not present in settings.LANGUAGES can be installed/used by a project."
For resetting the loaded translations, I found an example in `i18n.test_compilation.FuzzyTranslationTest` where the `setUp` "just" calls: `gettext_module._translations = {}`.
This argument can be single-lined. (It's only 111 chars so. Shorter if using `obj.__class__`)
Please remove temporary variable `actions`, also IMO it will be clearer to unpack `action` e.g. ```python names = [name for _, name, _ in obj._get_base_actions()] ```
Please add a trailing comma.
This is a classic case where you may have duplicates of multiple action names but are only warned about the first one. You resolve that and then get nagged again about the next one. It would be better to list all of the duplicated names. It also probably makes sense to just count all of the names using `collections.Counter` and look directly for duplicates; to wit: ```python counts = collections.Counter(names) duplicates = [name for name, count in counts.items() if count > 1] if duplicates: return [checks.Error( ￼ '__name__ attributes of actions defined in %s must be ' ￼ 'unique. Duplicated names: %s' % (obj.__class__, ', '.join(duplicates)), ￼ obj=obj.__class__, ￼ id='admin.E130', ￼ )] ```
> I'd prefer to return a list of errors rather than a single concatenated error. Is that the method I should change it to? Sorry - I didn't get around to replying, but yes, multiple works better.
I think you can apply my test patch and that should be sufficient.
put closing ) on the next line
deindent this line and the next line by 4 spaces
cast to list instead of str
`assertEqual(list(a), [...])` should be simpler
I would leave the first part of the sentence untouched. Also please use hanging indentation: ```suggestion print( 'The datetime and django.utils.timezone modules are available, so ' 'it is possible to provide e.g. timezone.now as a value.' ) ```
We don't need to mock `django.db.migrations.questioner.sys.stdout` anymore.
There's a lambda called `strip_prefix` in `inspectdb.py` that should be of use.
actually I think the preferred solution is to omit the u'' prefix, even on Python 2. The output already includes `from __future__ import unicode_literals` so there shouldn't be a problem without it.
`'bar'` is already in `out` from the first execution of `call_command()`. You should reinstantiate or use `out.truncate(0)` before the second call.
Unless I am missing something here, you only need `self.has_view_permission(request)`, since it checks for view permissions or change permission. ``` def has_view_permission(self, request, obj=None): """ Return True if the given request has permission to view the given Django model instance. The default implementation doesn't examine the `obj` parameter. If overridden by the user in subclasses, it should return True if the given request has permission to view the `obj` model instance. If `obj` is None, it should return True if the request has permission to view any object of the given type. """ opts = self.opts codename_view = get_permission_codename('view', opts) codename_change = get_permission_codename('change', opts) return ( request.user.has_perm('%s.%s' % (opts.app_label, codename_view)) or request.user.has_perm('%s.%s' % (opts.app_label, codename_change)) ) ```
self->same_host (I think that's what's meant)
Can you sort those attributes please
Is there a need to hardcode pks? This is generally to be avoided, I think.
This isn't triggered until the input queue is read at least once.
There are still many unrelated formatting changes that should be reverted.
Please remove the unrelated style changes.
Every day I get to learn something new. Thanks.
The optional trailing dot may "protect" an ending dash -- `xn--.` passes this. Is this intended? If not, switch the last two lines.
Forgot to mention earlier, but on first look I found `[a-z-' + ul` a little confusing because of the dash between two ranges that actually serves as a dash and not a range separator. I think it would be more readable as `[a-z' + ul + r'-]` (similar to how it is in `domain_re` above).
I think this change really indicates the need for a second test for wrapping a non-string object.
Are all the `six.text_type` needed? Tests seem to be passing with at least the first one removed. Shouldn't there be tests with lazy versions of args, kwargs? It looks like these tests are mainly testing `str.format()`.
I'm not sure the docstring adds any value here.
This should go to the 2nd commit :pick:
Are both of these going through the `__radd__` path? At a glance, I'd have _guessed_ that both are using `__add__` because the LHS is a `SimpleLazyObject` which now has that magic method? I could be wrong, it has been a _long_ time since I filed the ticket, so I may be misremembering.
I have been thinking about this too, what happens if we were to deprecate sha256 at some point again? Do we want to leave legacy_algorithm around for that? (Porbably no)
I don't think that we would like to keep handling of `legacy_algorithm` when deprecation ends, that's why I'm going to simplify this. I hope you don't mind.
Per https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/ these could use `assertIs(..., True)`. I've done this for existing `.check_token()` tests in #12380.
I don't understand why we have methods with a double underscores prefix which are copies from `SessionBase`, e.g. `__hash()`, `__legacy_encode()`, `__legacy_decode()` :thinking:
Maybe we could add `pbkdf2_sha1` in place of `sha1`.
I think the `= true` is a byproduct of filter requiring a left and right hand side. This can be fixed when that restriction is removed via filter/expressions.
Include a trailing comma so that if more items are added later, so we don't need to modify this line again.
You can use `self.assertRaisesMessage(ValueError, 'error string')` rather than inspecting the exception args.
Is there a reason to use `len()` instead of checking the objects? `len()` may take more effort to debug in the event of a failure.
~~Are you sure the `Value` wrapping and the `output_field` are necessary here? As long as you pass an `output_field=models.BooleanField()` to `Case.__init__` you should be good to go.`~~ _Edit: Well it looks like passing `output_field=models.BooleanField()` to `Case.__init__` doesn't work yet._
Smart... This only works because `shell.py` does inner imports, but that does seem unlikely to be refactored
```suggestion def test_stdin_read_inline_function_call(self, select): ```
I think we can chop it.
no need for breaking this over multiple lines now
Ok, cool. :thumbsup:
Why don't you do the decimal precision as part of the format expression? Something like: ```python number = ("{:_.%sf}" % decimal_pos).format(number) ```
Or you can still use f-strings for this too: ```python number = f'{number:_.{decimal_pos}f}' ```
IMHO I would simply use `_` not `,` and always replace. Reduces complexity and a replacement isn't too slow. In fact, it's probably faster than the if clause. If clauses can significantly slow down code execution, since your processor doesn't know which instructions to preload until you reached that particular instruction and decided where to go from there.
`as defined by the arguments` is not really telling me anything. I would either add a longer more descriptive doc string or none.
IMHO I don't think you should use 0 values as boolean. If you want boolean, use boolean. Besides, `grouping` may have too many types now. I can be an integer, a tuple and boolean. I would stick with a separate variable called `use_grouping` here. It's more descriptive.
why not use `a_signal` in this test? The signal objects seem to be identical.
`ERROR` in `assertLogs()` is still missing: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ```
Yes, we should check if it's on `ERROR` level: ```python with self.assertLogs('django.dispatch.dispatcher', 'ERROR') as cm: ... self.assertEqual(cm.records[0].getMessage(), ...) ``` and assert a message (`cm.records[0].getMessage()`) and an exception info (`cm.records[0].exc_info`).
maybe I'm being a stickler, but I'd make extra assertions on the log record's level and message
I would move it to the `test_send_robust_fail()`.
Set the name of _meta.indexes. This can't be done in Options.contribute_to_class() because fields haven't been added to the model yet.
It's done on purpose. We modify `attrs` in this loop so `list()` is used to create a copy.
True, it's unnecessary since 58ad030d05fa50cfed327368ab61defca3303e02. It's not a copy&paste code in was done on purpose in the original patch, see a68ea231012.
A test is missing for this change.
Is `test_doesnt_work_with_init_subclass` meant to test this change? I still don't see any test failures if this change is reverted.
Can this be simplified to ```suggestion # Collation change? elif getattr(old_field, 'db_collation', None) != getattr(new_field, 'db_collation', None): new_collation = getattr(new_field, 'db_collation', None) fragment = self._alter_column_collation_sql(new_field, new_type, new_collation) actions.append(fragment) ``` Or maybe we want to keep the old code to support field type and collation change at the same time (e.g. `CharField(db_collation='foo') -> TextField(db_collation='bar')`).
We use `new_default` only when `old_field.null and not new_field.null` so IMO it's fine to use ```diff diff --git a/django/db/backends/base/schema.py b/django/db/backends/base/schema.py index bfccf5e8fb..8cd5e11bbf 100644 --- a/django/db/backends/base/schema.py +++ b/django/db/backends/base/schema.py @@ -675,17 +675,17 @@ class BaseDatabaseSchemaEditor: # 3. Replace NULL constraint with NOT NULL # 4. Drop the default again. # Default change? - old_default = self.effective_default(old_field) - new_default = self.effective_default(new_field) - needs_database_default = ( - old_field.null and - not new_field.null and - old_default != new_default and - new_default is not None and - not self.skip_default(new_field) - ) - if needs_database_default: - actions.append(self._alter_column_default_sql(model, old_field, new_field)) + needs_database_default = False + if old_field.null and not new_field.null: + old_default = self.effective_default(old_field) + new_default = self.effective_default(new_field) + if ( + not self.skip_default(new_field) and + old_default != new_default and + new_default is not None + ): + needs_database_default = True + actions.append(self._alter_column_default_sql(model, old_field, new_field)) # Nullability change? if old_field.null != new_field.null: fragment = self._alter_column_null_sql(model, old_field, new_field) ```
Maybe `null_actions` for consistency with `post_actions`? And move it to where we init `actions` and `post_actions`? L581.
I think that we can keep this more DRY, i.e.: ```python else: sql = self.sql_alter_column_null if new_field.null else self.sql_alter_column_not_null return ( sql % { "column": self.quote_name(new_field.column), "type": new_type, }, [], ) ```
This could be moved closer to where it's used or even eliminated as an intermediate variable.
I think you should use `type` not `__class__`. At least in python 2 this will break if the class does not inherit from `object`.
I'd keep the current version without `type()` since it's unrelated. If there's a need for this change, create a ticket with a corresponding test.
chop blank line
how about: "Run the system checks on all ModelAdmins, except if they aren't customized at all."
`fix_this` is misleading, because there is nothing to fix here.
A free option for getting the tests running with Oracle is outlined [on the wiki](https://code.djangoproject.com/wiki/OracleTestSetup#using-the-oracle-developer-day-pre-installed-vm) if you are interested.
`Q()` is not a real "expression" and it deserves special treatment, see ticket-29125. IMO it makes sense to do this change only for all expressions (as for `django.db.models.fields.*`), but not all of them are importable from `django.db.models` so it's more complicated.
It's helpful to describe the issue with a few words, e.g. "Inserting non-ASCII values longer than X characters (#22144)." (I'm not certain that's a correct description of the issue).
I would move this docstring to the class: ```python class MySQLUpdateOrderByTest(TestCase): """Update field with a unique constraint using an ordered queryset.""" ```
We can chop this docstring.
I guess this needs to be something like `inherited_attributes |= set(base.__dict__.keys())` to work on Python 2.
As discussed on IRC: no.
what if two mixins have the same name (from different packages)? hypothetically: `facebook.models.UserMixin` and `twitter.models.UserMixin`
Appreciate what you've done with the tests but I think they're harder to comprehend now. As a Django dev I can jump in and read model classes, but the helpers are obscuring things a bit to me. Also you now have multiple tests per test method now - ideally there should just be a handful of classes per test and some assertions. I guess you can split based on overriding, non-overriding, etc.
In `_handle_m2m_field()` and `_handle_foreign_key_field()` we can avoid of temporary variables (`value`) and return directly, e.g. ```python def _handle_foreign_key_field(self, field, field_value): return base.deserialize_fk_value(field, field_value, self.using, self.handle_forward_references) ```
I see now, my mistake. Please put it under `test_index_together` though.
Could we check if we actually need this `with` statement again? Maybe the one above is just fine? :man_shrugging:
This will be called upon by third party db maintainers. I think it is OK to check each core DB here, and just no do any check for non-core databases at all.
Yes thanks for the answer!
https://www.postgresql.org/message-id/6721.1357856188%40sss.pgh.pa.us So probably the whole debate about touching the introspection for expressions should be closed. I could only get `pg_get_expr` to output whatever I used for `CREATE INDEX .. ON (lower(body), lower(title))` where `lower(body), lower(title)` would be returned by `pg_get_expr`.
The default should be the most common I think. So set the default, then change it in the postgres features.
Yes it was Ian, but my example used joined fields for an update which isn't (yet) allowed. How about something like: ``` Author.objects.update(alias=Greatest('name', 'goes_by') ``` Which will also test the handling of varchars in a Greatest.
Could be a little more precise by using exactly 3 or 6, not between 3 and 6 ```suggestion self.assertRegex(now_string, r"^.*\.(\d{3}|\d{6})") ```
Trailing zeros are stripped on PostgreSQL, so I changed to ```suggestion self.assertRegex(now_string, rf"^.*\.\d{{1,{precision}}}") ```
```suggestion self.assertEqual(a.headline, 'Default headline') ```
I don't think you can depend on a None choice being defined for a nullable field, necessarily. I don't think you need to make a change here.
I think using a semantic name would help here, e.g. `lookup_kwarg_null`
I've noticed that `None` from `flatchoices` should update `Unknown` not `All`. I fixed this.
adding trailing comma
this hanging indent is intentional, you'll see it throughout Django
Shouldn't we handle these situations? ``` >>> class TestForm(Form): ... my_field = forms.ChoiceField(choices=[['', 'zero']]) ... >>> t = TestForm() >>> print(t['my_field']) <select id="id_my_field" name="my_field" required> <option value="" selected="selected">zero</option> </select> ``` Or this: ``` >>> class TestForm(Form): ... my_field = forms.ChoiceField(choices=[(None, 'zero')]) ... >>> t = TestForm() >>> print(t['my_field']) <select id="id_my_field" name="my_field" required> <option value="" selected="selected">zero</option> </select> ```
Could you a docstring along the lines of `test_file_url()`, please :smile:
I'd keep `dispatch()` the first method on the view and sort the others by call stack.
Should use `assertRaisesMessage()` to verify the string also.
Not sure how much a difference it makes, but it seems better to store this in Python rather than having to read from a text file. Worth it to make the file location customizable? If so, it might be nice to make "common passwords" a separate package so we don't have to include that list in Django. I guess users might not care for the additional setup tasks though.
I think `Parent` and `Child` model names would be more in line with other model names I've seen.
note that `Meta` should appear after fields per: https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#model-style I made this one change when I committed it.
I think that should be `hire_date` (two words).
remove extra newline
The trailing space can be removed.
I think it can be omitted.
I think `__str__` can be omitted here. If it needs to stay, `CustomUserWithIntegerUsername` should be wrapped by `@python_2_unicode_compatible`.
I'd make this a separate test and then you can decorator the test method instead of using `with ....`.
I guess the method probably isn't needed but if you want to keep it, please fix it like c62807968d7930bfd34afc2036c67921b943592f.
I think this blank line can be removed.
You should be able to pass `is_active=False` to `create_user()`.
We can move the test that involves `login()` to the other pull request.
prefer `setUpTestData` since that executes once per test class instead of once for every method
@timgraham It might be more appropriate in another commit then. I believe I wanted to make sure nothing was logged if a m2m backed inline was submitted without changes.
I think you could use `self.assertSequenceEqual` rather than this.
maybe something like "Normally Django will use a connection to the 'postgres' database to avoid running initialization queries against the production database when it's not needed (for example, when running tests). Django was unable to create a connection to the 'postgres' database and will use the default database instead."
This can't be in `base`
Verify the message as well, please.
@akulakov - that may seem to be a more common pattern, but it is only because unpacking generalisations have only been available since Python 3.5, which is now the minimum version supported by Django. Unpacking generalisations also have the advantage that they have a dedicated operation that has less overhead than the function call, `dict()` in this case. The proposed change is more concise and perfectly clear according to the syntax of the language.
Fine, but not as part of this PR. If you can change these cases systemically, that would be great.
"Considre case" > "Consider the case".
Given `self.inner_votes` is an instance of `collections.Counter` this could be simplified to `self.inner_votes.update(inner_votes)`.
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
The backend should be given a chance to figure out what should happen in this situation. Possibly by adding DatabaseOperations.resolve_expression_source(expression, sources)
I think we prefer the closing paren on a newline
I think you should use `type` not `__class__`. At least in python 2 this will break if the class does not inherit from `object`.
I'd keep the current version without `type()` since it's unrelated. If there's a need for this change, create a ticket with a corresponding test.
chop blank line
how about: "Run the system checks on all ModelAdmins, except if they aren't customized at all."
`fix_this` is misleading, because there is nothing to fix here.
Lose the `params` temporary and simplify: ```python prefix += ' (%s)' % ', '.join('%s %s' % i for i in extra.items()) ```
I queried whether we needed to validate `options` here, but the DB does it for us. e.g. Using `SUMMARY` on Postgres <10: ``` EXPLAIN (ANALYSE true, TIMING true, SUMMARY true) ... ERROR: unrecognized EXPLAIN option "summary" ``` The error message is clear enough.
Something like this comes to mind: ```python with transaction.atomic(): transaction.set_rollback(True) print(queryset.explain(analyze=True)) ```
Yeah. There are quite a few, and this is anything but standard across backends. The advantage is being able to access all of this information without needing to pop out to the database shell and restricting the flags may cripple the use of this feature for some. Adding support via kwargs sounds sensible. The irritation may be determining the default state of the various flags based on the value of `verbose`. So it may be easier to keep the interface simple and just "enable all the things" if `verbose` is `True`, where they are not costly in terms of execution time, and then provide `analyze` separately in kwargs.
Trailing space in string not required.
I would add `('availability', BooleanFieldListFilter)` to the `BookAdminWithTupleBooleanFilter` instead of creating a separate class.
"cannot" is one word. add period.
I guess we could use `bulk_update` but not a big deal.
put closing ) on the next line
I don't think this is necessary? It should default to an empty string.
include trailing , (that way if more values are added in the future, we won't have to edit this line again)
I don't think it really make sense to pass recipient_list... the point of using `email_user` is to send mail to `AbstractUser.email`
the dictionary key/values should be indented
two newlines above class name
I simplified this test with `@mock_inputs()`.
Well, we _could_ make `on_delete` an actually-required arg to `ForeignObject` right now, and move it even before `from_fields` and `to_fields`, but that would require duplicating the deprecation warning in both `ForeignKey` and `OneToOneField`.
Well, there are a number of existing cases of docs URLs in user-facing messages (especially in migrations, but other places as well). I think there is a lot to recommend them from a UX perspective; someone who gets this warning is quite likely to in short order need a reference of the available `on_delete` options. I don't think the URL-going-stale issue is that big for a deprecation warning, which has a limited lifespan anyway. If someone does happen to rearrange those docs in the next couple years, we'd just update the message. (Like the ones in migrations, the message should use a Django-version-specific docs link, not the `stable` redirect, so that for a given Django version the link shouldn't ever go stale.)
This is a nitpick, but `on_delete` is not an attribute you set, it is an argument you pass. I think that second sentence could just be removed. What might be more useful here is a stable link to the `on_delete` docs.
Please do not change formatting
Is there really no alternative to a plain except? This would even catch KeyboardInterupt etc which we surely don't want. Which exceptions can occur here? As a last resort you can use except Exception, but I'd prefer it explicit.
avoid _we_ usage as well ``` SystemCheckError is surfaced when run_checks raises SystemCheckError and teardown databases raises ValueError
Avoid using `Test that` prefixes in docstring, this is necessarily testing something as it is a test. ``` Teardown functions are run when run_checks raises SystemCheckError. ```
Maybe just do this in the `__init__()` method of your subclass, after calling `super()`? That will keep all your modifications together in one place. This will also let you remove the `hasattr` check in `get_test_runner_kwargs()`.
I would make the test of `build_suite()` and `run_tests()` separate test methods.
Unnecessary trailing comma and white space.
there's no need to "cleanup" by logging out as each test creates a new test client
This is the same as the previous assertion. I'd think only 1 assertionis needed since all the `as_*` methods use `_html_output()`.
Could you try to write these tests at a lower level, without the `as_ul()` output methods? They're difficult to debug now.
```suggestion f'<li>Title: <input type="text" name="form-0-title"></li>' f'<li>Pub date: <input type="text" name="form-0-pub_date">' f'{delete_form}</li>' ```
please limit line lengths so horizontal scrolling isn't required, something like: ``` self.assertHTMLEqual( form.as_p(), '<p><input id="id_custom" name="custom" type="text" /> ' '...' ) ```
```suggestion # Windows registry may not be configured with correct # mimetypes. ```
```suggestion self.assertEqual(value, b'text/plain') ```
This isn't Django's default charset (unless I'm mistaken).
> this test is checking the support for a possible object that is seekable but has no `.tell()`. > `tempfile.NamedTemporaryFile()` has `.tell()`. Just as an aside, whether there is any change here or not, but you could do: ```python with tempfile.NamedTemporaryFile() as tmp: del tmp.tell # Emulate seekable file handle without .tell(). ... ```
For a gzip file, I believe this will cause the browser to unzip it. ``` $ python3 >>> import mimetypes >>> mimetypes.guess_type('f.tar.gz') ('application/x-tar', 'gzip') ``` But I'm guessing the user wants the mime type to be `application/gzip` (or similar) with no encoding. [MDN Docs](https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding) > The Content-Encoding entity header is used to compress the media-type. When present, its value indicates which encodings were applied to the entity-body. It lets the client know, how to decode in order to obtain the media-type referenced by the Content-Type header. I know of at least one third party Django app that has this issue: https://github.com/johnsensible/django-sendfile/issues/38
You lost a ] in here.
Tests are failing because you dropped the `]`.
I would rather keep the current behavior, but other opinions are welcome. It could be the target of a different ticket.
This is really a separate fix, but I guess we can do them in the same PR.
Ideally this would be passed as a parameter instead of being baked into the SQL. Maybe adding a `%%s` placeholder and inserting the format string at `params[0]` would work? ```python template = "strftime(%%s, %(expressions)s)" sql, params = self.as_sql(compiler, connection, template=template, **extra_context) format_string = '%%H:%%M:%%f' if db_type == 'time' else '%%Y-%%m-%%d %%H:%%M:%%f' params.insert(0, format_string) return sql, params ```
Period: ```suggestion "Quit and manually define a default value in models.py.", ```
I don't think we need parentheses and `Note:`. Also, there is no need to use `!`. Maybe: ```suggestion 'Ignore for now. Existing rows that contain NULL values ' 'will have to be handled manually, for example with a ' 'RunPython or RunSQL operation.', ``` ```
I would revert this change, the previous version is clearer to me.
Period ```suggestion 'Quit and manually define a default value in models.py.', ```
`later` is a bit misleading, since the expectation is that the dev will update models.py (immediately) after quitting so that they can continue to create their migrations.
Migrations are applied and recorded atomically.
This should be in the `finally`: ```python with self.temporary_migration_module(module='migrations.test_migrations'): try: ... finally: # Unmigrate everything. call_command('migrate', 'migrations', 'zero', verbosity=0) ```
Furthermore, why do you construct `unapplied_parents` at all? Can't you just loop over `self.graph.node_map[migration].parents` and on raise an exception when the first one has an inconsistent history? That would safe some time in bigger projects. ``` python for x in self.graph.node_map[migration].parents: if x is unapplied # use the condition from above raise InconsistentMigrationHistory(...) ```
I don't think this is correct. `settings.MIGRATION_MODULES` only contains user-defined migration modules -- presumably want the detection to work regardless of whether or not that setting is defined.
I would prefer the solution from #9339 where we list all missing files not only all labels.
use Model.objects.create() rather than `save()`? I don't think manually specifying an id is needed (or a best practice)
I'm unclear with the purpose of this line is -- the "statements" local variable isn't used
I'm not sure what this sentence means
maybe create_and_call -> "test" to be a bit shorter
``` # executemany() must use an update query. Make sure it does nothing # by putting a false condition in the WHERE clause. ```
Sounds, good thanks for giving this ticket a shot by the way. It's a tricky problem with a few edge cases but you'll certainly learn a lot of things along the way.
Hey guys, `index_together` and `unique_together` have been fixed before in this BR: https://code.djangoproject.com/ticket/24757
Here we also should call `super` and not copy-paste code
What about indexes and constraints based on `expressions`? For example: ```python Index(F('author'), F('title'), name='author_title_index') ```
This formatting change is not related with a bug fix, please revert.
```suggestion self.assertIs(app_dir.joinpath("apps.py").exists(), True) ```
This line and `os.mkdir(bad_target)` are unnecessary, we don't need to create directories for this test.
```suggestion content = app_path.joinpath("apps.py").read_text() ```
```suggestion content = app_path.joinpath("apps.py").read_text(encoding="utf8") ```
I would move test for conflict with an existing Python module to a separate test e.g. `test_importable_target_name`
You should use `supports_update_conflicts_with_unique_fields`.
You can do what I suggested above here as well.
You don't need to add the brackets with `join()`.
This method implementation could be simplified by doing: ```python if on_conflicts == ON_CONFLICTS_IGNORE: return 'ON CONFLICT DO NOTHING' if on_conflicts == ON_CONFLICTS_UPDATE: ... return result ... ``` This would also let you eliminate the `if-else` below and initializing `result` to `''`.
You should use `supports_update_conflicts_with_unique_fields`.
Once again, exec is not needed here.
(This is also more "food for thought" than an actual request for change - whatever you prefer is fine.)
`hasattr` is ugly because of its propensity to silently hide `AttributeError`, and because of its look-before-you-leap inefficiency. I would avoid it and instead use something like: ``` password_changed = getattr(validator, 'password_changed', lambda *a: None) password_changed(password, user) ```
start docstring on next line and "Create..."
This would be better as a set rather than a list.
Ahh OK, so maybe `%s.%s`.
I would only pass a `value`, without changing the default `invalid_choice` message, see a similar change for built-in validators 83fbaa92311dd96e330496a0e443ea71b9c183e2.
No, that would make it impossible to override the `invalid_choice` message. IMO we should revert changes to the `invalid_choice` message (L1191-L1192) and only pass a `value` to the `ValidationError`: ```python raise ValidationError( self.error_messages['invalid_choice'], code='invalid_choice', params={"value": value}, ) ```
```suggestion cls.set_up_called = True ```
Why does the message need to be passed into the class method? (Maybe there is a good reason I've missed.) I also think we want to state which choice enum and what value caused this to happen, e.g. ```python @classmethod def validate(cls, value): try: cls(value) except ValueError as e: raise exceptions.ValidationError('Invalid choice: %s.%s' % (cls.__name__, value)) from e ```
I think this should be a `ValueError`
Ok I understand that you have to determine if it's either a field reference or an explicit value but I think you should do it the other way around. That is accept both `six.text_type` and `six.integer_types` and consider `six.text_type` as field references (`F()`) and everything else as an explicit value (`Value()`).
"Both Y and X must be provided". Switch the Y and X in the error.
I think this would probably cause more confusion than it's worth. I'd be in favour of not supporting default_alias for new aggregates, and requiring users to supply their own alias. I'm biased against default_alias though, so I won't veto. Interested in what others thing.
``` .aggregate(regr=RegrSYY('col_a', 'col_b')) # vs .aggregate(RegrSYY('col_a', 'col_b')) -> col_a_col_b_regrsyy ``` It's a long and unwieldy default alias. You also have to be careful about the column name length in this situation. Oracle only supports names up to 30 chars, which means both column names need to be 10 chars or less to account for the extra bits of the underscores and aggregate name. I don't see the value.
Using `clashing_pair` in a hint is misleading. We should use appropriate model names not field names or table names.
Chop blank line.
Add a trailing comma.
Can we wrap this line after the comma.
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
Don't assert against the exact SQL since per-backend dialect will have a different syntax (e.g. wrt to identifier quoting). ```suggestion ``` Asserting against the resultset should be enough.
You could use `.get()` to assert a single result is returned ```suggestion self.assertEqual(authors.get(), author_2) ```
I think this test can be entirely removed if `test_nested_subquery_outer_ref_with_function` covers the usage case appropriately.
This assertion is not related with the patch. Please remove it.
@felixxm that's a tricky one for sure. We could adjust MySQL's `allows_group_by_pk` feature to be based of `not ONLY_FULL_GROUP_BY` but that would likely incur a large performance hit which is definitely not suitable for a backport. I guess we could always skip the test on MySQL for now.
Maybe you've missed `if summarize` branch (below).
We used the same message as in other places that's why I don't want to add a period only in this case.
Add a period to the end of the exception message.
is it possible to make the try/except block a bit smaller? try/except/else maybe? That will help to show where the error is expected.
You can drop the `.contains_column_references` as it's wasteful in this case because of the way it walks the expression tree given we'll have to walk it anyway below.
Use `try ... finally` and unregister this lookup to keep tests isolated.
Should this override an instance lookup? As far as I'm aware "instance" lookups should always have a precedence as lookups with bigger granularity :thinking: (\cc @charettes).
Can we test this with nested context processors to see that unregistering also works? e.g. ```python with register_lookup( models.CharField, CustomStartsWith, lookup_name="start") ): with register_lookup(Company.place.field, StartsWith4Char, lookup_name="start"): self.assertCountEqual( Company.objects.filter(place__start="f"), [self.obj1, self.obj3], ) self.assertCountEqual( Company.objects.filter(name__start="a"), [self.obj1, self.obj2, self.obj4], ) self.assertCountEqual( Company.objects.filter(place__start="f"), [self.obj1, self.obj3, self.obj4], ) ```
Use `self.assertCountEqual()` when ordering is not specified and we have more than one expected result.
I pushed extra tests to the https://github.com/django/django/pull/16023.
You'll want to branch off greater or equal to Python 3.6 here.
Python < 3.6.
What's the rationale for changing this test class name? It looks like unnecessary noise to me.
> No exception for Python 3.5 but docs say name='_Person__friends' is required. It's required because it won't be cached and no exception is raised because there is no way to detect it.
I feel like this _helper_ is making the assertion harder to reason about. Inlining `getattr(source, attr)` calls would be easier to read IMO.
Rephrase: `# Normalize locale strings input by the user.`
This is just not true - there is no "normalization" happening here. If anything it is an incredibly lax check that the locale folder name starts with two lowercase characters. This makes no guarantees.
I think we are missing the `call_command()` here.
This change is not tested and I'm not sure if it's excepted. I would focus on improving an error message.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
It'd be great we if we could avoid creating 5 new tables to reproduce the issue. Existing ones should be reusable somehow.
I like to include a trailing comma in a list of `kwargs` so if more are added later, you don't need to modify the line again (keeps and diff and git blame cleaner as I mentioned before)
no need for parens
Do we need to change `related_name` here? We could add `note` with `related_name='owner'` instead.
Actually, I think we can skip the router stuff and just use `django.db.connection`. These tests aren't run with custom routers so this'll always be run on the default database. (so we can move the skip condition to `test_long_column_name`).
Yes, maybe: "... time-related format specifiers (found 'a')."
Is it possible to include the invalid specifiers in the message? That would probably make it easier to debug.
`hasattr(field, "is_gfk")` - what's the underlying use case here? We shouldn't be hard-coding a concept like GFK into the API.
We don't refer tickets in tests anymore, please chop `#9762`, also maybe: ``` # Changing the locale doesn't change the "r" format. ```
@charettes thanks for the idea. I made PR #7755 with regression fix.
`out` would be clearer as `stdout`.
Before adding the warning, I would have said that it wasn't really worth adding a whole function for this. It could have been wrapped into the list comprehension below.
Hi, I was looking for a domain validator in Django and I've found this PR. I think a domain name should also be checked against a max length, as `URLValidator` does (https://github.com/django/django/blob/master/django/core/validators.py#L137).
The log message makes no sense. You are trying to normalize (or rather kludge) something that should be a locale to be a language code/tag, to then convert to a locale. But you are saying the locale has been normalized to a language code/tag which is incorrect. A language code/tag is not a locale, and here we *should be providing a locale*, hence my misgivings already stated about this whole thing. Regardless, you probably want to do this: ```python def normalize_locale(original, stdout): """ Normalizes incorrect locale strings, e.g. zh-cn, zh_cn, ZH-CN are converted to zh_CN. """ corrected = to_locale(original.lower().replace('_', '-')) if original != corrected: stdout.write('Normalized %s to %s.' % (original, corrected)) return corrected ```
This will overwrite an explicitly given message if you use ``` python validator = DomainNameValidator(accept_idna=True, message='Only IDNA domain allowed') ```
Dot is missing _"... for Django 2.x."_.
I had some trouble understanding exactly what this meant. Suggestion, "If this pattern is targeted in an include(), ensure the include() pattern has a trailing '/'." There is also "docs/ref/checks.txt" to update with the new message.
Please add `urls.W004` to the `ref/checks.txt`.
I think we should return a list of all warnings, e.g.: ```python def check(self): warnings = self._check_pattern_startswith_slash() if self._route.startswith('^') or self._route.endswith('$'): warnings.append(Warning(...)) return warnings ```
This message should include some helpful information to debug the error. Currently it gives no information as to where the problem is. This is the idea behind the existing `describe_pattern()` function.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
Constructing the entire string within the as_sql method departs from how other functions work. Is it possible to do something like: ``` class BaseCaseExpression(Func): function = None template = 'CASE %(simple)s %(conditions)s ELSE %(default)s END' ``` Then build up the dict required to fill in that template, and construct/return at the end? It may flow nicer, and allow 3rd party backends to modify the template without overriding the entire method.
`SearchedCase` is no longer it's own type so this should be named `Case conditions must be lookups`. Alternatively, do this checking directly inside the `When` types, since users will be using these directly.
Ah! Of course, sorry I missed that.
Please use single quotes.
This could be indented inside the `if conn.vendor` to avoid a redundant check.
I've realized something about this - if, for whatever reason (perhaps custom subclassing??), multiple apps are installed that can introspect these types, if this pattern is copied it's the *last* app in `INSTALLED_APPS` that take precedence, even though the general rule with Django is apps earlier in `INSTALLED_APPS` take precedence. Idk if it's a huge issue though.
Makes sense. I'd say that a test could be useful but since this isn't going to master, I don't mind if it's omitted.
After a quick look I _think_ these can be considered deterministic as well because they don't rely on a connection state directly; they expect `conn_tzname` to be passed as argument.
I see this is copied from the other test, but single quotes should be preferred per the style guide.
```suggestion return 'Create collation {self.name}' ```
I think it's too late for this check, `locale` shouldn't be an optional argument.
```suggestion return f'Remove collation {self.name}' ```
```suggestion raise NotSupportedError('Non-deterministic collations require PostgreSQL 12+.') ``` Also, this exception isn't tested.
We should also remove `self.collation_exists(schema_editor, self.name)` checks.
The URL tests got started off on a bad foot, I think. I prefer the pattern used in `test_security`. For one thing, if this first assertion fails, you have to use print statement debugging to figure out what the result actually was as opposed to the assertion error giving some useful info.
I try to avoid "we", e.g. The check allows a double slash, presuming the user knows....
Can you add an indication character right before and after `{{ output }}`, just to make sure that the output really comes at the right place. I.e.: `'{% endblocktrans %}>{{ output }}<'`
I usually just end the sentence with "(#26249)." instead of "Regression test..."
This test has a problem on Windows: ``` ====================================================================== FAIL: test_override_static_root (test_utils.tests.OverrideSettingsTests) ---------------------------------------------------------------------- Traceback (most recent call last): File "c:\Users\Tim\code\django\tests\test_utils\tests.py", line 872, in test_o verride_static_root self.assertEqual(staticfiles_storage.location, '/tmp/test') AssertionError: u'c:\\tmp\\test' != u'/tmp/test' - c:\tmp\test + /tmp/test ```
non existing -> nonexistent
Why's that? It's non-obvious at first glance.
I made a few edits and squashed commits but before I push those updates I wanted to ask if this test is really needed. None of the changes seem related to verbosity so this test seems unnecessary to me.
Copy / paste? I would have expected the ordering to change for the `duth1` and `duth2` arguments.
You could use single quotes in all strings for consistency (don't worry about existing tests).
The import usually goes at the top of the method.
I'm fine with core.exceptions then. Docs go in docs/ref/exceptions.txt.
I think exceptions in `django.core.exceptions` are mostly things that a user might need to import. I don't think `EmptyResultSet` meets that criteria, at least in my experience I never needed it in a project.
Good point, I didn't think of that module as being user facing. Perhaps django.db.utils would be a better place? It already contains various DatabaseError exceptions, so it wouldn't be totally out of place.
I'm torn whether or not this copy is necessary. When we resolve the expression we do a copy of the subquery anyway. Even if the queryset was cached and evaluated, the resolving will copy a new queryset anyway. ```python qs = Model.objects.whatever() sq = SubQuery(qs) list(qs) # this evaluates the queryset that subquery is holding onto OtherModel.objects.annotate(subq=sq) # queryset is copied here anyway, previous eval doesn't matter ``` Let me know if you can poke holes in my reasoning (it is new years day after all...).
Please don't change all the other unaffected lines.
They can be empty for subclasses, I think we can leave it that way.
I had to change this to `template_params['subquery'], sql_params = self.subquery.query.get_compiler(connection=connection).as_sql()` in order to compile correctly when using a database other than the `DEFAULT_DB_ALIAS`.
The current names are misleading, e.g. `RenderableForm` is not really a render-able form it's a mixin which makes the form render-able. I would rename these classes: - `Renderable` to `RenderableMixin`, - `RenderableForm` to `RenderableFormMixin`, - `RenderableError` to `RenderableErrorMixin`.
I'd use a more specific name and/or docstring that describes what's special about this error handler to trigger the regression since I could imagine future tests may want to use error handlers that have different features. Similar for the `urls.py` and test naming and/or docstring.
if I pass `attrs={'multiple': False)` and init with multiple=True, they are out of sync.
What happens if `multiple=True` but `attrs={'multiple': False}`? If things break, it would better to raise an exception here than to allow it
Was this intentional? Doesn't seem to be related to the task...
A `minimumInputLength` of zero is [the default for Select2](https://github.com/select2/select2/blob/120672dce79b6862cb17a966af06e0617a404b58/src/js/select2/defaults.js#L363).
Use single quotes consistently.
Are you sure this branch is ever skipped? AFAIK `auto_created` models are not part `ProjectState.models` entries.
please check flake8, I believe this is a warning because the line identation isn't distinguished from the next (fix by add 4 more spaces to this line)
Same thing here ```suggestion def add_constraint(self, app_label, model_name, constraint): model_state = self.models[app_label, model_name] model_state.options['constraints'] = [ *model_state.options[option_name], constraint ] self.reload_model(app_label, model_name, delay=True) def remove_constraint(self, app_label, model_name, constraint_name): ``` Maybe you meant to reduce the very similar logic between the to to a common method? ```python def _append_option(self, app_label, model_name, option_name, obj): model_state = self.models[app_label, model_name_lower] model_state.options[option_name] = [ *model_state.options[option_name], obj ] self.reload_model(app_label, model_name_lower, delay=True) def add_index(self, app_label, model_name, index): self._append_option(app_label, model_name, 'indexes', index) def add_constraint(self, app_label, model_name, constraint): self._append_option(app_label, model_name, 'constraints', constraint) ```
I think we can abstract away the need to _lower_ the name here. ```suggestion def alter_model_options(self, app_label, model_name, options, alter_option_keys=[]): ```
```suggestion self.remove_model(app_label, old_name) self.reload_model(app_label, new_name, delay=True) ```
no `u''` prefixes on strings please
this could use the indent style of the previous `CommandError`.
We allow lines up to 119 characters if it helps readability, or we use hanging indent like this: ``` return "<%s: %s>" % ( self.__class__.__name__, ..., ) ```
an app containing a locale folder
I think we are missing the `call_command()` here.
I added the comma to be consistent with the `include` and `condition` attributes. Also, on `ExclusionConstraint` we separate attributes by comma but not on `UniqueConstraint`, so 🤷 indeed..
We should use `__qualname__` in all classes.
I would revert these changes, a string representation of `condition` and `deferrable` doesn't need and extra quotes.
`expressions` should be before the `name` like in other classes.
Please check test coverage carefully. I didn't spot a test for this change.
We need idempotent functions that work reliably between python 2 and python 3. Then if the caller has specific needs, they can take care of their own edge cases. Whatever goes in `utils/encoding.py` should be considered "library" grade, just like werkzeug.
When you do `iri.decode(encoding)` you are getting unicode, so effectively you sometime have unicode, sometime bytes. If the caller needs bytes, it can encode in whatever encoding it desires .
They can only be decoded if these bytes were previously encoded in this encoding.
move this to an else block in (try/except/else)
This -> These
Actually the idea is to do this validation only if `schemes == '__all__'`. If the user provides some other scheme, then we might as well allow it.
I think we should be more explicit here, maybe: ```python if not value or '://' not in str(value): raise ValidationError(self.message, code=self.code) ... ```
I changed to `isinstance(value, str)` because it worked properly for an empty string or strings without a scheme.
I don't think we should go so deep into validation, we opt out from numbers but at the same time we allow the whole unicode range. Unicode numbers like `๑` would happily validate therefore it's an uphill battle. I'd opt for a vastly simplified regex to validate FQDN: `'(?:[a-z0-9\u00a1-\uffff-]+\.?)+'`. Sure it'll let some invalid segments go through (e.g. leading/trailing hyphens) but at least it doesn't pretend of being exhaustive. Proper validation requires a parser anyway.
I think we should include `*args, **kwargs` and pass them to the super `__init__`
chop ticket number
chop "Make sure" in favor of simply stating the expected behavior. The ticket reference isn't really needed -- we reserve that for obscure issues.
a single line is fine here (up to 119 chars is okay if it helps readability)
use single quotes
chop blank lines here and below
This check is redundant. `skipUnless` already guarantees that we have MySQL. You can remove the `try ... except` leaving only `import`.
This check is also redundant.
This check is also redundant.
I don't think it's accurate to query the database at init time, as we are not even sure yet that we will need this info. I'd rather have a cached property, so it will only get fetched when we really need it.
Python2 does not support `super()`.
Start the sentence "Duration's number of days..." Also, add a trailing period.
For translators, it would be better to use named placeholders, so languages which need reordering can do it nicely.
set default `step_size=None` instead of `"any"` and only render that attribute if it's `not None`.
Have a look at the `IntegerField` how it's done there. This has the advantage, that your `StepSizeValidator` can be reused. And it shall be reused, because `step` can also be applied to an `IntegerField`.
No need to define another attribute. The form class should be accessible as `self.TestForm`.
Ditto about being pointless, keep `os.path.exists(...)`.
I wonder if something like `self.PO_FILE_KO.replace('/ko/', '_do_not_pick`)` would make that a bit more resilient to future changes. No strong feeling either way.
You can pass `verbosity=0` instead to completely silence the command instead of creating an unused `StringIO` container.
Ditto ```suggestion return all( not os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
Nitpick but you can avoid a full list materialization by using a generator expression ```suggestion return all( os.path.exists(self.MO_FILE % (dir, lang)) for lang in langs ) ```
I would use `os.path.splitext()`, e.g. ```python def get_available_name(self, name, max_length=None): """ Append numbers to duplicate files rather than underscores, like Trac. """ basename, *ext = os.path.splitext(name) number = 2 while self.exists(name): name = ''.join([basename, '.', str(number)] + ext) number += 1 return name ```
Ah, that makes a lot of sense. Thanks :)
Not the greatest variable name...
You can avoid `thefile` by adding here: ``` work_file = orig_file ```
```suggestion raise NotSupportedError( ```
drop 'this will" / "it will"
Please add a trailing comma.
I think we can simplify this: ```python def json_script(value, element_id=None, json_encoder=None): from django.core.serializers.json import DjangoJSONEncoder json_str = json.dumps(value, cls=json_encoder or DjangoJSONEncoder).translate(_json_script_escapes) ```
```suggestion """Render as <p> elements.""" ```
Is this code based on an existing implementation? If that's the case, we should specify it / link to it.
I think the `_module_exists` and argument name could be improved. What about ```suggestion def _contains_subclass(subclass_path, candidate_paths): ```
site -> register_to
As the code itself hints, there's no reason to assume the imported attribute is a class.
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
> @kezabelle This method is very good, but there are currently many Django-related modules that reference import_string during operation. If you add a cache_import, you must modify and adjust the module code that references import_string to improve performance. You can add a new hook and use it in `import_string()`, e.g. ```python def cached_import(module_name, item_name): modules = sys.modules if module_name not in modules: import_module(module_name) return getattr(sys.modules[module_name], item_name) def import_string(dotted_path): """ Import a dotted module path and return the attribute/class designated by the last name in the path. Raise ImportError if the import failed. """ try: module_path, class_name = dotted_path.rsplit('.', 1) except ValueError as err: raise ImportError("%s doesn't look like a module path" % dotted_path) from err try: return cached_import(module_path, class_name) except AttributeError as err: raise ImportError('Module "%s" does not define a "%s" attribute/class' % ( module_path, class_name) ) from err ```
Michal and I discussed this on IRC and I don't think such a generic function is going to help here. This is a very narrow use case (implicit casting isn't working for certain fields in case expressions), and it needs to be special cased for certain fields. This isn't an Integer->Float kind of situation. I'm happy enough with the method to stay. If we can generalise later then that will be OK, but I don't want this to hold up the merge.
Instead of passing in `db_type` and `internal_type`, I would suggest just passing the field and the connection. That way, the method can extract the pieces of information it needs, which may be different for different backends.
(To make the implication explicit: if not, perhaps this method shouldn't have `case` in its name.)
I definitely do think we should at least try introducing the cast_sql method as described here. The argument types would be Field instances (and the names should likely be changed to input_field and output_field for consitency of Expression.output_field).
There is not need to wrap `CursorWrapper.execute`, we should be able to use `CaptureQueriesContext()`, e.g. ```python def test_has_key_query_columns_quoted(self): with CaptureQueriesContext(connection) as captured_queries: cache.has_key('key') self.assertEqual(len(captured_queries), 1) sql = captured_queries[0]['sql'] # Column names are quoted. self.assertIn(connection.ops.quote_name('expires'), sql) self.assertIn(connection.ops.quote_name('cache_key'), sql) ``` There is also no need to check a table name because it contains spaces, so it's already tested.
Might be better to define this as separate method like this: ``` def window_frame_start(self, start): if isinstance(start, int): if start < 0: return '%d %s' % (abs(start), self.PRECEDING) elif start == 0: return self.CURRENT_ROW elif start is None: return self.UNBOUNDED_PRECEDING raise ValueError('Illegal argument for start, must be either a negative integer, zero or None') ```
This `raise` seems redundant. I would remove these two lines (617-618) and leave only `raise ValueError(...)` at the end of this method.
"start argument must be a negative integer, zero, or None, but got %s."
I think you can remove temporary `msg`, also dot is missing and probably `preceding` should be uppercased and `n` should be lowercased. ```python raise NotSupportedError( 'PostgreSQL does not support RANGE BETWEEN n PRECEDING AND n ' 'FOLLOWING.' ) ```
`abs()` is redundant since `end` is greater than 0.
This test data seems wrong to me. For example, you have verbosity `1` leading to level `DEBUG`, which means that logging at a level of `DEBUG` should result in output per the logic below (since `logging_level >= level` appends `output = True`). That isn't right though, since verbosity `1` shouldn't show `DEBUG`. The test would be a lot easier to understand and update if it was simply a hard-coded, sorted list of tuples, e.g. ```python cases = [ (0, None, False), (0, logging.DEBUG, False), (0, logging.INFO, False), (0, logging.WARNING, False), ... ] ``` Including `level=None` will serve to check the default case. Also, you don't need to check `level=logging.NOTSET` since that's not a level that anyone would ever pass when logging a message. That level is more for when reading what level is set on a configured logger. Having the correct test should help with getting your logic correct in the `log()` method above.
You can just say `expected`. (It's clear from the next line.)
No problem, happy to help. Thanks for keeping at it.
Add a trailing comma so if more items are added later we don't have to modify this line again.
I noticed that all logs and prompts have `ERROR` style when using `--scriptable`, e.g.: ![image](https://user-images.githubusercontent.com/2865885/148344507-ada0d115-4a48-4001-81a2-b62c919c5e45.png) ![image](https://user-images.githubusercontent.com/2865885/148344684-e00db0d8-c25f-45fc-ba54-9dfef13eac7c.png) We could create a copy of `stderr` without the `ERROR` style and use it where appropriate :thinking: ```diff diff --git a/django/core/management/commands/makemigrations.py b/django/core/management/commands/makemigrations.py index cdb200f22e..096702814c 100644 --- a/django/core/management/commands/makemigrations.py +++ b/django/core/management/commands/makemigrations.py @@ -6,7 +6,7 @@ from itertools import takewhile from django.apps import apps from django.conf import settings from django.core.management.base import ( - BaseCommand, CommandError, no_translations, + BaseCommand, CommandError, no_translations, OutputWrapper ) from django.db import DEFAULT_DB_ALIAS, OperationalError, connections, router from django.db.migrations import Migration @@ -62,9 +62,17 @@ class Command(BaseCommand): help='Output only created migration filepaths to stdout; divert logging and prompts to stderr.', ) + def __init__(self, stdout=None, stderr=None, no_color=False, force_color=False): + super().__init__(stdout, stderr, no_color, force_color) + if no_color: + self.stderr_log = self.stderr + else: + # stderr without the ERROR style. + self.stderr_log = OutputWrapper(stderr or sys.stderr) + ```
Using `self.connection.features`: ```suggestion elif ( on_conflict == OnConflict.Update and self.connection.features.supports_update_conflicts_with_target ): ```
Use `self.quote_name()` to do the quoting of fields: ```suggestion return 'ON CONFLICT(%s) DO UPDATE SET %s' % ( ', '.join(map(self.quote_name, unique_fields or ())), ', '.join(f'{field}=excluded.{field}' for field in map(self.quote_name, update_fields or ())), ) ```
You should use `supports_update_conflicts_with_unique_fields`.
```suggestion elif ( on_conflict == OnConflict.Update and not self.connection.features.supports_update_conflicts_with_target ): ```
Chop blank line.
include a space at the end of the string
how about more simply: "with a through model." (add period)
Add a trailing comma.
The 4 lines above look identical to the `remote_model_key` lines a few lines before, except with `through` instead of `remote_field.model`. Maybe that can be a helper method accepting that argument.
We can use `self.real_apps`, there is no need to pass `real_apps`.
Silencing far more exceptions than previously (where it was `ImportError`) ... is this intentional, and will it lead to people having a harder time debugging when their app config goes wrong? I guess it'd be somewhere higher up the chained stack traces, maybe? Same expansion of caught exceptions (`ImportError` -> `Exception`) happens at the `import_string` so I assume the answer to this also answers that.
An aside: I see the reference to `EggLoader`. Haven't Python "eggs" been pretty much obsolete for ages? Can we remove this or the bits that are related to "eggs"? (Something to create a separate ticket for, if so.)
Yeah, the import itself is very likely non-necessary, too.
didn't knew about RegexURLPattern having the same method.. reading the docstring I'm thinking both should do this: ``` python # .. if isinstance(func, functools.partial): while isinstance(func, functools.partial): func = func.func # ... ``` shouldn't it ? again that's my wild guess here, I don't have read more about the context of how this method is used (nor the other one), etc.. So I could be simply wrong.
an app containing a locale folder
Unnecessary `.keys` call ```suggestion return list(unique_items) ```
Why don't you make unique_items a `set` too? This would save you the whole `not in` clause. You just do `Set.add` which will add the item if it's not in the present anyways ;) That being said, since you are adding all items of the list to a set. Just create a set from the list. This will be a lot faster, since the `in` clause performs only at `O(n)`.
You could do solve this recursively, but I don't know if this better readable really. meh
Use `django.utils.datastructures.OrderedSet` to make it clear what you are using this datastructure for.
I would filter that first, via a generator. I think this might be more readable. ```python lists = (lst for lst in lists if lst) ``` or ```python lists = filter(None, lists) ```
I guess the `add_argument` could be `action='store_false', dest='uses_https'`
Yeah, that would certainly be a better idea, rather than using `not` here for negation.
Can you just add the managers and admins including their names, please. I think that I'd expect the names to show up in the message if I define them in my settings.py
```suggestion # Validate app_label. ```
There is no need to resolve replaced/applied migrations so I would pass `None` instead of the default connection: ```suggestion loader = MigrationLoader(None) ```
I would add `('availability', BooleanFieldListFilter)` to the `BookAdminWithTupleBooleanFilter` instead of creating a separate class.
Please use single quotes.
Might be worth renaming this to `self.root_queryset`.
I guess we could try calling the primary key's `to_python` instead of hitting the database here. ```python def get_list_editable_queryset(self, request, prefix): object_pks = self.get_edited_object_pks(request, prefix) queryset = self.get_queryset(request) validate = queryset.model._meta.pk.to_python try: for pk in object_pks: validate(pk) except ValidationError: # Disable optimization return queryset return queryset.filter(pk__in=object_pks) ```
```suggestion self.asserCountEqual(queryset, [self.django_book, self.bio_book, self.djangonaut_book]) ```
Yeah the settings dependent part could be moved into the `__init__` of the middleware I guess.
This just occurred to me, but would it make sense to structure things so the `CSRF_TRUSTED_ORIGINS` processing can be done just once instead of with each request? (There is similar parsing / processing [below](https://github.com/django/django/pull/13829/files#diff-eaa105f5b436e20dd838c27c7a753ef4cf888edcc8f868c084600f6cb7343166R314-R317) in the referer checking.)
👍 Here's a random example if you needed one: ``` >>> urlparse('http://[') ValueError: Invalid IPv6 URL ```
I had suggested doing this before computing `good_origin`: https://github.com/django/django/pull/13829#discussion_r579863426 That way you can avoid the two method calls and string construction in favor of a set membership check.
```suggestion is_same_domain(request_netloc, host) for host in self.allowed_origin_subdomains.get(request_scheme, ()) ```
Is this correct? As far as I'm aware `OR` is not an effective connector with not negated `XOR` :thinking: ``` p XOR q = (p OR q) AND NOT (p AND q) NOT (p XOR q) = NOT ((p OR q) AND NOT (p AND q)) = NOT (p OR q) OR (p AND q) ``` so `OR` is an effective connector for negated `XOR`, maybe: ```python may_need_split = ( (in_negated and self.connector in {AND, XOR}) or (not in_negated and self.connector == OR) ) ``` Also, tests are missing.
We can do the same for `reffed_expression`: ```diff diff --git a/django/db/models/sql/query.py b/django/db/models/sql/query.py index b3d92d786c..21bc0aea7a 100644 --- a/django/db/models/sql/query.py +++ b/django/db/models/sql/query.py @@ -1286,11 +1286,9 @@ class Query(BaseExpression): if check_filterable: self.check_filterable(value) - clause = self.where_class() if reffed_expression: condition = self.build_lookup(lookups, reffed_expression, value) - clause.add(condition, AND) - return clause, [] + return self.where_class([condition], connector=AND), [] opts = self.get_meta() alias = self.get_initial_alias() @@ -1333,7 +1331,7 @@ class Query(BaseExpression): condition = self.build_lookup(lookups, col, value) lookup_type = condition.lookup_name - clause.add(condition, AND) + clause = self.where_class([condition], connector=AND) require_outer = lookup_type == 'isnull' and condition.rhs is True and not current_negated if current_negated and (lookup_type != 'isnull' or condition.rhs is False) and condition.rhs is not None: ```
could move this to the previous line while you're here
I'll edit this docstring to remove the references to the removed parameers, but please check my edits.
I understand what you meant, however this message can be difficult for most of folks. Unfortunately, I don't have a better wording (at least for now).
`grouping[0][0]` is a name of the first column, so these two assertions are unnecessary: ```python self.assertNotIn('name', grouping[0][0]) self.assertNotIn('contact', grouping[0][0]) ```
``` # Unmanaged related model that is not a table. ```
``` # Unmanaged origin model that is a table. ```
Chop blank line.
``` # Unmanaged related model that is a table. ```
Still missing test coverage here, I guess. `get_search_fields() missing 1 required positional argument: 'request'`
Shouldn't that be `self.get_autocomplete_fields(request)`
get_search_fields() not search_fields.
should most likely be `model=self.model`, it does not support `model_admin` -- this also shows that the tests are still lacking!
Use `elif` like in `formfield_for_foreignkey` above
If I understood the above code correctly, then `self.field` is on the source model, whereas `self.model_admin` points to the target admin, I think we should really rename those to avoid confusion.
I assume this isn't going to work with subclasses that override `get_inline_instances()`? Not sure if it's worth it, just mentioning it.
I think we can change `rast_index_wrapper` instead.
Damn it, there is clear way to get this working. Ie there is no reliable way to determine the source_model_admin for a given URL :( I think we might have to relax permissions a bit and provide the autocomplete to any user for every model which has search fields defined and where the user has any permissions on it.
From reading through Django's source code, you can rely that `self.field_remote_field.field_name` is set I think: https://github.com/django/django/blob/a8b3f96f6acfa082f99166e0a1cfb4b0fbc0eace/django/db/models/fields/related.py#L945-L948
This flag is ignored when `ensure_durability` is `False`, so we should inform users that is not allowed, e.g. ```diff (django-test) git:pr/13708 felixx@felixx-A555:~/repo/django/tests> git diff diff --git a/django/db/transaction.py b/django/db/transaction.py index c6ba346a99..8a84b97237 100644 --- a/django/db/transaction.py +++ b/django/db/transaction.py @@ -172,6 +172,11 @@ class Atomic(ContextDecorator): self.using = using self.savepoint = savepoint self.durable = durable + if self.durable and not self.ensure_durability: + raise ValueError( + 'A durable atomic block is not allowed. If you are running ' + 'tests, you must use TransactionTestCase, not TestCase.' + ) def __enter__(self): connection = get_connection(self.using) ``` We can be descriptive here.
From what I understand, the point of being able to turn off durability checking (via `ensure_durability`) is that durable atomic blocks _will_ be able to be run within a `TestCase`. So I think it's correct that it should ignore, rather than error.
```suggestion """ ```
That's actually the last name of a character in the comic these tests are based upon :-)
should lock -> locks
I guess you probably want `from django.test.utils import requires_tz_support` instead.
Bisected to 388bb5bd9aa3cd43825cd8a3632a57d8204f875f. I didn't finish investigating to understand why that's relevant here.
The deliberate error in the reproduction script (`u.is_active = False, # assigning a tuple to a boolean field`) doesn't raise a `ValidationError` until that commit.
Oh. Interesting :-| Bisecting the regression on Django's master branch with your test will show where the regression happened. Depending on what this reveals, a backport could be in order, even if the regression is old.
State the expected behavior in test docstrings and wrap docstrings at 79 chars per [Python style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style): ``` """ ORM queries are allowed after an error and a rollback in non-autocommit mode (#27504). """ ```
It looks like we already used this approach in `SingleRelatedObjectDescriptor` (raise a `ValueError` on unsaved objects) so I guess it's fine to use it here as well. I'm still unsure how this interacts with the `AttributeError` case but I guess it can be revisited later if necessary.
Can we normalize the error message with https://github.com/django/django/blob/master/django/db/models/fields/related.py#L460-L463.
Is this branch tested? No tests seem to fail (I tired SQLite & PG) if it's removed.
We should make use of `self.message`.
I don't think that we need this check. I would rather remove from docs [note](https://github.com/django/django/blob/77d335e5abec889b15323975187a8d5b10bfcb0f/docs/topics/db/queries.txt#L965-L979) about setting `id` to `None`. That is outdated after this patch. \cc @spookylukey
should this be super()
This can be single-lined.
As an example. The method signature should be ```python def rename_model(self, app_label, old_model_name, new_model_name): ... ``` And be called from `RenameModel.state_forwards` as `state.rename_model(app_label, self.old_name_lower, self.new_name_lower)` instead of passing the `Operation` instance along.
Do we need to check `removal_value`? It should be enough to check that `new_value` is not en empty set, I cannot imagine a different scenario :thinking: ```suggestion if new_value: ```
This docstring is unnecessary.
```suggestion self.assertIsNone(table_description[1].collation) ```
`get_table_collation()` is missing for Oracle, I added it to the main query.
This collation doesn't work for me: ``` django.db.utils.ProgrammingError: collation "en_US" for encoding "UTF8" does not exist ``` I've changed to the `en-x-icu`.
IMO we don't need to test the default behavior.
We should add database features for these, e.g. `supports_collation_on_charfield` and `supports_collation_on_textfield`; and use `skipUnlessDBFeature`.
, -> and
At first sight it could be simplified to: ``` [option not in [None, False] for option in mutually_exclusive_options].count(True) ``` But I have a feeling even more simplification might be possible. Note that we can't simply cast default to bool, which would make this even simpler, as some valid dates evaluate to false: https://mail.python.org/pipermail/python-ideas/2014-March/026446.html
I think that such iterables like `[None, False]` should be tuples like `(None, False)`, because it's less memory consuming and faster a bit. Anyway, it is not very important, because of small container size.
"a DeprecationWarning" -> "an Error"
I would revert this change, the previous version is clearer to me.
I'm leaning toward reintroducing `Node._new_instance()`, although probably call it `.create()` and make sure it is used everywhere which it hasn't been up to new. The reason for this is that sometimes using `.copy()` has unnecessary overhead of copying `__dict__` when we don't need to.
In this case you may as well do `obj = self.__class__()` as you're not passing anything in. `Node._new_instance()` only exists to help smooth out the incompatibilities between `Q.__init__()` and `Node.__init__()` when needing to reconstruct objects internally. In fact, it would be nice to eliminate it if possible.
I know this was copied from below but there's no point in not using `get()` directly. ``` python qs = self.get_queryset(instance=instance) # Assuming the database enforces foreign keys, this won't fail. return qs.get(self.field.get_reverse_related_filter(instance)) ```
_Gut feeling_ says that this ought to be a _clone_, so as not to leak the _original_ (un-negated) mutable expression out. e.g something like: ``` return self.expression.copy() ``` Currently you've got a test for `self.assertEqual(~~c, c)` which I would _guess_ (reading the diff only) would also pass with `assertIs` where I presume it oughtn't.
Are you passing args as kwargs like this and throughout the patch because of readability? I'm not sure it helps -- it seems natural that a `set()` method would take `(key, value)`.
If we went with `get_model_class()` above, this could simply be `model`.
Please include periods in docstrings.
Could you explain why the limit is 8? (or mention it's somewhat arbitrary)
one longer line is preferred (or at least avoid non-multiple of four indentation).
I think it would be clearer if you removed the "else" and deindented the rest of the method.
We don't need to call `len()`, `slice()` will work the same with `None`.
I think that you could move the slicing inside `DebugLexer._tag_re_split()` and then `DebugLexer.tokenize()` will be even closer to `Lexer.tokenize()`: ```suggestion for bit, position in self._tag_re_split(): ``` Maybe with these changes it makes sense to rename `DebugLexer._tag_re_split()` to something like `.split()` and add the same method to `Lexer` with something like: ```python def split(): yield from ((bit, None) for bit in tag_re.split(self.template_string)) ``` Then you should be able to ditch `DebugLexer.tokenize()` entirely and inherit it.
Passing the last argument as a keyword argument (`in_tag=False`) would make the code easier to follow. This is almost always better for boolean arguments, except when they're the only argument of the function.
It's hard to assess the correctness of this change through visual inspection. I'll trust you (and the test suite) on this.
Yup. It's completely irrelevant to the module it's in with this change.
What values would this condition have a different outcome than the current one? `is_active or self.allow_inactive_users or is_active is None`
Could omit the `email_field_name` variable and inline `UserModel.get_email_field_name()` instead.
At some point, I wondered if it would be easier to just let users do `.exclude(is_superuser=True)` when they need to.
I'd make this a separate test and then you can decorator the test method instead of using `with ....`.
Not sure it makes a difference but before it looks like we got `form=None` in the context.
I wonder if we could support running `runtests.py` from different directories :thinking: like we do for dotted module names, e.g. ```bash ~/repo/django> ./tests/runtests.py backends.postgresql ``` works fine, but ```bash ~/repo/django> ./tests/runtests.py backends/postgresql/ .... File "./tests/runtests.py", line 155, in get_label_module rel_path = path.relative_to(RUNTESTS_DIR) File "/usr/lib/python3.8/pathlib.py", line 904, in relative_to raise ValueError("{!r} does not start with {!r}" ValueError: '/repo/django/backends/postgresql' does not start with '/repo/django/tests' ``` crashes. I tried to fix this with: ```python # Otherwise, interpret the label as a path. if not path.is_absolute(): return path.parts[0] else: path = path.absolute() rel_path = path.relative_to(RUNTESTS_DIR) return rel_path.parts[0] ``` but it crashes with `ModuleNotFoundError` (like without this patch): ``` ====================================================================== ERROR: backends/postgresql (unittest.loader._FailedTest) ---------------------------------------------------------------------- ImportError: Failed to import test module: backends/postgresql Traceback (most recent call last): File "/usr/lib/python3.8/unittest/loader.py", line 154, in loadTestsFromName module = __import__(module_name) ModuleNotFoundError: No module named 'backends/postgresql' ```
Yeah it works for me, sorry again. The current version looks good :+1: , we could only raise a more descriptive error when a relative path is not correct (as proposed in https://github.com/django/django/pull/14507#discussion_r648186310).
"... doesn't look like a path to a module attribute", "... doesn't look like a path to an object". It isn't supposed to be a module.
As the code itself hints, there's no reason to assume the imported attribute is a class.
Yeah, the import itself is very likely non-necessary, too.
We don't need this skip.
It should give 'Modification de Title et Historique.'. I guess a gettext call is missing inside the `LogEntry.get_change_message`.
inner import for new model not required
This needs an update following 831358f23d545b8dba017c6b26bd295ba9f6c17d.
`add_index()` accepts `concurrently`, moreover `self.allow_migrate_model()` check is missing, IMO we should use ```python if self.allow_migrate_model(schema_editor.connection.alias, model): schema_editor.add_index(model, self.index, concurrently=True) ```
extra space after [
Is there a specific reason to `insert(0...` instead of `append`? `basedirs` is transformed to a set just below, so I think ordering really doesn't matter here.
an app containing a locale folder
Use hanging indent as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
``` py self.assertEqual(gettext('Lenin'), smart_text('Ленин')) self.assertEqual(gettext('Vodka'), smart_text('Vodka')) ```
Given `self.inner_votes` is an instance of `collections.Counter` this could be simplified to `self.inner_votes.update(inner_votes)`.
"Considre case" > "Consider the case".
At a guess, this comes from this code: https://github.com/django/django/commit/e9103402c0fa873aea58a6a11dba510cd308cb84#diff-11 which was present before the converters refactor. This needs to use the same flow to get the converters as the normal queries do.
The expression should decide the output type. If the database generates something different, then Django needs to either convert the database value, or preferrably use different SQL for the backend to produce directly the correct value. What we need here is some machinery that decides what is the correct output type for field types A and B for given connector. The problem here is 3rd party fields. For example, how do we correctly guess the type of IntegerField / CustomCompositeField? In addition we need ability to produce different SQL per field type, per backend: TextField() + TextField() should produce || connected SQL. Finally we need the ability to ask the backend for a converter for the expression. These are non-trivial problems. I think we have to solve the situation in some simple way, and deal with the above mentioned problems later on.
This method seems suspicious. It special-cases float, integer and decimal fields, but does nothing at all for other types of fields.
We should support both `db` and `database`, e.g. ```python database = settings_dict['OPTIONS'].get( 'database', settings_dict['OPTIONS'].get('db', settings_dict['NAME']), ) ```
I think we should copy `fields_cache`: ```suggestion state['_state'].fields_cache = state['_state'].fields_cache.copy() ``` because a copy of model instance can use the same values and we don't need to fetch it again.
Thanks, the current approach LGTM. Please uncheck "Patch needs improvement" flag on the ticket after local testing.
with -> the
Is this branching necessary? I can see how using `model.objects.none()` as a query holder could be problematic since it's not necessarily the same `QuerySet` class as the one from which `query` was extracted. Does the following work: ``` python def __getstate__(self): state = self.__dict__.copy() if isinstance(self.rhs, QuerySet): state['rhs'] = self.rhs.query return state ```
This line can be removed :thinking:.
IMO this line is unnecessary, and above `iter()` call can be removed.
`seprate` -> `Separate`, also trailing dot is missing.
It seems that we have two issues here, i.e. you can use fields from the same model multiple times, e.g. `parent__field1__field2__pk__field1`, and you cannot use `pk`. I think we should clean `_cls` if a field is not relation, e.g. ```python if part == 'pk': fld = _cls._meta.pk else: fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` I would split this into two fixes, first for using multiple times fields from the same model (with test): ``` fld = _cls._meta.get_field(part) if fld.is_relation: _cls = fld.get_path_info()[-1].to_opts.model else: _cls = None ``` and second to handle `pk` (with test).
add trailing comma
Using `clashing_pair` in a hint is misleading. We should use appropriate model names not field names or table names.
Chop blank line.
Can you please choose a new error code that is otherwise unused.
Add a trailing comma.
I would use `%s` formatting consistently.
I think the `hasattr` is unnecessary as the check is after `super().__init__()`. A child class of `BaseForm` will always have a `fields` instance variable, right? Removing the `hasattr` does not cause any tests to fail.
`self.fields[self._meta.model.USERNAME_FIELD]`? I think it's a mandatory field.
Use `self.username_field` instead.
Django should automatically validate `max_length` without a custom method: ``` from django import forms class MyForm(forms.Form): f = forms.CharField(max_length=1) >>> form = MyForm({'f': '12'}) >>> form.errors {'f': ['Ensure this value has at most 1 character (it has 2).']} ```
Please don't make unrelated whitespace changes.
Use single quotes consistently (could be done above and below also).
This pattern has a small issue where it never guarantees the assertion actually runs. It could be refactored so that the assertion is outside the loop, after the desired constraint is assigned to some variable.
I'm always wary of putting assertions inside loops and if-statements because you're never certain they are executed. If you added a counter and an assertion that `count==1` after the loop, that would be defensive.
Chop the ticket number `(#25253)`.
We should move `Foo.objects.create()` outside the context manager, i.e. ```python with connection.schema_editor() as editor: editor.alter_field(Foo, old_field, new_field, strict=True) Foo.objects.create() ```
I would chop `Do not crash in this case. `.
IMO ticket reference is not necessary.
We can add color to make it more visible :male_detective: , e.g. ```diff diff --git a/django/contrib/auth/migrations/0011_update_proxy_permissions.py b/django/contrib/auth/migrations/0011_update_proxy_permissions.py index 79a3782bde..985e462118 100644 --- a/django/contrib/auth/migrations/0011_update_proxy_permissions.py +++ b/django/contrib/auth/migrations/0011_update_proxy_permissions.py @@ -1,5 +1,6 @@ import sys +from django.core.management.color import color_style from django.db import migrations, transaction from django.db.models import Q from django.db.utils import IntegrityError @@ -18,6 +19,7 @@ def update_proxy_model_permissions(apps, schema_editor, reverse=False): Update the content_type of proxy model permissions to use the ContentType of the proxy model. """ + style = color_style() Permission = apps.get_model('auth', 'Permission') ContentType = apps.get_model('contenttypes', 'ContentType') for Model in apps.get_models(): @@ -44,7 +46,7 @@ def update_proxy_model_permissions(apps, schema_editor, reverse=False): except IntegrityError: old = '{}_{}'.format(old_content_type.app_label, old_content_type.model) new = '{}_{}'.format(new_content_type.app_label, new_content_type.model) - sys.stdout.write(WARNING.format(old=old, new=new, query=permissions_query)) + sys.stdout.write(style.WARNING(WARNING.format(old=old, new=new, query=permissions_query))) def revert_proxy_model_permissions(apps, schema_editor): ```
First we should verify this passes before we toggle `is_active` to False.
Please add a trailing comma.
``` 'BinaryField default cannot be a string, use bytes content ' 'instead.' ```
I don't see much value in using `self.subTest()` here.
I would omit the parenthesis in these messages (I know it's done elsewhere, but "I am at war" with that style unless you like it).
The `Foo` model as no `foos` field. As `Foo` is not `auto_created` it should have a similar message to `test_m2m_table_name_clash`.
Might be worth testing for the actual type.
Chop blank line.
`force_begin_transaction_with_broken_autocommit` is a really long name, but its purposes still isn't obvious to me. Could you add some info to the docstring about its purpose? If the name could be simplified/shortened, I think that would be beneficial as well.
`in_atomic_block` here is redundant: ```suggestion if ( self.durable and connection.atomic_blocks and not connection.atomic_blocks[-1]._from_testcase ): ```
```suggestion """ ```
Bisected to 388bb5bd9aa3cd43825cd8a3632a57d8204f875f. I didn't finish investigating to understand why that's relevant here.
Chop blank line.
```suggestion elif ( on_conflict == OnConflict.Update and not self.connection.features.supports_update_conflicts_with_target ): ```
You can do what I suggested above here as well.
You should use `supports_update_conflicts_with_unique_fields`.
Using `self.connection.features`: ```suggestion elif ( on_conflict == OnConflict.Update and self.connection.features.supports_update_conflicts_with_target ): ```
Please put the test in `AdminActionsTest`.
I have a feeling something else if off here. The outer query's joining strategy should not have to special case inner queries as they are self contained expressions. My guess is that something is getting mixed up wrt to aliases because the same model is being involved in the outer and inner queries.
No sure about which parts should remain in `Q.checks` instead. Current separation seems relatively good but I'd be curious about input from others.
```suggestion Question.objects.create(question='Not a question.') ```
Need to test that result is as expected, not only calling it.
Ahhh, yes, thanks!
Maybe: ```python for name, value in self.scope.get('headers', []): corrected_name = name.decode('latin1').upper().replace('-', '_') if corrected_name not in ('CONTENT_LENGTH', 'CONTENT_TYPE') corrected_name = 'HTTP_%s' corrected_name ```
FYI: we have also [`HttpHeaders`](https://github.com/django/django/blob/fc2536fe66c519b306f673672b795d16f87ed57d/django/http/request.py#L359-L374) class that have reserve logic, I'm not sure if we can reuse it somehow :thinking:
I wouldn't have thought so as `request.GET` is immutable in the WSGI implementation? At least I recall having to `.copy()` it first...
Should this be mutable? (`mutable=True`). `QueryDicts` handles `None` so `self.scope.get('query_string')` should work.
Nit-pick: I think Django generally favors the syntax with parens instead of the `\` continuation char.
`0` is unnecessary: ```suggestion return (10, 2) else: return (5, 7) ```
This test fails: `(1235, "This version of MySQL doesn't yet support 'FORMAT=JSON with EXPLAIN ANALYZE'")`.
For MySQL >= 8.0.13, `default` was not fully supported as other backends, for example: Alter a field with default value: ✅ `ALTER TABLE foo MODIFY COLUMN bar LONGTEXT DEFAULT("");` ❌ `ALTER TABLE foo ALTER COLUMN bar SET DEFAULT ('');` So unless we could tell what kind of action of this SQL is taken, otherwise we should always return `False` for safe.
This hook is unnecessary you can reuse `has_native_uuid_field`, e.g. ```python class DatabaseFeatures(BaseDatabaseFeatures): ... @cached_property def has_native_uuid_field(self): return self.connection.mysql_is_mariadb and self.connection.mysql_version >= (10, 7) ``` ```python class DatabaseWrapper(BaseDatabaseWrapper): ... @cached_property def data_types(self): return { ..., "UUIDField": "uuid" if self.features.has_native_uuid_field else "char(32)", } ```
You can have a look at 9bf652dfd6a738fd841471f6abd71cba1b206d9f as an example of how we introduced object level permission to authentication backends.
The parameter to this method seems odd to me. As it stands, no caller is explicitly using the parameter in a call to the method and I can't see many legitimate uses for it in derived classes. I think you're effectively just using the default value as a space to store a class-scope variable. Would it be simpler to just assign a member on the class? Or on the instance, if you prefer.
Having an overridable method seems like the most orthodox OOP solution (it's what a Java programmer would do :-) ) but I'm not convinced it really gives a useful abstraction: by coincidence it's the right place to make this one change, but I'm not sure there's a useful class of future modifications it opens up, so it feels like overkill to me. My thought with an instance variable was just to set it in the constructor in the base class, and overwrite it in the subclass constructor (not exposing it as a kwarg). I'm not sure there's any advantage to this; I think I was thinking about this because it's what I'd do in C++. I don't have a particularly strong feeling on this. I think if I were writing it I'd go with the class-level attribute.
OPTIONAL I would be inclined to put this directly below `validate_key()` (above) so that when you have the file open the two related methods are next to each other. (TBH, I'd put both of them directly below `make_key()` for the same reason but, if we don't want to move `validate_key()`, I'd at least put the new method in that place.)
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
Well, mariadb support in the mysql backend. Will get on to that soonish.
How did you choose the defaults? I think it would be simplest to default to True and have backends opt-out as needed (that eliminates the risk that a backend fails to opt-in) but feel free to explain your thinking.
I think this can be single lined: ```python # Does the backed support window expressions (aggregate OVER (expression))? ```
I'm curious if the slashes are needed. Both on MySQL and Oracle, the tests seem to pass without them.
We should add release notes for these feature flags.
use `reverse()` rather than a hard coded URL.
I'm unsure the purpose of `ugettext_lazy` here.
Don't hardcode a primary key (or `Model.__str__()`). Wrap strings at 79 characters.
And I would rename this attribute `superusers` as it's meant to contain multiple users.
You'll want to store the original routers and restore them in `tearDownClass` to preserve test isolation.
We can reuse `self.user`: ```suggestion request.user = self.user ```
Chop blank line.
```suggestion Question.objects.create(question='Not a question.') ```
These two permissions are never used. Please remove them. `cls.permissionuser` is only used in `test_simple_inline_permissions`. Create it inline there rather than on the class.
why an empty string? might as well use assertRaises at that point.
Maybe `Ntile`, but I can't figure out what it stands for...
`COT` doesn't exist on Oracle, please emulate it by `1 / TAN(%s)`.
You're right :+1:. I missed that.
`PI` doesn't exist on Oracle. It is a constant, therefore we can use `math.pi`.
IMO it works exactly the same way in [Oracle](https://docs.oracle.com/database/121/SQLRF/functions169.htm#SQLRF00698) and [MySQL](https://dev.mysql.com/doc/refman/5.7/en/mathematical-functions.html#function_round) database, am I missing sth? 🤔
this should probably stay, as we don't want `max_length` to suddenly show up somewhere in between states.
With this change, can the entire `clean()` method be removed from `EmailField` and `URLField`? The parent implementation already [calls `to_python()`](https://github.com/django/django/blob/415ae960bb9f1bdae798023fdce3247d2c938eec/django/forms/fields.py#L158).
At first sight it could be simplified to: ``` [option not in [None, False] for option in mutually_exclusive_options].count(True) ``` But I have a feeling even more simplification might be possible. Note that we can't simply cast default to bool, which would make this even simpler, as some valid dates evaluate to false: https://mail.python.org/pipermail/python-ideas/2014-March/026446.html
, -> and
Can we wrap this line after the comma.
I would keep `if not ...` in the same line.
I wouldn't move `if not ...` to the separate line, i.e. ```python Error(E002.msg.format(tag), id=E002.id) for tag, _ in settings.LANGUAGES if not language_code_re.match(tag) ````
I think we can add `settings.LANGUAGE_CODE` directly into `E001` (like in `core/checks/caches.py`) and leave this method unchanged.
Wrap strings at 79: ``` 'You have provided values in the LANGUAGES_BIDI setting that are not in ' 'the LANGUAGES setting.', ```
We thought that for some unexpected non-string data types if may be better to return their representation. I think it is not necessary.
Per new code guidelines, can we use `assertIs`? :)
Use `True` instead of `'True'` as value will be implicitly cast to `str`.
chop blank line
@timgraham is ordering by the result of an aggregate allowed without subqueries? If ordering by count does not error, then it should be safe to use that ordering. If not, introducing a different field into the orderby will affect the grouping (not that you suggested that), so we'll need to look at comparing the queryset out of order if there's another assert method available that does that. I'm not able to check either of these things at the moment, but I can take a look in about 8 hours if it's not resolved.
Should we also have a pointer here of the form ```suggestion with self.assertRaisesMessage(FieldError, "Cannot distinct on 'other_rating' alias. Use annotate to promote it"): ```
Well I did not check the encoding declaration (well.. I apparently checked another file) and I just told him to use the `chr()` syntax so that is pretty much my fault :-(
There are various reasons for doing this for example to mitigate design faults like circular dependencies or to postpone the construction triggers that could happen at compile time (i.e. when a class type is built) or even to keep the module namespace clear. Not sure without an example.
Please move imports to the top of the file.
That docstring doesn't add much info. It isn't useful to paraphrase a function's signature!
I don't think we need the blank line here.
```suggestion if VARIABLE_ATTRIBUTE_SEPARATOR + '_' in var or first_char == '_': ```
The added blank lines aren't needed.
variable could be omitted
Might want to pass an explicit empty string here or make `UndefinedVariable.string_rep` default to it and don't pass any arg along.
I think a simple `django.template.Context` will do here.
For the keys, I was thinking we should use the full field name (e.g. 'BigAutoField') rather than some other value like 'big_auto'. I think it would be less mental effort for the developer to have to convert camel case to underscore and remove "field". Let's alphabetize the keys too.
I was just about to suggest this too :+1:
I don't like this suggestion. What do you see as the advantage? Here's why I'm concerned: - It's more verbose - typos in the key name are silently ignored - by implementing a mapping in the base features, it shows which fields are implemented in Django's tests (I don't think we should try to implement all fields proactively but accept PRs if a third party backends needs it)
I would leave it empty (`introspected_field_types = {}`) by default and use `.get()` in tests, e.g. ```python connection.features.introspected_field_types.get('BooleanField') or 'BooleanField'` ```
IPAddressField is removed from Django so shouldn't be listed.
GZipMiddleware doesn't modify a weak ETag.
I think the blank lines could be chopped in this test.
To make this a better test, use multiple values and varying case. E.g. `'No-Cache, No-Store, Max-age=0'`.
As above, since `process_request()` returns a response, the second test isn't needed (see 434d309ef6dbecbfd2b322d3a1da78aa5cb05fa8).
A docstring describing the purpose of this test may be useful.
Ah I see, okay then.
```suggestion RuntimeWarning, ```
I think we should have a test and handling for the case where `mimetypes.guess_type()` returns `None` as done in `_create_attachment()`.
Use a single line. Our [style guide](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style) allows lines up to 119 characters if it helps readability.
This will need to be tested.
So we should probably use the enum here. Something like: ```suggestion self.assertEqual(FirstNames.JOHN.value, f.clean(FirstNames.JOHN)) ```
+1, this test was also removed in my force_text audit WIP branch.
`# Values provided in the form's data are ignored.` Might be good to have a test for `Form(data, initial=...)` too.
Despite the existing style of the first test, I would remove the intermediate `f` variable in the new tests as it'll help balance line lengths and make things more readable.
please multiline the string ``` '<select id="id_f" name="f" disabled><option value="J">John</option>' '<option value="P">Paul</option></select>') ```
Was going to suggest the same, but see that @charettes got there first. > Yes, but IMHO it's worse for readability. Fair enough.
We should add `charset` to `OPTIONS`: ```suggestion 'OPTIONS': { 'charset': 'utf8', }, ```
Instead of this file dance, it would be easier to use a `tempfile.NamedTemporaryFile`. It is also safer wrt parallel test runs.
Can you include latin-1, non-ASCII characters? `café` is one of the few English words matching this requirement. `Just latin-1 :)` will encode identically in ASCII, latin-1 and utf-8, making the tests much less interesting.
This isn't Django's default charset (unless I'm mistaken).
I think that `BaseForm.get_context()` describes this perfectly well: ```suggestion ``` But if we must keep it, it should be collapsed onto one line: ```suggestion """Returns context for form rendering.""" ```
```suggestion """Render as <p> elements.""" ```
I know this is the sort of layout that `black` would generate, but it's one of the more ugly choices it doesn't get right in my opinion. Perhaps we should `+=` instead of `.extend()`: ```suggestion top_errors += [ _('(Hidden field %(name)s) %(error)s') % {'name': name, 'error': str(e)} for e in bf_errors ] ```
```suggestion """Render as <li> elements excluding the surrounding <ul> tag.""" ```
Yes, that sounds good to me.
You can safely join this an the next line. You have up to 119 chars per line. ;)
Use single lines for all these asserts -- we allow up to 119 characters when it improves readability.
It might be nice to reorder this above _post_process so that lots of code doesn't appear as changed when it was only moved. It would certainly ease review.
This will consume the `streaming_content` generator on Python 2. Use `django.utils.six.moves.map` instead.
You can safely join this an the next line. You have up to 119 chars per line. ;)
You can use `assertSequenceEqual()` here ```python self.assertSequenceEqual( values, [{'discount_price': Decimal('59.38'), 'sum_discount': Decimal('59.38')}], ) ```
I think most assertEqual don't include a comma on this line.
I didn't dig much into this ticket, but is it still possible to have a value type not in the list handled in `_resolve_output_field`? If yes, could we keep a test for such a value (maybe in expressions tests).
Please break this down into a couple of lines to make it easier to read. Also, the `distinct` call should be unnecessary for this bug, and only introduces extra work that distracts from the main problem.
A style that didn't require so many lines and use non-4-space indent would be more consistent with the rest of the code. Something like: ``` vals = list(Book.objects.annotate(xprice=F('price')).filter(xprice__lte=30) .values('publisher', 'contact').annotate(count=Count('pk')).values('publisher', 'count') .order_by('publisher')) ```
It has to be switched back to `DEFERRED` afterwards ```suggestion sql_column_inline_fk_immediate = 'SET CONSTRAINTS %(name)s IMMEDIATE;SET CONSTRAINTS %(name)s DEFERRED' ```
Something along these lines would break on tables that haven't been rebuilt and still have `IMMEDIATE` foreign key constraints: ```python with transaction.atomic(): # The following line will immediately fail now that foreign key # constraints are enforced and were created as IMMEDIATE # instead of INITIALLY DEFERRED. Book.objects.create(author_id=1) Author.objects.create(id=1) ``` We might want to mention that constraints used to be built as `DEFERRABLE IMMEDIATE` in the _Foreign keys are now created with ``DEFERRABLE INITIALLY DEFERRED``_ section and might require a rebuild to allow the above pattern to be used.
I wonder how this will play with existing SQLite tables that don't have `DEFERRABLE INITIALLY DEFERRED` constraints. At this point I think the best course of action would be to mention it in the release notes.
Remove unnecessary new line ```suggestion sql_alter_column_no_default_null = sql_alter_column_no_default ```
We should add parentheses only on MySQL > 8.0.13 and only for `_limited_data_types`. I don't think that a new class variable/property is a good solution. I would rather add a method ```python def _column_default(self, field): return '%s' ``` that can be override in a MySQL backend, e.g. ```python def _column_default(self, field): if ( not self.connection.mysql_is_mariadb and self._supports_limited_data_type_defaults and self._is_limited_data_type(field) ): return '(%s)' return super()._column_default(field) ``` This can easily be reused in `_alter_column_default_sql()`.
`self.tables += (alias,)`
Ditto with `existing_tables`.
Unnecessary list comprehension, `tuple(self.model._meta.pk.get_col(inner_query.get_initial_alias()))` should do.
Use a set since it's only used for containment checks.
`in self.query.alias_map` should be faster.
``` """ QuerySet.count() on a many-to-many relation doesn't include an unnecessary JOIN. """ ``` Ticket references should be reserved for obscure issues (not needed here, I think).
Might want to only test for `JOIN` presence as this wouldn't fail if `LEFT JOIN` was used.
Move the exists assertions to another test.
The fact only a single result is returned is a strong enough assertion here. Some database backend could translate `__isnull` to some different SQL.
Oh I realize that asserting against the results is problematic given all the engines we're testing against support foreign keys. In this case yes, using the same `JOIN` check against `captured_query` should do!
It would probably be better to check `cl.queryset.query.distinct`
I don't think "base on test..." is important. Corrected grammar would be "based on test..."
You have the same docstring for 4 tests but they are obviously meant to test different things, so clarifying that would be helpful.
This test belongs with the tests for the delete action in `tests/admin_views/test_actions.py`.
I don't think this test is needed. The default implementation is already tested as well as overriding the method.
Yes, this should be taken care of before.
You're calling `model_name.lower()` twice in most cases
Since this model key is the main model key used in this method, how about defining `model_key` in the first line of the method? Then below you can choose a different name for the model key accessed in each loop of the for loop since it's used less frequently. That would also let you change the (current) first line of the method to `del self.models[model_key]`. You could also do `unregister_model(*model_key)` towards the bottom if you wanted, like you do for `reload_model()` above.
I don't think you need `list()` here.
You should be able to use direct attribute access here: `remote_field.through`
As above, wrap the format in quotes. "Your URL pattern '{}' has .."
I think the formatted pattern should be wrapped in quotes. "Your URL pattern '{}' uses..".
For future reference, we are using PEP 257 style verbs for new docstrings "Format...", etc.. Also, it's nice to be consistent with trailing punctuation.
How about omitting it until we have a use case? That will save writing tests and docs for a theoretical feature. :-) From a readability point of view, writing a `re_path()` that mixes regexes and converters in the string, and then has to initialize and pass converters in the URLconf sounds nasty and not something to encourage!
I'm going to be a +1 to just dropping `converters`
If you do the unrelated alignments, please push them in a separate PR.
We tend to favor the dict formatting as: ``` some_dict = { 'key1': 'value', } ```
This seems unnecessary.
Yes we should test a real use case instead of emulating this path.
I think this test would make a little more sense if we used a `CharField` for the primary key of `Foo`. It's not super important though.
James concern about the extra level of indentation caused by `with timezone.override()` + `try / finally: self.storage.delete(f_name)` could be solved by removing the file with `self.addCleanup(self.storage.delete, f_name)` instead.
I tried that approach while making my original edits but the test relies on the file being removed within the test (since it runs this method several times per test) instead of at `tearDown()`.
Use hanging indentation as described in [Python coding style](https://docs.djangoproject.com/en/dev/internals/contributing/writing-code/coding-style/#python-style).
This will need to be tested.
I'd combine w/previous line for better readability
