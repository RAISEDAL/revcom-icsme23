also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
this is much better!! ð
Not important, but couldn't this just be an array? String[] possiblePathValues = {"some_path", "anotherPath", null};
can we have braces around that ie: ``` if (newQ == subQuery) { return this; } ```
yes, make sense
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
ok, fair enough. ++ for setting up compatibility with GeoPointv2
You are right, I was confused because of what I saw in ScriptImpl for painless (naming implying it was in variables for the script, but that is actually the params). I still think this needs to be its own context. We can eventually move these to direct arguments of the execute method (again, so params can be read-only in the future).
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
Whoa this is even stranger to read since it spans 3 lines
nit: missing space
nit: please use lowercase start for variable names
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
Since we're moving that, we could inline this using turnary.
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
This method takes a phrase query and is supposed to create an equivalent phrase query that just has a different value of the slop, so we need to transfer the boost? Maybe the method should look like this now: ``` java private Query applySlop(Query q, int slop) { float boost = 1f; Query underlyingQuery = q; while (underlyingQuery instanceof BoostQuery) { BoostQuery bq = (BoostQuery) underlyingQuery; boost *= bq.getBoost(); underlyingQuery = bq.getQuery(); } if (underlyingQuery instanceof PhraseQuery) { PhraseQuery pq = (PhraseQuery) underlyingQuery; PhraseQuery.Builder builder = new PhraseQuery.Builder(); builder.setSlop(slop); final Term[] terms = pq.getTerms(); final int[] positions = pq.getPositions(); for (int i = 0; i < terms.length; ++i) { builder.add(terms[i], positions[i]); } pq = builder.build(); pq.setBoost(boost); return pq; } else if (underlyingQuery instanceof MultiPhraseQuery) { ((MultiPhraseQuery) underlyingQuery).setSlop(slop); return q; } else { return q; } } ```
maybe call this `getMetaDataOrDefault()`
the important part is having multiple open readers on this as well.
good point! I think we need to iterate over the filterFunctionBuilders and rewrite their corresponding filters
please give us messages for the assertions
having another look, index time lookup is needed when creating the search lookup, and I actually made another suggestion around possibly not needing IndexTimeScript entirely, so I don't think we will be able to do without adding indexTimeLooup.
fair enough, leave it.
nit: finishes running on the node
I don't think we need to change this here.
Actually I just checked and removing name and description from the Plugin interface should be easy. The only thing to think about is what to give for those properties when plugins are loaded from the classpath (plugin.types). I think here the name should just be the classname, and description something like "plugin loaded from classpath"? I don't know what other info we really have.
I think we should just use Set? The ExtentionPoint class was added at a time we thought that would be the new plugin model. But I don't think we should use it anymore.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
do we need this Reader interface? can't this just be `Funciton<StreamInput, T> reader`
Simon would say replace with `== false` ;)
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
otherwise, if you want it for testing, it can be done once in the ctor
I actually wonder if we should have a `MaybeBoolean` class that implements `ToXContent` and can do these kind of merge operations ie similar of haskel maybe
I don't see NO_MORE_DOCS changing in the future. I don't dislike having NO_MORE_DOCS=MAX_VALUE, it makes the sequences of integers returned by DocIdSetIterator monotonic from -1 (not started) to MAX_VALUE (exhausted) :)
are we losing the STRICT bit here? it's important that we use STRICT here, so we make sure that we never output deprecated stuff ourselves. and we test deprecations separately.
I c... ok
this method is dangerous as it wrong usage leads to re-resolving all the time. Maybe just remove it and do the `resolveSnapshotId` in TransportDeleteSnapshotAction
I think that's pretty much illegal it should not throw any and it should be handled internally
Add short-curcuit return if this == other.
++ can't hurt :)
I think it might be nice to have it behave the same for the Java API, where it needs to be explicitly set, but as you say, this can be a separate PR
you can probably cast it here and reuse it later
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
Since you touched the response, I am doing my duty to recommend moving these tests to `AbstractHlrcStreamableXContentTestCase` .
Nit: `"call back"` -> `"callback"`
this shouldn't be done here - it's part of the indexing logic.
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
make it final
just as a sanity check that declares we do not support arbitrary unicode. I don't think we have that around
Er, probably not. But a bit confusing name because it looks like a typo.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
nit: s/read blob's/read the blob's
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
We should remove the Store part. Perhaps make a constructor with a name? these errors are difficult tot trace so we should make it as clear as possible where the error came from (even if the stack trace is lost)
I guess, are any of the other assertions necessary given that we are checking that source has not changed at all in this case (and no metadata was added).
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
it's not really arbitrary is it ? :)
I'd just do `sum += Math.max(0, data[1])`
asked f2f, we can probably delete logging at this point.
In my dreams, merging would either throw an exception or return a new independent mapping so that we wouldn't need this validation phase :)
Ah, I see why this is a function ref - so that the `toString` generates the right method to invoke. That feels a little brittle but I understand what is up.
Remove and create again is not needed I think
I suspect these will be too small and we'll have time outs.
thanks for doing that Colin ;)
Why not add ``` java if (highlightFields.contains(fieldName)) { continue; } ``` around line 94? That'll prevent two regexes that find the same field from highlighting it twice.
can this runnable be an `AbstractRunnable`
I'd consider replacing the usage of `-1l` in this line and the prior with the field [proposed previously](https://github.com/elastic/elasticsearch/pull/14651/files#r45225330).
Maybe point out that this is actually the place where we modify the valid input query by adding a new object level to it.
Maybe throw error here it `nested_filter` is the only allowed option here.
I'd feel better if the `latch.countDown()` would be the first line in the catch block
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
indicesDeleted doesn't check for indexUUIDs. We have a separate method for it in this class `cleanMismatchedIndexUUIDs` - in this spirit of bringing all deletion code together - I think it's good to make indicesDelete aware of UUID switches (mark old as deleted), move the `applyDeletedIndices` to be executed where `cleanMismatchedIndexUUIDs` is called now and then we can remove `cleanMismatchedIndexUUIDs` make all go through here.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
Correct [equals](http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#equals%28java.lang.Object%29) implementation supposed to be reflexive. In other words the following test should pass: ``` StoreFileMetaData test = new StoreFileMetaData("test", 0, null, null); assertEquals(test, test); ``` Maybe `equals` is not a good substitution for `isSame` here.
Let's move this to a `finally` block.
ok, then assert that it's either snapshot or generic threadpool
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
You could move this back to the while condition? ``` while (next != null && counter++ < 10) ```
we don't need this `if` block, do we? All 6.x and 7.x indices have a single type.
should remove the "force:[{}]" in trace logger. @s1monw
nit: please use lowercase start for variable names
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
Nit: too many newlines here
Having through about this a bit more, I think the _prompt_ is going to be annoying rather than helpful. I think we'd be better off just printing out a warning message, and continuing on. Sorry for messing things around like this, but sometimes things become clearer during the review cycle.
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
Discussed this with @abeyad more. It looks like it should be part of RepositoryData after all, otherwise the index generation abstractions is getting exposed on the Repository interface layer, where it makes even less sense.
nit: formatting, add some whitespaces
I think we should change this so we output a `validation_method` field which can have the values `ignore_malformed`, `coerce` and `strict`. Then the parser should parse this as well as parsing the deprecated `coerce` and `ignore_malformed` boolean fields
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
Does it make sense to have the Enum and method name the same? I have no preference as to whether we call it `Weighting` or `WeightingType`
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Might be nice to add a check for existence of these parameters for completeness.
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
mayb just do `if (++count >=`
ok keep it then. I am not sure though what needs to be optional, if the client here, or the service in the parser service. I thought the former, not the latter.
hmm actually I think we should load deleted queries too
Nit picky: if we capture the node name from the start async we can do `internalCluster().getInstance(DiscoveryNode.class, blueNodeName).id()`
this logic belongs in transportWriteAction
If your intuition is that these will be almost always needed, then obviously we should keep them.
something is wrong in this sentence :)
thanks @nirmalc !
same request - please have a method called `haveWriteBudget` and do `while(haveWriteBudget() && buffer.isEmpty() == false) { `
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
this must be `2000051` rather than `2000003`
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
I think this'd be more clear if you said something like "invokeStatic assumes that it is not invoking a method on an interface."
nit: I changed this on master to get the parser from AcknowledgedResponse using a new `generateParser` method that I introduced there on request of Baz. Maybe we could use the same here in the backport to make it match the version on master.
good catch on delta > 0
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
Ah ok, I missing that method below, sorry.
this could be a for each loop instead
Same deal with `.get()`. I try to only do this when I edit the line so it doesn't blow up the diffs, but this is a good opportunity to do it here I think.
instead of changing the state first and then checking whether the previous state was the right one, let's only change the state if the current state matches (note that we're under the mutex here already, so it's safe to do this).
Ok, than that's fine for me. So overall LGTM.
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
I think it'd be nice to remove this second ctor so we're explicit every time.
ok as a follow-up
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
"now" should be "not"
I don't believe this is only kept for BWC. You use this to parse `_source` above.
typo in the method name here too
the printStackTrace should go away here
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
I double checked and heard that `@Ignore` is needed as well, otherwise IntelliJ tries to run this test as well when running all tests from the IDE.
Same here, nevermind again :)
I think you can just do this? ``` if (info.files().contains(markerFileName) == false) { return true; } ```
using ActionListenerResponseHandler will simplify this lightly.
we throw the exception and thus take care of the interrupt. We don't need to set it...
can we unify the resolvedDiscoveryNodes logic with the buildNodesToPing ? They are similar in the sense that they don't change during a ping cycle.
In these writeTo/readFrom methods, you need to make sure that you can talk to a node that is running an old version by adding checks on in/out.getVersion()
Maybe this one too, I'm not sure.
:) good catch
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
Yeah, exactly, and I think usage should really be reserved for incompatible or invalid arguments, for example. This is more a state thing, so now I think I'm convincing myself that configuration is apt.
Ah! The star imports come back. Its fun watching these things wash in and out like the tide.
maybe we should just get rid of this local variable and write the next line: ``` nodesIds = filterNodeIds(clusterState.nodes(), resolveNodes(request, clusterState)); ```
let's check this on every access, not only creation.
Can you give each of them a numeric id instead? This will allow to rename the enum constants without breaking the bw compat of the stream
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
no need for these local variables, they're only used once...
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
Does this need to set `change = true` also? It's missing from this `if` block
Snapshot Name - repository name + snapshot name ;-)
given our direction (REST client vs transport client) I think we are fine rejecting `-1` on the REST layer. But how about keeping the `int`, using `-1` as default, and rejecting negative values in the setters? That's how we changed some of the request validation as part of the search refactoring too. This way the java api would be rejecting -1 too, which is nice, especially cause we are reusing the same requests for the high level rest client.
Same here about indentation now
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
right, I had totally misunderstood how the test works
class could be `final`
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
I would add a flush(), since we expect people to see those bytes and we want to be independent of the filesystem impl (what if it uses buffering, thats its choice)
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
nit: space after the second percent sign (on all these lines)
> This method is private and only ever called from a single thread so there is no need to recheck. I'm just weary of having the failure handling case so far from the success case. I figure its harder for someone to break it if its closer together.
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
maybe be nice and add that you reuse the bulk request. So "refresh is not supported on an item request, set the refresh flag on the BulkRequest instead".
Shouldn't we test only three cases: no_sort, new_sort, old_sort ? Mixing the old and the new format should not be allowed.
+1. Good catch. I missed it. It would still be good to kill the node when testing - so we should have some assertions here too.
`Arrays.asStream(response.pingResponses)` would not materialize it
Just for my own education, and it is certainly super minor: when reading this part I was wondering if it would make sense to get the maxClauseCount limit once at the beginning of this method since its unlikely to change to avoid method calls in each iteration). Maybe Java does some clever optimizations to avoid this though and the effect most likely negligible.
I wonder if we want a trace message here...
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
Wow, that's a big difference! Do you know whether it is lossy compression or not? If not then indeed compression seems to make a lot of sense. :-)
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
These always read clearer to me as `<= 0`.
I think it would be more flexible if the keys were objects? (you could have composite keys, etc.)
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
Perhaps add the duplicate size to the assert message here
Please add a string message about the context registry being null
same here: no need for the [].
same here with removing retry logic
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
do we protect this from double invocation? I think we should just make sure we only invoke once. can you wrap it in here and ensure that? maybe just use `NotifyOnceListener`
shouldnt this solve the problem and not the above ``` String.format(Locale.ROOT, "https://download.elastic.co/org.elasticsearch.plugins/%s/%s-%s.zip", repo, version)); ```
make these parmaters to this method? then it doesn't really need to know about index creation requests.
What about just converting to bytes and comparing? The way you have it now this isn't consistent with `equals`.... Also the _cat API we call `toString` which doesn't really use the unit anyway.
It should - see `IsNull`
oh, the boxing horrors :)
I see this was already like this, but this can go on a single line.
I _think_ that you can get away with just letting the exception bubble up and RestController will send it to the user. You won't get the error log but I'm not sure logging an error on 400 level parse errors is a good thing in the long run anyway. I try to usually run requests with `error_trace` on them so we don't eat the stack trace....
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
is this always used in an assertBusy context? wonder if we should add it here. This can be suprising...
I've dug some more. This is caused by us running the tests with the built in gradle test runner rather than the randomized runner. We configure the randomized runner to run with the system properties but we don't ever configure the standard runner.
just call `parser.text()` instead of `parser.bytes().utf8ToString()` since it might be optimized under the hood
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
Is the `if` necessary? It seems to me that the following should work? ``` java for (String pattern : request.selectedFields()) { fieldNames.addAll(indexShard.mapperService().simpleMatchToIndexNames(pattern)); } ```
+1 that is what I would do too
hmm this has an empty impl? Not sure if we need the `Injectors.close()` if we need it, it should deal with null values!
we don't want it to be retried... that was the cause of the failure
+1 on removing the `Void context` from all methods. The `declareInnerHitsParseFields` is already complex to read I think, that won't add much.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
Throw error if old-style params passed alongside new-style script definition
the suppress warnings could be right on the line of code doing the cast instead of the whole method
points are allowed to reuse the byte[] to I would make a copy of it before adding it to encodedPointValues
I spent some time thinking about whether we can consolidate this, like we do for runtime fields (e.g. the compilation could be done in a single place for all types). We can't really do the same that we do for runtime fields as NumberType is an enum and can't have a generic type, while the different Factory and LeafFactory don't have anything in common throughout the different types hence require a generic type somewhere. Whatever we do ends up being complicated for little gain e.g. saving a few lines of code). One thing is I find it a bit tricky to follow that thanks to this we compile the script at mapper creation time and not at execution time. We could potentially make MapperScript an abstract class with a generic type (the factory) and compile the script in its constructor. That is not perfect but maybe clarifies when the script gets compiled.
++, the only thing is I would even go with a Map<String,String> if that works. not sure what you and Nik think about that.
I think we should not execute these writes directly here but extend ESIndexLevelReplicationTestCase#ReplicationAction then run them via the infra of the new action (see ESIndexLevelReplicationTestCase#IndexingAction).
can we fold this into ClusterHealthResponse? that way we can test this as well as part of the unit testing.
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
Ah nevermind, I see where we check it above :)
The indentation is off here and the rest of the way through this test.
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
same here these strings are only used in one place just use them directly and trash the Fields class
Oh I see why - there is no builder. Can we follow the same pattern as in other places - make this class immutable and add a builder? All purging and such can be done at the builder level.
assert for verification whether it is created
I am good with both options.
I also dont' think we should swallow the exceptions here? Someone asked for a gce address and we failed to get it...
You can use `XContentParserUtils.throwUnknownToken()` (that would throw a ParsingException instead but I think it's appropriate here)
fine with me
``` java final RefCounter previous = ref.getAndSet(indexShardOperationCounter); assert previous == null; ```
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
So, this could be simplified to `assertFalse` Or could be something like the following (which admittedly, is probably less simple) ``` import static org.hamcrest.CoreMatchers.everyItem; import static org.hamcrest.Matchers.greaterThanOrEqualTo; import static org.hamcrest.beans.HasPropertyWithValue.hasProperty; ... assertThat(response.records(), everyItem(hasProperty("recordScore", greaterThanOrEqualTo(50)))); ``` Man, that is frustrating that hamcrest does not support just passing a lambda as a type of matcher :(
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
I think if you don't have the Java build stuff setup you should make javana do the merge ð On Jul 14, 2016 8:21 PM, "Honza KrÃ¡l" notifications@github.com wrote: > In > test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java > https://github.com/elastic/elasticsearch/pull/19436#discussion_r70905675 > : > > > @@ -34,7 +34,7 @@ > > */ > > public final class Features { > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key"); > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key", "yaml"); > > Thank you @jasontedor https://github.com/jasontedor, I don't have my > env setup for java so I missed this. > > â > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub > https://github.com/elastic/elasticsearch/pull/19436/files/d53406b8d3919c5367c1bb574fd365fb2af7110e#r70905675, > or mute the thread > https://github.com/notifications/unsubscribe-auth/AANLotcG0AVdYcNe3YtwU1U545rSEKT2ks5qVtJ2gaJpZM4JMfjQ > .
your call on whether to change this, but we also have `Strings.EMPTY_ARRAY`
I was trying to understand why this works, because of the forward iteration here (with nested, we usually seek backwards (`BitSet.prevSetBit(...)`)). So this works because all live doc ids (root docs and nested docs) are evaluated in order.
May be `if (!FileSystemUtils.isAccessibleDirectory(dicDir, logger))`
don't you want to reset first and then set the parseFieldMatcher? :)
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
these ElasticsaerchExceptions are bogus remove them
you mean providing the size of the array I guess? cause I don't see a constructor that accepts an array in ArrayList.
can you add spaces? `new KeyManager[] { km }, new TrustManager[] { tm }`
optimization nit, but maybe we can just have one list, and reorder to push active one to the start, we do something similar in primaryFirst. This will mean we don't have to create 3 lists, just one
same here - I think it's better to log the info message if the deletion was successful.
we should probably bail here. One nit pick - I would prefer having this rejection logic closer to where it holds. I think there is only one method that can cause this.
Thanks for moving this to `InnerHitContextBuilder` and its subclasses!
if you use here `refresh();` from the base class we also make sure we get back no failures.
Typo, finalzlie -> finalize
Just wrap and rethrow and let junit report the exception.
do you have indentation at 2 chars only for this method? We use 4 chars in our codebase. I'd appreciate if you could change that.
can we set the timeout to 0 here? otherwise tests half the time takes 1s
right thanks for the explaining, I should have known, having worked on the search refactoring :)
those are hard to debug I can tell u :dancers:
I'm still not following you? What's wrong with the `static` reference? Whether you use a constant string field (`static final String` assigned from a literal string) or just use literal strings in all the places that you would use the constant, the effect is the same: a single `String` is put in the constant pool and that constant is pushed onto the stack when needed using `ldc`. The java compiler effectively interns all literal strings, and this is the same effect as using a constant string field.
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
well we use a dummy lock so I guess it's fine
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
you are perfectly right Christoph, let's merge the two and keep the existing class.
Lol - I spent some cycles trying to figure out how the hell we know this won't throw an index out of bounds exception, only to end up learning something about the BitSet api - it's funky ;)
nit: s/read blob's/read the blob's
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
Looking at this again, I think we can remove the node settings as updateDelay / getRemainingDelay only depends on index settings.
I think 0 is a good minimum value.
s/The tasks has/In case the task has/
I get that, I was just wondering why those default templates bother here
I wonder if it's nicer to append the random uuid.
not a big deal but maybe phrase it `remove() is not supported on GeoHashPathIterator`
Snapshot Name - repository name + snapshot name ;-)
I opened: #23338
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
Maybe a name like "PlusOneMonth"
It might be worth logging it at warning, maybe. Its not "normal" not to have it but is "OK". Its just one line on startup and so long as the line clearly states that everything is ok, we're just disabling groovy, then I think it should be logged every startup.
replace match here too
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
I think NamedWriteableAwareStreamInput was introduced just a bit later. Only my guess.
yeah nevermind I was confused about some internal classes
Autoboxing already happens and I wouldn't worry to much about it considering the depth is not that big. Same for `Linked` vs `Array` (in general arrays are faster except for inserting in the middle as that requires resizing/copying at which the linked structure excels). I think the `Tuple` makes the code a bit more compact and safe (the queues cannot get out of sync) and more readable/simple code always trumps optimization (especially micro ones as here).
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
I would use the following message: "ignored as shard is not being recovered from a snapshot" and not have an explicit check for `shardRouting.primary() == false`. That case is automatically handled by this case too as replica shards are never recovered from snapshot (their recovery source is always PEER).
we can... but it's important to not forget that some classes should not to depend on es. Packages don't enforce anything but may make you think about it (or maybe not). Anyways I think it's nice to keep separated the es runtime for ingest and the ingest classes that are independent from es core. There is a pretty big difference between these two sets of classes. As I asked above, maybe there are other ways to keep things clean, not sure.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
I hope I'm not splitting hairs, but there's also a typo in the field (deault is missing and 'f'). (This PR resulted from a question I asked here; thanks for all the awesome work you invest there!)
we can delete ForceMergeFailedEngineException now, right? It's not used.
nit: I think remove "next", since this is no longer a second step in the method
or just: "return ok;"? :)
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
This should be immutable I think, it looks like its mandatory.
I think that suggesters are just less far along than queries. It is fine though.
I think it is fine: we only build one search context per request per shard.
I think it is not clear here exactly when IndexMissingException is expected to be thrown or not. I would rather move the if on top and have different asserts path based on that. FOr the expected exception one you can then do: ``` try { //do something fail("shouldn't get here"); } catch (IndexMissingException e) { //assert on exception } ```
`retentionPolicySupplier` is confusing. It's a prune query supplier.
I liked the assertion you had there that if already have a result, this one has a higher seq no
This was a bit hard for me to read due to the order in which comparators are checked. Could it be rewritten in a more idiomatic way, ie. ``` java if (o1.isPrimary() != o2.isPrimary()) { return o1.isPrimary() ? -1 : 1; } final int secondaryCmp = secondaryComparator.compare(o1, o2); if (secondaryCmp != 0) { return secondaryCmp; } final int indexCmp = o1.index().compareTo(o2.index())); if (indexCmp != 0) { return indexCmp; } final int idCmp = o1.getId() - o2.getId(); if (idCmp != 0) { return idCmp; } ``` It would be helpful at least for me to see more quickly in which order comparisons are performed.
let's assume that if the method parameters are not marked as @Nullable that they are non-null. Otherwise we clutter the codebase everywhere with these checks.
This needs to be another method (`parseInnerFilterToQueryBuilder`) which replaces `parseInnerFilter` and also takes care of switching the interal `isFilter` flag.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
Maybe it doesn't have to come at all.... I think only `copyCurrentStructure` is part of the xcontent implementation. The rest is just "stuff that ES uses". I think.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
This is not the right condition, a plugin bin directory is not required to exist.
++ for ordinal and tests then
I think this should be at debug level
I think it'd be nice to remove this second ctor so we're explicit every time.
This shouldn't be here. You should use ESLoggerFactory instead.
this check is obsolet - we can just remove it
nit: space before brackets
Instead of doing the instanceof check here can we maybe wrap the body of the try / catch in another try catch and then rethrow? like this: ``` Java try { try { } catch (WriteFailure e) { // do all the things throw e.getCause(); // maybe check if e.getCause() can be null? } } catch (Throwable e) { // do all the other things } ```
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
minor: I think it would be a bit more obvious to explicitly call `DateTimeZone.getDefault()` instead of `null`. Since that is what Joda does with the `null` value. http://joda-time.sourceforge.net/apidocs/src-html/org/joda/time/DateTimeZone.html#line.301
I also dont' think we should swallow the exceptions here? Someone asked for a gce address and we failed to get it...
also, can we remove the boolean return value from doStart and remove the timeout handling from the public void onTimeout(TimeValue timeout) method of the callback given to the observer in line 245? just call doStart.
I hope I'm not splitting hairs, but there's also a typo in the field (deault is missing and 'f'). (This PR resulted from a question I asked here; thanks for all the awesome work you invest there!)
well, I'm not sure we can assume that all addresses are by default "public". I tend towards saying implementers need to make this call.
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
We typically use `Locale.ROOT` rather than `ENGLISH` for case conversion.
sounds great thanks
looks more tedious than just filling an array, but I didnt do an awful lot of java 8 stuff yet :-)
This change breaks backward compatibility between 2.1 & 2.2 (pull request is labelled v2.2.0)
I think this was more readable the old way.
May be `if (!FileSystemUtils.isAccessibleDirectory(dicDir, logger))`
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
Consider checking for `null` somewhere for `primarySize` before the division below.
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
grr nevermind I didn't see the last line pfff...
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
I guess we're doing `instanceof` not `getClass()`, but still, it sounds like maybe we should in some cases.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
Technically not an "and".
Two test requests: What happens when you have something like `Integer a = Integer.valueOf(0); int b = a ?: 1;` `Integer a = Integer.valueOf(0); int b = a ?: Integer.valueOf(1);` I believe these are expected to be ClassCastExceptions where Integer cannot be cast to int, but I'd like to be sure.
I meant `client().admin().indices().preparePutTemplate()` or `client().admin().indices().putTemplate()`.
we should check here that acked == true but shardAcked == false
would be great if this logic could be unit tested.
use `Objects.equals` for all once changed to potentially null references.
ok thanks for the explanation.
maybe also rename the setting? (in addition to the constant)
Can we make this 1 hour? If it times out it's nice to get thread dump
maybe better to say "failed to find primary despite of request being routing here. local cluster state version [{}]] is older than sending node (version [{}]), scheduling a retry... "
is there always at least one element in this list? (I haven't checked whether we assert it somewhere else)
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
would be nice to allow to configure it to a percentage of the heap size
well we use a dummy lock so I guess it's fine
This has a line-length violation. I pushed 575fa4e00a8be31a54859adf06f39c7280691040.
Same feedback as the last `toString` - I think you can remove `created` and might want to look at `Operation`'s `toString`.
I think we should have a dedicated method for this in IndicesService. ``` public FieldStats<?> getFieldStats(Engine.Searcher searcher, String field) { // do the caching in here and also lookup the MappedFieldType again! } ``` this way we don't allow everybody to cache whatever on our request cache!
you can replace these two lines with a call to `ThreadPool.terminate`
now I see what you meant yesterday saying that we have to parse meta here
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
The shapeFieldMapper seems unused here.
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
having another look, index time lookup is needed when creating the search lookup, and I actually made another suggestion around possibly not needing IndexTimeScript entirely, so I don't think we will be able to do without adding indexTimeLooup.
ok fine! :)
same here - would be good to have a brief summary of the shard that failed and why.
That assumes `list` can't contain null..if that is not the case ignore
I think it would be worth renaming this method, otherwise it will cause confusion in the future about whether it's expected to be a bug or not (since the only reference to the exact bug number is in the line you've deleted). Alternatively, the format this method tests could be moved back into the method above (which is where it was originally).
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
Nit: I think you can leave out ESTestCase here.
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
Should you use the static `templateName` import here and throughout? It looks like you might be mix 'n matching.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
nit: Everything okay, but I found this (and the following same constructs) a little hard to read. Can I suggest writing the boolean flag first without conditions (e.g. `out.writeBoolean(fuzzyOptions != null)` and then have the if-block only? But either was is fine.
nit: use assertThat(...) with isNull() as matcher instead? I think in general that is the preferred way of writing test assertions.
hmm do we need to skip the size if we are in production? I mean that assert will not trip if we run without -ea
formatting should be fixed like the rest in these three lines
you should pass fieldNames as an argument
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
This is logic that I think should go into ReplicatedOperation.
This logging statement has a `[{}]` but no argument to fill it
I think it would be cleaner to move the assert into the catch, and add a `fail("expected script exception")` after the call to `run()`.
ok didn't know that. yet another bug fixed in master then it seems
I think you can just blast the entire method in this case.
this must be `2000051` rather than `2000003`
@talevy Can you extract this IOException change from the PR and commit this to the branch? I can then benefit from it in the geoip PR too.
A question out of curiosity: the analyzer we get here doesn't have to be closed (via closeAnalyzer) because its not a new instance? I don't know enough about the lifecycle of these objects yet I'm afraid.
if just read metadata it will also be easier to implement a fetch all interfeces, sort interface name, fetch interface ip sequence
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
Probably should also be getAssignedNodeId.
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
ok let's drop it in master and keep it here for BWC
I think we can remove this exception now.
no i do not. but this IDE cannot compromise the actual build, which is 'gradle check'. changing tests.seed in this way can compromise the build, because then the values for other things looking for this (such as lucene) depends on class initialization order.
are those number randomizable ie `randomIntBetween(1,100)`
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
same here - just pass a new instance
I think this needs to be `true` as well.
But that is not equivalent? Arrays.toString is a static method, and different than result.buildConflicts().toString()
> At the same time though, acquiring the write lock would be good, because even though there is a warning that this should not be run when ES is running, trying the lock seems like it would be a good idea Definitely, +1
there is no exception possibility here? I think this is overparanoia
Not a big deal, I'm fine without it
to me these should be sets and required to be non-null
Incides -> Indices ? ;)
Sorry, what I meant by the previous request was to do an assertion on the whole error string (e.g. wie assertEquals), unless there are any reasons preventing this.
I don't think you need @Before here, the parent method already has it.
I prefer my way but have asked @jasontedor to chime in.
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
I will take care of this.
should we use a native trove collection here from String to long
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
By keeping track of contexts in 2 different data-structures, I think you are potentially introducing race conditions, eg. if a clear scroll action is issued concurrently with an automatic release of the context due to the fact there are no more hits to process.
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
after is now minimum_age
I am not sure if we should catch an exception here IMO the exception should bubble up
+1 I like plugin examples!
Not a specific concern, but just more configuration options for the end user when it is not being that effective. The code is trivial and not of maintenance concern so I am fine with we being consistent in all cases.
at that point you want have a read budget, which I mentioned above.
It would be nice to return a simple, non-empty structure here so that we test that aspect of the response parsing.
asked f2f, we can probably delete logging at this point.
I see that we need it from another package, I think it's ok.
maybe sort them by the list index `8`
I think we should complain if we don't find the header name.
Answering my own question: you build the array to simulate the task being on all of the simulated nodes. I don't know that that is required here but doesn't hurt anything.
nit: use assertThat(...) with isNull() as matcher instead? I think in general that is the preferred way of writing test assertions.
s/payload is/payloads are
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
I am not sure RestoreService would be the right place for it since addBlock would need to be moved to the same place and it's currently used all over the place. I don't have an issue with renaming it to `addIndexMedataBlocks` but since IndexMetadata is the only parameter, repeating IndexMetadata in the name might be redundant.
I would call `indexedValueForSearch`.
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
final, not volatile...
tokeinzer -> tokenizer
Thanks for the explanation. Let's do it here. Since the error has an inner cause which provides from_seq_no and to_seq_no information, I think we are good.
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
Should this be cached somehow? /cc @jpountz
after rebase you will have to get rid of any wildcard import, or the build fails :)
This should say `storeStats`, not `storeState`.
That might make sense though my preference is to handle this corner cases leniently. I was a bit confused by `UNKNOWN`, I would argue an empty list has `FALSE` nullability (it can never be null) but then again maybe it's something that's worth having a check.
Nit: this could be on the previous line.
Could you replace null above with `TRANSLOG_BUFFER_SIZE_SETTING`? (This is a separate issue, but I never backported to 1.7.x...)
I'd go for either check in the constructor or here.
I think completely removing it is unrealistic, but we may not get a disconnection event for quite some time (up to ~15 minutes by default on Linux). I do not think it should be delayed beyond the safety phase.
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
is this correct? this will return a copied array if offset > 0, yet the `arrayOffset` method will return the offset into an array that has offset 0... .
you don't have to assert on anything if an exception is expected
same for here, not sure if the full Objects.equals needs to be called
Can we keep the line numbers in the test assertions? I think they are important to maintain.
Why isn't this replacing `--hash`? The release hash here should be the only thing needed to download the artifacts.
this is just personal preference so feel free to ignore it, but I like the name `registerDeprecatedHandler`
Maybe "you should use time based indexes or cron a delete-by-query with a range query on a timestamp field"? Or something that mentions time based indexes....
can we move this back into the try? I'm worried that exceptions wouldn't release the shard lock .
confuses the shit out of me everytime :)
Can we use `in.getVersion()` to check in the read (and write) for serializing this as a single string for old versions, and array for new ones? Then we can backaport it to 0.90.
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
check listener.isDone() as we don't expect a retry here I think
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
There is actually a [standard](http://checkstyle.sourceforge.net/config_modifier.html) for this if you particularly enjoy standards.
I think I'd rather stay on the safe side
argh. Hidden by github ui. all good.
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
wondering if we should enforce immutability on this level... feels more natural to do it in the build()
formatting, 1 line instead of 2
sounds good, we were even thinking about merging those, we will not move them to separate packages for sure.
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
`ilm-move-to-error` -> `ilm-move-to-error-step`
can we add some java docs? the name to functionality transition is not trivial anymore
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
Er, well, it doesn't work like that. Ignore.
we may want to rename match_formats as well here, can do in another PR though.
This name won't work as I can specify multiple scripts of a single type (e.g. `inline`) and the `ParseField` name for them all will be `"inline"` so they will overwrite each other. I think we need to go back to the parser here and parse a `Map<String, Script>` so each script can have a name. In the request this would look like: ``` { ... "script": { "my_script_1": { "inline": "script contents", "lang": "expressions" }, "my_script_2": "script contents", ... } ``` Note that scripts can either be a JSON object or a String. The `Script.parse()` method handles both cases.
I think we should use `debug` for the logging here
no file? maybe IOException
I think this message is wrong? applyMappings only touches existing indices.
I'm afraid we need to rely on the order if we want to be able to distinguish between negations (applied when a wildcard expression appears before the negation) and referring to indices that start with `-`. We will be able to get rid of it in 6.0 only when we will be sure such indices are not around anymore. I opened #20962. Can we also have a test where the wildcard expression is not the first expression but still before the negation? e.g. `test1,test2,index*,-index1`
I understand with `wrap`. I think it'd be a little more clear if you just caught the `IOException` and sent it to `onFailure` but what you have will work as well.
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
@jaymode no. the opposite. I prefer not outputing fields with empty values. This is the norm now, and outputing empty field values is only useful in a tabular log format (column names at the top).
I'm happy we have all these tests. It is also another data point to move in the direction we discussed - i.e., failures should mark things as stale.
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
you can do some streaming java8 magic here.
Might be better to use the default of the request (in this case this coincides, but explicit is better in case of refactoring): getSnapshotsRequest.ignoreUnavailable(request.paramAsBoolean("ignore_unavailable", getSnapshotsRequest.ignoreUnavailable());
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
lower case F please :) - "found shard on ..."
Throw error if old-style params passed alongside new-style script definition
It is how other plugins do it, yeah. There isn't a clear definition of "correct" here.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
space missing between ) and {
Add short-curcuit return if this == other.
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
Typo, "Trasnlog" -> "Translog"
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
operation can be `final`
Is it right to just eat the exception thrown from the listener? At least log a warning or something.
add `assert entry.state() == State.ABORTED` here. You can directly write the message as "snapshot was aborted during initialization" which makes it clearer which situation is handled here.
It would be nice to have this take the args in the same order as computePolyTop (array, offset, length)
s/to list of/to the list of/
Double negative. ð
Would be nice to see this parsing code pulled into a function or helper on the parent class so it doesn't need to be the same in both implementations
Why do we need getters? These are all final and immutable
I think this message might be misleading.
I find it confusing the we have the same field names for this in both ReplicationPhase and PrimaryPhase.
I wonder if we can somehow come up with something that better normalizes across failed cloud instances? If a machine is pulled, but its replacement can come up within the allotted time, then it would be ideal to not trigger the recovery because we're waiting on the dead machine (based on its InetAddress).
is this new assert needed? after all the following cast will fail if the request is not a Replaceable...
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
you don't have to assert on anything if an exception is expected
I think that we can save the instanceof checks, builder.value(Object) does it already
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
This is not the right condition, a plugin bin directory is not required to exist.
I'm wondering if we should adapt the whole message and say "Recovery failed on " + targetNode , if there is no sourceNode
Ok fair enough, I'm happy leaving this as is then
Same concern regarding the leniency.
nit: I changed this on master to get the parser from AcknowledgedResponse using a new `generateParser` method that I introduced there on request of Baz. Maybe we could use the same here in the backport to make it match the version on master.
seems redundant indeed
++. Looks good.
ahh yeah in `assertAfterTest()` nevermind
ok didn't know that. yet another bug fixed in master then it seems
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
`it's` -> `its`
This assumes a version format that while fairly standard is not guaranteed.
I think that we should avoid re-computing this value every time we get status (think of a monitoring system polling the stats every second). We are creating unnecessary garbage on every poll for every shard.
Nit: `parallel` -> `concurrent`
Ok, than that's fine for me. So overall LGTM.
This is `INTEGER` in other mappings.
and randomly append '/' at the end
once #12937 is in we can do the following here: ``` QueryBuilder<?> finalQuery; if (queryBuilder.indices().length == 1 && getIndex().getName().equals(queryBuilder.indices()[0])) { finalQuery = queryBuilder.innerQuery(); } else { finalQuery = queryBuilder.noMatchQuery(); } Query finalLuceneQuery = finalQuery.toQuery(context); if (finalLuceneQuery != null) { finalLuceneQuery.setBoost(queryBuilder.boost()); } assertEquals(query, finalLuceneQuery); ```
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
I know the "dots in field names" discussion has been a long running one. Do we not yet have a more general/graceful way of throwing these exceptions? This is more of a question out of my own curiosity and not intended to hold up the PR.
I would probably make this package private
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
Oh, I'm fine with symmetry, I just wanted to make sure that I was reading it correctly.
nit: use the constant from the mapper? content type I think it is called
and the `ExceptionsHelper.` qualifier is unnecessary
Sorry about these crazy incantations....
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
script seems to be optional, I get NPEs in some roundtrip tests for this.
right I see that
I don't see any implementations extending this at the moment, are there any plans to add some later? If this is just going to be a collection of static methods and ParseFields I'd suggest making this an interface.
you also have this variant `org.elasticsearch.common.xcontent.XContentBuilder#timeValueField(java.lang.String, java.lang.String, long, java.util.concurrent.TimeUnit)` which you can use without changing TimeValue
or when some docs match the query but do not have a value
Checkstyle is unhappy with this.
does it make sense to remove the setters? I imagine it feels more ergonomic to use the `IndicesStatsRequestBuilder` for building up a modified `IndicesStatsRequest`
same as above, no need for try catch
Also, since "recover" and "restore" are very similar and easy to confuse, I think it'd be nice if this were named "`recoverState`"
remove line wrap
it's a minor thing but why would you assign a variable multiple times when it's not needed? default is a better fit here, it improves readability as well.
I can't wait for try-with-resources :)
I think it'd be nice to remove this second ctor so we're explicit every time.
This is going to be 512 Unicode code units, but I think we should do bytes.
I like dummy because it implies fake and the index is fake - not just empty.
Would it be beneficial here to return an empty string instead of null? If not, maybe just annotate this with `@Nullable`
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
can we add some trace logging here? I can imagine it will save some WTF at some point.
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
Why not public? Will make reflection faster for guice.
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
if we'll need this in other tests, we should probably try to shorten this setup part of test by re-using what we have in our java api, that allows to provide `Object... source` , but we also want to be able to randomize the xcontent type, which is why we need to adapt it a bit
nevermind I see it was already there, then it should be ok
make the error a bit more understandable for users? Like "processor x doesn't support some of the provided configuration parameters" and list them like you do already...
we should add ClusterService and IndexNameExpressionResolver to IndexQueryParseService so they get injected. Then this method could pretty much be moved to INdexQueryParseService like this: ``` public boolean matchesIndices(String... indices) { final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices); for (String index : concreteIndices) { if (Regex.simpleMatch(index, this.index.name())) { return true; } } return false; } ``` QueryShardContext would need to expose the same methd and delegate the IndexQueryParseService
I think I would not check the instances' classes but instead compute how many values the interval has using NumericUtils.subtract (it returns a byte[] that is comparable).
I would be using a `Set` in this circumstances.
let's not make this hold this PR, but let's keep track of this potential issue and address the need for generifying in a separate issue
Yeah, exactly, and I think usage should really be reserved for incompatible or invalid arguments, for example. This is more a state thing, so now I think I'm convincing myself that configuration is apt.
can you please use indexRandom to index docs
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
the == false is done on purpose to make these comparisons more explicit
can we use `== false` instead of `!` it's so much easier to read and burned my fingers too often
Safe because ~~our~~ we know
`it's` -> `its`
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
we shouldn't need this here in parse phase
yes, lets do this in a follow up change.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
subtractShardsMovingAwayRen -> subtractShardsMovingAway
I'm clearly not getting my point across. Please understand that multiple tests are run in the same jvm during jenkins!!!!!!!!!!!!
Again missing units :(
I would execute the `IOUtils.close(resources);` in a finally block after we sent back the response or the other way around.
64e5c25 added support for this.
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
@s1monw I'm sorry that I didn't take any time to reply last night. The situation with the response parameters is quite complicated. Look for example at `Settings#toXContent`. The situation here is that the `flat_settings` parameter is consumed there, but the signature `ToXContent#toXContent(XContentBuilder, Params)` is a general signature, we can't just go and add a boolean parameter for flat settings to the interface because it doesn't make sense in all situations. It is for this and similar reasons that I ultimately handled response parameters the way that I did. Barring a redesign, I would prefer that we remain consistent for now. > It's just yet another place we need to maintain and look for params. Right now it is how we handle output parameters.
The `withPassword` method is called every time we need a password, even if it's being used to _read_ a certificate file. In that case we don't want to print this warning, because that would cause additional output (and an additional prompt) for simple things like reading a CA file that has a long password. We need to only perform this check/warning if the password is being applied to a new file. I'm OK if we want get rid of the `promptYesNo` and just print out a warning, but we only want to do either of them when we know the password is being used to _write_ a file.
can you assign the key and the value here before we use it? it's way easier to read
Note that this is different than setting a single property as it adds the inputs to the list.
ok didn't know that. yet another bug fixed in master then it seems
The `Coordinator` becomes leader in `joinHandler.test()` not in `handleJoinRequest`, and that's outside this mutex, so it's technically possible that it could become a candidate again before this synchronised block.
maybe put this check before the primaryTerm check
`super.readBlock` instead of `readBlock` to prevent double `maybeIOExceptionOrBlock`.
nit: we can check the expected token and then create the searchProfileResults map
To coerce, should be: ``` parser.longValue(true); ```
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
can we rename this to `boolean isCanceled()` and then instead of the exception just return a boolean? I think it would be more intuitive and we really don't need yet another exception
nit: can we add the timeout value here.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
It would be worth requiring that `jobId` and `jobType` are not `null`.
exiting -> exists
I think we should have a dedicated method for this in IndicesService. ``` public FieldStats<?> getFieldStats(Engine.Searcher searcher, String field) { // do the caching in here and also lookup the MappedFieldType again! } ``` this way we don't allow everybody to cache whatever on our request cache!
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
good lets do that
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
yeah nevermind I was confused about some internal classes
nit: these could probably even be package private
you are right, sorry
this should happen after we update `isSecurityEnabledByTrialVersion`
sure, or just make it `[foobarbaz/0/mynode]` or something, `[foobarbaz//]` if there is only one or something
++. Maybe also add a sanity check that a get on the doc at the end gives us what we expect? (deleted or found)
I think this assumption is pretty broken. What if the type is `null`? We don't define any order in the types when they are specified in the URL but this code assume that there is an order. I think we have to make this explicit which type should be used.
we don't count shard not allocated / not started/ closed etc. as shard failures - see Search logic. This will end up as a difference between total shards and shard failed. The reason is that there is no way to distinguish this case with the one that our cluster state said they were unassigned.
can "printer" be null? I don't think so, but maybe guard agains it in the ctor.
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
I hope jit takes care of this to be honest
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
acceptDocs will be checked _before_ these bits are checked anyway
I would add an `assert this.context != null` here just to make sure
"just created files" <- what do you mean exactly? if one waits 2h they will be able to read it? if not I would just go with "the permissions on the store don't allow reading"
I think we should make sure that the String that is used as Id in serialization gets treated in a special way, also in the builders themselves so they are not accidentally changed between versions. Thats why I liked the old `getWritableName()` (that seems to be on its way out). Maybe we should even have an own class `QueryId` which simply wraps the NAME string constant but forces us (and users implementing their own queries) to think about this as a special case. We could change the existing `String getName()` method in `QueryBuilder` that currenty just forwards to `getWritableName` to do this. This is just some thought for discussion, nothing to block this PR though.
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
this change requires going over all the places we use `equals` in ShardRouting....
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
this needs to stay because the method can be called from any other class, it's a public static method....thus validate might not be called at all before calling this method.
ok, talked to David about it. We will add a note to breaking change docs.
Extremely minor, but this could drop the `public abstract` part now as `interface` implies it.
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
yes, we can't do too much about this, so it is better be defensive here.
don't drink and code ð» (same line twice)
Usually we'd stick this on the end of the last line.
maybe all the action names should contain `index_template` instead of `template_v2`? In this it would be `indices:admin/index_template/delete`. When v1 has been removed the v2 name is going to be confusing and changing that isn't fun from a bwc point of view.
(same question for FLOAT)
cool thanks for clarifying!
much cleaner. thx.
I see what the difference is now but I think the name needs to be changed here. Can we called this method `addPipelineAggregatorReader` or something like that since this is actually for registering the serialisation method for the PipelineAggregator itself not for the result. It's not analogous to the InternalAggregation. Likewise the `addBucketReader` method should be renamed to `addResultReader` since this is not about serialising a bucket but about serialising an InternalAggregation the same as in the metric and bucket aggregations
same here - we need move double starting and such to ShardStateActionTests
Just wrap and rethrow and let junit report the exception.
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
now that #30490 is in, could you replace the header argument with the RequestOptions one? In the method that accept a listener we add RequestOptions between the request and the listener though.
Maybe just handle the boolean for this PR, but we should think about removing it....
typo: filers -> filters
see above - I think you should add it though
I like this way more anyway
we shouldn't need this here in parse phase
can you explain why we do this now only if `autoCreateIndex.needToCheck()`
This line will break our `precommit` checks because it violates the 140-character line-length limit.
well maybe you don't like the success pattern though... but I think it should be closed even on Throwable
Oh this is tricky! Could we use `null` here instead? I'm not a big of making a `Script` that no one can compile. It'll have stuff like `engine=painless` which is isn't.
You won't even need the guard if you are just merging to 3.0.0, right? 3.0.0 doesn't have to be wire compatible with 2.x
`String.format(Locale.ROOT, "%s operation term [%d] is too old (current [%d])", shardId, term, primaryTerm)`
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
should be `logger.debug("...", e, shard.shardId())` :)
My preference would go to adding a serialization context to readFrom.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
> Would you do this just when it is overriden (ie not the default)? Or at all times? What about if they explicitly select netty in their settings? Anything but the first is not a one line change. Yep. Log all the time. > I don't think we should just willy nilly log things > I don't think this is useful. It saddens me that this takes so much effort and discussion. It is also sad that there is no constructive discussion but rather these yes/no statements. As I said, I find it useful, for the reasons I mentioned. That should be enough for this kind of change. I'm signing out of this now. I don't think it's constructive anymore.
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
can we debug log the default? also leaning to have info the "non default" setting, thats what we try to do most times in other components to try and keep the startup logs clean and informative.
I'd say it's fine with IAE
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
+1 I like plugin examples!
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
Please revert this change.
It is called pluginId in install because it is an identifier, which _may_ be a plugin name, but it also may be maven coordinates or a url.
I think I missed the discussion but why isn't all this (this method and the next two) part of BaseNodeResponse's toXContent implementation? It can declare an abstract method that the subclasses can override for their own xcontent? We use that pattern pretty frequently with things like the query builders.
Yep, this looks great
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
It is to make sure that the version comparison logic orders alphas, betas, and RCs correctly.
is there a way to filter out the index metadata here? We just want the global metadata.
Are there other files that might not be in there and we're ok with that? Should we log a warning or something? I suspect its just fine for the directory not to exist but if some file inside the directory doesn't exist when the directory does thats probably bad. Like, in production. In tests is fine to just eat the exception.
looking deeper, I see that we set a non null TermsLookup object only when we have it in query, which causes a validation error when values are set too. We should keep it that way then, this is as good as it gets.
1+ portCounter.incrementAndGet() % 9 ? (now we have a collision for 10 & 11 )
We can remove the `!` if we reverse this if statement, so ```java if (difference.isEmpty()) { status = RestStatus.OK; } else { ... the error stuff ... }
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
I think we should remove this if, call deepCopy recursively in any case, so that the main else works in this case too. Again being paranoid, I know...
space after `,`
We might should move these last two declarations to a common spot something like ``` static <T extends AbstractObjectParser<? extends QueryBuilder>> declareStandardFields(T parser) { parser.declareFloat((builder, value) -> builder.boost(value), AbstractQueryBuilder.BOOST_FIELD); parser.declareString((builder, value) -> builder.queryName(value), AbstractQueryBuilder.NAME_FIELD); return parser; } ``` and then we can declare them when we're initializing the object.
As mentioned offline, I think the name `checksum` captures what we want.
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
take out boost and queryname once you rebased
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
should we assert that reader.getCoreCacheKey() == engineSearcher.getDirectoryReader()? Forcing the core cache key handling to be delegated to the inner reader could be trappy otherwise
I saw this problem being dealt with in other place by setting currentFieldName to empty String. Worst that can happen then is that it is treated as fieldName in the query, which we should validate later and throw IAE then.
can you add a //norelease here too? context should really go away after all queries are refactored
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
actually, you may not even need the array here.
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
Missing a space here after `id`
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
nit: space before instanceof
nit: extra space
The `new HashSet<>()` can be replaced with `Collections.emptySet()` (and then you'll have an import to remove).
I think this could use the `rebalance` function in `CatAllocationTestBase`? It looks like it's performing the same function
I am still missing `_version`, `_version_type`, `fields`, and `_parent` here we should add them!
I think this declaration/initialization can be moved to inside the if
why do you pass the response to this method? `this` already has all information.
No, that's fine.
depends (which is why I asked). If it's about API bwc I think we should break it and be clear about the impact of the version. Which is also makes me think we should not render the field if we don't have a version (because we removed it)
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
I think we have at least one similar test that does the same, we can maybe share the dummy client to minimize the code repetition. It's not that we cannot use mockito, we could, we would need to have a bigger discussion around it, some people are in favour of that and some others are totally against it. I personally don't think mockito would solve all our problems, we should strive to make elasticsearch more unit testable, easier to say that to do though :)
Can you change the line wrapping on this somehow? Like stick `new InputStreamStreamInput` on a new line and indent it? I think as is it'd break how I visually scan try-with-resources.
This doesn't look right to me. If `subPath.path` is null, or if `seenDevices.add()` returned false then we don't call `seenMounts.add()` despite having seen the mount point in question.
this can go back to boolean if we move back Settings to boolean too
Since `value` internally is a String now, we can change read/write here as well.
and i guess where we instantiate singleton, we just let Kernel32Library be null if it cant load? I dont know if its cleaner actually, it means callers woudl have to check for that. i just think its wierd to have all methods have to check isLoaded and do nothing. Currently there are only a few, but if the class increases...
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
I think that it's cleaner to write this as: ``` ElasticsearchParseException ex = (ElasticsearchParseException)ExceptionsHelper.unwrap(e, ElasticsearchParseException.class); assertNotNull(ex); assertThat(ex.getMessage(), equalTo("processor [test] doesn't support one or more provided configuration parameters [unused]")); ```
can we rename it to something like allNodeResponded ? we're not sure we're going to delete...
This needs to be another method (`parseInnerFilterToQueryBuilder`) which replaces `parseInnerFilter` and also takes care of switching the interal `isFilter` flag.
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
solely based on names, hard to distinguish from `testRebalanceNotAllowed`
When getting a `searcher`, you need to keep it around, and then call `release` on it on the `finally` clause.
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
formatting, 1 line instead of 2
Remove and create again is not needed I think
I was only talking about the context _path_. But what you have is fine for now, the entire class really needs a rethink. :)
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
I wondered if there was something better than iterating too but there's not since `IndexWriter#getLiveCommitData` only returns an `Iterable`.
I would add an `assert this.context != null` here just to make sure
We should be testing serialization here by extending `AbstractXContentTestCase`. Unfortunately, that means we need to also write a parser for the request but it's worth it.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
given that the suffix is also known before we go and provide index, type, and id... (even in case of e.g. _search) I wonder if we can get rid of the list, and just provide parts and suffix as constructor argument, then convert it into string straightaway. Not even sure we need a builder for this.
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
no file? maybe IOException
I think this check should go into initializeSnapshot or repository.
if we do this, why did we need to change how createNewEngine behaved (i.e., update currentEngineReference etc.)
I think this is okay though, it checks if the current `zeroTermsQuery` is the same as the default, which is ZeroTermsQuery.NONE.
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
this seems to be a very expensive operation I wonder if we should special case this here rather than adding a generic way of doing this.
maybe expectThrows would be easier.
This was called "path" before.
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
It would also allow you to change the ``` java if (delete) { channel.deleteOnClose(); } channel.close(); ``` to ``` java channel.deleteOnClose(delete); channel.close(); ```
Sorry, what I meant by the previous request was to do an assertion on the whole error string (e.g. wie assertEquals), unless there are any reasons preventing this.
I also need to go back and do this for the PutUserRequest
we throw the exception and thus take care of the interrupt. We don't need to set it...
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
would be nice to allow to configure it to a percentage of the heap size
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
AFAICS (correct me if I'm wrong) you had to it this way because we don't know on what node version the primary is (i.e. if it is going to send maxSeqNo or not), and the shard is reset when we acquire the replica operation permit (i.e. possibly before we receive the first resync request). It's a shame because it means we can't ensure consistency for older indices. The only other solution I can think of right now would be to always send the maximum sequence number with the replication request (same as we do for the global checkpoint). We could then pass this to acquireReplicaOperationPermit (same as the global checkpoint).
can we use `== false` instead of `!` it's so much easier to read and burned my fingers too often
Listener can be null here.
ah I mean't Throwable.... sorry
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
Alternatively we can move this logic to the `beforeRefresh` method as this is the only place it's used at.
I think this has to happen before you start the cluster, or else the cluster will start with full knowledge.
a transformer and performer. Quite a guy :)
I feel like we implement this pattern enough times that we should make a helper for it at some point. No need now, but at some point.
> Would you do this just when it is overriden (ie not the default)? Or at all times? What about if they explicitly select netty in their settings? Anything but the first is not a one line change. Yep. Log all the time. > I don't think we should just willy nilly log things > I don't think this is useful. It saddens me that this takes so much effort and discussion. It is also sad that there is no constructive discussion but rather these yes/no statements. As I said, I find it useful, for the reasons I mentioned. That should be enough for this kind of change. I'm signing out of this now. I don't think it's constructive anymore.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
> just let the default be 1 instead My rational with going with half as default is that I think that adding replicas should change the behavior - if someone runs with 6 copies , it's probably not a good default to let of them (but one) go away before signalling alarm. I chose the word "half" in order to avoid a loaded word like "quorum" which implies stuff that aren't part of our model (i.e., quorum reads). I don't mind if we round up (i.e., `(size() + 1) / 2`) or down (i.e. `size()/2` ) as long as it's not `size()/2 + 1` .
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
ahh yeah in `assertAfterTest()` nevermind
now that #30490 is in, could you replace the header argument with the RequestOptions one? In the method that accept a listener we add RequestOptions between the request and the listener though.
If we're doing a reroute - I don't think we should retry on retryPrimaryException. That one only holds for the primary action.
Is this a typo? Not sure how this compiles...
this would make sense especially given that their setters accept primitive types
shortcut: VersionHandshakeResponseTransportResponseHandler handler = pendingHandshakes.remove(requestId);
what to do here otherwise? not really likely to happen that it's not a number I guess... maybe leniency is good here
for instance in RestoreService we use `addLast` at runtime which messes with this assumption, that entire order thing is broken and error prone. The best thing I can come up with so far is to add defined stage like this: ``` Java enum ApplyStage { NewClusterState, NodesConnected, StateRecovered, ShardsStarted, RepositoriesCreated, NodesDisconnected; } ``` where listeners can be registered but I am not too happy about it...
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
Please fix identation.
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
nit: extra line
My preference would go to adding a serialization context to readFrom.
Ah, nope, I'm just bad at Java. `[Metric1, Metric2]` is exactly what I was wanting. :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
I think we should always return 1 here. REST tests should run with default number of replicas (1) even against a single node, because that's what clients tests do too. We can never expect green unless we manually set number of replicas to 0 in a test, and we should align to clients builds here I think to prevent failures that don't repro for us. Thoughts? BTW running against a single node is very helpful because it allows us to realize when we make the wrong assumption in a REST test, which in the past was only going to fail for clients and never for us.
same here with removing retry logic
can we name this `CompleteDiff` don't use simple please :)
`.addPathPartAsIs("_xpack", "rollup", "job")`
just my personal preference, I don't like instanceof checks that's it. you are free to leave them if you prefer them ;)
can we report the right version we found ? note that we would probably need to change the the logic in the gateway allocator to check for both -1 version and exception (now -1 means both).
+1 this makes sense. Then we can drop the `PIPELINE_ALREADY_PROCESSED` transport header.
can we add a one lliner java doc explaining why this is needed (rather then pass through the the primary lock factory)? it's non-trivial to figure it is done to track the location of the lock file, if it's using files..
You can get away with it right now because there is only one test, but this should be initialized once before the test suite, not once before each test in the suite.
we could pass a glob with regex:xxx to newDirectoryStream if we want
This'd only come up if the target augmentation method is defined on an interface, right? Maybe we should not allow that at all.
if the argument name is `failNoIndices` you should provide `! indicesOptions.allowNoIndices()` as argument
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
Usually we'd stick this on the end of the last line.
do you know if there is a good reason to return 0 if we got a negative value, or could we just return 'result' directly? (if this doesn't make any tests fail, this is good enough for me)
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
master is the future 7.0, so I would do the following: ```java if (INDEX_MAPPER_DYNAMIC_SETTING.exists(indexSettings.getSettings())) { if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0)) { // 7.x index throw new IllegalArgumentException("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " was removed after version 6.0.0"); } else { // 6.x index DEPRECATION_LOGGER.deprecated("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " is deprecated since indices may not have more than one type anymore."); } } ``` Then when backporting I'll just remove the 7.x branch and make sure that we only emit a deprecation warning on 6.x indices (you don't need to worry about it).
we have `TestThreadPool` that makes it simpler
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
Same here... we don't really need `String[] addresses`
I would be using a `Set` in this circumstances.
java 8 FTW
or junit for that matter. try/catch is much more readable (and the way most other tests do this)
I'm clearly not getting my point across. Please understand that multiple tests are run in the same jvm during jenkins!!!!!!!!!!!!
Also, it can use `execute()` rather than `submit()` as it's not interested in getting a `Future` to track completion. Since you're off I'll push another commit that changes both things.
would it be possible to make the second part of this method part of the field script object itself? It would also be fantastic to use the same mechanism on both sides, but I know it is a bit tricky for different reasons: 1) that array that we reuse without resizing 2) we try so hard to avoid boxing 3) the usage pattern is slightly different if we compare doc_values, query and index time execution. I do wonder if it is worth investing on this, possibly having our own PrimitiveIterator or something that allows us to expose a clearer script API to access the computed values. For later I guess.
It's minor, but we usually lowercase exceptions and elide ending punctuation
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
I think all of these need to be trace and we should enable these in tests that are relevant.
please use Arrays.asList while we re here
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
Would it be better to use the Assert.fail(String) method or throw an AssertionError here? That way the test will fail correctly in the test framework
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
same here. ElasticsearchAssertions.assertThrows wil help
can this be final
This exception will be treated as ignore replica exception. :wink:
I think you forgot to add the name of the script here to the failure log
right thanks for the explaining, I should have known, having worked on the search refactoring :)
class could be `final`
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
Beware that bucketOrd has the following definition: ``` java final long bucketOrd(long owningBucketOrdinal, int filterOrd) { return owningBucketOrdinal * filters.length + filterOrd; } ``` So we need to somehow multiply by `filters.length + 1` instead of `filters.length` when we compute the other bucket otherwise there will be several "logical" buckets reusing the same "physical" bucket
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
there is a test helper method that can create plugin property files
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
same here re enumSet.toString
you are right, the original indices are read/written in the super class, good! You can then remove the PercolateShardRequest that takes shardId and originalIndices as arguments I think.
Quick question (unrelated to this PR) for clarification: the goal was to get rid of the Prototypes, but this will happen in later PRs? Is there already a proof-of-concept type of PR I can look at how this will work, I just played around with it a bit wasn't quiet sure how this will work with the common `boost` and `query_name` fields.
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
marks the shard store
wondering if we should enforce immutability on this level... feels more natural to do it in the build()
ok can we rename the getter then to `getFailedNodeExceptions()`
should be `'norms': True`
This should be `Type.FS.match(` instead of `Type.FS.name().equals`
I'd expect this to be in a synchronized block
+1 on just `field`
oh right sorry I had missed it's a single value for these processors. sounds good.
you could remove the null check by changing the second check to `Defaults.NAME.equals(parser.currentName())`
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
Does it even have to be a map? It feels like a set would do just fine here.
Heads up when you merge with master, I just merged another test where the original test query is modified assuming it is json, so that will need the same treatment as you do here I thinkg: https://github.com/elastic/elasticsearch/pull/14255/files#diff-9dc314365d49d84bff0645c2f9dfd7adR356 (and Overwrites in HasChild/HasParentQueryBuilderTests)
should we here or in the superclass fail if the cluster has not fully upgraded to 2.3? just as a safety guard I think that would be a good check in several places otherwise I can see us debugging weird issues `DiscoveryNodes#smallestNonClientNodeVersion()` has a neat method to check.
same as above, function name says nothing about what it does.
getDelayCalculationTimestampInNanos -> getLastComputedLeftDelayNanos
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
Nevermind, I just noticed this is required for bw compatibility.
can you explain why we do this now only if `autoCreateIndex.needToCheck()`
You can use end instead of `out.position()` here.
do we need this? it's like the base class (as we never have a cause)
I think you forgot to add the name of the script here to the failure log
Maybe replace these with writeOptionalString as well while you are at it
I'm fine with `IllegalArgumentException`, in all the places of course. :smile:
I think a nicer approach (can be a follow-up done by me) would be not to call `updateGlobalCheckpointOnReplica` here, but instead call ``` globalCheckpointTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED); ``` either here or in the IndexShard constructor (where we create the GlobalCheckpointTracker) when the recovery source is EMPTY_STORE.
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
yes please I haven't seen them used before in our codebase. At some point we will automate formatting and these classes will have to somehow be ignored I think.
you should run `gradle precommit`
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
Nit: `added [{}] the` -> `added [{}] to the`
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
Someday we're really going to have to standardize on American "canceled" or British/Australian "cancelled"... :)
yeah that is true. nevermind then
after rebase you will have to get rid of any wildcard import, or the build fails :)
this can be removed now, no? it will be cause a duplicate with the full cluster state log..
Nit: I think it'd be better for the message to read: ```[move_allocation] can't move abc123 from node1 to node2: node1 is not a data node``` (NB less punctuation, and no need to say `since its not allowed`)
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
I think the following if is not valid anymore in fromXContent: ``` MatchQuery.Type type = MatchQuery.Type.BOOLEAN; if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_FIELD)) { type = MatchQuery.Type.PHRASE; } else if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_PREFIX_FIELD)) { type = MatchQuery.Type.PHRASE_PREFIX; } ```
`assertNoFailures` is more common in newer tests and much shorter.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
Lol - I spent some cycles trying to figure out how the hell we know this won't throw an index out of bounds exception, only to end up learning something about the BitSet api - it's funky ;)
I will take care of this.
_value is only for agg scripts, we shouldn't have it for anything else
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
`them` -> `them;`
just fix a number, I don't think randomizing this adds much.
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
Maybe replace `SearchContext` with `IndexSearcher` if we don't want to expose `SearchContext` in plugins.
These are expected, even required when implementing `ActionListener`. Either we should create an `AbstractActionListener` that does this for us the same way we have a `AbstractRunnable` or we should add a permanent hack to allow this specific construct in `ActionListener` subclasses. The former seems like a better choice but it'd mean more work before we can get this merged.
let's reference "1m", "5m" and "15m" directly
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
I guess it could be renamed to isFalse() / isTrue() now
You indent this differently than the thing above it.
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
missing t at the end of the method name
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
can we use `== false`
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
I you decide to go this route you should also remember to replace the reference equality checks (`this == ActiveShardCount.NONE`) by equals checks or by looking at value (`this.value == 0`).
if you make `MulticastChannel` generic and the listener as well you safe the hard cast in Shared... just like `Shared extends MulticastChannel<MultiListener>` ...just an idea...
right, its a mock.. then use `ClusterName.DEFAULT` and you need one less constant.
good point! I think we need to iterate over the filterFunctionBuilders and rewrite their corresponding filters
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
Oh, I think I see why, it's for closing. I think it's still to pass in a search and close it on exception as you did now.
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
Maybe update, looks good to me now.
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
this case got lost
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
since you are returning the script, I think this can just be called `extractConditional`
cool can you update the title of the PR then? :)
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
Perfect! Thank you.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I'd recommend using the same syntax Lucene does: ``` bq.clauses().iterator().next().getQuery() ``` Just to follow their conventions
Clearing the current publication could be a method on the publication, avoiding the `thisPublication` malarky. The only other use is to call `toString()`.
Unused import here (not really a big deal)
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
If they are different then mlockall will not really work on unix either. That is because it may map additional stuff later!
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
++ . nit: add the state to the message please.
I see that there is already a rest test, great!
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
I'm on the fence as to whether we should only do this on non-realtime get. Real time gets don't really relate to refresh cycles (they force a refresh if needed). They are already "efficient" in the sense that they only refresh if they need to (i.e., there's a pending doc change in the version map).
nit: space after IOException
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
As we never expect a null value to be passed as parameter to this internal method, I'm not a fan of sprinkling this check here. This is defensive programming at its worst.
no need for `else` here: ``` java if (numPredictions < 1) { throw new IllegalArgumentException("numPredictions may not be less than 1."); } if (numPredictions == 1) { predictions[0] = next(values); return predictions; } ```
And i just did not have the time to yet yesterday remove the stupid asserts from SpanScorer. Please, lets not drag this stuff in again. If oyu want to push fine, but you will see a second push from me removing all this crap.
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
I think that will fail compilation? ð
++ for ordinal and tests then
I am fine with doing it in a follow-up PR if that works better for you
You didn't introduce it, but seeing this line again reminds me that this is buggy if Long.compare returns Integer.MIN_VALUE, which is legal :) So it should rather be `Long.compare(o2.getDocCount(), o1.getDocCount())` (without the minus sign)
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
A better wording for the error is: `[from] can't be negative` Changing that will require updating tests
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
I think that inserting random fields here would reveal problems on the parsing side with the current code.
this could be a for each loop instead
It'd be nice to be sure it contained that `not_found` wasn't found.
acceptDocs will be checked _before_ these bits are checked anyway
here is a space missing before `EMPTY_FLAGS`
It looks like you have proper ram usage stuff. Maybe it'd be simpler to refuse to expand the tree if it'd put the `bytesAllocated` above a certain size.
this class is also missing a hashCode impl.
I know it was like that before, but we are here now. ð
I'm clearly not getting my point across. Please understand that multiple tests are run in the same jvm during jenkins!!!!!!!!!!!!
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
one too many new line? :)
Thanks, I get the general idea now.
nit: you might be able to save a few toString lines by extending ToXContentToBytes here. no big deal though
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
cool. lets look at it on another issue.
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
ok fair enough...
yeah, that was what I meant
The `Coordinator` becomes leader in `joinHandler.test()` not in `handleJoinRequest`, and that's outside this mutex, so it's technically possible that it could become a candidate again before this synchronised block.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
I think adding a constant somewhere for # makes sense. It may make sense to also add a constant for typed_keys, but I don't have a strong opinion on that.
Also, please annotate with `@IndexSettings Settings indexSettings`, there's nothing worse than `indexSettings` being renamed to `settings` at a later time and then not knowing which Settings it actually is.
Oh, never mind, I misread. Sorry for that. ð
I was wondering if `getSuperset/SubsetSize` is part of the Bucket interface but not rendered via the Rest response, should we either add rendering of these values to the bucket response or remove it from the interface to get equivalent behaviour of functionality of the transport client with the high level rest client here? I think this can be done in a separate issue though, maybe its not needed at all.
Also, since "recover" and "restore" are very similar and easy to confuse, I think it'd be nice if this were named "`recoverState`"
`expectedType.cast(e)` should remove the need for the unchecked suppression.
Nit: it isn't a jsonBuilder - it is whatever kind of xcontent was passed in. Nit: maybe only set prettyPrint if the original had it set? I don't know if you can tell though. Neither are a big deal.
a transformer and performer. Quite a guy :)
No, there are only two ways for sets/maps, because of how multibinder works. I think it is more confusing to have some things bound using a binder, and others with registration/settings. Classes that ES controls should be registered, and set. If there was a way to just not allow multiple multibinders to work I would say we should do that, but I don't think such a thing exists.
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
This should be a `ConstructingObjectParser` so that the private empty ctr can be removed.
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
nit: space after `if`
Maybe replace these with writeOptionalString as well while you are at it
same here - pls refer to `current`
This can be `Files.notExist(...)`
can we use package private methods and have unit tests for this.. an integration seems like an overkill.
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
I think that it's cleaner to write this as: ``` ElasticsearchParseException ex = (ElasticsearchParseException)ExceptionsHelper.unwrap(e, ElasticsearchParseException.class); assertNotNull(ex); assertThat(ex.getMessage(), equalTo("processor [test] doesn't support one or more provided configuration parameters [unused]")); ```
Do we really need to ignore the setting in post 2.0 indexes? Why not just support both for a while? You already check above that both aren't specified.
If you want to test the multi-write behavior you could make a testing aggregation here that needs to be rewritten twice. I'm not sure how important that is to you, but it ought to be possible.
same here regarding nullable ..
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
Why is this `volatile`? It doesn't look necessary to me.
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
please wrap in {}
ok, then assert that it's either snapshot or generic threadpool
I think allowing this on a whole class is too broad. Is there a use case I'm not thinking of? I just figure it'd almost always be better to have it on a method or constructor.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
I think this patch could work just fine? ``` DIFF diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java index 8a1df50..94a0ab1 100644 --- a/core/src/main/java/org/elasticsearch/node/Node.java +++ b/core/src/main/java/org/elasticsearch/node/Node.java @@ -98,6 +98,7 @@ import org.elasticsearch.search.SearchService; import org.elasticsearch.snapshots.SnapshotShardsService; import org.elasticsearch.snapshots.SnapshotsService; import org.elasticsearch.tasks.TaskResultsService; +import org.elasticsearch.threadpool.ExecutorBuilder; import org.elasticsearch.threadpool.ThreadPool; import org.elasticsearch.threadpool.ThreadPoolModule; import org.elasticsearch.transport.TransportService; @@ -210,12 +211,12 @@ public class Node implements Closeable { throw new IllegalStateException("Failed to created node environment", ex); } final NetworkService networkService = new NetworkService(settings); - final ThreadPool threadPool = new ThreadPool(settings); + final List<ExecutorBuilder<?>> executorBuilders = pluginsService.getExecutorBuilders(); + final ThreadPool threadPool = new ThreadPool(settings, executorBuilders.toArray(new ExecutorBuilder[0])); NamedWriteableRegistry namedWriteableRegistry = new NamedWriteableRegistry(); boolean success = false; try { - final MonitorService monitorService = new MonitorService(settings, nodeEnvironment, threadPool); ModulesBuilder modules = new ModulesBuilder(); modules.add(new Version.Module(version)); modules.add(new CircuitBreakerModule(settings)); @@ -223,6 +224,7 @@ public class Node implements Closeable { for (Module pluginModule : pluginsService.nodeModules()) { modules.add(pluginModule); } + final MonitorService monitorService = new MonitorService(settings, nodeEnvironment, threadPool); modules.add(new PluginsModule(pluginsService)); SettingsModule settingsModule = new SettingsModule(this.settings); modules.add(settingsModule); diff --git a/core/src/main/java/org/elasticsearch/plugins/Plugin.java b/core/src/main/java/org/elasticsearch/plugins/Plugin.java index 1efc151..695a255 100644 --- a/core/src/main/java/org/elasticsearch/plugins/Plugin.java +++ b/core/src/main/java/org/elasticsearch/plugins/Plugin.java @@ -23,9 +23,12 @@ import org.elasticsearch.common.component.LifecycleComponent; import org.elasticsearch.common.inject.Module; import org.elasticsearch.common.settings.Settings; import org.elasticsearch.index.IndexModule; +import org.elasticsearch.threadpool.ExecutorBuilder; +import org.elasticsearch.threadpool.ThreadPool; import java.util.Collection; import java.util.Collections; +import java.util.List; /** * An extension point allowing to plug in custom functionality. @@ -80,4 +83,8 @@ public abstract class Plugin { */ @Deprecated public final void onModule(IndexModule indexModule) {} + + public List<ExecutorBuilder<?>> getExecutorBuilders() { + return Collections.emptyList(); + } } diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java index f373da6..bb22854 100644 --- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java +++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java @@ -40,6 +40,7 @@ import org.elasticsearch.common.settings.Setting; import org.elasticsearch.common.settings.Setting.Property; import org.elasticsearch.common.settings.Settings; import org.elasticsearch.index.IndexModule; +import org.elasticsearch.threadpool.ExecutorBuilder; import java.io.IOException; import java.lang.reflect.InvocationTargetException; @@ -261,6 +262,14 @@ public class PluginsService extends AbstractComponent { return modules; } + public List<ExecutorBuilder<?>> getExecutorBuilders() { + ArrayList<ExecutorBuilder<?>> builders = new ArrayList<>(); + for (Tuple<PluginInfo, Plugin> plugin : plugins) { + builders.addAll(plugin.v2().getExecutorBuilders()); + } + return getExecutorBuilders(); + } + public Collection<Class<? extends LifecycleComponent>> nodeServices() { List<Class<? extends LifecycleComponent>> services = new ArrayList<>(); for (Tuple<PluginInfo, Plugin> plugin : plugins) { diff --git a/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java b/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java index 31f3f31..61e5141 100644 --- a/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java +++ b/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java @@ -30,7 +30,7 @@ import java.util.List; * * @param <U> the underlying type of the executor settings */ -abstract class ExecutorBuilder<U extends ExecutorBuilder.ExecutorSettings> { +public abstract class ExecutorBuilder<U extends ExecutorBuilder.ExecutorSettings> { private final String name; diff --git a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java index 0b564b2..1d641aa 100644 --- a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java +++ b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java @@ -151,7 +151,7 @@ public class ThreadPool extends AbstractLifecycleComponent<ThreadPool> { return Collections.unmodifiableCollection(builders.values()); } - public ThreadPool(Settings settings) { + public ThreadPool(Settings settings, ExecutorBuilder<?>... customBuilders) { super(settings); final Map<String, ExecutorBuilder> builders = new HashMap<>(); @@ -175,7 +175,13 @@ public class ThreadPool extends AbstractLifecycleComponent<ThreadPool> { builders.put(Names.FETCH_SHARD_STARTED, new ScalingExecutorBuilder(Names.FETCH_SHARD_STARTED, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5))); builders.put(Names.FORCE_MERGE, new FixedExecutorBuilder(settings, Names.FORCE_MERGE, 1, -1)); builders.put(Names.FETCH_SHARD_STORE, new ScalingExecutorBuilder(Names.FETCH_SHARD_STORE, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5))); - this.builders = builders; + for (ExecutorBuilder<?> builder : customBuilders) { + if (builders.containsKey(builder.name())) { + throw new IllegalArgumentException("builder with name: " + builder.name() + " already exists"); + } + builders.put(builder.name(), builder); + } + this.builders = Collections.unmodifiableMap(builders); assert Node.NODE_NAME_SETTING.exists(settings); threadContext = new ThreadContext(settings); @@ -190,10 +196,6 @@ public class ThreadPool extends AbstractLifecycleComponent<ThreadPool> { this.estimatedTimeThread.start(); } - void add(ExecutorBuilder builder) { - builders.put(builder.name(), builder); - } - @Override protected void doStart() { final Map<String, ExecutorHolder> executors = new HashMap<>(); ```
you also have this variant `org.elasticsearch.common.xcontent.XContentBuilder#timeValueField(java.lang.String, java.lang.String, long, java.util.concurrent.TimeUnit)` which you can use without changing TimeValue
As this setting should usually be only set once, it is probably simpler to leave it non-dynamic (as @jasontedor suggested and as it was before this PR). In case where this must absolutely be updated on a production cluster, rolling restart (of master nodes) with config update is always possible.
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
ok didn't know that. yet another bug fixed in master then it seems
you can use `assertAcked(prepareCreate(...))` here
is this somewhere on a todo? I'm afraid we'll loose it
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
Needs a guard.
which other queries do you mean? You mean check against this specific field in similar queries or just in general. I think the question is "when can this happen?". If stuff can happen in both java api and rest layer, validate is the way to go. If we already perform some kind of validation that makes sense in the parser, then having null here can happen only from the java api and we should maybe try and fail straight-away.
this deserves a sep issue I guess but good catch
I think we should remove this method and insist on using the setScoreMode(QueryRescoreMode) method instead. This will make the API cleaner as only the permitted values (the ones in the enum) can be used. The parser can then use the fromString() method to convert REST request values to the enum but Java API users will have the safety of the enum
could be a instance variable, as used in all tests
Missing the `indexName` argument to the debug log here
Wherever makes the most sense really. In this case I would put the default constants in `DirectSpellcheckerSettings` I think
This potentially overflows. I mean it's ok for our purposes (it overflows deterministically) but a sufficiently powerful linter would complain. Suggest `^` instead of `+`.
maybe just call this `public BytesReference materializeAndClose() throws IOException` and don't even return the stream.
it makes it too easy to call delete when its not necessary.
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
For backporting to 6.3, I think this needs to be changed to 7.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
Man this feels like a mess compared to ObjectParser. We can't do anything about it in the middle of this PR though. Just makes me sad.
We can't safely say that all such exceptions will extend `ElasticsearchException` (e.g., a bad `NullPointerException`), but I like your idea of wrapping the ones that do not extend (as long as it's not wrapping it in an exception that sounds like the user can do something about it).
3 more indentation issues above
oh sure, thanks for clarifying...
From the top of my head I think you can leave this out as well
I honestly don't get it... the way I look at it, we moved from having the `env` "polluting" the `Factory` interface to having it now "pollute" the `Factory.Provider`... why don't we just either wire the concrete factories into a map binder, or, if we don't want to wire them, see if we can pass in the Env. directly to the Module ctor (just like it can accept `Settings`)
hmm why did you remove the mapping from here? I think that was a good change? you should add the settings from from `public Settings indexSettings()` are only used if you use `prepareCreate` so you should add the settings to the versionSettings below. other than that it looks awesome
In these cases its acceptable to use randomize testing's `rarely()` or its like to cover either branch randomly.
The indentation is off here and the rest of the way through this test.
can we make this getAgeInMillis and do the conversions here? we make use of millis everywhere so it will make for an easier to work with api. The nanos resolution is not guaranteed anyway.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
512 \* 1024 :tongue:
s/y ou/you Also I think upfront is one word.
Can we have a small note on what this test does? link is good but description is better. Same thing with method name: `testNoRegionReturnsEmptyList` or something like that
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
what changed here? I can't spot the difference compared to before
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
just initialize it and make it final - it just compliicates the code
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
class could be `final`
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
this curly bracket should be on the previous line
Should there be sanity checks that you cannot resume a watcher that is already running (so that the watcher doesn't run twice).
Wow, you are totally right, I see that now :)
I see some places where null is not protected against...
Conversion to bytesref is done elsewhere with `indexedValueForSearch`. I'm unsure of the impact of rejecting anything but bytesrefs.
++, the only thing is I would even go with a Map<String,String> if that works. not sure what you and Nik think about that.
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
I've dug some more. This is caused by us running the tests with the built in gradle test runner rather than the randomized runner. We configure the randomized runner to run with the system properties but we don't ever configure the standard runner.
Please no `null` for no change needed, returning `Function.identity` is clear, and there is no need to make an optimization check.
Think it'd be good to keep the `translog stream is corrupted` string here unless there's a good reason to change it. It's useful to be able to search for exception messages when working on support cases, and this sort of change makes that technique less useful.
license header is broken here
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
this whole block here looks pretty much the same in all invocations. Can we make this even simpler? Maybe create a method `createIndexAndWaitForActiveShards` in `MetaDataCreateIndexService`. I've implemented it here: https://github.com/ywelsch/elasticsearch/commit/6e67ecabbfa5cc2568c0c987401e3ea521c7a330
why is this method synced? I don't see a reason though...
and 2 more occurrences below
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
Perfect! Thank you.
I think I would make a breaking change here. Let's drop support for the string value in the builder and add it to the breaking changes. The parser still supports `none` and `all` but the builder only accepts a query. Then the method below needs to pretty much be moved to the parser.
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
I think you should pass the Result here. Maybe also add an assertion in the ctor that the result is either `Result.DELETED` or `Result.NOT_FOUND`.
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
it makes it too easy to call delete when its not necessary.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
So negative delays count delays? I figured they should count as not-delayed.
and do that in all other classes we do this for serialization in this pull request.
I think you should pass the Result here. Maybe also add an assertion in the ctor that the result is either `Result.DELETED` or `Result.NOT_FOUND`.
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
Good to read, but this more or less repeats what ParseFieldMatcher.match() already does. I think it just adds another stop on the road to the actual match-implementation, which is not even in ParseFieldMatcher but in the ParseField itself. I was thinking about simple shortening like `matcher.match(currentFieldName, PARSE_FIELD)`, but I think its fine the way it is right now in the PR, not worth going trough all the files again IMHO.
no need to be volatile anymore
ok fair enough I didn't try it :)
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
Oops nevermind, I misread.
If the constructor is modified, this method won't be needed anymore.
I think that we should have left an assertion here that the Java version is not JDK 11 (I think we will be able to remove this for JDK 11). I also think that this code should have been guarded by an if block checking that we are on JDK 10 and otherwise not add this permission.
I think we should throw an exception when `id < 0`, which should never happen? (unless Bad Stuffâ¢)
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
can we call this last seen clusterState? it doesn't need to be volatile as it is changed under a lock.
Can we do all of these things (stripping last char, backslash escape and quote escape) in one pass with a string builder? Right now 3 copies are made of the string.
Nit: too many newlines here
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Minor suggestion to make it clearer that we're not waiting for the write index not to exist: ```suggestion public static final String NAME = "check-not-write-index"; ```
if we make such change, can we do it in a separate PR please? ;)
relativize can be tricky if paths have different roots. is siteFile really guaranteed to be absolute too? In lucene i coded this "minimal path" with the following idiom: ``` root = root.toAbsolutePath().normalize(); path = root.relativize(path.toAbsolutePath().normalize()); ```
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
can we use org.elasticsearch.indices.recovery.RecoverySource.Actions#START_RECOVERY ? it's a better indication that the recovery is started.
maybe we should have a helper method for this? this looks used in several places
import not needed.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
ok I remember now. The point of IndicesRequest and CompositeIndicesRequest is to return the indices that a request works against. when a request is composed of multiple operations, it should implement CompositeIndicesRequest. In this case delete by query reads from some indices as part of search, and writes as part of deletes. But what indices would it delete from? It is not possible to create a DeleteRequest that points to multiple indices, yet it is hard to predict all the deletions that will be performed as part of the request execution. I doubt that this request should implement CompositeIndicesRequest then.
should we catch exceptions here to make sure we cancel everything we need
similar concern about modifying the value that is set
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
I think this should throw IAE if you pass null - that's 100% of the time a bug
I don't understand here what you mean by synthetic variable. If you mean the two ENulls, the analysis and writing would be contained to only compile-time.
nit: should be "commit_ting_ writer with commit data"
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
add a return method here just in case? I don't like this construct but can't think of how to improve it (all other options I see suck too)
not really important
Okay, doesn't matter if the builder only outputs verbose version as long as we support the other one still.
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
why do you pass the response to this method? `this` already has all information.
hmm I see it's to opt out...
`new AtomicReference<>();` with the extra `<>`.
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
I expect to be tested as it's static, but I don't see test? I think its good to have one. Also, it seems it can be package private.
As @rjernst says, this is incredibly broken behavior. It invalidates all the work we did to reject unrecognized URL parameters, now it accepts any parameters including garbage parameters.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
this can be out of if now.
same here regarding nullable ..
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
why do you pass the response to this method? `this` already has all information.
`.addPathPartAsIs("_xpack", "rollup", "job")`
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
I think this check comes too early. Templates have not been applied yet. I suggest doing this once IndexMetadata has been created.
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
`Arrays.asStream(response.pingResponses)` would not materialize it
Consider adding ``` static final NoAuthCredentials NONE = new NoAuthCredentials(); ``` and making the `NoAuthCredentials` `class` package protected (drop `public`). It may not be used enough to warrant having a `static` field hanging around though, but I liked what you did with the original `BasicAuthCredentials` and `EMPTY` before changing it a bit.
good catch on delta > 0
Ah, I see why this is a function ref - so that the `toString` generates the right method to invoke. That feels a little brittle but I understand what is up.
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
cool thanks :)
maybe we should just get rid of this local variable and write the next line: ``` nodesIds = filterNodeIds(clusterState.nodes(), resolveNodes(request, clusterState)); ```
Not needed anymore.
This part I like since it is growing based on the number of aggregator instances, which is not accounted today.
same typo - copy paste probably
This message probably made sense once but it doesn't anymore. I'd suggest `Cannot update the job config because job...`
I think it would be more flexible if the keys were objects? (you could have composite keys, etc.)
`Arrays.toString(paths)` already adds [] , no need to add them
can you undo all indentation changes, it adds noise to the diff
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
same here with removing retry logic
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
oh nevermind, I just found the method that called it with null :)
ok keep it then. I am not sure though what needs to be optional, if the client here, or the service in the parser service. I thought the former, not the latter.
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
As well as the default buffer size
It is to make sure that the version comparison logic orders alphas, betas, and RCs correctly.
I think conceptually this should be QueryParseContext instead, if it needs to do more (toQuery) then we need to figure out how to create the QueryShardContext too out of it, but the other way around seems confusing to me. Sorry I see we are going back and forth on this.
if you use here `refresh();` from the base class we also make sure we get back no failures.
Maybe we should just do the version bump? Technically we don't need to keep disc compatibility with the alphas so something like this isn't required but I like having it for history's sake. Maybe leave a note about what can go in 6, i.e. everything but size_field_type with doc values.
nit: there's already a `.translate()` method, so I would rename this to `translated` or `isTranslated`
typo: filers -> filters
count > 0? just being paranoid :)
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
Just discussed it with Robert and indeed this fsync is not necessary.
Maybe pass the `Executor` in to the ctor instead of `ThreadPool`? You could keep this method so you can still override it in tests to throw.
You could add an assert that it's not ES 7.x here so we know to remove it
I'm not sure this logic is correct... fieldType is mutable right? We should compute a final boolean in the ctor if we need this instead.
max_expansions may still be used along with fuzziness, so it may not be ok to deprecate. Can you double check? This is why splitting MatchQuery would help. It is hard to figure out what happens when.
We should deal with rejections if the executor is closed.
Since "version" and "primary" are used not only here, but below in the `fromXContent`, they may go better in a static `Fields` encapsulation so if they are changed in the future they only have to be changed in one place.
I think we should complain if we don't find the header name.
can we add a note here why this is optional? the validate request suggests otherwise...
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
the == false is done on purpose to make these comparisons more explicit
sorry I meant `org.elasticsearch.common.xcontent.ObjectParser` all the time my fault
I think this'd be more clear if you said something like "invokeStatic assumes that it is not invoking a method on an interface."
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
the generic thread pull should never reject, unless it's shut down. that's it's semantics. I would also vote for a trace log in the raiseNodeDisconnected, but that's another change :) It's just confusing imo if you shut down a cluster and see these messages.
wonder if we should make these Integer and Boolean just int and boolean primite types.
I'm fine with `IllegalArgumentException`, in all the places of course. :smile:
I took a quick stab at sth. that avoids the Tuple and replacing the test builder [here](https://gist.github.com/cbuescher/88531fe7c2abd38936ef), but it still looks a little bit strange to me. EDIT: Doesn't work, equals-tests break with this little hack. Sorry, nevermind.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think we can get rid of this field in the abstract class, as far as I see it can be "term", "completion" or "phrase", those should be the NamedWritable NAME constants in the subclasses, so the superclass won't need to store it anymore.
nit - we flush also it will reduce the size of uncommitted gens but strictly speaking it doesn't mean it will be below the threshold
I thought we said we would move this method to IndexQueryParseService so we can avoid exposing the Client.
`it's` -> `its`
We will need stronger assertions here too.
@markharwood remember to take hash % copies# collisions into account. So if you see two shards being search on the same node, they should have the same hash modulo number of shard copies.
can we name this maybe just `UpdateTask`
Yeah, looking at it again, that makes sense!
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
I think it should either be an `else if` or the `if` should be on the next line.
you don't need do handle queryName yourself anymore, nor boost
Nit: in other places advancing the parser is directly done in the "ensureExpectedToken" call. Saves one line and I think it is equally readable. There's several places in this method where this might be possible, not sure how much lines this saves. Also, if you don't like it, just a matter of tase I think
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
You can get away with it right now because there is only one test, but this should be initialized once before the test suite, not once before each test in the suite.
Besides jokes I see your point on NoOp naming, let's leave empty then, it doesn't convince me 100% but I cannot come up with a better name
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
Change "param required" to "parameters are required"
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
but why? :)
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
I don't think this is correct? Do tests pass? This should fail on unmapped fields.
I'd move this to line above, but I like the thought behind the change.
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
cancel that :) I figured it out.
I am sorry, I didn't think this through. The two sections have the same name, so the json wouldn't even be valid if they were both there. I think we should not check it explicitly, otherwise we would have to do it for every single field in our parsers, which we don't do. Relates to #19614
don't try to fix it, you just moved code around, but this catch block worries me :(
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
This can be outside the try/catch right? If there is a failure to create the pipeline, there is no pipeline to close.
this should be `IOUtils.close(phase1Snapshot, () -> resources.remove(phase1Snapshot))'
I think you should remove the `!` here, throw exception if `failNoIndices` is `true`
good point I am curious too now :) I hadn't noticed this at first
I just think its weird to declare the field expects the value to be an int when actually we are also expecting string values that are not the exact string representation of an int (i.e. cannot be parsed using `Integer.valueOf(String)`). It took me a little while to work out how this worked when I reviewed it so personally I think its worth making the change for code readability.
In these cases its acceptable to use randomize testing's `rarely()` or its like to cover either branch randomly.
I think this is a duplicate of `connect()` above (minus an assertion) although I prefer this name a bit.
cool thanks for clarifying!
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
do we want to unify this code with the refresh method by making this get a manager to work on? (+ a string description for failures)
Could you explain why this needs to be public now? I think we should try to keep this package private if possible
should be `final`
Nit: "seq no" -> "seq_no" (inconsistencies will make searching more difficult)
nit: iff does not need an "otherwise". Either make iff to if or remove Otherwise.
"new" -> "now"
same here just use synchronized methods
yea I think it would be good to have a test that makes sure that the index expression specified in remove_index resolves against indices only, rather than aliases and indices. I don't think the current test does that.
simpler as it decouples these two things. And no need for having this method return a boolean.
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
I think we can simplify this and make sure we have 1 shard, no replicas.
Nit: `accross` -> `across`
I don't think we need this part? Even if you've created an index with 6.4, you still want to be warned that things are going away if you upgrade to 6.5
final and java docs
it's just yet another unmanaged thread in the system..
I think 1/2 + 1 == 1 :)
the ones returned here are the fields that can be shuffled or that should not be shuffled? Not sure if the name is consistent with the behaviour
I'd not do this, just pass syntactically valid values to the Prototype ctor
I wondered if there was something better than iterating too but there's not since `IndexWriter#getLiveCommitData` only returns an `Iterable`.
we may want to rename match_formats as well here, can do in another PR though.
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
this will not get executed as a test if the method does not begin with `test`
s/HashMap<String, Object> fields/Map<String, Object> fields
as we discussed - corruptions can't lead to mapping parsing failures. They fail way earlier when reading from the translogs
we don't want it to be retried... that was the cause of the failure
I'm not sure if this is practical in all cases, but IMO a lambda would work pretty well here: ``` nrReplicasChanged.forEach((fNumberOfReplicas, indices) -> { ```
can we just delegate to `valueOf` and if it throws an exception we return the default? I don't think we should do the linear checks here
we should clearly state that these are the shard of the new index
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
thanks for digging in. i only dug into the aws one and have not looked at the root case of the gce problems. If it involves weakhashmaps, maybe its something easy we can fix for them as well to avoid pain.
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
We can save object creations here by making the ByteArrayDataInput final and using `ByteArrayDataInput.reset`.
just call `parser.text()` instead of `parser.bytes().utf8ToString()` since it might be optimized under the hood
Oh oh! deleteUnderLock should be called when you hold the lock! instead we should use IndicesService.deleteIndexStore
I really like this class since it's so self-contained and has all the tests etc. no weird guice bloat etc. NICE!
no need to make this public; package-visible is good enough.
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
don't prettyprint please we don't test this here
Shouldn't this be equal to the `jsonBuilder().string()` above, without adding `.prettyPrint()`? And a nitpick: please add a space after the comma..
This seems to only be used for tests. Maybe it should be a helper method in the test framework instead of part of the public api? I would be afraid of something accidentally using this in ES code.
can we assert that if we need to generate a new history uuid we always use `*_CREATE_TRANSLOG` as an open mode? that's why we rely on the translog uuid only for trimming purposes (and avoid thinking about what it means to generate a new history uuid)
In my dreams, merging would either throw an exception or return a new independent mapping so that we wouldn't need this validation phase :)
shall we check that we get some results back? Just making sure that we actually search against the alias. If it doesn't exist we could get back empty results without any error...
this is super ugly I think `AsyncShardFetch.Started` and `AsyncShardFetch.Store` should be an impl detail of `GatewayAllocator` no need to bind this or anything
that awfully sounds like two voices for debug.... your turn, @jasontedor.
"now" should be "not"
I think we need additional null checks here. Before the refactoring we only needed to check lucene queries in parse() method for null. Now also their `toQuery()` can potentially return `null` (e.g. if this FilteredQueryBuilder would be nested in itself). Same goes for the filter.
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
This test should assert that the headers are correct.
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
Elasticsearch tradition is to make this an EMPTY constant :)
would be nice to allow to configure it to a percentage of the heap size
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
nit: extra space
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Nit: spacing between `while` and `(`.
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
final and java docs
Optional: darkon has this style that I like where you start a new block every time you startObject or startArray and it makes these much more readable!
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
nit: you can just let the validate throw it's exception - this will fail the test and give us more info
I donât think this buys you anything in terms of concurrency. The list reference is already final.
it's important to log the shard routing of the out of sync shards
new is not possible with an older version...
nit: maxTermFreq must be positive
I believe `ScrollHelper.fetchAllByEntity` already wraps the listener in the client's `threadContext`.
Instead of having this public ctor should we have one that has this signature: ``` Java public CompressedXContent(ToXContent xcontent, XContentType type, Params params) { // do the serialization here with checked output stream etc } ``` that way we can hide the _CRC32_ impl detail entirely
ReflectiveOperationException can be used instead of both of these
I think the less-specific types are better when you can get away with them so that you do not come to rely on implementation details of the concrete type.
I see this was already like this, but this can go on a single line.
Snapshot Name - repository name + snapshot name ;-)
same here, might be that we are good, but let's make sure we don't lose the STRICT one
nit: maxTermFreq must be positive
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
good point, we will once we have the processor that updates them, which is being worked on.
Most likely meant `&&` instead of `&`.
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
how about changing this to `if (upgradesInProgress.decrementAndGet() == 1) {` so we can remove the return statement. I find this easier to read as the action only happens when the in progress value is 1.
same here, all retry logic should be removed
@s1monw if you're proposing we use inheritance and you assume the base class will always be caching DF then we could just remove all the "if(this.docFreq)" checks in the existing code as a simple way to clean things up? That would leave us with just the "if(this.totalTermFreq)" checks.
I think we should separate the two and push this as is. Your code refactoring has more changes than this functional change and on the security end I think we should be careful. let get this in and cleanup the stuff afterwards
same here - I think it's better to log the info message if the deletion was successful.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
formatting should be fixed like the rest in these three lines
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
i think `== true` can be skipped
would you mind adding `<>` after `new PriorityQueue` ? otherwise this is an unchecked assignment.
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
use the constant defined in SnapshotId...
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
why not protect against double closing in the snapshot it self? this is a common problem
let's make sure we deprecate it as well in 2.x
I think the OOM reference was a copy paste error from another clause. This clause doesn't do `translog.newTransientTranslog(translogId);` so no need to revert it - although it seems to do no harm if there is no current transient translog.
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
nit: formatting, add some whitespaces
Fair enough. I know it used to work in previous version but I'm fine with this implementation. And even better it will be consistent with Kibana plugin manager which also checks that `://` exists.
Let's replace the `assertTrue` by more effective matchers, and replace the `assertEquals` by `assertThat(..., equalTo(...))`.
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
We've been moving away from these inner fields classes, we don't need them to encapsulate some strings.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
Can you remove this annotation? It's not needed anymore and this will fail when you'll rebase on master.
Ok I see the problem... I still find this hackish (needing to throw an exception to test things), but there's no easy way around it if we want to test different requests and responses. I'd consider using a mock request (one per client type actually) instead and give up on testing those real requests and responses. It would be more unit test friendly cause you'd know the request and the response you need to return (unless it's a nodes info request), you don't need an exception and you can assert on the sendRequest directly. Using real requests it feels wrong to only test a few of them anyway and we know that it's the client that injects the headers (`execute` method), that's what we need to test.
oh cool the read is in the ctor! nice!
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
I think you don't need to create cache keys and could directly use LeafReader instances as cache keys.
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
can we swap member and constant we know the constant is not null :)
should be aliases
Safe because ~~our~~ we know
This should be `public static <T> PreBuiltCache<T> getCache(CachingStrategy cachingStrategy)`. As a result a few warnings on the caller methods are gone.
we will have to be careful though. If a very short-running method with < 256 calls is timed using this approach, we will have significant overhead from `System.nanoTime()` calls.
This method takes a phrase query and is supposed to create an equivalent phrase query that just has a different value of the slop, so we need to transfer the boost? Maybe the method should look like this now: ``` java private Query applySlop(Query q, int slop) { float boost = 1f; Query underlyingQuery = q; while (underlyingQuery instanceof BoostQuery) { BoostQuery bq = (BoostQuery) underlyingQuery; boost *= bq.getBoost(); underlyingQuery = bq.getQuery(); } if (underlyingQuery instanceof PhraseQuery) { PhraseQuery pq = (PhraseQuery) underlyingQuery; PhraseQuery.Builder builder = new PhraseQuery.Builder(); builder.setSlop(slop); final Term[] terms = pq.getTerms(); final int[] positions = pq.getPositions(); for (int i = 0; i < terms.length; ++i) { builder.add(terms[i], positions[i]); } pq = builder.build(); pq.setBoost(boost); return pq; } else if (underlyingQuery instanceof MultiPhraseQuery) { ((MultiPhraseQuery) underlyingQuery).setSlop(slop); return q; } else { return q; } } ```
please make sure all files closed and no file is leaked.
> but then if that's the case I wonder, how do we test that the setting is not really needed, cause it shouldn't be? :) @javanna imo this should be a pre-release smoke test.
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
wonder if we should make these Integer and Boolean just int and boolean primite types.
this should happen after we update `isSecurityEnabledByTrialVersion`
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
I think that all of these members variables except for `finalResponseListener` can be `private`.
can you leave this class for now, add the same TODO as in the parser? We can't have a parser without a builder in the query-refactoring branch.
not sure, but should we make the location available to java api users too? Transport client is still a thing in 5.x and this way one has to build the location by passing in the routing value. Should the location rather be a field in the response object? Not sure though as it becomes a header in the final rest response. maybe it's ok this way.
I think you want (soft)deleted
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
I think it's better to use the index version created to test whether the old or the new parent join should be used. This way you can make sure that the correct explanation is returned in the exception if the parent field is not filled.
this is not needed. createIndex automatically reroutes.
I'm on the fence regarding this one - on one hand it's a public api and people can do whatever with it so you don't want them to slow down the release of the lock. On the other hand as an API it is really weird to have `POST_RECOVERY` come in after `STARTED` (which may happen if the shard is allocated on master - though the chance is still very small)... will think more.
These are not the only exceptions that can be thrown. There a bunch of situations in which an `IOException` can be thrown. It's probably worth changing the signature to reflect this too.
Typo, finalzlie -> finalize
Thanks for the clarification @nik9000.
I think it is important to keep different classes on the client-side so that we can have more type safety and potentially add some methods to only eg. avg in the future
this might also be called I think
> extending AbstractQueryBuilder does it for you Awesome!
I am starting to see that the default boost doesn't get printed out but other default fields do. Makes sense to me but maybe we want to be consistent? I think we should have this a separate discussion, make some decision and do the same everywhere (I have the feeling we are not yet settled yet on one way or another)
All our tests currently use `RandomizedTest#atLeast` method, you can do the same here.
index's toString gives you '[index_name]' no need for '[{}]'
can we use `== false` instead of `!` it's so much easier to read and burned my fingers too often
I think this is okay though, it checks if the current `zeroTermsQuery` is the same as the default, which is ZeroTermsQuery.NONE.
ok now i can see that it is null when removing the task, sorry for the noise
can this be final
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
Besides jokes I see your point on NoOp naming, let's leave empty then, it doesn't convince me 100% but I cannot come up with a better name
I'm not sure if the cast is worth it here. It is usually simpler to just work in integers even if we know if can't be more than 255.
we may want to rename match_formats as well here, can do in another PR though.
This could be collapsed into the previous `if` statement: ``` java if ((searchResponse.getShardFailures() != null && searchResponse.getShardFailures().length > 0) || searchResponse.isTimedOut()) { .... } ```
should be clause.getOccur() == SHOULD
I don't like leniency. Can it be `"true"`, `"false"` or `null` with the former parsing to the right `boolean` and null giving the default? A typo of `"tru"` will parse to `false` and that makes me :cry:.
nit: we almost never use `Locale.US` exept for some number formating. While I think it doesn't make a difference for the enum names in question here, I'd suggest going with `Locale.ROOT`
indicesDeleted doesn't check for indexUUIDs. We have a separate method for it in this class `cleanMismatchedIndexUUIDs` - in this spirit of bringing all deletion code together - I think it's good to make indicesDelete aware of UUID switches (mark old as deleted), move the `applyDeletedIndices` to be executed where `cleanMismatchedIndexUUIDs` is called now and then we can remove `cleanMismatchedIndexUUIDs` make all go through here.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
I wonder if we should make this a hard exception, potentially in the AllocationId constructor. When we start using this ID, a null value will create havoc in other places and will be hard to debug..
do we really need to walk these directories, can we just do what `getFSInfoIgnoringQuota` does? I really don't think we should walk the direcotries
Missing the `indexName` argument to the debug log here
> There are people in the team that prefer it this way rather than having a random timeout on the latch Then I guess I'm fine with it, it just made failing tests hang locally for me for quiet a while (I guess there are some hard timeouts after all).
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
at that point you want have a read budget, which I mentioned above.
should we catch exceptions here to make sure we cancel everything we need
You could probably avoid this by making the linux check a method that you stub out in OsProbe.
oh cool the read is in the ctor! nice!
Not 100% sure of the rules here, but `private` seems too restricted for this.
Why is this `volatile`? It doesn't look necessary to me.
this could be a for each loop instead
I see, yea we can't avoid this then. Maybe share the default value through a constant so at least we don't duplicate it. Odd! :)
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
and -> an
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
should say shard active
I think we can share this line and the return new BulkItemRequest line? these two clauses will need to set a final `updateResponse` field.
please use Arrays.asList while we re here
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
We shouldn't need to log if we through an exception. I don't like the hard cutover but I can live with it. If I discount the hard cutover my only thing is the exception message.
same note as in the json processor PR.
yea I think it would be good to have a test that makes sure that the index expression specified in remove_index resolves against indices only, rather than aliases and indices. I don't think the current test does that.
fancy pants :)
yeah nevermind I was confused about some internal classes
nice one. Good to add.
I think 0 is a good minimum value.
I think this is a sign that `getActionFilters` maybe should take `ThreadPool` as an argument.
Whoops, you already did, ignore this!
I think adding a constant somewhere for # makes sense. It may make sense to also add a constant for typed_keys, but I don't have a strong opinion on that.
I think this can be combined into LoadedPlugin, adding the ClassLoader there.
I think we can better call this in the Store.OnCloseListener.afterIndexClosed(). Feels cleaner to call this once we think all shards have bee removed.
You could make it the same with an `else if` instead of `else`: ``` } else if (theAnalyzer != null) { builder.searchAnalyzer(theAnalyzer); } ```
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
Since you don't care about the body of the source maybe use something like `setSource("foo", "bar")`.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
ahh yeah in `assertAfterTest()` nevermind
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
nit: space after the second percent sign (on all these lines)
`.addPathPartAsIs("_xpack", "rollup", "job")`
I'm fairly sure I have the wrong generics incantation there....
+1 to capture `System.nanoTime()` at the beginning of the method
otherwise, if you want it for testing, it can be done once in the ctor
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
Does this message go back to the end user? If so the fact that a map must be empty is more of an implementation detail than an meaningful error message for the end user. Something like "Mapping definition for field X has unsupported parameters: foo, bar" would be more appropriate.
Let's replace the `assertTrue` by more effective matchers, and replace the `assertEquals` by `assertThat(..., equalTo(...))`.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
maybe make if final
We can leave `API` out of the test name.
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
++ thanks for adding these checks
yeah that is what I figured!
waitForyellow can go away...
I wonder about the cases where this can happen as the `close` method on `InternalTestCluster` that calls `shutdown` on the executor is synchronized (same as this method). Have you observed this exception being thrown? If we don't expect this to occur under normal operations, I would prefer not to swallow the exception here.
given that the request goes through validate first, I think we could remove this assertion, this is already checked in as part of validate which will throw an error otherwise.
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
And it looks like you cover the response below. So you can ignore this.
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
++ to this pattern
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
Do we need this on this one? It seems like these test suites are very small and any of them taking 40 minutes is grounds for making someone look at the VM at a minimum.
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
Perfect! Thank you.
just because it seems like it's used only internally, that's it. No strong opinions though ;)
where is this method used? I can't find it
it will also give a chance to the AssertingIndexSearcher to perform additional checks
This is true. The alternative way I was thinking about would be to pull a terms enum from the sorted set doc values, and set bits in the bit set based on the hash of the values rather than their ordinal. This way, the partitioning would be based on the value but the terms aggregation would still be able to leverage ordinals to do the bucketing. The drawback is that it requires to compute a hash on every term of the field.
maybe we should have a constant for it
new is not possible with an older version...
This should check `isSecurityEnabled`. The other methods like isAuthAllowed do not take into account the default distribution behavior where security is disabled with a new trial license unless it is explicitly enabled.
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
This exception will be treated as ignore replica exception. :wink:
minor nit: "for" -> "on"
remove the setBoost
`com.sun.glass.ui.Size` appears to be unused.
I'd supply a lambda, yeah.
To avoid this getting out-of-sync in the future, it would be nice to use `PARENT_TYPE_FIELD.getPreferredName()` instead of hard-coding `parent_type`. The same idea applies to `query` below.
I liked the assertion you had there that if already have a result, this one has a higher seq no
I think this assumption is pretty broken. What if the type is `null`? We don't define any order in the types when they are specified in the URL but this code assume that there is an order. I think we have to make this explicit which type should be used.
this could lead to NPE if from the java api no set call is performed
Can we return 0 when the value count is 0 to be consistent with the singe-value case, or throw a proper exception? I am concerned this code could raise a weird error message otherwise.
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
I am not sure whether the log message is too specific, i.e. the subclass must not necessarily be a service.
If it is relevant for String impls then I don't see why it should not also apply in the long impl.
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
I mean in the code but just noticed there was one already
same here: no need for the [].
I think we can now remove this condition as the client can not be null because we throw now `new ElasticsearchException("Unable to configure Azure compute service", e);` in the CTOR
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
You are already in `ESRestTestCase` so you don't need the to reference the class.
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
can we just `return new BytesRef()` in this case? I don't know if the text characters are null if we can really rely on text offset and length? Maybe a better check, not relying on null check is: ``` if (parser.getTextLength() == 0) { return new BytesRef(); } ```
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
> If we felt like testing fromXContent without SearchModule we could implement a super easy mock implementation That we can easily do with a little registry too I think? fromXContent won't depend on SearchModule anyway, that is the point of having a separate registry for only the pieces that fromXContent needs (registered score functions). In the end there isn't a huge difference between the two solutions. there is and will be a lookup method somewhere, but instead of being a method reference as argument, it will be an explicit registry. I find it more readable this way, but I do get how this is just a matter of opinions.
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
Yeah, I checked https://github.com/torvalds/linux/blob/9705596d08ac87c18aee32cc97f2783b7d14624e/include/uapi/asm-generic/unistd.h and they all look right to me.
Can we call this just `score`? I've been trying to give the script context identifiers names that don't include "script" since that is implicit.
thinking out loud, maybe I am getting confused, but in order for a field to get highlighted, doesn't it need to be stored too or we need to have the _source at least? but metadata fields, which match `*` are not part of the `_source` hence they need to be stored or excluded from highlighting by definition. I have the feeling we should do something more to address that...
More indentation that is hard for me to read.
I don't think the compile script should be stashed here. Instead, just check that the script can be resolved with the script service (don't just check inline; for example, it would then also ensure if they use a file script it exists).
same here, just `this.charFilters.add(new NameOrDefinition(charFilter));`
this can only be a runtime exception you can just bubble it up no need to use `convertToRuntime`
Nit: please add spaces after the `if` and before the `{`.
I think we should move this above the nodeChannels.close() so it will be logged before an eventual consequence.
is this always used in an assertBusy context? wonder if we should add it here. This can be suprising...
Construction now loses the side effect of a `NullPointerException` when this class is misused by giving `null` values for everything except `sourcePath`, which could lead to new, unexpected `NullPointerException`s upon use.
can we maybe try to trigger this differently? I mean can we for instance try to call `#available()` or can we maybe read the first byte on open and wrap in a `BufferedInputStream` and then do this: ```Java InputStream stream = is.isMarkSupported() ? is : new BufferedInputStream(is); // do the following in doPrivileged? stream.mark(1); stream.skip(1); stream.reset(); return stream; ```
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
use simpler constructor.
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
I'd also like a test for the case that either a single bound or none of the bounds are specified (even if that means checking that an exception is thrown depending on the decision we make).
would it make sense to add this nice iterator to core? the ingest plugin could reuse it in this case.
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
I think this should throw IAE if you pass null - that's 100% of the time a bug
s/to list of/to the list of/
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
shall we test POSITIVE_INFINITY too? seems like we return null for that too but the default value once parsed is only one...
This assumes a version format that while fairly standard is not guaranteed.
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
I think this method is not quite right yet. A few observations: - if (unassigned) primary, then finalExplanation / finalDecision should be influenced by staleness of copy. In case of a replica, however, staleness does not influence allocation decision. - if replica, then we can still show that store copy is corrupt / has an io / error without influencing final decision / explanation - for the primary / replica shard allocator, corrupt / io_error is treated as no data. I think we can first calculate store copy (which just represents the status on disk) and then influence finalExpl / finalDecision based on that. Here is my go at it: ``` public static NodeExplanation calculateNodeExplanation(ShardRouting shard, DiscoveryNode node, Decision nodeDecision, Float nodeWeight, IndicesShardStoresResponse.StoreStatus storeStatus, String assignedNodeId, Set<String> activeAllocationIds) { final StoreCopy storeCopy; if (storeStatus == null) { // No copies of the data storeCopy = StoreCopy.NONE; } else { final Throwable storeErr = storeStatus.getStoreException(); if (storeErr != null) { if (ExceptionsHelper.unwrapCause(storeErr) instanceof CorruptIndexException) { storeCopy = StoreCopy.CORRUPT; } else { storeCopy = StoreCopy.IO_ERROR; } } else if (activeAllocationIds.isEmpty()) { // The ids are only empty if dealing with a legacy index // TODO: fetch the shard state versions and display here? storeCopy = StoreCopy.UNKNOWN; } else if (activeAllocationIds.contains(storeStatus.getAllocationId())) { storeCopy = StoreCopy.AVAILABLE; } else { // Otherwise, this is a stale copy of the data (allocation ids don't match) storeCopy = StoreCopy.STALE; } } final FinalDecision finalDecision; final String finalExplanation; if (node.getId().equals(assignedNodeId)) { finalDecision = FinalDecision.ALREADY_ASSIGNED; finalExplanation = "the shard is already assigned to this node"; } else if (shard.primary() && shard.unassigned() && storeCopy == StoreCopy.STALE) { finalExplanation = "the copy of the shard is stale, allocation ids do not match"; finalDecision = FinalDecision.NO; } else { if (nodeDecision.type() == Decision.Type.NO) { finalDecision = FinalDecision.NO; finalExplanation = "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision"; } else { finalDecision = FinalDecision.YES; if (storeCopy == StoreCopy.AVAILABLE) { finalExplanation = "the shard can be assigned and the node contains a valid copy of the shard data"; } else { finalExplanation = "the shard can be assigned"; } } } return new NodeExplanation(node, nodeDecision, nodeWeight, storeStatus, finalDecision, finalExplanation, storeCopy); } ```
oh oh I hadn't read your reply when I replied ;)
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
I can push the change if you don't have it ready yet.
and 2 more occurrences below
I think this assertion should be in `getAnyNodeExcept()` - it's ok to return an empty list here.
then do something like this `source[n/a max source size: ...`
index's toString gives you '[index_name]' no need for '[{}]'
Oh I see, it's the ZTable stuff. Sorry for the noise :)
This test is not really testing what we want to be testing here. The reason that it's not is because the cache key for a file named `".hidden_file"` is not `"hidden_file"`, but rather it is `""`. A file named `".hidden_file"` never would have been processed by the compilation engine because it doesn't have an extension. So this will ultimately throw, but not for the right reason.
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
can we call the latch in a finally block just to be absolutely sure
I mean to say that I think you can just call `Strings#toString`.
I get that, I was just wondering why those default templates bother here
well.. as I said, **IMO** the separation is cleaner. But if you keep the prototype way, you'll eventually need to keep the current `build()` method and introduce a new `Processor build(Map)` method **next** to it... it's a bit messy tbh... the same applies to the `Pipeline.Builder`. Another option is leave things as they are (so leave the current `void fromMap(Map)` method) and then introduce a factory to a builder... however you look at it, we need a factory somewhere... a construct that is registered by "type" that can create the appropriate builder/processor for that type... something along the lines of: ``` Processor.Builder builder = registry.get("type").create(); ``` Another option is to mandate all builders to have an empty ctor and use reflection to create those. So instead of injecting a set of builders, you'd work with a set of builder classes and then the code will just create new instances using reflection on default ctor.
I like including the original size here. Maybe instead if the source is chopped it should read like `first 2048 characters out of 10122123: _slice_of_the_source_`.
space missing before `new Named...`
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
The shapeFieldMapper seems unused here.
Good point, I forgot about the pretty printing. `equalToIgnoringWhiteSpace` sounds good.
> I don't have a strong opinion on this one either way I do because less code that is easy to understand is easier to maintain than more code. ð¼
`this` is unnecessary
here you may be able to use copyCurrentStructure
can the aid matching be the implementation and the rest just assertions ? it should be enough
I think that `node);` fits in the previous line
minor semantic difference: over [here](https://github.com/s1monw/elasticsearch/blob/fix_recovery_finalization/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java#L304) we throw the unwrapped corruption exception, not the remote version. I think we should do the same here and throw corruptIndexException
no utils for this :( `out.writeLongArray()` maybe :)
maybe like this: ``` Java try { IOUtils.close(() -> processes.stream().map(s -> (Closeable)s::destroy).iterator()); } finally { processes.clear(); } ```
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
even though this is just `debug`, logging an encryption key is worrisome
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
Please fix identation.
no i do not. but this IDE cannot compromise the actual build, which is 'gradle check'. changing tests.seed in this way can compromise the build, because then the values for other things looking for this (such as lucene) depends on class initialization order.
I think we should remove all these boolean and pass an set of flags as a vararg... It becomes less and less readable (not in this PR)
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
why do you pass the response to this method? `this` already has all information.
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
here too, sorry :)
This logging statement has a `[{}]` but no argument to fill it
At this point I don't know that `@param` adds anything either.
import not needed.
good point! I think we need to iterate over the filterFunctionBuilders and rewrite their corresponding filters
would you mind reverting the variable name change, at least temporarily? it confuses the review
Or do it as a direct followup, I suppose.
same here, might be that we are good, but let's make sure we don't lose the STRICT one
nit: space before brackets
As far as I understand in the REST layer, we don't print out any index for which there are no aliases to return, but only in case the alias (name) parameter was provided.(https://github.com/elastic/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/rest/action/admin/indices/RestGetAliasesAction.java#L139). I believe this change tries to mimic the same behaviour for the transport client, but in the REST layer we don't look at what the name parameter matches, only at whether it's provided or not: ``` curl localhost:9200/_alias?pretty { "index2" : { "aliases" : { } }, "index" : { "aliases" : { "alias" : { } } } } curl localhost:9200/_alias/_all?pretty { "index" : { "aliases" : { "alias" : { } } } } ``` That may be right or wrong, but I think we should try to return the same results if we make this change, so I'd say without changing the behaviour at REST (although we may want to discuss what the right thing to do is) the best we can do at transport is to only look at whether any specific alias was requested rather than whether the expression matched all or not. Furthermore, I'd expect that once these changes are made to `MetaData`, the REST action should be updated as some logic can be removed? By the way, related but it should not affect this PR, there's also #28799 under review that is moving the REST logic to the transport layer, yet the REST logic remains in `GetAliasesResponse#toXContent` which doesn't change what the transport client returns. I would probably consider renaming the `AliasesRequest#aliases` method (to `replaceAliases`?) and make sure that it's only used internally (although it needs to be public), and have users call the current setter. We clearly can't have both call the same method or we lose information about what was set in the first place. That would make it possible to keep track of whether specific aliases were requested or not through a flag, similarly to what you do now.
I think this message might be misleading.
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
I think we should fix our datastrucuture first and don't make Path trie super complicated and flexible. This should be fixed first before we make this change here.
I am not sure why you changed this.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
see text from other suggestion for empty primary allocation
Here it still says `on a per index basis` -> should be corrected.
Looks good. Thanks :)
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
Same here. It might be better to make this `TRACE`.
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
As this setting should usually be only set once, it is probably simpler to leave it non-dynamic (as @jasontedor suggested and as it was before this PR). In case where this must absolutely be updated on a production cluster, rolling restart (of master nodes) with config update is always possible.
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
use a try-with resources for the parser value
A question out of curiosity: the analyzer we get here doesn't have to be closed (via closeAnalyzer) because its not a new instance? I don't know enough about the lifecycle of these objects yet I'm afraid.
There is actually a [standard](http://checkstyle.sourceforge.net/config_modifier.html) for this if you particularly enjoy standards.
yeah nevermind I was confused about some internal classes
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
since we catch throwable I think you can scratch the `success` thing and just do the `latch.countDown();` in there? sorry I could have realised that earlier :)
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
Can we get back to this once we need this complexity and keep it as simple as possible for now please? Can we hardcode the OBJECT_FIELD_NAME exclusion and be done with it? queries also have access to individual field names if they need that.
we can make this catch throwable and remove the catch from https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/rest/RestController.java#L175
I wonder about the cases where this can happen as the `close` method on `InternalTestCluster` that calls `shutdown` on the executor is synchronized (same as this method). Have you observed this exception being thrown? If we don't expect this to occur under normal operations, I would prefer not to swallow the exception here.
I wonder if this case distinction should be part of ReplicatedOperation.
just initialize it and make it final - it just compliicates the code
++ to talking this through but to put it out there, what I am thinking is that we re-build the user after the lookup. For this case we have PkiUser and LookedUpUser. The final user will be the combination of the PkiUser's metadata, the LookedUpUser's metadata, and the LookedUpUser's roles. The looked up user's metadata would trump the PkiUser's metadata in case of a conflict. This does get trickier when you do this in an AD/LDAP realm since some of the metadata comes from the group resolution. In that case, I would only include the metadata that does not involve group resolution from the authenticating realm.
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
Just a question: would it be possible to extend from `LongFieldMapper`? Would be nice to have some code reuse.
Is this done already? Maybe specify what "sanity checks" means otherwise.
it would be awesome to have some doc-strings on these settings
close is supposed to clear as well so this shouldn't be necessary to call clearReleasables
Here you can do something like this: ```diff diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java index 356b9a29dc..36794e880f 100644 --- a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java +++ b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java @@ -65,9 +65,11 @@ public class PublishClusterStateStats implements Writeable, ToXContentObject { @Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException { builder.startObject("published_cluster_states"); - builder.field("full_states", fullClusterStateReceivedCount); - builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); - builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + { + builder.field("full_states", fullClusterStateReceivedCount); + builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); + builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + } builder.endObject(); return builder; } ``` which makes the JSON-structure clearer in the code.
maybe just push the `maxUnsafeAutoIdTimestamp` up to engine and make the methods final
do we want to unify this code with the refresh method by making this get a manager to work on? (+ a string description for failures)
ok fair enough
while we are at it, can we move this log to debug? its very noisy and it can happen with join retry logic
Probably should also be getAssignedNodeId.
NIT: Noisy reformatting
But yeah, keep it now.
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
I think we should stick to the current validate api for now, although it does feel weird that we don't actually throw exception. What happens is that the listener gets notified of the exception in `TransportAction#execute`. We can't yet hook into the validate mechanism as the `SearchRequest` only contains a `source` bytes array in json format, but at the end of the refactoring we should have different elements that hold the different parts of a search request, among which the query which can be validated as part of `SearchRequest#validate`. This is to me the only way to make sure that validation happens whenever needed.
we can delete ForceMergeFailedEngineException now, right? It's not used.
Right - RollupIT is the right place
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
Space missing between `}` and `is`.
those are hard to debug I can tell u :dancers:
Sorry, I overlooked the null check. This is good!
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
I'd have added an integer to `TypeParser` and sorted them by the integer resolving same integers alphabetically or something. And set the FieldNamesFieldMapper to MAXINT. But I think what you did here is ultimately simpler.
please ignore - misread the constructor - seems like a null is a valid value.
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
ok, i see it. Its just a little non-obvious due to the way searchers are bubbled up. maybe we can add an assert in the future.
What about : ``` json "retries": { "bulk": 0, "search": 0, } ``` Note: I tend to like JSON inner objects since clients and parsers can skip whole objects while parsing...
I think this message might be misleading.
could be a instance variable, as used in all tests
Maybe it always should have been....
Can you shrink-wrap this try clause? (Pull the `map.put` out after it.)
I think this check should go into initializeSnapshot or repository.
This might read better if it were renamed to `hasRun` initialized with false and then it could be ``` java if (hasRun.compareAndSet(false, true)) { prepareBulkRequest.run(); } ```
I'd return an Immutable set... it enforce compilation failure when used inappropriately (if the user tries to mutate the set)
maybe add an explicit `continue;` here to indicate that it's being skipped
"if if" again
Ok great, thanks for the correction @rjernst
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
can you also add ``` @Override public Decision canForceAllocatePrimary(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) { assert shardRouting.primary() : "must not call canForceAllocatePrimary on a non-primary shard " + shardRouting; return canAllocate(shardRouting, node, allocation); } ``` as this is a hard constraint with no exceptions
I think that these log parameters are backwards.
And i just did not have the time to yet yesterday remove the stupid asserts from SpanScorer. Please, lets not drag this stuff in again. If oyu want to push fine, but you will see a second push from me removing all this crap.
Let's use `assertThat(..., equalTo(...))`.
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
oh oh I hadn't read your reply when I replied ;)
I would be more precise on the version, cause it's not clear if it is from 1.5.1 or 1.6.0.
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
nit: extra line
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
I don't think "Not implemented yet" adds anything other the exception type (and could be misleading if we never intend to implement).
ð to this escape hatch
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
got it. Thanks.
Why do we need getters? These are all final and immutable
It should say greater than zero, 0 is not permitted.
maybe just `return blobMetaData.length() == fileInfo.length();`
In fact, it should probably say something like `Remove the plugin specified by {@code pluginName}.`
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
I find the boolean condition quite hard to read, maybe negate the whole logic to get rid of all this weird `&&` and `== false`: ``` if (newPrimary.unassigned() || newPrimary.isSameAllocation(oldPrimary) || (oldPrimary.relocating() && newPrimary.isRelocationTargetOf(oldPrimary))) { // same primary term } else { // incrementing the primary term ... } `` ```
can we rename this to shouldIgnoreNewClusterState? it's not only about being dated.
I think this check should go into initializeSnapshot or repository.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
can we use `== false` instead of `!`
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
+1 to throwing the exception.
I think 0 is a good minimum value.
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
marks the shard store
ð much better readable
No, you are right, I didn't realize the need for api users before going through the whole changes.
maybe also test a nested conditional setup? (So have conditional and then another conditional in the matched or unmatched list)
if you do not supply the the content-type, you can just hand over the builder and do not need to create a string object here. Also I would just return `JSON is disabled` instead of mentioning the config option here. The shorter the better IMO.
We can't safely say that all such exceptions will extend `ElasticsearchException` (e.g., a bad `NullPointerException`), but I like your idea of wrapping the ones that do not extend (as long as it's not wrapping it in an exception that sounds like the user can do something about it).
Below is what I get when I try it out. As you can see that log message is drowned in many other log messages that don't mention the index name. A lot of this is guice and we're working on fixing it, but I think the easiest is to make sure that the index name is mentioned in the exception for now? people won't see it otherwise. ``` [2016-11-03T00:08:29,112][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... a terminal screen worth of stack trace here ... Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] .... [2016-11-03T00:08:29,144][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,146][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal screen worth of output [2016-11-03T00:08:29,161][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,161][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.archiveBrokenIndexSettings(MetaDataIndexUpgradeService.java:171) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:81) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] [2016-11-03T00:08:29,229][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main] org.elasticsearch.bootstrap.StartupException: org.elasticsearch.common.inject.CreationException: Guice creation errors: 1) Error injecting constructor, java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] <--- THESE IS REPEATED 4 times at org.elasticsearch.gateway.GatewayMetaState.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayMetaState for parameter 4 at org.elasticsearch.gateway.GatewayService.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayService ... another terminal, this time full of guice information Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) at org.elasticsearch.common.settings.Setting$$Lambda$183/2092885124.apply(Unknown Source) at org.elasticsearch.common.settings.Setting.get(Setting.java:312) at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:525) ... 47 more And this ^^^ is the last message on the screen. ```
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
I think we want to assert here that lastRequestedSeqno is the global checkpoint
save -> safe
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
if we use millis then we really should make sure that time doesn't go backwards!
`curWrnHeaderSize` -> `currentWarningHeaderSize`
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
could be a instance variable, as used in all tests
does this need to be public and also does this class need to be subclassable
Could you make the reduction create a new aggregation instead of filling the first one? This proved to be error-prone in the past.
`seqno` -> `_seq_no`
nevermind I see it was already there, then it should be ok
Please do not drop stack traces; `Throwable#getMessage` is an abomination.
typo: dictionnary -> dictionary
fair enough, leave it.
You are already in `ESRestTestCase` so you don't need the to reference the class.
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
I think it can be even less in tests. No one is worried about sending multiple requests there.
this curly bracket should be on the previous line
we can pass along a reason to persistence to be used as writeReason
s/payload is/payloads are
Nit: `reject` -> `rejected`
oh, the boxing horrors :)
++ to talking this through but to put it out there, what I am thinking is that we re-build the user after the lookup. For this case we have PkiUser and LookedUpUser. The final user will be the combination of the PkiUser's metadata, the LookedUpUser's metadata, and the LookedUpUser's roles. The looked up user's metadata would trump the PkiUser's metadata in case of a conflict. This does get trickier when you do this in an AD/LDAP realm since some of the metadata comes from the group resolution. In that case, I would only include the metadata that does not involve group resolution from the authenticating realm.
ok can we rename the getter then to `getFailedNodeExceptions()`
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
I think a nicer approach (can be a follow-up done by me) would be not to call `updateGlobalCheckpointOnReplica` here, but instead call ``` globalCheckpointTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED); ``` either here or in the IndexShard constructor (where we create the GlobalCheckpointTracker) when the recovery source is EMPTY_STORE.
I don't see NO_MORE_DOCS changing in the future. I don't dislike having NO_MORE_DOCS=MAX_VALUE, it makes the sequences of integers returned by DocIdSetIterator monotonic from -1 (not started) to MAX_VALUE (exhausted) :)
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
we should make this entire class package private and try to contain visibility here as well.
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
Nit: `"call back"` -> `"callback"`
`if (serializedStates != null) {` is no longer needed
`it's` -> `its`
Same here, I think List is already initialized in L51.
I think that makes sense. Otherwise we may throw an index not found exception if the index patterns the user is interested in does not yet exist.
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
+1 then we shouldn't forget about it :)
Should we initialize indexBoosts to new ArrayList<>() straight-away instead and remove this null invariant? This if would go away too.
I think we discussed this before, but it didn't change, thus I'm bringing it up again ;) can we add a constructor that accepts `shardInfo` as argument and change the subclasses constructors to accept it there, just to enforce that this info is needed so we don't forget it anywhere. Maybe then we could also remove the setter...
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
is it an option to make this method package private? Then it would become more of an internal thing. Thanks for addressing this!
I think it'd be nice to have this in :test:framework so others can use it.
I guess it could be renamed to isFalse() / isTrue() now
Needs a guard.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
Throw the exception here
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
count > 0? just being paranoid :)
maybe put this check before the primaryTerm check
maybe call this "resolveSnapshotNames"? I would also prefer to use `List<String> snapshotNames` as parameter to bring it closer to the return type.
`s/Class<C>/Class<? extends C>/`
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
thanks for checking, that is fine then
I think checking for newline is better than relying on pretty printing having space between key/object...
This one also uses a Java 9 method.
do we need this Reader interface? can't this just be `Funciton<StreamInput, T> reader`
just my personal preference, I don't like instanceof checks that's it. you are free to leave them if you prefer them ;)
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
we should include `e` here, otherwise we lose the cause of the configuration error.
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
I prefer my way but have asked @jasontedor to chime in.
can we have two static helpers that allow to create the processor either providing the Client or the RestHighLevelClient ? I am thinking of users, there are many existing usages of BulkProcessor out there. I may be ok to change the way it gets created, but as a user I would be surprised to have to pass in a method reference. That should be more of an implementation detail.
we could pass a glob with regex:xxx to newDirectoryStream if we want
I dont have a good answer for this yet. While we can totally test this, the value in the server -> client.fromXContent is greater than just testing the client.toXContent -> client.fromXContent. I think these kinds of tests are not really providing much value, and we also test the former in the IT tests.
- do we need to `new`-up a distinct `SSEAwsKeyManagementParams` each time `S3BlobStore#getSSEAwsKey()` is sent? Can we instead `new`-up one in the constructor (e.g., is `SSEAwsKeyManagementParams` externally mutable?) - from what I can tell, this and `S3BlobStore#serverSideEncryptionKey()` can be _package-private_; exposing public accessors on encryption keys is unnecessarily risky.
Gotcha, thanks for the explanation!
I'm fine with leaving it, yeah. I did want a prettier one but if this is what we can do, it'll do.
Actually I just checked and removing name and description from the Plugin interface should be easy. The only thing to think about is what to give for those properties when plugins are loaded from the classpath (plugin.types). I think here the name should just be the classname, and description something like "plugin loaded from classpath"? I don't know what other info we really have.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
I would add an `assert this.context != null` here just to make sure
I'm not a big fan of ActionListener<Void>? Maybe we can do this differently and replace it with two functions? Runnable for the onResponse() part and for onFailure use a Consumer.
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
nit: `an` -> `a`
here too, toQuery might return null, not sure what happens
s/to list of/to the list of/
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
this smells like it should be a setting validation thing. Testing for this so deep, on every request without throwing exceptions feels wrong.
is this a leftover? I don't see where this is used outside of tests? and even there I think it's a huge overkill. Can we please remove this entirely. If you really need stuff like this for testing then look at `ThreadContext#setTransient` which you get from a threadpool
I think I miss something here because I think we need it for now but not in the future after we have a Lucene rollback. I will reach out to discuss this.
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
Indeed, I think two BytesReference instances should be considered equal if they have the same content (which is what the way other children of BytesReference are implemented suggests). My point was this path of the equals method ignores the offset of `other` (it starts comparing its bytes at `0` instead of `other.offset`.
Maybe something like: The bucket can "overflow", in which case the excess capacity is just "spilled", rather than saved up. So it never holds more than a minute's capacity.
same here - since we have on onFailure handler, calling is the equivalent of re-throwing the exception, imo.
can this also be `IndexingOperationListener... listeners` please
I mean random number of replicas with random combination of non-active states
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
I think we _do_ need to consider BWC for these lists. If you look at the implementation of `readList()` and `writeList()` they start by reading/writing the list length. So we need to write an empty list to versions before 6.5, and read a list of something. We can replace `PartitionScore::new` with a function in `Bucket` that reads the same stuff that `PartitionScore::new` read but just discards it.
one too many whitespace between List<C> and the method name
yes I would at this point. it's a remote connection to another cluster that may be at a different location etc.
we should assert this is never called (same for the other places here where `UnsupportedOperationException` is thrown), as this indicates a bug.
Pls be sure this is not null. Other converters do a null check and return and give this `addCommaSeparatedPathParts` a empty array if need be. check `forceMerge` for an example
the dollar sign option :)
In the other tests that are migrated to use Zen2 we set this to `true` (i.e. we are not testing the Zen1 case any more). I think that's what we want to do here too, but in any case we should be consistent about this.
People don't know what archiving setting means. They just upgrade and their end up in an illegal state. I think it will be cleared not to mention the "can't be archived" part. But as said - just a nit, not a big deal.
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
To be clear - I think we want to know how the oldest file is, regardless of the generations. It will always be the oldest generation and the first in the reader list, but I don't think we want to rely on it. Part of the role of the stats is to validate things are correct.
this one ends up sending parameters that are getting ignored, see `IndicesOptions.fromMap`. we should remove the last three parameters. This should be cleaned up, the problem is that some indices options are settable at REST, while some other are internal properties that define each API (the default argument in `fromMap`) which cannot be changed, so they should never be printed out nor parsed back.
I'm okay with `foo.backup`. It would also not be hidden from non-Windows users by default.
I _think_ that you can get away with just letting the exception bubble up and RestController will send it to the user. You won't get the error log but I'm not sure logging an error on 400 level parse errors is a good thing in the long run anyway. I try to usually run requests with `error_trace` on them so we don't eat the stack trace....
nit: can you assign `event.state()` to a local var
Also, you dont necessarily have to change this but you can now replace `.execute.actionGet();` with just `.get();`
+1 on the closed indices use case. Good catch. I'm not sure it has effect now. Did some sniffing and we close the shards in too many places upon index close. First place in `IndicesClusterStateService.applyDeletedShards`, then we have another iteration in the beginning of `IndicesClusterStateService.applyCleanedIndices` : ``` for (IndexService indexService : indicesService) { String index = indexService.index().getName(); IndexMetaData indexMetaData = event.state().metaData().index(index); if (indexMetaData != null && indexMetaData.state() == IndexMetaData.State.CLOSE) { for (Integer shardId : indexService.shardIds()) { logger.debug("[{}][{}] removing shard (index is closed)", index, shardId); try { indexService.removeShard(shardId, "removing shard (index is closed)"); } catch (Throwable e) { logger.warn("[{}] failed to remove shard (index is closed)", e, index); } } } } ``` and only then we do `indicesService.removeIndex(index, reason);` which closes the index (but it has no shards any more..)
if the argument name is `failNoIndices` you should provide `! indicesOptions.allowNoIndices()` as argument
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I like this much better!
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
can we init this with `1`
index's toString gives you '[index_name]' no need for '[{}]'
I think this should be done via IndexShard#failShard (which can be exposed via indexShardReference ). Will be cleaner and faster (it's local fail first, then notify the master)
Looks like there isn't an ExecutebleScript equivalent for search scripts anyway - ignore this.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
I'm confused because I thought you were implying there are cluster level tasks always running in the background, that are simply part of the cluster operating normally. A leak is a leak, and we should catch and reject it.
Again, putting the unit in the name would help here, unless someone reads the docs they can't tell whether it's millis or nanos
we should soften the language here. We can return before these are active (with a time out flag))
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
nit: we can check the expected token and then create the searchProfileResults map
you are right, sorry
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
We can remove the `!` if we reverse this if statement, so ```java if (difference.isEmpty()) { status = RestStatus.OK; } else { ... the error stuff ... }
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
OMG `== false`! ð±
This can be final. This makes it easier to immediately see what is and is not immutable.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
Because of the structure of the grammar it's a way to get the `-` symbol from the immediate parent context in the hierarchy that could possibly contain it.
Yeah, it's puzzling!
ok fair enough
we only have index name (and not index uuid) in this one, wonder if we need snapshot uuid here...
This could be `Strings.hasLength(tokenizerName)`
I think I missed the discussion but why isn't all this (this method and the next two) part of BaseNodeResponse's toXContent implementation? It can declare an abstract method that the subclasses can override for their own xcontent? We use that pattern pretty frequently with things like the query builders.
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
typo I guess `s/chanHaveDuplicates/canHaveDuplicates/`
you can call `bytesAsInt()` then you safe the cast and it checks that it's lossless
nah this should just pass a string.
I missed it, indeed it should be moved to setupSuiteScopeCluster
sure sounds good. I thought the enum contained all the possible codes :)
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
I don't understand the need to use Occur.FILTER here (or in other parsers) versus Occur.MUST. To me these are just parsers for queries, and thats the correct logic, the fact it is wrapped as a Filter means these will all become non-scoring clauses.
Wouldn't the definition of "upgradable" for string to text/keyword mean the norms setting fits with what is allowed? As this is now, it would mean eg keyword fields could have all of the old settings right, but they would be deprecated...that is just really weird for a new mapper type.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
same thing with 'even make' here
at that point you want have a read budget, which I mentioned above.
Oh nevermind, I see the problem now, the field name is not used to calculate equality so they can stomp on each other even if they have the same name :(
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
left over reference to a countdown latch
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
This method also does not need to exist, as you can use `this(indices, IndicesOptions.strictExpandOpen())`, and fix the validation in the other constructor.
FWIW I've used this in the past for production ES clusters to have a set of common settings (elasticsearch.yml) and node-specific settings (elasticsearch.json) to merge two files with settings. That said, I still think it's safer/better to remove this feature and fail if more than one config file is found. It reduces the complexity for reasoning where a setting came from.
We had to choose a shared prefix in order for there to be a consistent way to detect types deprecation messages in REST tests (and ignore them). I think @jdconrad is just using this prefix here for consistency.
Usually we also make a few API calls to the server, e.g. https://github.com/elastic/elasticsearch/blob/2aba52de8f9315b0e384e1c657d7b0401d26a1b0/qa/vagrant/src/main/java/org/elasticsearch/packaging/test/PackageTestCase.java#L121-L122 I'm not completely sold on the value of those though
new is not possible with an older version...
The fqdn was used before though too. It is not introduced here. It makes it clear which exception it is (e.g. org.elasticsearch.script.ScriptException vs javax.script.ScriptException), and it makes it easier to remove exceptions from here in master (vs having an import statement too), which is really needed.
`this()` is obsolete
I am good with both options.
`S3SignerType should not be available for China region`
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
you should replace the curly bracket with a square bracket here.... :D
I think we can do this more simply by looking at `endsWith(".jar")` of the uri string. We don't really need to convert the uri to a path, since we don't need to load the file. Then, the original if statement can simply be wrapped with like: ``` URL location = clazz.getProtectionDomain().getCodeSource().getLocation(); if (location.toString().endsWith(".jar") == false) { // original if and exception here } ``` Basically, if the file is in a jar, we don't need to worry about it here, as those would have already been added to the codebases map by `Security.getCodebaseJarMap`. This method is about adding classes that are on the classpath, but not via a jar (ie built by the IDE).
Isn't `js` the common extension? At least, that's what is in RFC 4329.
Yeah, let's the keep the tests just focused on whether or not `MinMasterNodeCheck` does the right thing based on whether or not `discovery.zen.minimum_master_nodes` is set and we can think about broader tests for the default checks from `BootstrapCheck` itself in a separate pull request.
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
This shouldn't be needed anymore. By default we wait for the index to be created now.
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
Might be slightly better to return a StringBuilder here as well to not create an additional object? Maybe this could also be done in several other places in this PR where partial WKT strings are built (e.g. all the contentToWKT calls)
looks new. I like this update!
and do that in all other classes we do this for serialization in this pull request.
I would use System.currentTimeInMillis, nanoTime has different semantics
I think this would read much simpler if you would do `if (it != null)`
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
I was thinking of something like: ``` java public static enum TestQueryType { MATCH_ALL { @Override public QueryBuilder buildQuery() { return QueryBuilders.matchAllQuery(); } }, MATCH { @Override public QueryBuilder buildQuery() { return QueryBuilders.matchQuery(TestIndexField.STRING_FIELD.toString(), randomAsciiOfLengthBetween(MIN_SMALL_INTERVAL, MAX_SMALL_INTERVAL)); } }, TERM { @Override public QueryBuilder buildQuery() { return QueryBuilders.termQuery(TestIndexField.STRING_FIELD.toString(), randomAsciiOfLengthBetween(MIN_SMALL_INTERVAL, MAX_SMALL_INTERVAL)); } }, QUERY_STRING { @Override public QueryBuilder buildQuery() { return QueryBuilders.wildcardQuery(TestIndexField.STRING_FIELD.toString(), randomBoolean() ? "*" : "?"); } }, WILDCARD { @Override public QueryBuilder buildQuery() { return QueryBuilders.wildcardQuery(TestIndexField.STRING_FIELD.toString(), randomBoolean() ? "*" : "?"); } }; public abstract QueryBuilder buildQuery(); } ``` Then to build a random query, you could do: ``` java randomFrom(TestQueryType.values()).buildQuery(); ```
I think it would be better to pass a boolean in to this method, since it's ambiguous from the name of the method whether it sets a var (could be named `setDeleteOnClose()` if it were setting something) or actually does the deleting.
there is an `hasUnassigned` method already, so yeah, I'm +1 on being explicit here...
I don't see this change implemented here.
I think âdoes not have soft deletes enabledâ was great!
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
@javanna I don't think it is? see org.elasticsearch.action.deletebyquery.DeleteByQueryResponse#iterator
Indeed, I think two BytesReference instances should be considered equal if they have the same content (which is what the way other children of BytesReference are implemented suggests). My point was this path of the equals method ignores the offset of `other` (it starts comparing its bytes at `0` instead of `other.offset`.
I like this much better!
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
in this re-write, we have a lot more things we probably want to report in our status.
Nit: `s/soft-deletes enabled/soft deletes to be enabled`
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
This will need updating once the setting is moved.
Fair enough, good to know.
maybe it's me but this change seems fishy... we do much more than before now here, also not using indices options coming from the request... but first of all are we sure we want to support writing into index names containing date math expressions? in my mind it was more about reading, search api etc.
I think that we can check the second byte as well to make sure, same way we do in SMILE (by not only checking the first byte), check here: https://github.com/FasterXML/jackson-dataformat-cbor/blob/master/src/main/java/com/fasterxml/jackson/dataformat/cbor/CBORParserBootstrapper.java#L112 for the logic
nit: space before brackets
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
why not round robin on this? I think the randomness still allows us to have collisions and will keep us wondering. +1 on the insight that suite and test scope don't co-exists! Also, this makes us one step closer to using it randomly in our global cluster scope.
If the constructor is modified, this method won't be needed anymore.
Sorry about these crazy incantations....
Can we make this 1 hour? If it times out it's nice to get thread dump
I know it was like that before, but we are here now. ð
Wherever makes the most sense really. In this case I would put the default constants in `DirectSpellcheckerSettings` I think
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
minor nit: you could move this into the WatcherState enum and just have a method `isStopState()`
do we really need so many tests? this is just about parsing? It can probably just have unit testing for this..
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
Here it is more clean, but again I think using `synonym_query_style` would be better
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
we can use in.readVInt() here, no? it's always non-negative... (same goes for other counters and also note that you'd have to change the writeTo message of course)
this is unneeded - we just iterate of the list...
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
this method is not returning a boolean
I'm fine with `IllegalArgumentException`, in all the places of course. :smile:
Check nextToken is Token.END_OBJECT and throw appropriate error if not. Without this additional check the parser errors are somewhat confused if the JSON contains a parameter.
+1 that is what I would do too
the naming might be a bit confusing: `clusterSettings` and then `getClusterSettings()` as variable names
I guess it could be renamed to isFalse() / isTrue() now
Could you explain why this is needed instead of checking `expireAfterAccess <= 0`? I think it'd make the class more readable.
extra space makes everything not line up!
this would allow to remove the two parse fields above I think
Nit: `primary term` -> `_primary_term`
I think filter and query can never be null here? not sure whether we should validate this here.
then let's use it now otherwise this change is half baked
In which case your original solution would have worked too. Sorry
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
no need to set timeout, the default is good enough
good catch on delta > 0
and use the constant here
Maybe use `getSecure()` so that it's closer to the other methods in this class (`get()`).
You're right @benwtrent, we've been dropping the `@throws` clause in some of the methods in the client. We'll need to revisit and add them. I'll make a note to do that.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
I ran it and it took ~2-4 seconds, I was checking to see whether the `@Slow` tag was needed :)
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
`engine failure` -> shard failure
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
Can you switch this around and use the preferred name as first constructor argument? This way it looks like there's something special with this field, which I guess its not.
why have the condition at all? Just always overwrite? Same for disterrpct above
if we use a negative value here we can also just do this: ``` if (output.getVersion().before(Version.V_1_1_0)) { b = Math.max(0, b); } ```
I think it would be clearer to rename `file` to `dir` or `directory` here
we should include `e` here, otherwise we lose the cause of the configuration error.
you can remove the QueryParsingException catch, it's unreachable
hmm why did you remove the mapping from here? I think that was a good change? you should add the settings from from `public Settings indexSettings()` are only used if you use `prepareCreate` so you should add the settings to the versionSettings below. other than that it looks awesome
This is logic that I think should go into ReplicatedOperation.
Please fix identation.
oh, the boxing horrors :)
sorry, my bad.
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
Would it be beneficial here to return an empty string instead of null? If not, maybe just annotate this with `@Nullable`
I'd rather merge TermsQueryBuilder and TermsLookupBuilder, this is going to be a problem anyway when registering builders for serialization if we want to keep registering the parser only and deduce the builder from it . I don't see any value in having two builders for the same query, it becomes confusing for java api users too. Also, the easy way of creating queries should be through querybuilders, we can keep the existing `QueryBuilders#termsLookupQuery` but it will return a TermsQueryBuilder instead. We can also add more methods to `QueryBuilders` to create a terms lookup query that holds all the needed params.
the way we check the resulting query here reminds of the previous createExpectedQuery, as we still leverage lucene's equals and because of that we run into issues. Also, it makes little sense to test the result by calling the same method that we call in prod code (handleTermsQuery). I would keep these checks more lightweight then.
fielddata format can still contain arbitrary values: ``` PUT testidx { "mappings": { "doc": { "properties": { "user": { "type": "string", "fielddata": { "format": "fst", "blah": "blub" } } } } } } ``` I am however not sure what is expected here because when I get the mapping the wrong entry will be returned...
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
This API call is forbidden and fails the build. `random().nextBytes(randomBytes);` is fine though. I'll fix it before I merge.
For backporting to 6.3, I think this needs to be changed to 7.
I see what you are talking about. Weird. I'm fine with it then. I mean, I don't like it, but I don't really have to like it. It makes sense to make it look like the test above even if the test above looks funny to me!
can we assert that if we need to generate a new history uuid we always use `*_CREATE_TRANSLOG` as an open mode? that's why we rely on the translog uuid only for trimming purposes (and avoid thinking about what it means to generate a new history uuid)
I think that we can save the instanceof checks, builder.value(Object) does it already
s/to list of/to the list of/
Just a style note, we prefer the more verbose negation (`foo != true` or `foo == false`) over the short form (`!foo`), because the short form is easy to misread or overlook. :)
this is good as we already have a unit test for the filter. Wondering if that current BulkProcessingState object needs its own unit tests outside its use within a filter.
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
This can stay as a break - exactInclude is the highest form of checking, no need to check more
can you add a //norelease here too? context should really go away after all queries are refactored
Same here... we don't really need `String[] addresses`
I donât think this buys you anything in terms of concurrency. The list reference is already final.
I suggest trace logging here
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
Why is this `volatile`? It doesn't look necessary to me.
I've dug some more. This is caused by us running the tests with the built in gradle test runner rather than the randomized runner. We configure the randomized runner to run with the system properties but we don't ever configure the standard runner.
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
then do something like this `source[n/a max source size: ...`
I think all of these need to be trace and we should enable these in tests that are relevant.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
I know this is existing, but I think we can lift this up to a singleton so that we do not create a new instance on every publish to every node.
I usually do this: ``` assert xContentBuilder.generator().isClosed(); return true; ```
we shouldn't need this here in parse phase
Typo: "Dynamics" -> "Dynamic"
you can replace with //norelease so we don't forget but at least you can get this in while we fix this problem in master.
There's an extraneous blank line here.
This thread can leak and fail the test, I think that you need to clean it up (join on it in tear down).
I think this can be removed (here and from the interface) and then `this.shardId` can be used in the only caller, the `.get()` method
OK. Just double checking :)
I had a quick look and opened #25519 with what I imagine the strategy is. It certainly looks big enough to be worth doing in its own PR.
This empty `if` followed by this line looks off.
Oh right, sorry for the noise.
If its early I think this is safe - but now maybe the read timeout on test side will be too low.
What uses this? And why is forbidden APIs not angry about passing in String,int here... i feel like i banned that method. I dont like it as its wired to 127.0.0.1 in non-test code.
It would be nice to find another way to do this other than replacing the thread context. I had a look but didn't find other ways though :) I guess you have tried as well.
> write past EOF :dancers: +1!
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
no need to set timeout, the default is good enough
I think something like `randomSearchSourceBuilder` would be a more consistent with other random builders.
I'm happy we made those exist queries fast. :)
I don't like leniency. Can it be `"true"`, `"false"` or `null` with the former parsing to the right `boolean` and null giving the default? A typo of `"tru"` will parse to `false` and that makes me :cry:.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I think something like `randomSearchSourceBuilder` would be a more consistent with other random builders.
scratch that, I think this will be fine as-is in 6.x as well.
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
+1 to have `fromXContent` and `parse` be static
well, we can call it `ZenTestDiscovery` :) - my point is more that then we can move the `getZenPing` to the test only variant and not have it public on `ZenDiscovery`. There were also times where we considered mocking elect master service where this test-only discovery would have been useful.
++ . nit: add the state to the message please.
not sure either, I just thought we introduced `parserName()` to have our temporary `toQuery()` method working. ``` //norelease to be removed once all query builders override toQuery providing their own specific implementation. public Query toQuery(QueryParseContext parseContext) throws QueryParsingException, IOException { return parseContext.indexQueryParserService().queryParser(parserName()).parse(parseContext); } ```
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
I had a look at all these parse methods. We might need to clean them up, we have too many variants of it, most of them are used in tests. But in general they are used by any component that needs to parse queries: percolator, highlighting (supports a separate highlight_query that gets parsed as part of highlighting), query rescorer, translog (old delete_by_query)...... I think those parse methods should be converted to fromXContent and return a QueryBuilder instead.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
It seems like there are unnecessarily many levels where `null` is allowed. You're allowing `aggregatorFactoryBuilder` to be `null` here, but also in `FeatureIndexBuilderJobConfig` `aggregationConfig` is allowed to be `null`. I think at most one of these possibilities should be allowed.
I believe we've been just using the string version of field instead of these lately.
maybe make sure it's positive
You can use the diamond operator here.
oh... didnt see the `updateInvocation` counter... nvm
ok thanks for the explanation. @s1monw any magic that we can do to fix this? :)
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
yep. missed it. sorry for the noise
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
instead of if statements maybe use switch statement? ``` java switch (toType) { case: "integer": // do stuff break; case: "float": // etc. } ```
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
This is only used in the constructor, doesn't need to be a field.
I had a look and the settings code has been dramatically improved with 5.0 already, hence this fix is not required any longer. Nothing to do then, but thanks again for pointing this out.
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
I'm not super comfortable making this. I think maybe instead we should add the match skipping at the `FieldParser` level. Maybe some kind of subclass that skips or something. Not sure.
do we want to check the phase/action times since those are meant to change
I'm fine with leaving it, yeah. I did want a prettier one but if this is what we can do, it'll do.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
I took another look at MovAvgModelStreams, and although I'm not completely sure it look a lot like what NamedWritable is doing, so I was wondering if Stream could be replaced by it.
Sure I was just wondering if there is a use case for this.
Lol - I spent some cycles trying to figure out how the hell we know this won't throw an index out of bounds exception, only to end up learning something about the BitSet api - it's funky ;)
It would be nice to find another way to do this other than replacing the thread context. I had a look but didn't find other ways though :) I guess you have tried as well.
space between `if` and `(`
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
maybe you can just delegate to `read(byte[],int,int)`
@s1monw if you're proposing we use inheritance and you assume the base class will always be caching DF then we could just remove all the "if(this.docFreq)" checks in the existing code as a simple way to clean things up? That would leave us with just the "if(this.totalTermFreq)" checks.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
To coerce, should be: ``` parser.longValue(true); ```
We need to check here if `ttl` read from translog is lower than 0, if so, then we actually don't have a value...
Here you call super method while in toQuery/doToQuery, doEquals, doWrite etc... superclass calls abstract method. Any reason why this is different here? Might be more consistent to follow one pattern and have the superclass always call concrete implementation? Just an idea really.
Can change this to the new autoclose functionality in Java 7 now that the codebase is on it: ``` try (ZipFile zipFile = new ZipFile(pluginFile)) { // ... } catch (Exception e) { // ... } ``` Thereby dropping the entire `zipFile`-related code from within the `finally` block.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
maybe we should just get rid of this local variable and write the next line: ``` nodesIds = filterNodeIds(clusterState.nodes(), resolveNodes(request, clusterState)); ```
oh man that class is a nighmare. really I just realized how fucked up this is grrr.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
extra space makes everything not line up!
same here re enumSet.toString
can you use `InetAddresses.forString` intead, which guarantees it won't do a dns lookup
Same, copy-paste error here
This is going to be 512 Unicode code units, but I think we should do bytes.
Perfect! Thank you.
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
this is same as what we do in term query. We randomly choose a value depending on the type. We might choose the mapped field for that value type, or just pick an unmapped field for it.
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
I like the idea of the predicate. It could for instance be something like `registry.supports(name, Aggregation.class)`. This way we could also support ignoreUnknownFields for forward compatibility
indentation is off after other changes
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
gotcha, thanks for explaining.
ok as a follow-up
++ thanks for changing this :)
I think we should keep it in the name even if it is verbose
> If there are multiple commits, what does IndexWriter.getCommitData() return? I am guessing it reads the "latest" commit's data? Yes, the latest.
good catch! that means we are not properly testing this case either given that we didn't catch it.
can we change this to Loggers.getLogger(getClass());? it is what it should have been to begin with, which is my fault ;)
So I'm thinking of using this in the reindex API which'd make it used inside of Elasticsearch. Taking a ThreadPool is fairly normal for the internals of Elasticsearch. I suppose if you wanted to keep API backwards compatibility then you could make it optional and the whole thing to fail if one isn't provided but a backoff needs it.
This doesn't feel right to me, adding a parameter to the bootstrap check infrastructure that is specific to a check. I think that we should try to find a different approach (I'm happy to help brainstorm about this, but I have not yet done so).
The message is a little weird. I don't think "next release" should be mentioned.
would you mind adding `<>` after `new PriorityQueue` ? otherwise this is an unchecked assignment.
Or do it as a direct followup, I suppose.
This method can be package-private.
maybe omit lowercase from the method names here? (since these tests also run for uppercase and trim)
Let's make this a `SetOnce<BlobContainer>`
This might be `WRITE` actually - we are creating an index or modifying an index after all.
I usually do this: ``` assert xContentBuilder.generator().isClosed(); return true; ```
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
`readFrom` is going to be removed from the `Writeable` interface, maybe in a few hours. Right now it has a default implementation telling you not to use it. So I'd just skip this bit.
wondering if this should call `this(stats.queryCount, etc.)`, since the addition is not required given that we are creating a new object
And we could then just leave an assert here.
To clarify, I meant the default indices options used if the user doesn't set them.
sorry, my bad.
`s/step/cluster state step/`
This seems to test the case where the same path has a number of distinct mount points. Can this happen? I can't think how.
future note - once refresh mapping is gone, we should inline this with index creation.
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
maybe, to be more precise, it would be good to check the partition that included the new primary.
this makes me wonder: if a node has node.ingest set to false, for sure no processors should run, hence simulate should be off and IngestDisabledActionFilter should throw exception when a pipeline_id is used as it does now. But how about crud actions for pipelines? One has to go to specific nodes to store them, that have node.ingest set to true? this may not be needed, as those are just index, delete and get operations that any node supports...it's like making client nodes reject index requests, they can forward them to the proper nodes, no problem with that.
do we really need to do this? I mean if we hit the exception our search layer will retry for us? I don't think we should do this at all.
argh. Missed the grey method start line in the github diff.
Fall back to _old_ behavior
We talked about this and it's going to be tricky. Nevermind...
points are allowed to reuse the byte[] to I would make a copy of it before adding it to encodedPointValues
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
this code and the code in `SearchPhaseController#sortDocs` is almost identical. I think the only difference is the assignment of the shard ID. Maybe we can factor this out into a static method and use it in both places. It would be good to redcue the duplication on such a level and it would increase the test coverage. I would be in favor of that.
Nit: space between the cast operator and the target.
please fail if vals.length > 3
Here it still says `on a per index basis` -> should be corrected.
then call here `register(SimpleProcessor.TYPE, SimpleProcessor.Builder.Factory.class);`
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
The indentation is off here and the rest of the way through this test.
I think 0 is a good minimum value.
I wonder if we should use a hash here instead if some corruption wipes all bytes to 0 or some other value? maybe `MurmurHash3`
if you do not supply the the content-type, you can just hand over the builder and do not need to create a string object here. Also I would just return `JSON is disabled` instead of mentioning the config option here. The shorter the better IMO.
Why remove it? I was adding them because I thought it was nice to mark the constructors for anyone unfamiliar with Elasticsearch. It'd help them get their bearings.
we shouldn't need this here in parse phase
some adjustment is needed here once you merged master in
And we could then just leave an assert here.
The existing `ESTestCase#randomSubsetOf(int, Object...)` should just delegate to this new method here.
This exception will be treated as ignore replica exception. :wink:
make it final
Does this message go back to the end user? If so the fact that a map must be empty is more of an implementation detail than an meaningful error message for the end user. Something like "Mapping definition for field X has unsupported parameters: foo, bar" would be more appropriate.
Right, I mean change it so that it isn't static. Or have a different, non-static getAnalyzer() method that calls out to the static version in the base class.
Yes, I would ditch DOS (as you have done). I don't think we run any CI on non-ACL aware platforms. If it turns out we do, then we should just do an `assumeFalse` as the test is not possible on that platform.
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
I see, that is hideous. ð¦
maybe add a method to `IndexScriptExecution` like this: ``` Java public boolean enabled(ScriptEngineService service) { // return true for IndexScriptExecution.ALL // return service.sandboxed() for SANDBOXED // return false for others / by default return false; } ```
did you run into this being a problem? how can we open an index that was created before 5.0.0 and never had insync replicas but does have allocationId? the only thing I can think of is a node network issue during shard initialization. I'm wondering if we need to optimize for this and no keep this code simple (i.e., demote shards with a lock exception)
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
we are generally moving away from gazillion packages and classes I am not a fan of all these service and they make things more complicated than they need to be today. I have a hard time to understand what feels wrong here and where you draw the line
`seqno` -> `_seq_no`
Or we can let poorly formatted values pass through and throw exceptions at the end if values are missing, similar to how we do for queries
Nit: spacing between the `)` and `{`: `){` -> `) {`
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
Not a big deal, I'm fine without it
I think these don't need to be volatile any more, now that we read under lock.
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
can this runnable be an `AbstractRunnable`
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
@bizybot can you open up a issue that describes this behavior of the object parser and label it with discuss? Then we can move this PR forward.
space missing before `new Named...`
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
I'm not sure this method name is right. Maybe I just don't know this code that well though.
copy paste :)
I think it might be easier to read the code without this method to be honest. It saves a line every time you call it makes me go "what is going on here?" every time I see it. Not sure.
same as above for non exception case
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
you are perfectly right Christoph, let's merge the two and keep the existing class.
the exception declaration is not necessary.
I don't think raising en exception to save a few lines of code here is a good idea, please change this back to how it was before.
Wasn't me, it was the tests :)
I would call `indexedValueForSearch`.
I don't think that we should move this code into the InetAddresses.java source file. That code is from the Guava code base, and is licensed to the Guava authors (see the license header). By moving this code which is not from Guava here we will create a confusing situation with respect to the licensing of the code. Let's take this code to IpFieldMapper.java.
"just created files" <- what do you mean exactly? if one waits 2h they will be able to read it? if not I would just go with "the permissions on the store don't allow reading"
If your intuition is that these will be almost always needed, then obviously we should keep them.
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
I think this declaration/initialization can be moved to inside the if
Nothing to do here for this PR, but how can we keep this up to date? We already have this list in like 3 other places it seems...
I think this constructor can go away
formatting - 1 line instead of 2
oh, multi-bucket comparisons are ready already? :)
I think I would make a breaking change here. Let's drop support for the string value in the builder and add it to the breaking changes. The parser still supports `none` and `all` but the builder only accepts a query. Then the method below needs to pretty much be moved to the parser.
Nit: "seq no" -> "seq_no" (inconsistencies will make searching more difficult)
missing generics type same as above
+1 to that for the yaml configuration.
one more thing (sorry!). For the language clients, I think it would be good to also have a small REST test that uses search_type count, just to verify that all of the clients (and our REST layer) still support it.
Would it be better to use the Assert.fail(String) method or throw an AssertionError here? That way the test will fail correctly in the test framework
so what about the other settings you can set on the Item like source filtering? I think we should expose all of them here though.
can we do this `((Long)value).longValue())` no boxing needed here
Ah yeah I suppose that might be ok, in this case it's user-defined input so that's pretty awkward but it beats breaking.
these ElasticsaerchExceptions are bogus remove them
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
space missing before `new Named...`
we set the rewrite method twice it seems? probably a bug in the original parser
FWIW I've used this in the past for production ES clusters to have a set of common settings (elasticsearch.yml) and node-specific settings (elasticsearch.json) to merge two files with settings. That said, I still think it's safer/better to remove this feature and fail if more than one config file is found. It reduces the complexity for reasoning where a setting came from.
space after `,`
I think this should be trace
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
We should use a try-with-resources syntax with this.
I think it'd be useful to see the filenames in the exception message.
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
@jtibshirani is correct
We do this check in RestoreService.isRepositoryInUse. I am not quite sure what's the reason to repeat it here.
I'd just use the Id really
Can you add the `translogId` to the log message here? It makes tracking stuff down on shared filesystems much easier.
I'm okay with this.
If we don't cache the fields, we should remove the fields.clear() at the end.
Test is called "testPrimaryOperationLocks" and then most of the code is there to check replicaOperationLock ;-)
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
Remove and create again is not needed I think
Forbidden API: ``` Forbidden method invocation: java.lang.String#toUpperCase() [Uses default locale] in org.elasticsearch.cloud.aws.blobstore.S3BlobStore (S3BlobStore.java:204) ```
I'm good with latest. It's also probably a good idea to change testJoinElectedMaster_incompatibleMinVersion as well
space missing before `new Named...`
The distinction of what "class" means (why it does not include def or arrays) should probably be explained before this list.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
I don't think this needs the string/boolean. They can be regular enum values. And the constants can be inside the enum, so that they can be used as if they were additional values.
Doesn't actually throw `IOException`.
I think we should separate the two and push this as is. Your code refactoring has more changes than this functional change and on the security end I think we should be careful. let get this in and cleanup the stuff afterwards
can you try to exercise this method to make sure we open a new searcher and close / release everything
well we use a dummy lock so I guess it's fine
As this setting should usually be only set once, it is probably simpler to leave it non-dynamic (as @jasontedor suggested and as it was before this PR). In case where this must absolutely be updated on a production cluster, rolling restart (of master nodes) with config update is always possible.
I think we can go with a higher bulk size, because we only do deletes. Something like 5000 or even 10000.
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
fyi, I added serialization to the enum I moved to MatchQuery (#13402) maybe we can reuse this.
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
maybe just inline this into the `planIndexingAsNonPrimary` method? I think that would be cleaner.
thanks for moving this to a unit test!
indentation makes the `if` block a bit hard to read
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
I know this is how it used to be, but can we make the if be more like the `masterNodeChangePredicate` name and check the the master node is not null and have changed? (we now test for a cluster state change)
The language in this sentence isn't clear, perhaps change "that is replacing" to "and it is replacing"
yeah, prefer top-level there as well.
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
Can we switch between the string and the millis representation fo the modified date using the `human` flag like the explain API already does? That way we can just have one `modified_date` field in the output? Also the parser will not need to worry about the string version in this case since the client it will never set the human flag
Nit: spacing between `!` and `value`.
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
too many shards [%d] allocated to this node, [%s=%d]
this might also be called I think
I called these methods test*ToAndFromXContent() as they effectively do one complete roundtrip: toXContent -> fromXContent -> toXContent
can me extract this into a method, it is used in 3 places
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
Right... but I'd be happy if we could unit test this, and if we do then we need to ensure the object start.
I would call `indexedValueForSearch`.
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
`createIndex("test")` ? then you can remove the following `assertAcked`
too many shards [%d] allocated to this node, [%s=%d]
I think that inserting random fields here would reveal problems on the parsing side with the current code.
Nit: `who's the a better` -> `which is the better`
maybe we could randomize the names of the 2 settings we have in this test
what naming convention do we want to follow here? I saw around some innerQueryBuider(), here innerQuery(), maybe we even want to drop the inner prefix... let's decide for one of the options and go for it everywhere.
I'm confused. Does this mean we restart the leader checker on every incoming publication? We call becomeFollower on every incoming publication
Perfect! Thank you.
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
I think it'd be cleaner to put the `finishHim(e);` into an `else` statement than to return early in this logic
Just a suggestion, I don't mind if we remove it here entirely. I used to like those tests because they show how a typical xContent output of those classes looks like. But with these large ones its kind of debatable whether it is useful.
I'm afraid we need to rely on the order if we want to be able to distinguish between negations (applied when a wildcard expression appears before the negation) and referring to indices that start with `-`. We will be able to get rid of it in 6.0 only when we will be sure such indices are not around anymore. I opened #20962. Can we also have a test where the wildcard expression is not the first expression but still before the negation? e.g. `test1,test2,index*,-index1`
nit: s/read blob's/read the blob's
`} catch (IllegalArgumentException e) {`
Why do we need a good github search when we have @clintongormley :)
Allowing this to be customizable is nice but it is going to break parsing pretty hard if this doesn't stay MILLISECONDS.
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
> write past EOF :dancers: +1!
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
index's toString gives you '[index_name]' no need for '[{}]'
the printStackTrace should go away here
good point. I didn't think about that. The value to append can be an json object too, so yes the exception should be replaced with logic to deal with that.
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
I am not sure RestoreService would be the right place for it since addBlock would need to be moved to the same place and it's currently used all over the place. I don't have an issue with renaming it to `addIndexMedataBlocks` but since IndexMetadata is the only parameter, repeating IndexMetadata in the name might be redundant.
"new" -> "now"
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
No need for an empty default ctor when the super is also a default ctor.
maybe add an explicit `continue;` here to indicate that it's being skipped
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
right thanks for the explaining, I should have known, having worked on the search refactoring :)
Can you move all that code to AwsEc2ServiceImpl.getEc2Attributes instead? Potentially we could unit test this method.
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
oh nevermind, I just found the method that called it with null :)
++ for ordinal and tests then
Ok, sounds fine.
Wouldn't the definition of "upgradable" for string to text/keyword mean the norms setting fits with what is allowed? As this is now, it would mean eg keyword fields could have all of the old settings right, but they would be deprecated...that is just really weird for a new mapper type.
sounds great thanks
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
I think everything inherited from BaseTasksRequest should be converted.
ta -> to
I would inline `superSettings` and now there's another `put(Settings.EMPTY)` to nuke.
can we do this `((Long)value).longValue())` no boxing needed here
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
please wrap in {}
++. Maybe also add a sanity check that a get on the doc at the end gives us what we expect? (deleted or found)
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
add action name pls.
This seems not to be the right exception message here (looks like cp'ed from term query).
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
you are perfectly right Christoph, let's merge the two and keep the existing class.
I wonder if this is a good name for this reducer? I haven't got any good ideas for alternatives but to me a differencing reducer would subtract one series from another rather than subtracting offsets from a single series. It took me a while to be clear on what this reducer was actually doing. I will defer to someones better judgement though as I appreciate that this might be a standard statistical term
I _think_ we have a deprecation logger. We should probably log something when we see `position_offset_gap`.
I don't think we need this branch anymore.
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
I'd probably write validate's results to a variable and reuse it.
`assertThat((List) filteredMap.get("array"), hasSize(1))` has better error messages.
What is the reason you decided to not use this check anymore? I cannot find it in the refactored method.
can we add some java docs? the name to functionality transition is not trivial anymore
maybe log it debug or trace? not sure how many times this can happen...
copy paste :)
I wonder if this should be `Exception`. see also #20659
maybe call this `setHit`
Ah ok, I missing that method below, sorry.
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
Sure, good plan.
I thought we said we would move this method to IndexQueryParseService so we can avoid exposing the Client.
this entire thing looks much better now! cool stuff
calling `ConcurrentHashMap#size()` can be quite expensive IMO. I think we should keep track of the open ctx in a counter instead of using the map. I don't think being a little off here makes a difference. I think we don't need to add any sychronization changes here.
Same here, original exception is dropped.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
This change should not be necessary. We already have the ability to plugin in a filesystem in tests. See `PathUtilsForTesting.installMock()`
Yes, I confused myself.
@uboness I mean that it is called by the transport client going through the transport service directly (as was the nodes info call before), it is not exposed through clients, so java api users can't call it explicitly (the `Client` doesn't expose such api).
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Fair enough. I just see the increment/visit/decrement pattern a lot and it feels like something you could make more automatic/harder to forget/explicitly named.
I see what your are saying but I donât think we can rely on this. The nanoTime() is not guaranteed to actually have nano precision (just resolution). it is only guaranteed to never go backâ¦ > On 29 Jun 2015, at 10:39, Masaru Hasegawa notifications@github.com wrote: > > In core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStateTest.java: > > > @@ -154,7 +154,7 @@ public void run() { > > if (randomBoolean()) { > > timer.stop(); > > assertThat(timer.stopTime(), greaterThanOrEqualTo(timer.startTime())); > > - assertThat(timer.time(), equalTo(timer.stopTime() - timer.startTime())); > > - assertThat(timer.time(), lessThanOrEqualTo(timer.stopTime() - timer.startTime())); > > I think lessThanOrEqualTo is correct. (because it's rounded down to nearest decimal value) > > If we use nano seconds, when start time is 1ns and stop time is 1000000ns (1ms), time() would be 99999ns but it's 0ms because of TimeValue.nsecToMSec. > But if we use milliseconds, above becomes 1ms - 0ms = 1ms. In this case, time() < stop() - start(). > When start time is 1ns (0ms) and stop time is 1999999ns (1ms), it's 1999998ns but time() will be 1ms and stop() - start() = 1ms. > > That's said, I like time() > 0 since it makes it simpler. > > â > Reply to this email directly or view it on GitHub.
Can we remove `tag` as parameter here and make it part of the `config` parameter? In the end it is an optional argument and it feels that the this should be part of config, this way the signature of this method remains clean.
This could just be `close()`
can this see `unregister task for id: [{}]`
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
I'm good with one decimal point with the caveat that this endpoint really should not be being indexed.
should say shard active
maybe we can factor out a method `boolean hasHits(QuerySearchResult result)` it's used in two places an a complex condition
When it gets long like this can you indent it like ``` assertResult(() -> builder() .startObject() .startObject("foo") .startObject("bar") .endObject() .endObject() .endObject(), ``` I know we `assertThat` has the matcher second, but maybe we should put the closure second for this? I think it is nice when the closure is second because it makes the code formatting prettier.
> Or "no longer than 512 bytes" +1
I am concerned about this change. We are leaking communication abstraction into the service layer here. I wonder if it can be avoided by passing necessary structures of CreateIndexRequest as part of CreateIndexClusterStateUpdateRequest or referring to it as TransportMessage or passing necessary pieces of information from TransportMessage as part of CreateIndexClusterStateUpdateRequest.
I would definitely prefer a pure function here that returns a `Set<ShardId>` instead of mutating the method parameter
minDocFreq must be positive
I think this catch not needed. It will be caught higher up.
I am wondering if we should add `buffer` (size or operations) to the Status object? We can do it in a follow up if you are okay.
I'm not sure we need to send this over the wire though.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
ah I mean't Throwable.... sorry
> should we just do the naive thing and handle the last 8 bytes case via a naive loop of writeByte() for each byte, so that the footer logic is only in one place? +1
this is unneeded see above
good these variants go away...
final, not volatile...
I don't know how often this is called, depending on this maybe it makes sense to store the formatter somewhere for later reuse unless `format` changes? Is only called a few times maybe not worth the trouble.
Looks like there isn't an ExecutebleScript equivalent for search scripts anyway - ignore this.
Can you add some randomization ? We run this method multiple times and then perform some checks on the generated query (serialization, correctness, ...).
thanks for adding this
can this see `unregister task for id: [{}]`
this whole block here looks pretty much the same in all invocations. Can we make this even simpler? Maybe create a method `createIndexAndWaitForActiveShards` in `MetaDataCreateIndexService`. I've implemented it here: https://github.com/ywelsch/elasticsearch/commit/6e67ecabbfa5cc2568c0c987401e3ea521c7a330
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
given that we also filter responses by creating a new response filter chain and filtered action listener, this inner class is not just a request filter chain... can we maybe merge the two at this point? Seems like in the end we either filters nothing or both (request and response) anyway...
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
Can you remove the empty javdoc? We are going to fail the build on those at some point....
points are allowed to reuse the byte[] to I would make a copy of it before adding it to encodedPointValues
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
maybe we should be more explicit and initialize indexBoost in an else branch here, rather than above when declaring it. I think de-serialization is the only scenario when it may not get assigned.
For static varialbles, `final` should indeed be used whenever possible.
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
Why not? http://vimeo.com/105758303
I think that we are leaking a thread local here? We should close the current threadContext before overriding it.
All our tests currently use `RandomizedTest#atLeast` method, you can do the same here.
Nit: this blank line is extraneous.
do you have indentation at 2 chars only for this method? We use 4 chars in our codebase. I'd appreciate if you could change that.
do we really need to walk these directories, can we just do what `getFSInfoIgnoringQuota` does? I really don't think we should walk the direcotries
should be clause.getOccur() == SHOULD
same question as above
You're right @benwtrent, we've been dropping the `@throws` clause in some of the methods in the client. We'll need to revisit and add them. I'll make a note to do that.
no need for a constant here, you can use `StandardCharsets.UTF_8`.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
you can do some streaming java8 magic here.
maybe I would split this in two ifs, the outer one about version, then the inner one around levels.
spaces after '//'
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
Can you keep the formatting? I tend to find it easier to read when formatted
one too many new line? :)
please return a Map instead no google guava stuff in public interfaces
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
ok fair enough
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
here you may be able to use copyCurrentStructure
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
If the usage of forbidden APIs is in a few places, I would consider it better to suppress only at the lowest level (sometimes I like wrapping those in a private method I suppress). The reason is that if an unintentional forbidden call creeps in it will be caught.
This predicate can be simplified to `(count, limit) -> count > limit`.
Nit: please add spaces after the `if` and before the `{`.
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
Maybe we can remain streaming parsing if the type was parsed before the query? If the `XContentStructure` class has 2 set methods setTypes() and setQuery(), then the latter method can be smart, so that if the type is already know it would immediately create the Lucene query. If the type isn't know it would just keep the unparsed query around in a BytesReference field. I see that would change this class completely, but I really like to do streaming parsing if possible.
Here's another place to maybe use a [field](https://github.com/elastic/elasticsearch/pull/14651/files#r45225330).
It doesn't have to be JSON, we support Yaml, Cbor and Smile, so better to say we expected the beginning of an object or something along those lines.
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
Can we get back to this once we need this complexity and keep it as simple as possible for now please? Can we hardcode the OBJECT_FIELD_NAME exclusion and be done with it? queries also have access to individual field names if they need that.
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
Instead of making up our own exception, why not use just use Files.delete? This will give you a better exception message. https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#delete(java.nio.file.Path)
I wonder if we should use the cluster state for this check. I'm worried about people passing in a dated cluster state here. Maybe a cleaner model is to make this method synchronised (to avoid async collision with the create code) and check the existence of the index instance in the #indices map member of this class.
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
I think it'd be nice to remove this second ctor so we're explicit every time.
Er - if you are going to log something then it doesn't matter which order you do it I guess.
can you add the `@Override` back? (here and in all the other subclasses of `Discovery`)
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
Same here - the same as base calss
It would be worth requiring that `jobId` and `jobType` are not `null`.
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
Helper method is no longer needed now that `Logger.debug` exists.
drop the actually? sounds so "uncertain" :)
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
Oh nevermind, I see the problem now, the field name is not used to calculate equality so they can stomp on each other even if they have the same name :(
Should we still log something here, in case `terminal.println` throws an IOException? Or the impossible becomes possible (hey, you never know with JDK9)
good catch on delta > 0
use a try-with resources for the parser value
Can you reverse this, the negative makes it harder to read
no need to remember all individual boosts, you can just multiply: ``` java float boost = 1f; while(query instanceof BoostQuery) { BoostQuery boostQuery = (BoostQuery) query; boost *= boostQuery.getBoost(); query = boostQuery.getQuery(); } ```
you should run `gradle precommit`
I believe this can be provided by overwriting EsTestCase#xContentRegistry().
fyi - this gives you double [[]]
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
yeah, that was what I meant
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
preferably put this into the `next()` method instead so it will also cover the other blocking calls in this class. Could you also write this as `assert Transports.assertNotTransportThread(...)`, this will save from extra CPU in non-debug mode.
Is this necessary? I think that the cluster should know it only has one master node and sets this accordingly.
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
I'd do ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new FsChannelImmutableReader(id, channelReference, length, totalOperations); channelReference.incRef(); // reader private reference return reader; } finally { channelReference.decRef(); } } else { throw new ElasticsearchIllegalStateException("can't increment translog [" + id + "] channel ref count"); } ```
I think you can just blast the entire method in this case.
these unit tests are great! We are going to need more of them :)
just as a sanity check that declares we do not support arbitrary unicode. I don't think we have that around
this always yields true
Does it need to be Writeable? It looks like we only serialize it using JSON.
You could probably avoid this by making the linux check a method that you stub out in OsProbe.
I don't think we either but I know some folks like them so I certainly don't object to them.
nit: missing space
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
nevermind I was confused... all is good
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
this keeps bugging me :) we should something on the executor as well....
we shouldn't need this here in parse phase
that is a good idea, but maybe add the switch later on then? it really makes no sense right now :)
Actually I just checked and removing name and description from the Plugin interface should be easy. The only thing to think about is what to give for those properties when plugins are loaded from the classpath (plugin.types). I think here the name should just be the classname, and description something like "plugin loaded from classpath"? I don't know what other info we really have.
`retry < this.numberOfRetries` is implied here due to the outer check.
same here regarding the logging as above if applicable
let's keep as is, with the assertion message I think it's ok. I wonder if we should have an assertion at the end of this method to say something like "if we have an active primary shard that's not relocating, then the replication tracker is in primary mode".
Did you push the change that added it? I don't see it.
I'd rather have a different parameter there. However, that would add complexity. It might be better to not handle missing field or NaN and Inf at all and let the user sort it out with range filters.
Extra space is extra.
Can you have a quick look again if this should be MATCH_PHRASE_PREFIX_FIELD instead? In which case it would also be good to catch this in tests if it is wrong.
Same feedback as the last `toString` - I think you can remove `created` and might want to look at `Operation`'s `toString`.
> we'll still see this infinite loop for "{" for example. I'd expect the parser to throw an exception on this? > Is it really a good idea to have the behavior of org.elasticsearch.rest.action.RestActions#parseTopLevelQueryBuilder be to loop forever on part of a valid JSON request? :) Of course not, and this is not what @cbuescher said.
+1 to: ``` List<DiscoveryNode> nodes = this.nodes; if (closed) { throw new IllegalStateException("transport client is closed"); } ensureNodesAreAvailable(nodes); ```
why did you add it? I mean, it is very internal...., it will mean cluster state API will become so much more noisy
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
Please fix identation.
Given the method's name I expected it to check the values too.
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
left over reference to a countdown latch
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
Please fix identation.
It might be a good idea (possibly in a different PR) to have a method on `ScriptEngineService` called something like `getSupportedScriptContexts()` which each implementation can use to define what script APIs they support. I imagine there are/will be other language that don't support some script APIs and this would not only allow them to use this too but would also remove language specific code form the ScriptService, which should probably remain language agnostic.
```suggestion public void setFile(File file) { this.file = file; } public void setFile(String file) { this.file = getProject().file(file); } ``` Along the same lines as above to avoid the use of Object.
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
`s/shadow replicas/shadow shards/`
`them` -> `them;`
This change would only break `wildcard` query on these fields, right ? +1 to make them string fields, `prefix` and `regex` query do not work currently because of this so it would be a bug fix. I am also ok to do that in a follow up, the changes in this pr have a different scope.
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
sorry I didn't see that you created a copy (I missed the "new HashMap" part)
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
Another to remove
Again, I wouldn't pull out the ternary.
Out of date doc.
you can remove the validate call for now, we will fix all queries soon, I promise
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
This cast should not be necessary. You can use `in.readMap(StreamInput::readString, StreamInput::readString)`
Is this any quicker if you use bulks? I tend to do that out of habit.
Is there a reason these three fields need to be test instance members be randomized in the init() method? Otherwise I would prfer making them local in createTestIntstance().
But that is not equivalent? Arrays.toString is a static method, and different than result.buildConflicts().toString()
In my dreams, merging would either throw an exception or return a new independent mapping so that we wouldn't need this validation phase :)
I think these don't need to be volatile any more, now that we read under lock.
I think 0 is a good minimum value.
minor: I think it would be a bit more obvious to explicitly call `DateTimeZone.getDefault()` instead of `null`. Since that is what Joda does with the `null` value. http://joda-time.sourceforge.net/apidocs/src-html/org/joda/time/DateTimeZone.html#line.301
timestampMillis -> unassignedTimeMillis delayCalculationTimestampNanos -> unassignedTimeNanos
maybe make if final
Do these really have to be test instance fields? Can they be passed around? They are easy enough to construct.
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
I think we should make all of the mutating methods in here package private to be consistent like `moveToPrimary` etc.
The reason used to be not to make writeNamedWriteable public. I think it is still the same. Design decision we made with Simon when we added the NamedWriteable abstraction. We didn't want e.g. plugins being able to serialize just anything by using this generic write method.
Instead of making up our own exception, why not use just use Files.delete? This will give you a better exception message. https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#delete(java.nio.file.Path)
not really wrong since we do not require things to be reproducible in that case, but I'd rather like to use context.reader().maxDoc() instead of context.docBase so that matches only depend on the current segment
I am fine with doing it in a follow-up PR if that works better for you
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
While you are here why not remove the whole `Fields` class and just use strings? That is the "new style". For things that are used in more than one place we'll typically use constants - and if those things are using in parsing the constant will typically be a ParseField, but otherwise we've started to not make these `Fields` classes.
w00t thanks !!
The score of this query depends on the number of shards, the default similarity, ... To make sure that we have consistent scoring you can use a `function_score` query like the following: ```` QueryBuilder query = functionScoreQuery( termQuery("name", "one"), ScoreFunctionBuilders.fieldValueFactorFunction("my_static_doc_score") ).boostMode(CombineFunction.REPLACE); ```` ... and add the `my_static_doc_score` at indexing time.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
Incides -> Indices ? ;)
confuses the shit out of me everytime :)
nit: this change is not needed
Er, probably not. But a bit confusing name because it looks like a typo.
I think that this should be an `IllegalStateException`.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
the important part is having multiple open readers on this as well.
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
this is really the job of TRA to test this? it's an index meta data thing. Whis is it here? I think testing here should be very minimal and just check that the TRA funnel index level setting to a request object _IF_ the request has it's method set to default. All the rest of the logic is a `ReplicationOperation` thing.
I think we should separate the two and push this as is. Your code refactoring has more changes than this functional change and on the security end I think we should be careful. let get this in and cleanup the stuff afterwards
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
I don't believe its necessary, ++ for taking it out
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
+1 to not swallow the original exception
sorry, my bad.
good test, would be better to move it to a brand new class though, as this existing test class starts a single node cluster but you don't need to send any requests to it. This is a pure unit test, you can call it `StringFieldMapperXContentTests` and make it extend `ElasticsearchTestCase`.
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
Nit: Can we give this a more meaningful name instead of an abbreviation? I'm fine with `TestResponseHandler` for example.
I wish that we did not have to go from MapperScript to IndexTimeScript, and rather reuse the same concept. I still wonder if this could be `void executeScript(SearchLookup, LeafReaderContext, ParseContext)`? We could make the notion of scripted field known to FieldMapper, let MappingLookup collect all mappers that have a script declared, then each one of those has the execute method called. That way you can also ensure the same behaviour once you add this functionality to other mappers? This suggestion goes against another one I made on making OneTimeFieldExecutor implement IndexTimeScript. MAybe with this suggestion IndexTimeScript could go away and we would have to see what to do with the one time executor.
I just realized that this would make the upgrade experience really difficult for indices that break this limit already. They would have to close their index before the upgrade, change the limit in the new version and open the index again. That's a bit too much I believe so to be safe we should check this setting only for indices created before it existed: ``` if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0_alpha1)) ``` ... and only log a deprecation warning if the filter breaks the limit on an index that was created an a previous version (see DeprecationLogger and its usage to see how to do that). This way we could also backport this new setting in 6.x and makes the upgrade easier.
Can we add an assertion that this is never negative? I don't think it ever will be, but just to be sure...
tests should avoid using `now` as it can hurt reproducibility
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
Can't recovery -> Can't recover
why did you change this to take a `TranslogGeneration` with the uuid instead of just the `long minGeneration`? It's not using that uuid anywhere here AFAICS.
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
This can be `assertTrue(called.compareAndSet(false, true))` to avoid the race condition between the assert and the set.
you are right thanks a lot for catching this
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
this is usually a bad sign. We should use sleep anywhere. Sometimes it's needed but we try give all the utilities to make sure no one used it explicitly. In this case we have assert busy: ``` assertBusy(() -> { final ClusterState currState = internalCluster().clusterService(masterNode1).state(); assertTrue("index not deleted", currState.metaData().hasIndex("test") == false && currState.status() == ClusterState.ClusterStateStatus.APPLIED); }); ```
I don't understand here what you mean by synthetic variable. If you mean the two ENulls, the analysis and writing would be contained to only compile-time.
I'm not a big fan of ActionListener<Void>? Maybe we can do this differently and replace it with two functions? Runnable for the onResponse() part and for onFailure use a Consumer.
Hm. Not sure about the custom similarity part. For you maybe :) The whole purpose of IndexLookup was to have an easy to use api for access to term stats. I found it very convenient. Whether or not we should have IndexLookup is a different discussion because it can be used in other contexts too.
please wrap in {}
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
My preference would go to adding a serialization context to readFrom.
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
This includes both of the fixes but to make the change uncontorversial it should just include the `finally` part, not the checking if the file exists part. Personally I think removing the file up front is the right thing to do but I'd like to separate that out into a separate PR because I expect other folks to object to that way of doing it (see the linked issue) and I'd like to get the `finally` block portion of this fix in.
this always yields true
Sure. This one is more than good enough :)
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
ok I remember now. The point of IndicesRequest and CompositeIndicesRequest is to return the indices that a request works against. when a request is composed of multiple operations, it should implement CompositeIndicesRequest. In this case delete by query reads from some indices as part of search, and writes as part of deletes. But what indices would it delete from? It is not possible to create a DeleteRequest that points to multiple indices, yet it is hard to predict all the deletions that will be performed as part of the request execution. I doubt that this request should implement CompositeIndicesRequest then.
And it looks like you cover the response below. So you can ignore this.
yea sorry....... should have been "seems harmless". Yet we may want to change what we do here and whether we need logging or not. And not sneak it in among all these other changes.
doc level failure (normal failures are OK from an algorithmic perspective).
so this means we don't support `topLeft` anymore? I think we have to to be honest. Also we have to support `northWest`
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
Maybe let's just call Objects.equal(script, other.script) for simplicity? I know you did not introduce it though...
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
Earlier in the SecurityLifeCycleService the cluster changed event was handled in order - first, to handle the event in SecurityIndexManager later it would start the index audit trail. Is there any order defined which does not change the behavior of handling cluster event? Not sure if this would be of any concern.
I'm not sure if the cast is worth it here. It is usually simpler to just work in integers even if we know if can't be more than 255.
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
`this` is unnecessary
I personally think those queries should be build using query builders but we can do that in a second step.
This change would only break `wildcard` query on these fields, right ? +1 to make them string fields, `prefix` and `regex` query do not work currently because of this so it would be a bug fix. I am also ok to do that in a follow up, the changes in this pr have a different scope.
confuses the shit out of me everytime :)
Again, this doesn't seem to actually use the `entry.getValue()`.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
The 2 `if-else` conditions can then also be simplified to just: ``` if (lowestVersionSeen == null ||Â replicaNodeVersion.before(lowestVersionSeen)) { lowestVersionSeen = replicaNodeVersion; candidate = shardRouting; } ```
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
can you throw an exception in the else clause, eg. "All queries must extend AbstractQueryBuilder but ..."
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
would be nice to allow to configure it to a percentage of the heap size
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
Won't the `indexName` be wrong below, since it is just `_parent`? Maybe we should just have a special case here for `_parent` for now? Something like: ``` String indexName = fieldMapper.fieldType.names().indexName(); FieldDataType fieldDataType = fieldMapper.fieldType().fieldDataType(); if (fieldMapper instanceOf ParentFieldMapper) { ParentFieldMapper parentMapper = (ParentFieldMapper)fieldMapper; indexName = parentMapper.getJoinFieldType().names().indexName(); fieldDataType = parentMapper.getJoinFieldType().fieldDataType(); } ```
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
Why do we need a good github search when we have @clintongormley :)
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
Nit: `reject` -> `rejected`
well if you put in into an `assert` it's not called in production that is the purpose of `assertions`? I think we should call it at the bottom of the constructor and maybe in `iterator()` as well as `shards()`
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
I was confused because `request.index()` does not exist here. There is `getCurrentItem().index()` though.
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
What about just converting to bytes and comparing? The way you have it now this isn't consistent with `equals`.... Also the _cat API we call `toString` which doesn't really use the unit anyway.
this can be out of if now.
minor nit: "int he" -> "in the"
index's toString gives you '[index_name]' no need for '[{}]'
You can use `assertAcked()`
after rebase you will have to get rid of any wildcard import, or the build fails :)
Right - RollupIT is the right place
maybe put the actual and expected length in the message
braces please. for the rest of the method too. (I realize you just tweaked this to be a lambda but it would be good to fix this as two line single statement `if`s are dangerous and evil).
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
one too many new line? :)
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
I had a look and the settings code has been dramatically improved with 5.0 already, hence this fix is not required any longer. Nothing to do then, but thanks again for pointing this out.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
@s1monw if you're proposing we use inheritance and you assume the base class will always be caching DF then we could just remove all the "if(this.docFreq)" checks in the existing code as a simple way to clean things up? That would leave us with just the "if(this.totalTermFreq)" checks.
I'd probably add an `else` clause that sets `splitOnWhitespace` to the appropriate value just to be super clear.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
s/can't used/can't be used/;s/their/they/;s/subtile/subtle/
maybe use `shouldCompress` here to make it a little clearer? ```java if (shouldCompress) { IOUtils.closeWhileHandlingException(stream, bytesStreamOutput); } else { assert stream == bytesStreamOutput : "the stream variable is not the same instance as bytesStreamOutput"; IOUtils.closeWhileHandlingException(stream); } ```
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
`assertNoFailures` is more common in newer tests and much shorter.
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
This is not the right condition, a plugin bin directory is not required to exist.
I don't see this change implemented here.
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
again, this is the reasoning: if we check for existence of a field in the parser, it means that the only way it can be null in the builder is when it comes in through java api. In that case we might want to fail fast and throw error in the constructor/setter already rather than in validate. If non validated values might come in through the parser as well then validate is the way to go. In this case it makes to do as Christoph suggested. In term query builder I think it still makes sense what we do (again, you can test it to see the differences), same for common terms query.
I mean in the code but just noticed there was one already
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
Can you give each of them a numeric id instead? This will allow to rename the enum constants without breaking the bw compat of the stream
nit: mergeSourceIndex -> resizeSourceIndex
class could be `final`
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
we should get rid of the retry logic here entirely, there is no need for the while loop when we aren't retrying.
maybe `== false` just so we don't typo it in the future
Error if old-style params passed alongside new-style script
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
I think this needs to call PathUtils.get (not Paths.get) so that it does not use the JVM default filesystem, in the case one is set differently in tests.
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
it's fine to remove it
FYI we don't throw version conflicts on replicas any more... (not related to your change)
we should log the exception here.
[{}] for path.
Can we just explicitly test these? Let's have a test that the field is removed, no error, in the old ones, and another test that tan exception is thrown for newer indices. Randomizing the version is fine, but let's keep it to randomize within the versions we expect to have a particular behavior, so that we keep full coverage of what we are testing on every test run.
minor nit: "int he" -> "in the"
this is a personal preference, I like to avoid overriding the setup and teardown methods of estestcase and use separate one
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
Let's maybe call it `preCollect`? (symetric with `postCollect`)
would you mind reverting the variable name change, at least temporarily? it confuses the review
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
Why do we need a concrete and an abstract method for each test where the caller only calls these methods anyway? I think we should just make `testReadFrom` and `testWriteTo` abstract.
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
For backporting to 6.3, I think this needs to be changed to 7.
Did this change in the builder or does the case check stay? Can't find it, maybe missed it.
should this be "not mounting...consistently" or "mounting...inconsistently"? But I would think not the current double negative.
you can have a look at SimpleQueryStringBuilder.VERSION_5_1_0_UNRELEASED to see how to do it
I tend to try an indent these manually so they *look* a little more like json. Not that this is required, but it does help when they get big like this.
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
I think this check should go into initializeSnapshot or repository.
Got confused by this and had to go to the code :) - I think this will be clearer "returns the time in millisecond until this unassigned shard can be reassigned."
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
ok let's leave it as is for now.
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
I think this will be clearer if we say - "// precreate incoming indices and popluate them with the relevant types"
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
> I thought I was getting at that without making it too wordy. The key is that you're not registering a `DeprecationRestHandler` as the name `registerDeprecatedHandler` implies. Instead, you're registering a handler that gets wrapped as a `DeprecationRestHandler` before registration. I guess `registerAsDeprecationHandler` would be slightly less wordy than `registerHandlerAsDeprecationHandler` but the point still remains.
similar concerns as DeleteRequest
+1 to setTopReader instead of next (it makes more sense imo since there is a single top reader)
Where are these mapper helpers used? I've only found them used by tests. Maybe we don't need them? I removed a number of them before for metadata fields.
same here re enumSet.toString
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Itâs fine @javanna, pull it in in this one. I would prefer we keep changes like this out of PRs, they can go in separately, I want less to think about when I review.
Hope this doesn't bite us for really slow (read: Windows) CI servers...
oh damned it's BWC I guess...
Can you add a check for reparsing (ie taking a settings that have been run through archiver and using them in another settings builder) the settings works? ie the setting stays archived and doesn't disappear.
I think this catch not needed. It will be caught higher up.
Unless your node is named "1", this is not a valid configuration. Please have a look at the [docs](https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-discovery.html) or reach out to @DaveCTurner or me on how to configure this. Note that if your tests are running a single node in development mode, then no configuration should be necessary.
Can you indent this one extra time? When the body of the block below it and a part of the `if` statement line up I have trouble separating them properly when reading quickly.
nit: naming issue...
`com.sun.glass.ui.Size` appears to be unused.
maybe, to be more precise, it would be good to check the partition that included the new primary.
> However, I am not sure if we should do it. why is that? We're building all this machinery to have search availability during the transition, except for this very short moment? I had the same idea about retrying. An alternative would be to do refcounting for closing the engine, to ensure that we only actually close once all in-flight `acquireSearcher` calls have been completed.
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
I was wondering if `getSuperset/SubsetSize` is part of the Bucket interface but not rendered via the Rest response, should we either add rendering of these values to the bucket response or remove it from the interface to get equivalent behaviour of functionality of the transport client with the high level rest client here? I think this can be done in a separate issue though, maybe its not needed at all.
It's super minor, but our log standardization is usually all lowercase
oh I see. I missed it.
I think it could be null instead of `"*"`
I took a quick stab at sth. that avoids the Tuple and replacing the test builder [here](https://gist.github.com/cbuescher/88531fe7c2abd38936ef), but it still looks a little bit strange to me. EDIT: Doesn't work, equals-tests break with this little hack. Sorry, nevermind.
do we want to check the phase/action times since those are meant to change
fileswitch -> default here
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
calling `ConcurrentHashMap#size()` can be quite expensive IMO. I think we should keep track of the open ctx in a counter instead of using the map. I don't think being a little off here makes a difference. I think we don't need to add any sychronization changes here.
Why not have the standard to string? A multiline return value is difficult to work with in a debugger...
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
Same concern about reproducibility as in the other PR.
use `ThreadPool#terminate` here otherwise you will get lingering threads etc.
Do we need this on this one? It seems like these test suites are very small and any of them taking 40 minutes is grounds for making someone look at the VM at a minimum.
I'm not so comfortable with separating this code from the one in `updatePrimaryTermIfNeeded` - they are tightly connected. Instead of sharing code this way, how about creating a callback that will run: ``` indexShardOperationPermits.acquire(listener, executorOnDelay, true, debugInfo); ``` or ``` indexShardOperationPermits.asyncBlockOperations(listener, timeout.duration(), timeout.timeUnit()); ```
typo: tracker -> tracked
I think this should throw IAE if you pass null - that's 100% of the time a bug
you can just replace with `IOUtils#closeWhileHandlingExceptions`
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
this logic belongs in transportWriteAction
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
`originalLocation` param is redundant
+1 this makes sense. Then we can drop the `PIPELINE_ALREADY_PROCESSED` transport header.
I meant the listener we pass to the transport
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
@s1monw I tried but realized that `NumericDocValues#advanceExact` method requires increasing docID values but it's not the case here. Do you have any suggestion for this? ``` /** Advance the iterator to exactly {@code target} and return whether * {@code target} has a value. * {@code target} must be greater than or equal to the current * {@link #docID() doc ID} and must be a valid doc ID, ie. &ge; 0 and * &lt; {@code maxDoc}. * After this method returns, {@link #docID()} retuns {@code target}. */ public abstract boolean advanceExact(int target) throws IOException; ```
Fine with me.
I'd expect this to be in a synchronized block
I think this declaration/initialization can be moved to inside the if
we usually do check the lucene version in a static block ``` Java static { assert Version.CURRENT.luceneVersion == org.apache.lucene.utli.Version.LUCENE_48 : "Remove this class in Lucene 4.9"; } ```
@s1monw I'm sorry that I didn't take any time to reply last night. The situation with the response parameters is quite complicated. Look for example at `Settings#toXContent`. The situation here is that the `flat_settings` parameter is consumed there, but the signature `ToXContent#toXContent(XContentBuilder, Params)` is a general signature, we can't just go and add a boolean parameter for flat settings to the interface because it doesn't make sense in all situations. It is for this and similar reasons that I ultimately handled response parameters the way that I did. Barring a redesign, I would prefer that we remain consistent for now. > It's just yet another place we need to maintain and look for params. Right now it is how we handle output parameters.
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
This field is `static`, but it's set via a constructor. That seems odd.
Hurray no more weird `while (true)` loop
I assumed that there is no problem setting values and checking that the output of the conversion from high-level request to low-level request is the expected one. We don't validate etc. I would do only what is straight-forward.
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
good point I am curious too now :) I hadn't noticed this at first
I was just opening the issue but I'll wait to see the conclusion here first in case we decide copying the first directory manually is still a better trade-off.
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
same here and in the rest of this method
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
I see you have backcompat below for when this setting is passed in through a string field. However, i think we also need to have it for custom analyzers here.
I think we should fail the local shard on any unexpected error. Seems like the "safe" thing to do..
I would probably throw an exception instead of accepting null here.
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
I swear I'm missing something. I thought that top-level variables wouldn't be working with this based on the grammar changes I see...
thanks for adding this
Something like "This class assumes that the supplier is fast, with performance on the order of a volatile read." would give a lot of context to the decisions around how to use the Supplier.
I wonder if it'd be easier to read if there were two methods? I'd kind of feel more comfortable having two just so you don't need auto-boxing. It might not make a huge difference, but in general `Rounding` doesn't its best not to allocate stuff. I think this method doesn't have to be so efficient, but still.
I get that, I was just wondering why those default templates bother here
the XContent here does not match what you removed in the REST API. There was a bit about early termination, as well as count that you need to include. You likely need to also include the begin/end calls, or else this will fail tests. You can check the tests with `./gradlew :server:check` from the base of the checkout. If tests dont fail then we need some better tests around the response hehe
They are just hedging their bets.
Should this else clause be returned to what it was before the original refactoring PR? https://github.com/elastic/elasticsearch/pull/32068/files#diff-c94184ea4ef180f10817aa2bbd41a8edL119
why is this? what's wrong with `1.f`
oh cool the read is in the ctor! nice!
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
these unit tests are great! We are going to need more of them :)
do we need ordered things? does order help anywhere? If not I would just use HashMap
I don't think we should swallow the exceptions here, instead, this could be a try-with-resources block like: ``` java try (BufferedReader br = new BufferedReader(rulesReader)) { .. read the string .. } ```
the utility should be a static class
Actually, now that you refactored LongHash, I think this can be made much simpler: we can just iterate with `i` from `0` to `bucketOrds.size()` (which is the number of entries in the hash table, instead of `bucketOrds.capacity()` which is the number of slots) and directly use `i` as a bucket ordinal. ``` patch --- a/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/LongTermsAggregator.java +++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/LongTermsAggregator.java @@ -108,13 +108,7 @@ public class LongTermsAggregator extends BucketsAggregator { BucketPriorityQueue ordered = new BucketPriorityQueue(size, order.comparator(this)); LongTerms.Bucket spare = null; - for (long i = 0; i < bucketOrds.capacity(); ++i) { - final long ord = bucketOrds.id(i); - if (ord < 0) { - // slot is not allocated - continue; - } - + for (long ord = 0; ord < bucketOrds.size(); ++ord) { if (spare == null) { spare = new LongTerms.Bucket(0, 0, null); } ``` (The same change should apply to other aggs.)
seems redundant indeed
Nit: `cs version` -> `cluster_state_version`, please.
The use of `#` might make queries confusing since it is also used for filter clauses.
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
and 2 more occurrences below
This check is unnecessary as if a job is being opened we are certain there is ML Metadata already installed.
This line will break our `precommit` checks because it violates the 140-character line-length limit.
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
good point, I think it's ok if it is configurable. and then it should do by default the same as the rest of the same search request does.
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
finally! its gone!
nit: `accuracy` instead of `Accuracy`
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
ok I remember now. The point of IndicesRequest and CompositeIndicesRequest is to return the indices that a request works against. when a request is composed of multiple operations, it should implement CompositeIndicesRequest. In this case delete by query reads from some indices as part of search, and writes as part of deletes. But what indices would it delete from? It is not possible to create a DeleteRequest that points to multiple indices, yet it is hard to predict all the deletions that will be performed as part of the request execution. I doubt that this request should implement CompositeIndicesRequest then.
should probably be `Math.abs(value) >= 65520` rather than 65504. 65504 is indeed the maximum value but values up to 65520 excluded would be rounded to 65504
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
I'd recommend using the same syntax Lucene does: ``` bq.clauses().iterator().next().getQuery() ``` Just to follow their conventions
cool stuff I didn't see that one!
oh sorry, I had missed that you used the filtered collection below
no need to break here
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
Is this extra method needed? I would combine it with the previous one that seems to be its only caller atm.
I wonder if we should start already sharing some common code between our BaseQueryTestCase and this class....wouldn't want to complicate things though. Also our base test class in not in master of course so that woul already complicate things...
This logging statement has a `[{}]` but no argument to fill it
was the answer yes? :)
What if this.docCount was already -1? then it should stay -1 right? (in the else case here)
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
We can remove the `!` if we reverse this if statement, so ```java if (difference.isEmpty()) { status = RestStatus.OK; } else { ... the error stuff ... }
oh, woops. thought I counted right. sry
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
use `assertNoShardFailures` here please
``` if (Double.isNaN(v1)) { return Double.isNaN(v2) ? 0 : 1; } ```
same here, I think it will be easier to read with "shard state persisted despite of persist=false"
this keeps bugging me :) we should something on the executor as well....
Simon added a fancy resolveIndex method
we should also catch `NoSuchFileException`
I think we can reduce the scope of this change by exposing a resolveShardId method that resolves index,type,id and routing to a shardId. And then we don't need to touch these. Also, I know that type is not used now, but why not pass it? is there a place we don't have it? I hope we can back port this change to 2.x, so having type here will reduce the change.
I wonder if we should make this a hard exception, potentially in the AllocationId constructor. When we start using this ID, a null value will create havoc in other places and will be hard to debug..
we can make this a function to `List<MergableCustomMetaData>` - we alreay check with instance of in the implementation of it.
sweet! and we should have REST tests for them which you haven't removed, so everything should be fine indeed
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
Ok fair enough, Hadn't considered the settings aspect of this.
nit: extra line
I prefer my way but have asked @jasontedor to chime in.
something is wrong in this sentence :)
right, other encodings have no use here. Sorry for the holdup...
I don't think we need the constant.
I see, that is hideous. ð¦
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
Correct [equals](http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#equals%28java.lang.Object%29) implementation supposed to be reflexive. In other words the following test should pass: ``` StoreFileMetaData test = new StoreFileMetaData("test", 0, null, null); assertEquals(test, test); ``` Maybe `equals` is not a good substitution for `isSame` here.
I think we should not execute these writes directly here but extend ESIndexLevelReplicationTestCase#ReplicationAction then run them via the infra of the new action (see ESIndexLevelReplicationTestCase#IndexingAction).
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
I don't think you need the `Integer.toString` bit.
we should include `e` here, otherwise we lose the cause of the configuration error.
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
We typically do this light weight coordination on the same thread. I.e., Names.SAME . This does nothingother than spawn another bulk request. This will cause a new thread to be spawned as we don't do anything else with the bulk pool on the client. To be honest, I don't think the transport client should have so many thread pools. I'll open a different issue for that.
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
We should have access to the services on the coordinating node, and they should be usable there, so I think this will come out in further refactoring.
the start cluster does this.
I'm on the fence as to whether we should only do this on non-realtime get. Real time gets don't really relate to refresh cycles (they force a refresh if needed). They are already "efficient" in the sense that they only refresh if they need to (i.e., there's a pending doc change in the version map).
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
s/payload is/payloads are
We can avoid arraylist resizing by creating it with `diff.different.size() + diff.missing.size()` and then doing `addAll` for the diff parts
This situation feels very fragile to me. It means in the future if we do want a settings instance here because we want to control fine-grained logging settings for a CLI tool, we can not without accidentally reintroducing the problem.
My concern here is if a user sets the budget to `H` headers and `B` bytes because they can not handle more than that (e.g., the common case being a proxy) then we have to subtract a header (or possibly many) to stay under the `(H, B)` budget after we include the missed warnings warning.
Is the version needed? I don't see it being read here.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
We should log the the failure here if the close fails
By keeping track of contexts in 2 different data-structures, I think you are potentially introducing race conditions, eg. if a clear scroll action is issued concurrently with an automatic release of the context due to the fact there are no more hits to process.
this can go back to boolean if we move back Settings to boolean too
can we fold this into ClusterHealthResponse? that way we can test this as well as part of the unit testing.
I don't think this test is needed. `testSpanMultiTermQuery` does the same thing.
I might make something like ``` private void expectMissingBodyError(Matcher<String> responseMatcher, ThrowingRunnable exec) { ResponseException responseException = expectThrows(ResponseException.class, exec); assertEquals(400, responseException.getResponse().getStatusLine().getStatusCode()); assertThat(responseException.getMessage(), responseMatcher); }
maybe make if final
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
I wish that we did not have to go from MapperScript to IndexTimeScript, and rather reuse the same concept. I still wonder if this could be `void executeScript(SearchLookup, LeafReaderContext, ParseContext)`? We could make the notion of scripted field known to FieldMapper, let MappingLookup collect all mappers that have a script declared, then each one of those has the execute method called. That way you can also ensure the same behaviour once you add this functionality to other mappers? This suggestion goes against another one I made on making OneTimeFieldExecutor implement IndexTimeScript. MAybe with this suggestion IndexTimeScript could go away and we would have to see what to do with the one time executor.
I think that we need to guard against overflow here!
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
I don't think that we need such big docs, 100kb seems a lot still even if it's the upper bound.
should this be "not mounting...consistently" or "mounting...inconsistently"? But I would think not the current double negative.
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
it is to me, buy hey, taste :) up to you.
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
Man this feels like a mess compared to ObjectParser. We can't do anything about it in the middle of this PR though. Just makes me sad.
you can remove the validate call for now, we will fix all queries soon, I promise
I don't understand here what you mean by synthetic variable. If you mean the two ENulls, the analysis and writing would be contained to only compile-time.
might also want to add a toString implementation on ShardRecoveryHandler or add the shard in question to the assert.
I always wonder if we should use the PROTOTYPE constant here instead, cause that is what we need I guess. If so we should change all other tests accordingly
I think the naming is fine. This feature as described in the issue is about not counting tokens filtered from the token stream. This is what `enable_position_increments=false` does and I think it's all we need to do here. If your analyzer adds alternative tokens to each position they should not alter the final count since we're looking for the number of tokens in the original text.
Nit: add a space between `if` and `(`
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
maybe we should have a constant for it
ð much better readable
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
Right - RollupIT is the right place
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
maybe call this `getMetaDataOrDefault()`
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
why is this? what's wrong with `1.f`
I you decide to go this route you should also remember to replace the reference equality checks (`this == ActiveShardCount.NONE`) by equals checks or by looking at value (`this.value == 0`).
We don't want to actually check what version of `openssl` they have installed. They might be generating certificates to be used on a different machine that has a different version of openssl. It's OK to always print a warning about the password exceeding the old openssl limit.
I think an explanation why it's ok to throw an exception here might be helpful for future us.
wondering whether `CompiledScript` should hold the `Script` and `ExecutableScript` should hold the `CompiledScript`
see text from other suggestion for empty primary allocation
I'd probably write validate's results to a variable and reuse it.
Any way we can unify this with `BucketHelpers.resolveBucketValue()`? Or perhaps move this into the helper class and rename both of them to be more specific (`resolveHistoBucketValue()` and `resolveMultiBucketValue()` or something?) Also, I foresee this needing to handle gap policies too...unfortunately. :( For example, an agg like Autocorrelation needs to ingest a histogram (which might need gap policy) but emits a set of sibling buckets that represent correlation lags.
Nit: please add a space before the `,` separating the function arguments.
once #12937 is in we can do the following here: ``` QueryBuilder<?> finalQuery; if (queryBuilder.indices().length == 1 && getIndex().getName().equals(queryBuilder.indices()[0])) { finalQuery = queryBuilder.innerQuery(); } else { finalQuery = queryBuilder.noMatchQuery(); } Query finalLuceneQuery = finalQuery.toQuery(context); if (finalLuceneQuery != null) { finalLuceneQuery.setBoost(queryBuilder.boost()); } assertEquals(query, finalLuceneQuery); ```
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
why is this? what's wrong with `1.f`
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
I think it is good enough to call `output.bytes().steamInput()`.
we have `ToXContent.EMPTY_PARAMS`
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
I think this can become an assertion now? we never expect it to happen...
so `round` should be called once per factory instead of once per aggregator
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
I think I saw this in Christoph's PR too. Hopefully you don't need it.
no need to reason an "ex.getMessage", we already log the exception...
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
I see, yea we can't avoid this then. Maybe share the default value through a constant so at least we don't duplicate it. Odd! :)
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
there is an `hasUnassigned` method already, so yeah, I'm +1 on being explicit here...
Asserts are better for this. ð
I'm experiencing the same @s1monw . I had missed this change and I would like to better understand the rationale behind it. Why do we have to restart the global cluster if a test fails within the suite? Also, this seems wrong as if there's one failure in the suite we restart the global cluster for all the subsequent tests...this slows down all the subsequent tests quite a lot (e.g. think of REST tests in network mode).
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
Can change this to the new autoclose functionality in Java 7 now that the codebase is on it: ``` try (ZipFile zipFile = new ZipFile(pluginFile)) { // ... } catch (Exception e) { // ... } ``` Thereby dropping the entire `zipFile`-related code from within the `finally` block.
Feels a bit weird that one method is returning a list and the other one an array
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
maybe make if final
similar concerns as IndexRequest
I saw this problem being dealt with in other place by setting currentFieldName to empty String. Worst that can happen then is that it is treated as fieldName in the query, which we should validate later and throw IAE then.
remove the set boost
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
index's toString gives you '[index_name]' no need for '[{}]'
this makes me wonder: if a node has node.ingest set to false, for sure no processors should run, hence simulate should be off and IngestDisabledActionFilter should throw exception when a pipeline_id is used as it does now. But how about crud actions for pipelines? One has to go to specific nodes to store them, that have node.ingest set to true? this may not be needed, as those are just index, delete and get operations that any node supports...it's like making client nodes reject index requests, they can forward them to the proper nodes, no problem with that.
Nit: addresses -> address
Same here for `compareAndSet`
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
I think this should be an `assert false;` + throw new UnsupportedOperationException
Nit: please add spaces around the `=` sign.
The message is a little weird. I don't think "next release" should be mentioned.
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Checkstyle is unhappy with this.
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
could be `final`
that awfully sounds like two voices for debug.... your turn, @jasontedor.
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
`blocksmd.copyContext(trysmd);`? I know you use "context" to mean something and this might not be the right use of that word though.
Maybe `SystemUser.NAME`? I worry that in the future when we do object level security using a username that doesnât correspond to a real user may be a security hole.
Here it still says `on a per index basis` -> should be corrected.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
no need for if/else, just write ``` return getNodeDecisions() != null && getNodeDecisions().stream().anyMatch(...) ```
no matter what I really want to have the manger go away here. I think it bloats the code we can just fold it in.
ok. I'm with you.
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
Is the version needed? I don't see it being read here.
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
> write past EOF :dancers: +1!
but why? :)
You could probably avoid this by making the linux check a method that you stub out in OsProbe.
unkown -> uknown
I think this can leak a reader if `reset(DirectoryReader delegate)` fails (especially when the `this.delegate != null` is true)
@javanna thank you that helps a lot.
I think I forgot a .value possibly? From your message I did not get if you managed to make it work after all, if not ping me and let's make sure that it works on doc_values
++ on removing this catch. Not true any more
oh, woops. thought I counted right. sry
fine with me as well. go ahead and push!
Nit: I think you can leave out ESTestCase here.
This question reminds me of an interesting larger topic that I believe could be related: At least for precision IIRC one can compute a micro-averaged or macro-averaged version. Maybe it makes sense to let users decide which of the two (or both) they want? No idea how this plays out with the other quality metrics you looked at.
you can comma separate these instead... i know the likelihood of us not using `/` is low, but its best to not have them in this.
I wonder if we should enable this only for new indices that we know are created with es 1.4
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
All of this is equivalent to the simpler ``` return Objects.equals(newMasterNode, previousMasterNode) == false; ``` (see equals implementation of DiscoveryNode)
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
connec to to -> connect to
nit: could be one line
nit: maybe the null check isn't necessary
Needs a guard.
I have no idea how we get these weirdly aligned lines....
I think we should have these checks in validate. and if we don't want to rely on validate in doXContent have if conditionals there and ignore what's null just to prevent NPEs, but I wouldn't want to do validation and throw IAE in doXContent, where we just print stuff out.
why do you pass the response to this method? `this` already has all information.
Good point, I was thinking about fielddata_fields but we can't get them anyway if a doc is only in the translog...
``` java assertThat(provider.fetchCount, is(1)); ```
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
Why do we register `S3Repository.Repository.*` settings here? Those are extracted from the repository settings when it is created/registered, but I don't think we need to register a global `compress` or `throttle_retries` setting...
I think an absurdly high limit could still be helpful? (in a follow-up PR)
can we increase the timeout on the request? if one runs a debugger the test may fail to retry because a timeout happens, making it confusing.
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
removed? It does not seem to be used.
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
I suggest that we take advantage of this change to remove support for time-based expiration, which we don't need
+1 to not swallow the original exception
I think this `close()` should be in a `finally` block in case the write fails
same here. ElasticsearchAssertions.assertThrows wil help
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
Super-minor, but missing a space between `if` and `(` here.
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
but why? :)
+1 on just `field`
Someday we're really going to have to standardize on American "canceled" or British/Australian "cancelled"... :)
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
can we not wrap a translog but rather just keep this test translog next to the normal one? keep it simple and readable :)
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
And one downside even with being initialized before each test method, is some tests do multiple asserts like this inside a single method. So we'd have to clean up those tests to be separate test methods, but thats still fine.
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
maybe also rename the setting? (in addition to the constant)
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
I'm happy we have all these tests. It is also another data point to move in the direction we discussed - i.e., failures should mark things as stale.
I do not think we should log here. This is on the reload of a file and not an update to the ciphers settings
I am always getting confused by this one and refresh. Shouldn't this be `WRITE` and not `METADATA_WRITE`? We don't really change any metadata here.
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
Could you explain why this is needed instead of checking `expireAfterAccess <= 0`? I think it'd make the class more readable.
Sorry, I overlooked the null check. This is good!
I think it's better to use the index version created to test whether the old or the new parent join should be used. This way you can make sure that the correct explanation is returned in the exception if the parent field is not filled.
Also `-test1,*test2*,-test20` or something along those lines? :)
ok let's avoid the concurrent put/computeIfAbsent issue for now, we can try to improve in the future if we observe slow concurrent access
use simpler constructor.
I think it'd be nice to remove this second ctor so we're explicit every time.
Typo: "recover" -> "recovery"
I think we should use `debug` for the logging here
