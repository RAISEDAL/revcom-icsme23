also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
Since you don't care about the body of the source maybe use something like `setSource("foo", "bar")`.
I like `hasSize(1)` for this kind of thing because it makes a nicer error message.
this is much better!! ð
The `<=` will need to be escaped.
Nit: " . " -> ". "
Not important, but couldn't this just be an array? String[] possiblePathValues = {"some_path", "anotherPath", null};
Should we also have tests for the case that some intermediate mappers already exist? For instance above you are testing to index a field called `foo.bar.baz`, so it would be interesting to check that everything also works if `foo` already exists.
I see, and you are right, camel case is preferred. I probably misread the "NoNestedDocs" part of the name as "no nested docs" and that confused me for a second, but either way is fine.
can we have braces around that ie: ``` if (newQ == subQuery) { return this; } ```
Can you propagate the boost to this query? If this query is enclosed in a BooleanQuery, it could have an impact on the normalization factor.
we set the rewrite method twice it seems? probably a bug in the original parser
yes, make sense
also, using a non-inner class means we can free the memory (i.e. cluster state copy) rather then have them accumulate with every retry
We can pass a name in the constructor if need be? On 11 dec. 2015 9:53 AM +0100, Martijn van Groningennotifications@github.com, wrote: > Incore/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java(https://github.com/elastic/elasticsearch/pull/15363#discussion_r47332645): > > > @@ -304,7 +304,27 @@ public void onFailure(Throwable t) {>observer.waitForNextChange(new ClusterStateObserver.Listener() {>@Override>public void onNewClusterState(ClusterState state) {>- threadPool.executor(executor).execute(AsyncReplicaAction.this);>+ transportService.sendRequest(clusterService.localNode(), transportReplicaAction, request, new EmptyTransportResponseHandler(ThreadPool.Names.SAME) {>+>+ @Override>+ public void handleResponse(TransportResponse.Empty response) {>+ try {>+ channel.sendResponse(response);>+ } catch (IOException e) {>+ logger.debug("failed to send retry on replica response, action [{}], request [{}]", e, actionName, request); > > got it. btw about the generic helper, we always have a custom log message or want to deal a failure differently in many scenarios, so I think a generic helper isn't going to help much. > > â > Reply to this email directly orview it on GitHub(https://github.com/elastic/elasticsearch/pull/15363/files#r47332645).
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
Ok, then it's fine.
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
ok, fair enough. ++ for setting up compatibility with GeoPointv2
is it worth doing the conversion from and to geohash every time here? Could it be better to not do the conversion and store two doubles per bucket instead of one long? I guess its a trade-off between execution time and memory
btw - the test uncovered some issue with the dangling indices import. You might run into a node not connected issues - working on an independent fix.
You are right, I was confused because of what I saw in ScriptImpl for painless (naming implying it was in variables for the script, but that is actually the params). I still think this needs to be its own context. We can eventually move these to direct arguments of the execute method (again, so params can be read-only in the future).
I think this should be its own context. Putting these into params would be a breaking change, and also not utilize the intent of having contexts (different variables for different uses).
looks new. I like this update!
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
This is logic that I think should go into ReplicatedOperation.
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
Whoa this is even stranger to read since it spans 3 lines
the node where the shard should move to
Perhaps annotate this one with `@Nullable` since it's the only one that can be null here
nit: missing space
I don't think this test is needed. `testSpanMultiTermQuery` does the same thing.
yeah that is true. nevermind then
nit: please use lowercase start for variable names
nit: please use lowercase start for variable names
You can use `XContentParserUtils.throwUnknownToken()` (that would throw a ParsingException instead but I think it's appropriate here)
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
I would leave it as-is, it needs to extend BaseQueryTestCase
ah ok I see
Since we're moving that, we could inline this using turnary.
To make jobs built with this method reusable when we come to send data to them in other tests, I think it would be better to fix the time format to `EPOCH_MS` and time field name to a specific value, e.g. "time". However, since it takes hours to get the PR CI build to complete and we'll be changing this same file in future PRs that implement the other endpoints I'm happy to leave this as-is for now.
Given that there are 3 tests it would be nice to give all of them descriptive names.
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
here too we do the same twice
you can replace with //norelease so we don't forget but at least you can get this in while we fix this problem in master.
This method takes a phrase query and is supposed to create an equivalent phrase query that just has a different value of the slop, so we need to transfer the boost? Maybe the method should look like this now: ``` java private Query applySlop(Query q, int slop) { float boost = 1f; Query underlyingQuery = q; while (underlyingQuery instanceof BoostQuery) { BoostQuery bq = (BoostQuery) underlyingQuery; boost *= bq.getBoost(); underlyingQuery = bq.getQuery(); } if (underlyingQuery instanceof PhraseQuery) { PhraseQuery pq = (PhraseQuery) underlyingQuery; PhraseQuery.Builder builder = new PhraseQuery.Builder(); builder.setSlop(slop); final Term[] terms = pq.getTerms(); final int[] positions = pq.getPositions(); for (int i = 0; i < terms.length; ++i) { builder.add(terms[i], positions[i]); } pq = builder.build(); pq.setBoost(boost); return pq; } else if (underlyingQuery instanceof MultiPhraseQuery) { ((MultiPhraseQuery) underlyingQuery).setSlop(slop); return q; } else { return q; } } ```
if we can assert that, it would work for me too
I think it should either be an `else if` or the `if` should be on the next line.
maybe call this `getMetaDataOrDefault()`
I notice this pattern in every implementation. Perhaps this should be a Map instead of Collection (keyed by the custom type name)? Then the map can be copied, and keys replaced, removed, or added easily, without needing to have logic for the other custom metadata that the plugin does not care about.
Please no `null` for no change needed, returning `Function.identity` is clear, and there is no need to make an optimization check.
the important part is having multiple open readers on this as well.
as an alternative you can mark it as final abstract then you don't need the private ctor
something like this: ```Java public SearchOnlyEngine(EngineConfig config) { super(config); try { Store store = config.getStore(); store.incRef(); DirectoryReader reader = null; boolean success = false; try { this.lastCommittedSegmentInfos = Lucene.readSegmentInfos(store.directory()); this.translogStats = new TranslogStats(0, 0, 0, 0, 0); final SequenceNumbers.CommitInfo seqNoStats = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(lastCommittedSegmentInfos.userData.entrySet()); long maxSeqNo = seqNoStats.maxSeqNo; long localCheckpoint = seqNoStats.localCheckpoint; this.seqNoStats = new SeqNoStats(maxSeqNo, localCheckpoint, localCheckpoint); reader = SeqIdGeneratingDirectoryReader.wrap(ElasticsearchDirectoryReader.wrap(DirectoryReader .open(store.directory()), config.getShardId()), config.getPrimaryTermSupplier().getAsLong()); this.indexCommit = reader.getIndexCommit(); this.searcherManager = new SearcherManager(reader, new SearcherFactory()); success = true; } finally { if (success == false) { IOUtils.close(reader, store::decRef); } } } catch (IOException e) { throw new UncheckedIOException(e); // this is stupid } } ``` I did something similar a while back so I had it ready... I am not sure it safe to use ð¯
good point! I think we need to iterate over the filterFunctionBuilders and rewrite their corresponding filters
you are the man! that is awesome!!! that should just work. I really wonder if we can build a BWC test index with a percolator that ensures we can read this stuff if would be awesome to have asuch a test
looks like it can be final
please give us messages for the assertions
You already asserted this 2 lines ago, this is a duplicate.
I think we should use `writeAtomic` everywhere just to reduce the complexity.
having another look, index time lookup is needed when creating the search lookup, and I actually made another suggestion around possibly not needing IndexTimeScript entirely, so I don't think we will be able to do without adding indexTimeLooup.
You could add an assert that it's not ES 7.x here so we know to remove it
Notice the difference in the first parameter to MergeResult. This is the "simulate" argument. The first time we don't change anything in the merge, only check for any problems. Ideally we could move this simulation to something like we have here with check compatibility. I had a branch for a this long ago, but it was a complex change.
fair enough, leave it.
this class could be made `final`
Nit: this blank line is extraneous.
nit: finishes running on the node
we are generally moving away from gazillion packages and classes I am not a fan of all these service and they make things more complicated than they need to be today. I have a hard time to understand what feels wrong here and where you draw the line
it's really taste I guess so fine with me
I don't think we need to change this here.
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
oh I see what you meant now in the other PR :) if Tuples don't pollute the method arguments, I am ok with this, actually it simplifies synchronization issues between the two maps otherwise, I will update my PR to do the same.
Actually I just checked and removing name and description from the Plugin interface should be easy. The only thing to think about is what to give for those properties when plugins are loaded from the classpath (plugin.types). I think here the name should just be the classname, and description something like "plugin loaded from classpath"? I don't know what other info we really have.
Also, can you add an element to maven enforcer plugin for plugins/pom.xml so it fails build cleanly and early if this property is not set? We should also insert a check in pluginservice, if it differs from the directory name, someone manually meddled
This file is new in 2.0, we can change it
I think we should just use Set? The ExtentionPoint class was added at a time we thought that would be the new plugin model. But I don't think we should use it anymore.
As long as we make sure plugins don't try to overwrite any of our handlers, I think we will be fine. They pass back a set, so if they decide to insert the same class twice, it's their own silliness.
new ArrayList<String>() => new ArrayList<>()
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
maybe, to be more precise, it would be good to check the partition that included the new primary.
do we need this Reader interface? can't this just be `Funciton<StreamInput, T> reader`
finally! its gone!
StreamInputReader already does this.
Simon would say replace with `== false` ;)
let's have an assert and drop the branch
it's fine, when I did the refactoring SpanQueryBuilder became an abstract class without any problem, but now it needs to be a marker interface again cause java doesn't support multiple inheritance ;) We just need a cast, sorry for the noise I had missed this change to be honest but now I get it, thanks a lot for digging!
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
ah ok I see
otherwise, if you want it for testing, it can be done once in the ctor
This can just be `System.out.print(msg)` now I think. Thanks for removing the formatting from these print apis! I think that was the real problem, its trappy for a `printf()` to be named anything other than `*printf()`. And in this case the caller can just always `String.format` themselves.
args are not used.. we should either remove those from the method sig (which will be consistent with the `println` methods) or pass `String.format(text, args)` to `doPrint`
I actually wonder if we should have a `MaybeBoolean` class that implements `ToXContent` and can do these kind of merge operations ie similar of haskel maybe
can we implement this in a non-functional way? I have a hard time to understand that
do we need ordered things? does order help anywhere? If not I would just use HashMap
I don't see NO_MORE_DOCS changing in the future. I don't dislike having NO_MORE_DOCS=MAX_VALUE, it makes the sequences of integers returned by DocIdSetIterator monotonic from -1 (not started) to MAX_VALUE (exhausted) :)
Hmm, this assertion can never fail? (NO_NORE_DOCS is Integer.MAX_VALUE). It looks like the other modes have the same issue, I think the intent was to put a "&&" instead of the "||"
Sure, I was just wondering as this patterns appears now at least 3 times.
are we losing the STRICT bit here? it's important that we use STRICT here, so we make sure that we never output deprecated stuff ourselves. and we test deprecations separately.
same here, might be that we are good, but let's make sure we don't lose the STRICT one
I think the following if is not valid anymore in fromXContent: ``` MatchQuery.Type type = MatchQuery.Type.BOOLEAN; if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_FIELD)) { type = MatchQuery.Type.PHRASE; } else if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_PREFIX_FIELD)) { type = MatchQuery.Type.PHRASE_PREFIX; } ```
I c... ok
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
this method is dangerous as it wrong usage leads to re-resolving all the time. Maybe just remove it and do the `resolveSnapshotId` in TransportDeleteSnapshotAction
maybe call this "resolveSnapshotNames"? I would also prefer to use `List<String> snapshotNames` as parameter to bring it closer to the return type.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
I think that's pretty much illegal it should not throw any and it should be handled internally
I think we should move this above the nodeChannels.close() so it will be logged before an eventual consequence.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
Add short-curcuit return if this == other.
Wondering if it would be possible to create the builder first, then call all these setters in the parsing loop above already. Not really that important though.
Sure, thats fine.
++ can't hurt :)
typo: direct**or** -> direct
oh boy :)
I think it might be nice to have it behave the same for the Java API, where it needs to be explicitly set, but as you say, this can be a separate PR
As I mentioned above, I do think we should support both 0 and -1 for no throttle to be consistent with our other "disabling" APIs
This might be really confusing. We don't support any parameters that are provided by `BaseTasksRequest<GetTaskRequest>` so the only reason to use it would be to continue using TransportTasksAction which is overkill here anyway since we know the node that we need to get the task from. So, we can base this directly on TransportNodesAction instead.
you can probably cast it here and reuse it later
oh I see the trouble that I caused you, because not all of them are actually ElasticsearchException. Good test though, much more coverage now!
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
Note to remember: while this is kept as a QueryBuilder internally, I think we need to make sure to call `toFiler()` on it once on the shard (e.g. in the new build() method, doesn't seem to be there yet)
Add short-curcuit return if this == other.
Since you touched the response, I am doing my duty to recommend moving these tests to `AbstractHlrcStreamableXContentTestCase` .
I think I saw this in Christoph's PR too. Hopefully you don't need it.
same heere, randomIntBetween(0, 5) would be more life-like
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
this shouldn't be done here - it's part of the indexing logic.
The caller should continue consuming the snapshot until the `next` method returns null. In the last call, lastSeenSeqNo equals to toSeqNo and op is null. This guard is added to avoid checking in this case. I am +1 on the assertion.
@bleskes I moved this to `next` but we also need to dudup for nested docs then I moved this to `readDocAsOp` again. I think we should optimize for nested docs. I am open to suggestions here.
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
nit: formatting, add some whitespaces
Nit: please add spaces around the `=` sign.
make it final
Make it `public abstract class`
If the usage of forbidden APIs is in a few places, I would consider it better to suppress only at the lowest level (sometimes I like wrapping those in a private method I suppress). The reason is that if an unintentional forbidden call creeps in it will be caught.
just as a sanity check that declares we do not support arbitrary unicode. I don't think we have that around
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
Er, probably not. But a bit confusing name because it looks like a typo.
I think this file needs formatting `if(` -> `if (`
ok can we rename the getter then to `getFailedNodeExceptions()`
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
nit: s/read blob's/read the blob's
I'd throw the exception in `initCannedACL()` method instead of checking for a `null` here.
This is where a safeClient() would be helpful, so that you have less chance that the underlying storage instance changed between the copy and delete calls
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
I think we should stick with calling these getters like `getCharFilters` because it is the char filters that the plugin has, they aren't "extra" in the context of this one plugin.
I think it'd be nice to have this in :test:framework so others can use it.
We should remove the Store part. Perhaps make a constructor with a name? these errors are difficult tot trace so we should make it as clear as possible where the error came from (even if the stack trace is lost)
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
I wonder if we want to add an `@After` rule that checks that all semaphore permits are back.
I guess, are any of the other assertions necessary given that we are checking that source has not changed at all in this case (and no metadata was added).
I would be using a `Set` in this circumstances.
do we need ordered things? does order help anywhere? If not I would just use HashMap
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Feel like this should be more significant than `debug` because it really indicates a form of failure in some scenarios.
@dadoonet I don't think it complicates things that much.. it's just traversing the file tree... and yes... sub-folders need to be supported as well. so if you see a folder with the same name/path in both places, recursively merge the two by adding the new files and skipping existing ones. I'd also argue that if in the es plugin config dir there's a file that doesn't exist in the new plugin dir structure, then rename it to "<original_file_name>.<original_extension>.old" (or something like that).
it's not really arbitrary is it ? :)
same here - just pass a new instance
If we are going to reformat, it should be within the 100-column limit.
I'd just do `sum += Math.max(0, data[1])`
no utils for this :( `out.writeLongArray()` maybe :)
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
asked f2f, we can probably delete logging at this point.
we can remove this catch
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
In my dreams, merging would either throw an exception or return a new independent mapping so that we wouldn't need this validation phase :)
I'm not sure myself why this hasn't been done this way. :-) It's fine, I was just curious if you had tested calling super and if it introduced issues.
alright that's what I thought too, sounds good
Ah, I see why this is a function ref - so that the `toString` generates the right method to invoke. That feels a little brittle but I understand what is up.
If the constructor is modified, this method won't be needed anymore.
oh boy :)
Remove and create again is not needed I think
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
I suspect these will be too small and we'll have time outs.
can we use package private methods and have unit tests for this.. an integration seems like an overkill.
space missing between ) and {
thanks for doing that Colin ;)
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
same question as above
Why not add ``` java if (highlightFields.contains(fieldName)) { continue; } ``` around line 94? That'll prevent two regexes that find the same field from highlighting it twice.
It looks to me like it duplicates the logic of creating a XContentBuilder in a given type and then write the filtered source as map. Could it be something like this? ``` ... Object value = source.filter(fetchSourceContext); try { if (nestedHit) { value = getNestedSource((Map<String, Object>) value, hitContext); } final int initialCapacity = Math.min(1024, source.internalSourceRef().length()); // deal with null here try (BytesStreamOutput streamOutput = new BytesStreamOutput(initialCapacity)) { XContentBuilder builder = new XContentBuilder(source.sourceContentType().xContent(), streamOutput); builder.value(value); hitContext.hit().sourceRef(builder.bytes()); } ... ```
why don't we just bubble this exception up as an `ElasticsearchException`
can this runnable be an `AbstractRunnable`
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
can we just us a `Map` here instead of the guava one
I'd consider replacing the usage of `-1l` in this line and the prior with the field [proposed previously](https://github.com/elastic/elasticsearch/pull/14651/files#r45225330).
simpler to write `(origin == Origin.PRIMARY) == (versionType != null)`
Here's another place to maybe use a [field](https://github.com/elastic/elasticsearch/pull/14651/files#r45225330).
Maybe point out that this is actually the place where we modify the valid input query by adding a new object level to it.
I think it'd be nice to separate mutation generation code from the parse testing code. It is complex enough that it'd nice to have a test for it that asserted that it returned the mutations you expect it to return.
Since you don't decrease this when you hit an `END_OBJECT` this isn't really `depth`. It is more like `objectIndex` or something.
Maybe throw error here it `nested_filter` is the only allowed option here.
Wondering if it would be possible to create the builder first, then call all these setters in the parsing loop above already. Not really that important though.
Sure, thats fine.
I'd feel better if the `latch.countDown()` would be the first line in the catch block
err I guess you need to have failures added first so second...
maybe just `return blobMetaData.length() == fileInfo.length();`
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
I see that we need it from another package, I think it's ok.
maybe reverse this check? (`expected.equals(map) == false`)
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
we should move to have an inner terms lookup builder. BTW You don't necessarily need to have a flag in your class, you just have to serialize what the method returns and read based on that on the other side. If you read correctly the method will return the right result. The flag would anyway depend on other instance members as far as I can see.
indicesDeleted doesn't check for indexUUIDs. We have a separate method for it in this class `cleanMismatchedIndexUUIDs` - in this spirit of bringing all deletion code together - I think it's good to make indicesDelete aware of UUID switches (mark old as deleted), move the `applyDeletedIndices` to be executed where `cleanMismatchedIndexUUIDs` is called now and then we can remove `cleanMismatchedIndexUUIDs` make all go through here.
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
ok let me have a look then ;)
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
hmm no idea really need to think about that one? should this be a //nocommit
Please fix identation.
Correct [equals](http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#equals%28java.lang.Object%29) implementation supposed to be reflexive. In other words the following test should pass: ``` StoreFileMetaData test = new StoreFileMetaData("test", 0, null, null); assertEquals(test, test); ``` Maybe `equals` is not a good substitution for `isSame` here.
similarly, equals uses the hash while hashCode doesn't
It feels wrong that hashCode is using writtenBy while equals isn't
Let's move this to a `finally` block.
This includes both of the fixes but to make the change uncontorversial it should just include the `finally` part, not the checking if the file exists part. Personally I think removing the file up front is the right thing to do but I'd like to separate that out into a separate PR because I expect other folks to object to that way of doing it (see the linked issue) and I'd like to get the `finally` block portion of this fix in.
And anyway, moving it to a `finally` block does help because if the create fails because the file already exists, the delete in the `finally` block will clean it up so we only fail in this way once.
ok, then assert that it's either snapshot or generic threadpool
let's check this on every access, not only creation.
I'd expect this to be in a synchronized block
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
can we use "script_factor" I think it's nicer than the came case
could these three methods somehow be in the base test class, at least partially? what I am looking for is avoiding copy pasting when writing new tests, and possibly not forgetting to cover important scenarios.
You could move this back to the while condition? ``` while (next != null && counter++ < 10) ```
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
we don't need this `if` block, do we? All 6.x and 7.x indices have a single type.
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
should remove the "force:[{}]" in trace logger. @s1monw
can we report the right version we found ? note that we would probably need to change the the logic in the gateway allocator to check for both -1 version and exception (now -1 means both).
Typo, finalzlie -> finalize
nit: please use lowercase start for variable names
nit: please use lowercase start for variable names
Maybe add something like "produced by calling _analyze" and maybe the index name (not sure if this is easily available here, if not its fine) to make it even clearer what the offending call was.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
I think it is fine: we only build one search context per request per shard.
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
save -> safe
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
Nit: too many newlines here
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
Nit: `getNumConnection` -> `getNumConnections`.
Having through about this a bit more, I think the _prompt_ is going to be annoying rather than helpful. I think we'd be better off just printing out a warning message, and continuing on. Sorry for messing things around like this, but sometimes things become clearer during the review cycle.
I think this needs to be `true` as well.
same here please add a nice constant that is human readable
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
To coerce, should be: ``` parser.longValue(true); ```
Please don't undo the migration to the diamond operator. :-)
Discussed this with @abeyad more. It looks like it should be part of RepositoryData after all, otherwise the index generation abstractions is getting exposed on the Repository interface layer, where it makes even less sense.
I would be using a `Set` in this circumstances.
lower cased now...
nit: formatting, add some whitespaces
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:918E10886BC43EC1]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.LineStringBuilder.<init>(LineStringBuilder.java:49) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiLineString(GeoWKTShapeParserTests.java:112) ... ```
I think we should change this so we output a `validation_method` field which can have the values `ignore_malformed`, `coerce` and `strict`. Then the parser should parse this as well as parsing the deprecated `coerce` and `ignore_malformed` boolean fields
Maybe also use a constant here
I am starting to see that the default boost doesn't get printed out but other default fields do. Makes sense to me but maybe we want to be consistent? I think we should have this a separate discussion, make some decision and do the same everywhere (I have the feeling we are not yet settled yet on one way or another)
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
Does it make sense to have the Enum and method name the same? I have no preference as to whether we call it `Weighting` or `WeightingType`
`min` can be named `simple` or `aggregation`
could we not specify it with the following? ``` "movavg": { "bucketsPath": "the_sum", "weighting" : { "single_exp" : { "alpha" : 0.5 } } } ```
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
`s/Class<C>/Class<? extends C>/`
++ thanks Nik
Might be nice to add a check for existence of these parameters for completeness.
mention here too that this is what we do also in the corresponding builder
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
There is no way this compiles.
Sorry I had missed that
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
The first two of these fields are unused. I think that's right, and we should remove them and also `ec2Bucket`, by generating the key and token and then passing them into the bucket's constructor.
This _nearly_ feels worthy of abstraction over the various sets of credentials, and I think that'll definitely be worth doing when the ECS-style credentials are added. Optional now, but worth thinking about.
mayb just do `if (++count >=`
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I mean random number of replicas with random combination of non-active states
ok keep it then. I am not sure though what needs to be optional, if the client here, or the service in the parser service. I thought the former, not the latter.
Ok, didn't know about those...I guess keep for consistency...
I think this name should be IndexMetaDataUpgradeService? Otherwise it sounds like there is a "metadata index".
hmm actually I think we should load deleted queries too
+1 to a follow-up
actually I'm wondering if we should use an IntObjectHashMap: given that the percolator works on a type, I'm afraid users have a lot of data in other types too so creating a Query[maxDoc] could cause an OOME on some of them. By using an IntObjectHashMap we will be more on the safe side: it will une more memory if all docs have a query but much less in the sparse case.
Nit picky: if we capture the node name from the start async we can do `internalCluster().getInstance(DiscoveryNode.class, blueNodeName).id()`
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
can we check that nodeOrdinal is < unicastHostPorts and throw an exception? I think in theory we don't need to enforce this but can search for ports on the fly, but let's leave that to a day we need it.
this logic belongs in transportWriteAction
> Though I do prefer that it fails fast instead of lazily later. ++
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
If your intuition is that these will be almost always needed, then obviously we should keep them.
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
something is wrong in this sentence :)
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
thanks @nirmalc !
> Dynamically changing is very useful in case of cluster with multiple indices/data shapes. Which `multi_term` query are you using ? Is it to increase the default value of 1024 ? Any multi term query that don't use top terms rewriting is not a good fit for the span query in general. If you need to perform prefix queries within span queries it is preferable to index the prefix using the `edge_ngram` filter. This way you can transform any prefix query into a span term query on a single term.
My original intent was to add a `max_expansion` to force the rewrite of all multi terms to use a top terms rewrite when used inside a span query but in this case the `max_expansion` param can be interpreted as the number of top terms to keep during the rewrite. However I prefer your approach which throws an exception on `multi_term` queries that don't use top terms rewrite and matches more than 1024 terms. In this case we can fail the query with a nice message explaining that a top term rewrite should be used on the `multi_term` query if applicable. `max_expansion` is confusing in this scenario and doesn't bring much so I think we should simply honor the BooleanQuery max clause limit.
same request - please have a method called `haveWriteBudget` and do `while(haveWriteBudget() && buffer.isEmpty() == false) { `
I think all of these need to be trace and we should enable these in tests that are relevant.
IMO lets drop them all. IF you have to make them trace you can also just add them back if you need it.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
This predicate can be simplified to `(count, limit) -> count > limit`.
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
can you add a //norelease here too? context should really go away after all queries are refactored
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
this must be `2000051` rather than `2000003`
I think its awkward we wrap these files in InputStreamIndexInput here, and have the method take InputStream, when it could just take DataInput? The one lone other usage of it, in a separate file (BlobStoreIndexShardRepository), could just wrap its InputStream with a o.a.l.util.InputStreamDataInput. and then the hashFile() would just be a simple readBytes() call into the byte array. I know this isn't new in the patch, but this path adds more indexinput-wrapping since its not calling hashFile(String) anymore.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
I think this'd be more clear if you said something like "invokeStatic assumes that it is not invoking a method on an interface."
I'd remove this again. Because this is done in original ASM, just to prevent incorrect stack on voids
I don't think you can use this method because it won't necessarily store the type correctly since we do the slots ourself to avoid trash being on the stack with variables scopes and such. Instead you'll have to use writer.visitVarInsn(asmtype.getOpcode(Opcodes.ILOAD), slot);
nit: I changed this on master to get the parser from AcknowledgedResponse using a new `generateParser` method that I introduced there on request of Baz. Maybe we could use the same here in the backport to make it match the version on master.
Nit picky: I wonder if we should make this ctor get all the parameters and construct the message locally. Will be easier to read the code and use, imho.
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
good catch on delta > 0
`limitedTo(long bytes)`? Clone is kinda non-specific.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
if we run into an exception here we have to close the stream. we usually do this: ```Java boolean success = false; try { // do something with the stream success = true; return stream; } finally { if (success == false) { IOUtils.closeWhileHandlingException(stream); } }
Ah ok, I missing that method below, sorry.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
well then you have to have a dedicated parser interface - I wonder if this is a general thing we should have on stream input though
this could be a for each loop instead
I am surprised that we don't have a default impl for this :)
The `new HashSet<>()` can be replaced with `Collections.emptySet()` (and then you'll have an import to remove).
Same deal with `.get()`. I try to only do this when I edit the line so it doesn't blow up the diffs, but this is a good opportunity to do it here I think.
I think you can drop the `(long)`s because these are `double`s now.
Feel free to tell me I'm totally wrong - but do we feel confident enough that a mistake here (in code) is a good enough reason to cause the [node to restart](https://github.com/elastic/elasticsearch/pull/19272) ? I'm worried about endless restarts, where a single mistake on a specific API can cause problems on an entire node.
instead of changing the state first and then checking whether the previous state was the right one, let's only change the state if the current state matches (note that we're under the mutex here already, so it's safe to do this).
can add a sentence or two about what is currently known to be potentially missing? (in sync markers for shards on new nodes that should be accounted for GP calculations). I think it will help (at least it would me) to understand what this is about.
Test is called "testPrimaryOperationLocks" and then most of the code is there to check replicaOperationLock ;-)
Ok, than that's fine for me. So overall LGTM.
well if a test doesn't call `super.nodeSettings(nodeOrdinal)` that is a bug. We have to enforce it though. IMO we can use a similar way as the test base class does but we don't have to do it here...
underscore case? :)
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
This worries me a bit as this is inconsistent with the filters and ranges aggregations.
mention here too that this is what we do also in the corresponding builder
I think it'd be nice to remove this second ctor so we're explicit every time.
Ah! I get it now. LGTM
I think you can change this to a `Supplier<Analyzer>` now.
ok as a follow-up
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
Is there a reason these three fields need to be test instance members be randomized in the init() method? Otherwise I would prfer making them local in createTestIntstance().
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
"now" should be "not"
typo : now -> not
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
I don't believe this is only kept for BWC. You use this to parse `_source` above.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I guess it could be renamed to isFalse() / isTrue() now
typo in the method name here too
Incides -> Indices ? ;)
do we really need so many tests? this is just about parsing? It can probably just have unit testing for this..
the printStackTrace should go away here
I think we are still missing preference? Should be similar to the get API.
we should support the preference and parent flags similar to the get API.
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
Yeah, I think we can collapse both deciders into one here - it will make things simpler. Call it RecoveriesAllocationDecider that is incharge of all recovering shards (replicas and relocating primaries). It's good to do it in a different PR imo..
oh nevermind, I just found the method that called it with null :)
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
I double checked and heard that `@Ignore` is needed as well, otherwise IntelliJ tries to run this test as well when running all tests from the IDE.
this should be an abstract class, not sure if we also need the `@Ignore` annotation.
Since this is static, the name should be `THREAD_POOL`.
Same here, nevermind again :)
The migration process will only move datafeeds from cluster state to index when the entire cluster has been upgraded to whatever version this goes into (6.6 or 6.7). So if we can find the minimum node version in the cluster in `toXContent()` then we can write the extra fields into the X-Content representation only after the entire cluster has been upgraded. That will make full cluster restarts work in the case where the entire cluster is on 6.6/6.7 (and it is essential this works because some people will run 6.7 for a year after 7.0 is released). So if `job_id` is `null` after a full cluster restart then that implies the cluster was not completely upgraded to 6.6/6.7, and hence the migration will not have started, and hence the information can be obtained from the `MlMetadata` in cluster state.
The problem here is that it would break multi-version clusters. We still need to read/write vLong depending on in/out.getVersion so that at least positive offsets work.
I think you can just do this? ``` if (info.files().contains(markerFileName) == false) { return true; } ```
thank you for renaming this.
yea, I would at least debug log it..., it shouldn't happen
using ActionListenerResponseHandler will simplify this lightly.
I know this is how it used to be, but can we make the if be more like the `masterNodeChangePredicate` name and check the the master node is not null and have changed? (we now test for a cluster state change)
Somewhat simpler: ("timed out while retrying [{}] after failure (timeout [{}])", action, failure) . I'm doubting between DEBUG and WARN for this log...
we throw the exception and thus take care of the interrupt. We don't need to set it...
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
this might also be called I think
can we unify the resolvedDiscoveryNodes logic with the buildNodesToPing ? They are similar in the sense that they don't change during a ping cycle.
You can add the return value of `resolveDiscoveryNodes` to the HashSet being built
can you assign the key and the value here before we use it? it's way easier to read
In these writeTo/readFrom methods, you need to make sure that you can talk to a node that is running an old version by adding checks on in/out.getVersion()
this is also java 1.7
can we debug log the default? also leaning to have info the "non default" setting, thats what we try to do most times in other components to try and keep the startup logs clean and informative.
Maybe this one too, I'm not sure.
Fine by me.
I think s/lang/defaultLang/
:) good catch
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
you can remove randomization of boost and queryName
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
@clintongormley mentioned that NONE doesn't have many external usages (we only use it for index auto creation) so we might want to drop the special naming and use `0`. I will keep the object reuse in parsing.
and.. looking at the parsing logic this is indeed internal and we don't accept none from strings. Sorry for the noise.
Yeah, exactly, and I think usage should really be reserved for incompatible or invalid arguments, for example. This is more a state thing, so now I think I'm convincing myself that configuration is apt.
This should be a `USAGE` error, not a `DATA_ERROR` (and the period dropped from the exception message).
No, it should stay "id" in the message because plugins are installed by id (with the exception of some special plugins that can be installed by name only). Yet "name" is fine for removal because plugins are removed by name.
Ah! The star imports come back. Its fun watching these things wash in and out like the tide.
beware that wildcard imports will cause the build to fail
to me it's kind of unclear what this suggester CAN do now vs. what is will be able to do in the future :)
maybe we should just get rid of this local variable and write the next line: ``` nodesIds = filterNodeIds(clusterState.nodes(), resolveNodes(request, clusterState)); ```
I think this code will be simpler if we have two methods - sendFullClusterState and sendClusterStateDiff , each dealing with it's own serialization (and have the cache map passed to them). We can have sendClusterStateDiff fall back to sendFullClusterState if needed , which will mean no resend method..
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
let's check this on every access, not only creation.
ok, then assert that it's either snapshot or generic threadpool
If you need this in test, you can still call it getBlobStore()
Can you give each of them a numeric id instead? This will allow to rename the enum constants without breaking the bw compat of the stream
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
extra space makes everything not line up!
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
nit: missing a space after the first comma
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
no need for these local variables, they're only used once...
same here - we need move double starting and such to ShardStateActionTests
this should go away
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
I think this can move to before the threads start - will be nastier
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
Does this need to set `change = true` also? It's missing from this `if` block
DEFAUTL -> DEFAULT
As well as the default buffer size
Snapshot Name - repository name + snapshot name ;-)
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
given our direction (REST client vs transport client) I think we are fine rejecting `-1` on the REST layer. But how about keeping the `int`, using `-1` as default, and rejecting negative values in the setters? That's how we changed some of the request validation as part of the search refactoring too. This way the java api would be rejecting -1 too, which is nice, especially cause we are reusing the same requests for the high level rest client.
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
nit: could be `new MultiSearchRequest().indicesOptions()` instead
Same here about indentation now
I think saying that we can not convert the follower index to a non-follower would be clearer. My concern here is that if `bar` is following `foo` and this message says `cannot unfollow index [bar]` it would be confusing since it is `foo` that will no longer be being followed by `bar`.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
right, I had totally misunderstood how the test works
after rebase you will have to get rid of any wildcard import, or the build fails :)
Yeah, it's relatively new but it's the clear path forward especially with JUnit 5 coming with built-in support for the same.
class could be `final`
nit: extra empty line
for readability I'd use this. as well
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
I would add a flush(), since we expect people to see those bytes and we want to be independent of the filesystem impl (what if it uses buffering, thats its choice)
Ooops - that method is new in Java 8 and you'll be backporting this to 2.0 - so you'd need the `StandardCharsets.UTF_8` anyway. I still think its marginally easier to read my way because you don't need `getBytes` and `StandardOpenOptions.APPEND`.
That'd be cool! I was hoping something like ``` java Files.write(loggingConf, Arrays.asList( "logger.test: INFO, console", "appender.console.type: console"), StandardCharsets.UTF_8); ``` would be possible. Either way is cool with me.
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
nit: space after the second percent sign (on all these lines)
I think the variable name `http_port` is misleading. In RFC3986 this is called [authority](http://tools.ietf.org/html/rfc3986#section-3.2) but I think `host_port` or something along those lines is also fine. Btw, I checked out of interest and all your logic works also fine for IPv6 addresses.
You can use subprocess instead: s = subprocess.check_output('git diff --shortstat', shell=True)
> This method is private and only ever called from a single thread so there is no need to recheck. I'm just weary of having the failure handling case so far from the success case. I figure its harder for someone to break it if its closer together.
Ok - I see where it is called. These checks are a bit too distant for my taste.
I'm not sure why, but the usual convention for freeing resources when the request is done is to have a method called `finishHim`. Mortal combat reference? Anyway, the nice thing about this convention is that it gives us a place to look for resources to be freed. But above I mention reusing a thread pool of some sort anyway.
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
Maybe use the same convention as we use in the other builders here. Have these variables as Double objects and default to null here. Then check for null before including them in the XContent output and leave defining the defaults to the parser? This applies to all the models
we need to remove this from onGoingRecoveries and only call cancel if it was found, otherwise we may leave a lingering recovery id, pointing at a cancelled recovery.
maybe be nice and add that you reuse the bulk request. So "refresh is not supported on an item request, set the refresh flag on the BulkRequest instead".
if we add a null check to the String constructor we can remote this check here given that the parser already looks for the existence of the field too.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
Shouldn't we test only three cases: no_sort, new_sort, old_sort ? Mixing the old and the new format should not be allowed.
Not related to tests but this function should be deprecated.
Like above, I'd simply use randomFrom(SortMode.values()).
+1. Good catch. I missed it. It would still be good to kill the node when testing - so we should have some assertions here too.
same here re enumSet.toString
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
`Arrays.asStream(response.pingResponses)` would not materialize it
just flip it then you don't need to negate
+1 this really cleans up code in several places
Just for my own education, and it is certainly super minor: when reading this part I was wondering if it would make sense to get the maxClauseCount limit once at the beginning of this method since its unlikely to change to avoid method calls in each iteration). Maybe Java does some clever optimizations to avoid this though and the effect most likely negligible.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I guess it could be renamed to isFalse() / isTrue() now
I wonder if we want a trace message here...
I think this is a left over.
For backporting to 6.3, I think this needs to be changed to 7.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
Wow, that's a big difference! Do you know whether it is lossy compression or not? If not then indeed compression seems to make a lot of sense. :-)
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
this can only be a runtime exception you can just bubble it up no need to use `convertToRuntime`
These always read clearer to me as `<= 0`.
It looks like this could fit in 140 columns.
typo: direct**or** -> direct
I think it would be more flexible if the keys were objects? (you could have composite keys, etc.)
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
sounds great thanks
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
Perhaps add the duplicate size to the assert message here
whoops I read it backwards, so yeah, not really necessary
exiting -> exists
Please add a string message about the context registry being null
Could be `contentType = scriptMetadata.getOptions().getOrDefault(Script.CONTENT_TYPE_OPTION, DEFAULT_CONTENT_TYPE);` And then you can remove the null check below
Would be nice to see this parsing code pulled into a function or helper on the parent class so it doesn't need to be the same in both implementations
same here: no need for the [].
index's toString gives you '[index_name]' no need for '[{}]'
same here - I think it's better to log the info message if the deletion was successful.
same here with removing retry logic
same here, all retry logic should be removed
same here with removing retry logic
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
Maybe you could put the validation removed from toCContent here. (point.size > 0)
I see, so parser always sets both "order" and "mode", regardless of whether they are set by the user. But what if we only go through the java api, use a plain builder and set "reverse = false". Translated to json this should give us "mode = MIN", but only if not explicitely set by the user otherwise, no? Sorry, haven't got a good solution myself so far either.
do we protect this from double invocation? I think we should just make sure we only invoke once. can you wrap it in here and ensure that? maybe just use `NotifyOnceListener`
it's find in this case! LGTM
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
shouldnt this solve the problem and not the above ``` String.format(Locale.ROOT, "https://download.elastic.co/org.elasticsearch.plugins/%s/%s-%s.zip", repo, version)); ```
have you run this through maven? I think `String.format()` without a locale is part of the forbidden API
Fine with me :) I'm already wiping the repository itself after each test, so this shouldn't have much effect (I don't think).
make these parmaters to this method? then it doesn't really need to know about index creation requests.
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
What about just converting to bytes and comparing? The way you have it now this isn't consistent with `equals`.... Also the _cat API we call `toString` which doesn't really use the unit anyway.
Yeah, looking at it again, that makes sense!
similarly, equals uses the hash while hashCode doesn't
It should - see `IsNull`
Wondering if the class name shouldn't be `IfNull`...
If the constructor is modified, this method won't be needed anymore.
oh, the boxing horrors :)
here we could use sublists again - just scan to the place you need. No need to reverse then.
removed can just be a count. We always remove from the beginning of the queue.
I see this was already like this, but this can go on a single line.
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
acceptDocs will be checked _before_ these bits are checked anyway
I _think_ that you can get away with just letting the exception bubble up and RestController will send it to the user. You won't get the error log but I'm not sure logging an error on 400 level parse errors is a good thing in the long run anyway. I try to usually run requests with `error_trace` on them so we don't eat the stack trace....
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
nit: extra newline
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
We should make TaskInfo final then.
Can you reverse this, the negative makes it harder to read
is this always used in an assertBusy context? wonder if we should add it here. This can be suprising...
It feels like this is the wrong place to do this. I think we should do this in `Bootstrap` and then just pass a `Path tmpDir` to `InternalSettingsPreparer#prepareEnvironment` and make sure it's mandatory for all instances of environment that are not the single arg ctor. Btw. it feels like there are some sleeping bugs if this ctor is used in prod code.
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
I've dug some more. This is caused by us running the tests with the built in gradle test runner rather than the randomized runner. We configure the randomized runner to run with the system properties but we don't ever configure the standard runner.
When I pulled this locally and reverted the changes to this file I didn't have any trouble. We've traditionally been very weary of making changes to this file so I'd really like to make sure we need this before we do it, even if it is temporary.
And some more: this is not caused by the build compare plugin. Maybe by gradle 4.8 or maybe by one of our hacks to make 4.8 work.
just call `parser.text()` instead of `parser.bytes().utf8ToString()` since it might be optimized under the hood
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
replace match here too
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
I asked before if the bit from runForDoc till the end can be a new method exposed by the Script class, in the effort of consolidating how field script classes expose their values. Do you have thoughts on this? We could also do it later
would it be possible to make the second part of this method part of the field script object itself? It would also be fantastic to use the same mechanism on both sides, but I know it is a bit tricky for different reasons: 1) that array that we reuse without resizing 2) we try so hard to avoid boxing 3) the usage pattern is slightly different if we compare doc_values, query and index time execution. I do wonder if it is worth investing on this, possibly having our own PrimitiveIterator or something that allows us to expose a clearer script API to access the computed values. For later I guess.
Is the `if` necessary? It seems to me that the following should work? ``` java for (String pattern : request.selectedFields()) { fieldNames.addAll(indexShard.mapperService().simpleMatchToIndexNames(pattern)); } ```
you can just use `MultiFileds.getFields(index.createSearcher().getIndexReader());`
this should be `isExists`
+1 that is what I would do too
This is what I meant, yeah. I'd have made it a `private static final ImmutableList<String>` instead of `Immutable<Highlighter>` but it doesn't make much difference.
can you remove this TODO? I'm not sure we are going to implement this after all, nobody needs it for now :)
hmm this has an empty impl? Not sure if we need the `Injectors.close()` if we need it, it should deal with null values!
trash the @param and @return
can cause and name be final
we don't want it to be retried... that was the cause of the failure
my thoughts too :)
Typo: "Dynamics" -> "Dynamic"
+1 on removing the `Void context` from all methods. The `declareInnerHitsParseFields` is already complex to read I think, that won't add much.
Sorry, I just saw that you remove them already, thanks!
Right... but I'd be happy if we could unit test this, and if we do then we need to ensure the object start.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
hey @martijnvg I double checked with @clintongormley and we both think it's better to add the actual index that was closed, not the alias. Knowing that an alias is closed has little sense, better to report back which concrete index was closed.
I think we should mention the index, cause that is the useful bit (e.g. which index is closed), also because we never really hide the fact that users are using aliases (e.g. when indexing into an alias, the response will contain the concrete index as `_index`, not the alias).
Throw error if old-style params passed alongside new-style script definition
Error if old-style params passed alongside new-style script
this new exception is going to trigger errors too if we try to serialize it to an older node
the suppress warnings could be right on the line of code doing the cast instead of the whole method
could name this `getUUID` to be consistent with other usages of UUID in the code base
Ditto here with `getUUID()`
points are allowed to reuse the byte[] to I would make a copy of it before adding it to encodedPointValues
should be clause.getOccur() == SHOULD
`seqno` -> `_seq_no`
I spent some time thinking about whether we can consolidate this, like we do for runtime fields (e.g. the compilation could be done in a single place for all types). We can't really do the same that we do for runtime fields as NumberType is an enum and can't have a generic type, while the different Factory and LeafFactory don't have anything in common throughout the different types hence require a generic type somewhere. Whatever we do ends up being complicated for little gain e.g. saving a few lines of code). One thing is I find it a bit tricky to follow that thanks to this we compile the script at mapper creation time and not at execution time. We could potentially make MapperScript an abstract class with a generic type (the factory) and compile the script in its constructor. That is not perfect but maybe clarifies when the script gets compiled.
sorry, I was referring to the AbstractScriptFieldType#parseScript which does exactly the same
shall we make the error message agnostic "on field []" and reuse the existing parse method? It will need to be moved to a common place I guess.
++, the only thing is I would even go with a Map<String,String> if that works. not sure what you and Nik think about that.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
nit: could be one line
I think we should not execute these writes directly here but extend ESIndexLevelReplicationTestCase#ReplicationAction then run them via the infra of the new action (see ESIndexLevelReplicationTestCase#IndexingAction).
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
we have `TestThreadPool` that makes it simpler
can we fold this into ClusterHealthResponse? that way we can test this as well as part of the unit testing.
Should you use the static `templateName` import here and throughout? It looks like you might be mix 'n matching.
I'd just use the Id really
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
I wonder if we want to add an `@After` rule that checks that all semaphore permits are back.
I think this can move to before the threads start - will be nastier
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
Ah nevermind, I see where we check it above :)
ok fair enough
Yeah, I think we can collapse both deciders into one here - it will make things simpler. Call it RecoveriesAllocationDecider that is incharge of all recovering shards (replicas and relocating primaries). It's good to do it in a different PR imo..
The indentation is off here and the rest of the way through this test.
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
I think this code will be simpler if we have two methods - sendFullClusterState and sendClusterStateDiff , each dealing with it's own serialization (and have the cache map passed to them). We can have sendClusterStateDiff fall back to sendFullClusterState if needed , which will mean no resend method..
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
Somewhat simpler: ("timed out while retrying [{}] after failure (timeout [{}])", action, failure) . I'm doubting between DEBUG and WARN for this log...
This constructor doesn't seem to be necessary.
same here these strings are only used in one place just use them directly and trash the Fields class
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
I am not a huge fan of base64 but I guess you are right.
Oh I see why - there is no builder. Can we follow the same pattern as in other places - make this class immutable and add a builder? All purging and such can be done at the builder level.
can we make those statically configurable ? (no need for dynamic settings)
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
assert for verification whether it is created
Right - RollupIT is the right place
same here please add a nice constant that is human readable
I am good with both options.
fine with me as well. go ahead and push!
interesting, what is the reason for this funny upper bound? :)
I also dont' think we should swallow the exceptions here? Someone asked for a gce address and we failed to get it...
@dadoonet I think the log message can still say "Failed to fetch metadata from google" ? more than just client creation can go wrong here..
@rmuir are we OK with this? Is there a better way (not sure at all, just double checking).
You can use `XContentParserUtils.throwUnknownToken()` (that would throw a ParsingException instead but I think it's appropriate here)
If you're just going to use another builder internally, why not return Settings from this and the other fromXContent and remove the builder arg? Seems a little odd to take a builder, and also return a builder, when the advantage of taking the builder (not creating another builder) is not used.
This can be replaced by ` ensureExpectedToken(XContentParser.Token.START_OBJECT, token, parser::getTokenLocation);` from `XContentParserUtils`
fine with me
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
``` java final RefCounter previous = ref.getAndSet(indexShardOperationCounter); assert previous == null; ```
yeah nevermind I was confused about some internal classes
if not needed +1 on removing
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
typo: direct**or** -> direct
the start cluster does this.
So, this could be simplified to `assertFalse` Or could be something like the following (which admittedly, is probably less simple) ``` import static org.hamcrest.CoreMatchers.everyItem; import static org.hamcrest.Matchers.greaterThanOrEqualTo; import static org.hamcrest.beans.HasPropertyWithValue.hasProperty; ... assertThat(response.records(), everyItem(hasProperty("recordScore", greaterThanOrEqualTo(50)))); ``` Man, that is frustrating that hamcrest does not support just passing a lambda as a type of matcher :(
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
I see, I didn't notice that, cool no problem
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
similarly here I would like it better with a regular for loop and by making fillSegmentInfo take a single segment at a time
this is not needed. createIndex automatically reroutes.
I think if you don't have the Java build stuff setup you should make javana do the merge ð On Jul 14, 2016 8:21 PM, "Honza KrÃ¡l" notifications@github.com wrote: > In > test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java > https://github.com/elastic/elasticsearch/pull/19436#discussion_r70905675 > : > > > @@ -34,7 +34,7 @@ > > */ > > public final class Features { > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key"); > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key", "yaml"); > > Thank you @jasontedor https://github.com/jasontedor, I don't have my > env setup for java so I missed this. > > â > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub > https://github.com/elastic/elasticsearch/pull/19436/files/d53406b8d3919c5367c1bb574fd365fb2af7110e#r70905675, > or mute the thread > https://github.com/notifications/unsubscribe-auth/AANLotcG0AVdYcNe3YtwU1U545rSEKT2ks5qVtJ2gaJpZM4JMfjQ > .
This has a line-length violation. I pushed 575fa4e00a8be31a54859adf06f39c7280691040.
well well if you were an external contributor I would have run the whole suite that takes 45 minutes. But in your case, trust won. I should have totally counted the characters of that line as part of the review. P.S. we java folks are the first ones pushing without running tests at times (WAT?), so no biggie. I will check closer next time.
your call on whether to change this, but we also have `Strings.EMPTY_ARRAY`
if it prints out null it may be ok, if it gives NPE we need a null check, that's what I meant.
we may have a small problem here, when toXContent is called on an object deserialized from a previous version that didn't send the _id .
I was trying to understand why this works, because of the forward iteration here (with nested, we usually seek backwards (`BitSet.prevSetBit(...)`)). So this works because all live doc ids (root docs and nested docs) are evaluated in order.
I think ``` java if (prevParentDoc == -1) { childDocId = childDocs.nextDoc(); } else { if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc); } } ``` could just be replaced with ``` java if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc + 1); } ``` ? (No more check that the previous parent doc is -1, and advance to `prevParentDoc+1` instead of `prevParentDoc`)
I don't think "Not implemented yet" adds anything other the exception type (and could be misleading if we never intend to implement).
May be `if (!FileSystemUtils.isAccessibleDirectory(dicDir, logger))`
Minor typo of `local` instead of `locale` in the exception message.
typo: dictionnary -> dictionary
don't you want to reset first and then set the parseFieldMatcher? :)
asked f2f, we can probably delete logging at this point.
we can remove this catch
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
I think I saw this in Christoph's PR too. Hopefully you don't need it.
I don't think you need @Before here, the parent method already has it.
these ElasticsaerchExceptions are bogus remove them
Typo, "Trasnlog" -> "Translog"
Should use `{}` logging style instead of string concatenation here
you mean providing the size of the array I guess? cause I don't see a constructor that accepts an array in ArrayList.
We also need a simple rest test, testing integration like we have for the other processors
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
can you add spaces? `new KeyManager[] { km }, new TrustManager[] { tm }`
indentation is off after other changes
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
optimization nit, but maybe we can just have one list, and reorder to push active one to the start, we do something similar in primaryFirst. This will mean we don't have to create 3 lists, just one
can me extract this into a method, it is used in 3 places
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
same here - I think it's better to log the info message if the deletion was successful.
s/to list of/to the list of/
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
we should probably bail here. One nit pick - I would prefer having this rejection logic closer to where it holds. I think there is only one method that can cause this.
we should log the exception here.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
Thanks for moving this to `InnerHitContextBuilder` and its subclasses!
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
Fair enough. I wouldn't change the capitalization though.
if you use here `refresh();` from the base class we also make sure we get back no failures.
Also, you dont necessarily have to change this but you can now replace `.execute.actionGet();` with just `.get();`
Btw, you don't necessarily need to use a jsonBuilder here, you can just do `setSource("text","parent")`
Typo, finalzlie -> finalize
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
Just wrap and rethrow and let junit report the exception.
Also, `.get()` is much more common than `.execute().actionGet()`.
This `if` is never false because `numberOfShards` is between 4 and 10
do you have indentation at 2 chars only for this method? We use 4 chars in our codebase. I'd appreciate if you could change that.
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
this is not needed. createIndex automatically reroutes.
can we set the timeout to 0 here? otherwise tests half the time takes 1s
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
true. nevermind then
right thanks for the explaining, I should have known, having worked on the search refactoring :)
maybe also rename the setting? (in addition to the constant)
I don't think so, I think these should be bytes or size-value only.
those are hard to debug I can tell u :dancers:
Thank you for cutting over to a better clock :)
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I'm still not following you? What's wrong with the `static` reference? Whether you use a constant string field (`static final String` assigned from a literal string) or just use literal strings in all the places that you would use the constant, the effect is the same: a single `String` is put in the constant pool and that constant is pushed onto the stack when needed using `ldc`. The java compiler effectively interns all literal strings, and this is the same effect as using a constant string field.
I'm not following you? The bytes for the string have to sit somewhere and they always have to be there. When the compiler needs to use a string from the constant pool, it just emits a special instruction `ldc` to load a reference to the string onto the stack.
Nit: I'd just use the string rather than make a constant. We are slowly removing these objects.
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
For static varialbles, `final` should indeed be used whenever possible.
can we use getters here like `getNode` `isCanceled`
well we use a dummy lock so I guess it's fine
try finally here please since if close fails we don't release lock etc which can be missleading
we have `TestThreadPool` that makes it simpler
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
I think we should return active.get() == false and also - set it if we became idle...
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
you are perfectly right Christoph, let's merge the two and keep the existing class.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
No, you are right, I didn't realize the need for api users before going through the whole changes.
Lol - I spent some cycles trying to figure out how the hell we know this won't throw an index out of bounds exception, only to end up learning something about the BitSet api - it's funky ;)
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
nit: s/read blob's/read the blob's
I'd throw the exception in `initCannedACL()` method instead of checking for a `null` here.
This is where a safeClient() would be helpful, so that you have less chance that the underlying storage instance changed between the copy and delete calls
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
we also need unittests for these queries!!!
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
Looking at this again, I think we can remove the node settings as updateDelay / getRemainingDelay only depends on index settings.
do we need the version check here? it's folded into allocatedPostIndexCreate() ? I think it will be simpler to read if we remove this from the if and add an assert on this, explaining why we expect it like that. Something like: ``` if (lastActiveAllocationIds.isEmpty()) { assert indexSettings.getIndexVersionCreated().before(Version.V_3_0_0) : "trying to allocated a primary with an empty allocation id set, but index is new"; ```
`allocation.hasPendingAsyncFetch()` will always return false here. The field that is used to determine this value is set by Primary/ReplicaShardAllocator. Even if this field were correctly set here, it would still be the wrong value to determine whether the shard can be allocated or not. The primary/replica shard allocator is only interested in knowing whether there are still pending fetches for the targeted shard id.
I think 0 is a good minimum value.
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
We call them "master nodes" everywhere else. :frowning:
s/The tasks has/In case the task has/
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I get that, I was just wondering why those default templates bother here
cool stuff I didn't see that one!
maybe in a followup we can think about removing these -1s... see what platforms fail, and better fine-grain the stuff (e.g. add assumption for WINDOWS, IBM jdk, whatever it might be). Then we know when and where stats are available.
I wonder if it's nicer to append the random uuid.
if we run into an exception here we have to close the stream. we usually do this: ```Java boolean success = false; try { // do something with the stream success = true; return stream; } finally { if (success == false) { IOUtils.closeWhileHandlingException(stream); } }
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
not a big deal but maybe phrase it `remove() is not supported on GeoHashPathIterator`
maybe make if final
for readability I'd use this. as well
Snapshot Name - repository name + snapshot name ;-)
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
I opened: #23338
or when some docs match the query but do not have a value
I think I've seen this somewhere else today ;-)
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
This empty `if` followed by this line looks off.
Nit - strictly speaking these are publishing stats, can we open the object with just published cluster stats (drop received). You can maybe received back in the keys, which can be shorted by dropping the cluster states from the key names - itâs implied from the object theyâre in.
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
I think we should change this to a warning level log (without the return it would be logged as warning in the overloaded shardFailed message)
Maybe a name like "PlusOneMonth"
Search and executable, and execute look like they should delegate stuff to a single method. Orsomething.
I think s/lang/defaultLang/
It might be worth logging it at warning, maybe. Its not "normal" not to have it but is "OK". Its just one line on startup and so long as the line clearly states that everything is ok, we're just disabling groovy, then I think it should be logged every startup.
then call here `register(SimpleProcessor.TYPE, SimpleProcessor.Builder.Factory.class);`
Having limitless extensibility is not a good thing... as a plugin developer, I want to know what I can and cannot do... what I can extend. Otherwise I can easily do something I really shouldn't, break something along the way, without even knowing I broke it. Having well defined extension points and effectively limiting the extensibility of es in general: - helps us make sure plugins cannot break things (as they'll be restricted to what we allow them to do) - helps the users know what they can do and rest assured that they're not doing something they're not supposed to So overall, personally I'm less concerned about not capturing all the extension points at first run.. I'm more concerned about first capturing control over it. Then we can start opening up extension points as we see fit in a controlled manner.
replace match here too
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
Can you remove the empty javdoc? We are going to fail the build on those at some point....
I think NamedWriteableAwareStreamInput was introduced just a bit later. Only my guess.
same here - just pass a new instance
I think it should be: `<C> C readNamedWriteable(@SuppressWarnings("unused") Class<? extends C> categoryClass) throws IOException {`
yeah nevermind I was confused about some internal classes
Throwing a RetryOnPrimaryException feels ugly. I see why you did it and I can't come up with something better. On top of that, this made me realize that RetryOnPrimaryException has serious problems. I'll reach out to discuss. to be clear - this shouldn't stop this PR as it is an existing situation.
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
Autoboxing already happens and I wouldn't worry to much about it considering the depth is not that big. Same for `Linked` vs `Array` (in general arrays are faster except for inserting in the middle as that requires resizing/copying at which the linked structure excels). I think the `Tuple` makes the code a bit more compact and safe (the queues cannot get out of sync) and more readable/simple code always trumps optimization (especially micro ones as here).
Since the index and the Map are associated, how about using only one `Deque` which holds a `Tuple` instead of two `Deque`: ``` Deque<Tuple<Map<String, Object> index>>` queue = ... if (node instanceof Map) { queue.add(new Tuple<>(node, Integer.valueOf(i)); } ```
+1. It looks like a small method and while it might be inlined the extra `Tuple/Integer` are boiler-plate. If the method gets unrolled, both the index and the found value will be available without wrapping/boxing.
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
this will annoy the forbidden API after rebase + squash. Heads up
same here regarding nullable ..
I would use the following message: "ignored as shard is not being recovered from a snapshot" and not have an explicit check for `shardRouting.primary() == false`. That case is automatically handled by this case too as replica shards are never recovered from snapshot (their recovery source is always PEER).
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
I would write this check as ``` if (shardRestoreStatus.state().completed() == false) { ``` and then add an assertion that `shardRestoreStatus.state() != SUCCESS` (as the shard should have been moved to started and the recovery source cleaned up at that point).
we can... but it's important to not forget that some classes should not to depend on es. Packages don't enforce anything but may make you think about it (or maybe not). Anyways I think it's nice to keep separated the es runtime for ingest and the ingest classes that are independent from es core. There is a pretty big difference between these two sets of classes. As I asked above, maybe there are other ways to keep things clean, not sure.
Good idea to add this safety net.
I think we can do this without adding an interface? Users should not need to do this? A script cannot realistically be used for both search and executable. I know this is more a problem with the existing scripting apis, but I think here we can just implement executable, and search should throw UOE.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
I don't think we should do `__default__` we can pass the default separately...
I saw this problem being dealt with in other place by setting currentFieldName to empty String. Worst that can happen then is that it is treated as fieldName in the query, which we should validate later and throw IAE then.
I hope I'm not splitting hairs, but there's also a typo in the field (deault is missing and 'f'). (This PR resulted from a question I asked here; thanks for all the awesome work you invest there!)
nit: space before RESPONSES
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
we can delete ForceMergeFailedEngineException now, right? It's not used.
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
nit: I think remove "next", since this is no longer a second step in the method
we need transport stuff too, for example, TransportSettings#PUBLISH_HOST (but there are more) . I wonder if we should just pass through everything prefixed with network and transport.
I'm doubting here too, though I see the value in a controlled environment. The true long term fix here is testing so we know what we need. Do note that one can set ANY setting on the tribe.\* level. This is about defining inheritance.
or just: "return ok;"? :)
ok let's avoid the concurrent put/computeIfAbsent issue for now, we can try to improve in the future if we observe slow concurrent access
I think the unlock calls should always be in a finally block
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
It could be useful for debugging too. In the future it's conceivable that the support diag tool might use the HLRC, and we wouldn't want to be dropping this value.
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
This should be immutable I think, it looks like its mandatory.
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
I think we can get rid of this field in the abstract class, as far as I see it can be "term", "completion" or "phrase", those should be the NamedWritable NAME constants in the subclasses, so the superclass won't need to store it anymore.
I think that suggesters are just less far along than queries. It is fine though.
I think we've been registering default stuff in the module to keep it all in one spot.
I didn't check but unittests for this would be awesome!
I think it is fine: we only build one search context per request per shard.
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
I think it is not clear here exactly when IndexMissingException is expected to be thrown or not. I would rather move the if on top and have different asserts path based on that. FOr the expected exception one you can then do: ``` try { //do something fail("shouldn't get here"); } catch (IndexMissingException e) { //assert on exception } ```
I'll leave this one
seems redundant indeed
`retentionPolicySupplier` is confusing. It's a prune query supplier.
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
I liked the assertion you had there that if already have a result, this one has a higher seq no
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
can you try to exercise this method to make sure we open a new searcher and close / release everything
This was a bit hard for me to read due to the order in which comparators are checked. Could it be rewritten in a more idiomatic way, ie. ``` java if (o1.isPrimary() != o2.isPrimary()) { return o1.isPrimary() ? -1 : 1; } final int secondaryCmp = secondaryComparator.compare(o1, o2); if (secondaryCmp != 0) { return secondaryCmp; } final int indexCmp = o1.index().compareTo(o2.index())); if (indexCmp != 0) { return indexCmp; } final int idCmp = o1.getId() - o2.getId(); if (idCmp != 0) { return idCmp; } ``` It would be helpful at least for me to see more quickly in which order comparisons are performed.
``` if (Double.isNaN(v1)) { return Double.isNaN(v2) ? 0 : 1; } ```
just beware that Long.compare is Java 1.7 only, you might want to use Longs.compare from Guava instead when merging to 1.x
let's assume that if the method parameters are not marked as @Nullable that they are non-null. Otherwise we clutter the codebase everywhere with these checks.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
@clintongormley mentioned that NONE doesn't have many external usages (we only use it for index auto creation) so we might want to drop the special naming and use `0`. I will keep the object reuse in parsing.
This needs to be another method (`parseInnerFilterToQueryBuilder`) which replaces `parseInnerFilter` and also takes care of switching the interal `isFilter` flag.
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
w00t thanks !!
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
something is wrong in this sentence :)
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
Maybe it doesn't have to come at all.... I think only `copyCurrentStructure` is part of the xcontent implementation. The rest is just "stuff that ES uses". I think.
I think an explanation why it's ok to throw an exception here might be helpful for future us.
it should rather save the XContentType detected from the bytes (XContentFactory.xContent(bytes)) above and re-use it.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Oh, nevermind on the second point, I see `ShardLock` implements `Closable` already.
In our discussion about semaphores I understood a different model we keep a semaphore per index/shard directory (like the on the disk locks but in memory). That would be pruned when the folders are pruned. I see where you were heading. I'm fine with either way.
This is not the right condition, a plugin bin directory is not required to exist.
We can remove the period here, this is a sentence fragment (as these usually are).
We can drop everything after and including the comma.
++ for ordinal and tests then
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
oh cool the read is in the ctor! nice!
I think this should be at debug level
I think the assertions are fine because ILM is in full control of the phase, action and step settings (they are INTERNAL settings so can't be touched by a user and will soon be moved to a custom index metadata object further locking down access to them. Therefore, I don't think its necessary to check that if one is set all three are set in production code but its useful to have the check in testing to make sure we don't do something silly so assertions feel right to me.
oh, woops. thought I counted right. sry
I think it'd be nice to remove this second ctor so we're explicit every time.
Ah! I get it now. LGTM
I think you can change this to a `Supplier<Analyzer>` now.
This shouldn't be here. You should use ESLoggerFactory instead.
Again, I wouldn't pull out the ternary.
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
this check is obsolet - we can just remove it
should be cached thread pool, the default constructor does the right thing here
also, I think the opened channel needs to be closed at one point
nit: space before brackets
typo: optain -> obtain
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
Instead of doing the instanceof check here can we maybe wrap the body of the try / catch in another try catch and then rethrow? like this: ``` Java try { try { } catch (WriteFailure e) { // do all the things throw e.getCause(); // maybe check if e.getCause() can be null? } } catch (Throwable e) { // do all the other things } ```
good point, I think it's ok if it is configurable. and then it should do by default the same as the rest of the same search request does.
I find it odd that we modify the original source builder with the resolved indices names and replace what we originally had. Would it be possible to transport the resolved indices differently? I think we should serialize this new info separately and carefully handle bw compatibility around that.
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
missing t at the end of the method name
Not a specific concern, but just more configuration options for the end user when it is not being that effective. The code is trivial and not of maintenance concern so I am fine with we being consistent in all cases.
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
minor: I think it would be a bit more obvious to explicitly call `DateTimeZone.getDefault()` instead of `null`. Since that is what Joda does with the `null` value. http://joda-time.sourceforge.net/apidocs/src-html/org/joda/time/DateTimeZone.html#line.301
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I would also be fine with removing all the camelCase options for all formats in this PR to make it consistent.
I also dont' think we should swallow the exceptions here? Someone asked for a gce address and we failed to get it...
@dadoonet I think the log message can still say "Failed to fetch metadata from google" ? more than just client creation can go wrong here..
@rmuir are we OK with this? Is there a better way (not sure at all, just double checking).
also, can we remove the boolean return value from doStart and remove the timeout handling from the public void onTimeout(TimeValue timeout) method of the callback given to the observer in line 245? just call doStart.
this doesn't mean the index is not active, but rather that it doesn't exist or is closed. I don't think we need to retry in that case. [Old cold would throw `IndexNotFoundException` in this case](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java#L203).
Got confused. It actually likely the previous routing node has an older cluster state in which we should override the existing value.. nevermind
I hope I'm not splitting hairs, but there's also a typo in the field (deault is missing and 'f'). (This PR resulted from a question I asked here; thanks for all the awesome work you invest there!)
nit: space before RESPONSES
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
well, I'm not sure we can assume that all addresses are by default "public". I tend towards saying implementers need to make this call.
I think it would be more flexible if the keys were objects? (you could have composite keys, etc.)
maybe simpler to just write ``` final boolean peersRemoved = peersByAddress.values().removeIf(Peer::handleWakeUp); ``` and then further below just ``` return peersRemoved; ```
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
Please rework this word wrap too.
nit: missing a space after the first comma
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
I find these two empty `continueProcessing` methods confusing, if we manage to merge the two filter chains impl as said above, we would get rid of them I think
this class could be made `final`
We typically use `Locale.ROOT` rather than `ENGLISH` for case conversion.
can you just leave the constant in this class? There isn't a need to put it in realm imo
Use `Collections.singletonMap` here and `Collections.singletonList`
sounds great thanks
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
but if you are in strict mode you get an exception so you don't get back false :)
looks more tedious than just filling an array, but I didnt do an awful lot of java 8 stuff yet :-)
The parentheses around `t` are unnecessary.
Ok, then for the profile settings you only read the publish_port and publish_host instead of the other settings. I see the difference now. Before it seemd like you wanted to read exactly the same settings, then I wondered why that part couldn't be shared.
This change breaks backward compatibility between 2.1 & 2.2 (pull request is labelled v2.2.0)
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
I think this was more readable the old way.
I *think* it should be enough to just call the API without any assertion. We already should already throw an exception if the response isn't a 200.
oh, woops. thought I counted right. sry
May be `if (!FileSystemUtils.isAccessibleDirectory(dicDir, logger))`
Minor typo of `local` instead of `locale` in the exception message.
typo: dictionnary -> dictionary
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
I have yet to get to that alternative, I am lagging behind :)
lots of things here will need to be moved to the data node too once we refactor this query I think
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
good catch! that means we are not properly testing this case either given that we didn't catch it.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
Consider checking for `null` somewhere for `primarySize` before the division below.
You don't need these `text-align`s. The one in the header is enough.
Change to Throwable.
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
catched -> caught
Another simplification - if we push the code at https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterIndexHealth.java#L81 into ClusterIndexShardHealth's constructor, we can use it here and just make it a simple lookup in the enum set..
grr nevermind I didn't see the last line pfff...
or N times
I think you can use `RestClient.SyncResponseListener` here instead
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I guess we're doing `instanceof` not `getClass()`, but still, it sounds like maybe we should in some cases.
While you are cleaning up maybe we should put these into their own class that `XContentBuilder` extends? That way all of the wrapper methods are all in one spot.
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
I think the nodes can stay as an array. The constructor just converts to an array again.
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
Technically not an "and".
This method also does not need to exist, as you can use `this(indices, IndicesOptions.strictExpandOpen())`, and fix the validation in the other constructor.
nit: remove extra new line
Two test requests: What happens when you have something like `Integer a = Integer.valueOf(0); int b = a ?: 1;` `Integer a = Integer.valueOf(0); int b = a ?: Integer.valueOf(1);` I believe these are expected to be ClassCastExceptions where Integer cannot be cast to int, but I'd like to be sure.
@nik9000 Robert and I had a long conversation about boxing early during development. We decided to eliminate it as much as possible because of serious complications involving promotion and casting (which as you know is already very complicated). There's only a couple of places auto-boxing happens -- arguments to methods because it would be hard to force a user to cast something to an object to add to a list and with anything related to def type. Otherwise, there is no auto-boxing in painless. Perhaps, this should be the same for consistency? Sorry, I sort of missed this yesterday thinking about the cases, but def should work anyway already, otherwise primitives don't make sense here since we don't allow Integer to become an int anywhere else. With the def type we deemed auto-boxing to not be necessary anymore, and ideally something Java would've hidden from the user to begin with. It also happens that users can call boxed methods on unboxed types to further eliminate the need to ever have a boxed type.
@nik9000 What do you think about this proposal for now? What if for the null safe operator (?.), if the guarded type is a primitive we disallow it, and then for the elvis operator (?:) if the lhs is a primitive we disallow that too. I honestly don't think anyone will notice because currently there is no way to get a primitive out of a field from a non-static type (nothing exists in the whitelist afaik), and I would argue in the case where you want a primitive out of a call, it doesn't make sense to have the receiver be a boxed type. You would still have to check to see if the receiver was null afterwards anyway. For most cases the type will be def and the auto-boxing will just happen anyway. Both of these operators can be very useful for def types without needing to have them do magic for primitives. I would hate to not have them because of boxing issues when it's improbable that users would run into them. I would think the average use case would be something along the lines of list?.list?.map?.get(value)) in which case this operator is awesome.
I meant `client().admin().indices().preparePutTemplate()` or `client().admin().indices().putTemplate()`.
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
`assertNoFailures` is more common in newer tests and much shorter.
we should check here that acked == true but shardAcked == false
This also might need an `ensureGreen`
Can you rewrite these to use `assertThat(..., equalTo(...))`. I prefer this form because it's clearer which is the expectation and which is the value under test whereas with `assertEquals` it often gets confused.
would be great if this logic could be unit tested.
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Yeah, it's pretty new. :-)
use `Objects.equals` for all once changed to potentially null references.
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
make `Boolean` and only serialize when not null
ok thanks for the explanation.
you can use MustacheScriptEngineService.NAME
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
maybe also rename the setting? (in addition to the constant)
right thanks for the explaining, I should have known, having worked on the search refactoring :)
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
Can we make this 1 hour? If it times out it's nice to get thread dump
same as above for non exception case
I am good
maybe better to say "failed to find primary despite of request being routing here. local cluster state version [{}]] is older than sending node (version [{}]), scheduling a retry... "
Got confused. It actually likely the previous routing node has an older cluster state in which we should override the existing value.. nevermind
something I noticed while reviewing the bwc code - we can pass the indexMetadata (or primary term) as an argument. We look it up on in the calling method. Save on double lookups.
is there always at least one element in this list? (I haven't checked whether we assert it somewhere else)
I am fine with doing it in a follow-up PR if that works better for you
Just for my own education, and it is certainly super minor: when reading this part I was wondering if it would make sense to get the maxClauseCount limit once at the beginning of this method since its unlikely to change to avoid method calls in each iteration). Maybe Java does some clever optimizations to avoid this though and the effect most likely negligible.
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
This is similar to the internal implementation, nice
Misspelled in the \@param tag also
would be nice to allow to configure it to a percentage of the heap size
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
well we use a dummy lock so I guess it's fine
try finally here please since if close fails we don't release lock etc which can be missleading
and -> an
This has a line-length violation. I pushed 575fa4e00a8be31a54859adf06f39c7280691040.
I think if you don't have the Java build stuff setup you should make javana do the merge ð On Jul 14, 2016 8:21 PM, "Honza KrÃ¡l" notifications@github.com wrote: > In > test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java > https://github.com/elastic/elasticsearch/pull/19436#discussion_r70905675 > : > > > @@ -34,7 +34,7 @@ > > */ > > public final class Features { > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key"); > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key", "yaml"); > > Thank you @jasontedor https://github.com/jasontedor, I don't have my > env setup for java so I missed this. > > â > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub > https://github.com/elastic/elasticsearch/pull/19436/files/d53406b8d3919c5367c1bb574fd365fb2af7110e#r70905675, > or mute the thread > https://github.com/notifications/unsubscribe-auth/AANLotcG0AVdYcNe3YtwU1U545rSEKT2ks5qVtJ2gaJpZM4JMfjQ > .
well well if you were an external contributor I would have run the whole suite that takes 45 minutes. But in your case, trust won. I should have totally counted the characters of that line as part of the review. P.S. we java folks are the first ones pushing without running tests at times (WAT?), so no biggie. I will check closer next time.
Same feedback as the last `toString` - I think you can remove `created` and might want to look at `Operation`'s `toString`.
Same deal as the last `toString`.
I'd move this to line above, but I like the thought behind the change.
I think we should have a dedicated method for this in IndicesService. ``` public FieldStats<?> getFieldStats(Engine.Searcher searcher, String field) { // do the caching in here and also lookup the MappedFieldType again! } ``` this way we don't allow everybody to cache whatever on our request cache!
I would add an `assert this.context != null` here just to make sure
I think filter and query can never be null here? not sure whether we should validate this here.
you can replace these two lines with a call to `ThreadPool.terminate`
Right - RollupIT is the right place
Writeable#readFrom returns a new instance of the object, it allows to have final fields, but it requires to have a PROTO instance of the object to call readFrom against. I wish there was an interface to declare writeTo only though but we don't have it at the moment.
now I see what you meant yesterday saying that we have to parse meta here
but if you are in strict mode you get an exception so you don't get back false :)
mention here too that this is what we do also in the corresponding builder
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
Nit: spacing between the `)` and `{`: `){` -> `) {`
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
I think we can simplify here and print everything out, default values included, that's what we went for in all of the other queries too.
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
+1 on just `field`
No, you are right, I didn't realize the need for api users before going through the whole changes.
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
you don't have to assert on anything if an exception is expected
you could use `scriptRequest.setJsonEntity`
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
Hurray no more weird `while (true)` loop
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
I think we already do since we don't lowercase the suffix. That's fine with me. I think it's consistent with what we usually do with conf files. Let's try and add some docs for this to make it clear.
I see what you mean, that we somehow break bw comp but I would leave only the lowercase variants to make this consistent with other places where we load files e.g. we would never load `elasticsearch.YML` . I think this change is acceptable and in the scope of the PR since we are in fact limiting the files that are getting loaded as logging configuration.
The shapeFieldMapper seems unused here.
same problem as above I think, only that unmatched closing brackets will create holes here.
Ok, I see. Nevermind, since its a private method I leave it up to you to change or not, I was confused a bit but the method is short enough to understand what its doing.
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
make `Boolean` and only serialize when not null
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
+1 on removing it
Search and executable, and execute look like they should delegate stuff to a single method. Orsomething.
having another look, index time lookup is needed when creating the search lookup, and I actually made another suggestion around possibly not needing IndexTimeScript entirely, so I don't think we will be able to do without adding indexTimeLooup.
can we just use `getUuid()` no need to have two
I'd prefer using `IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> prez.setRelevalntRatingThreshold(-1))` here like we do in many other tests and get rid of the @Rule
ok fine! :)
make this an atomicreference to throwable so we can see what it was in the failure message? (use assertNull)
make this Error? we alway want to use this.
same here - would be good to have a brief summary of the shard that failed and why.
use simpler constructor.
I expect to be tested as it's static, but I don't see test? I think its good to have one. Also, it seems it can be package private.
That assumes `list` can't contain null..if that is not the case ignore
Er, well, it doesn't work like that. Ignore.
similar concern about in-place reduction
I think it would be worth renaming this method, otherwise it will cause confusion in the future about whether it's expected to be a bug or not (since the only reference to the exact bug number is in the line you've deleted). Alternatively, the format this method tests could be moved back into the method above (which is where it was originally).
I think it might be nice to move this in `TcpHeader`
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
Right - RollupIT is the right place
Now that I'm seeing these, I wonder if the default names should be `attr` and `value`. We could add aliases if we need longer. Since it's such a small API it's probably fine with the short versions.
Nit: I think you can leave out ESTestCase here.
Nit: I think you can leave out ESTestCase here.
Like above, I'd simply use randomFrom(SortMode.values()).
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
Should you use the static `templateName` import here and throughout? It looks like you might be mix 'n matching.
I think this is expected to be a sorted list on the `job_id`.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
Is the version needed? I don't see it being read here.
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
nit: Everything okay, but I found this (and the following same constructs) a little hard to read. Can I suggest writing the boolean flag first without conditions (e.g. `out.writeBoolean(fuzzyOptions != null)` and then have the if-block only? But either was is fine.
when it is possible, I would do it...not a huge deal but still ;)
and the last one ;)
nit: use assertThat(...) with isNull() as matcher instead? I think in general that is the preferred way of writing test assertions.
same as above, could be an array
grr nevermind I didn't see the last line pfff...
hmm do we need to skip the size if we are in production? I mean that assert will not trip if we run without -ea
I'm not following, do you want it to be a regular exception instead of an assert? We still need to do the `readVInt` regardless of `-ea` or without, it's just the 0 size comparison that is an assert for tests
This should be fatal.
formatting should be fixed like the rest in these three lines
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
you should pass fieldNames as an argument
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
For static varialbles, `final` should indeed be used whenever possible.
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
1. There is a minor typo/grammatical mishap here - text should read "[cluster.name] must not _contain_ ':' character" 2. Id consider putting this exception text into a final static variable somewhere it would make sense to put it. This text is currently used in two places in the code - once here, and once in a unit test - and the way things are now, if you want to change the contents of this text, you need to change two strings in two different places in the code. If you had this text in a final String variable, and you referenced that variable here and in the test, you would only ever need to change the string in one place.
There should be an extra space between the `if` and the `(`, and the `))` and the `{`.
This is logic that I think should go into ReplicatedOperation.
this logic belongs in transportWriteAction
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
This logging statement has a `[{}]` but no argument to fill it
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
does this need to be public and also does this class need to be subclassable
I think it would be cleaner to move the assert into the catch, and add a `fail("expected script exception")` after the call to `run()`.
This is missing a `+` between `newUsed` and `"/"`, so it's not compiling currently
It'd be nice to be sure it contained that `not_found` wasn't found.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I think you can just blast the entire method in this case.
formatting, 1 line instead of 2
Throwing a RetryOnPrimaryException feels ugly. I see why you did it and I can't come up with something better. On top of that, this made me realize that RetryOnPrimaryException has serious problems. I'll reach out to discuss. to be clear - this shouldn't stop this PR as it is an existing situation.
this must be `2000051` rather than `2000003`
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Yeah, I think the problem with the test here is that we don't make sure that nothing is left in the stream after we read it. That's why we didn't catch it here.
@talevy Can you extract this IOException change from the PR and commit this to the branch? I can then benefit from it in the geoip PR too.
this should just throw IOEXception no need for a shadowing ConfigException
the `grok` field can be final too
A question out of curiosity: the analyzer we get here doesn't have to be closed (via closeAnalyzer) because its not a new instance? I don't know enough about the lifecycle of these objects yet I'm afraid.
This can maybe go inside the following `else` branch.
same here, just `this.charFilters.add(new NameOrDefinition(charFilter));`
if just read metadata it will also be easier to implement a fetch all interfeces, sort interface name, fetch interface ip sequence
Maybe merge all the groovy securing code into one place? It feels funky to have the default receiver whitelist here but method blacklist above.
I think we can check the beforePart == null out of the if(!..equals) and it will make it cleaner.
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
I think this adds a `timeZone.previousTransition()` computation even for fixed time zone cases. I think to save computation we could return even earlier in unproblematic cases when `timeZone.isFixed()` like before.
Probably should also be getAssignedNodeId.
I like this style. I think I'm going to steal it.
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
forcing execution should be a parameter for now imo - I know we want/maybe/potentially change how we deal with replicas and queues, but for now I rather not change semantics and have primary ops non-forced and replicas ops forced.
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
Ah ok, I missing that method below, sorry.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
ok let's drop it in master and keep it here for BWC
we are talking about toString method?! No way we add a distinction in there... if we pass this to the user then fix it in the rest layer
Honestly I prefer inline, but all the user-facing stuff has been called dynamic, so I'd probably stick with that.
I think we can remove this exception now.
good catch with the sync here!
Maybe use a simple for loop here like: ``` Java if (!contextMapping.isEmpty()) { builder.startArray(Fields.CONTEXT); for (ContextMapping c : contextMapping) { builder.value(c); } builder.endArray(); } ```
no i do not. but this IDE cannot compromise the actual build, which is 'gradle check'. changing tests.seed in this way can compromise the build, because then the values for other things looking for this (such as lucene) depends on class initialization order.
don't change tests.seed, i dont care what intellij does, this is wrong to do.
I think we should use `writeAtomic` everywhere just to reduce the complexity.
are those number randomizable ie `randomIntBetween(1,100)`
thanks for doing that Colin ;)
same question as above
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
Would you kindly add some line feeds here to make it look like json instead of a wall of text? It'd be so much easier to read.
good catch! that means we are not properly testing this case either given that we didn't catch it.
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
I think we've started to use `setShard` style here? I'm not totally sure.
Do we need this? the settings are already immutable
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
this new exception is going to trigger errors too if we try to serialize it to an older node
I think s/lang/defaultLang/
same here - just pass a new instance
can we add that to ClusterStateCreationUtils? It might be useful for others as well
this could be a for each loop instead
I think this needs to be `true` as well.
We don't want to actually check what version of `openssl` they have installed. They might be generating certificates to be used on a different machine that has a different version of openssl. It's OK to always print a warning about the password exceeding the old openssl limit.
This one should be `true`. We want to check the password length any time we're generating a _new_ private key.
But that is not equivalent? Arrays.toString is a static method, and different than result.buildConflicts().toString()
maybe put this in an `if else` clause? For me this makes it clearer what is pre 2.0 and what is 2.0 behaviour.
why do we need to merge this again since we are still holding on to the lock? I don't necessarily understand why this is helping us as well but that might just be because I don't know this code very well.
> At the same time though, acquiring the write lock would be good, because even though there is a warning that this should not be run when ES is running, trying the lock seems like it would be a good idea Definitely, +1
> If there are multiple commits, what does IndexWriter.getCommitData() return? I am guessing it reads the "latest" commit's data? Yes, the latest.
It won't always be the case that there will be one index commit, sequence numbers will change this assumption.
there is no exception possibility here? I think this is overparanoia
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
I wonder if we want a trace message here...
Not a big deal, I'm fine without it
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
Lets leave off the third sentence
to me these should be sets and required to be non-null
A problem for another PR, I assume.
can you use try with resource here since we are on java 7 now ie: ``` Java try (CBORParser parser = CborXContent.cborFactory.createParser(content)) { parser.nextToken(); generator.copyCurrentStructure(parser); } ```
Incides -> Indices ? ;)
typo in the method name here too
please replace `assert false` with `fail()` if we run without assertions this test fails :)
Sorry, what I meant by the previous request was to do an assertion on the whole error string (e.g. wie assertEquals), unless there are any reasons preventing this.
nit: `an` -> `a`
Can we keep the line numbers in the test assertions? I think they are important to maintain.
I don't think you need @Before here, the parent method already has it.
there are more similar problems below
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
I prefer my way but have asked @jasontedor to chime in.
// must use exception that is not **ignored by** replication logic. (also 2 more occurrences of this in IndexShard)
maybe put this check before the primaryTerm check
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
Nit: it isn't a jsonBuilder - it is whatever kind of xcontent was passed in. Nit: maybe only set prettyPrint if the original had it set? I don't know if you can tell though. Neither are a big deal.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I will take care of this.
same question as above
thanks for doing that Colin ;)
should we use a native trove collection here from String to long
why is this public? it's only used internally, right
But the Iterators it returns aren't.
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
Since `value` internally is a String now, we can change read/write here as well.
sorry, my bad.
By keeping track of contexts in 2 different data-structures, I think you are potentially introducing race conditions, eg. if a clear scroll action is issued concurrently with an automatic release of the context due to the fact there are no more hits to process.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
can this see `unregister task for id: [{}]`
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
thsi is actually concerning... what if the user uses yaml reponse format or cbor then we render still in JSON? I think we need to find a better way to serialise this. I really don't know from the top of my head how to solve this to be honest...
after is now minimum_age
Same here about multi-line toString methods
Here again I think we should use `builder.timeField` to handle this
I am not sure if we should catch an exception here IMO the exception should bubble up
should we catch exceptions here to make sure we cancel everything we need
I didn't look at other users of that method, but +1 ! this boolean annoyed me for a while :)
+1 I like plugin examples!
`client().prepareIndex(...` is more normal now.
This shouldn't be needed anymore. By default we wait for the index to be created now.
Not a specific concern, but just more configuration options for the end user when it is not being that effective. The code is trivial and not of maintenance concern so I am fine with we being consistent in all cases.
++ to talking this through but to put it out there, what I am thinking is that we re-build the user after the lookup. For this case we have PkiUser and LookedUpUser. The final user will be the combination of the PkiUser's metadata, the LookedUpUser's metadata, and the LookedUpUser's roles. The looked up user's metadata would trump the PkiUser's metadata in case of a conflict. This does get trickier when you do this in an AD/LDAP realm since some of the metadata comes from the group resolution. In that case, I would only include the metadata that does not involve group resolution from the authenticating realm.
Nit: Needs a blank line.
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
It would be nice to return a simple, non-empty structure here so that we test that aspect of the response parsing.
oh boy :)
+1 to this, there is always the low-level rest client for this, and we can revisit adding it at a later time if we change our minds.
asked f2f, we can probably delete logging at this point.
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
I see that we need it from another package, I think it's ok.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
maybe sort them by the list index `8`
Please revert this change.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
I think we should complain if we don't find the header name.
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
Answering my own question: you build the array to simulate the task being on all of the simulated nodes. I don't know that that is required here but doesn't hurt anything.
"Simulate a task that attempts to execute only on filterNodes. We are testing that this works."
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
nit: use assertThat(...) with isNull() as matcher instead? I think in general that is the preferred way of writing test assertions.
this is not needed. createIndex automatically reroutes.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
s/payload is/payloads are
s/payload is/payloads are
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
do we want to check listener.isDone? (because it is supposed to return immediately). get() waits.
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
I am not sure RestoreService would be the right place for it since addBlock would need to be moved to the same place and it's currently used all over the place. I don't have an issue with renaming it to `addIndexMedataBlocks` but since IndexMetadata is the only parameter, repeating IndexMetadata in the name might be redundant.
should we check here that the totalShardWeight is not negative. I was just thinking if somebody uses the number of docs per shard and we overflow? I really wonder if we should put some upperbound into the setting to ensure folk don't go crazy? They should use some log scale rather than actual numbers? maybe we use `1<<16` as the upper limit for now? and move totalShardWeight to a long and use doubles elsewhere? I really just wanna protect us form going negative :)
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
we shouldn't be lenient in case `upperTerm` doesnt't implement BytesRef
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
shall we test POSITIVE_INFINITY too? seems like we return null for that too but the default value once parsed is only one...
same as in the other PR, I would rather throw UnsupportedOperationException in the default case
final, not volatile...
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
On reflection I think this means we don't need `lastCommittedState` any more.
tokeinzer -> tokenizer
I like dummy because it implies fake and the index is fake - not just empty.
Builin -> Builtin (forgot a 't')
Thanks for the explanation. Let's do it here. Since the error has an inner cause which provides from_seq_no and to_seq_no information, I think we are good.
+100 to any way that doesn't rely on message strings. Thanks for iterating on this to get there!
> I am thinking to have a dedicated exception so that we can access "fromSeqNo" and "toSeqNo" but maybe overkilled. We should not introduce that dedicated exception I think.
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
Did this change in the builder or does the case check stay? Can't find it, maybe missed it.
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
Should this be cached somehow? /cc @jpountz
I think you don't need to create cache keys and could directly use LeafReader instances as cache keys.
I think you can just do this? ``` if (info.files().contains(markerFileName) == false) { return true; } ```
after rebase you will have to get rid of any wildcard import, or the build fails :)
There is now a base class `RestActionTestCase` that helps remove some of the test boilerplate.
argh, I forgot UnicastZenPing doesn't support local addresses by default. Sorry for the noise.. (we should fix this at one point)
This should say `storeStats`, not `storeState`.
Typo, finalzlie -> finalize
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
That might make sense though my preference is to handle this corner cases leniently. I was a bit confused by `UNKNOWN`, I would argue an empty list has `FALSE` nullability (it can never be null) but then again maybe it's something that's worth having a check.
I'd remove the bitmask - it doesn't seem to add much value (see the previous method suggestions for implementing and); shorter and clearer than using bits.
If the constructor is modified, this method won't be needed anymore.
Nit: this could be on the previous line.
I think it'd be useful to see the filenames in the exception message.
I think we don't need this line or the following two, since they duplicate docs found elsewhere.
Could you replace null above with `TRANSLOG_BUFFER_SIZE_SETTING`? (This is a separate issue, but I never backported to 1.7.x...)
Pre-existing issue: I think 30s default is too large, because an index that was inactive and suddenly becomes active with a 512 KB indexing buffer for up to 30s of heavy indexing is suddenly writing many, many segments. It would be better if the first indexing op to arrive to an inactive shard could force IMC to wake up and re-evaluate. I'll open a separate issue about this ...
if we do this, then specifying just host without a port will cause to return a list of 100 addresses by default
I'd go for either check in the constructor or here.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
thanks for unwrapping
I think completely removing it is unrealistic, but we may not get a disconnection event for quite some time (up to ~15 minutes by default on Linux). I do not think it should be delayed beyond the safety phase.
I just realized, for this log message and all of the ones below it here, we only log `index` and totally omit `reason` because there is only one `{}` in the log message...
I guess we should call this method `updateAppliedStates()` and the field should be `appliedStatesByVersion`.
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
looking deeper, I see that we set a non null TermsLookup object only when we have it in query, which causes a validation error when values are set too. We should keep it that way then, this is as good as it gets.
I meant that other way around, not in the else, set termsLookup only if values == null
is this correct? this will return a copied array if offset > 0, yet the `arrayOffset` method will return the offset into an array that has offset 0... .
I think we should return the BytesRef array we get from reading from byte array, and `arrayOffset` will use the same logic, and return the offset form the BytesRef
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
you don't have to assert on anything if an exception is expected
not sure either, I just thought we introduced `parserName()` to have our temporary `toQuery()` method working. ``` //norelease to be removed once all query builders override toQuery providing their own specific implementation. public Query toQuery(QueryParseContext parseContext) throws QueryParsingException, IOException { return parseContext.indexQueryParserService().queryParser(parserName()).parse(parseContext); } ```
then check for non null here...
same for here, not sure if the full Objects.equals needs to be called
I'm wondering if we need to use `Objects.equals` here which would be quite heavy-weight on the entire CockroachTasksInProgress... in this case, for example, all we care about is if there are new task entries whose executor is the local node id... in that case, maybe we can have a method on `CockroachTasksInProgress` such as `hasNewEntriesForExecutor(localNodeId)`
I think this catch not needed. It will be caught higher up.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
I wonder if this should be `Exception`. see also #20659
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
Why isn't this replacing `--hash`? The release hash here should be the only thing needed to download the artifacts.
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
last `%version` should be `%major_minor_version`
this is just personal preference so feel free to ignore it, but I like the name `registerDeprecatedHandler`
> I thought I was getting at that without making it too wordy. The key is that you're not registering a `DeprecationRestHandler` as the name `registerDeprecatedHandler` implies. Instead, you're registering a handler that gets wrapped as a `DeprecationRestHandler` before registration. I guess `registerAsDeprecationHandler` would be slightly less wordy than `registerHandlerAsDeprecationHandler` but the point still remains.
The language in this sentence isn't clear, perhaps change "that is replacing" to "and it is replacing"
Maybe "you should use time based indexes or cron a delete-by-query with a range query on a timestamp field"? Or something that mentions time based indexes....
I also think that this should log the input instead of the normalized input.
fielddata format can still contain arbitrary values: ``` PUT testidx { "mappings": { "doc": { "properties": { "user": { "type": "string", "fielddata": { "format": "fst", "blah": "blub" } } } } } } ``` I am however not sure what is expected here because when I get the mapping the wrong entry will be returned...
can we move this back into the try? I'm worried that exceptions wouldn't release the shard lock .
nit: ditto for `final` method args here
index's toString gives you '[index_name]' no need for '[{}]'
confuses the shit out of me everytime :)
"new" -> "now"
Typo "uncomitted" -> "uncommitted"
Can we use `in.getVersion()` to check in the read (and write) for serializing this as a single string for old versions, and array for new ones? Then we can backaport it to 0.90.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
I would probably throw an exception instead of accepting null here.
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
we should be careful here and check for sources that are binary (SMILE etc..)
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
maybe add the type that is found in the error message with fieldType.typeName()
And we could then just leave an assert here.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
we should totally not have this method, one more reason to not implement the interface.
check listener.isDone() as we don't expect a retry here I think
true. nevermind then
yeah that is true. nevermind then
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
There is actually a [standard](http://checkstyle.sourceforge.net/config_modifier.html) for this if you particularly enjoy standards.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
I think I'd rather stay on the safe side
I liked the assertion you had there that if already have a result, this one has a higher seq no
can we also step out if `matchedDocId < DocIdSetIterator.NO_MORE_DOC`
argh. Hidden by github ui. all good.
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
just `for (IndexMetaData indexMetaData : state.metaData())`
this is not needed. createIndex automatically reroutes.
wondering if we should enforce immutability on this level... feels more natural to do it in the build()
can we swap member and constant we know the constant is not null :)
paranoid! :) (re double immutability)
formatting, 1 line instead of 2
formatting - 1 line instead of 2
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
sounds good, we were even thinking about merging those, we will not move them to separate packages for sure.
if you make the `AliasActions` class static you can remove this odd looking `request.new` :)
this is a java 7 feature you need to do `new String[] {alias};`
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
same note as in the json processor PR.
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
we should make this entire class package private and try to contain visibility here as well.
ok can you add alls these infos into this class
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
Nit: spacing between `!` and `value`.
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
There is a problem with this test setup that I just found: the xContentType that is used for parsing here is not necessarily the same as the one that is used int randomUpdateResponse(). So the expected values might be off, e.g. if in randomUpdateResponse() SMILE is used and here xContentType is Yaml.
you are right thanks a lot for catching this
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
good catch! that means we are not properly testing this case either given that we didn't catch it.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
`ilm-move-to-error` -> `ilm-move-to-error-step`
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
can we add some java docs? the name to functionality transition is not trivial anymore
The indentation is off here and the rest of the way through this test.
I think this code will be simpler if we have two methods - sendFullClusterState and sendClusterStateDiff , each dealing with it's own serialization (and have the cache map passed to them). We can have sendClusterStateDiff fall back to sendFullClusterState if needed , which will mean no resend method..
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
you could use `scriptRequest.setJsonEntity`
Er, well, it doesn't work like that. Ignore.
I was wondering if `getSuperset/SubsetSize` is part of the Bucket interface but not rendered via the Rest response, should we either add rendering of these values to the bucket response or remove it from the interface to get equivalent behaviour of functionality of the transport client with the high level rest client here? I think this can be done in a separate issue though, maybe its not needed at all.
I'm okay with the UnsupportedOperationException for now if we can track this question (whether we can reach consistency between the functionality the transport client provides via the SignificantTerms.Bucket interface with the rest response) in a separate issue
we may want to rename match_formats as well here, can do in another PR though.
oh right sorry I had missed it's a single value for these processors. sounds good.
I like this simplification!
This name won't work as I can specify multiple scripts of a single type (e.g. `inline`) and the `ParseField` name for them all will be `"inline"` so they will overwrite each other. I think we need to go back to the parser here and parse a `Map<String, Script>` so each script can have a name. In the request this would look like: ``` { ... "script": { "my_script_1": { "inline": "script contents", "lang": "expressions" }, "my_script_2": "script contents", ... } ``` Note that scripts can either be a JSON object or a String. The `Script.parse()` method handles both cases.
ok I wasn't sure, perfect
If the constructor is modified, this method won't be needed anymore.
I think we should use `debug` for the logging here
please remove that blank line
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
no file? maybe IOException
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
I'd feel better if the `latch.countDown()` would be the first line in the catch block
I think this message is wrong? applyMappings only touches existing indices.
nit: can you assign `event.state()` to a local var
we should also have messages here in this assert
I'm afraid we need to rely on the order if we want to be able to distinguish between negations (applied when a wildcard expression appears before the negation) and referring to indices that start with `-`. We will be able to get rid of it in 6.0 only when we will be sure such indices are not around anymore. I opened #20962. Can we also have a test where the wildcard expression is not the first expression but still before the negation? e.g. `test1,test2,index*,-index1`
Also `-test1,*test2*,-test20` or something along those lines? :)
do you understand this if block? I suspect it made sense before your change, to make it possible to refer to existing indices or aliases that started with `-` rather than treating the name as a negation. That said, I can't quite follow why it makes sense in some cases for `result` to be `null`. This was already there, not your doing but I wonder if it's related and may be cleaned up.
I understand with `wrap`. I think it'd be a little more clear if you just caught the `IOException` and sent it to `onFailure` but what you have will work as well.
You *shouldn't* need to `catch (Exception` here because the caller already does and will forward any exceptions you throw to `onFailure`.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
Sure, I was just wondering as this patterns appears now at least 3 times.
I think we should discuss such ideas in follow-up PRs. It's not clear to me that replacing duplicate code with more abstractions would be a win.
@jaymode no. the opposite. I prefer not outputing fields with empty values. This is the norm now, and outputing empty field values is only useful in a tabular log format (column names at the top).
I think we can change this to `return ", opaque_id=[" + opaqueId "]";` and in the log message `, opaque_id=[{}]` will just be `{}` since we always add this at the end and we keep consistency with the way we handle indices.
I think that we are leaking a thread local here? We should close the current threadContext before overriding it.
I'm happy we have all these tests. It is also another data point to move in the direction we discussed - i.e., failures should mark things as stale.
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Assert that the current thread holds the lock on `this`? The results from `ObjectLongMap#indexOf` remain valid only if no one else is mutating.
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
And we could then just leave an assert here.
you can do some streaming java8 magic here.
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
Might be better to use the default of the request (in this case this coincides, but explicit is better in case of refactoring): getSnapshotsRequest.ignoreUnavailable(request.paramAsBoolean("ignore_unavailable", getSnapshotsRequest.ignoreUnavailable());
I don't think we either but I know some folks like them so I certainly don't object to them.
oh oh I hadn't read your reply when I replied ;)
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Makes sense to me. I only point it out in case you hadn't noticed it and it could save you any code.
I don't think we should even have IndexLookup. It is no more work to write and use a custom similarity than to write and use a native script, and the point of similarity is for customizing exactly this.
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
this is super ugly I think `AsyncShardFetch.Started` and `AsyncShardFetch.Store` should be an impl detail of `GatewayAllocator` no need to bind this or anything
that sucks, sorry :) We can't build stuff that is dependent on the order of how the listeners are added! Can we find a better way of doing this? I think each listener needs to have priority or so and every prioritoy can only be added once? Maybe we don't need this to be a list at all? This stuff is so fragile we have to iterate until it's safe
lower case F please :) - "found shard on ..."
missing { } :)
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
Throw error if old-style params passed alongside new-style script definition
Error if old-style params passed alongside new-style script
same as above, this breaks bw comp for the java api
It is how other plugins do it, yeah. There isn't a clear definition of "correct" here.
just FYI - you can do setSettings("index.number_of_replicas", 0)
Ahh ok it makes sense that this has gone from the subclasses. However I think I prefer it to remain on the subclasses for the sake of being explicit.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
I think this check does not add much (I would skip it)
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
see above - I think you should add it though
actually, if its a single page, then we can just reference the first page byte array, if not, then we should return false. same with `array` and `arrayOffset`.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
maybe 7 indices with 50 docs is a bit too much (= slow test), let's reduce randomness to 3 indices, each max 2 shards, and 10 docs.
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
space missing between ) and {
Yeah, let's the keep the tests just focused on whether or not `MinMasterNodeCheck` does the right thing based on whether or not `discovery.zen.minimum_master_nodes` is set and we can think about broader tests for the default checks from `BootstrapCheck` itself in a separate pull request.
There's a `BootstrapCheck#check(boolean, List<BootstrapCheck.Check>)` override that is visible for testing exactly so that the test can be written without having to rely on passing in a setting the triggers enforcement.
Add short-curcuit return if this == other.
Er, well, it doesn't work like that. Ignore.
I think `writeGenericValue` handles null values, so you could omitt the surrounding check.
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
Typo, "Trasnlog" -> "Translog"
these ElasticsaerchExceptions are bogus remove them
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
cancel that :) I figured it out.
operation can be `final`
nit: extra line
This method looks much simpler now ð
Is it right to just eat the exception thrown from the listener? At least log a warning or something.
> I have just moved code around, so this implementation is not new. Fair enough. I'd still log a warning just to help debug any mistakes in the listener. If all goes well and the listener catches any exceptions then we will never call it.
does this need to be public and also does this class need to be subclassable
add `assert entry.state() == State.ABORTED` here. You can directly write the message as "snapshot was aborted during initialization" which makes it clearer which situation is handled here.
I think this can be optimized further. Here we are updating status of shards that are participating in the restore process. There are only two possible outcome of this operation for a snapshot itâs ether done when all shards are done or it is not done. It doesnât matter if we are applying a single shard or multiple shards â there is still only one outcome per snapshot. If a snapshot is done we need to check if all shards in this snapshot has started and if they are not â create a listener. In other words instead of having an array with one element per shard it might make sense to have a map with one element per snapshot.
I think this should be trace
It would be nice to have this take the args in the same order as computePolyTop (array, offset, length)
Again, it would be cleaner to init `i` to `offset + 1` so that you don't have to add `offset` in every iteration.
I think it would be cleaner to set translated outside of the if statement. ``` boolean translated = incorrectOrientation && rng > DATELINE && rng != 360.0; if (translated || shellCorrected && component != 0) { ... ```
s/to list of/to the list of/
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
Double negative. ð
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
To make jobs built with this method reusable when we come to send data to them in other tests, I think it would be better to fix the time format to `EPOCH_MS` and time field name to a specific value, e.g. "time". However, since it takes hours to get the PR CI build to complete and we'll be changing this same file in future PRs that implement the other endpoints I'm happy to leave this as-is for now.
Would be nice to see this parsing code pulled into a function or helper on the parent class so it doesn't need to be the same in both implementations
Could be `contentType = scriptMetadata.getOptions().getOrDefault(Script.CONTENT_TYPE_OPTION, DEFAULT_CONTENT_TYPE);` And then you can remove the null check below
Please add a string message about the context registry being null
Why do we need getters? These are all final and immutable
Believe it or not, it's fine to pass `null` to `IOUtils.closeWhileHandlingException` (it just skips them). We do that for cases where you might have N things that need closing from a large try block, and you don't know which are `null` and which are not (depends on where the exception was thrown). But for here I like the `null` check: less smelly.
`new AtomicReference<>();` with the extra `<>`.
I think this message might be misleading.
out of memory (source: [" + source + "])
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
I find it confusing the we have the same field names for this in both ReplicationPhase and PrimaryPhase.
actually I just got a bit confused because both classes are in the same file...
this doesn't mean the index is not active, but rather that it doesn't exist or is closed. I don't think we need to retry in that case. [Old cold would throw `IndexNotFoundException` in this case](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java#L203).
I wonder if we can somehow come up with something that better normalizes across failed cloud instances? If a machine is pulled, but its replacement can come up within the allotted time, then it would be ideal to not trigger the recovery because we're waiting on the dead machine (based on its InetAddress).
I think we should extend our cloud integration plugins to add some kind of a stable identifier as a node attribute (if not already doing so) and auto-configure this setting to it. /cc @dadoinet @tlrx
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
is this new assert needed? after all the following cast will fail if the request is not a Replaceable...
Can this lead to user code change? ( as you changed the tests above )
can we mark this as nullable (and doc when it's null)? also, can we move it next to the setter, and make the naming consistent with the rest of this class? (i.e., shardId)
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
no need for `else` here
I think s/lang/defaultLang/
you don't have to assert on anything if an exception is expected
you can make one of them public and call it from both tests, I don't mind
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
I think that we can save the instanceof checks, builder.value(Object) does it already
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
remove this additional line break? :)
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
can we do this `((Long)value).longValue())` no boxing needed here
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
This is not the right condition, a plugin bin directory is not required to exist.
We can remove the period here, this is a sentence fragment (as these usually are).
We can drop everything after and including the comma.
I'm wondering if we should adapt the whole message and say "Recovery failed on " + targetNode , if there is no sourceNode
The sequence number backwards layer won't be needed after 7.0.0.
Asserts are better for this. ð
Ok fair enough, I'm happy leaving this as is then
Actually I'd still prefer to go with Colin's idea to use empty sets. We can still optimize later by making sure to use a Collections.emptySet (which is a singleton) if the size is 0.
just initialize it and make it final - it just compliicates the code
Same concern regarding the leniency.
This can just be a plain old logging statement `logger.debug("[discovery-file] using dynamic discovery nodes {}", discoNodes);`.
I really don't think we need this leniency, I'd like to understand why we're introducing it. I think we should just blow up the pings.
nit: I changed this on master to get the parser from AcknowledgedResponse using a new `generateParser` method that I introduced there on request of Baz. Maybe we could use the same here in the backport to make it match the version on master.
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
seems redundant indeed
I'll leave this one
hey @martijnvg I double checked with @clintongormley and we both think it's better to add the actual index that was closed, not the alias. Knowing that an alias is closed has little sense, better to report back which concrete index was closed.
++. Looks good.
sorry - got confused - I thought this code skips the primary. I think it will be clear if the if here would say `ShardRouting.primary() == false`
make sure you fix the codestyle here
ahh yeah in `assertAfterTest()` nevermind
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
maybe use `shouldCompress` here to make it a little clearer? ```java if (shouldCompress) { IOUtils.closeWhileHandlingException(stream, bytesStreamOutput); } else { assert stream == bytesStreamOutput : "the stream variable is not the same instance as bytesStreamOutput"; IOUtils.closeWhileHandlingException(stream); } ```
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I don't think it matters. We should not force making huge changes to the entire codebase in order to not add things which will just be deprecated and/or confusing to the user.
`it's` -> `its`
`translogs` -> `translog's`
you can do some streaming java8 magic here.
This assumes a version format that while fairly standard is not guaranteed.
This isn't quite right. Wrap the ends with checks in parentheses.
So it's starts with and (ends with or ends with).
I think that we should avoid re-computing this value every time we get status (think of a monitoring system polling the stats every second). We are creating unnecessary garbage on every poll for every shard.
This means a serialization change too, to support -1.
I don't think it should be 0, I think it should be -1 so that we can distinguish a fetch just happened less than 1ms ago from a fetch just happened.
Nit: `parallel` -> `concurrent`
Typo: `afllowed` -> `allowed`
should we here or in the superclass fail if the cluster has not fully upgraded to 2.3? just as a safety guard I think that would be a good check in several places otherwise I can see us debugging weird issues `DiscoveryNodes#smallestNonClientNodeVersion()` has a neat method to check.
Ok, than that's fine for me. So overall LGTM.
well if a test doesn't call `super.nodeSettings(nodeOrdinal)` that is a bug. We have to enforce it though. IMO we can use a similar way as the test base class does but we don't have to do it here...
underscore case? :)
This is `INTEGER` in other mappings.
This is an interesting question. At the moment this is what other APIs use to determine that a job is in the process of being deleted. Maybe storing that flag in an index won't be sufficiently atomic in the future. An alternative might be to make the job deletion process a persistent task, and use the existence of that persistent task to determine whether a job is being deleted. This field is probably just one of several places where indices won't give the same ordering guarantee that cluster state gave us.
why not calling `RestActions#buildBroadcastShardsHeader` instead ? Aren't we losing support for the `group_shard_failures` flag? It is not relevant for the high-level REST client as there is no way to set it but I think it's important given that the parsing code is in ES core. Which reminds me, we should probably test this as well in `RefreshResponseTests`. This param can be passed in as part of the `ToXContent.Params` when calling `toXContent`
and randomly append '/' at the end
missing fail :) use expectThrows instead
s/y ou/you Also I think upfront is one word.
once #12937 is in we can do the following here: ``` QueryBuilder<?> finalQuery; if (queryBuilder.indices().length == 1 && getIndex().getName().equals(queryBuilder.indices()[0])) { finalQuery = queryBuilder.innerQuery(); } else { finalQuery = queryBuilder.noMatchQuery(); } Query finalLuceneQuery = finalQuery.toQuery(context); if (finalLuceneQuery != null) { finalLuceneQuery.setBoost(queryBuilder.boost()); } assertEquals(query, finalLuceneQuery); ```
I say goodbye you say hello ;-)
once #12937 is in we can do the following here: ``` String[] indices; if (randomBoolean()) { indices = new String[]{getIndex().getName()}; } else { indices = generateRandomStringArray(5, 10, false, false); } IndicesQueryBuilder query = new IndicesQueryBuilder(RandomQueryBuilder.createQuery(random()), indices); ```
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
At this point I don't know that `@param` adds anything either.
Sorry you are right, we should be using ParsingException. That snippet was the pre-refactored version. The difference is that ParsingException does not need the SearchContext (not available on the coordinating node) and actually points to the location in the request for the error (the XContentLocation). Please use ParsingException in this PR since this is going to be parsed on the coordinating node
I know the "dots in field names" discussion has been a long running one. Do we not yet have a more general/graceful way of throwing these exceptions? This is more of a question out of my own curiosity and not intended to hold up the PR.
Weird markdown seemed to silently remove some of my text...I was trying to say `FieldStats<java.lang.Long>` (which is what I think you meant by your last statement).
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I would probably make this package private
I think we discussed this before, but it didn't change, thus I'm bringing it up again ;) can we add a constructor that accepts `shardInfo` as argument and change the subclasses constructors to accept it there, just to enforce that this info is needed so we don't forget it anywhere. Maybe then we could also remove the setter...
nit cat we explicitly call the other constructor with null? i.e., `this(null)`
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
I wanted to remove the `allowCommit.set(false)` here with an ensureOpen at the beginning of the method. Only saw later it's already there. No doubles.
maybe replace this with ensureOpen in the beginning? feels cleaner to me
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
Incides -> Indices ? ;)
I think this check does not add much (I would skip it)
Oh, I'm fine with symmetry, I just wanted to make sure that I was reading it correctly.
just please don't add one. There are too many classes already.
ok, fair enough
nit: use the constant from the mapper? content type I think it is called
maybe one day we will a base class for runtime mapper field types that does this in one place.
oh boy :)
and the `ExceptionsHelper.` qualifier is unnecessary
can this be a constant
`expectedType.cast(e)` should remove the need for the unchecked suppression.
Sorry about these crazy incantations....
I'd use `randomAsciiOfLength(5)` rather than fixed strings for this.
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
I assumed that there is no problem setting values and checking that the output of the conversion from high-level request to low-level request is the expected one. We don't validate etc. I would do only what is straight-forward.
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
script seems to be optional, I get NPEs in some roundtrip tests for this.
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
I don't mind as long as we use `writeString/readString` and `writeOptionalString/readOptionalString` consistently. So you can maybe just change the `readFrom` to explicitly use readBoolean.
right I see that
The score of this query depends on the number of shards, the default similarity, ... To make sure that we have consistent scoring you can use a `function_score` query like the following: ```` QueryBuilder query = functionScoreQuery( termQuery("name", "one"), ScoreFunctionBuilders.fieldValueFactorFunction("my_static_doc_score") ).boostMode(CombineFunction.REPLACE); ```` ... and add the `my_static_doc_score` at indexing time.
"white spaces" -> "whitespace"
I don't see any implementations extending this at the moment, are there any plans to add some later? If this is just going to be a collection of static methods and ParseFields I'd suggest making this an interface.
Okay, can you briefly explain the (maybe future) relationship of the ShapeParser and the above GeoJsonParser class? Currently they both seem to mostly consist of a "static ShapeBuilder parse(XContentParser parser, GeoShapeFieldMapper shapeMapper)" method, don't have any state themselves but ShapeParser calls GeoJsonParser. It would be useful to understand where this is going.
Thanks, I get the general idea now.
you also have this variant `org.elasticsearch.common.xcontent.XContentBuilder#timeValueField(java.lang.String, java.lang.String, long, java.util.concurrent.TimeUnit)` which you can use without changing TimeValue
newQueue -> newTombstone
If we use Collection<Tombstonre> we can return an unmodifiableCollection() which doesn't copy stuff..
or when some docs match the query but do not have a value
I think it's fine to add such a method to NoCacheFilter
here too we do the same twice
Checkstyle is unhappy with this.
Checkstyle is unhappy with this.
This test should assert that the headers are correct.
does it make sense to remove the setters? I imagine it feels more ergonomic to use the `IndicesStatsRequestBuilder` for building up a modified `IndicesStatsRequest`
I actually think we can get rid of this entirely. We start the `IndicesService` before `IndicesClusterStateService` and stop it in the reverse order in `Node.java`. I think we can just rely on the state of `IndicesClusterStateService` and don't add this to the interface at all.
we can rather make it private and throw an exception like `ensureStarted()` and call it before we go anywhere that violates the condition but even that is best effort.
same as above, no need for try catch
We also need a simple rest test, testing integration like we have for the other processors
I prefer `assertEquals` in cases like this. `assertThat` is great if you need to take a matcher or want to assert something complicated, but I like `assertEquals` for equality.
Also, since "recover" and "restore" are very similar and easy to confuse, I think it'd be nice if this were named "`recoverState`"
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
you can move this method (and the one below it) up to IndexShardTestCase (in test:framework). It could be useful for other people.
remove line wrap
remove line wrap
remove line wrap
it's a minor thing but why would you assign a variable multiple times when it's not needed? default is a better fit here, it improves readability as well.
maybe we could have a `default` here which could make this switch a bit more readable rather than assigning value before the switch in any case.
Can we get back to this once we need this complexity and keep it as simple as possible for now please? Can we hardcode the OBJECT_FIELD_NAME exclusion and be done with it? queries also have access to individual field names if they need that.
I can't wait for try-with-resources :)
Wouldn't it be better to not call setScorer at all? I suspect most collector impls do not expect a null Scorer.
oh no I see, there is also a return. I think it's confusing that we can reach here because of either an assertion or a return statement
I think it'd be nice to remove this second ctor so we're explicit every time.
Ah! I get it now. LGTM
I think you can change this to a `Supplier<Analyzer>` now.
This is going to be 512 Unicode code units, but I think we should do bytes.
nit: maybe use Strings.isEmpty.
This should be `aliasAction.aliases == null || aliasAction.aliases.length == 0`
I like dummy because it implies fake and the index is fake - not just empty.
tokeinzer -> tokenizer
Builin -> Builtin (forgot a 't')
Would it be beneficial here to return an empty string instead of null? If not, maybe just annotate this with `@Nullable`
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
oh cool the read is in the ctor! nice!
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
can we add some trace logging here? I can imagine it will save some WTF at some point.
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
this made me worry we don't log these failures anymore.. In this specific case I think we are best to just let the exception bubble up, but it does raise a more general issue - if people put exceptions in the builder, it's their responsiblity to report it. we should probably add something to the internal cluster service to auto log it.
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
catched -> caught
Another simplification - if we push the code at https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterIndexHealth.java#L81 into ClusterIndexShardHealth's constructor, we can use it here and just make it a simple lookup in the enum set..
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
nit: maybe use Strings.isEmpty.
Strings.hasLength(xyz) can be used with explitict comparison with boolean False
Why not public? Will make reflection faster for guice.
I think we can't do that this way, for the query cache to work we have to pass in the `Searcher searcher` that we acquire in `SearchService` just above the creation of `DefaultShardContext` otherwise we will be subject to refreshes and the cache will have broken values.
I think we have to have a test for this, I suggest that we use a single node test that we can control that refreshes after we created the context with a new doc in it matching the query and ensure we are still rewriting to match all / none and then check if we have a cache hit? something like this...
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
Since `value` internally is a String now, we can change read/write here as well.
sorry, my bad.
if we'll need this in other tests, we should probably try to shorten this setup part of test by re-using what we have in our java api, that allows to provide `Object... source` , but we also want to be able to randomize the xcontent type, which is why we need to adapt it a bit
We can allow flush here, I think.
I don't think you need the `Integer.toString` bit.
nevermind I see it was already there, then it should be ok
clarify the error message specifying what needs to be non null? the inner query...also remove empty, doesnt make sense here
alright that's what I thought too, sounds good
make the error a bit more understandable for users? Like "processor x doesn't support some of the provided configuration parameters" and list them like you do already...
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
I think BuildFactory should be allowed to throw a ParseException since subclasses should have the ability to throw it if there is a problem with creating the builder at this point
we should add ClusterService and IndexNameExpressionResolver to IndexQueryParseService so they get injected. Then this method could pretty much be moved to INdexQueryParseService like this: ``` public boolean matchesIndices(String... indices) { final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices); for (String index : concreteIndices) { if (Regex.simpleMatch(index, this.index.name())) { return true; } } return false; } ``` QueryShardContext would need to expose the same methd and delegate the IndexQueryParseService
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
This line is called multiple times as we keep adding indices. It could be called once at the end of the loop I guess.
I think I would not check the instances' classes but instead compute how many values the interval has using NumericUtils.subtract (it returns a byte[] that is comparable).
maybe update the docs to say this is a terms query rather than a bool
(same question for FLOAT)
I would be using a `Set` in this circumstances.
You don't need to create an explicit default ctor since the super class has a default ctor.
No need for an empty default ctor when the super is also a default ctor.
let's not make this hold this PR, but let's keep track of this potential issue and address the need for generifying in a separate issue
same question as above
how much work would be to "decode" the values and expand the test? I am wondering if it's worth doing or not.
Yeah, exactly, and I think usage should really be reserved for incompatible or invalid arguments, for example. This is more a state thing, so now I think I'm convincing myself that configuration is apt.
This should be a `USAGE` error, not a `DATA_ERROR` (and the period dropped from the exception message).
No, it should stay "id" in the message because plugins are installed by id (with the exception of some special plugins that can be installed by name only). Yet "name" is fine for removal because plugins are removed by name.
can you please use indexRandom to index docs
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
`createIndex("test")` ? then you can remove the following `assertAcked`
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
can we add an assert to make sure that highlighterType != null here? it really should since we know that plain highlighter always returns true, but the assert would make it more explicit that it is expected
I liked the assertion you had there that if already have a result, this one has a higher seq no
the == false is done on purpose to make these comparisons more explicit
thinking out loud, maybe I am getting confused, but in order for a field to get highlighted, doesn't it need to be stored too or we need to have the _source at least? but metadata fields, which match `*` are not part of the `_source` hence they need to be stored or excluded from highlighting by definition. I have the feeling we should do something more to address that...
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
can we use `== false` instead of `!` it's so much easier to read and burned my fingers too often
maybe use `coordinates.children.isEmpty()`instead
Might be slightly better to return a StringBuilder here as well to not create an additional object? Maybe this could also be done in several other places in this PR where partial WKT strings are built (e.g. all the contentToWKT calls)
Safe because ~~our~~ we know
update version to beta 1
And we could then just leave an assert here.
`it's` -> `its`
`translogs` -> `translog's`
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
"joined the cluster back" -> "rejoined the cluster"
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
we shouldn't need this here in parse phase
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
why is this? what's wrong with `1.f`
yes, lets do this in a follow up change.
+1 then we shouldn't forget about it :)
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
I personally think those queries should be build using query builders but we can do that in a second step.
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You can use `assertAcked()`
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
just FYI - you can do setSettings("index.number_of_replicas", 0)
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
subtractShardsMovingAwayRen -> subtractShardsMovingAway
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
I'm clearly not getting my point across. Please understand that multiple tests are run in the same jvm during jenkins!!!!!!!!!!!!
I wonder if we want to ban `new Random(int)` to make it harder for folks to do `new Random(System.currentTimeMillis)`. If so then `Randomness` is probably the right way to go. Otherwise I like `GOOD_FAST_HASH_SEED`.
Just to make it better, setting it here in clinit is not so ideal, because its not perfectly reproducible when multiple tests are run in the same jvm. you will still have perceived reproducibility issues vs jenkins if you go about it this way: because the random will be initialized _once_ and then we will run 8 test classes against it. then, when you later try to reproduce the one that failed, the sequence will be different (even though the initial value is the same), because the other tests are not also invoked. but if you do it this way, it at least allows "whole build" reproducibility, which is an improvement. That means e.g. if you nuke your local execution hints file and run 'gradle test -Dtests.seed=xxxxxx -Dtests.jvm=yyyyyy', it will match what jenkins did. But nobody does that.
Again missing units :(
Again, putting the unit in the name would help here, unless someone reads the docs they can't tell whether it's millis or nanos
can we replace the Math.max with an assertion? it should never happen and we shouldn't protect for it.
I would execute the `IOUtils.close(resources);` in a finally block after we sent back the response or the other way around.
s/listener/delegate/? I read this and immediately thought "infinite loop!" because this thing already **is** a listener. I know it is silly though.
should we release the releasable just in case the exception comes from the listener? this would allow us to only implement on failure.
64e5c25 added support for this.
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
It might also depend on which implementation of `AcknowledgedResponse` you are using, since we have two, yay duplication!!! You should have a look at `StartRollupJobResponse`, which is an example of changing the word from `acknowledged` to `started`. this should get you on the right track.
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
@s1monw I'm sorry that I didn't take any time to reply last night. The situation with the response parameters is quite complicated. Look for example at `Settings#toXContent`. The situation here is that the `flat_settings` parameter is consumed there, but the signature `ToXContent#toXContent(XContentBuilder, Params)` is a general signature, we can't just go and add a boolean parameter for flat settings to the interface because it doesn't make sense in all situations. It is for this and similar reasons that I ultimately handled response parameters the way that I did. Barring a redesign, I would prefer that we remain consistent for now. > It's just yet another place we need to maintain and look for params. Right now it is how we handle output parameters.
This is one way to do it, but I'm wondering why you opted to do it this way instead of using the infrastructure that exists for handling response parameters? Namely, override `AbstractCatAction#responseParams` (being sure to include the response params from super).
This isn't where I would expect it to be consumed since it affects the output only, not the request handling.
The `withPassword` method is called every time we need a password, even if it's being used to _read_ a certificate file. In that case we don't want to print this warning, because that would cause additional output (and an additional prompt) for simple things like reading a CA file that has a long password. We need to only perform this check/warning if the password is being applied to a new file. I'm OK if we want get rid of the `promptYesNo` and just print out a warning, but we only want to do either of them when we know the password is being used to _write_ a file.
Having through about this a bit more, I think the _prompt_ is going to be annoying rather than helpful. I think we'd be better off just printing out a warning message, and continuing on. Sorry for messing things around like this, but sometimes things become clearer during the review cycle.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
can you assign the key and the value here before we use it? it's way easier to read
this will result in wrong counts even though it's volatile. We should use an atomic long or sync this block
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
Note that this is different than setting a single property as it adds the inputs to the list.
The method was not named as a setter in groovy so this could be DSL-like. ie, usage looks like (notice the lack of equals sign): ``` noticeTask { licensesDir 'foo' } ```
no need for a constant here, you can use `StandardCharsets.UTF_8`.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
The `Coordinator` becomes leader in `joinHandler.test()` not in `handleJoinRequest`, and that's outside this mutex, so it's technically possible that it could become a candidate again before this synchronised block.
This definitely feels like overkill now the `JoinHelper` is mode-aware and its mode is in sync with the coordinator.
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
maybe put this check before the primaryTerm check
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
`super.readBlock` instead of `readBlock` to prevent double `maybeIOExceptionOrBlock`.
this does not change anything here? We are already catching the `NoSuchFileException` in the line below, which is an `IOException`.
This is where a safeClient() would be helpful, so that you have less chance that the underlying storage instance changed between the copy and delete calls
nit: we can check the expected token and then create the searchProfileResults map
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
Error if old-style params passed alongside new-style script
To coerce, should be: ``` parser.longValue(true); ```
same here: ``` parser.longValue(true); ```
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
maybe just inline this into the `planIndexingAsNonPrimary` method? I think that would be cleaner.
random drive by question - why is the primary term part of the index result? it's already part of index and index result is supposed to capture the dynamic things that the engine has assigned.
can we rename this to `boolean isCanceled()` and then instead of the exception just return a boolean? I think it would be more intuitive and we really don't need yet another exception
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
nit: can we add the timeout value here.
I wonder whether we should use `unicastConnectExecutor` for this and keep it contained (and throttled).
Actually plugins can implement `Closeable` and they will be closed when the node shuts down.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
this is not needed. createIndex automatically reroutes.
It would be worth requiring that `jobId` and `jobType` are not `null`.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
exiting -> exists
I think this would be cleaner as ```java aliasAndIndexLookup.compute(aliasMetaData.getAlias(), (aliasName, alias) -> { if (alias == null) { return new AliasOrIndex.Alias(aliasMetaData, indexMetaData); } else { ((AliasOrIndex.Alias) alias).addIndex(indexMetaData); return alias; } }); ```
Perhaps add the duplicate size to the assert message here
I think we should have a dedicated method for this in IndicesService. ``` public FieldStats<?> getFieldStats(Engine.Searcher searcher, String field) { // do the caching in here and also lookup the MappedFieldType again! } ``` this way we don't allow everybody to cache whatever on our request cache!
We should be writing out the settings in the "new format". There is no longer index_analyzer. So in the case of search_analyzer being set alone, when we serialize, we should write both analyzer and search_analyzer.
You can simplify this to: ``` boolean writeSearchAnalyzer = // logic if (writeSearchAnalyzer || analyzer logic) { // write analyzer } if (writeSearchAnalyzer) { // write search_analyzer } ``` This will also keep the same order (analyzer followed by search_analyzer) that we had before.
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
much cleaner. thx.
good lets do that
is this somewhere on a todo? I'm afraid we'll loose it
nit: can we use the "without" terminology? I think this better matches other code like the builders for java time stuff having eg`withTimeZone`. Drop implies mutating the current object.
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
we could pass a glob with regex:xxx to newDirectoryStream if we want
This many levels of nesting hurts my head! How about refactoring the inner half into a private `findShardIds(@Nullable String index, Path indexPath)` method so it's easier to read? I'm worried about the potential for future typos for anyone else touching this code
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
Also we should wrap the `-` in `{@code -}`
yeah nevermind I was confused about some internal classes
But yeah, keep it now.
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
nit: these could probably even be package private
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
The shapeFieldMapper seems unused here.
you are right, sorry
maybe expectThrows would be easier.
Exception e = expectThrows(Exception.class, () -> doSomething()); assertEquals(e.getMessage(), containsString("bla"));
this should happen after we update `isSecurityEnabledByTrialVersion`
got it. Thanks.
I meant that we can have the if clause once in `Security.java` and call `check()` on all the checks (or the one `check()` if we decide to implement `FipsChecks` in a simpler manner ) IF `fips_mode` is set
sure, or just make it `[foobarbaz/0/mynode]` or something, `[foobarbaz//]` if there is only one or something
It's minor, but we usually lowercase exceptions and elide ending punctuation
It drives me bonkers that this is called "scroll" everywhere instead of "scrollId", but it's a matter of taste, no impetus to change it if you like it :)
++. Maybe also add a sanity check that a get on the doc at the end gives us what we expect? (deleted or found)
you evil person :)
I presume this is still in progress? (which is fine)
I think this assumption is pretty broken. What if the type is `null`? We don't define any order in the types when they are specified in the URL but this code assume that there is an order. I think we have to make this explicit which type should be used.
as discussed over voice we should really try to disambiguate and barf if we can't so no index should trigger and exception asap
I don't get it sorry :)
we don't count shard not allocated / not started/ closed etc. as shard failures - see Search logic. This will end up as a difference between total shards and shard failed. The reason is that there is no way to distinguish this case with the one that our cluster state said they were unassigned.
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
also, can we remove the boolean return value from doStart and remove the timeout handling from the public void onTimeout(TimeValue timeout) method of the callback given to the observer in line 245? just call doStart.
can "printer" be null? I don't think so, but maybe guard agains it in the ctor.
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
I see now... yea it's odd here cause this query has a single float field, looks better on more complex queries (especially cause you don't really see that among many fields)...
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
actually I just got a bit confused because both classes are in the same file...
I hope jit takes care of this to be honest
just a nit, can we move the `initialRecoveryFilters != null` first since it might be able to skip the lookup then
This predicate can be simplified to `(count, limit) -> count > limit`.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
I think you can change this to a `Supplier<Analyzer>` now.
Ah! I get it now. LGTM
acceptDocs will be checked _before_ these bits are checked anyway
Fine with me.
Maybe throw error here it `nested_filter` is the only allowed option here.
I would add an `assert this.context != null` here just to make sure
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
"just created files" <- what do you mean exactly? if one waits 2h they will be able to read it? if not I would just go with "the permissions on the store don't allow reading"
Is the version needed? I don't see it being read here.
this feels weird to have this here (concerning whether we should delete data of closed indices , on master nodes - I feel this should be made higher up). It is a different change though... (and has nothing to do with your change).
I think we should make sure that the String that is used as Id in serialization gets treated in a special way, also in the builders themselves so they are not accidentally changed between versions. Thats why I liked the old `getWritableName()` (that seems to be on its way out). Maybe we should even have an own class `QueryId` which simply wraps the NAME string constant but forces us (and users implementing their own queries) to think about this as a special case. We could change the existing `String getName()` method in `QueryBuilder` that currenty just forwards to `getWritableName` to do this. This is just some thought for discussion, nothing to block this PR though.
To me, this logic should really be in `IndicesQueriesRegistry` so we construct the registry with just the `Settings` object and then call a `registerQuery(ParseField, QueryParser<?>)` method which unpacks the `ParseField` and adds it to the registry map. That was the registry is dealing with how to internally structure the data and the internals can be easily changed later without affecting outside code.
Hmmm, I do see what you mean. Personally I would still prefer the register method in the registry but I think this is a personal preference thing rather than a substantial concern so I'm happy to yield on it :smile:
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
I'd say yes... if you want to be able to parse script as a string, you want to be able to serialize it as as string. I believe serialization should be symmetric - you write what you read. For this reason, I believe the script type should be nullable. if you read a script like a string, the read state should be preserved for the writing.
this new exception is going to trigger errors too if we try to serialize it to an older node
this change requires going over all the places we use `equals` in ShardRouting....
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
hmm no idea really need to think about that one? should this be a //nocommit
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
oh man that class is a nighmare. really I just realized how fucked up this is grrr.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
this needs to stay because the method can be called from any other class, it's a public static method....thus validate might not be called at all before calling this method.
you don't need do handle queryName yourself anymore, nor boost
we should add ClusterService and IndexNameExpressionResolver to IndexQueryParseService so they get injected. Then this method could pretty much be moved to INdexQueryParseService like this: ``` public boolean matchesIndices(String... indices) { final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices); for (String index : concreteIndices) { if (Regex.simpleMatch(index, this.index.name())) { return true; } } return false; } ``` QueryShardContext would need to expose the same methd and delegate the IndexQueryParseService
ok, talked to David about it. We will add a note to breaking change docs.
IMO we should not handle this in here... we should special case this in `ThreadPool.java` and maybe just use `null` as the value for the queue or move the `UNBOUNDED` sentinel there.
honestly I don't think we should allow negative values here! In such a case we should maybe use a sentinel or `null` as the negative invariant. Throw a hard exception if a negative value is passed!
Extremely minor, but this could drop the `public abstract` part now as `interface` implies it.
Technically not an "and".
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
same - wdyt about a condition suffix/
I meant the listener we pass to the transport
yes, we can't do too much about this, so it is better be defensive here.
is it really possible that we receive join requests if `ZenDiscover#doStart()` hasn't been completed yet? this feels odd to me
this can be removed now, no? it will be cause a duplicate with the full cluster state log..
don't drink and code ð» (same line twice)
maybe `== false` just so we don't typo it in the future
derives -> derived
Usually we'd stick this on the end of the last line.
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
Right - RollupIT is the right place
maybe all the action names should contain `index_template` instead of `template_v2`? In this it would be `indices:admin/index_template/delete`. When v1 has been removed the v2 name is going to be confusing and changing that isn't fun from a bwc point of view.
should we also fail if the name is empty? maybe use `String.isEmpty(name)`
This method also does not need to exist, as you can use `this(indices, IndicesOptions.strictExpandOpen())`, and fix the validation in the other constructor.
(same question for FLOAT)
this method seems to be only used at indexing time, so I don't think it should accept `nowInMillis` since index dates need to be concrete dates rather than math expressions
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
cool thanks for clarifying!
I think this is a sign that `getActionFilters` maybe should take `ThreadPool` as an argument.
On reflection I think this means we don't need `lastCommittedState` any more.
much cleaner. thx.
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
I see what the difference is now but I think the name needs to be changed here. Can we called this method `addPipelineAggregatorReader` or something like that since this is actually for registering the serialisation method for the PipelineAggregator itself not for the result. It's not analogous to the InternalAggregation. Likewise the `addBucketReader` method should be renamed to `addResultReader` since this is not about serialising a bucket but about serialising an InternalAggregation the same as in the metric and bucket aggregations
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
same here - we need move double starting and such to ShardStateActionTests
ver -> version
This assert message says 2 shards, but the check is for `equalTo(6)`
Just wrap and rethrow and let junit report the exception.
Also, `.get()` is much more common than `.execute().actionGet()`.
This `if` is never false because `numberOfShards` is between 4 and 10
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
maybe just `esVersion()`
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
now that #30490 is in, could you replace the header argument with the RequestOptions one? In the method that accept a listener we add RequestOptions between the request and the listener though.
same here - pls refer to `current`
s/token role/token. Mention asynchronously
Maybe just handle the boolean for this PR, but we should think about removing it....
What about the case when `request.fetchSource().fetchSource()` is false? Why do we even have a boolean there? Maybe we should just use null instead? It doesn't make sense to have a `FetchSourceContext` with `fetchSource = false` and `includes = ["something"]`.
can you explain why we do this now only if `autoCreateIndex.needToCheck()`
typo: filers -> filters
I think we should stick with calling these getters like `getCharFilters` because it is the char filters that the plugin has, they aren't "extra" in the context of this one plugin.
All of the `*Plugin` interfaces we have added so far have used `get*`. I think we should be consistent.
see above - I think you should add it though
actually, if its a single page, then we can just reference the first page byte array, if not, then we should return false. same with `array` and `arrayOffset`.
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
I like this way more anyway
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
+1 to capture `System.nanoTime()` at the beginning of the method
we shouldn't need this here in parse phase
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
one step further: I think we could deprecate/norelease these two parseFilter methods and make sure that our refactored queries don't use them, cause they have been moved to toFilter in the corresponding builder.
can you explain why we do this now only if `autoCreateIndex.needToCheck()`
Ok - I see where it is called. These checks are a bit too distant for my taste.
> This method is private and only ever called from a single thread so there is no need to recheck. I'm just weary of having the failure handling case so far from the success case. I figure its harder for someone to break it if its closer together.
This line will break our `precommit` checks because it violates the 140-character line-length limit.
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
fine with me as well. go ahead and push!
well maybe you don't like the success pattern though... but I think it should be closed even on Throwable
can we init this with `1`
can we hide `shared.refcount` behind a method ie. decRef() / incRef() to be consistent with other stuff
Oh this is tricky! Could we use `null` here instead? I'm not a big of making a `Script` that no one can compile. It'll have stuff like `engine=painless` which is isn't.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I think s/lang/defaultLang/
You won't even need the guard if you are just merging to 3.0.0, right? 3.0.0 doesn't have to be wire compatible with 2.x
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
can we use getters here like `getNode` `isCanceled`
`String.format(Locale.ROOT, "%s operation term [%d] is too old (current [%d])", shardId, term, primaryTerm)`
I didn't look at other users of that method, but +1 ! this boolean annoyed me for a while :)
everything in here just uses the state maybe we only pass the state to the method instead of the ClusterChangedEvent
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
This is going to be very funny for term vectors because `fieldText` is empty.
I think we usually prefer a space after `if` and before `(`.
should be `logger.debug("...", e, shard.shardId())` :)
actually I just got a bit confused because both classes are in the same file...
I find it confusing the we have the same field names for this in both ReplicationPhase and PrimaryPhase.
My preference would go to adding a serialization context to readFrom.
I understand this, but this sound confusing to me. You would have some member in each builder that is only set for the prototypes, need special constructors for the injection. I understand your proposed solution with the static method access much better.
well then you have to have a dedicated parser interface - I wonder if this is a general thing we should have on stream input though
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
> Would you do this just when it is overriden (ie not the default)? Or at all times? What about if they explicitly select netty in their settings? Anything but the first is not a one line change. Yep. Log all the time. > I don't think we should just willy nilly log things > I don't think this is useful. It saddens me that this takes so much effort and discussion. It is also sad that there is no constructive discussion but rather these yes/no statements. As I said, I find it useful, for the reasons I mentioned. That should be enough for this kind of change. I'm signing out of this now. I don't think it's constructive anymore.
I think it's important to know that the transport system is replaced and that the settings have effect. This also has security implications, as plugins can add settings. I think this should stay an info log like it was. Adding something similar to the SelectedType is good but over there debug is the right call indeed - it may be used for many things.
oh, I see. It felt like a utility class but it's officially a bless thing. Thanks for pointing it out.
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
It could be useful for debugging too. In the future it's conceivable that the support diag tool might use the HLRC, and we wouldn't want to be dropping this value.
can we debug log the default? also leaning to have info the "non default" setting, thats what we try to do most times in other components to try and keep the startup logs clean and informative.
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
This could be `Strings.hasLength(tokenizerName)`
I'd say it's fine with IAE
but why? :)
can you add a small introduction about what this is? e.g. Parser for terms query and terms lookup
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
To be clear - I think we want to know how the oldest file is, regardless of the generations. It will always be the oldest generation and the first in the reader list, but I don't think we want to rely on it. Part of the role of the stats is to validate things are correct.
Can we add a Math.max(0, currentTime - Math.min()) ? we rely on this being non negative, but time may go back and the FS may have other quirks.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
+1 I like plugin examples!
`client().prepareIndex(...` is more normal now.
This shouldn't be needed anymore. By default we wait for the index to be created now.
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
[{}] for path.
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
Please revert this change.
it would be awesome to have some doc-strings on these settings
Space after the equals. Its a silly small change but it helps my eyes.
It is called pluginId in install because it is an identifier, which _may_ be a plugin name, but it also may be maven coordinates or a url.
No, it should stay "id" in the message because plugins are installed by id (with the exception of some special plugins that can be installed by name only). Yet "name" is fine for removal because plugins are removed by name.
No need to squash, we can do it on merge.
I think I missed the discussion but why isn't all this (this method and the next two) part of BaseNodeResponse's toXContent implementation? It can declare an abstract method that the subclasses can override for their own xcontent? We use that pattern pretty frequently with things like the query builders.
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
Yep, this looks great
we should totally not have this method, one more reason to not implement the interface.
I would probably throw an exception instead of accepting null here.
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
I think this should happen first to make this PR less complex
It is to make sure that the version comparison logic orders alphas, betas, and RCs correctly.
add a whitespace after the if and before the parentheses
ie. when showTermDocCountError is true
is there a way to filter out the index metadata here? We just want the global metadata.
Since `getSnapshotInfoInternal` (just below) is only used by `getSnapshotInfo`, we can move the code in `getSnapshotInfoInternal` directly into `getSnapshotInfo` and get rid of `getSnaphotInfoInternal`
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
Are there other files that might not be in there and we're ok with that? Should we log a warning or something? I suspect its just fine for the directory not to exist but if some file inside the directory doesn't exist when the directory does thats probably bad. Like, in production. In tests is fine to just eat the exception.
we could pass a glob with regex:xxx to newDirectoryStream if we want
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
looking deeper, I see that we set a non null TermsLookup object only when we have it in query, which causes a validation error when values are set too. We should keep it that way then, this is as good as it gets.
I meant that other way around, not in the else, set termsLookup only if values == null
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
1+ portCounter.incrementAndGet() % 9 ? (now we have a collision for 10 & 11 )
why not round robin on this? I think the randomness still allows us to have collisions and will keep us wondering. +1 on the insight that suite and test scope don't co-exists! Also, this makes us one step closer to using it randomly in our global cluster scope.
The max TCP port is 65535 , min 30K gives us ~30K or 30 JVMs.
We can remove the `!` if we reverse this if statement, so ```java if (difference.isEmpty()) { status = RestStatus.OK; } else { ... the error stuff ... }
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Under what circumstances would the mappings for an index be null (as opposed to an empty map)? It seems the default for `GetIndexResponse` is to always have an empty map for mappings (and aliases and settings) and it would only get assigned to a non-null map.
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Well, I think this needs to be fixed here. There is no index created version in field data settings, this is an artificial thing that it sounds like you have added to workaround some other issue.
you can maybe use `StreamInput#readList()`? like `in.readList(in::readString);`
I think we should remove this if, call deepCopy recursively in any case, so that the main else works in this case too. Again being paranoid, I know...
do we need ordered things? does order help anywhere? If not I would just use HashMap
are we sure we want to silently go ahead this way when templateService is null? Maybe we should fail so that we find out when it happens, unless it's situation that is actually expected to happen.
space after `,`
I think you can just initialize to null
we have a test util method that we use to shuffle fields in the response so we make sure that our parsers don't rely on specific keys ordering.
We might should move these last two declarations to a common spot something like ``` static <T extends AbstractObjectParser<? extends QueryBuilder>> declareStandardFields(T parser) { parser.declareFloat((builder, value) -> builder.boost(value), AbstractQueryBuilder.BOOST_FIELD); parser.declareString((builder, value) -> builder.queryName(value), AbstractQueryBuilder.NAME_FIELD); return parser; } ``` and then we can declare them when we're initializing the object.
I'm fairly sure I have the wrong generics incantation there....
I might use an empty array here or switch the IdsQueryBuilder work with lists.
As mentioned offline, I think the name `checksum` captures what we want.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
I think it is fine: we only build one search context per request per shard.
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
take out boost and queryname once you rebased
yes my reasoning is that a compile error makes you think about validation rather then forgetting because there's a default empty impl that does no validation. I tend to prefer an empty validate in all queries that don't need to validate, although that's verbose. Plus that is what we do with ActionRequest as well.
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
replace match here too
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
should we assert that reader.getCoreCacheKey() == engineSearcher.getDirectoryReader()? Forcing the core cache key handling to be delegated to the inner reader could be trappy otherwise
thanks for unwrapping
s/can't used/can't be used/;s/their/they/;s/subtile/subtle/
I saw this problem being dealt with in other place by setting currentFieldName to empty String. Worst that can happen then is that it is treated as fieldName in the query, which we should validate later and throw IAE then.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
can you add a //norelease here too? context should really go away after all queries are refactored
I would add an `assert this.context != null` here just to make sure
I always wondered the same, I think we don't given that everything works without... that said we do have a lot of empty constructors with the `@Inject` annotation. Up to you... ;)
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
I think s/lang/defaultLang/
Fine by me.
actually, you may not even need the array here.
I am not sure that this test is that useful. I think that these two bytes reference objects are even equal when compared directly so they don't need to be compared using assertToXContentEquivalent. We should rather test that order doesn't matter by shuffling keys and/or verify the behaviour of assertObjectEquals .
I see, and you are right, camel case is preferred. I probably misread the "NoNestedDocs" part of the name as "no nested docs" and that confused me for a second, but either way is fine.
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
oh oh I hadn't read your reply when I replied ;)
I wonder if this should rather be made part of Request#multiSearch like we did for bulk. I see that it may be nice to have read and write methods close to each other, on the other hand the only place where we need to write this format is in our client.
Missing a space here after `id`
You won't even need the guard if you are just merging to 3.0.0, right? 3.0.0 doesn't have to be wire compatible with 2.x
should this listener be volatile? I also wonder if we should fail / throw an exceptin if the listener is non-null when we try to set it? -- there is a nice class in lucene called `org.apache.lucene.util.SetOnce<Listener>` which does that for you
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
this can be out of if now.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
I find that `equalTo` is almost always a bad choice. In this case I think `assertThat(cancelTaskResponse.getTask(), hasSize(1));` will do the same thing but have much better error reporting. That way you get to see all the tasks when there are too many. Same for the above assertion.
+1 I like plugin examples!
nit: space before instanceof
nit: space before instanceof
I think we can do this more simply by looking at `endsWith(".jar")` of the uri string. We don't really need to convert the uri to a path, since we don't need to load the file. Then, the original if statement can simply be wrapped with like: ``` URL location = clazz.getProtectionDomain().getCodeSource().getLocation(); if (location.toString().endsWith(".jar") == false) { // original if and exception here } ``` Basically, if the file is in a jar, we don't need to worry about it here, as those would have already been added to the codebases map by `Security.getCodebaseJarMap`. This method is about adding classes that are on the classpath, but not via a jar (ie built by the IDE).
nit: extra space
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
assert for verification whether it is created
The `new HashSet<>()` can be replaced with `Collections.emptySet()` (and then you'll have an import to remove).
It defaults to `false`. :)
Let's also make this a JUnit assertion instead of a Java assertion.
I think this could use the `rebalance` function in `CatAllocationTestBase`? It looks like it's performing the same function
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
you are right thanks a lot for catching this
I am still missing `_version`, `_version_type`, `fields`, and `_parent` here we should add them!
As Boa mentioned before we would need both a default to print out, and a boolean that tells whether the current value is default or not, as the `currentValue != defaultValue` is not enough. Something like the following should help in most cases I think? ``` public static void maybeAdd(XContentBuilder builder, String key, Object value, Object defValue, boolean isDefault, boolean includeDefault) { if (value != null || !isDefault) { builder.field(key, value); } else if (includeDefault) { builder.field(key, defValue); } } ``` That said, maybe it doesn't cover 100% but 90% of the cases, and for the 10% left we can still have the custom if? In my opinion it doesn't need to be perfect but still better than copy pasting that `if` so many times.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
I think this declaration/initialization can be moved to inside the if
can resolve possibly return null? if so we should check for it
the important part is having multiple open readers on this as well.
why do you pass the response to this method? `this` already has all information.
remove "or timing out".
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
No, that's fine.
This is only used in the constructor, doesn't need to be a field.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
depends (which is why I asked). If it's about API bwc I think we should break it and be clear about the impact of the version. Which is also makes me think we should not render the field if we don't have a version (because we removed it)
Wondering if this could be abstract, so subclasses don't forget to implement it. Looks like many would have an empty implementation though, so just a thought.
What about : ``` json "retries": { "bulk": 0, "search": 0, } ``` Note: I tend to like JSON inner objects since clients and parsers can skip whole objects while parsing...
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
this setting should probable `componentSettings.get("page.type", ..)`, which resolves to the full setting of `cache.recycler.page.type`.
also, the setting should be using `componentSettings.get("page.limit", ...)`, so it will resolve to `cache.recycler.page.limit` (and I think the in_bytes usage here is not needed).
I think we have at least one similar test that does the same, we can maybe share the dummy client to minimize the code repetition. It's not that we cannot use mockito, we could, we would need to have a bigger discussion around it, some people are in favour of that and some others are totally against it. I personally don't think mockito would solve all our problems, we should strive to make elasticsearch more unit testable, easier to say that to do though :)
cool stuff I didn't see that one!
can this be final
Can you change the line wrapping on this somehow? Like stick `new InputStreamStreamInput` on a new line and indent it? I think as is it'd break how I visually scan try-with-resources.
I think I'd rather stay on the safe side
thanks for unwrapping
This doesn't look right to me. If `subPath.path` is null, or if `seenDevices.add()` returned false then we don't call `seenMounts.add()` despite having seen the mount point in question.
we could pass a glob with regex:xxx to newDirectoryStream if we want
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
Since `value` internally is a String now, we can change read/write here as well.
sorry, my bad.
we set the rewrite method twice it seems? probably a bug in the original parser
and i guess where we instantiate singleton, we just let Kernel32Library be null if it cant load? I dont know if its cleaner actually, it means callers woudl have to check for that. i just think its wierd to have all methods have to check isLoaded and do nothing. Currently there are only a few, but if the class increases...
can we change this to Loggers.getLogger(getClass());? it is what it should have been to begin with, which is my fault ;)
`} catch (IllegalArgumentException e) {`
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
I think I saw this in Christoph's PR too. Hopefully you don't need it.
I don't think you need @Before here, the parent method already has it.
I think that it's cleaner to write this as: ``` ElasticsearchParseException ex = (ElasticsearchParseException)ExceptionsHelper.unwrap(e, ElasticsearchParseException.class); assertNotNull(ex); assertThat(ex.getMessage(), equalTo("processor [test] doesn't support one or more provided configuration parameters [unused]")); ```
Maybe: ``` java Exception e = expectThrows(IllegalArgumentException.class, () -> RestAnalyzeAction.buildFromContent(content, analyzeRequest, new ParseFieldMatcher(Settings.EMPTY))); assertThat(e.getMessage(), startsWith("Unknown parameter [token_filter]")); ``` That way you don't have to assert the type of the exception.
Maybe call this "testEmptyBoolSubclausesMatchAll()"? Sorry if I misunderstood what the test is doing, I just think having a github issue number in the name is unhelpful to someone if they see a failure.
can we rename it to something like allNodeResponded ? we're not sure we're going to delete...
I don't think we need all these counters? we can have awaitingReponses which goes to 0 and a activeCopies one that goes up. We stop when awaitingResponses reaches 0 and delete when activeCopies is what we expect
I think we should encapsulate the testing code from the `clusterChanged` method and just call it again to sanity check it's safe to delete
This needs to be another method (`parseInnerFilterToQueryBuilder`) which replaces `parseInnerFilter` and also takes care of switching the interal `isFilter` flag.
ok lets get this PR in and address this problem separately, I think we overlooked this when migrating the bool query. This check should be moved to the toQuery method. We should start looking into dividing the context into a query parse context and a to query context I think
other question, sorry! but I still find this confusing... previously we had null here for two situations: 1) empty filter/query 2) queries that after getting parsed would become a null query (their parse method returns null) the first case falls now under the EmptyQueryBuilder case, which we handle here. But there can still be queries whose toQuery returns null, which need to be ignored, but that we know only in the toQuery, but we still set the minimumShouldMatch only based on case 1). I think setting the minimumShouldMatch like should happen later in the toQuery, which kinda makes sense, it needs to be done only on the resulting lucene query, not against the query builder. So we can potentially add empty query here to the clauses as long as we move this check for null should clauses only in the toQuery method, if that makes sense
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
any chance we can remove the interface and just name this class NioChannel
there is only one impl
solely based on names, hard to distinguish from `testRebalanceNotAllowed`
I guess that's not encapsulated into the message, so it's hard to check huh..
I would use the following message: "ignored as shard is not being recovered from a snapshot" and not have an explicit check for `shardRouting.primary() == false`. That case is automatically handled by this case too as replica shards are never recovered from snapshot (their recovery source is always PEER).
When getting a `searcher`, you need to keep it around, and then call `release` on it on the `finally` clause.
Once we have a `running` flag, we can check on it and not on `isAlive`.
I suggest adding a volatile flag called `running`, add a method called `stop` that sets it to `false` and interrupts the thread.
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
would be great if this logic could be unit tested.
I think filter and query can never be null here? not sure whether we should validate this here.
formatting, 1 line instead of 2
formatting - 1 line instead of 2
can this be in try-with logic.... you are not closing this input stream at all
Remove and create again is not needed I think
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
I was only talking about the context _path_. But what you have is fine for now, the entire class really needs a rethink. :)
I would also like it better if the side effects of this getDynamicParentMapper were limited to just dynamic field creation, and path management stayed local (so that we keep both the add and remove together in the same method).
Do we really need a tuple? Shouldn't it always be `paths.length - 1`, ie anymore more than one path piece means we had to get that many extra parent mappers? Alternatively, I had also considered adding a serialized form, ie do a join of the first `paths.length - 1` elements of path and add those as "one thing", so you are always just removing a single element at the end. I think this would work since all path serialization does is add dots between elements.
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I wondered if there was something better than iterating too but there's not since `IndexWriter#getLiveCommitData` only returns an `Iterable`.
a transformer and performer. Quite a guy :)
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
I would add an `assert this.context != null` here just to make sure
can you add a //norelease here too? context should really go away after all queries are refactored
In a followup PR we should merge SortBuilder and SortBuilderParser, I think. The latter one was only introduced as an intermediate step to avoid having to refactor all builders at once. Not sure if we can add the interface ToXContent there as well then.
We should be testing serialization here by extending `AbstractXContentTestCase`. Unfortunately, that means we need to also write a parser for the request but it's worth it.
final and java docs
it's a shame java need this...
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
Can we call this just `score`? I've been trying to give the script context identifiers names that don't include "script" since that is implicit.
nevermind I was confused... all is good
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
This predicate can be simplified to `(count, limit) -> count > limit`.
What if the user specifies 0 here? Previously that meant unbounded.
given that the suffix is also known before we go and provide index, type, and id... (even in case of e.g. _search) I wonder if we can get rid of the list, and just provide parts and suffix as constructor argument, then convert it into string straightaway. Not even sure we need a builder for this.
Nit: maybe move this up next to the other methods (ping/exists/get) that output new Requests.
Maybe we can replace calls of this helper with the new Endpoint class? Might get a tad bit longer in the end, so I'm fine either way.
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
no file? maybe IOException
maybe just `return blobMetaData.length() == fileInfo.length();`
I'd feel better if the `latch.countDown()` would be the first line in the catch block
I think this check should go into initializeSnapshot or repository.
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
Since `getSnapshotInfoInternal` (just below) is only used by `getSnapshotInfo`, we can move the code in `getSnapshotInfoInternal` directly into `getSnapshotInfo` and get rid of `getSnaphotInfoInternal`
if we do this, why did we need to change how createNewEngine behaved (i.e., update currentEngineReference etc.)
it will be good to have some kind of progress logs here (like log ever 10k ops or something) under debug.
I looked at the implications of exposing an engine that isn't fully recovered yet and it's OK, with the exception of syncFlush(). Depending how this ends up being, we may need to make sure that runs under a permit.
I think this is okay though, it checks if the current `zeroTermsQuery` is the same as the default, which is ZeroTermsQuery.NONE.
we frequently use randomizing client, I think that it should frequently use the default (null) preference
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
this seems to be a very expensive operation I wonder if we should special case this here rather than adding a generic way of doing this.
Looks better to me but I think I'd rather like a Map<String, AtomicLong>, ideally pre-filled with every possible action name so that the map is effectively immutable afterwards and concurrency is only handled at the AtomicLong level? It would also create fewer boxed longs.
Nit: `seqNum` -> `seqNo`
maybe expectThrows would be easier.
Is this is necessary given we loop over OpType.values()? If other values are added in the future we should fail because expectedBulkItemResponse/originalBytes is not set anyway.
is it an option to make this method package private? Then it would become more of an internal thing. Thanks for addressing this!
This was called "path" before.
Ah CONTENT_TYPE I see. Sorry for the noise ;)
I'm pretty sure camelCase shouldn't be supported any more.
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
Do yo need the parameter `filters`? The only call of `evaluate`just uses the field `filters`.
In case you don't need the parameter, you can remove the null check as the constructor already checks that as a precondition.
It would also allow you to change the ``` java if (delete) { channel.deleteOnClose(); } channel.close(); ``` to ``` java channel.deleteOnClose(delete); channel.close(); ```
I think it would be better to pass a boolean in to this method, since it's ambiguous from the name of the method whether it sets a var (could be named `setDeleteOnClose()` if it were setting something) or actually does the deleting.
I only mentioned it because if we really have to keep this, then StandardOpenOption.DELETE_ON_CLOSE could be an implementation. But this one has race conditions too, this delete-on-close stuff is why Lucene's lockfactories were buggy for years. Lets defer it to a new issue, ideally we just nuke it completely.
Sorry, what I meant by the previous request was to do an assertion on the whole error string (e.g. wie assertEquals), unless there are any reasons preventing this.
Is this is necessary given we loop over OpType.values()? If other values are added in the future we should fail because expectedBulkItemResponse/originalBytes is not set anyway.
nit: `an` -> `a`
I also need to go back and do this for the PutUserRequest
Can we also clear the temp `charBytes` array, something on the lines of: ``` final byte[] charBytes = CharArrays.toUtf8Bytes(password); try { return builder.startObject() .field("password").utf8Value(charBytes, 0, charBytes.length) .endObject(); } finally { Arrays.fill(charBytes, '\u0000'); } ```
nit: remove extra new line
we throw the exception and thus take care of the interrupt. We don't need to set it...
Could you explain why you log a deprecation her? Might be missing some context, but I thought this PR wasn't about deprecation but about adding some option to the field mapper.
same here just use synchronized methods
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
thanks @nik9000 ! @elastic/es-clients is this ok? I guess all the client runners will have to be changed accordingly.
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
would be nice to allow to configure it to a percentage of the heap size
@gmarz @kimchy but it is okay for them to be different simply because we allow it :) The worse case is that we kill starting with MinHeap (growing to max immediately) instead of otherwise the worse case being mlockall'ing too little.
If they are different then mlockall will not really work on unix either. That is because it may map additional stuff later!
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
AFAICS (correct me if I'm wrong) you had to it this way because we don't know on what node version the primary is (i.e. if it is going to send maxSeqNo or not), and the shard is reset when we acquire the replica operation permit (i.e. possibly before we receive the first resync request). It's a shame because it means we can't ensure consistency for older indices. The only other solution I can think of right now would be to always send the maximum sequence number with the replication request (same as we do for the global checkpoint). We could then pass this to acquireReplicaOperationPermit (same as the global checkpoint).
I looked at the implications of exposing an engine that isn't fully recovered yet and it's OK, with the exception of syncFlush(). Depending how this ends up being, we may need to make sure that runs under a permit.
make this synchronized too. it's safer since you modify both references
can we use `== false` instead of `!` it's so much easier to read and burned my fingers too often
One way to implement this: Ignore the LockFactory of the inner directories and require the LockFactory to be set on DistributorDirectory itsself (by extending BaseDirectory and taking a external LockFactory on ctor). In that case the Distributor would know the exact type of lock, because it is responsible for locking. The underlying directories would just need no locking at all (NoLockFactory). But this would be a change out of the scope of this issue. But I like the current impl better. Locking should be the responsibility of the directory that actually holds the lock. This implementation is now implemented the same way like FileSwitchDirectory. FileSwitchDirectory just has the additional "feature" that it delegates the makeLock() call by its file extension, too (and no longer places it in primary dir), see MIGRATE.txt in Lucene. Please also keep in mind, that the lock file itsself is an implementation detail, so maybe we get another lockFactory in the future that does not create any files at all (e.g., by locking the directory itsself or writing some information to its metadata). So to me it looks wrong to see the lock file as required to be listed in listAll(). Lucene itsself does not depend on that (because lock files are unknown to lucene), Lucene just uses the makeLock() method, nothing more.
I think enforcing this as a List of `ShardLock`s would be better, type safety wise
Listener can be null here.
unkown -> uknown
Instead of acquiring the shard lock for a second time, I would prefer if we would do it once, and move this call under that lock and just rename `tryOpenIndex` to `tryOpenIndexUnderLock`, removing the locking mechanism from it. Same thing for `TransportNodesListShardStoreMetaData`. You can then also remove the `ShardLocker` interface, which irked me for a while.
ah I mean't Throwable.... sorry
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding jvm plugin [{}]", plugin.v1()); } ```
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
It'd be "more normal" to declare this as `Writeable` and use `readOptionalWriteable` and `writeOptionalWriteable`. You've done plenty in this PR so it can wait though!
Alternatively we can move this logic to the `beforeRefresh` method as this is the only place it's used at.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
I think filter and query can never be null here? not sure whether we should validate this here.
I think this has to happen before you start the cluster, or else the cluster will start with full knowledge.
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
a transformer and performer. Quite a guy :)
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
I feel like we implement this pattern enough times that we should make a helper for it at some point. No need now, but at some point.
Hope this doesn't bite us for really slow (read: Windows) CI servers...
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
> Would you do this just when it is overriden (ie not the default)? Or at all times? What about if they explicitly select netty in their settings? Anything but the first is not a one line change. Yep. Log all the time. > I don't think we should just willy nilly log things > I don't think this is useful. It saddens me that this takes so much effort and discussion. It is also sad that there is no constructive discussion but rather these yes/no statements. As I said, I find it useful, for the reasons I mentioned. That should be enough for this kind of change. I'm signing out of this now. I don't think it's constructive anymore.
I think it's important to know that the transport system is replaced and that the settings have effect. This also has security implications, as plugins can add settings. I think this should stay an info log like it was. Adding something similar to the SelectedType is good but over there debug is the right call indeed - it may be used for many things.
oh, I see. It felt like a utility class but it's officially a bless thing. Thanks for pointing it out.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
ok...but client depends on the transport service anyway no? I think I don't get it
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
This logging should be removed.
Thanks for moving this to `InnerHitContextBuilder` and its subclasses!
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
yes lets do it later otherwise we have to remove setters and break things.
sure things changes now that we know for sure the target branch, that said making everything final would be better to do once we merged back to master to prevent merge conflicts here. Same with renaming XYZQueryBuilder to XYZQuery, and moving to proper getters and setters.
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
64e5c25 added support for this.
It might also depend on which implementation of `AcknowledgedResponse` you are using, since we have two, yay duplication!!! You should have a look at `StartRollupJobResponse`, which is an example of changing the word from `acknowledged` to `started`. this should get you on the right track.
> just let the default be 1 instead My rational with going with half as default is that I think that adding replicas should change the behavior - if someone runs with 6 copies , it's probably not a good default to let of them (but one) go away before signalling alarm. I chose the word "half" in order to avoid a loaded word like "quorum" which implies stuff that aren't part of our model (i.e., quorum reads). I don't mind if we round up (i.e., `(size() + 1) / 2`) or down (i.e. `size()/2` ) as long as it's not `size()/2 + 1` .
> 6 shard copies? That's rather useless in a system like ES We do have people using more then 3 shards so that lead to the idea of having the default scale with it. Thinking about it more I think the main usage for having so many copies is auto-expand-replicas-like usages, where you want to have shard copies available on all active nodes. In those case I think you mostly care about the data being on everything thatâs up and not be bound by durability guarantees. In that case I would be fine with waitForActiveShards default to 1 and allow people to set things differently on the index level if the want different default (when we do that change). > This setting is of limited use anyhow as it does not provide the guarantee that most users are after Correct - this setting is meant to be used to limit the scope of events that will be indexed into less than a given number of shards. It should be coupled with a check of the response of each write operation.
This method could take an IndexMetaData object as parameter instead. This would let us get rid of exceeds method as well.
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
Same here about multi-line toString methods
ahh yeah in `assertAfterTest()` nevermind
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
underscore case? :)
now that #30490 is in, could you replace the header argument with the RequestOptions one? In the method that accept a listener we add RequestOptions between the request and the listener though.
as odd as this sounds, could you rename the methods to flushSynced as that's how this API is referred to in our [SPEC](https://github.com/elastic/elasticsearch/blob/master/rest-api-spec/src/main/resources/rest-api-spec/api/indices.flush_synced.json) ? request and response can and should stay the same.
same here - pls refer to `current`
If we're doing a reroute - I don't think we should retry on retryPrimaryException. That one only holds for the primary action.
can we have an explicit boolean for this? feels hacky...
Nit: I think it will be safer to have this boolean as a parameter and determine the action here. I'm weary of arbitrary string input.
Is this a typo? Not sure how this compiles...
Ahhh, it's been a long time since I have seen this syntax...
Can you add a check for reparsing (ie taking a settings that have been run through archiver and using them in another settings builder) the settings works? ie the setting stays archived and doesn't disappear.
this would make sense especially given that their setters accept primitive types
wonder if we should make these Integer and Boolean just int and boolean primite types.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
shortcut: VersionHandshakeResponseTransportResponseHandler handler = pendingHandshakes.remove(requestId);
nice and clean :) another variant you may want to consider is creating an index with way more shards than nodes and see that we get to yellow (now we will wait for a quorum of copies)
Nit: `if(` -> `if (` (whitespace)
what to do here otherwise? not really likely to happen that it's not a number I guess... maybe leniency is good here
I get it now, yea I feel more comfortable making these changes in the query-refactoring branch cause we have more extensive tests, otherwise we should introduce tests in master too. It doesn't fix any bug anyways...
right, missed that :)
for instance in RestoreService we use `addLast` at runtime which messes with this assumption, that entire order thing is broken and error prone. The best thing I can come up with so far is to add defined stage like this: ``` Java enum ApplyStage { NewClusterState, NodesConnected, StateRecovered, ShardsStarted, RepositoriesCreated, NodesDisconnected; } ``` where listeners can be registered but I am not too happy about it...
that sucks, sorry :) We can't build stuff that is dependent on the order of how the listeners are added! Can we find a better way of doing this? I think each listener needs to have priority or so and every prioritoy can only be added once? Maybe we don't need this to be a list at all? This stuff is so fragile we have to iterate until it's safe
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
Heads up when you merge with master, I just merged another test where the original test query is modified assuming it is json, so that will need the same treatment as you do here I thinkg: https://github.com/elastic/elasticsearch/pull/14255/files#diff-9dc314365d49d84bff0645c2f9dfd7adR356 (and Overwrites in HasChild/HasParentQueryBuilderTests)
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
Nit: addresses -> address
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
Please fix identation.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
One option might be for this class to hold the already serialised form of the exception, but I'm not sure if that is better or worse than the current solution
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I don't think it matters. We should not force making huge changes to the entire codebase in order to not add things which will just be deprecated and/or confusing to the user.
nit: extra line
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
My preference would go to adding a serialization context to readFrom.
I understand this, but this sound confusing to me. You would have some member in each builder that is only set for the prototypes, need special constructors for the injection. I understand your proposed solution with the static method access much better.
well then you have to have a dedicated parser interface - I wonder if this is a general thing we should have on stream input though
Ah, nope, I'm just bad at Java. `[Metric1, Metric2]` is exactly what I was wanting. :)
Now that there are two cases, I wonder if we should push the isAggregatable() check out of the type conditionals (e.g. apply to everything), then have an `if...if else...else` for the types? That way we won't need another conditional inside the first that specializes for the date type. Not sure how that would look, so the current way is fine if that ends up being messier. :) Has a nice side effect that the validation error will include both a message about non-aggregatable field as well as the metric missing at the same time.
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
if we only use all names to put things in the map we lose all the deprecation warnings that we might have etc. we should rather keep track of the original ParseField and call ParseFieldMatcher#match.
I think we should always return 1 here. REST tests should run with default number of replicas (1) even against a single node, because that's what clients tests do too. We can never expect green unless we manually set number of replicas to 0 in a test, and we should align to clients builds here I think to prevent failures that don't repro for us. Thoughts? BTW running against a single node is very helpful because it allows us to realize when we make the wrong assumption in a REST test, which in the past was only going to fail for clients and never for us.
well if a test doesn't call `super.nodeSettings(nodeOrdinal)` that is a bug. We have to enforce it though. IMO we can use a similar way as the test base class does but we don't have to do it here...
well we don't need to extend this anywhere, plus these changes don't have anything to do with this PR at this point, would prefer to leave them out.
same here with removing retry logic
same here with removing retry logic
same here, all retry logic should be removed
can we name this `CompleteDiff` don't use simple please :)
`min` can be named `simple` or `aggregation`
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
`.addPathPartAsIs("_xpack", "rollup", "job")`
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
we also support a parameter called `updateAllTypes` here.
just my personal preference, I don't like instanceof checks that's it. you are free to leave them if you prefer them ;)
I think if we get in that other PR I just reviewd we can reuse here the new method that you introduced there? :)
we should `@Test` to forbidden API
can we report the right version we found ? note that we would probably need to change the the logic in the gateway allocator to check for both -1 version and exception (now -1 means both).
Instead of acquiring the shard lock for a second time, I would prefer if we would do it once, and move this call under that lock and just rename `tryOpenIndex` to `tryOpenIndexUnderLock`, removing the locking mechanism from it. Same thing for `TransportNodesListShardStoreMetaData`. You can then also remove the `ShardLocker` interface, which irked me for a while.
missing { } :)
+1 this makes sense. Then we can drop the `PIPELINE_ALREADY_PROCESSED` transport header.
I'm not a big fan of ActionListener<Void>? Maybe we can do this differently and replace it with two functions? Runnable for the onResponse() part and for onFailure use a Consumer.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
can we add a one lliner java doc explaining why this is needed (rather then pass through the the primary lock factory)? it's non-trivial to figure it is done to track the location of the lock file, if it's using files..
It looks like this includes the change from #8383? (nothing that needs to change, just curious)
++ on debug message
You can get away with it right now because there is only one test, but this should be initialized once before the test suite, not once before each test in the suite.
You can just use the literal boolean `false` instead of the string `"false"`.
Can you make this a JUnit assertion instead of a Java assertion? It's preferable to use a test assertion with matchers for this because then nice error messages are produced automatically when the assertion fails.
we could pass a glob with regex:xxx to newDirectoryStream if we want
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I think it'd be easier to read if this were `ObjectParser` stuff.
This'd only come up if the target augmentation method is defined on an interface, right? Maybe we should not allow that at all.
I think this'd be more clear if you said something like "invokeStatic assumes that it is not invoking a method on an interface."
I see why you did this with the map here. I wonder if this is more of an argument for a builder because you can set the lang on the builder before you do the parsing.
if the argument name is `failNoIndices` you should provide `! indicesOptions.allowNoIndices()` as argument
I see your point on changing the name, that makes sense cause allowNoIndices != indicesOptions.allowNoIndices
if the argument name is `failNoIndices` you should provide `! indicesOptions. ignoreUnavailable()` as argument
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
Nit: space between the cast operator and the target.
Usually we'd stick this on the end of the last line.
Right - RollupIT is the right place
CCE is never a good idea to throw out - especially since it forces the caller to handle it. It should be handled inside convert directly.
do you know if there is a good reason to return 0 if we got a negative value, or could we just return 'result' directly? (if this doesn't make any tests fail, this is good enough for me)
do we need ordered things? does order help anywhere? If not I would just use HashMap
It feels wrong that hashCode is using writtenBy while equals isn't
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
Please add a string message about the context registry being null
master is the future 7.0, so I would do the following: ```java if (INDEX_MAPPER_DYNAMIC_SETTING.exists(indexSettings.getSettings())) { if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0)) { // 7.x index throw new IllegalArgumentException("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " was removed after version 6.0.0"); } else { // 6.x index DEPRECATION_LOGGER.deprecated("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " is deprecated since indices may not have more than one type anymore."); } } ``` Then when backporting I'll just remove the 7.x branch and make sure that we only emit a deprecation warning on 6.x indices (you don't need to worry about it).
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
we have `TestThreadPool` that makes it simpler
use `ThreadPool#terminate` here otherwise you will get lingering threads etc.
I think that all of these members variables except for `finalResponseListener` can be `private`.
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
nit: formatting, add some whitespaces
if we fail to start do we close the started ones
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
cancel that :) I figured it out.
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
oh cool the read is in the ctor! nice!
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
Same here... we don't really need `String[] addresses`
``` java assertThat(provider.fetchCount, is(1)); ```
``` java assertThat(provider.fetchCount, is(2)); ```
I would be using a `Set` in this circumstances.
We also need a simple rest test, testing integration like we have for the other processors
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
java 8 FTW
I wonder if this case distinction should be part of ReplicatedOperation.
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
or junit for that matter. try/catch is much more readable (and the way most other tests do this)
Can we just use a simple try/catch here? I don't see why we need to use hamcrest complicatedness...
Same suggestion here for `assertNotEquals`.
I'm clearly not getting my point across. Please understand that multiple tests are run in the same jvm during jenkins!!!!!!!!!!!!
I wonder if we want to ban `new Random(int)` to make it harder for folks to do `new Random(System.currentTimeMillis)`. If so then `Randomness` is probably the right way to go. Otherwise I like `GOOD_FAST_HASH_SEED`.
Just to make it better, setting it here in clinit is not so ideal, because its not perfectly reproducible when multiple tests are run in the same jvm. you will still have perceived reproducibility issues vs jenkins if you go about it this way: because the random will be initialized _once_ and then we will run 8 test classes against it. then, when you later try to reproduce the one that failed, the sequence will be different (even though the initial value is the same), because the other tests are not also invoked. but if you do it this way, it at least allows "whole build" reproducibility, which is an improvement. That means e.g. if you nuke your local execution hints file and run 'gradle test -Dtests.seed=xxxxxx -Dtests.jvm=yyyyyy', it will match what jenkins did. But nobody does that.
Also, it can use `execute()` rather than `submit()` as it's not interested in getting a `Future` to track completion. Since you're off I'll push another commit that changes both things.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
pageParams is missing from the equality check
would it be possible to make the second part of this method part of the field script object itself? It would also be fantastic to use the same mechanism on both sides, but I know it is a bit tricky for different reasons: 1) that array that we reuse without resizing 2) we try so hard to avoid boxing 3) the usage pattern is slightly different if we compare doc_values, query and index time execution. I do wonder if it is worth investing on this, possibly having our own PrimitiveIterator or something that allows us to expose a clearer script API to access the computed values. For later I guess.
I asked before if the bit from runForDoc till the end can be a new method exposed by the Script class, in the effort of consolidating how field script classes expose their values. Do you have thoughts on this? We could also do it later
I spent some time thinking about whether we can consolidate this, like we do for runtime fields (e.g. the compilation could be done in a single place for all types). We can't really do the same that we do for runtime fields as NumberType is an enum and can't have a generic type, while the different Factory and LeafFactory don't have anything in common throughout the different types hence require a generic type somewhere. Whatever we do ends up being complicated for little gain e.g. saving a few lines of code). One thing is I find it a bit tricky to follow that thanks to this we compile the script at mapper creation time and not at execution time. We could potentially make MapperScript an abstract class with a generic type (the factory) and compile the script in its constructor. That is not perfect but maybe clarifies when the script gets compiled.
It's minor, but we usually lowercase exceptions and elide ending punctuation
I think something like `randomSearchSourceBuilder` would be a more consistent with other random builders.
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
if we run into an exception here we have to close the stream. we usually do this: ```Java boolean success = false; try { // do something with the stream success = true; return stream; } finally { if (success == false) { IOUtils.closeWhileHandlingException(stream); } }
I think all of these need to be trace and we should enable these in tests that are relevant.
IMO lets drop them all. IF you have to make them trace you can also just add them back if you need it.
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
please use Arrays.asList while we re here
can this be synchronized please
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
now I see what you meant yesterday saying that we have to parse meta here
Would it be better to use the Assert.fail(String) method or throw an AssertionError here? That way the test will fail correctly in the test framework
My motivation is both making it so there is one obvious way to calculate distance (I was reminded recently of this beatiful mantra from the Zen of Python: `There should be oneâ and preferably only one âobvious way to do it.`). I also think not having instance methods will allow us to play more with the underlying field access so we dont need an intermediate object, GeoPoint).
Oh I see, it's the ZTable stuff. Sorry for the noise :)
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
w00t thanks !!
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
`Arrays.toString(paths)` already adds [] , no need to add them
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
same here. ElasticsearchAssertions.assertThrows wil help
maybe add the type that is found in the error message with fieldType.typeName()
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
can this be final
@uboness I mean that it is called by the transport client going through the transport service directly (as was the nodes info call before), it is not exposed through clients, so java api users can't call it explicitly (the `Client` doesn't expose such api).
I really like this class since it's so self-contained and has all the tests etc. no weird guice bloat etc. NICE!
This exception will be treated as ignore replica exception. :wink:
maybe put this check before the primaryTerm check
try finally here please since if close fails we don't release lock etc which can be missleading
I think you forgot to add the name of the script here to the failure log
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
Er - if you are going to log something then it doesn't matter which order you do it I guess.
right thanks for the explaining, I should have known, having worked on the search refactoring :)
We call them "master nodes" everywhere else. :frowning:
this should be `INDICES_CACHE_REQUEST_CLEAN_INTERVAL.get(settings)`
class could be `final`
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
There is because it becomes one very simple line: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java index 6220c4d..5604bf7 100644 --- a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java +++ b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java @@ -89,15 +89,7 @@ final public class IndexGraveyard implements MetaData.Custom { @Override public boolean equals(Object obj) { - if (this == obj) { - return true; - } - if (obj == null || getClass() != obj.getClass()) { - return false; - } - @SuppressWarnings("unchecked") - IndexGraveyard that = (IndexGraveyard) obj; - return Objects.equals(tombstones, that.tombstones); + return obj instanceof IndexGraveyard && Objects.equals(tombstones, ((IndexGraveyard)obj).tombstones); } @Override ```
You're right, I confused myself.
Beware that bucketOrd has the following definition: ``` java final long bucketOrd(long owningBucketOrdinal, int filterOrd) { return owningBucketOrdinal * filters.length + filterOrd; } ``` So we need to somehow multiply by `filters.length + 1` instead of `filters.length` when we compute the other bucket otherwise there will be several "logical" buckets reusing the same "physical" bucket
I think ``` java if (prevParentDoc == -1) { childDocId = childDocs.nextDoc(); } else { if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc); } } ``` could just be replaced with ``` java if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc + 1); } ``` ? (No more check that the previous parent doc is -1, and advance to `prevParentDoc+1` instead of `prevParentDoc`)
is it worth doing the conversion from and to geohash every time here? Could it be better to not do the conversion and store two doubles per bucket instead of one long? I guess its a trade-off between execution time and memory
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
ah I mean't Throwable.... sorry
This can just be a plain old logging statement `logger.debug("[discovery-file] using dynamic discovery nodes {}", discoNodes);`.
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
This whole loop reads fairly low-level. If config files can be considered small, we could just read them much more concisely with the Stream API (untested): ``` java String rules = Files.readAllLines(path) .stream() .filter((v) -> v.startsWith("#") == false) .collect(Collectors.joining("\n")); ``` All the low-level stuff is gone. But this relies on Java 8 features and will only work on master.
there is a test helper method that can create plugin property files
We will need stronger assertions here too.
This lambda does not need to be a statement block.
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Feel like this should be more significant than `debug` because it really indicates a form of failure in some scenarios.
I still think skipping is better tbh... otherwise the users will be more confused on how to merge the old one with the new one. I don't think the file formats will change that much... but when they do, we'll simply be able to tell them what to change in the files they already configured in order to be compatible with the new version (not sure that will even be needed, we could perhaps support both formats in the code and make it transparent).
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
This predicate can be simplified to `(count, limit) -> count > limit`.
oh nevermind, I just found the method that called it with null :)
same here re enumSet.toString
same here. I would prefer to have a separate `runTranslogRecovery` method that we use for the local replay after reset. This method could then use a different stats object as well as a different origin.
I am not a super fan of this. I wonder if we can afterwards rethink this.
you are right, the original indices are read/written in the super class, good! You can then remove the PercolateShardRequest that takes shardId and originalIndices as arguments I think.
I think it's odd to have a public constructor for a test only... remove the OriginalIndices parameter at least? it's always set to null I think.
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
Quick question (unrelated to this PR) for clarification: the goal was to get rid of the Prototypes, but this will happen in later PRs? Is there already a proof-of-concept type of PR I can look at how this will work, I just played around with it a bit wasn't quiet sure how this will work with the common `boost` and `query_name` fields.
Having all the query names ony here in `SearchModule` also makes it hard to test them for accidental changes. We are not doing that yet, but I think we should, and for that they should stay in their respective classes.
The previous builder also supported "multiMatch". I'm late to the party, but this is one problem I see in removing the alternative `names()` method from the builders, it moves the parser names (and alternatives) far away from the builders themselves. I guess this move is part of makign QueryParse a functional interface, but couldn't we leave the `names()` method and use it even though it will not be part of the QueryParser() interface? Or add it to AbstractQueryBuilder instead? Having all these string constants here in this class without a connection to their builder is a source of errors IMHO.
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
nit: can you use assertThat or expose the actual values in the message.
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
marks the shard store
I wonder what our system invariants are w.r.t primaryTerm in IndexShard. Primary term has for example a direct impact on the reroute phase. A new primary term means that we need to route to a new primary location. The big question is: What is the relation between primaryTerm that we use for routing to primaryTerm in IndexShard? Maybe we could require both to be the same and otherwise abort primaryOperation? Other invariants to think about: - If IndexShard gets created as primary shard (that is not a relocation target), then it should have the same primary term until its closed, right? - If IndexShard gets created as primary shard (that IS a relocation target), then it should switch its primary term only once, namely when it gets activated. I wonder how can we better capture these invariants in the code.
I spent some cycles reading this and convincing my self that we can do this regardless of the searcher scope - i.e., that if we end up here with an internal searcher it will be OK (it is!). I would personally think it will be simpler to follow if we mark access in `awaitPendingRefresh`. That would mean all flow /state management is around the engine and you don't have to go through engine code to see how things work. This is of course subjective, so just a suggestion.
wondering if we should enforce immutability on this level... feels more natural to do it in the build()
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
can we swap member and constant we know the constant is not null :)
ok can we rename the getter then to `getFailedNodeExceptions()`
can we use getters here like `getNode` `isCanceled`
same here these strings are only used in one place just use them directly and trash the Fields class
should be `'norms': True`
so we can assert _that_ we can still use it
I guess it could be renamed to isFalse() / isTrue() now
This should be `Type.FS.match(` instead of `Type.FS.name().equals`
just use `Collections.unmodifiableList()`
Having limitless extensibility is not a good thing... as a plugin developer, I want to know what I can and cannot do... what I can extend. Otherwise I can easily do something I really shouldn't, break something along the way, without even knowing I broke it. Having well defined extension points and effectively limiting the extensibility of es in general: - helps us make sure plugins cannot break things (as they'll be restricted to what we allow them to do) - helps the users know what they can do and rest assured that they're not doing something they're not supposed to So overall, personally I'm less concerned about not capturing all the extension points at first run.. I'm more concerned about first capturing control over it. Then we can start opening up extension points as we see fit in a controlled manner.
I'd expect this to be in a synchronized block
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
we should probably bail here. One nit pick - I would prefer having this rejection logic closer to where it holds. I think there is only one method that can cause this.
+1 on just `field`
is this a pattern or just a separator? wondering about naming
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
oh right sorry I had missed it's a single value for these processors. sounds good.
java 8 FTW
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
you could remove the null check by changing the second check to `Defaults.NAME.equals(parser.currentName())`
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
"joined the cluster back" -> "rejoined the cluster"
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
Does it even have to be a map? It feels like a set would do just fine here.
Does it matter whether it went from above the high watermark to normal or above the low to normal? Could you get away with just storing a single Map? I figure that'd be simpler.
can we turn it around and do `if (usage != null)`
Heads up when you merge with master, I just merged another test where the original test query is modified assuming it is json, so that will need the same treatment as you do here I thinkg: https://github.com/elastic/elasticsearch/pull/14255/files#diff-9dc314365d49d84bff0645c2f9dfd7adR356 (and Overwrites in HasChild/HasParentQueryBuilderTests)
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
should we here or in the superclass fail if the cluster has not fully upgraded to 2.3? just as a safety guard I think that would be a good check in several places otherwise I can see us debugging weird issues `DiscoveryNodes#smallestNonClientNodeVersion()` has a neat method to check.
You can get away with it right now because there is only one test, but this should be initialized once before the test suite, not once before each test in the suite.
It defaults to `false`. :)
same as above, function name says nothing about what it does.
This constructor doesn't seem to be necessary.
can we add something to indicate where this comes from? something like unexpected error while processing cluster state version [{}]
getDelayCalculationTimestampInNanos -> getLastComputedLeftDelayNanos
Oh, got confused , which is the point :) getDelayCalculationTimestampInNanos -> getUnassignedTimeInNanos
oh hahahah, I can't read, that's an L
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I don't know how often this is called, depending on this maybe it makes sense to store the formatter somewhere for later reuse unless `format` changes? Is only called a few times maybe not worth the trouble.
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
Is it a problem if we just track a non-existing file? To me this looks like this is already broken for NativeFSLockFactory, because this one may reuse already created lock files (the existence of lock file does not mean its locked). So we can just record here "there may be a lock file to track".
I do not think we should log here. This is on the reload of a file and not an update to the ciphers settings
Nevermind, I just noticed this is required for bw compatibility.
It seems to me like this class would be simpler if headers were always not null (and just empty in case there is no header).
I think you want ToXContentObject here.
can you explain why we do this now only if `autoCreateIndex.needToCheck()`
this code block is repeated and always deals with index requests I think. We can probably factor it out to a method.
can we do: ``` Java if (addFailureIfIndexIsClosed(updateRequest.index(), updateRequest.type(), updateRequest.id(), bulkRequest, responses, i)) { continue; } ```
You can use end instead of `out.position()` here.
`limitedTo(long bytes)`? Clone is kinda non-specific.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
do we need this? it's like the base class (as we never have a cause)
I think 5xx (server error) is worst than 4xx, but let's just go with the first.
OK for now, but I guaranteed someone will use this and be surprised. But sure, we can wait.
I think you forgot to add the name of the script here to the failure log
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
Maybe replace these with writeOptionalString as well while you are at it
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
I'm fine with `IllegalArgumentException`, in all the places of course. :smile:
then check for non null here...
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
I think a nicer approach (can be a follow-up done by me) would be not to call `updateGlobalCheckpointOnReplica` here, but instead call ``` globalCheckpointTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED); ``` either here or in the IndexShard constructor (where we create the GlobalCheckpointTracker) when the recovery source is EMPTY_STORE.
I would prefer not to call `updateGlobalCheckpointOnReplica` on the `GlobalCheckpointTracker` if the shard is a blessed primary. A shard that's created from snapshot / local_store / local_shards is by definition blessed from the master. It should just activate the tracker. The activation logic for a replica can be different than for a primary.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
cool thanks for the explanation!
Besides jokes I see your point on NoOp naming, let's leave empty then, it doesn't convince me 100% but I cannot come up with a better name
yes please I haven't seen them used before in our codebase. At some point we will automate formatting and these classes will have to somehow be ignored I think.
And it looks like you cover the response below. So you can ignore this.
I wonder if it'd be nice to have the assertion in the docs with a note about how this is the response. And maybe a note that you don't have to assert anything if you don't care whether or not it was created up updated because non-200s throw exceptions.
you should run `gradle precommit`
please use Arrays.asList while we re here
I think you want ToXContentObject here.
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
Nit: `added [{}] the` -> `added [{}] to the`
Nit: this does not need to be on a separate line
Nit: there is an extra space after the `&&` and before `inSyncLocalCheckpoints`
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
Again, need to figure out what to do if ATOMIC_MOVE is not supported
Someday we're really going to have to standardize on American "canceled" or British/Australian "cancelled"... :)
I am not sure if we should catch an exception here IMO the exception should bubble up
maybe `== false` just so we don't typo it in the future
yeah that is true. nevermind then
can we add that to ClusterStateCreationUtils? It might be useful for others as well
check listener.isDone() as we don't expect a retry here I think
after rebase you will have to get rid of any wildcard import, or the build fails :)
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Now I wonder if you should make readFrom/writeTo final and make an abstract method that is just responsible for reading the response. That pattern was used by the query builders until they switched to constructor based reading and it seems fairly a appropriate. I don't think it should block the PR though. It isn't really important I think.
this can be removed now, no? it will be cause a duplicate with the full cluster state log..
scrap the method, but the block (saw the listener call now).
can we add something to indicate where this comes from? something like unexpected error while processing cluster state version [{}]
Nit: I think it'd be better for the message to read: ```[move_allocation] can't move abc123 from node1 to node2: node1 is not a data node``` (NB less punctuation, and no need to say `since its not allowed`)
Could you wrap these lines to <120 characters? We're trying to cut down on overlong lines.
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
can we move this in a sep method and make this `private boolean balance()` only have a single return statement, all these returns are hard to read
add space between `if` and `(` (in other places as well)
I think the following if is not valid anymore in fromXContent: ``` MatchQuery.Type type = MatchQuery.Type.BOOLEAN; if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_FIELD)) { type = MatchQuery.Type.PHRASE; } else if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_PREFIX_FIELD)) { type = MatchQuery.Type.PHRASE_PREFIX; } ```
this would allow to remove the two parse fields above I think
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
`assertNoFailures` is more common in newer tests and much shorter.
I like `hasSize(1)` for this kind of thing because it makes a nicer error message.
Since you don't care about the body of the source maybe use something like `setSource("foo", "bar")`.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
Is there a reason these three fields need to be test instance members be randomized in the init() method? Otherwise I would prfer making them local in createTestIntstance().
Lol - I spent some cycles trying to figure out how the hell we know this won't throw an index out of bounds exception, only to end up learning something about the BitSet api - it's funky ;)
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
I will take care of this.
this is same as what we do in term query. We randomly choose a value depending on the type. We might choose the mapped field for that value type, or just pick an unmapped field for it.
Got it, sorry didn't fully realize how value is initialized in any case before. So scratch this remark.
_value is only for agg scripts, we shouldn't have it for anything else
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
If the constructor is modified, this method won't be needed anymore.
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
3 more indentation issues above
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
can we call this log: ``` received a cluster state from a different master then the current one, ignoring (received {}, current {}) ``` also note that disco nodes already have [] in their toString.
is it really possible that we receive join requests if `ZenDiscover#doStart()` hasn't been completed yet? this feels odd to me
`them` -> `them;`
I think this needs to be `Version.V_6_0_0_alpha3` now.
Just discussed it with Robert and indeed this fsync is not necessary.
just fix a number, I don't think randomizing this adds much.
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
can you check that you can reopen the translog and that you can at least read all operations that weren't trimmed? this should not result in a translog corruption.
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
could be a instance variable, as used in all tests
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
typo: optain -> obtain
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
is there a way to filter out the index metadata here? We just want the global metadata.
lets put this into a unit tests class
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
this should just throw IOEXception no need for a shadowing ConfigException
@talevy Can you extract this IOException change from the PR and commit this to the branch? I can then benefit from it in the geoip PR too.
Maybe replace `SearchContext` with `IndexSearcher` if we don't want to expose `SearchContext` in plugins.
I think it is fine: we only build one search context per request per shard.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
These are expected, even required when implementing `ActionListener`. Either we should create an `AbstractActionListener` that does this for us the same way we have a `AbstractRunnable` or we should add a permanent hack to allow this specific construct in `ActionListener` subclasses. The former seems like a better choice but it'd mean more work before we can get this merged.
I feel like we implement this pattern enough times that we should make a helper for it at some point. No need now, but at some point.
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
let's reference "1m", "5m" and "15m" directly
I believe we've been just using the string version of field instead of these lately.
Or we can let poorly formatted values pass through and throw exceptions at the end if values are missing, similar to how we do for queries
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
no need for `else` here
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
I guess it could be renamed to isFalse() / isTrue() now
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I don't believe this is only kept for BWC. You use this to parse `_source` above.
You indent this differently than the thing above it.
nit: some whitespaces around the operators etc... would be nice
Thanks, I probably read the test to quickly and missed the startArray() part. You are absolutely right, this is how I expected the test. Sorry for the noise.
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
can we add an assert to make sure that highlighterType != null here? it really should since we know that plain highlighter always returns true, but the assert would make it more explicit that it is expected
the == false is done on purpose to make these comparisons more explicit
missing t at the end of the method name
While I understand why passing `Plugin` here is safe, after thinking about it a bit, I think I prefer replacing the `Plugin plugin` with `String source` to give the flexibility to choose whether this logic should be applied on the Plugin itself (using `onModule` or `processModules`) or on a different `PreProcessModule` (that latter feels more natural to me)
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
3 more indentation issues above
Looks like there isn't an ExecutebleScript equivalent for search scripts anyway - ignore this.
can we use `== false`
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
I'm confused. The cluster state was already applied on the node, no? I don't understand the extra restriction here.
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
Ah! More like: ``` private static final ObjectParser<Parameter, Void> PARAMETER_PARSER = new ObjectParser<>("parameter", true, Parameter:true); static { PARAMETER_PARSER.declareBoolean(Parameter::setRequired, new ParseField("required"); } ``` And they you can call it like `PARAMETER_PARSER.parse(parser, null).isRequired()` like you have. That way we reuse the parser. It probably isn't a big deal, but it is what we do everywhere else so we may as well do it here.
I don't think this should have been changed
I you decide to go this route you should also remember to replace the reference equality checks (`this == ActiveShardCount.NONE`) by equals checks or by looking at value (`this.value == 0`).
we "special case" NONE here but not ONE, maybe it's simpler just to remove this method as well as the `validateValue` one and use `new ActiveShardCount(...)` in the two places it's currently used (and also ad ``` if (value < -2) { throw new IllegalArgumentException(...) } ``` to the constructor.
see text from other suggestion for empty primary allocation
if you make `MulticastChannel` generic and the listener as well you safe the hard cast in Shared... just like `Shared extends MulticastChannel<MultiListener>` ...just an idea...
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
it's really taste I guess so fine with me
right, its a mock.. then use `ClusterName.DEFAULT` and you need one less constant.
this should be an abstract class, not sure if we also need the `@Ignore` annotation.
I double checked and heard that `@Ignore` is needed as well, otherwise IntelliJ tries to run this test as well when running all tests from the IDE.
good point! I think we need to iterate over the filterFunctionBuilders and rewrite their corresponding filters
you are the man! that is awesome!!! that should just work. I really wonder if we can build a BWC test index with a percolator that ensures we can read this stuff if would be awesome to have asuch a test
looks like it can be final
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Oh, I think I see why, it's for closing. I think it's still to pass in a search and close it on exception as you did now.
The caller should continue consuming the snapshot until the `next` method returns null. In the last call, lastSeenSeqNo equals to toSeqNo and op is null. This guard is added to avoid checking in this case. I am +1 on the assertion.
@bleskes I moved this to `next` but we also need to dudup for nested docs then I moved this to `readDocAsOp` again. I think we should optimize for nested docs. I am open to suggestions here.
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
I wonder if `PARSER.declareString((b, v) -> b.sortMode(SortMode.fromString(b), SORTMODE_FIELD);` is better? I kind of prefer it because then you don't need to think about `ValueType`.
Same deal here, it'd be cool if there was a static `parser` method or `PARSER` member that we could use as a parser here.
Maybe update, looks good to me now.
Can you switch this around and use the preferred name as first constructor argument? This way it looks like there's something special with this field, which I guess its not.
I'm not sure if this might be a case where both names are allowed, at least the doc state both version, not mentioning any deprecation.
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
you can omit `ElasticsearchException` here it's unchecked
That assumes `list` can't contain null..if that is not the case ignore
this case got lost
add space after `//`
space missing between `)` and `{`
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
since you are returning the script, I think this can just be called `extractConditional`
I think that we can save the instanceof checks, builder.value(Object) does it already
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
cool can you update the title of the PR then? :)
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
Maybe you could put the validation removed from toCContent here. (point.size > 0)
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
Same here, this it the field type tokenized flag, no? Not sure if this matters.
Can you make this `== false`? It took me a second to see the `!` :)
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
Sorry, I overlooked the null check. This is good!
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I'd prefer to have a simple `assertEquals` and to a String comparison here. No need for all the constants either, makes it harder to read IMHO.
Good point, I forgot about the pretty printing. `equalToIgnoringWhiteSpace` sounds good.
I'd recommend using the same syntax Lucene does: ``` bq.clauses().iterator().next().getQuery() ``` Just to follow their conventions
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
I think it should either be an `else if` or the `if` should be on the next line.
Clearing the current publication could be a method on the publication, avoiding the `thisPublication` malarky. The only other use is to call `toString()`.
I know this is for concurrency reasons. Just wondering: Would it make sense to move the update of the term under the mutex? In that case, this condition would not need to be checked here.
Not 100% sure of the rules here, but `private` seems too restricted for this.
Unused import here (not really a big deal)
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
Shouldn't this be using `ElasticsearchTestCase.randomFrom` instead of `com.carrotsearch.ant.tasks.junit4.dependencies.com.carrotsearch.randomizedtesting.generators.RandomPicks.randomFrom`? I don't want it to end up not using the right seed
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
This method is not necessary. With the code as is, we would be extracting the entire zip, but only using the one directory from it. Instead, we should do checks when extracting, see the `unzip` method. There we can have a prefix check like: ``` if (entry.getName().startsWith("elasticsearch/") == false) { // only extract the elasticsearch directory continue; } Path targetFile = target.resolve(entry.getName().substring("elasticsearch/".size())); ``` This will unzip everything in the `elasticsearch` directory directly into the temp installation directory, and all the other plugin cli installation code can work as-is.
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
If they are different then mlockall will not really work on unix either. That is because it may map additional stuff later!
@gmarz @kimchy but it is okay for them to be different simply because we allow it :) The worse case is that we kill starting with MinHeap (growing to max immediately) instead of otherwise the worse case being mlockall'ing too little.
Can we just add max(HeapInit, HeapMax) feels like a quick win here.
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
I think we can omit catching this and failing when caught, that's default behaviour, what matters if the `finally` I guess
same as above, this seems the same method as before
++ . nit: add the state to the message please.
++, one less releasable to remember to free.
same here re enumSet.toString
I see that there is already a rest test, great!
foo all switch statements in those tests, I think it would be less error-prone if we fail() in the default case? (not as much for now as for when we'll modify these tests)
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
I'm on the fence as to whether we should only do this on non-realtime get. Real time gets don't really relate to refresh cycles (they force a refresh if needed). They are already "efficient" in the sense that they only refresh if they need to (i.e., there's a pending doc change in the version map).
should remove the "force:[{}]" in trace logger. @s1monw
I wonder if this case distinction should be part of ReplicatedOperation.
nit: space after IOException
braces please. for the rest of the method too. (I realize you just tweaked this to be a lambda but it would be good to fix this as two line single statement `if`s are dangerous and evil).
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
As we never expect a null value to be passed as parameter to this internal method, I'm not a fan of sprinkling this check here. This is defensive programming at its worst.
nit: `== false`
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
no need for `else` here: ``` java if (numPredictions < 1) { throw new IllegalArgumentException("numPredictions may not be less than 1."); } if (numPredictions == 1) { predictions[0] = next(values); return predictions; } ```
the `numPredications < 1` check feels like an assertion... should probably be the first statement in the method
I mean in the code but just noticed there was one already
And i just did not have the time to yet yesterday remove the stupid asserts from SpanScorer. Please, lets not drag this stuff in again. If oyu want to push fine, but you will see a second push from me removing all this crap.
Why do we need the copy-paste at all? This whole thing seems like a code duplication of PayloadTermQuery.
would be great if this logic could be unit tested.
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
64e5c25 added support for this.
It might also depend on which implementation of `AcknowledgedResponse` you are using, since we have two, yay duplication!!! You should have a look at `StartRollupJobResponse`, which is an example of changing the word from `acknowledged` to `started`. this should get you on the right track.
I think that will fail compilation? ð
Oh, never mind, I misread. Sorry for that. ð
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
++ for ordinal and tests then
I wonder if you can remove the `Response` type parameter here too!
either way that's fine
I am fine with doing it in a follow-up PR if that works better for you
don't try to fix it, you just moved code around, but this catch block worries me :(
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
You didn't introduce it, but seeing this line again reminds me that this is buggy if Long.compare returns Integer.MIN_VALUE, which is legal :) So it should rather be `Long.compare(o2.getDocCount(), o1.getDocCount())` (without the minus sign)
actually I don't fully understand why we can't just do `this.order = order` all the time
Can you throw something else? It just makes me uncomfortable to throw AssertionError.
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
this can be out of if now.
can we add some randomization here around the version - check that new has a higher version then old and vice versa
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
did you run into this being a problem? how can we open an index that was created before 5.0.0 and never had insync replicas but does have allocationId? the only thing I can think of is a node network issue during shard initialization. I'm wondering if we need to optimize for this and no keep this code simple (i.e., demote shards with a lock exception)
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
A better wording for the error is: `[from] can't be negative` Changing that will require updating tests
I'm wondering that maybe we should not expose SearchAfterBuilder at all to the client API and make it internal to SearchSourceBuilder? So SearchSourceBuilder would still hold a SearchAfterBuilder instance, but the two above methods would look like: ``` java public Object[] searchAfter() { return searchAfterBuilder.getSortValues(); } public SearchSourceBuilder searchAfter(Object[] values) { this.searchAfterBuilder = new SearchAfterBuilder(values); return this; } ```
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
whoops I read it backwards, so yeah, not really necessary
Perhaps add the duplicate size to the assert message here
I think that inserting random fields here would reveal problems on the parsing side with the current code.
what happens if there is no mapper? I would tend to simply ignore (to match the logic we have for stored fields now)
Can you test something that is not byte-aligned, like /15 or /17? We used to have bugs in those cases.
this could be a for each loop instead
I am surprised that we don't have a default impl for this :)
The `new HashSet<>()` can be replaced with `Collections.emptySet()` (and then you'll have an import to remove).
It'd be nice to be sure it contained that `not_found` wasn't found.
same here with awaitBusy
are those number randomizable ie `randomIntBetween(1,100)`
acceptDocs will be checked _before_ these bits are checked anyway
Fine with me.
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
here is a space missing before `EMPTY_FLAGS`
I had the same thought, but I guess the point is to properly validate things when they get set to the builder, so that non supported values will never be serialized. I assume that we do that already, otherwise we should.
So as far as I see is this is the crucial change in this PR? I was wondering if might have undesired effects that we allow more field value types to be serialized/deserialized than before by using `writeGenericValue`. What would happen for example when fieldValue is a GeoPoint. It would have caused the serialization to trip previously, now it will be okay (and I guess it might cause error later). I guess switching to `writeGenericValue` is a good tradeoff here but would like to hear your ideas about that.
It looks like you have proper ram usage stuff. Maybe it'd be simpler to refuse to expand the tree if it'd put the `bytesAllocated` above a certain size.
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
this class is also missing a hashCode impl.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
Oh I see it below, makes sense, `wrapper` just sounds like a noun instead of a flag
I know it was like that before, but we are here now. ð
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
I'm clearly not getting my point across. Please understand that multiple tests are run in the same jvm during jenkins!!!!!!!!!!!!
I wonder if we want to ban `new Random(int)` to make it harder for folks to do `new Random(System.currentTimeMillis)`. If so then `Randomness` is probably the right way to go. Otherwise I like `GOOD_FAST_HASH_SEED`.
Just to make it better, setting it here in clinit is not so ideal, because its not perfectly reproducible when multiple tests are run in the same jvm. you will still have perceived reproducibility issues vs jenkins if you go about it this way: because the random will be initialized _once_ and then we will run 8 test classes against it. then, when you later try to reproduce the one that failed, the sequence will be different (even though the initial value is the same), because the other tests are not also invoked. but if you do it this way, it at least allows "whole build" reproducibility, which is an improvement. That means e.g. if you nuke your local execution hints file and run 'gradle test -Dtests.seed=xxxxxx -Dtests.jvm=yyyyyy', it will match what jenkins did. But nobody does that.
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
I think filter and query can never be null here? not sure whether we should validate this here.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
one too many new line? :)
Can you `s/.execute().get()/.get()/`? I try to do that if I'm going to be touching the line.
do we really need so many tests? this is just about parsing? It can probably just have unit testing for this..
Thanks, I get the general idea now.
I don't see any implementations extending this at the moment, are there any plans to add some later? If this is just going to be a collection of static methods and ParseFields I'd suggest making this an interface.
Okay, can you briefly explain the (maybe future) relationship of the ShapeParser and the above GeoJsonParser class? Currently they both seem to mostly consist of a "static ShapeBuilder parse(XContentParser parser, GeoShapeFieldMapper shapeMapper)" method, don't have any state themselves but ShapeParser calls GeoJsonParser. It would be useful to understand where this is going.
nit: you might be able to save a few toString lines by extending ToXContentToBytes here. no big deal though
Writeable does that too but allows to have final fields and drop empty constructors
+1 on pulling this out, I'm sure this can be used in other places, although in many of the tests I'm thinking about right now we have NamedWriteable things under test, but only the copy method would need to be slightly different.
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
If the constructor is modified, this method won't be needed anymore.
It would be nice if this class was immutable, and this line shows why it isn't currently. This is how to make it immutable: ``` List<CompositeValuesSourceBuilder<?>> sources = new ArrayList<>(num); for (int i = 0; i < num; i++) { CompositeValuesSourceBuilder<?> builder = CompositeValuesSourceParserHelper.readFrom(in); sources.add(builder); } this.sources = Collections.unmodifableList(sources); ```
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
can we just pass the action to the `AsyncShardFetch` class instead of subclassing this seems so close, maybe the two actions can share a common interface
i think `== true` can be skipped
cool. lets look at it on another issue.
typo, all flies -> files
minor semantic difference: over [here](https://github.com/s1monw/elasticsearch/blob/fix_recovery_finalization/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java#L304) we throw the unwrapped corruption exception, not the remote version. I think we should do the same here and throw corruptIndexException
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
I assumed that there is no problem setting values and checking that the output of the conversion from high-level request to low-level request is the expected one. We don't validate etc. I would do only what is straight-forward.
ok fair enough...
this is not needed. createIndex automatically reroutes.
maybe make this variable final? just better indicate it will never change
yeah, that was what I meant
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
Question, do you think it would be helpful to copy the pattern we have elsewhere having a `*Safe` version of the functions? So something like: ``` java public Decision getDecisionSafe() { if (isDecisionTaken() == false) { throw new IllegalArgumentException("decision must have been taken in order to return decision"); } return decision; } ```
The `Coordinator` becomes leader in `joinHandler.test()` not in `handleJoinRequest`, and that's outside this mutex, so it's technically possible that it could become a candidate again before this synchronised block.
This definitely feels like overkill now the `JoinHelper` is mode-aware and its mode is in sync with the coordinator.
Should really ask for `toString()`s on these handlers too, although this adds noise.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
I think adding a constant somewhere for # makes sense. It may make sense to also add a constant for typed_keys, but I don't have a strong opinion on that.
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
Also, please annotate with `@IndexSettings Settings indexSettings`, there's nothing worse than `indexSettings` being renamed to `settings` at a later time and then not knowing which Settings it actually is.
`s/shadow replicas/shadow shards/`
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
Oh, never mind, I misread. Sorry for that. ð
I think that will fail compilation? ð
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
I was wondering if `getSuperset/SubsetSize` is part of the Bucket interface but not rendered via the Rest response, should we either add rendering of these values to the bucket response or remove it from the interface to get equivalent behaviour of functionality of the transport client with the high level rest client here? I think this can be done in a separate issue though, maybe its not needed at all.
I'm okay with the UnsupportedOperationException for now if we can track this question (whether we can reach consistency between the functionality the transport client provides via the SignificantTerms.Bucket interface with the rest response) in a separate issue
does this work? it works for percentiles, but with percentiles rank it's reversed
Also, since "recover" and "restore" are very similar and easy to confuse, I think it'd be nice if this were named "`recoverState`"
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
`expectedType.cast(e)` should remove the need for the unchecked suppression.
A blank line above and below. ð
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Nit: it isn't a jsonBuilder - it is whatever kind of xcontent was passed in. Nit: maybe only set prettyPrint if the original had it set? I don't know if you can tell though. Neither are a big deal.
do we need == true ? :)
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
a transformer and performer. Quite a guy :)
Typo "uncomitted" -> "uncommitted"
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
No, there are only two ways for sets/maps, because of how multibinder works. I think it is more confusing to have some things bound using a binder, and others with registration/settings. Classes that ES controls should be registered, and set. If there was a way to just not allow multiple multibinders to work I would say we should do that, but I don't think such a thing exists.
Also, we should really move this discussion to another issue. I think this PR is fine as is, this was just a suggestion for a follow up/thought.
Having limitless extensibility is not a good thing... as a plugin developer, I want to know what I can and cannot do... what I can extend. Otherwise I can easily do something I really shouldn't, break something along the way, without even knowing I broke it. Having well defined extension points and effectively limiting the extensibility of es in general: - helps us make sure plugins cannot break things (as they'll be restricted to what we allow them to do) - helps the users know what they can do and rest assured that they're not doing something they're not supposed to So overall, personally I'm less concerned about not capturing all the extension points at first run.. I'm more concerned about first capturing control over it. Then we can start opening up extension points as we see fit in a controlled manner.
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
This should be a `ConstructingObjectParser` so that the private empty ctr can be removed.
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
nit: I changed this on master to get the parser from AcknowledgedResponse using a new `generateParser` method that I introduced there on request of Baz. Maybe we could use the same here in the backport to make it match the version on master.
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
could be a instance variable, as used in all tests
why a single data node? If you need that, you can use `numDataNodes=1` instead
nit: space after `if`
This method seems like it could be in `JobConfigProvider`? Then we don't have to duplicate it between this action and the put-datafeed action.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
Maybe replace these with writeOptionalString as well while you are at it
I understand this is the oversight you've mentioned
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
same here - pls refer to `current`
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
64e5c25 added support for this.
This can be `Files.notExist(...)`
I know this was copied over from another place, but I wonder if we should give preference to the recovering file. If I read this correctly , if we have both recovering and non-recovering, it is now random which one we choose.
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
can we use package private methods and have unit tests for this.. an integration seems like an overkill.
I suspect these will be too small and we'll have time outs.
I think we can clean up the http/transport/gatway settings here
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
also, at the moment we don't check for ids uniqueness, which is probably fine given what we need ids for, just double checking that we don't rely on uniqueness anywhere
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
> we still want to use an beta over an alpha There shouldn't be anything needing to choose a beta over an alpha? There should be nothing using any qualified build to check bwc.
I think that it's cleaner to write this as: ``` ElasticsearchParseException ex = (ElasticsearchParseException)ExceptionsHelper.unwrap(e, ElasticsearchParseException.class); assertNotNull(ex); assertThat(ex.getMessage(), equalTo("processor [test] doesn't support one or more provided configuration parameters [unused]")); ```
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
Do we really need to ignore the setting in post 2.0 indexes? Why not just support both for a while? You already check above that both aren't specified.
I _think_ we have a deprecation logger. We should probably log something when we see `position_offset_gap`.
We shouldn't need to log if we through an exception. I don't like the hard cutover but I can live with it. If I discount the hard cutover my only thing is the exception message.
If you want to test the multi-write behavior you could make a testing aggregation here that needs to be rewritten twice. I'm not sure how important that is to you, but it ought to be possible.
I'm wondering if the parent really helps define equality here? Additionally, by adding this we will do more checks than necessary given that we compare both sub-aggs and parent aggs
you should replace the curly bracket with a square bracket here.... :D
same here regarding nullable ..
We suppress and not report all errors which are OK. I don't think we need a special protection here about it.
Elasticsearch tradition is to make this an EMPTY constant :)
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
I think this needs to be `Version.V_6_0_0_alpha3` now.
Just discussed it with Robert and indeed this fsync is not necessary.
Why is this `volatile`? It doesn't look necessary to me.
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
And i just did not have the time to yet yesterday remove the stupid asserts from SpanScorer. Please, lets not drag this stuff in again. If oyu want to push fine, but you will see a second push from me removing all this crap.
Why do we need the copy-paste at all? This whole thing seems like a code duplication of PayloadTermQuery.
please wrap in {}
please wrap with `{}`
you have 140 chars use them :)
ok, then assert that it's either snapshot or generic threadpool
let's check this on every access, not only creation.
If you need this in test, you can still call it getBlobStore()
I think allowing this on a whole class is too broad. Is there a use case I'm not thinking of? I just figure it'd almost always be better to have it on a method or constructor.
> fail if the annotation was unnecessary Yeah, that is very important. It would be nice to be able to annotate at the exception level. Much cleaner if not for those nasty problems. I still think we shouldn't allow the annotation on classes at all and should force them to make a static method call if they want to swallow. But I'm not so against it that I'd block this whole PR over it.
Consider adding ``` static final NoAuthCredentials NONE = new NoAuthCredentials(); ``` and making the `NoAuthCredentials` `class` package protected (drop `public`). It may not be used enough to warrant having a `static` field hanging around though, but I liked what you did with the original `BasicAuthCredentials` and `EMPTY` before changing it a bit.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
then check for non null here...
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
I think this patch could work just fine? ``` DIFF diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java index 8a1df50..94a0ab1 100644 --- a/core/src/main/java/org/elasticsearch/node/Node.java +++ b/core/src/main/java/org/elasticsearch/node/Node.java @@ -98,6 +98,7 @@ import org.elasticsearch.search.SearchService; import org.elasticsearch.snapshots.SnapshotShardsService; import org.elasticsearch.snapshots.SnapshotsService; import org.elasticsearch.tasks.TaskResultsService; +import org.elasticsearch.threadpool.ExecutorBuilder; import org.elasticsearch.threadpool.ThreadPool; import org.elasticsearch.threadpool.ThreadPoolModule; import org.elasticsearch.transport.TransportService; @@ -210,12 +211,12 @@ public class Node implements Closeable { throw new IllegalStateException("Failed to created node environment", ex); } final NetworkService networkService = new NetworkService(settings); - final ThreadPool threadPool = new ThreadPool(settings); + final List<ExecutorBuilder<?>> executorBuilders = pluginsService.getExecutorBuilders(); + final ThreadPool threadPool = new ThreadPool(settings, executorBuilders.toArray(new ExecutorBuilder[0])); NamedWriteableRegistry namedWriteableRegistry = new NamedWriteableRegistry(); boolean success = false; try { - final MonitorService monitorService = new MonitorService(settings, nodeEnvironment, threadPool); ModulesBuilder modules = new ModulesBuilder(); modules.add(new Version.Module(version)); modules.add(new CircuitBreakerModule(settings)); @@ -223,6 +224,7 @@ public class Node implements Closeable { for (Module pluginModule : pluginsService.nodeModules()) { modules.add(pluginModule); } + final MonitorService monitorService = new MonitorService(settings, nodeEnvironment, threadPool); modules.add(new PluginsModule(pluginsService)); SettingsModule settingsModule = new SettingsModule(this.settings); modules.add(settingsModule); diff --git a/core/src/main/java/org/elasticsearch/plugins/Plugin.java b/core/src/main/java/org/elasticsearch/plugins/Plugin.java index 1efc151..695a255 100644 --- a/core/src/main/java/org/elasticsearch/plugins/Plugin.java +++ b/core/src/main/java/org/elasticsearch/plugins/Plugin.java @@ -23,9 +23,12 @@ import org.elasticsearch.common.component.LifecycleComponent; import org.elasticsearch.common.inject.Module; import org.elasticsearch.common.settings.Settings; import org.elasticsearch.index.IndexModule; +import org.elasticsearch.threadpool.ExecutorBuilder; +import org.elasticsearch.threadpool.ThreadPool; import java.util.Collection; import java.util.Collections; +import java.util.List; /** * An extension point allowing to plug in custom functionality. @@ -80,4 +83,8 @@ public abstract class Plugin { */ @Deprecated public final void onModule(IndexModule indexModule) {} + + public List<ExecutorBuilder<?>> getExecutorBuilders() { + return Collections.emptyList(); + } } diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java index f373da6..bb22854 100644 --- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java +++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java @@ -40,6 +40,7 @@ import org.elasticsearch.common.settings.Setting; import org.elasticsearch.common.settings.Setting.Property; import org.elasticsearch.common.settings.Settings; import org.elasticsearch.index.IndexModule; +import org.elasticsearch.threadpool.ExecutorBuilder; import java.io.IOException; import java.lang.reflect.InvocationTargetException; @@ -261,6 +262,14 @@ public class PluginsService extends AbstractComponent { return modules; } + public List<ExecutorBuilder<?>> getExecutorBuilders() { + ArrayList<ExecutorBuilder<?>> builders = new ArrayList<>(); + for (Tuple<PluginInfo, Plugin> plugin : plugins) { + builders.addAll(plugin.v2().getExecutorBuilders()); + } + return getExecutorBuilders(); + } + public Collection<Class<? extends LifecycleComponent>> nodeServices() { List<Class<? extends LifecycleComponent>> services = new ArrayList<>(); for (Tuple<PluginInfo, Plugin> plugin : plugins) { diff --git a/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java b/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java index 31f3f31..61e5141 100644 --- a/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java +++ b/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java @@ -30,7 +30,7 @@ import java.util.List; * * @param <U> the underlying type of the executor settings */ -abstract class ExecutorBuilder<U extends ExecutorBuilder.ExecutorSettings> { +public abstract class ExecutorBuilder<U extends ExecutorBuilder.ExecutorSettings> { private final String name; diff --git a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java index 0b564b2..1d641aa 100644 --- a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java +++ b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java @@ -151,7 +151,7 @@ public class ThreadPool extends AbstractLifecycleComponent<ThreadPool> { return Collections.unmodifiableCollection(builders.values()); } - public ThreadPool(Settings settings) { + public ThreadPool(Settings settings, ExecutorBuilder<?>... customBuilders) { super(settings); final Map<String, ExecutorBuilder> builders = new HashMap<>(); @@ -175,7 +175,13 @@ public class ThreadPool extends AbstractLifecycleComponent<ThreadPool> { builders.put(Names.FETCH_SHARD_STARTED, new ScalingExecutorBuilder(Names.FETCH_SHARD_STARTED, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5))); builders.put(Names.FORCE_MERGE, new FixedExecutorBuilder(settings, Names.FORCE_MERGE, 1, -1)); builders.put(Names.FETCH_SHARD_STORE, new ScalingExecutorBuilder(Names.FETCH_SHARD_STORE, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5))); - this.builders = builders; + for (ExecutorBuilder<?> builder : customBuilders) { + if (builders.containsKey(builder.name())) { + throw new IllegalArgumentException("builder with name: " + builder.name() + " already exists"); + } + builders.put(builder.name(), builder); + } + this.builders = Collections.unmodifiableMap(builders); assert Node.NODE_NAME_SETTING.exists(settings); threadContext = new ThreadContext(settings); @@ -190,10 +196,6 @@ public class ThreadPool extends AbstractLifecycleComponent<ThreadPool> { this.estimatedTimeThread.start(); } - void add(ExecutorBuilder builder) { - builders.put(builder.name(), builder); - } - @Override protected void doStart() { final Map<String, ExecutorHolder> executors = new HashMap<>(); ```
wondering whether it'd be better to just call the index `".ingest"`... it'll give us flexibility if we'll need to store other things later on aside from pipelines
I wonder if we want to add an `@After` rule that checks that all semaphore permits are back.
you also have this variant `org.elasticsearch.common.xcontent.XContentBuilder#timeValueField(java.lang.String, java.lang.String, long, java.util.concurrent.TimeUnit)` which you can use without changing TimeValue
newQueue -> newTombstone
If we use Collection<Tombstonre> we can return an unmodifiableCollection() which doesn't copy stuff..
As this setting should usually be only set once, it is probably simpler to leave it non-dynamic (as @jasontedor suggested and as it was before this PR). In case where this must absolutely be updated on a production cluster, rolling restart (of master nodes) with config update is always possible.
fancy pants :)
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
You can use `assertAcked()`
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
ok didn't know that. yet another bug fixed in master then it seems
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
you can use `assertAcked(prepareCreate(...))` here
I get that, I was just wondering why those default templates bother here
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
is this somewhere on a todo? I'm afraid we'll loose it
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
Since this is only going to be used in tests, I think we can get away with: ```suggestion return Objects.hash(maxSeqNo, localCheckpoint, globalCheckpoint); ```
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
I also think we should not catch the excep here.
Construction now loses the side effect of a `NullPointerException` when this class is misused by giving `null` values for everything except `sourcePath`, which could lead to new, unexpected `NullPointerException`s upon use.
Needs a guard.
Needs a guard.
Needs a guard.
which other queries do you mean? You mean check against this specific field in similar queries or just in general. I think the question is "when can this happen?". If stuff can happen in both java api and rest layer, validate is the way to go. If we already perform some kind of validation that makes sense in the parser, then having null here can happen only from the java api and we should maybe try and fail straight-away.
again, this is the reasoning: if we check for existence of a field in the parser, it means that the only way it can be null in the builder is when it comes in through java api. In that case we might want to fail fast and throw error in the constructor/setter already rather than in validate. If non validated values might come in through the parser as well then validate is the way to go. In this case it makes to do as Christoph suggested. In term query builder I think it still makes sense what we do (again, you can test it to see the differences), same for common terms query.
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
this deserves a sep issue I guess but good catch
do we need ordered things? does order help anywhere? If not I would just use HashMap
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
I think we should remove this method and insist on using the setScoreMode(QueryRescoreMode) method instead. This will make the API cleaner as only the permitted values (the ones in the enum) can be used. The parser can then use the fromString() method to convert REST request values to the enum but Java API users will have the safety of the enum
Nit: I think you can leave out ESTestCase here.
I think we should remove this method and the ignoreMalformed() method and instead have a validationMethod() method here instead
could be a instance variable, as used in all tests
I'm pretty sure this just throws an AssertionError so it wouldn't work either. I don't suspect it'd be very likely and I think the test would fail spectacularly on an InterruptedException anyway, so maybe just log an error? You could also make some list outside the runnable to accumulate the result. I bet we have some useful thing sitting around for this if you wanted to do more than log though.
Got it. LGTM
Missing the `indexName` argument to the debug log here
typo here "ot" -> "to"
`FutureUtils.cancel` has a check for a null future, no need to add this check
Wherever makes the most sense really. In this case I would put the default constants in `DirectSpellcheckerSettings` I think
nit: IMO `suggestMode must not be null` sounds more explicit.
nit: `accuracy` instead of `Accuracy`
This potentially overflows. I mean it's ok for our purposes (it overflows deterministically) but a sufficiently powerful linter would complain. Suggest `^` instead of `+`.
this is not needed. createIndex automatically reroutes.
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
maybe just call this `public BytesReference materializeAndClose() throws IOException` and don't even return the stream.
lets keep this class here and make it pkg private and final. it's very special
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
it makes it too easy to call delete when its not necessary.
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
nit: s/read blob's/read the blob's
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
For backporting to 6.3, I think this needs to be changed to 7.
Strings.EMPTY_ARRAY could be used too (if you want)
same here - I think it's better to log the info message if the deletion was successful.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
and.. looking at the parsing logic this is indeed internal and we don't accept none from strings. Sorry for the noise.
@clintongormley mentioned that NONE doesn't have many external usages (we only use it for index auto creation) so we might want to drop the special naming and use `0`. I will keep the object reuse in parsing.
Man this feels like a mess compared to ObjectParser. We can't do anything about it in the middle of this PR though. Just makes me sad.
can you throw an exception here too? I'm worried of users providing the partition numbers as strings, which would be ignored
so `round` should be called once per factory instead of once per aggregator
We can't safely say that all such exceptions will extend `ElasticsearchException` (e.g., a bad `NullPointerException`), but I like your idea of wrapping the ones that do not extend (as long as it's not wrapping it in an exception that sounds like the user can do something about it).
> Would using `ExceptionsHelper#convertToElastic(...)` helper method in `ConfigurationUtils#newConfigurationException(...)` or similar here be sufficient? +1
Please don't lose the original exception. It's already difficult enough to debug script exceptions without them being swallowed.
3 more indentation issues above
You are throwing away the stack trace here. Just have this method throw Exception, and the tests that call it as well.
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
oh sure, thanks for clarifying...
NIT: Noisy reformatting
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
From the top of my head I think you can leave this out as well
I think the message should be "security manager is disabled", because the assume would only print the message and ignore test if the security manager is disabled.
I get that, I was just wondering why those default templates bother here
I honestly don't get it... the way I look at it, we moved from having the `env` "polluting" the `Factory` interface to having it now "pollute" the `Factory.Provider`... why don't we just either wire the concrete factories into a map binder, or, if we don't want to wire them, see if we can pass in the Env. directly to the Module ctor (just like it can accept `Settings`)
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
hmm why did you remove the mapping from here? I think that was a good change? you should add the settings from from `public Settings indexSettings()` are only used if you use `prepareCreate` so you should add the settings to the versionSettings below. other than that it looks awesome
Maybe call this "testEmptyBoolSubclausesMatchAll()"? Sorry if I misunderstood what the test is doing, I just think having a github issue number in the name is unhelpful to someone if they see a failure.
... so that this doesn't need the `{credentials}` parameter in the URL ...
In these cases its acceptable to use randomize testing's `rarely()` or its like to cover either branch randomly.
I really dislike this style of variable reuse in our tests. If I use my IDE to navigate to the definition of this variable I end up on a line assigning a value to this variable that is removed from its current value. This hinders readability, especially in longer tests. Letâs avoid introducing it here, we should be moving away from it.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
The indentation is off here and the rest of the way through this test.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
can we make this getAgeInMillis and do the conversions here? we make use of millis everywhere so it will make for an easier to work with api. The nanos resolution is not guaranteed anyway.
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
nit: "so we assume"...
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
Please fix identation.
One option might be for this class to hold the already serialised form of the exception, but I'm not sure if that is better or worse than the current solution
512 \* 1024 :tongue:
You can't create the thread here, it should be created in `start` (you can't start again a closed thread). It should also be set to be daemon, and it should have a name as well. Check EstimatedTimeThread in ThreadPool for an example.
I suggest adding a volatile flag called `running`, add a method called `stop` that sets it to `false` and interrupts the thread.
s/y ou/you Also I think upfront is one word.
Maybe rename `myself` this to _local_ like in `network.host` setting? At some point we should support port ranges too, but it can be done in a follow up PR.
This test should assert that the headers are correct.
Can we have a small note on what this test does? link is good but description is better. Same thing with method name: `testNoRegionReturnsEmptyList` or something like that
hmm why did you remove the mapping from here? I think that was a good change? you should add the settings from from `public Settings indexSettings()` are only used if you use `prepareCreate` so you should add the settings to the versionSettings below. other than that it looks awesome
Is this necessary? I think that the cluster should know it only has one master node and sets this accordingly.
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
Another `_` java 9 will be mad at
This is logic that I think should go into ReplicatedOperation.
what changed here? I can't spot the difference compared to before
Probably for another PR since it's unrelated but I wonder if `scriptable`, `formattable` and `timezoneAware` should be properties of the Builder object rather than/ as well as the parser so the builder can ensure an IllegalArgumentException is thrown if e.g. an unscriptable agg has the script method called on it? /cc @jpountz
I think some of them could be private
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
I think it is fine: we only build one search context per request per shard.
Nit: `findHostName` -> `getHostName`
just initialize it and make it final - it just compliicates the code
can we just throw ElasticsearchException since it has the HTTP code baked in and it's also a RT exception
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
class could be `final`
I like this style. I think I'm going to steal it.
I dont have a good answer for this yet. While we can totally test this, the value in the server -> client.fromXContent is greater than just testing the client.toXContent -> client.fromXContent. I think these kinds of tests are not really providing much value, and we also test the former in the IT tests.
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
I suspect that some aggregations could be grouped under the same parsed aggregation implementation, so we won't really have a 1-1 relationship between the internal agg and the parsed agg. Like an aggregation of type "sum" (ie InternalSum) and "min" (ie InternalMin) can be parsed back using a same `LongSingleValueParsedAggregation`. In definitive I'm not sure we should add the getType() here or also in the Aggregation interface.
this curly bracket should be on the previous line
No, you are right, I didn't realize the need for api users before going through the whole changes.
you are perfectly right Christoph, let's merge the two and keep the existing class.
Should there be sanity checks that you cannot resume a watcher that is already running (so that the watcher doesn't run twice).
maybe in a followup we can think about removing these -1s... see what platforms fail, and better fine-grain the stuff (e.g. add assumption for WINDOWS, IBM jdk, whatever it might be). Then we know when and where stats are available.
@jtibshirani is correct
Wow, you are totally right, I see that now :)
the XContent here does not match what you removed in the REST API. There was a bit about early termination, as well as count that you need to include. You likely need to also include the begin/end calls, or else this will fail tests. You can check the tests with `./gradlew :server:check` from the base of the checkout. If tests dont fail then we need some better tests around the response hehe
spaces between commas
I see some places where null is not protected against...
for readability I'd use this. as well
Elasticsearch tradition is to make this an EMPTY constant :)
Conversion to bytesref is done elsewhere with `indexedValueForSearch`. I'm unsure of the impact of rejecting anything but bytesrefs.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
oh boy :)
++, the only thing is I would even go with a Map<String,String> if that works. not sure what you and Nik think about that.
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
nit: updates -> update
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
we can't change the format of the response at this time. We can at some point, but for now we just have to parse what we have, and figure out what we should do to make things better for the future, meaning potentially breaking changes etc.
Compared to our other parsing code this is a little weird because it doesn't know what field it is parsing up front. I get why you do this, but it is weird. Also it is weird because we don't serialize all that much information. You get almost nothing if there isn't an error.
I've dug some more. This is caused by us running the tests with the built in gradle test runner rather than the randomized runner. We configure the randomized runner to run with the system properties but we don't ever configure the standard runner.
When I pulled this locally and reverted the changes to this file I didn't have any trouble. We've traditionally been very weary of making changes to this file so I'd really like to make sure we need this before we do it, even if it is temporary.
And some more: this is not caused by the build compare plugin. Maybe by gradle 4.8 or maybe by one of our hacks to make 4.8 work.
Please no `null` for no change needed, returning `Function.identity` is clear, and there is no need to make an optimization check.
we can maybe use similar technique as we do in `QueryParsingException` and also report the location
@return needs to go into new line..
Think it'd be good to keep the `translog stream is corrupted` string here unless there's a good reason to change it. It's useful to be able to search for exception messages when working on support cases, and this sort of change makes that technique less useful.
open reader doesn't need to check for <0 and throw an exception any more.
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
license header is broken here
++ for a checkedfunction
I guess you could make this a final class that takes a functional interface as its only parameter and runs it and you could still use lambdas for it. My instincts are that that is marginally better from a design standpoint (composition vs inheritance) and a little easier to read but I'm not sure.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
It'd be "more normal" to declare this as `Writeable` and use `readOptionalWriteable` and `writeOptionalWriteable`. You've done plenty in this PR so it can wait though!
can this be in try-with logic.... you are not closing this input stream at all
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
just call `parser.text()` instead of `parser.bytes().utf8ToString()` since it might be optimized under the hood
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
this whole block here looks pretty much the same in all invocations. Can we make this even simpler? Maybe create a method `createIndexAndWaitForActiveShards` in `MetaDataCreateIndexService`. I've implemented it here: https://github.com/ywelsch/elasticsearch/commit/6e67ecabbfa5cc2568c0c987401e3ea521c7a330
never mind, I saw them later on
using ActionListenerResponseHandler will simplify this lightly.
why is this method synced? I don't see a reason though...
I think we can now revert this change, `for` instead of `while`, 2 lines less? ;)
why do we need this toString() here? We run it right away and don't log it anywhere.
and 2 more occurrences below
too many shards already allocated to this node for index ...
too many shards [%d] allocated to this node, [%s=%d]
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
I think I would make a breaking change here. Let's drop support for the string value in the builder and add it to the breaking changes. The parser still supports `none` and `all` but the builder only accepts a query. Then the method below needs to pretty much be moved to the parser.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
nit: indenting should be only 4 extra spaces
Since we're moving that, we could inline this using turnary.
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
same here - just pass a new instance
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
I think you should pass the Result here. Maybe also add an assertion in the ctor that the result is either `Result.DELETED` or `Result.NOT_FOUND`.
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
I see it now - I think how you've got it now is the most right thing then.
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
Sorry you are right, we should be using ParsingException. That snippet was the pre-refactored version. The difference is that ParsingException does not need the SearchContext (not available on the coordinating node) and actually points to the location in the request for the error (the XContentLocation). Please use ParsingException in this PR since this is going to be parsed on the coordinating node
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
it makes it too easy to call delete when its not necessary.
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I don't believe this is only kept for BWC. You use this to parse `_source` above.
I guess it could be renamed to isFalse() / isTrue() now
So negative delays count delays? I figured they should count as not-delayed.
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
and do that in all other classes we do this for serialization in this pull request.
I don't get this part why do you change the way we read the `TranslogStats` here? can't this just be ``` Java translog = in.readOptionalStreamable(new TranslogStats()); suggest = new SuggestStats(); if (in.getVersion().onOrAfter(Version.V_1_2_0)) { suggest = in.readOptionalStreamable(suggest); } ```
I think consensus is to avoid build failures entirely whenever possible
I think you should pass the Result here. Maybe also add an assertion in the ctor that the result is either `Result.DELETED` or `Result.NOT_FOUND`.
I'd just leave the ternary operation there.
I think you can just blast the entire method in this case.
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
true. nevermind then
Good to read, but this more or less repeats what ParseFieldMatcher.match() already does. I think it just adds another stop on the road to the actual match-implementation, which is not even in ParseFieldMatcher but in the ParseField itself. I was thinking about simple shortening like `matcher.match(currentFieldName, PARSE_FIELD)`, but I think its fine the way it is right now in the PR, not worth going trough all the files again IMHO.
nit: reading all this makes me think if we could get parseContext.parseFieldMatcher() once with a shorter local name at the beginning and then shorten the lines here a bit. Just for readability. I know at this points it's probably some tedious search/replace action, just throwing this in as a thought.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
no need to be volatile anymore
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
this looks a bit odd of a toString() implementation as it's very much targeted towards that one logging call site. Maybe change it to be more generic.
ok fair enough I didn't try it :)
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
I would write this check as ``` if (shardRestoreStatus.state().completed() == false) { ``` and then add an assertion that `shardRestoreStatus.state() != SUCCESS` (as the shard should have been moved to started and the recovery source cleaned up at that point).
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
this can go back to boolean if we move back Settings to boolean too
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
make `Boolean` and only serialize when not null
nit: "an started" -> "a started"
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
I'd feel better if the `latch.countDown()` would be the first line in the catch block
err I guess you need to have failures added first so second...
Oops nevermind, I misread.
We need to check here if `ttl` read from translog is lower than 0, if so, then we actually don't have a value...
replace match here too
If the constructor is modified, this method won't be needed anymore.
One option might be for this class to hold the already serialised form of the exception, but I'm not sure if that is better or worse than the current solution
It would be nice to return a simple, non-empty structure here so that we test that aspect of the response parsing.
I think that we should have left an assertion here that the Java version is not JDK 11 (I think we will be able to remove this for JDK 11). I also think that this code should have been guarded by an if block checking that we are on JDK 10 and otherwise not add this permission.
No, it cannot be private, since it's used by `AttachmentProcessor` in the same package. That was the part that I was missing. I think its misleading.
I can push the change if you don't have it ready yet.
I think we should throw an exception when `id < 0`, which should never happen? (unless Bad Stuffâ¢)
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
can we call this last seen clusterState? it doesn't need to be volatile as it is changed under a lock.
can we use ReleasableLock and try with resources? (or a plain old synchronize :) )
can we add a check for whether we sent a diff? I want to avoid a potential infinite loop.
Can we do all of these things (stripping last char, backslash escape and quote escape) in one pass with a string builder? Right now 3 copies are made of the string.
`blocksmd.copyContext(trysmd);`? I know you use "context" to mean something and this might not be the right use of that word though.
Or `adapter.createStatementMetadata(blockctx, trysmd);` or `trysmd.substatement(blockctx);`.
Nit: too many newlines here
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
same - wdyt about a condition suffix/
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
can we name this `CompleteDiff` don't use simple please :)
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
Minor suggestion to make it clearer that we're not waiting for the write index not to exist: ```suggestion public static final String NAME = "check-not-write-index"; ```
Can we switch between the string and the millis representation fo the modified date using the `human` flag like the explain API already does? That way we can just have one `modified_date` field in the output? Also the parser will not need to worry about the string version in this case since the client it will never set the human flag
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
if we make such change, can we do it in a separate PR please? ;)
oh, multi-bucket comparisons are ready already? :)
missing fail :) use expectThrows instead
relativize can be tricky if paths have different roots. is siteFile really guaranteed to be absolute too? In lucene i coded this "minimal path" with the following idiom: ``` root = root.toAbsolutePath().normalize(); path = root.relativize(path.toAbsolutePath().normalize()); ```
watch out for manual path concatenations - / doesn't work on windows :)
Nitpicking but I wonder if we should just use the File's constructor for this use case: http://docs.oracle.com/javase/7/docs/api/java/io/File.html#File(java.io.File, java.lang.String)
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I don't know how often this is called, depending on this maybe it makes sense to store the formatter somewhere for later reuse unless `format` changes? Is only called a few times maybe not worth the trouble.
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
can we use org.elasticsearch.indices.recovery.RecoverySource.Actions#START_RECOVERY ? it's a better indication that the recovery is started.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
hm. so this hangs now every now and then for a minute. I think it is when the coordinating node is node_1. Then the cluster state observer waits for the next cluster state which does not come and the index request is only executed when the observer times out. We can send the request via node_2 but I think we actually need a way to handle this better.
maybe we should have a helper method for this? this looks used in several places
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
import not needed.
Not needed anymore.
Not needed anymore.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
`limitedTo(long bytes)`? Clone is kinda non-specific.
good catch on delta > 0
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
ok I remember now. The point of IndicesRequest and CompositeIndicesRequest is to return the indices that a request works against. when a request is composed of multiple operations, it should implement CompositeIndicesRequest. In this case delete by query reads from some indices as part of search, and writes as part of deletes. But what indices would it delete from? It is not possible to create a DeleteRequest that points to multiple indices, yet it is hard to predict all the deletions that will be performed as part of the request execution. I doubt that this request should implement CompositeIndicesRequest then.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
should we catch exceptions here to make sure we cancel everything we need
we need to remove this from onGoingRecoveries and only call cancel if it was found, otherwise we may leave a lingering recovery id, pointing at a cancelled recovery.
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
similar concern about modifying the value that is set
same should be done for minChildren and maxChildren too. Wondering now if it makes sense to move to `int` rather than `Integer` for all three fields
Full default value handling story here: https://github.com/elastic/dev/blob/master/design/queries/general-guidelines.md#default-handling
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
please return a Map instead no google guava stuff in public interfaces
I think this should throw IAE if you pass null - that's 100% of the time a bug
hopefully having a default for fuzziness makes it non optional and simplifies things slightly here too
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
I don't understand here what you mean by synthetic variable. If you mean the two ENulls, the analysis and writing would be contained to only compile-time.
Two test requests: What happens when you have something like `Integer a = Integer.valueOf(0); int b = a ?: 1;` `Integer a = Integer.valueOf(0); int b = a ?: Integer.valueOf(1);` I believe these are expected to be ClassCastExceptions where Integer cannot be cast to int, but I'd like to be sure.
@nik9000 Robert and I had a long conversation about boxing early during development. We decided to eliminate it as much as possible because of serious complications involving promotion and casting (which as you know is already very complicated). There's only a couple of places auto-boxing happens -- arguments to methods because it would be hard to force a user to cast something to an object to add to a list and with anything related to def type. Otherwise, there is no auto-boxing in painless. Perhaps, this should be the same for consistency? Sorry, I sort of missed this yesterday thinking about the cases, but def should work anyway already, otherwise primitives don't make sense here since we don't allow Integer to become an int anywhere else. With the def type we deemed auto-boxing to not be necessary anymore, and ideally something Java would've hidden from the user to begin with. It also happens that users can call boxed methods on unboxed types to further eliminate the need to ever have a boxed type.
nit: should be "commit_ting_ writer with commit data"
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
I dislike this idiom here, because if e.g. encoding is wrong it will silently replace with U+FFFD. Is this done anywhere else in the codebase? If so, maybe useful to have a method, that would e.g. set onMalformedInput/onUnmappableCharacter and so on.
This many levels of nesting hurts my head! How about refactoring the inner half into a private `findShardIds(@Nullable String index, Path indexPath)` method so it's easier to read? I'm worried about the potential for future typos for anyone else touching this code
add a return method here just in case? I don't like this construct but can't think of how to improve it (all other options I see suck too)
yeah that is true. nevermind then
do we want to check listener.isDone? (because it is supposed to return immediately). get() waits.
not really important
Er - if you are going to log something then it doesn't matter which order you do it I guess.
same as above, this breaks bw comp for the java api
Okay, doesn't matter if the builder only outputs verbose version as long as we support the other one still.
We would need a call to super() somewhere here. Or, like we did with the query builders, have the superclass declare two abstract doEquals/doHashCode methods that it then calls and the subclasses need to implement.
Sorry, didn't see that, you're right.
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
why do you pass the response to this method? `this` already has all information.
I only mentioned it because if we really have to keep this, then StandardOpenOption.DELETE_ON_CLOSE could be an implementation. But this one has race conditions too, this delete-on-close stuff is why Lucene's lockfactories were buggy for years. Lets defer it to a new issue, ideally we just nuke it completely.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
hmm I see it's to opt out...
Extremely insignificant, but just for clarity: I think you mean "does" (indeed contain a fatal error) on this line.
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
`new AtomicReference<>();` with the extra `<>`.
is this needed? as far as I can tell, the implementation does nothing?: ``` try { if (lock != null) { <-- **lock is null** try { lock.release(); lock = null; } finally { clearLockHeld(path); } } } finally { IOUtils.close(channel); <-- channel is null channel = null; } ```
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
Perhaps add the duplicate size to the assert message here
whoops I read it backwards, so yeah, not really necessary
I expect to be tested as it's static, but I don't see test? I think its good to have one. Also, it seems it can be package private.
I think this is easier to understand as it makes a 1-1 copy of the current active shard allocations in the routing table: ``` for (IndexShardRoutingTable shardRoutings : indexRoutingTable) { Set<AllocationId> activeShards = shardRoutings.activeShards().stream() .map(shardRouting -> shardRouting.allocationId()) .filter(allocationId -> allocationId != null) .collect(Collectors.toSet()); if (activeShards.isEmpty() == false && activeShards.equals(indexMetaData.getActiveShards(shardRoutings.shardId().id())) == false) { // only update active allocation ids if there is an active shard if (indexMetaDataBuilder == null) { indexMetaDataBuilder = IndexMetaData.builder(indexMetaData); } indexMetaDataBuilder.setActiveAllocations(shardRoutings.shardId().id(), activeShards); } } ```
we typically just use string concat. I think we can just do "shards started [{}]"..
As @rjernst says, this is incredibly broken behavior. It invalidates all the work we did to reject unrecognized URL parameters, now it accepts any parameters including garbage parameters.
please use the root locale
also please use `== false` for comparison
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
this can be out of if now.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
same here regarding nullable ..
Elasticsearch tradition is to make this an EMPTY constant :)
We suppress and not report all errors which are OK. I don't think we need a special protection here about it.
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
Nit: spacing between the `)` and `{`: `){` -> `) {`
why do you pass the response to this method? `this` already has all information.
remove "or timing out".
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
`.addPathPartAsIs("_xpack", "rollup", "job")`
you can comma separate these instead... i know the likelihood of us not using `/` is low, but its best to not have them in this.
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
we can do this in a more optimize manner. We can create a builder, and then use `copyCurrentStructure` on the builder (passing it a parser), to just copy it over, compared with parsing into a map and then serializing the map. Also, since its internal, I would use smile builder, as its considerably more efficient than json.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
oh cool the read is in the ctor! nice!
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
I think this check comes too early. Templates have not been applied yet. I suggest doing this once IndexMetadata has been created.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
never mind, I saw them later on
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
The factory is what holds onto the params, so that they can be passed to the constructor. Think of the factory as the signature for the constructor. It's not boilerplate; it is actually needed based on current uses of scripts throughout the system. Also note that the factory signature is what allows the script instance to have arbitrary objects passed in. If `ScriptService.compile` were to return an instance directly, instead of a factory, we would need some way to pass in this information in a generic way, which would probably mean duck typing through a String->Object map and then require casts. With the factory, we get static type checking of the arguments a script needs to be constructed.
Maybe we could name the context (and the class) something more descriptive for it's purpose? While the rest api is for executing a script, I think this context is a generic test context? Perhaps it could be "painless_test" (and PainlessTestScript) or something like that? I like having "test" in there because it is clear this is not for production uses, but to test painless code. It would also be more clear for when we do support other contexts in the execute api.
`Arrays.asStream(response.pingResponses)` would not materialize it
I know this was copied over from another place, but I wonder if we should give preference to the recovering file. If I read this correctly , if we have both recovering and non-recovering, it is now random which one we choose.
You don't trust Files.move :)
Consider adding ``` static final NoAuthCredentials NONE = new NoAuthCredentials(); ``` and making the `NoAuthCredentials` `class` package protected (drop `public`). It may not be used enough to warrant having a `static` field hanging around though, but I liked what you did with the original `BasicAuthCredentials` and `EMPTY` before changing it a bit.
Extremely minor, but this could drop the `public abstract` part now as `interface` implies it.
Consider changing to `void applyAuthorization(URLConnection connection);` (and then changing the children to "apply" themselves there; the `EmptyAuthCredentials` would naturally be a no-op). This should help to avoid an N +/- 1 list of `if` statements in the `HttpDownloadHelper` as more types of `AuthCredentials` are naturally supported.
good catch on delta > 0
maybe we implement `Iterable<V>`
also this class should be final.
Ah, I see why this is a function ref - so that the `toString` generates the right method to invoke. That feels a little brittle but I understand what is up.
I'd remove the bitmask - it doesn't seem to add much value (see the previous method suggestions for implementing and); shorter and clearer than using bits.
make it final
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
maybe, to be more precise, it would be good to check the partition that included the new primary.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
cool thanks :)
Can we just keep it simple here and eagerly allocate the array to full size (and fill it completely) above? These should be small sizes (single digits). I don't think we need to optimize as if this array could be hundreds of elements.
`i` should be a long since `size()` returns a long
maybe we should just get rid of this local variable and write the next line: ``` nodesIds = filterNodeIds(clusterState.nodes(), resolveNodes(request, clusterState)); ```
I wonder if this should just be the implementation provided in `TransportReplicationAction`? It appears there are only two classes that currently provide a non-trivial implementation of this method.
s/The tasks has/In case the task has/
Not needed anymore.
Not needed anymore.
Same concern about reproducibility as in the other PR.
This part I like since it is growing based on the number of aggregator instances, which is not accounted today.
can we clean up the other try catch? it's not needed now (as we catch things here too)
This is missing a `+` between `newUsed` and `"/"`, so it's not compiling currently
same typo - copy paste probably
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
This message probably made sense once but it doesn't anymore. I'd suggest `Cannot update the job config because job...`
typo: optain -> obtain
I think this is expected to be a sorted list on the `job_id`.
I think it would be more flexible if the keys were objects? (you could have composite keys, etc.)
I'd prefer this to be `@Nullable` as well... relates to xcontent serialization
if we do make it nullable @colings86 we have to make sure some value gets provided as part of the `canExecuteScript` call, where the type is required to decide whether the script can be executed or not.
`Arrays.toString(paths)` already adds [] , no need to add them
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
i think `== true` can be skipped
can you undo all indentation changes, it adds noise to the diff
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
This predicate can be simplified to `(count, limit) -> count > limit`.
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
nit: extra line
same here with removing retry logic
same here with removing retry logic
same here, all retry logic should be removed
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
oh nevermind, I just found the method that called it with null :)
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
What if the user specifies 0 here? Previously that meant unbounded.
ok keep it then. I am not sure though what needs to be optional, if the client here, or the service in the parser service. I thought the former, not the latter.
Ok, didn't know about those...I guess keep for consistency...
I think this name should be IndexMetaDataUpgradeService? Otherwise it sounds like there is a "metadata index".
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
Nit: " . " -> ". "
Typo: "temporary" -> "temporarily"
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
just `for (IndexMetaData indexMetaData : state.metaData())`
this is not needed. createIndex automatically reroutes.
As well as the default buffer size
DEFAUTL -> DEFAULT again
Can probably just call this `INDEX_CONCURRENCY` instead of `INDEX_INDEX_CONCURRENCY`
It is to make sure that the version comparison logic orders alphas, betas, and RCs correctly.
add a whitespace after the if and before the parentheses
ie. when showTermDocCountError is true
I think conceptually this should be QueryParseContext instead, if it needs to do more (toQuery) then we need to figure out how to create the QueryShardContext too out of it, but the other way around seems confusing to me. Sorry I see we are going back and forth on this.
nevermind, I guess it depends on how you look at it. at the end of the day this parse method does parse + toQuery, having QueryShardContext is fine given that it will still happen on the shard. Also given that the QueryParseContext is much more lightweight, it makes more sense if done this way. Plus the parse method will go away, so leave it as-is.
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
if you use here `refresh();` from the base class we also make sure we get back no failures.
ensureSearchable is calling ensureGreen, so for that to be the same as waiting for shards on index creation, on the prepareCreate("index") call, we would have to setWaitForActiveShards(ActiveShardCount.ALL)
The method name implies yellow though. I bet there are places where we don't _need_ green.
Maybe we should just do the version bump? Technically we don't need to keep disc compatibility with the alphas so something like this isn't required but I like having it for history's sake. Maybe leave a note about what can go in 6, i.e. everything but size_field_type with doc values.
maybe add the type that is found in the error message with fieldType.typeName()
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
nit: there's already a `.translate()` method, so I would rename this to `translated` or `isTranslated`
++ you're right. Without reverting back to a member variable or unnecessarily implementing something I don't believe there is any thing else.
nitpick: it would be nice for the second clause to be aligned vertically with the clause above
typo: filers -> filters
I think we should stick with calling these getters like `getCharFilters` because it is the char filters that the plugin has, they aren't "extra" in the context of this one plugin.
All of the `*Plugin` interfaces we have added so far have used `get*`. I think we should be consistent.
count > 0? just being paranoid :)
Is this is necessary given we loop over OpType.values()? If other values are added in the future we should fail because expectedBulkItemResponse/originalBytes is not set anyway.
maxDepth can be final
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
why do we need this here? I think this entire `hashAndLengthEqual` can and has to go away
Strings.EMPTY_ARRAY could be used too (if you want)
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
I think it's fine to add such a method to NoCacheFilter
Just discussed it with Robert and indeed this fsync is not necessary.
+1 to not swallow the original exception
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
Maybe pass the `Executor` in to the ctor instead of `ThreadPool`? You could keep this method so you can still override it in tests to throw.
do we want to do something with is error? (not related to this change)
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
You could add an assert that it's not ES 7.x here so we know to remove it
nit: missing a space after the first comma
Please rework this word wrap too.
I'm not sure this logic is correct... fieldType is mutable right? We should compute a final boolean in the ctor if we need this instead.
Oh I see. I like it better the current way better then. I was confused by the fact that you could have both ALWAYS and PARTIAL in the same doc, maybe we could add an assertion that it never happers.
Can you make this `== false`? It took me a second to see the `!` :)
max_expansions may still be used along with fuzziness, so it may not be ok to deprecate. Can you double check? This is why splitting MatchQuery would help. It is hard to figure out what happens when.
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
can we make those two constructors call the 3rd one so that we can centralize validation (if we ever add some)
We should deal with rejections if the executor is closed.
I think that `node);` fits in the previous line
I think we use the empty string somewhere yes, not sure if that was a wise choice. I don't mind leaving null, no biggie
Since "version" and "primary" are used not only here, but below in the `fromXContent`, they may go better in a static `Fields` encapsulation so if they are changed in the future they only have to be changed in one place.
I'd probably write validate's results to a variable and reuse it.
This "_global" should be a static constant var.
I think we should complain if we don't find the header name.
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
can we add a note here why this is optional? the validate request suggests otherwise...
I see, it became a writable...
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
I see it now - I think how you've got it now is the most right thing then.
Again, I wouldn't pull out the ternary.
the == false is done on purpose to make these comparisons more explicit
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
can we add an assert to make sure that highlighterType != null here? it really should since we know that plain highlighter always returns true, but the assert would make it more explicit that it is expected
sorry I meant `org.elasticsearch.common.xcontent.ObjectParser` all the time my fault
+1 on using static strings - I didn't realize that the XContentStrings things are not usable when parsing.
this feels weird. I think this partially comes from the fact that the allocation id field name is serialized by this object. Instead I would change the toXContent of this one to start with startObject. Then in [ShardRouting](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/ShardRouting.java#L719) we can do: ``` if (allocationId() != null) { builder.field("allocation_id"); allocationId.toXContent(builder, params); } ```
I think this'd be more clear if you said something like "invokeStatic assumes that it is not invoking a method on an interface."
This should be `Type.FS.match(` instead of `Type.FS.name().equals`
wondering if we need recoveryState.isPeerRecovery() to simplify these lines.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
the generic thread pull should never reject, unless it's shut down. that's it's semantics. I would also vote for a trace log in the raiseNodeDisconnected, but that's another change :) It's just confusing imo if you shut down a cluster and see these messages.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
`engine failure` -> shard failure
wonder if we should make these Integer and Boolean just int and boolean primite types.
this would make sense especially given that their setters accept primitive types
From the discussion before I think that removing the special case for FuzzyQuery inside filter context is okay here since CONSTANT_SCORE_REWRITE ist the default MultiTermQuery rewrite method anyway. @jpountz could you have a look at this change since I think it's related to the filter/query merging.
I'm fine with `IllegalArgumentException`, in all the places of course. :smile:
then check for non null here...
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
I took a quick stab at sth. that avoids the Tuple and replacing the test builder [here](https://gist.github.com/cbuescher/88531fe7c2abd38936ef), but it still looks a little bit strange to me. EDIT: Doesn't work, equals-tests break with this little hack. Sorry, nevermind.
+1. Maybe this helper so far is limited to the query / suggester tests only, but then again it might be general enough for ESTestCase.
I believe this can be provided by overwriting EsTestCase#xContentRegistry().
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
I think filter and query can never be null here? not sure whether we should validate this here.
I think we can get rid of this field in the abstract class, as far as I see it can be "term", "completion" or "phrase", those should be the NamedWritable NAME constants in the subclasses, so the superclass won't need to store it anymore.
I'm not 100% familiar with suggesters at this point, but from looking at the docs, I think `name` here refers to some custom name for each suggest entry in the request (like "my-location-suggestion" etc..) and its used amongst other things to name the results in the response. The NamedWritable#getWritbaleName() should provide a unique name for the type of writable object. In this case I think the abstract class shouldn't implement this, but the three implementations (Suggest/Term/Completion) whould return how they are identified here.
Those two code snippets are very similar.. I think we should go more generic here, maybe you can add a static `XContentHelper.toString(ToXContent foo)` which acts like in the `SearchSourceBuilder` and does not throw an exception, but returns an error JSON ``` java @Override public String toString() { try { XContentBuilder builder = XContentFactory.contentBuilder(XContentType.JSON).prettyPrint(); toXContent(builder, ToXContent.EMPTY_PARAMS); return builder.string(); } catch (Exception e) { return "{ \"error\" : \"" + e.getMessage() + "\"}"; } } ``` There should be another `XContentHelper.toString(ToXContent foo, boolean wrapInObject)` method which adds the needed `builder.startObject()` and `builder.endObject` calls, if specified. With this change, both of this calls, would basically be one-liners. Hope it makes sense...
nit - we flush also it will reduce the size of uncommitted gens but strictly speaking it doesn't mean it will be below the threshold
can we extract the uncommitted gen from the `lastCommittedSegmentInfos`? Also uncommitted gen is confusing because the gen's id is in the commit point.
I'm not happy with the extra boolean flag to include / exclude the current generation as a fall back. It's too subtle an error prone. How about doing the following (I think you had it in the past and we moved away from it towards the uncommittedX api - sorry for that): 1) If the min gen for the local checkpoint + 1 is > current committed gen , return true. 2) If the min gen is equal to the *current* translog gen, the current gen is not empty (using `totalOperationsByMinGen`) and the local checkpoint is equal to the max seq#, return true.
I thought we said we would move this method to IndexQueryParseService so we can avoid exposing the Client.
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
`it's` -> `its`
`translogs` -> `translog's`
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
We will need stronger assertions here too.
there is a test helper method that can create plugin property files
I think that the both kinds of tests (verbose and non-verbose) should specify exactly what the output is. Note that as written the non-verbose tests would pass even if the production code was changed to always output the verbose output. So, the output would be wrong but the test would not fail.
@markharwood remember to take hash % copies# collisions into account. So if you see two shards being search on the same node, they should have the same hash modulo number of shard copies.
nit: can you use assertThat or expose the actual values in the message.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
can we name this maybe just `UpdateTask`
I think we should use `debug` for the logging here
please remove that blank line
Yeah, looking at it again, that makes sense!
What about just converting to bytes and comparing? The way you have it now this isn't consistent with `equals`.... Also the _cat API we call `toString` which doesn't really use the unit anyway.
similarly, equals uses the hash while hashCode doesn't
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
use ArrayList? one less usage for non standard code...
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I think it should either be an `else if` or the `if` should be on the next line.
indentation makes the `if` block a bit hard to read
we don't need a context in this test, these two lines can go away
you don't need do handle queryName yourself anymore, nor boost
we should add ClusterService and IndexNameExpressionResolver to IndexQueryParseService so they get injected. Then this method could pretty much be moved to INdexQueryParseService like this: ``` public boolean matchesIndices(String... indices) { final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices); for (String index : concreteIndices) { if (Regex.simpleMatch(index, this.index.name())) { return true; } } return false; } ``` QueryShardContext would need to expose the same methd and delegate the IndexQueryParseService
if we add a null check to the String constructor we can remote this check here given that the parser already looks for the existence of the field too.
Nit: in other places advancing the parser is directly done in the "ensureExpectedToken" call. Saves one line and I think it is equally readable. There's several places in this method where this might be possible, not sure how much lines this saves. Also, if you don't like it, just a matter of tase I think
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
Why not have the standard to string? A multiline return value is difficult to work with in a debugger...
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
same note as in the json processor PR.
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
You can get away with it right now because there is only one test, but this should be initialized once before the test suite, not once before each test in the suite.
Can you make this a JUnit assertion instead of a Java assertion? It's preferable to use a test assertion with matchers for this because then nice error messages are produced automatically when the assertion fails.
Since this is static, the name should be `THREAD_POOL`.
Besides jokes I see your point on NoOp naming, let's leave empty then, it doesn't convince me 100% but I cannot come up with a better name
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
cool thanks for the explanation!
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
Should we increase visibility in this case? Makes only sense if we can then really test more, though, otherwise okay to leave it I guess.
Then we should leave it, the situation in general improves here already.
Change "param required" to "parameters are required"
add a short method that checks the content type and get rid of the list? If this class becomes too big I am good with getting the bulk part out. some of this methods are going to be useful for msearch too at some point.
this code block is repeated and always deals with index requests I think. We can probably factor it out to a method.
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
just being over paranoid I think this class should be final
but why? :)
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
something is wrong in this sentence :)
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
On reflection I think this means we don't need `lastCommittedState` any more.
I believe `ScrollHelper.fetchAllByEntity` already wraps the listener in the client's `threadContext`.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
I don't believe this is only kept for BWC. You use this to parse `_source` above.
I don't think this is correct? Do tests pass? This should fail on unmapped fields.
Maybe better to use MapperService.isMetadataField since "_" is a valid prefix for a user field name.
Without much context to this code, it appears that `parameters` was likely meant to be sent as the first parameter to `newInstance`. The code here checks `script.getParams()` for null, but it does not check it downstream and could result in NPE if `script.params()` is ever null.
I'd move this to line above, but I like the thought behind the change.
Same deal as the last `toString`.
Same feedback as the last `toString` - I think you can remove `created` and might want to look at `Operation`'s `toString`.
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
You can use the diamond operator here.
You can use the diamond operator here.
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
I am sorry, I didn't think this through. The two sections have the same name, so the json wouldn't even be valid if they were both there. I think we should not check it explicitly, otherwise we would have to do it for every single field in our parsers, which we don't do. Relates to #19614
Do you think we could get away with making this an assertion instead? A plugin developer would hit it during testing.
I think that it can rather be empty, hence we always print out the array, which sounds ok to me. I think the null check can go away.
don't try to fix it, you just moved code around, but this catch block worries me :(
you can remove the validate call for now, we will fix all queries soon, I promise
you can just use `MultiFileds.getFields(index.createSearcher().getIndexReader());`
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
see above - I think you should add it though
This can be outside the try/catch right? If there is a failure to create the pipeline, there is no pipeline to close.
And regardless of if the parsing exception is important, if closing is necessary, failure to close should be added as suppressed exceptions to the parse failure.
But that means the pipeline can never be used again (it is now closed).
this should be `IOUtils.close(phase1Snapshot, () -> resources.remove(phase1Snapshot))'
I would execute the `IOUtils.close(resources);` in a finally block after we sent back the response or the other way around.
Typo, finalzlie -> finalize
I think you should remove the `!` here, throw exception if `failNoIndices` is `true`
I think we should mention the index, cause that is the useful bit (e.g. which index is closed), also because we never really hide the fact that users are using aliases (e.g. when indexing into an alias, the response will contain the concrete index as `_index`, not the alias).
hey @martijnvg I double checked with @clintongormley and we both think it's better to add the actual index that was closed, not the alias. Knowing that an alias is closed has little sense, better to report back which concrete index was closed.
good point I am curious too now :) I hadn't noticed this at first
`expectedType.cast(e)` should remove the need for the unchecked suppression.
with the recent changes, I think that you only need the filter above when testing with failures. here and in the other test.
I just think its weird to declare the field expects the value to be an int when actually we are also expecting string values that are not the exact string representation of an int (i.e. cannot be parsed using `Integer.valueOf(String)`). It took me a little while to work out how this worked when I reviewed it so personally I think its worth making the change for code readability.
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
This does not necessarily need to be within a static initialization block.
In these cases its acceptable to use randomize testing's `rarely()` or its like to cover either branch randomly.
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
This does not compile; `FakeRestRequest` does not have a constructor with two arguments. This is a recent change and I think you just missed it when you rebased.
I think this is a duplicate of `connect()` above (minus an assertion) although I prefer this name a bit.
Wasn't me, it was the tests :)
nit: can we move the look up of the primary to the callers that pass null? this method is hairy enough :)
cool thanks for clarifying!
oh I see what you meant now in the other PR :) if Tuples don't pollute the method arguments, I am ok with this, actually it simplifies synchronization issues between the two maps otherwise, I will update my PR to do the same.
Ah yes, thanks!
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
and remove the below null check
otherwise I would be happy to just return in the else block and remove the instanceof check in the while loop below
do we want to unify this code with the refresh method by making this get a manager to work on? (+ a string description for failures)
hmm I see it's to opt out...
same here re enumSet.toString
Could you explain why this needs to be public now? I think we should try to keep this package private if possible
Can you throw something else? It just makes me uncomfortable to throw AssertionError.
actually I don't fully understand why we can't just do `this.order = order` all the time
should be `final`
Not necessary with `ConstructingObjectParser`
excude_interim - missing 'l' -> exclude_interim
Nit: "seq no" -> "seq_no" (inconsistencies will make searching more difficult)
make these variables protected please and access them directly in IndexShard. I don't like accessing fields on self through getters. Also, this makes the PR harder to review, as it adds much noise.
can we just inline this in the transport action file? I don't see the need for another file.
nit: iff does not need an "otherwise". Either make iff to if or remove Otherwise.
"if if" again
this should happen after we update `isSecurityEnabledByTrialVersion`
"new" -> "now"
confuses the shit out of me everytime :)
OMG `== false`! ð±
same here just use synchronized methods
iirc we add `Asynchronously ...` to this sentence in the other APIs. But its a minor nit...
Just a note here. We decided that by convention we will use the same naming as maven. `groupId` has now changed to `org.elasticsearch.distribution.[packaging]` so I think we should also reflect that change here and use `org/elasticsearch/distribution/[packaging]` where `packaging` is: - rpm - deb - zip - tar
yea I think it would be good to have a test that makes sure that the index expression specified in remove_index resolves against indices only, rather than aliases and indices. I don't think the current test does that.
Incides -> Indices ? ;)
I think we can remove this
simpler as it decouples these two things. And no need for having this method return a boolean.
why change the semantics here to only call close when setting the tragedy the first time? Let's keep the existing semantics and make `setTragicException` return void
this case got lost
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
scratch that, I think this will be fine as-is in 6.x as well.
we also support a parameter called `updateAllTypes` here.
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
I don't mind as long as we use `writeString/readString` and `writeOptionalString/readOptionalString` consistently. So you can maybe just change the `readFrom` to explicitly use readBoolean.
and the last one ;)
I think we can simplify this and make sure we have 1 shard, no replicas.
I think we can clean up the http/transport/gatway settings here
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
Nit: `accross` -> `across`
I'd rather just `new ConcurrentLinkedQueue<>()`.
I think that we can do better than this. If I'm reading this correctly, this means that we wait until an entire batch is complete before submitting another batch of requests. Thus, a slow request can hold the next batch and thus the response. I think instead we should try to maintain as many requests in the queue as possible, up to the concurrent request limit.
I don't think we need this part? Even if you've created an index with 6.4, you still want to be warned that things are going away if you upgrade to 6.5
thanks for adding this
You could add an assert that it's not ES 7.x here so we know to remove it
final and java docs
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
nit: remove extra new line
it's just yet another unmanaged thread in the system..
Sure, but you get that also with a 5-10ms sleep. Basically I don't think we should continue to go the path of long sleep-based tests, we know this is not good...
I opened #19880 with an alternative which does not use sleeps.
I think 1/2 + 1 == 1 :)
I get that, I was just wondering why those default templates bother here
for master you don't need to specify the gateway.type we only have what used to be local!
the ones returned here are the fields that can be shuffled or that should not be shuffled? Not sure if the name is consistent with the behaviour
The main advantage to me is that implementers of nextValueHashed wouldn't have to be concerned anymore about whether they can fill the bytes or are just allowed to change the pointers, since they would know for a fact they are always operating on a private BytesRef instance, they are allowed to do whatever they want to.
Instead of exposing it as a shared scratch, maybe it could be exposed as the current value? Meaning that instead of eg. doing ``` java BytesRef scratch = bytesValues.getSharedScratch(); bytesValues.setDocId(42); int hash = bytesValues.nextValueHashed(scratch); // the value is now in scratch ``` Consumers would do ``` java bytesValues.setDocId(42); int nextHash = bytesValues.nextValueHashed(); BytesRef value = bytesValues.current(); ``` (The name is maybe not the best candidate, but the idea is to do something like `TermsEnum.term()` or `DocIdSetIterator.docId()`.)
I'd not do this, just pass syntactically valid values to the Prototype ctor
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
I would probably throw an exception instead of accepting null here.
I wondered if there was something better than iterating too but there's not since `IndexWriter#getLiveCommitData` only returns an `Iterable`.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
a transformer and performer. Quite a guy :)
we may want to rename match_formats as well here, can do in another PR though.
oh right sorry I had missed it's a single value for these processors. sounds good.
I like this simplification!
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
But yeah, keep it now.
this will not get executed as a test if the method does not begin with `test`
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
s/HashMap<String, Object> fields/Map<String, Object> fields
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
as we discussed - corruptions can't lead to mapping parsing failures. They fail way earlier when reading from the translogs
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
If that's the case, we don't need - that's making sure :D - where do you see it's done in ESTestCase? (I didn't check myself)
we don't want it to be retried... that was the cause of the failure
my thoughts too :)
Typo: "Dynamics" -> "Dynamic"
I'm not sure if this is practical in all cases, but IMO a lambda would work pretty well here: ``` nrReplicasChanged.forEach((fNumberOfReplicas, indices) -> { ```
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
this is not needed. createIndex automatically reroutes.
can we just delegate to `valueOf` and if it throws an exception we return the default? I don't think we should do the linear checks here
Same idea here as with StreamInput: ``` java @FunctionalInterface public interface StreamOutputWriter<T> { void write(StreamOutput t, T value) throws IOException; } public <T, R> void writeMapOfLists(Map<T, List<R>> map, StreamOutputWriter<T> keyWriter, StreamOutputWriter<R> valueWriter) throws IOException { writeVInt(map.size()); for (Map.Entry<T, List<R>> entry : map.entrySet()) { keyWriter.write(this, entry.getKey()); writeVInt(entry.getValue().size()); for (R v : entry.getValue()) { valueWriter.write(this, v); } } } ``` The caller would use it with: ``` java out.writeMapOfLists(map, StreamOutput::writeString, StreamOutput::writeString) ```
I don't think we should do `__default__` we can pass the default separately...
we should clearly state that these are the shard of the new index
why do you pass the response to this method? `this` already has all information.
remove "or timing out".
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
+1 to this, there is always the low-level rest client for this, and we can revisit adding it at a later time if we change our minds.
thanks for digging in. i only dug into the aws one and have not looked at the root case of the gce problems. If it involves weakhashmaps, maybe its something easy we can fix for them as well to avoid pain.
Ok that was fast :D
nit: `== false`
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
I called these methods test*ToAndFromXContent() as they effectively do one complete roundtrip: toXContent -> fromXContent -> toXContent
I am adding a util method for this in XContentHelper, maybe worth replacing this later (should not block this PR)
We can save object creations here by making the ByteArrayDataInput final and using `ByteArrayDataInput.reset`.
ideally, you should read directly into `scrach.bytes` instead of allocating a `byte[]`
this check is obsolet - we can just remove it
just call `parser.text()` instead of `parser.bytes().utf8ToString()` since it might be optimized under the hood
now I see what you meant yesterday saying that we have to parse meta here
Writeable#readFrom returns a new instance of the object, it allows to have final fields, but it requires to have a PROTO instance of the object to call readFrom against. I wish there was an interface to declare writeTo only though but we don't have it at the moment.
Oh oh! deleteUnderLock should be called when you hold the lock! instead we should use IndicesService.deleteIndexStore
this is unneeded - we just iterate of the list...
I think this will result in a double info logging - we already logged at info level when discovering this.
I really like this class since it's so self-contained and has all the tests etc. no weird guice bloat etc. NICE!
if you make `MulticastChannel` generic and the listener as well you safe the hard cast in Shared... just like `Shared extends MulticastChannel<MultiListener>` ...just an idea...
Yeah, it's relatively new but it's the clear path forward especially with JUnit 5 coming with built-in support for the same.
no need to make this public; package-visible is good enough.
Please revert this change.
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
I think you can avoid that by overriding `AbstractXContentTestCase#assertToXContentEquivalence`? I think it's worth using `AbstractXContentTestCase` here, it's going to be much more thorough than hand-rolling parsing tests.
@jtibshirani is correct
don't prettyprint please we don't test this here
Although the code is clear, the level of indirection here makes it hard for the reader to figure out that this (and similar other) test does. As a suggestion, what about combining test_object/test_object_IgnoreMalformed, then the code from `sourceWithObject` can be inlined in the test case. Also I would make the assertion on field1 and field2 explicit, even if that means a few more lines of code. In this case I would trade repetition for readability.
Would you kindly add some line feeds here to make it look like json instead of a wall of text? It'd be so much easier to read.
Shouldn't this be equal to the `jsonBuilder().string()` above, without adding `.prettyPrint()`? And a nitpick: please add a space after the comma..
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
This seems to only be used for tests. Maybe it should be a helper method in the test framework instead of part of the public api? I would be afraid of something accidentally using this in ES code.
Ok, my confusion stemmed from the fact the first result when searching down the diff was ScriptProcessorFactoryTests.java, which this PR changes from testing against `getMessage()`, to using `getDetailedMessage()`. I see now that is the only case. Can it be switched back? Changing the tests to use `ExceptionsHelper.detailedMessage` seems ok given they all already use it.
I think you should just do `instanceof Number` and else call `.toString()`
can we assert that if we need to generate a new history uuid we always use `*_CREATE_TRANSLOG` as an open mode? that's why we rely on the translog uuid only for trimming purposes (and avoid thinking about what it means to generate a new history uuid)
I wanted to remove the `allowCommit.set(false)` here with an ensureOpen at the beginning of the method. Only saw later it's already there. No doubles.
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
In my dreams, merging would either throw an exception or return a new independent mapping so that we wouldn't need this validation phase :)
I think that will fail compilation? ð
Oh, never mind, I misread. Sorry for that. ð
shall we check that we get some results back? Just making sure that we actually search against the alias. If it doesn't exist we could get back empty results without any error...
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
this is super ugly I think `AsyncShardFetch.Started` and `AsyncShardFetch.Store` should be an impl detail of `GatewayAllocator` no need to bind this or anything
just for kicks can we have `reason = "works around https://bugs.openjdk.java.net/browse/JDK-8034057"` it's just more obvious which bug is meant
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
"now" should be "not"
typo : now -> not
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
I think we need additional null checks here. Before the refactoring we only needed to check lucene queries in parse() method for null. Now also their `toQuery()` can potentially return `null` (e.g. if this FilteredQueryBuilder would be nested in itself). Same goes for the filter.
btw. I am currently thinking about how we can at least make the inner QueryBuilders we use always non-null, but will need to do this in separate PR and ask Adrien about it.
I just realize that there might be a bug in the existing code already. We only seem to add the query to the named queries if it's a BooleanQuery, the other cases return early. Not sure, but we might want to change that.
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
Should we increase visibility in this case? Makes only sense if we can then really test more, though, otherwise okay to leave it I guess.
Then we should leave it, the situation in general improves here already.
This test should assert that the headers are correct.
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
wouldn't it be cleaner to just work with sets here? (instead of converting to arrays)
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
we need to check on the node version, and only call it on nodes that are version 1.3 and above, otherwise they won't have this API
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
Elasticsearch tradition is to make this an EMPTY constant :)
drop the actually? sounds so "uncertain" :)
same here regarding nullable ..
would be nice to allow to configure it to a percentage of the heap size
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
wondering if we need recoveryState.isPeerRecovery() to simplify these lines.
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
For static varialbles, `final` should indeed be used whenever possible.
Optional: darkon has this style that I like where you start a new block every time you startObject or startArray and it makes these much more readable!
nit: extra space
Yeah, I'd make these a hard check and throw a `new IllegalArgumentException("Usage doesn't look like UnifiedHighlighter")`.
same question as above
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
can we please unpack the tuple right away instead of using v1 v2? just easier to read
Nit: spacing between `while` and `(`.
Nit: spacing between `!` and `value`.
this deserves a sep issue I guess but good catch
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
fine with me
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
final and java docs
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
nit: remove extra new line
Optional: darkon has this style that I like where you start a new block every time you startObject or startArray and it makes these much more readable!
I get that, I was just wondering why those default templates bother here
I think you can shorten the mapping here: `addMapping(type, "name", "type=string, analyzer=stop"` that hurts my eyes less :)
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
nit: you can just let the validate throw it's exception - this will fail the test and give us more info
same here - we need move double starting and such to ShardStateActionTests
we should check the exception is what we expect (assert part or all of the message)
I donât think this buys you anything in terms of concurrency. The list reference is already final.
This has issues as two calls could wind up finishing this listener. I think it would be better to use a AtomicBoolean and compareAndSet.
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
it's important to log the shard routing of the out of sync shards
Can you add the `translogId` to the log message here? It makes tracking stuff down on shared filesystems much easier.
Nevermind, I see it later on in the `commitIndexWriter` method :)
new is not possible with an older version...
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
argh. Hidden by github ui. all good.
nit: maxTermFreq must be positive
nit: `if minDocFreq is greater than 1, then it must not be a fraction`
minDocFreq must be positive
I believe `ScrollHelper.fetchAllByEntity` already wraps the listener in the client's `threadContext`.
Yes! you are right ð
I don't think we need this branch anymore.
Instead of having this public ctor should we have one that has this signature: ``` Java public CompressedXContent(ToXContent xcontent, XContentType type, Params params) { // do the serialization here with checked output stream etc } ``` that way we can hide the _CRC32_ impl detail entirely
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
ReflectiveOperationException can be used instead of both of these
can we just change this to System.getProperty("tests.seed") != null? Then that method can be removed.
In case you don't need the parameter, you can remove the null check as the constructor already checks that as a precondition.
I think the less-specific types are better when you can get away with them so that you do not come to rely on implementation details of the concrete type.
I'm fine with it, given the explanation. I only saw that it seemed to be a variable name change that was unnecessary.
can we add bogus non relevant settings? Would be good to know they don't mess up with things.
I see this was already like this, but this can go on a single line.
Yeah, it's pretty new. :-)
Fine with me.
Snapshot Name - repository name + snapshot name ;-)
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
same here, might be that we are good, but let's make sure we don't lose the STRICT one
to make this simpler, I think we should add a method `addCustomFields` to the `AcknowledgedResponse` object instead and just call `response.addCustomFields(builder)` in `AcknowledgedRestListener`. As a follow-up we can then make AcknowledgedResponse implement `StatusToXContent`.
I don't think is necessary. `request` is passed as`params`. So, "verbose" is already in `params` if it was specified, you just need to be careful resolving defaults. You would also miss other parameters here such as human and pretty.
nit: maxTermFreq must be positive
nit: `if minDocFreq is greater than 1, then it must not be a fraction`
We would need a call to super() somewhere here. Or, like we did with the query builders, have the superclass declare two abstract doEquals/doHashCode methods that it then calls and the subclasses need to implement.
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
this might be called by `scheduledRefresh`, which can happen at any time
this could possibly called I think
good point, we will once we have the processor that updates them, which is being worked on.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
This can be outside the try/catch right? If there is a failure to create the pipeline, there is no pipeline to close.
Most likely meant `&&` instead of `&`.
here is a space missing before `EMPTY_FLAGS`
so `round` should be called once per factory instead of once per aggregator
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
how about changing this to `if (upgradesInProgress.decrementAndGet() == 1) {` so we can remove the return statement. I find this easier to read as the action only happens when the in progress value is 1.
I think that we can do better than this. If I'm reading this correctly, this means that we wait until an entire batch is complete before submitting another batch of requests. Thus, a slow request can hold the next batch and thus the response. I think instead we should try to maintain as many requests in the queue as possible, up to the concurrent request limit.
I think we should do this as one of the first steps in the if block. The reasoning is that if an exception occurs before this, we will never get the chance to continue operating as nothing will trigger this method again
same here, all retry logic should be removed
same here with removing retry logic
same here with removing retry logic
@s1monw if you're proposing we use inheritance and you assume the base class will always be caching DF then we could just remove all the "if(this.docFreq)" checks in the existing code as a simple way to clean things up? That would leave us with just the "if(this.totalTermFreq)" checks.
I think we should have a baseclass that only handles DocFreq and then subclass it if we need TTF that should remove a lot of branches here though. I don't like the long methods that basically repeat code because of the TTF / DF swtiches. I mean it makes sense do split it since they have a higher cost if TTF is needed though.
I guess that's ok...
I think we should separate the two and push this as is. Your code refactoring has more changes than this functional change and on the security end I think we should be careful. let get this in and cleanup the stuff afterwards
yeah again, its definitely bad the way it is now, easy to break. if we initialize netty classes too early before security kicks in, we might not notice anything, then suddenly users jvms are crashing (e.g. because of some bug in unsafe/native usage, or whatever). with a netty module things would get way better: one advantage is, netty isnt on the classpath anymore, instead we load it explicitly with `URLClassLoader.newInstance` in PluginService, followed by `Class.forName` and so on with the registered plugin class from the plugins configuration file. So it would be well-defined exactly when these classes will get loaded, and its all after security and everything else is fully initialized.
> Last - if there is any way to determine the list of classes loaded at the point security kicks in, Yeah, you can do something like this: `JAVA_OPTS=-verbose:class bin/elasticsearch`
same here - I think it's better to log the info message if the deletion was successful.
Left over Note
same here: no need for the [].
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
nit: extra line
formatting should be fixed like the rest in these three lines
can you please inline this while [adding docs](https://github.com/elastic/elasticsearch/pull/30176/files#diff-ed6e20d0c4d03d97ae9b7a9a33190c4bR1532)? We need to have more roll overs randomly
same heere, randomIntBetween(0, 5) would be more life-like
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
I'd probably write validate's results to a variable and reuse it.
i think `== true` can be skipped
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
this method seems to be wrong here the class is concerned with fetching data in an async fashion, I think what we do with it or what we call as a result should just be somewhere else. I wonder if we can just have an ActionListener that we pass to execute this onSuccess and onFailure since those seem to be the two mode we have.
would you mind adding `<>` after `new PriorityQueue` ? otherwise this is an unchecked assignment.
this only works if we have entries? shall we check? Also can we just do a for loop here instead
That assumes `list` can't contain null..if that is not the case ignore
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
I think we can share this line and the return new BulkItemRequest line? these two clauses will need to set a final `updateResponse` field.
use the constant defined in SnapshotId...
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I think we should return active.get() == false and also - set it if we became idle...
why not protect against double closing in the snapshot it self? this is a common problem
This is logic that I think should go into ReplicatedOperation.
Thinking about this more, I wonder if we should have this run-even-if-there-is-nothing-to-do complexity. I'll reach out to discuss.
let's make sure we deprecate it as well in 2.x
you can rebase and get the changes upstream now ;)
same as in the regex PR, I wonder if we should have parser.text() or parser.textOrNull()
I think the OOM reference was a copy paste error from another clause. This clause doesn't do `translog.newTransientTranslog(translogId);` so no need to revert it - although it seems to do no harm if there is no current transient translog.
I think this missed a misses a maybeFailEngine
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
I think that inserting random fields here would reveal problems on the parsing side with the current code.
MultiSearchResponseTests was written before the test base classes were made more flexible, we should probably migrate that too if it works well for your case
nit: formatting, add some whitespaces
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:918E10886BC43EC1]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.LineStringBuilder.<init>(LineStringBuilder.java:49) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiLineString(GeoWKTShapeParserTests.java:112) ... ```
Fair enough. I know it used to work in previous version but I'm fine with this implementation. And even better it will be consistent with Kibana plugin manager which also checks that `://` exists.
Also I use sometimes (in workshops) file:../relative/path
No, it should stay "id" in the message because plugins are installed by id (with the exception of some special plugins that can be installed by name only). Yet "name" is fine for removal because plugins are removed by name.
Let's replace the `assertTrue` by more effective matchers, and replace the `assertEquals` by `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
Hmm why are we ignoring exceptions here? You can consolidate those two `deleteFilesIgnoringExceptions` into one call and it will do the right thing if either path hit an exc while being deleted...
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
We've been moving away from these inner fields classes, we don't need them to encapsulate some strings.
I think you want ToXContentObject here.
nit cat we explicitly call the other constructor with null? i.e., `this(null)`
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
Ah ok, I missing that method below, sorry.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
Can you remove this annotation? It's not needed anymore and this will fail when you'll rebase on master.
``` java assertThat(provider.fetchCount, is(1)); ```
``` java assertThat(provider.fetchCount, is(2)); ```
Ok I see the problem... I still find this hackish (needing to throw an exception to test things), but there's no easy way around it if we want to test different requests and responses. I'd consider using a mock request (one per client type actually) instead and give up on testing those real requests and responses. It would be more unit test friendly cause you'd know the request and the response you need to return (unless it's a nodes info request), you don't need an exception and you can assert on the sendRequest directly. Using real requests it feels wrong to only test a few of them anyway and we know that it's the client that injects the headers (`execute` method), that's what we need to test.
I would maybe move this to be the actual test method, with `@Test` annotation, and have either an abstract setup method to be implemented by subclasses or even use junit annotations like `@Before` if possible in the subclasses.
I double checked and heard that `@Ignore` is needed as well, otherwise IntelliJ tries to run this test as well when running all tests from the IDE.
oh cool the read is in the ctor! nice!
ok can we rename the getter then to `getFailedNodeExceptions()`
after is now minimum_age
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
nice! I like this. super helpful for keeping track
we should totally not have this method, one more reason to not implement the interface.
I think you don't need to create cache keys and could directly use LeafReader instances as cache keys.
Should this be cached somehow? /cc @jpountz
I think this can leak a reader if `reset(DirectoryReader delegate)` fails (especially when the `this.delegate != null` is true)
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
can we swap member and constant we know the constant is not null :)
what happens if we assign to null? wondering why these checks are needed
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
should be aliases
should be action
I know that this is how it used to be but we add an explanation that this is called before the index is added to the cluster state? created is misleading.
Safe because ~~our~~ we know
update version to beta 1
And we could then just leave an assert here.
This should be `public static <T> PreBuiltCache<T> getCache(CachingStrategy cachingStrategy)`. As a result a few warnings on the caller methods are gone.
I think all three implementations of `PreBuiltCache` could potentially be `private`
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
we will have to be careful though. If a very short-running method with < 256 calls is timed using this approach, we will have significant overhead from `System.nanoTime()` calls.
nit: "so we assume"...
We can use the SuppressForbidden annotation on top of the class to fix this.
This method takes a phrase query and is supposed to create an equivalent phrase query that just has a different value of the slop, so we need to transfer the boost? Maybe the method should look like this now: ``` java private Query applySlop(Query q, int slop) { float boost = 1f; Query underlyingQuery = q; while (underlyingQuery instanceof BoostQuery) { BoostQuery bq = (BoostQuery) underlyingQuery; boost *= bq.getBoost(); underlyingQuery = bq.getQuery(); } if (underlyingQuery instanceof PhraseQuery) { PhraseQuery pq = (PhraseQuery) underlyingQuery; PhraseQuery.Builder builder = new PhraseQuery.Builder(); builder.setSlop(slop); final Term[] terms = pq.getTerms(); final int[] positions = pq.getPositions(); for (int i = 0; i < terms.length; ++i) { builder.add(terms[i], positions[i]); } pq = builder.build(); pq.setBoost(boost); return pq; } else if (underlyingQuery instanceof MultiPhraseQuery) { ((MultiPhraseQuery) underlyingQuery).setSlop(slop); return q; } else { return q; } } ```
if we can assert that, it would work for me too
Errr. Oh man. I should know this one but I don't!
please make sure all files closed and no file is leaked.
If that's the case, we don't need - that's making sure :D - where do you see it's done in ESTestCase? (I didn't check myself)
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
> but then if that's the case I wonder, how do we test that the setting is not really needed, cause it shouldn't be? :) @javanna imo this should be a pre-release smoke test.
but, it seems we look for an hexadecimal number? (which is OK because normal long are also parseable as hex, but you know, pedantic)
Hopefully the answer is no, we do this here only so the test is reproducible? but then if that's the case I wonder, how do we test that the setting is not really needed, cause it shouldn't be? :)
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
Ahh okay, that makes sense, I missed that
You can just use the literal boolean `false` instead of the string `"false"`.
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
can we check and stop if the background thread had any issues? o.w. will have to dig through more than needed.
wonder if we should make these Integer and Boolean just int and boolean primite types.
this would make sense especially given that their setters accept primitive types
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
this should happen after we update `isSecurityEnabledByTrialVersion`
nit - we flush also it will reduce the size of uncommitted gens but strictly speaking it doesn't mean it will be below the threshold
I'm not happy with the extra boolean flag to include / exclude the current generation as a fall back. It's too subtle an error prone. How about doing the following (I think you had it in the past and we moved away from it towards the uncommittedX api - sorry for that): 1) If the min gen for the local checkpoint + 1 is > current committed gen , return true. 2) If the min gen is equal to the *current* translog gen, the current gen is not empty (using `totalOperationsByMinGen`) and the local checkpoint is equal to the max seq#, return true.
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
Same suggestion here for `assertNotEquals`.
We also need a simple rest test, testing integration like we have for the other processors
I think that all of these members variables except for `finalResponseListener` can be `private`.
Nit: there is an excess blank line here.
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
can you leave this class for now, add the same TODO as in the parser? We can't have a parser without a builder in the query-refactoring branch.
nit: you might be able to save a few toString lines by extending ToXContentToBytes here. no big deal though
good idea, I think this should solve my concern above about setting things that are not supported through the java api.
not sure, but should we make the location available to java api users too? Transport client is still a thing in 5.x and this way one has to build the location by passing in the routing value. Should the location rather be a field in the response object? Not sure though as it becomes a header in the final rest response. maybe it's ok this way.
I guess you would have to carry the routing around in the response, serialize it etc. maybe it is not worth the trouble.
Pre-size the buffer? ``` java final String index = getIndex(); final String type = getType(); final String id = getId(); final StringBuilder location = new StringBuilder(3 + index.length() + type.length() + id.length() + (routing == null) ? 0 : (9 + routing.length())); ```
I think you want (soft)deleted
I liked the assertion you had there that if already have a result, this one has a higher seq no
I think we should discuss such ideas in follow-up PRs. It's not clear to me that replacing duplicate code with more abstractions would be a win.
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
I think this can use the FileSystemUtils method you added to get all paths as an array for a directory, instead of creating the stream here.
we could pass a glob with regex:xxx to newDirectoryStream if we want
I think it's better to use the index version created to test whether the old or the new parent join should be used. This way you can make sure that the correct explanation is returned in the exception if the parent field is not filled.
I think we should do this even if we use docvlaues? I think we should have consistent slicing no matter how it's done!
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
this is not needed. createIndex automatically reroutes.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
I'm on the fence regarding this one - on one hand it's a public api and people can do whatever with it so you don't want them to slow down the release of the lock. On the other hand as an API it is really weird to have `POST_RECOVERY` come in after `STARTED` (which may happen if the shard is allocated on master - though the chance is still very small)... will think more.
same here re enumSet.toString
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
These are not the only exceptions that can be thrown. There a bunch of situations in which an `IOException` can be thrown. It's probably worth changing the signature to reflect this too.
Name of the plugin to remove.
I'd just say "Remove the plugin named {@code plugin named}".
Typo, finalzlie -> finalize
we can do try-with but we need to have 2 try blocks. since the write lock needs to be released last. but in a try / with blokc it's released before the finally block is executed
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
Thanks for the clarification @nik9000.
yeah, prefer top-level there as well.
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
I think it is important to keep different classes on the client-side so that we can have more type safety and potentially add some methods to only eg. avg in the future
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
I would probably throw an exception instead of accepting null here.
this might also be called I think
this could possibly called I think
this might be called by `scheduledRefresh`, which can happen at any time
> extending AbstractQueryBuilder does it for you Awesome!
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
right I had missed that previous check, sounds good then
I am starting to see that the default boost doesn't get printed out but other default fields do. Makes sense to me but maybe we want to be consistent? I think we should have this a separate discussion, make some decision and do the same everywhere (I have the feeling we are not yet settled yet on one way or another)
why not calling `RestActions#buildBroadcastShardsHeader` instead ? Aren't we losing support for the `group_shard_failures` flag? It is not relevant for the high-level REST client as there is no way to set it but I think it's important given that the parsing code is in ES core. Which reminds me, we should probably test this as well in `RefreshResponseTests`. This param can be passed in as part of the `ToXContent.Params` when calling `toXContent`
As Boa mentioned before we would need both a default to print out, and a boolean that tells whether the current value is default or not, as the `currentValue != defaultValue` is not enough. Something like the following should help in most cases I think? ``` public static void maybeAdd(XContentBuilder builder, String key, Object value, Object defValue, boolean isDefault, boolean includeDefault) { if (value != null || !isDefault) { builder.field(key, value); } else if (includeDefault) { builder.field(key, defValue); } } ``` That said, maybe it doesn't cover 100% but 90% of the cases, and for the 10% left we can still have the custom if? In my opinion it doesn't need to be perfect but still better than copy pasting that `if` so many times.
All our tests currently use `RandomizedTest#atLeast` method, you can do the same here.
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
Left over Note
can we use `== false` instead of `!` it's so much easier to read and burned my fingers too often
Ok sounds good....as long as all the REST tests pass, I'm always afraid of any change to `PathTrie` :) Thanks a lot for the detailed explanation! Maybe it would be better to treat it as a bugfix and get it in separately? I don't have a strong opinion though since it's something that came up with this new api and wouldn't make sense without. Just thinking it would better highlighted as a different change and leave some more history on it this was applied.
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
I think this is okay though, it checks if the current `zeroTermsQuery` is the same as the default, which is ZeroTermsQuery.NONE.
we frequently use randomizing client, I think that it should frequently use the default (null) preference
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
ok now i can see that it is null when removing the task, sorry for the noise
I think you want to use `notVisitedTasks` here instead of `runningTasks`
perhaps a different name for this listener, as it doesn't only handle failures but also successful response publishing
can this be final
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
same here: ``` parser.longValue(true); ```
This seems to be the only "shared" portion for string/value. Perhaps it could be moved out? Or just have a helper method, or even just leave the duplication (it is only 2 lines really, not bad).
Besides jokes I see your point on NoOp naming, let's leave empty then, it doesn't convince me 100% but I cannot come up with a better name
I think saying that it should not be allowed in the query DSL is a bit misleading, cause it is allowed and we parse it properly. I know what you mean though and why you wrote that, I need yet to come up with a better explanation for this...
cool thanks for the explanation!
I'm not sure if the cast is worth it here. It is usually simpler to just work in integers even if we know if can't be more than 255.
I'm fine with the answer being "no, you are crazy Nik" or "not right now".
I wonder if it is worth compressing the hitCount into byteSequence? That way you only have to store an array of ints? You'd have to cap `hitCount` at 255 but maybe that is ok? Or you could use an array of long and have tons of precision on your `hitCount`.
we may want to rename match_formats as well here, can do in another PR though.
oh right sorry I had missed it's a single value for these processors. sounds good.
I like this simplification!
This could be collapsed into the previous `if` statement: ``` java if ((searchResponse.getShardFailures() != null && searchResponse.getShardFailures().length > 0) || searchResponse.isTimedOut()) { .... } ```
(Not that you have it, it's a matter of preference)
Hope this doesn't bite us for really slow (read: Windows) CI servers...
should be clause.getOccur() == SHOULD
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
I don't like leniency. Can it be `"true"`, `"false"` or `null` with the former parsing to the right `boolean` and null giving the default? A typo of `"tru"` will parse to `false` and that makes me :cry:.
The worst is how `on` and `no` both parse to legitimate values, very dangerous for transposing typos.
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
nit: we almost never use `Locale.US` exept for some number formating. While I think it doesn't make a difference for the enum names in question here, I'd suggest going with `Locale.ROOT`
There's no need to specify `this` : `if (isString() && other.isString())`
I don't think raising en exception to save a few lines of code here is a good idea, please change this back to how it was before.
indicesDeleted doesn't check for indexUUIDs. We have a separate method for it in this class `cleanMismatchedIndexUUIDs` - in this spirit of bringing all deletion code together - I think it's good to make indicesDelete aware of UUID switches (mark old as deleted), move the `applyDeletedIndices` to be executed where `cleanMismatchedIndexUUIDs` is called now and then we can remove `cleanMismatchedIndexUUIDs` make all go through here.
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
ok let me have a look then ;)
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
Why remove it? I was adding them because I thought it was nice to mark the constructors for anyone unfamiliar with Elasticsearch. It'd help them get their bearings.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
I think we can check the beforePart == null out of the if(!..equals) and it will make it cleaner.
I wonder if we should make this a hard exception, potentially in the AllocationId constructor. When we start using this ID, a null value will create havoc in other places and will be hard to debug..
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Assert that the current thread holds the lock on `this`? The results from `ObjectLongMap#indexOf` remain valid only if no one else is mutating.
do we really need to walk these directories, can we just do what `getFSInfoIgnoringQuota` does? I really don't think we should walk the direcotries
is this needed? as far as I can tell, the implementation does nothing?: ``` try { if (lock != null) { <-- **lock is null** try { lock.release(); lock = null; } finally { clearLockHeld(path); } } } finally { IOUtils.close(channel); <-- channel is null channel = null; } ```
`new AtomicReference<>();` with the extra `<>`.
Missing the `indexName` argument to the debug log here
typo here "ot" -> "to"
I think this message is misleading - we don't actually schedule the delete of this index but rather ignore it. Maybe change to "failed to lock a dangling index [{}], probably in the process in being deleted, ignoring." . I also think we should include the exception as it may not be a LockObtainFailedException but something else.
> There are people in the team that prefer it this way rather than having a random timeout on the latch Then I guess I'm fine with it, it just made failing tests hang locally for me for quiet a while (I guess there are some hard timeouts after all).
lets revert this. We do not need it here
Is this needed? I think the observer takes care of this? If not, I can work on folding this into the observer as a follow up.
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
Nice, I like the randomization on the thread pool.
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
should we catch exceptions here to make sure we cancel everything we need
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
canceled -> cancelled
You could probably avoid this by making the linux check a method that you stub out in OsProbe.
method refs ftw
Can you add some randomization ? We run this method multiple times and then perform some checks on the generated query (serialization, correctness, ...).
oh cool the read is in the ctor! nice!
ok can we rename the getter then to `getFailedNodeExceptions()`
after is now minimum_age
Not 100% sure of the rules here, but `private` seems too restricted for this.
Does this question have an answer? I _think_ any failures are passed to the response handler.
We should assert that this is called (and I guess that we can say something about the response that is passed in).
Why is this `volatile`? It doesn't look necessary to me.
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
this could be a for each loop instead
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
Not sure if we want this optimization, but we could always run these three requests in parallel, putting the responses in three `AtomicReference`s and using three `CountDownLatch`s to wait until all three complete.
I see, yea we can't avoid this then. Maybe share the default value through a constant so at least we don't duplicate it. Odd! :)
this is odd especially because it seems that once you set a value for this field, you can never reset it to its original default value.
given that the request goes through validate first, I think we could remove this assertion, this is already checked in as part of validate which will throw an error otherwise.
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
could be a instance variable, as used in all tests
please use `assumeFalse(Constants.WINDOWS);`
and -> an
Also, since "recover" and "restore" are very similar and easy to confuse, I think it'd be nice if this were named "`recoverState`"
`Arrays.toString(paths)` already adds [] , no need to add them
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
can we do this `((Long)value).longValue())` no boxing needed here
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
should say shard active
this can ne ThreadPool.Names.SAME, the handling is lightweight enough to not require forking to the unbounded generic TP
we need to check on the node version, and only call it on nodes that are version 1.3 and above, otherwise they won't have this API
I think we can share this line and the return new BulkItemRequest line? these two clauses will need to set a final `updateResponse` field.
can we call this primaryItemRequest? It's the one that's sent to the primary. Also, if we pass it as a `BulkItemRequest` parameter, we can avoid sending `requestIndex` and `BulkShardRequest` (from which need the concreteIndex, which I think we can from the shard). Last can we assert that the `BulkItemRequest` has as a request object the `updateRequest` we got? this is all super trappy but we can take one step at a time :)
nit: flip this to true? easier on the eyes
please use Arrays.asList while we re here
can this be synchronized please
if just read metadata it will also be easier to implement a fetch all interfeces, sort interface name, fetch interface ip sequence
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
Ah! Got it.
you don't have to assert on anything if an exception is expected
We shouldn't need to log if we through an exception. I don't like the hard cutover but I can live with it. If I discount the hard cutover my only thing is the exception message.
Do we really need to ignore the setting in post 2.0 indexes? Why not just support both for a while? You already check above that both aren't specified.
I _think_ we have a deprecation logger. We should probably log something when we see `position_offset_gap`.
same note as in the json processor PR.
I don't know that we should fix this now, but I think failures of this test will miss the gradle reproduction steps, right? I've been thinking of pulling those into a tiny shared project without dependencies just so we don't have trouble with stuff like this but I haven't looked into it deeply enough to be sure.
Note that this is different than setting a single property as it adds the inputs to the list.
yea I think it would be good to have a test that makes sure that the index expression specified in remove_index resolves against indices only, rather than aliases and indices. I don't think the current test does that.
I think we can omit catching this and failing when caught, that's default behaviour, what matters if the `finally` I guess
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
fancy pants :)
can this be: ``` Java public static final Setting<URL> URL = new Setting<>("url", "http:", URL::new, false, Setting.Scope.CLUSTER); ... URL url = ...; if (URL.exits(settings) == false && REPOSITORIES_URL.exists(settings) == false) { throw new RepositoryException(name.name(), "missing url"); } ```
this can be: ``` Java public static final Setting<List<URIPattern>> ALLOWED_URLS_SETTING = Setting.listSetting("repositories.url.allowed_urls",Collections.emptyList(), URIPattern::new, false, Setting.Scope.CLUSTER); ```
yeah nevermind I was confused about some internal classes
operation can be `final`
nit: extra line
nice one. Good to add.
can we add some randomization here around the version - check that new has a higher version then old and vice versa
yep. missed it. sorry for the noise
I think 0 is a good minimum value.
I don't think so, I think these should be bytes or size-value only.
++ to keep byteSizeSetting here
I think this is a sign that `getActionFilters` maybe should take `ThreadPool` as an argument.
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
Whoops, you already did, ignore this!
cool. lets look at it on another issue.
typo, all flies -> files
I think adding a constant somewhere for # makes sense. It may make sense to also add a constant for typed_keys, but I don't have a strong opinion on that.
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
I think this can be combined into LoadedPlugin, adding the ClassLoader there.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
I think we can better call this in the Store.OnCloseListener.afterIndexClosed(). Feels cleaner to call this once we think all shards have bee removed.
Can this use `nodeEnvironment.shardPaths(shardId)` instead? Then it doesn't need to use `toPaths`
We should log the the failure here if the close fails
You could make it the same with an `else if` instead of `else`: ``` } else if (theAnalyzer != null) { builder.searchAnalyzer(theAnalyzer); } ```
As far as I can (brief check only) they are always null, but it wasn't part of the API to change properties that are not part of the json being parsed. Not a big deal..
so I think we need to somehow extend the `fuzzyPrefixLength` with the length of our context otherwise we will apply LD to the prefix as well? Also we need a test for this I guess
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
[{}] for path.
Since you don't care about the body of the source maybe use something like `setSource("foo", "bar")`.
`assertNoFailures` is more common in newer tests and much shorter.
I like `hasSize(1)` for this kind of thing because it makes a nicer error message.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
you should pass fieldNames as an argument
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
Why is this `volatile`? It doesn't look necessary to me.
ahh yeah in `assertAfterTest()` nevermind
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
underscore case? :)
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
I think we could check that successful == total shards and that total shards is greater than zero
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
nit: space after the second percent sign (on all these lines)
Just a note here. We decided that by convention we will use the same naming as maven. `groupId` has now changed to `org.elasticsearch.distribution.[packaging]` so I think we should also reflect that change here and use `org/elasticsearch/distribution/[packaging]` where `packaging` is: - rpm - deb - zip - tar
For all of these find calls, you can use `in` operator instead: if '(On branch %s' % branchName) not in s:
`.addPathPartAsIs("_xpack", "rollup", "job")`
`fielddata` is the preferred name as of my merging #28943 today.
Can you update the `\rest-api-spec\src\main\resources\rest-api-spec\api\indices.clear_cache.json` as well? ( do we need to specify all supported params, or only the preferred ones. There is also a `recycler` flag in the rest specs which I do not see in the code )
I'm fairly sure I have the wrong generics incantation there....
We might should move these last two declarations to a common spot something like ``` static <T extends AbstractObjectParser<? extends QueryBuilder>> declareStandardFields(T parser) { parser.declareFloat((builder, value) -> builder.boost(value), AbstractQueryBuilder.BOOST_FIELD); parser.declareString((builder, value) -> builder.queryName(value), AbstractQueryBuilder.NAME_FIELD); return parser; } ``` and then we can declare them when we're initializing the object.
I might use an empty array here or switch the IdsQueryBuilder work with lists.
+1 to capture `System.nanoTime()` at the beginning of the method
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
otherwise, if you want it for testing, it can be done once in the ctor
Helper method is no longer needed now that `Logger.debug` exists.
This test should assert that the headers are correct.
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
this is super ugly I think `AsyncShardFetch.Started` and `AsyncShardFetch.Store` should be an impl detail of `GatewayAllocator` no need to bind this or anything
that sucks, sorry :) We can't build stuff that is dependent on the order of how the listeners are added! Can we find a better way of doing this? I think each listener needs to have priority or so and every prioritoy can only be added once? Maybe we don't need this to be a list at all? This stuff is so fragile we have to iterate until it's safe
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
This is similar to the internal implementation, nice
I think an absurdly high limit could still be helpful? (in a follow-up PR)
Does this message go back to the end user? If so the fact that a map must be empty is more of an implementation detail than an meaningful error message for the end user. Something like "Mapping definition for field X has unsupported parameters: foo, bar" would be more appropriate.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Let's replace the `assertTrue` by more effective matchers, and replace the `assertEquals` by `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
Is the version needed? I don't see it being read here.
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
Hurray no more weird `while (true)` loop
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
Minor typo of `local` instead of `locale` in the exception message.
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
maybe make if final
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
maybe also test a nested conditional setup? (So have conditional and then another conditional in the matched or unmatched list)
We can leave `API` out of the test name.
This can be final. This makes it easier to immediately see what is and is not immutable.
can you add more rolling while adding? Also *sometimes* increment the primary term
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I think the OOM reference was a copy paste error from another clause. This clause doesn't do `translog.newTransientTranslog(translogId);` so no need to revert it - although it seems to do no harm if there is no current transient translog.
I think this missed a misses a maybeFailEngine
++ thanks for adding these checks
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
yeah that is what I figured!
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
waitForyellow can go away...
nit pick - can we start with node1 and relocate to node2 ? :)
just FYI - you can do setSettings("index.number_of_replicas", 0)
I wonder about the cases where this can happen as the `close` method on `InternalTestCluster` that calls `shutdown` on the executor is synchronized (same as this method). Have you observed this exception being thrown? If we don't expect this to occur under normal operations, I would prefer not to swallow the exception here.
space missing between ) and {
We discussed this on another channel, and decided to only do the auto-bootstrapping when autoManageMinMaster mode is active. We also decided to have multiple nodes participate in / run the bootstrapping process.
given that the request goes through validate first, I think we could remove this assertion, this is already checked in as part of validate which will throw an error otherwise.
is it necessary to mock the rescorer builder, seems like an easy object to create manually, unless I am missing something. In general, I tend to use mockito only as a last-resort, when things are really hard to reconstruct, that's why I'm asking.
why this opening bracket here and the closing one in line 186? Apart from that LGTM
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Recently we've been doing something more like this: ``` clearIndicesCacheRequest.queryCache(request.paramAsBoolean("query", clearIndicesCacheRequest.queryCache())); clearIndicesCacheRequest.requestCache(request.paramAsBoolean("request", clearIndicesCacheRequest.requestCache())); ... ``` Rather than the loop. The whole loop thing is more appropriate for by-hand xcontent parsing then url parsing.
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
And it looks like you cover the response below. So you can ignore this.
I wonder if it'd be nice to have the assertion in the docs with a note about how this is the response. And maybe a note that you don't have to assert anything if you don't care whether or not it was created up updated because non-200s throw exceptions.
I believe this text is out of date now that we have a macro.
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
right I had missed that previous check, sounds good then
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
Nit: `}` is in a funny place.
Also, we will need the oposite conversion from the ES enums (e.g. TermSuggestionBuilder.SuggestMode) to the Lucene enums (org.apache.lucene.search.spell.SuggestMode) used in the DirectSpellcheckerSettings later anyway, so rather than having `fromUnderlying` better turn the direction around to each enum knows how to produce the corresponding low-level enum.
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Yeah, I think the problem with the test here is that we don't make sure that nothing is left in the stream after we read it. That's why we didn't catch it here.
We will need stronger assertions here too.
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Remove and create again is not needed I think
should it be `final` ? seems to be a const semantics
++ to this pattern
Another `_` java 9 will be mad at
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
is this needed here? I think it does something only when the current token is start array or start object.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
Do we need this on this one? It seems like these test suites are very small and any of them taking 40 minutes is grounds for making someone look at the VM at a minimum.
this is fine for now, but I'd rather have more runs on CI than spreading these repeats all over the place. We are most likely going to forget about them, already too many things we have to watch out for in this branch.
remove the iterations please
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
we shouldn't need this here in parse phase
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
This seems quite sneaky that you modify the lists returned by `getGetMethods()` and `getGetReturns()`. Additionally, I'm not sure how it actually works since you increment `get`, but then but remove, so the size is changing. Can you instead create a copy of the lists in SSource ctor and use those local versions? I think you could then just create the lists on SSource only containing variables contained in `reserved.getUsedVariables()`? Then just iterate the member lists here to add to the `mainMethod`.
just because it seems like it's used only internally, that's it. No strong opinions though ;)
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
where is this method used? I can't find it
guava has a `Iterables.elementsEqual()` - which works slightly different, maybe your implementation is a bit faster
lower cased now...
it will also give a chance to the AssertingIndexSearcher to perform additional checks
you can use `getRandom().nextBytes(bytes)` here
Can you fix the indentation
This is true. The alternative way I was thinking about would be to pull a terms enum from the sorted set doc values, and set bits in the bit set based on the hash of the values rather than their ordinal. This way, the partitioning would be based on the value but the terms aggregation would still be able to leverage ordinals to do the bucketing. The drawback is that it requires to compute a hash on every term of the field.
+1 for the terms enum pulled from the sorted set. It should be fast to enumerate the terms since it is a sequential reads in the term dict of each segment. The hashing will be slow though, but again it's great if we can have a way to exhaust a term aggregations consistently even if it's not as fast as we would like ;).
you need a long, or this could overflow. Or even not store it at all, and use `termsEnum.ord()` to know the ord of the current term
maybe we should have a constant for it
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
new is not possible with an older version...
I don't think this test is needed. `testSpanMultiTermQuery` does the same thing.
nit: missing space
This should check `isSecurityEnabled`. The other methods like isAuthAllowed do not take into account the default distribution behavior where security is disabled with a new trial license unless it is explicitly enabled.
Is it intentional that this is looking only at `isAuthAllowed` and not `isSecurityEnabled` ? The implementation here will disable the cache for trial licenses even if they have not enabled security.
nit: I'd prefer that we move the sendRequest call to the try block and remove the return from the catch block
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
also, at the moment we don't check for ids uniqueness, which is probably fine given what we need ids for, just double checking that we don't rely on uniqueness anywhere
This exception will be treated as ignore replica exception. :wink:
I think this check is wrong. When we have relocation going on and relocation source is marked as relocated (i.e. we call executeRemotely in TransportReplicationAction), then we have primary relocation target replicating back to primary relocation source (see also ReplicationPhase).
typo I guess `s/chanHaveDuplicates/canHaveDuplicates/`
minor nit: "for" -> "on"
I don't get this part why do you change the way we read the `TranslogStats` here? can't this just be ``` Java translog = in.readOptionalStreamable(new TranslogStats()); suggest = new SuggestStats(); if (in.getVersion().onOrAfter(Version.V_1_2_0)) { suggest = in.readOptionalStreamable(suggest); } ```
and do that in all other classes we do this for serialization in this pull request.
remove the setBoost
remove the set boost
you can remove randomization of boost and queryName
`com.sun.glass.ui.Size` appears to be unused.
Nitpicking - unused imports were added to this and other IndexActions.
We had to choose a shared prefix in order for there to be a consistent way to detect types deprecation messages in REST tests (and ignore them). I think @jdconrad is just using this prefix here for consistency.
I'd supply a lambda, yeah.
nit: space before RESPONSES
ok can we rename the getter then to `getFailedNodeExceptions()`
To avoid this getting out-of-sync in the future, it would be nice to use `PARENT_TYPE_FIELD.getPreferredName()` instead of hard-coding `parent_type`. The same idea applies to `query` below.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
good catch! that means we are not properly testing this case either given that we didn't catch it.
I liked the assertion you had there that if already have a result, this one has a higher seq no
`seqno` -> `_seq_no`
Nit: `primary term` -> `_primary_term`
I think this assumption is pretty broken. What if the type is `null`? We don't define any order in the types when they are specified in the URL but this code assume that there is an order. I think we have to make this explicit which type should be used.
you can remove the validate call for now, we will fix all queries soon, I promise
of course how could I forget about this, I pushed it 30 mins ago :)
this could lead to NPE if from the java api no set call is performed
it's fine, when I did the refactoring SpanQueryBuilder became an abstract class without any problem, but now it needs to be a marker interface again cause java doesn't support multiple inheritance ;) We just need a cast, sorry for the noise I had missed this change to be honest but now I get it, thanks a lot for digging!
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
Can we return 0 when the value count is 0 to be consistent with the singe-value case, or throw a proper exception? I am concerned this code could raise a weird error message otherwise.
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
ideally, you should read directly into `scrach.bytes` instead of allocating a `byte[]`
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
and randomly append '/' at the end
I might make something like ``` private void expectMissingBodyError(Matcher<String> responseMatcher, ThrowingRunnable exec) { ResponseException responseException = expectThrows(ResponseException.class, exec); assertEquals(400, responseException.getResponse().getStatusLine().getStatusCode()); assertThat(responseException.getMessage(), responseMatcher); }
I am not sure whether the log message is too specific, i.e. the subclass must not necessarily be a service.
how about `onGet` as a name instead of primer
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
If it is relevant for String impls then I don't see why it should not also apply in the long impl.
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
I mean in the code but just noticed there was one already
Usually we'd stick this on the end of the last line.
nit:`maxEdits` instead of `max_edits`
same here: no need for the [].
index's toString gives you '[index_name]' no need for '[{}]'
Left over Note
I think we can now remove this condition as the client can not be null because we throw now `new ElasticsearchException("Unable to configure Azure compute service", e);` in the CTOR
``` java || this.secondariesStorageSettings.isEmpty() ``` :crying_cat_face:
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
I think it would have been worth it but now that you mention it - other requests may have changed this in the mean time too, so let's leave this assertion.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
You are already in `ESRestTestCase` so you don't need the to reference the class.
This seems a bit broad.
Here we lose the option to fail if an expected warning didn't materialise. Is that OK? Its conceivable some tests can be certain in their expectations of failure and we do need a way to fail when we fail to fail (so to speak).
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
And we could then just leave an assert here.
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
can we just `return new BytesRef()` in this case? I don't know if the text characters are null if we can really rely on text offset and length? Maybe a better check, not relying on null check is: ``` if (parser.getTextLength() == 0) { return new BytesRef(); } ```
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
you don't have to assert on anything if an exception is expected
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
Ah yeah I suppose that might be ok, in this case it's user-defined input so that's pretty awkward but it beats breaking.
should this be "not mounting...consistently" or "mounting...inconsistently"? But I would think not the current double negative.
> If we felt like testing fromXContent without SearchModule we could implement a super easy mock implementation That we can easily do with a little registry too I think? fromXContent won't depend on SearchModule anyway, that is the point of having a separate registry for only the pieces that fromXContent needs (registered score functions). In the end there isn't a huge difference between the two solutions. there is and will be a lookup method somewhere, but instead of being a method reference as argument, it will be an explicit registry. I find it more readable this way, but I do get how this is just a matter of opinions.
the lookupScoreFunctionParser method allows to use SearchModule as the registry using method references. So effectively we need and already have a registry, but this solution saves us one class as we don't have a separate registry class for score functions.
I have a question: what is wrong with java classes in their own .java file? :) Along with IndicesQUeriesregistry I would call this ScoreFunctionsRegistry probably.
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
> I think we're talking about two different sets of leniency :) ++ :smile:
The worst is how `on` and `no` both parse to legitimate values, very dangerous for transposing typos.
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
We can save object creations here by making the ByteArrayDataInput final and using `ByteArrayDataInput.reset`.
ideally, you should read directly into `scrach.bytes` instead of allocating a `byte[]`
Yeah, I checked https://github.com/torvalds/linux/blob/9705596d08ac87c18aee32cc97f2783b7d14624e/include/uapi/asm-generic/unistd.h and they all look right to me.
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
gotcha, thanks for explaining.
Can we call this just `score`? I've been trying to give the script context identifiers names that don't include "script" since that is implicit.
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
thinking out loud, maybe I am getting confused, but in order for a field to get highlighted, doesn't it need to be stored too or we need to have the _source at least? but metadata fields, which match `*` are not part of the `_source` hence they need to be stored or excluded from highlighting by definition. I have the feeling we should do something more to address that...
debug or info? I would be more for debug
the == false is done on purpose to make these comparisons more explicit
More indentation that is hard for me to read.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
I don't think the compile script should be stashed here. Instead, just check that the script can be resolved with the script service (don't just check inline; for example, it would then also ensure if they use a file script it exists).
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
I think s/lang/defaultLang/
same here, just `this.charFilters.add(new NameOrDefinition(charFilter));`
+1 much better than the while loops in the rest action
this new exception is going to trigger errors too if we try to serialize it to an older node
this can only be a runtime exception you can just bubble it up no need to use `convertToRuntime`
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
I think it is fine: we only build one search context per request per shard.
Nit: please add spaces after the `if` and before the `{`.
Nit: please add spaces after the `for` and before the `{`.
Nit: please add a space before the `,` separating the function arguments.
I think we should move this above the nodeChannels.close() so it will be logged before an eventual consequence.
nit: let's just log the index here (so we get the uuid and such with Nik's latest change)
the generic thread pull should never reject, unless it's shut down. that's it's semantics. I would also vote for a trace log in the raiseNodeDisconnected, but that's another change :) It's just confusing imo if you shut down a cluster and see these messages.
is this always used in an assertBusy context? wonder if we should add it here. This can be suprising...
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
you can just use a glob here ie: ``` blobNamePrefix = blobNamePrefix == null ? "" : blobNamePrefix; try (DirectoryStream<Path> stream = Files.newDirectoryStream(path, blobNamePrefix + "*") { //.... } ```
Construction now loses the side effect of a `NullPointerException` when this class is misused by giving `null` values for everything except `sourcePath`, which could lead to new, unexpected `NullPointerException`s upon use.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
can we maybe try to trigger this differently? I mean can we for instance try to call `#available()` or can we maybe read the first byte on open and wrap in a `BufferedInputStream` and then do this: ```Java InputStream stream = is.isMarkSupported() ? is : new BufferedInputStream(is); // do the following in doPrivileged? stream.mark(1); stream.skip(1); stream.reset(); return stream; ```
if we run into an exception here we have to close the stream. we usually do this: ```Java boolean success = false; try { // do something with the stream success = true; return stream; } finally { if (success == false) { IOUtils.closeWhileHandlingException(stream); } }
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
Nit: " . " -> ". "
Typo: "temporary" -> "temporarily"
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Ahh, sorry. You are 100% correct.
Sorry, I overlooked the null check. This is good!
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
I think you can just initialize to null
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
use simpler constructor.
I think this is easier to understand as it makes a 1-1 copy of the current active shard allocations in the routing table: ``` for (IndexShardRoutingTable shardRoutings : indexRoutingTable) { Set<AllocationId> activeShards = shardRoutings.activeShards().stream() .map(shardRouting -> shardRouting.allocationId()) .filter(allocationId -> allocationId != null) .collect(Collectors.toSet()); if (activeShards.isEmpty() == false && activeShards.equals(indexMetaData.getActiveShards(shardRoutings.shardId().id())) == false) { // only update active allocation ids if there is an active shard if (indexMetaDataBuilder == null) { indexMetaDataBuilder = IndexMetaData.builder(indexMetaData); } indexMetaDataBuilder.setActiveAllocations(shardRoutings.shardId().id(), activeShards); } } ```
new is not possible with an older version...
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
err I guess you need to have failures added first so second...
I'd feel better if the `latch.countDown()` would be the first line in the catch block
I'd also like a test for the case that either a single bound or none of the bounds are specified (even if that means checking that an exception is thrown depending on the decision we make).
rather use `logger.debug` than `System.out`
Should we also have tests for the case that some intermediate mappers already exist? For instance above you are testing to index a field called `foo.bar.baz`, so it would be interesting to check that everything also works if `foo` already exists.
would it make sense to add this nice iterator to core? the ingest plugin could reuse it in this case.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
I think this is expected to be a sorted list on the `job_id`.
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
Ah ok, I missing that method below, sorry.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
I think this should throw IAE if you pass null - that's 100% of the time a bug
fyi, I removed the ZeroTermsQuery class from MatchQueryBuilder entirely in #13402, moved everything plus serialization to #13402, so we might remove this setter and only have one.
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
s/to list of/to the list of/
Oh, that error handling!
let's keep as is, with the assertion message I think it's ok. I wonder if we should have an assertion at the end of this method to say something like "if we have an active primary shard that's not relocating, then the replication tracker is in primary mode".
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
ok can we rename the getter then to `getFailedNodeExceptions()`
We should make TaskInfo final then.
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
Another `_` java 9 will be mad at
This is logic that I think should go into ReplicatedOperation.
shall we test POSITIVE_INFINITY too? seems like we return null for that too but the default value once parsed is only one...
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
This assumes a version format that while fairly standard is not guaranteed.
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
Sure, good plan.
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I think this method is not quite right yet. A few observations: - if (unassigned) primary, then finalExplanation / finalDecision should be influenced by staleness of copy. In case of a replica, however, staleness does not influence allocation decision. - if replica, then we can still show that store copy is corrupt / has an io / error without influencing final decision / explanation - for the primary / replica shard allocator, corrupt / io_error is treated as no data. I think we can first calculate store copy (which just represents the status on disk) and then influence finalExpl / finalDecision based on that. Here is my go at it: ``` public static NodeExplanation calculateNodeExplanation(ShardRouting shard, DiscoveryNode node, Decision nodeDecision, Float nodeWeight, IndicesShardStoresResponse.StoreStatus storeStatus, String assignedNodeId, Set<String> activeAllocationIds) { final StoreCopy storeCopy; if (storeStatus == null) { // No copies of the data storeCopy = StoreCopy.NONE; } else { final Throwable storeErr = storeStatus.getStoreException(); if (storeErr != null) { if (ExceptionsHelper.unwrapCause(storeErr) instanceof CorruptIndexException) { storeCopy = StoreCopy.CORRUPT; } else { storeCopy = StoreCopy.IO_ERROR; } } else if (activeAllocationIds.isEmpty()) { // The ids are only empty if dealing with a legacy index // TODO: fetch the shard state versions and display here? storeCopy = StoreCopy.UNKNOWN; } else if (activeAllocationIds.contains(storeStatus.getAllocationId())) { storeCopy = StoreCopy.AVAILABLE; } else { // Otherwise, this is a stale copy of the data (allocation ids don't match) storeCopy = StoreCopy.STALE; } } final FinalDecision finalDecision; final String finalExplanation; if (node.getId().equals(assignedNodeId)) { finalDecision = FinalDecision.ALREADY_ASSIGNED; finalExplanation = "the shard is already assigned to this node"; } else if (shard.primary() && shard.unassigned() && storeCopy == StoreCopy.STALE) { finalExplanation = "the copy of the shard is stale, allocation ids do not match"; finalDecision = FinalDecision.NO; } else { if (nodeDecision.type() == Decision.Type.NO) { finalDecision = FinalDecision.NO; finalExplanation = "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision"; } else { finalDecision = FinalDecision.YES; if (storeCopy == StoreCopy.AVAILABLE) { finalExplanation = "the shard can be assigned and the node contains a valid copy of the shard data"; } else { finalExplanation = "the shard can be assigned"; } } } return new NodeExplanation(node, nodeDecision, nodeWeight, storeStatus, finalDecision, finalExplanation, storeCopy); } ```
I think this should explain why shard fetching is preventing allocation (otherwise this message will be too cryptic for the user). For primary shards it is to determine which nodes have a non-stale copy of the data. For replica shards it is to determine which nodes have a copy of the data and which copy shares the most data with the primary to speed up recovery.
Looking at the overall code of `calculateNodeExplanation` again, I think we should also improve the message in case where the shard can be assigned but we have throttling. Can be a follow-up.
oh oh I hadn't read your reply when I replied ;)
can `aliases` be final as well
Might be better to use the default of the request (in this case this coincides, but explicit is better in case of refactoring): getSnapshotsRequest.ignoreUnavailable(request.paramAsBoolean("ignore_unavailable", getSnapshotsRequest.ignoreUnavailable());
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
removed? It does not seem to be used.
I can push the change if you don't have it ready yet.
No, it cannot be private, since it's used by `AttachmentProcessor` in the same package. That was the part that I was missing. I think its misleading.
I think that we should have left an assertion here that the Java version is not JDK 11 (I think we will be able to remove this for JDK 11). I also think that this code should have been guarded by an if block checking that we are on JDK 10 and otherwise not add this permission.
and 2 more occurrences below
too many shards already allocated to this node for index ...
I believe this message needs to be changed now, since the first value is the "used" value now
I think this assertion should be in `getAnyNodeExcept()` - it's ok to return an empty list here.
maybe inject failure both before or after executing the actual action.
I think I'd prefer two tests to test these two paths.
then do something like this `source[n/a max source size: ...`
I like including the original size here. Maybe instead if the source is chopped it should read like `first 2048 characters out of 10122123: _slice_of_the_source_`.
I don't think we need the exact number of bytes and if bytes is what we have we should use it. No reason to work hard to get characters.
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
Oh I see, it's the ZTable stuff. Sorry for the noise :)
interesting, what is the reason for this funny upper bound? :)
For the record, I'm asking because I expect the setter to be called once while these create methods can be called _many_ times
This test is not really testing what we want to be testing here. The reason that it's not is because the cache key for a file named `".hidden_file"` is not `"hidden_file"`, but rather it is `""`. A file named `".hidden_file"` never would have been processed by the compilation engine because it doesn't have an extension. So this will ultimately throw, but not for the right reason.
We will need stronger assertions here too.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
I understand this is the oversight you've mentioned
I don't mind as long as we use `writeString/readString` and `writeOptionalString/readOptionalString` consistently. So you can maybe just change the `readFrom` to explicitly use readBoolean.
can we call the latch in a finally block just to be absolutely sure
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
use `localNode.equals(incomingObject)` we know that `localnode` is non-null
I mean to say that I think you can just call `Strings#toString`.
The second one, implement toString with the utility. On May 8, 2016 9:28 PM, "Johnny Lim" notifications@github.com wrote: > In core/src/main/java/org/elasticsearch/action/get/GetResponse.java > https://github.com/elastic/elasticsearch/pull/18102#discussion_r62442944 > : > > > @@ -168,4 +169,17 @@ public void writeTo(StreamOutput out) throws IOException { > > super.writeTo(out); > > getResult.writeTo(out); > > } > > + > > - @Override > > - public String toString() { > > - try { > > @nik9000 https://github.com/nik9000 Are you suggesting not implementing > SearchResponse.toString() but using Strings.toString() in application > code, or implementing SearchResponse.toString() via using > Strings.toString()? > > â > You are receiving this because you were mentioned. > Reply to this email directly or view it on GitHub > https://github.com/elastic/elasticsearch/pull/18102/files/c5f0c73b8b0f9c57500656081005aa64e28f509b#r62442944
I think this is the same as `Strings.toString(this)`? Otherwise I think this looks fine.
I get that, I was just wondering why those default templates bother here
cool stuff I didn't see that one!
maybe in a followup we can think about removing these -1s... see what platforms fail, and better fine-grain the stuff (e.g. add assumption for WINDOWS, IBM jdk, whatever it might be). Then we know when and where stats are available.
well.. as I said, **IMO** the separation is cleaner. But if you keep the prototype way, you'll eventually need to keep the current `build()` method and introduce a new `Processor build(Map)` method **next** to it... it's a bit messy tbh... the same applies to the `Pipeline.Builder`. Another option is leave things as they are (so leave the current `void fromMap(Map)` method) and then introduce a factory to a builder... however you look at it, we need a factory somewhere... a construct that is registered by "type" that can create the appropriate builder/processor for that type... something along the lines of: ``` Processor.Builder builder = registry.get("type").create(); ``` Another option is to mandate all builders to have an empty ctor and use reflection to create those. So instead of injecting a set of builders, you'd work with a set of builder classes and then the code will just create new instances using reflection on default ctor.
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
I like including the original size here. Maybe instead if the source is chopped it should read like `first 2048 characters out of 10122123: _slice_of_the_source_`.
I don't think we need the exact number of bytes and if bytes is what we have we should use it. No reason to work hard to get characters.
we should be careful here and check for sources that are binary (SMILE etc..)
space missing before `new Named...`
space missing before `new Named...`
here is a space missing before `new NamedAnalyzer`
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
The shapeFieldMapper seems unused here.
same problem as above I think, only that unmatched closing brackets will create holes here.
Ok, I see. Nevermind, since its a private method I leave it up to you to change or not, I was confused a bit but the method is short enough to understand what its doing.
Good point, I forgot about the pretty printing. `equalToIgnoringWhiteSpace` sounds good.
I'd prefer to have a simple `assertEquals` and to a String comparison here. No need for all the constants either, makes it harder to read IMHO.
I don't think you need to explicitely test toXContent, this is done by toString implicitely and this is the change that we want to check.
> I don't have a strong opinion on this one either way I do because less code that is easy to understand is easier to maintain than more code. ð¼
I think that since you're deferring to `Objects.equals` anyway all the other checks above can be removed.
You're right, I confused myself.
`this` is unnecessary
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
oh damned it's BWC I guess...
here you may be able to use copyCurrentStructure
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
can the aid matching be the implementation and the rest just assertions ? it should be enough
I wonder if with this change you can remove `UpdateHelper.Operation` entirely and just use `DocWriteResult.Operation`. I'm not sure it'd be clear to use `CREATE` instead of `UPSERT` in all the places though.
it's a shame we have to wrap the call back here, but I don't see how to simplify this without doing something not nice instead, like making the PrimaryShardRefernce having a non-final releasable field...
I think that `node);` fits in the previous line
I think we use the empty string somewhere yes, not sure if that was a wise choice. I don't mind leaving null, no biggie
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
minor semantic difference: over [here](https://github.com/s1monw/elasticsearch/blob/fix_recovery_finalization/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java#L304) we throw the unwrapped corruption exception, not the remote version. I think we should do the same here and throw corruptIndexException
typo, all flies -> files
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
no utils for this :( `out.writeLongArray()` maybe :)
I'd just do `sum += Math.max(0, data[1])`
maybe omit lowercase from the method names here? (since these tests also run for uppercase and trim)
maybe like this: ``` Java try { IOUtils.close(() -> processes.stream().map(s -> (Closeable)s::destroy).iterator()); } finally { processes.clear(); } ```
or rather pass it to `spawnNativePluginControllers` and change it's signature to `spawnNativePluginControllers(Path pluginPath, Map<String,String> env)` I don't think we need to depend on `Environment`
can we make the environment variables passed on to this configurable ie. as ctor arguments? I also wonder if the variable should be prefixed with `ES_`
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
I think we should throw an exception when `id < 0`, which should never happen? (unless Bad Stuffâ¢)
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
even though this is just `debug`, logging an encryption key is worrisome
Let's make this an `UncheckedIOException` too.
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
I think that we need to guard against overflow here!
This is not quite what I think of as exponential backoff. The problem that I see with an implementation like this is that we can have a thundering herd problem. If there is some failure that causes a bunch of tasks to simultaneously fail (e.g., say that we have a bunch of outstanding fetch tasks waiting for a response, and the network connection breaks, failing all of them), all of the retries will keep waking up at the same time, itself potentially causing issues due to a herd. Typically it would be that there is a random component in exponential backoff, to avoid this herding. As a first approach, what I suggest here is: choose a random value k between 0 and 2^number of retries - 1. Then retry after k * delay seconds. We can cap this at max retry delay.
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
I wonder if this should rather be made part of Request#multiSearch like we did for bulk. I see that it may be nice to have read and write methods close to each other, on the other hand the only place where we need to write this format is in our client.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
Please fix identation.
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
no i do not. but this IDE cannot compromise the actual build, which is 'gradle check'. changing tests.seed in this way can compromise the build, because then the values for other things looking for this (such as lucene) depends on class initialization order.
don't change tests.seed, i dont care what intellij does, this is wrong to do.
I think we should use `writeAtomic` everywhere just to reduce the complexity.
I think we should remove all these boolean and pass an set of flags as a vararg... It becomes less and less readable (not in this PR)
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
Now that I'm seeing these, I wonder if the default names should be `attr` and `value`. We could add aliases if we need longer. Since it's such a small API it's probably fine with the short versions.
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
We will need stronger assertions here too.
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding jvm plugin [{}]", plugin.v1()); } ```
why do you pass the response to this method? `this` already has all information.
this breaks backwards compatibility, you will need if based on version in both `readFrom` and `writeTo`
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
here too, sorry :)
This is confusing is what this is.
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
This logging statement has a `[{}]` but no argument to fill it
Nice, I like the randomization on the thread pool.
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
At this point I don't know that `@param` adds anything either.
nit: can we call it getParseFieldMatcher? now that we have an interface it should be easy to rename all the existing impls at the same time. If you feel like it should be a follow-up, I am fine with that.
We did used to do this but we've moved away from it. So you'll see examples in the code when we had this but it is no longer the preferred way.
import not needed.
Same concern about reproducibility as in the other PR.
> Makes sense? It does not make sense. Having try/catch like this means the test doesn't really know what it is testing.
good point! I think we need to iterate over the filterFunctionBuilders and rewrite their corresponding filters
you are the man! that is awesome!!! that should just work. I really wonder if we can build a BWC test index with a percolator that ensures we can read this stuff if would be awesome to have asuch a test
looks like it can be final
would you mind reverting the variable name change, at least temporarily? it confuses the review
Sure, good plan.
On deeper thought, this seems unduly lenient: it should only return credentials for the role that `GET /latest/meta-data/iam/security-credentials/` returned, and should return 404 otherwise. Also I think `credentialResponseFunction` can be inlined, it's only used in one place. Also also we could prevent cheating slightly more by inventing random credentials when the service starts up, rather than synthesising them from the role name.
Or do it as a direct followup, I suppose.
you can have a look at SimpleQueryStringBuilder.VERSION_5_1_0_UNRELEASED to see how to do it
new is not possible with an older version...
same here, might be that we are good, but let's make sure we don't lose the STRICT one
are we losing the STRICT bit here? it's important that we use STRICT here, so we make sure that we never output deprecated stuff ourselves. and we test deprecations separately.
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
nit: space before brackets
typo: optain -> obtain
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
As far as I understand in the REST layer, we don't print out any index for which there are no aliases to return, but only in case the alias (name) parameter was provided.(https://github.com/elastic/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/rest/action/admin/indices/RestGetAliasesAction.java#L139). I believe this change tries to mimic the same behaviour for the transport client, but in the REST layer we don't look at what the name parameter matches, only at whether it's provided or not: ``` curl localhost:9200/_alias?pretty { "index2" : { "aliases" : { } }, "index" : { "aliases" : { "alias" : { } } } } curl localhost:9200/_alias/_all?pretty { "index" : { "aliases" : { "alias" : { } } } } ``` That may be right or wrong, but I think we should try to return the same results if we make this change, so I'd say without changing the behaviour at REST (although we may want to discuss what the right thing to do is) the best we can do at transport is to only look at whether any specific alias was requested rather than whether the expression matched all or not. Furthermore, I'd expect that once these changes are made to `MetaData`, the REST action should be updated as some logic can be removed? By the way, related but it should not affect this PR, there's also #28799 under review that is moving the REST logic to the transport layer, yet the REST logic remains in `GetAliasesResponse#toXContent` which doesn't change what the transport client returns. I would probably consider renaming the `AliasesRequest#aliases` method (to `replaceAliases`?) and make sure that it's only used internally (although it needs to be public), and have users call the current setter. We clearly can't have both call the same method or we lose information about what was set in the first place. That would make it possible to keep track of whether specific aliases were requested or not through a flag, similarly to what you do now.
should be action
can `aliases` be final as well
I think this message might be misleading.
I think this missed a misses a maybeFailEngine
I think we should, yes
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Feel like this should be more significant than `debug` because it really indicates a form of failure in some scenarios.
It'd be better, to only skip the config files that have the same name, not the whole directory. So for example, if currently es has a config dir that looks like this (for plugins `foo`): ``` /config/foo/bar.yml ``` and the new plugin that installs needs to copy two files there: ``` /config/foo/bar.yml /config/foo/baz.yml ``` we'll skip `bar.yml` but we'll still copy `baz.yml`. This will help us a lot when we guide the user on how to upgrade - instead of telling the user, to copy & modify a bunch of files, we'll only need to tell him to modify files under `config/foo`
I think we should fix our datastrucuture first and don't make Path trie super complicated and flexible. This should be fixed first before we make this change here.
I'm afraid this won't work - you only want to decrement this when someone responds to the channel... it needs to be built into the RestChannel..
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
I am not sure why you changed this.
Can we also defer to `super.nodeSettings(nodeOrdinal)` so we don't also need to set `DISCOVERY_HOSTS_PROVIDER_SETTING` and `MAX_LOCAL_STORAGE_NODES_SETTING` here? (This also picks up a correct value for `DISCOVERY_ZEN_PING_UNICAST_HOSTS_SETTING`).
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
Do we need this? the settings are already immutable
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
see text from other suggestion for empty primary allocation
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
Here it still says `on a per index basis` -> should be corrected.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
can we implement `Closeable` and use an AtomicBoolean to signal it's closed I like the `if (closed.compareAndSet(false, true))` pattern
Looks good. Thanks :)
The other `BUFFER_SIZE_SETTING` (~ line 111) must also be updated. (I hate those settings overrides...)
Oh nevermind, `CodecUtil.checkHeader` is already doing the real check. You really do not trust anyone ;)
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
If that's the case, we don't need - that's making sure :D - where do you see it's done in ESTestCase? (I didn't check myself)
please make sure all files closed and no file is leaked.
Same here. It might be better to make this `TRACE`.
I think this can be optimized further. Here we are updating status of shards that are participating in the restore process. There are only two possible outcome of this operation for a snapshot itâs ether done when all shards are done or it is not done. It doesnât matter if we are applying a single shard or multiple shards â there is still only one outcome per snapshot. If a snapshot is done we need to check if all shards in this snapshot has started and if they are not â create a listener. In other words instead of having an array with one element per shard it might make sense to have a map with one element per snapshot.
this can be removed now, no? it will be cause a duplicate with the full cluster state log..
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
If it is relevant for String impls then I don't see why it should not also apply in the long impl.
good catch on delta > 0
As this setting should usually be only set once, it is probably simpler to leave it non-dynamic (as @jasontedor suggested and as it was before this PR). In case where this must absolutely be updated on a production cluster, rolling restart (of master nodes) with config update is always possible.
right thanks for the explaining, I should have known, having worked on the search refactoring :)
fancy pants :)
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
use a try-with resources for the parser value
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
A question out of curiosity: the analyzer we get here doesn't have to be closed (via closeAnalyzer) because its not a new instance? I don't know enough about the lifecycle of these objects yet I'm afraid.
This can maybe go inside the following `else` branch.
Got it. Thanks
There is actually a [standard](http://checkstyle.sourceforge.net/config_modifier.html) for this if you particularly enjoy standards.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
yeah nevermind I was confused about some internal classes
But yeah, keep it now.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
I think I saw this in Christoph's PR too. Hopefully you don't need it.
I don't think you need @Before here, the parent method already has it.
since we catch throwable I think you can scratch the `success` thing and just do the `latch.countDown();` in there? sorry I could have realised that earlier :)
This logging statement has a `[{}]` but no argument to fill it
add the exception? :)
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
last parameter can be set to from.
Can we get back to this once we need this complexity and keep it as simple as possible for now please? Can we hardcode the OBJECT_FIELD_NAME exclusion and be done with it? queries also have access to individual field names if they need that.
it's a minor thing but why would you assign a variable multiple times when it's not needed? default is a better fit here, it improves readability as well.
maybe we could have a `default` here which could make this switch a bit more readable rather than assigning value before the switch in any case.
we can make this catch throwable and remove the catch from https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/rest/RestController.java#L175
can we clean up the other try catch? it's not needed now (as we catch things here too)
I meant that one indeed. GitHub is playing tricks - it didn't show me that change in the same commit (but now it does). Sorry for the noise.
I wonder about the cases where this can happen as the `close` method on `InternalTestCluster` that calls `shutdown` on the executor is synchronized (same as this method). Have you observed this exception being thrown? If we don't expect this to occur under normal operations, I would prefer not to swallow the exception here.
space missing between ) and {
We discussed this on another channel, and decided to only do the auto-bootstrapping when autoManageMinMaster mode is active. We also decided to have multiple nodes participate in / run the bootstrapping process.
I wonder if this case distinction should be part of ReplicatedOperation.
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
ok let's leave it as is for now.
just initialize it and make it final - it just compliicates the code
can we just throw ElasticsearchException since it has the HTTP code baked in and it's also a RT exception
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
++ to talking this through but to put it out there, what I am thinking is that we re-build the user after the lookup. For this case we have PkiUser and LookedUpUser. The final user will be the combination of the PkiUser's metadata, the LookedUpUser's metadata, and the LookedUpUser's roles. The looked up user's metadata would trump the PkiUser's metadata in case of a conflict. This does get trickier when you do this in an AD/LDAP realm since some of the metadata comes from the group resolution. In that case, I would only include the metadata that does not involve group resolution from the authenticating realm.
Not a specific concern, but just more configuration options for the end user when it is not being that effective. The code is trivial and not of maintenance concern so I am fine with we being consistent in all cases.
lets revert this. We do not need it here
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
To be clear - I think we want to know how the oldest file is, regardless of the generations. It will always be the oldest generation and the first in the reader list, but I don't think we want to rely on it. Part of the role of the stats is to validate things are correct.
why did you change this to take a `TranslogGeneration` with the uuid instead of just the `long minGeneration`? It's not using that uuid anywhere here AFAICS.
Just a question: would it be possible to extend from `LongFieldMapper`? Would be nice to have some code reuse.
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
Is this done already? Maybe specify what "sanity checks" means otherwise.
I wonder if `profile` and `explain` should be forbidden too? Both have non-negligible impact on performance, and seem irrelevant to ranking as well.
I would be using a `Set` in this circumstances.
it would be awesome to have some doc-strings on these settings
maybe make this variable final? just better indicate it will never change
ok fair enough...
close is supposed to clear as well so this shouldn't be necessary to call clearReleasables
you can remove the QueryParsingException catch, it's unreachable
this part of the change looks a bit scary to me. I'm wondering how hard it would be to do this 'state' management and wrapping of collectors outside of IndexSearcher so that we don't have to check what the query is.
Here you can do something like this: ```diff diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java index 356b9a29dc..36794e880f 100644 --- a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java +++ b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java @@ -65,9 +65,11 @@ public class PublishClusterStateStats implements Writeable, ToXContentObject { @Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException { builder.startObject("published_cluster_states"); - builder.field("full_states", fullClusterStateReceivedCount); - builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); - builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + { + builder.field("full_states", fullClusterStateReceivedCount); + builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); + builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + } builder.endObject(); return builder; } ``` which makes the JSON-structure clearer in the code.
This method can be package-private.
Nit - strictly speaking these are publishing stats, can we open the object with just published cluster stats (drop received). You can maybe received back in the keys, which can be shorted by dropping the cluster states from the key names - itâs implied from the object theyâre in.
maybe just push the `maxUnsafeAutoIdTimestamp` up to engine and make the methods final
if we do this, why did we need to change how createNewEngine behaved (i.e., update currentEngineReference etc.)
I looked at the implications of exposing an engine that isn't fully recovered yet and it's OK, with the exception of syncFlush(). Depending how this ends up being, we may need to make sure that runs under a permit.
do we want to unify this code with the refresh method by making this get a manager to work on? (+ a string description for failures)
I think we should return active.get() == false and also - set it if we became idle...
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
ok fair enough
for readability I'd use this. as well
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
while we are at it, can we move this log to debug? its very noisy and it can happen with join retry logic
the start cluster does this.
Nit: `accross` -> `across`
Probably should also be getAssignedNodeId.
I like this style. I think I'm going to steal it.
ok can we rename the getter then to `getFailedNodeExceptions()`
NIT: Noisy reformatting
I like `hasSize` better for this because it gives a nicer error message on failure.
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
But yeah, keep it now.
Typo: "Dynamics" -> "Dynamic"
Should we add a `default:` clause just in case here? It looks like the original code had one
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
you can remove the validate call for now, we will fix all queries soon, I promise
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
I think we should stick to the current validate api for now, although it does feel weird that we don't actually throw exception. What happens is that the listener gets notified of the exception in `TransportAction#execute`. We can't yet hook into the validate mechanism as the `SearchRequest` only contains a `source` bytes array in json format, but at the end of the refactoring we should have different elements that hold the different parts of a search request, among which the query which can be validated as part of `SearchRequest#validate`. This is to me the only way to make sure that validation happens whenever needed.
sorry for changing my mind, what do you think about having our own exception here e.g. `QueryValidationException` ? when we'll hook into the search request validation we can just wrap it in the ActionRequestValidationException or something along those lines. I wouldn't query builders to depend on transport action packages ideally.
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
we can delete ForceMergeFailedEngineException now, right? It's not used.
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
Right - RollupIT is the right place
you could use `scriptRequest.setJsonEntity`
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
And one more...they seem to be all over, I presume a mistake in regex find/replace.
Space missing between `}` and `is`.
`foo`-> `{@code foo}`
typo: `i` missing. Also, maybe rephrase to something like: `materialized and represent the result columns sent to the client`.
those are hard to debug I can tell u :dancers:
Thank you for cutting over to a better clock :)
Woops, never mind: maybe put params around `status.activeIndexing == false` ;)
Sorry, I overlooked the null check. This is good!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Ahh, sorry. You are 100% correct.
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
More indentation that is hard for me to read.
then check for non null here...
I'd have added an integer to `TypeParser` and sorted them by the integer resolving same integers alphabetically or something. And set the FieldNamesFieldMapper to MAXINT. But I think what you did here is ultimately simpler.
I opened: #23338
update version to beta 1
please ignore - misread the constructor - seems like a null is a valid value.
update version to beta 1
maybe add the type that is found in the error message with fieldType.typeName()
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
fine with me
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
ok, i see it. Its just a little non-obvious due to the way searchers are bubbled up. maybe we can add an assert in the future.
can you try to exercise this method to make sure we open a new searcher and close / release everything
I'm a bit concerned that this will be the case almost all the time except when we wrap. Can we avoid this if statement and just recreate an IndexSearcher all the time? (the else branch)
What about : ``` json "retries": { "bulk": 0, "search": 0, } ``` Note: I tend to like JSON inner objects since clients and parsers can skip whole objects while parsing...
sorry I meant `org.elasticsearch.common.xcontent.ObjectParser` all the time my fault
+1 on using static strings - I didn't realize that the XContentStrings things are not usable when parsing.
I think this message might be misleading.
we can do try-with but we need to have 2 try blocks. since the write lock needs to be released last. but in a try / with blokc it's released before the finally block is executed
Typo, finalzlie -> finalize
could be a instance variable, as used in all tests
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
Maybe it always should have been....
I'd prefer `param.substring("the 13 character string".length());` or something like that.
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
Can you shrink-wrap this try clause? (Pull the `map.put` out after it.)
It's expected that some files will sometimes be gone here, because `IndexWriter` is actively changing the index while this reader has a point-in-time snapshot open. Maybe we catch `FileNotFoundException` and `NoSuchFileException` and don't log (even trace) those ones? Any other `IOException` we should log.
Actually, I think IW should not remove files that are being used by NRT readers (we fixed this a while back in Lucene), so I think we should continue to log the exception, but can you increase log level to WARN? Also, can you shrink wrap the exception handling? Put one try/finally around the `listAll`, and another on the `directory.fileLength`? And include in the exception message which directory (`directory.toString()`) and which file caused an exception.
I think this check should go into initializeSnapshot or repository.
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
I think we have this logic in the settings already maybe we can factor it out and reuse? seems scary and it would be good to be consistent.
This might read better if it were renamed to `hasRun` initialized with false and then it could be ``` java if (hasRun.compareAndSet(false, true)) { prepareBulkRequest.run(); } ```
Ahh okay, that makes sense, I missed that
Could initialize this with the size of the hits list to prevent resizing
I'd return an Immutable set... it enforce compilation failure when used inappropriately (if the user tries to mutate the set)
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
Do we really need to also duplicate the typed_keys logic here? Can't we just print out the name of the parsed aggregation (it can be initialized with type#name)
maybe add an explicit `continue;` here to indicate that it's being skipped
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
should say shard active
"if if" again
this is unneeded? we check before we call...
why did you decide not to do the approximation we talked about? i.e., `System.nanoTime() - (Math.min(0, System.currentTimeMillis() - this.timestap))* 1000000L;`
Ok great, thanks for the correction @rjernst
It was removed from ParseField in #17933. It also shouldn't be added here.
I'm pretty sure camelCase shouldn't be supported any more.
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
we shouldn't need this here in parse phase
why is this? what's wrong with `1.f`
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
Ok, then it's fine.
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
can you also add ``` @Override public Decision canForceAllocatePrimary(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) { assert shardRouting.primary() : "must not call canForceAllocatePrimary on a non-primary shard " + shardRouting; return canAllocate(shardRouting, node, allocation); } ``` as this is a hard constraint with no exceptions
I would use the following message: "ignored as shard is not being recovered from a snapshot" and not have an explicit check for `shardRouting.primary() == false`. That case is automatically handled by this case too as replica shards are never recovered from snapshot (their recovery source is always PEER).
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
I think that these log parameters are backwards.
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
And i just did not have the time to yet yesterday remove the stupid asserts from SpanScorer. Please, lets not drag this stuff in again. If oyu want to push fine, but you will see a second push from me removing all this crap.
Why do we need the copy-paste at all? This whole thing seems like a code duplication of PayloadTermQuery.
would be great if this logic could be unit tested.
Let's use `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
Let's replace the `assertTrue` by more effective matchers, and replace the `assertEquals` by `assertThat(..., equalTo(...))`.
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I don't think it matters. We should not force making huge changes to the entire codebase in order to not add things which will just be deprecated and/or confusing to the user.
oh oh I hadn't read your reply when I replied ;)
can we clean up the other try catch? it's not needed now (as we catch things here too)
I meant that one indeed. GitHub is playing tricks - it didn't show me that change in the same commit (but now it does). Sorry for the noise.
I would be more precise on the version, cause it's not clear if it is from 1.5.1 or 1.6.0.
you migth want to use //nocommit so maven notifies you when you forget about it ;)
version reminder here too, and s/splitted/split
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
nit: extra line
nit: `== false`
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
is this a leftover? I don't see where this is used outside of tests? and even there I think it's a huge overkill. Can we please remove this entirely. If you really need stuff like this for testing then look at `ThreadContext#setTransient` which you get from a threadpool
I don't think "Not implemented yet" adds anything other the exception type (and could be misleading if we never intend to implement).
This can (and should) be final.
This empty line can go.
ð to this escape hatch
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Not related to this PR but I think that we should check if what we are trying to remove is not part of the BLACKLIST. Someone could potentially provide a plugin which contains his own `bin/elasticsearch` script, which looks scary to me.
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
minor note: we consider shards inactive until the first indexing operation has happen, so I think this part is OK regardless of the change.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
got it. Thanks.
It's better to use variable names with context so for example `check1` could be `keystoreCheck`, etc.
this should happen after we update `isSecurityEnabledByTrialVersion`
Why do we need getters? These are all final and immutable
Ah, I see the dilemma. If you want to encapsulate for that reason, that seems fine. Then please use the naming convention proposed in #14266? ie `settings()`, `environment()`, etc since they are read only
I like dummy because it implies fake and the index is fake - not just empty.
It should say greater than zero, 0 is not permitted.
I think the unlock calls should always be in a finally block
I don't think it changed the readability much - it made the checks simpler but then it left me wondering why two variables were needed. I was doing the "why does this have to be here, let me think hard about it" think.
maybe just `return blobMetaData.length() == fileInfo.length();`
err I guess you need to have failures added first so second...
I'd feel better if the `latch.countDown()` would be the first line in the catch block
In fact, it should probably say something like `Remove the plugin specified by {@code pluginName}.`
The indentation is off here.
Let's drop the uppercase on `Terminal`.
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
I find the boolean condition quite hard to read, maybe negate the whole logic to get rid of all this weird `&&` and `== false`: ``` if (newPrimary.unassigned() || newPrimary.isSameAllocation(oldPrimary) || (oldPrimary.relocating() && newPrimary.isRelocationTargetOf(oldPrimary))) { // same primary term } else { // incrementing the primary term ... } `` ```
Can you add a textual description (makes it easier to understand)? I was wondering for example at first why we don't increase primary term upon full cluster restart (then I noticed we do, as isSameAllocation yields false if oldPrimary is unassigned primary).
I'm happy we have all these tests. It is also another data point to move in the direction we discussed - i.e., failures should mark things as stale.
can we rename this to shouldIgnoreNewClusterState? it's not only about being dated.
can we call this log: ``` received a cluster state from a different master then the current one, ignoring (received {}, current {}) ``` also note that disco nodes already have [] in their toString.
can we extract this logic and the logic above (where we prune/ dedup incoming cluster states), into a static method and unit test it? would make me sleep better :) This is super important.
I think this check should go into initializeSnapshot or repository.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
is there a way to filter out the index metadata here? We just want the global metadata.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
This does not necessarily need to be within a static initialization block.
can we use `== false` instead of `!`
just for kicks can we have `reason = "works around https://bugs.openjdk.java.net/browse/JDK-8034057"` it's just more obvious which bug is meant
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
Hey I saw some updates on this PR and I just wanted to throw a reminder out that we are not going to do a singleton(404) here, because we want a delete that is not found to throw an exception. Also, last time we spoke you were going to change this to AcknowledgedResponse. <3
heh, duh... Sorry, ive been on vacation and full of turkey since last week.
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
just `for (IndexMetaData indexMetaData : state.metaData())`
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
one more thing (sorry!). For the language clients, I think it would be good to also have a small REST test that uses search_type count, just to verify that all of the clients (and our REST layer) still support it.
the logger here should either be static, or passed in the constructor (better, since it will have much more info)
+1 to throwing the exception.
same here - since we have on onFailure handler, calling is the equivalent of re-throwing the exception, imo.
Imho, the interruption is dealt with here. We don't need to bother the code higher up with it.
I think 0 is a good minimum value.
We call them "master nodes" everywhere else. :frowning:
right thanks for the explaining, I should have known, having worked on the search refactoring :)
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
shouldn't we use here `!REST_EXCEPTION_SKIP_STACK_TRACE_DEFAULT` instead of `false`
I think you can just initialize to null
marks the shard store
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
ð much better readable
instead of this check just override `public void onRejection(Throwable t)`
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
No, you are right, I didn't realize the need for api users before going through the whole changes.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
you are perfectly right Christoph, let's merge the two and keep the existing class.
maybe also test a nested conditional setup? (So have conditional and then another conditional in the matched or unmatched list)
after rebase you will have to get rid of any wildcard import, or the build fails :)
I prefer `assertEquals` in cases like this. `assertThat` is great if you need to take a matcher or want to assert something complicated, but I like `assertEquals` for equality.
if you do not supply the the content-type, you can just hand over the builder and do not need to create a string object here. Also I would just return `JSON is disabled` instead of mentioning the config option here. The shorter the better IMO.
Minor nitpick 3: You could put the two if-statements into a long one making this diff really small
I can't come up with any more seriousness :)
We can't safely say that all such exceptions will extend `ElasticsearchException` (e.g., a bad `NullPointerException`), but I like your idea of wrapping the ones that do not extend (as long as it's not wrapping it in an exception that sounds like the user can do something about it).
> Would using `ExceptionsHelper#convertToElastic(...)` helper method in `ConfigurationUtils#newConfigurationException(...)` or similar here be sufficient? +1
Please don't lose the original exception. It's already difficult enough to debug script exceptions without them being swallowed.
Below is what I get when I try it out. As you can see that log message is drowned in many other log messages that don't mention the index name. A lot of this is guice and we're working on fixing it, but I think the easiest is to make sure that the index name is mentioned in the exception for now? people won't see it otherwise. ``` [2016-11-03T00:08:29,112][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... a terminal screen worth of stack trace here ... Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] .... [2016-11-03T00:08:29,144][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,146][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal screen worth of output [2016-11-03T00:08:29,161][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,161][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.archiveBrokenIndexSettings(MetaDataIndexUpgradeService.java:171) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:81) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] [2016-11-03T00:08:29,229][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main] org.elasticsearch.bootstrap.StartupException: org.elasticsearch.common.inject.CreationException: Guice creation errors: 1) Error injecting constructor, java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] <--- THESE IS REPEATED 4 times at org.elasticsearch.gateway.GatewayMetaState.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayMetaState for parameter 4 at org.elasticsearch.gateway.GatewayService.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayService ... another terminal, this time full of guice information Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) at org.elasticsearch.common.settings.Setting$$Lambda$183/2092885124.apply(Unknown Source) at org.elasticsearch.common.settings.Setting.get(Setting.java:312) at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:525) ... 47 more And this ^^^ is the last message on the screen. ```
I think this should be at debug level
Fall back to _old_ behavior
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
remove this additional line break? :)
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
save -> safe
OK. > On 20 Jul 2015, at 14:01, Shay Banon notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java: > > > ## > > - AsyncShardFetch<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> fetch = asyncFetchStarted.get(shard.shardId()); > > - if (fetch == null) { > > - fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction); > > - asyncFetchStarted.put(shard.shardId(), fetch); > > - } > > - AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId())); > > - if (shardState.hasData() == false) { > > - logger.trace("{}: ignoring allocation, still fetching shard started state", shard); > > - unassignedIterator.remove(); > > - routingNodes.ignoredUnassigned().add(shard); > > - continue; > > - } > > - shardState.processAllocation(allocation); > > - changed |= primaryShardAllocator.allocateUnassigned(allocation); > > - changed |= replicaShardAllocator.allocateUnassigned(allocation); > > I will do the assert when I remove the primaryAllocated flag in a different change > > â > Reply to this email directly or view it on GitHub.
can we add an assertion going out that going out of the primary shard allocator we don't have any primary shards in the unassigned list, unless we expect them to be there? (primaryAllocatedPostApi is false or restoreSource != null)
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
last parameter can be set to from.
if we use millis then we really should make sure that time doesn't go backwards!
no need for this to be public
I would use System.currentTimeInMillis, nanoTime has different semantics
`curWrnHeaderSize` -> `currentWarningHeaderSize`
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
The user already expects if they have set this setting that warning headers will be truncated. Therefore, I don't think we should do this, losing a warning header (or more) at the expense of a warning header saying that there are more warnings that can be found in the logs. Instead I think that we should log (in the main Elasticsearch log) when we truncate.
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
It'd be "more normal" to declare this as `Writeable` and use `readOptionalWriteable` and `writeOptionalWriteable`. You've done plenty in this PR so it can wait though!
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
We tend to prefer `false ==` over `!` because it is harder to miss the `!`.
It's frustrating that we cannot share this code with SearchRequestBuiler.
could be a instance variable, as used in all tests
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
does this need to be public and also does this class need to be subclassable
Is it right to just eat the exception thrown from the listener? At least log a warning or something.
> I have just moved code around, so this implementation is not new. Fair enough. I'd still log a warning just to help debug any mistakes in the listener. If all goes well and the listener catches any exceptions then we will never call it.
Could you make the reduction create a new aggregation instead of filling the first one? This proved to be error-prone in the past.
similar concern about in-place reduction
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
`seqno` -> `_seq_no`
Nit: `primary term` -> `_primary_term`
I think you want (soft)deleted
nevermind I see it was already there, then it should be ok
clarify the error message specifying what needs to be non null? the inner query...also remove empty, doesnt make sense here
alright that's what I thought too, sounds good
Please do not drop stack traces; `Throwable#getMessage` is an abomination.
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
typo: dictionnary -> dictionary
we could pass a glob with regex:xxx to newDirectoryStream if we want
you can just use a glob here ie: ``` blobNamePrefix = blobNamePrefix == null ? "" : blobNamePrefix; try (DirectoryStream<Path> stream = Files.newDirectoryStream(path, blobNamePrefix + "*") { //.... } ```
fair enough, leave it.
this class could be made `final`
Nit: this blank line is extraneous.
You are already in `ESRestTestCase` so you don't need the to reference the class.
This seems a bit broad.
Here we lose the option to fail if an expected warning didn't materialise. Is that OK? Its conceivable some tests can be certain in their expectations of failure and we do need a way to fail when we fail to fail (so to speak).
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
maybe just inline this into the `planIndexingAsNonPrimary` method? I think that would be cleaner.
Nit: this does not need to be on a separate line
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Do we really need this randomization? seems like the wrong place to test the version created setting is working properly.
new is not possible with an older version...
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
yes lets do it later otherwise we have to remove setters and break things.
sure things changes now that we know for sure the target branch, that said making everything final would be better to do once we merged back to master to prevent merge conflicts here. Same with renaming XYZQueryBuilder to XYZQuery, and moving to proper getters and setters.
I think it can be even less in tests. No one is worried about sending multiple requests there.
can we make this configurable? also 500 millis is way too small and will busy spin. I guess 10s ? (the real solutions will be to have long polling, but that will come later).
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
this curly bracket should be on the previous line
No, you are right, I didn't realize the need for api users before going through the whole changes.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
we can pass along a reason to persistence to be used as writeReason
It's currently remote controlled by the creation of oldShardStateMetadata in updateRoutingEntry. If we want to keep the optional persistence based on the previous state, we can do it directly on currentRouting have it all in one place (either in updateRoutingEntry, or replacing persistMetadata. Something like this: ``` if (persistState) { final String writeReason; if (newRouting.active() == false) { logger.trace("skipping state persistence as it's not active"); writeReason = null; } else if (currentRouting == null) { writeReason = "freshly started, version [" + newRouting.version() + "]"; } else if (currentRouting.version() < newRouting.version()) { writeReason = "version changed from [" + currentRouting.version() + "] to [" + newRouting.version() + "]"; } else if (currentRouting.equals(newRouting) == false) { writeReason = "routing changed from " + currentRouting + "] to " + newRouting; } else { logger.trace("skip writing shard state. previous version:[{}] current version: [{}]",currentRouting.version(), newRouting.version()); writeReason = null; } if (writeReason != null) { final ShardStateMetaData shardStateMetaData = new ShardStateMetaData(newRouting.version(), newRouting.primary(), getIndexUUID()); try { ShardStateMetaData.write(logger, writeReason, shardId, shardStateMetaData, currentRouting != null, nodeEnv.shardPaths(shardId)); } catch (IOException e) { // this is how we used to handle it.... :( logger.warn("failed to write shard state for shard " + shardId, e); // we failed to write the shard state, we will try and write // it next time... } } } ```
`s/shadow replicas/shadow shards/`
s/payload is/payloads are
s/payload is/payloads are
I see, so parser always sets both "order" and "mode", regardless of whether they are set by the user. But what if we only go through the java api, use a plain builder and set "reverse = false". Translated to json this should give us "mode = MIN", but only if not explicitely set by the user otherwise, no? Sorry, haven't got a good solution myself so far either.
Nit: `reject` -> `rejected`
ok let's leave it as is for now.
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
oh, the boxing horrors :)
here we could use sublists again - just scan to the place you need. No need to reverse then.
removed can just be a count. We always remove from the beginning of the queue.
++ to talking this through but to put it out there, what I am thinking is that we re-build the user after the lookup. For this case we have PkiUser and LookedUpUser. The final user will be the combination of the PkiUser's metadata, the LookedUpUser's metadata, and the LookedUpUser's roles. The looked up user's metadata would trump the PkiUser's metadata in case of a conflict. This does get trickier when you do this in an AD/LDAP realm since some of the metadata comes from the group resolution. In that case, I would only include the metadata that does not involve group resolution from the authenticating realm.
Not a specific concern, but just more configuration options for the end user when it is not being that effective. The code is trivial and not of maintenance concern so I am fine with we being consistent in all cases.
Nit: Needs a blank line.
ok can we rename the getter then to `getFailedNodeExceptions()`
Optional: darkon has this style that I like where you start a new block every time you startObject or startArray and it makes these much more readable!
extra space makes everything not line up!
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
There's an extraneous blank line here.
I think that `node);` fits in the previous line
I think a nicer approach (can be a follow-up done by me) would be not to call `updateGlobalCheckpointOnReplica` here, but instead call ``` globalCheckpointTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED); ``` either here or in the IndexShard constructor (where we create the GlobalCheckpointTracker) when the recovery source is EMPTY_STORE.
I would prefer not to call `updateGlobalCheckpointOnReplica` on the `GlobalCheckpointTracker` if the shard is a blessed primary. A shard that's created from snapshot / local_store / local_shards is by definition blessed from the master. It should just activate the tracker. The activation logic for a replica can be different than for a primary.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
I don't see NO_MORE_DOCS changing in the future. I don't dislike having NO_MORE_DOCS=MAX_VALUE, it makes the sequences of integers returned by DocIdSetIterator monotonic from -1 (not started) to MAX_VALUE (exhausted) :)
Hmm, this assertion can never fail? (NO_NORE_DOCS is Integer.MAX_VALUE). It looks like the other modes have the same issue, I think the intent was to put a "&&" instead of the "||"
can we use "script_factor" I think it's nicer than the came case
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
is this needed here? I think it does something only when the current token is start array or start object.
we should make this entire class package private and try to contain visibility here as well.
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
ok can you add alls these infos into this class
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
can we add an assert to make sure that highlighterType != null here? it really should since we know that plain highlighter always returns true, but the assert would make it more explicit that it is expected
the == false is done on purpose to make these comparisons more explicit
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
`if (serializedStates != null) {` is no longer needed
can we call this last seen clusterState? it doesn't need to be volatile as it is changed under a lock.
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
`it's` -> `its`
`translogs` -> `translog's`
you can do some streaming java8 magic here.
Same here, I think List is already initialized in L51.
I don't think we should do `__default__` we can pass the default separately...
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
I think that makes sense. Otherwise we may throw an index not found exception if the index patterns the user is interested in does not yet exist.
I don't think this should have been changed
lets revert this. We do not need it here
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
Because a processor may also be wrapped by other processors with on failure definitions.
I like `hasSize` better for this because it gives a nicer error message on failure.
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Autoboxing already happens and I wouldn't worry to much about it considering the depth is not that big. Same for `Linked` vs `Array` (in general arrays are faster except for inserting in the middle as that requires resizing/copying at which the linked structure excels). I think the `Tuple` makes the code a bit more compact and safe (the queues cannot get out of sync) and more readable/simple code always trumps optimization (especially micro ones as here).
Since the index and the Map are associated, how about using only one `Deque` which holds a `Tuple` instead of two `Deque`: ``` Deque<Tuple<Map<String, Object> index>>` queue = ... if (node instanceof Map) { queue.add(new Tuple<>(node, Integer.valueOf(i)); } ```
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
I wonder if this should rather be made part of Request#multiSearch like we did for bulk. I see that it may be nice to have read and write methods close to each other, on the other hand the only place where we need to write this format is in our client.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
+1 then we shouldn't forget about it :)
we should totally not have this method, one more reason to not implement the interface.
Set capacity to `2`
Should we initialize indexBoosts to new ArrayList<>() straight-away instead and remove this null invariant? This if would go away too.
Can you use StreamInput#readList ? You need to check for the version here since this code can receive requests from nodes in previous version. Something like ````if (in.getVersion.onOrAfter(Version.V_6....)````
This should be the version we are going back to, so 6.5. In this PR, disable bwc tests in the root build.gradle file. Then re-enable in the backport, and do a followup to master to re-enable there as well. This minimizes the changes necessary to followup to master (instead of needing to remember and change all the places that have this version constant).
I think we discussed this before, but it didn't change, thus I'm bringing it up again ;) can we add a constructor that accepts `shardInfo` as argument and change the subclasses constructors to accept it there, just to enforce that this info is needed so we don't forget it anywhere. Maybe then we could also remove the setter...
I see some places where null is not protected against...
I didn't check but unittests for this would be awesome!
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
same - please name it something like `explainOrThrowRejectedCommand`
is it an option to make this method package private? Then it would become more of an internal thing. Thanks for addressing this!
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
Exception e = expectThrows(Exception.class, () -> doSomething()); assertEquals(e.getMessage(), containsString("bla"));
I think it'd be nice to have this in :test:framework so others can use it.
Probably worth putting an explanation in here.
Maybe explain that it is used in places where you want to make sure that scripts are valid but don't care about the specific script and this is the easiest way to do that.
I guess it could be renamed to isFalse() / isTrue() now
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I don't believe this is only kept for BWC. You use this to parse `_source` above.
Needs a guard.
Ah yes, thanks!
I think this message should be a bit more clear. Can you include: - the path - the supportedAttributes - some explanation about what attributes we're looking for It can just be `"Don't know how to make file {} non-readable on a filesystem with attributes {}"`
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
can we sometime just rely on the wrong allocation id? (and have a valid node)
Throw the exception here
Just a formatting issue here. Add a space before the curly bracket: ``` java if (cannedACL == null || cannedACL.equals("")) { ```
Same formatting issue as below
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
do we want to check listener.isDone? (because it is supposed to return immediately). get() waits.
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
So, this could be simplified to `assertFalse` Or could be something like the following (which admittedly, is probably less simple) ``` import static org.hamcrest.CoreMatchers.everyItem; import static org.hamcrest.Matchers.greaterThanOrEqualTo; import static org.hamcrest.beans.HasPropertyWithValue.hasProperty; ... assertThat(response.records(), everyItem(hasProperty("recordScore", greaterThanOrEqualTo(50)))); ``` Man, that is frustrating that hamcrest does not support just passing a lambda as a type of matcher :(
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
count > 0? just being paranoid :)
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
`s/Class<C>/Class<? extends C>/`
maybe put this check before the primaryTerm check
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
can the aid matching be the implementation and the rest just assertions ? it should be enough
maybe call this "resolveSnapshotNames"? I would also prefer to use `List<String> snapshotNames` as parameter to bring it closer to the return type.
Maybe just rename the method to `snapshotShard` or something. I know it takes the IndexShard, that that really helps.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
`s/Class<C>/Class<? extends C>/`
`s/Class<C>/Class<? extends C>/`
It's not a big deal, but I liked that it allows to - make StreamInput not depend on NamedWriteableRegistry - stack registries: you could stack registers on top on each other, while the current approach requires that you provide a registry that knows about all namedwriteables at once. I don't have use-cases in mind, but thought this could be useful.
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
this code and the code in `SearchPhaseController#sortDocs` is almost identical. I think the only difference is the assignment of the shard ID. Maybe we can factor this out into a static method and use it in both places. It would be good to redcue the duplication on such a level and it would increase the test coverage. I would be in favor of that.
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
thanks for checking, that is fine then
we may have a small problem here, when toXContent is called on an object deserialized from a previous version that didn't send the _id .
if it prints out null it may be ok, if it gives NPE we need a null check, that's what I meant.
I think checking for newline is better than relying on pretty printing having space between key/object...
I would really just check for newlines.
Shouldn't this be equal to the `jsonBuilder().string()` above, without adding `.prettyPrint()`? And a nitpick: please add a space after the comma..
This one also uses a Java 9 method.
This one has the same problem with java 8.
do we need ordered things? does order help anywhere? If not I would just use HashMap
do we need this Reader interface? can't this just be `Funciton<StreamInput, T> reader`
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
just my personal preference, I don't like instanceof checks that's it. you are free to leave them if you prefer them ;)
I think if we get in that other PR I just reviewd we can reuse here the new method that you introduced there? :)
as I mentioned a million times now, when we will say let's not use it and remove it everywhere I will stop whining about it. I don't want to see three methods with annotations and one without it, it hurts my eyes. Either with or without it, not in the middle, at least in the same test class.
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
make it final
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
we should include `e` here, otherwise we lose the cause of the configuration error.
please log the exception here as well we really wanna see what was going wrong
Writeable#readFrom returns a new instance of the object, it allows to have final fields, but it requires to have a PROTO instance of the object to call readFrom against. I wish there was an interface to declare writeTo only though but we don't have it at the moment.
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
maybe have a helper method since the logic below does that though...
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
I prefer my way but have asked @jasontedor to chime in.
// must use exception that is not **ignored by** replication logic. (also 2 more occurrences of this in IndexShard)
maybe put this check before the primaryTerm check
can we have two static helpers that allow to create the processor either providing the Client or the RestHighLevelClient ? I am thinking of users, there are many existing usages of BulkProcessor out there. I may be ok to change the way it gets created, but as a user I would be surprised to have to pass in a method reference. That should be more of an implementation detail.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
got it thank you.
we could pass a glob with regex:xxx to newDirectoryStream if we want
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I dont have a good answer for this yet. While we can totally test this, the value in the server -> client.fromXContent is greater than just testing the client.toXContent -> client.fromXContent. I think these kinds of tests are not really providing much value, and we also test the former in the IT tests.
Do you need this? I dont see it being used anywhere.
I think we can check the beforePart == null out of the if(!..equals) and it will make it cleaner.
- do we need to `new`-up a distinct `SSEAwsKeyManagementParams` each time `S3BlobStore#getSSEAwsKey()` is sent? Can we instead `new`-up one in the constructor (e.g., is `SSEAwsKeyManagementParams` externally mutable?) - from what I can tell, this and `S3BlobStore#serverSideEncryptionKey()` can be _package-private_; exposing public accessors on encryption keys is unnecessarily risky.
Maybe we could call the remaining equals() implementation in the query builders slightly different? When I read this code and don't know about the abstract superclass, this might look a bit odd since it's doesn't really overwrite the canonic equals() but it sort of looks like it does.
I think we should do this even if we use docvlaues? I think we should have consistent slicing no matter how it's done!
Gotcha, thanks for the explanation!
ok cool then we need to fix this place? https://github.com/elasticsearch/elasticsearch/pull/3953/files#diff-79371c2235df5580ddc99db30932bea5R89
the utility should be a static class
I'm fine with leaving it, yeah. I did want a prettier one but if this is what we can do, it'll do.
I talked with @costin earlier about this - he wants to keep the order the same and my proposal doesn't. What about this? ``` while (result.size() > 1) { ListIterator<Expression> itr = result.iterator(); while (itr.hasNext()) { itr.add(combiner.apply(itr.remove(), itr.remove())); } } ``` Your version works but `for (int i = 0; i < result.size() - 1; i++) {` make me think it'll be a normal loop and then you remove and add and I'm confused. Using the `ListIterator` forces the reader to think.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
Actually I just checked and removing name and description from the Plugin interface should be easy. The only thing to think about is what to give for those properties when plugins are loaded from the classpath (plugin.types). I think here the name should just be the classname, and description something like "plugin loaded from classpath"? I don't know what other info we really have.
Also, can you add an element to maven enforcer plugin for plugins/pom.xml so it fails build cleanly and early if this property is not set? We should also insert a check in pluginservice, if it differs from the directory name, someone manually meddled
We should also check the name matches that in jvm plugins. As a follow up, we should at least remove description from jvm Plugin interface, and possibly also name (possibly a little harder, just requires passing around PluginInfo instead of Plugin I think).
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
can you add a //norelease here too? context should really go away after all queries are refactored
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
Nit: spacing between `while` and `(`.
Nit: spacing between `!` and `value`.
I would add an `assert this.context != null` here just to make sure
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
I'm not a big fan of ActionListener<Void>? Maybe we can do this differently and replace it with two functions? Runnable for the onResponse() part and for onFailure use a Consumer.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I don't think it matters. We should not force making huge changes to the entire codebase in order to not add things which will just be deprecated and/or confusing to the user.
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
This is similar to the internal implementation, nice
Misspelled in the \@param tag also
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
can we configure the delayed allocation to not be the default (`1m`) but something high enough to trigger what we are trying to fix, like `200ms`? This will speed up the test.
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
nit: `an` -> `a`
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
I think it's confusing that the WriteReplicaResult flow is different than WritePrimaryResul. i.e., `finishWrite` is called in the constructor for one and in the respond method for the other. We should try to make them the same as far as possible.
here too, toQuery might return null, not sure what happens
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
as I mentioned a million times now, when we will say let's not use it and remove it everywhere I will stop whining about it. I don't want to see three methods with annotations and one without it, it hurts my eyes. Either with or without it, not in the middle, at least in the same test class.
s/to list of/to the list of/
Does this need to set `change = true` also? It's missing from this `if` block
As well as the default buffer size
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
looking deeper, I see that we set a non null TermsLookup object only when we have it in query, which causes a validation error when values are set too. We should keep it that way then, this is as good as it gets.
I meant that other way around, not in the else, set termsLookup only if values == null
this smells like it should be a setting validation thing. Testing for this so deep, on every request without throwing exceptions feels wrong.
nit: use assertThat(...) with isNull() as matcher instead? I think in general that is the preferred way of writing test assertions.
if the size was previously less than PAGE_SIZE_IN_BYTES (possible with the contructor that exposes a size), this will actually grow the array (potentially going from a simple heap-allocated byte[] wrapper to a recycling instance)
is this a leftover? I don't see where this is used outside of tests? and even there I think it's a huge overkill. Can we please remove this entirely. If you really need stuff like this for testing then look at `ThreadContext#setTransient` which you get from a threadpool
can we rename this to `boolean isCanceled()` and then instead of the exception just return a boolean? I think it would be more intuitive and we really don't need yet another exception
This is why I do not like `assertEquals`; this is backwards from expected and actual. Instead: `assertThat(t1.v1(), equalTo(2L))`.
I think I miss something here because I think we need it for now but not in the future after we have a Lucene rollback. I will reach out to discuss this.
We have dedup in this PR already (line 161-163). The `lastSeenSeqNo` is used for dedup and range check. I am fine to remove the primary sort and dedup mechanism.
As discussed - this should be needed in the future. Maybe we should remove it and instead assert that we never have duplicate seq#
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
ok let me have a look then ;)
It might be cleaner and create less new-Function objects if you extract this compute block as a new method, say "newIndexFieldDataCache(fieldName)", then just do `fieldDataCaches.computeIfAbsent(fieldName, this::newIndexFieldDataCache)` here.
Indeed, I think two BytesReference instances should be considered equal if they have the same content (which is what the way other children of BytesReference are implemented suggests). My point was this path of the equals method ignores the offset of `other` (it starts comparing its bytes at `0` instead of `other.offset`.
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
is this correct? this will return a copied array if offset > 0, yet the `arrayOffset` method will return the offset into an array that has offset 0... .
Maybe something like: The bucket can "overflow", in which case the excess capacity is just "spilled", rather than saved up. So it never holds more than a minute's capacity.
I'd mention the name of the setting that controls the limit in the error message. I can imagine needing this desperately. I'm honestly really hoping no one sees this for the first time in production, but I know some people will.
It might be a good idea (possibly in a different PR) to have a method on `ScriptEngineService` called something like `getSupportedScriptContexts()` which each implementation can use to define what script APIs they support. I imagine there are/will be other language that don't support some script APIs and this would not only allow them to use this too but would also remove language specific code form the ScriptService, which should probably remain language agnostic.
same here - since we have on onFailure handler, calling is the equivalent of re-throwing the exception, imo.
+1 to throwing the exception.
This should be `== false` right? otherwise we will warn if the latch _found_ a state
can this also be `IndexingOperationListener... listeners` please
I don't think there is any need to keep `META_FIELDS`, and this is incorrect do both because `META_FIELDS` is static right now (so should not be initialized in the ctor) and because it leaves the incorrect values there now. `META_FIELDS` should be removed completely, and the methods that use it should instead pull the keyset from `mapperRegistry`.
these can go away if we cut over to a `IndexingRequestListener...`
I mean random number of replicas with random combination of non-active states
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I think we can check also randomly on a shard that relocates _to_ the local node
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
Does this message go back to the end user? If so the fact that a map must be empty is more of an implementation detail than an meaningful error message for the end user. Something like "Mapping definition for field X has unsupported parameters: foo, bar" would be more appropriate.
Can you use `== false` here...the `!` is almost hidden in all the other text around it...
I think we _do_ need to consider BWC for these lists. If you look at the implementation of `readList()` and `writeList()` they start by reading/writing the list length. So we need to write an empty list to versions before 6.5, and read a list of something. We can replace `PartitionScore::new` with a function in `Bucket` that reads the same stuff that `PartitionScore::new` read but just discards it.
That is true for when there is a transport client which I didn't think of at the first place. So, yes, we'll need to do the trick of reading the scores. There is another place where I'm doing this: https://github.com/elastic/elasticsearch/blob/6.x/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/job/config/Detector.java#L253. You can take a look and follow a similar approach. Note we only need that code in the `6.x` branch.
this needs to be fixed before merging (as it should go to 5.2.1).
one too many whitespace between List<C> and the method name
It's not a big deal, but I liked that it allows to - make StreamInput not depend on NamedWriteableRegistry - stack registries: you could stack registers on top on each other, while the current approach requires that you provide a registry that knows about all namedwriteables at once. I don't have use-cases in mind, but thought this could be useful.
`s/Class<C>/Class<? extends C>/`
yes I would at this point. it's a remote connection to another cluster that may be at a different location etc.
should we call the field `socket_timeout` ? Will we want to add `connect_timeout` too in the future? I think timeout is very generic so we may want to be more specific.
maybe just `esVersion()`
we should assert this is never called (same for the other places here where `UnsupportedOperationException` is thrown), as this indicates a bug.
I think this should be an `assert false;` + throw new UnsupportedOperationException
something like this: ```Java public SearchOnlyEngine(EngineConfig config) { super(config); try { Store store = config.getStore(); store.incRef(); DirectoryReader reader = null; boolean success = false; try { this.lastCommittedSegmentInfos = Lucene.readSegmentInfos(store.directory()); this.translogStats = new TranslogStats(0, 0, 0, 0, 0); final SequenceNumbers.CommitInfo seqNoStats = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(lastCommittedSegmentInfos.userData.entrySet()); long maxSeqNo = seqNoStats.maxSeqNo; long localCheckpoint = seqNoStats.localCheckpoint; this.seqNoStats = new SeqNoStats(maxSeqNo, localCheckpoint, localCheckpoint); reader = SeqIdGeneratingDirectoryReader.wrap(ElasticsearchDirectoryReader.wrap(DirectoryReader .open(store.directory()), config.getShardId()), config.getPrimaryTermSupplier().getAsLong()); this.indexCommit = reader.getIndexCommit(); this.searcherManager = new SearcherManager(reader, new SearcherFactory()); success = true; } finally { if (success == false) { IOUtils.close(reader, store::decRef); } } } catch (IOException e) { throw new UncheckedIOException(e); // this is stupid } } ``` I did something similar a while back so I had it ready... I am not sure it safe to use ð¯
Pls be sure this is not null. Other converters do a null check and return and give this `addCommaSeparatedPathParts` a empty array if need be. check `forceMerge` for an example
no need for extra space
we also support a parameter called `updateAllTypes` here.
the dollar sign option :)
should these be private? not sure who is using it...
again, this is the reasoning: if we check for existence of a field in the parser, it means that the only way it can be null in the builder is when it comes in through java api. In that case we might want to fail fast and throw error in the constructor/setter already rather than in validate. If non validated values might come in through the parser as well then validate is the way to go. In this case it makes to do as Christoph suggested. In term query builder I think it still makes sense what we do (again, you can test it to see the differences), same for common terms query.
In the other tests that are migrated to use Zen2 we set this to `true` (i.e. we are not testing the Zen1 case any more). I think that's what we want to do here too, but in any case we should be consistent about this.
seems like this is not needed anymore given that we don't go through InternalSettingsPreparer anymore? sysprops will always be ignored I think
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
People don't know what archiving setting means. They just upgrade and their end up in an illegal state. I think it will be cleared not to mention the "can't be archived" part. But as said - just a nit, not a big deal.
Also- I traced the code and as far as I can tell, in the case of `index.number_of_shards` we never say which index was problematic? I think it's important to add that info..
Nit: `get's` -> `gets`
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should only be done in close()
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
To be clear - I think we want to know how the oldest file is, regardless of the generations. It will always be the oldest generation and the first in the reader list, but I don't think we want to rely on it. Part of the role of the stats is to validate things are correct.
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
why did you change this to take a `TranslogGeneration` with the uuid instead of just the `long minGeneration`? It's not using that uuid anywhere here AFAICS.
this one ends up sending parameters that are getting ignored, see `IndicesOptions.fromMap`. we should remove the last three parameters. This should be cleaned up, the problem is that some indices options are settable at REST, while some other are internal properties that define each API (the default argument in `fromMap`) which cannot be changed, so they should never be printed out nor parsed back.
We should be writing out the settings in the "new format". There is no longer index_analyzer. So in the case of search_analyzer being set alone, when we serialize, we should write both analyzer and search_analyzer.
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
I'm okay with `foo.backup`. It would also not be hidden from non-Windows users by default.
@dadoonet I don't think it complicates things that much.. it's just traversing the file tree... and yes... sub-folders need to be supported as well. so if you see a folder with the same name/path in both places, recursively merge the two by adding the new files and skipping existing ones. I'd also argue that if in the es plugin config dir there's a file that doesn't exist in the new plugin dir structure, then rename it to "<original_file_name>.<original_extension>.old" (or something like that).
It'd be better, to only skip the config files that have the same name, not the whole directory. So for example, if currently es has a config dir that looks like this (for plugins `foo`): ``` /config/foo/bar.yml ``` and the new plugin that installs needs to copy two files there: ``` /config/foo/bar.yml /config/foo/baz.yml ``` we'll skip `bar.yml` but we'll still copy `baz.yml`. This will help us a lot when we guide the user on how to upgrade - instead of telling the user, to copy & modify a bunch of files, we'll only need to tell him to modify files under `config/foo`
I _think_ that you can get away with just letting the exception bubble up and RestController will send it to the user. You won't get the error log but I'm not sure logging an error on 400 level parse errors is a good thing in the long run anyway. I try to usually run requests with `error_trace` on them so we don't eat the stack trace....
you need to generate two errors for this to test what you want :)
Actually, ignore this, the rest actions are actually just forwarding to the transport actions
nit: can you assign `event.state()` to a local var
we should also have messages here in this assert
future note - once refresh mapping is gone, we should inline this with index creation.
Also, you dont necessarily have to change this but you can now replace `.execute.actionGet();` with just `.get();`
nit: missing space
Yeah - I'm sure that is what happened. Ok - cool with me!
+1 on the closed indices use case. Good catch. I'm not sure it has effect now. Did some sniffing and we close the shards in too many places upon index close. First place in `IndicesClusterStateService.applyDeletedShards`, then we have another iteration in the beginning of `IndicesClusterStateService.applyCleanedIndices` : ``` for (IndexService indexService : indicesService) { String index = indexService.index().getName(); IndexMetaData indexMetaData = event.state().metaData().index(index); if (indexMetaData != null && indexMetaData.state() == IndexMetaData.State.CLOSE) { for (Integer shardId : indexService.shardIds()) { logger.debug("[{}][{}] removing shard (index is closed)", index, shardId); try { indexService.removeShard(shardId, "removing shard (index is closed)"); } catch (Throwable e) { logger.warn("[{}] failed to remove shard (index is closed)", e, index); } } } } ``` and only then we do `indicesService.removeIndex(index, reason);` which closes the index (but it has no shards any more..)
or "failed to close store on shard removal"
Closing the store doesn't necessarily mean the shard is being deleted, I tested this and this codepath can happen when the index is closed, so I think this should be "failed to close store on shard closing"
if the argument name is `failNoIndices` you should provide `! indicesOptions.allowNoIndices()` as argument
I see your point on changing the name, that makes sense cause allowNoIndices != indicesOptions.allowNoIndices
if the argument name is `failNoIndices` you should provide `! indicesOptions. ignoreUnavailable()` as argument
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I like this much better!
I _think_ you can do `XContentParser::mapStrings` above instead of having this method.
I think s/lang/defaultLang/
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
I think this check does not add much (I would skip it)
maybe make this variable final? just better indicate it will never change
can we init this with `1`
well maybe you don't like the success pattern though... but I think it should be closed even on Throwable
can we hide `shared.refcount` behind a method ie. decRef() / incRef() to be consistent with other stuff
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
I think this should be done via IndexShard#failShard (which can be exposed via indexShardReference ). Will be cleaner and faster (it's local fail first, then notify the master)
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
Nit: space between the cast operator and the target.
Looks like there isn't an ExecutebleScript equivalent for search scripts anyway - ignore this.
Talked with @cbuescher in a chat - since these are just copied from their old place they should probably just keep their implementation in this PR. Moving to test framework is still possible in this PR.
Maybe explain that it is used in places where you want to make sure that scripts are valid but don't care about the specific script and this is the easiest way to do that.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
You don't need to create an explicit default ctor since the super class has a default ctor.
No need for an empty default ctor when the super is also a default ctor.
I'm confused because I thought you were implying there are cluster level tasks always running in the background, that are simply part of the cluster operating normally. A leak is a leak, and we should catch and reject it.
I am not sure that it warrants "WARN" logging level. It's perfectly fine for some of the tasks to be running in a working cluster. This includes node and master fault detection pings for example. I feel that INFO level logging would be more appropriate here.
Somehow we need to distinguish "background" tasks for the cluster from those started by rest actions.
Again, putting the unit in the name would help here, unless someone reads the docs they can't tell whether it's millis or nanos
Again missing units :(
can we replace the Math.max with an assertion? it should never happen and we shouldn't protect for it.
we should soften the language here. We can return before these are active (with a time out flag))
Why is it not possible to specify 0? I might want to create an index without waiting for any shard of that index to be active.
But that is not equivalent? Arrays.toString is a static method, and different than result.buildConflicts().toString()
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
this can go back to boolean if we move back Settings to boolean too
nit: we can check the expected token and then create the searchProfileResults map
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
is this needed here? I think it does something only when the current token is start array or start object.
you are right, sorry
space between `if` and `(`
maybe expectThrows would be easier.
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
we should log the exception here.
this can very verbose (600 shards on a node). I'm doubting whether we should have this as debug and have an info level log saying "allocation of [X] unassigned shards delayed".
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
here too we do the same twice
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
We can remove the `!` if we reverse this if statement, so ```java if (difference.isEmpty()) { status = RestStatus.OK; } else { ... the error stuff ... }
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Under what circumstances would the mappings for an index be null (as opposed to an empty map)? It seems the default for `GetIndexResponse` is to always have an empty map for mappings (and aliases and settings) and it would only get assigned to a non-null map.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
same here - I think it's better to log the info message if the deletion was successful.
index's toString gives you '[index_name]' no need for '[{}]'
OMG `== false`! ð±
should we assert that reader.getCoreCacheKey() == engineSearcher.getDirectoryReader()? Forcing the core cache key handling to be delegated to the inner reader could be trappy otherwise
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
This can be final. This makes it easier to immediately see what is and is not immutable.
can you add more rolling while adding? Also *sometimes* increment the primary term
Note that you want to make sure that you test the difference between the terms in the ops and the terms in the files. These are not the same.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
Because of the structure of the grammar it's a way to get the `-` symbol from the immediate parent context in the hierarchy that could possibly contain it.
Let's improve the expression a bit: 1. add location (so the user can tell where the parsing stopped): `new ParsingException(source(ctx), "")` 2. rephrase the message to better convey the message: "SQL statement too large; halt parsing to prevent memory errors (stopped at depth {})" or something along those lines.
I talked with @costin earlier about this - he wants to keep the order the same and my proposal doesn't. What about this? ``` while (result.size() > 1) { ListIterator<Expression> itr = result.iterator(); while (itr.hasNext()) { itr.add(combiner.apply(itr.remove(), itr.remove())); } } ``` Your version works but `for (int i = 0; i < result.size() - 1; i++) {` make me think it'll be a normal loop and then you remove and add and I'm confused. Using the `ListIterator` forces the reader to think.
Yeah, it's puzzling!
And yes, I misread the assertion at first but the puzzle why a change is needed only here remains! ð
You should also test `nextUp(-0f)` ?: ```` assertEquals( NumberFieldMapper.NumberType.DOUBLE.rangeQuery("field", -0f, null, false, false), NumberFieldMapper.NumberType.DOUBLE.rangeQuery("field", +0f, null, true, false)); ````
ok fair enough
Yeah, I think we can collapse both deciders into one here - it will make things simpler. Call it RecoveriesAllocationDecider that is incharge of all recovering shards (replicas and relocating primaries). It's good to do it in a different PR imo..
This predicate can be simplified to `(count, limit) -> count > limit`.
we only have index name (and not index uuid) in this one, wonder if we need snapshot uuid here...
you probably intended to write "alias:id,snapshot".
I think this needs to be "unidented" by 4 spaces. Also just for the "beauty" of things you can move the leading whitespace char to the prev line.
This could be `Strings.hasLength(tokenizerName)`
I am not sure if we should catch an exception here IMO the exception should bubble up
would it be possible to eagerly initialize the clients and make them final? I don't see why not, but maybe I am missing something.
I think I missed the discussion but why isn't all this (this method and the next two) part of BaseNodeResponse's toXContent implementation? It can declare an abstract method that the subclasses can override for their own xcontent? We use that pattern pretty frequently with things like the query builders.
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
typo I guess `s/chanHaveDuplicates/canHaveDuplicates/`
I think this is wrong? I this is an indexing request on a replica and we're here, that means that there is already a doc with this id. In this case we want to just ignore the request. +1 on what Simon said regarding not changing this code.
This might be more readable and succinct with `&&` chaining, what do you think? ``` java return timestamp == create.timestamp && ttl == create.ttl && version == create.version && id.equals(create.id) && type.equals(create.type) && ... etc ... ```
you can call `bytesAsInt()` then you safe the cast and it checks that it's lossless
nit: `== false`
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
nah this should just pass a string.
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
this new exception is going to trigger errors too if we try to serialize it to an older node
I missed it, indeed it should be moved to setupSuiteScopeCluster
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
sure sounds good. I thought the enum contained all the possible codes :)
cool. this is sufficient for ILM for now, so that makes sense
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
You can use the diamond operator here.
You can use the diamond operator here.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
missing t at the end of the method name
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
I don't understand the need to use Occur.FILTER here (or in other parsers) versus Occur.MUST. To me these are just parsers for queries, and thats the correct logic, the fact it is wrapped as a Filter means these will all become non-scoring clauses.
I don't get it sorry :)
yeah it might be ok to do this since we are only parsing it on a search thread. I wonder if we can add an assertion for the threadpool that it is not a nework thread ever? but opening a diff issue is good
Wouldn't the definition of "upgradable" for string to text/keyword mean the norms setting fits with what is allowed? As this is now, it would mean eg keyword fields could have all of the old settings right, but they would be deprecated...that is just really weird for a new mapper type.
And the same for TextFieldMapper, although that is a little different since it uses parseTextField...
Can you use `== false` here...the `!` is almost hidden in all the other text around it...
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
instead of the assertBusy, maybe use a future above with setWaitForCompletion(true).
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
same thing with 'even make' here
s/payload is/payloads are
I think we should enable this by default and maybe say `5`
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
last parameter can be set to from.
Oh nevermind, I see the problem now, the field name is not used to calculate equality so they can stomp on each other even if they have the same name :(
Can you use StreamInput#readList ? You need to check for the version here since this code can receive requests from nodes in previous version. Something like ````if (in.getVersion.onOrAfter(Version.V_6....)````
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
I think it would be better to do something like `return "[" + new BytesRef(ranges, 0, BYTES) + " TO " + new BytesRef(ranges, BYTES, BYTES) + "]";`
left over reference to a countdown latch
Oh, nevermind on the second point, I see `ShardLock` implements `Closable` already.
In our discussion about semaphores I understood a different model we keep a semaphore per index/shard directory (like the on the disk locks but in memory). That would be pruned when the folders are pruned. I see where you were heading. I'm fine with either way.
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
Another `_` java 9 will be mad at
This method also does not need to exist, as you can use `this(indices, IndicesOptions.strictExpandOpen())`, and fix the validation in the other constructor.
yea Im all for not exetnding that class. And Im also all for putting things that are primitive and easily validatable into the constructors. Optionals, i think im ok with setters but i think this also deserves a wider audience to discuss.
This is a question, not a change request: What is our philosophy regarding having setters vs. immutable request objects going forward for the HLRC? I've been under the impression we preferred immutable objects, but it doesn't seem to be consistent.
FWIW I've used this in the past for production ES clusters to have a set of common settings (elasticsearch.yml) and node-specific settings (elasticsearch.json) to merge two files with settings. That said, I still think it's safer/better to remove this feature and fail if more than one config file is found. It reduces the complexity for reasoning where a setting came from.
we need to support whatever extensions Settings supports and that includes json & java properties formats. I wouldn't worry about restricting it to these three (yml, json, properties) with regards to bwc.
with the current code a `logging.whatever.yaml` file would be loaded. I wonder if this is our intention or a side-effect of the current behaviour. Honestly I would be in favour of simplifying this further and even have something like `if (file.getFileName().toString().equals("logging.yaml") || file.getFileName().toString().equals("logging.yml") )` unless we want to extend this to json and properties files, which I think would be off-topic in this PR.
We had to choose a shared prefix in order for there to be a consistent way to detect types deprecation messages in REST tests (and ignore them). I think @jdconrad is just using this prefix here for consistency.
I don't think you need @Before here, the parent method already has it.
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
Usually we also make a few API calls to the server, e.g. https://github.com/elastic/elasticsearch/blob/2aba52de8f9315b0e384e1c657d7b0401d26a1b0/qa/vagrant/src/main/java/org/elasticsearch/packaging/test/PackageTestCase.java#L121-L122 I'm not completely sold on the value of those though
Nit: can you put this and `runWithoutJava` next to each other
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
new is not possible with an older version...
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
The fqdn was used before though too. It is not introduced here. It makes it clear which exception it is (e.g. org.elasticsearch.script.ScriptException vs javax.script.ScriptException), and it makes it easier to remove exceptions from here in master (vs having an import statement too), which is really needed.
Can you rewrite this as an array of ctor references and iterate the list to build the map? It might be a bit easier to read.
I guess it would be better to have a random unicode string here instead of the English? We don't need hits here really
`this()` is obsolete
please fail if vals.length > 3
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
I am good with both options.
fine with me as well. go ahead and push!
maybe it is a matter of style, but i think its easier to handle the exceptional case like a guard up front: check stats.docCount == -1 and set to -1, otherwise sum. this is not really important to me.
`S3SignerType should not be available for China region`
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
`} catch(IllegalArgumentException e) {`
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
I don't see how the cluster state is not _always_ the right place to store configuration. Putting it in an index is a hack. I don't see the issue with "large pipeline configuration", but I also don't see how it would differ from how cluster state for a specific index is passed where necessary, eg mappings are not loaded for all indexes on all nodes.
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
Is the version needed? I don't see it being read here.
this will annoy the forbidden API after rebase + squash. Heads up
you should replace the curly bracket with a square bracket here.... :D
do we need == true ? :)
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
I think we can do this more simply by looking at `endsWith(".jar")` of the uri string. We don't really need to convert the uri to a path, since we don't need to load the file. Then, the original if statement can simply be wrapped with like: ``` URL location = clazz.getProtectionDomain().getCodeSource().getLocation(); if (location.toString().endsWith(".jar") == false) { // original if and exception here } ``` Basically, if the file is in a jar, we don't need to worry about it here, as those would have already been added to the codebases map by `Security.getCodebaseJarMap`. This method is about adding classes that are on the classpath, but not via a jar (ie built by the IDE).
This assumes a version format that while fairly standard is not guaranteed.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
Isn't `js` the common extension? At least, that's what is in RFC 4329.
Since these tests are so fast + simple, maybe we could just test both methods every time. I don't think this will be much extra code, as you could re-use the same `FakeRestRequest.Builder`.
nit: shard routing already has [] in it's toString
Yeah, let's the keep the tests just focused on whether or not `MinMasterNodeCheck` does the right thing based on whether or not `discovery.zen.minimum_master_nodes` is set and we can think about broader tests for the default checks from `BootstrapCheck` itself in a separate pull request.
There's a `BootstrapCheck#check(boolean, List<BootstrapCheck.Check>)` override that is visible for testing exactly so that the test can be written without having to rely on passing in a setting the triggers enforcement.
nit: IllegalArgumentException ;-) You're checking the `settings` argument here, not the state of InternalTestCluster.
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
This shouldn't be needed anymore. By default we wait for the index to be created now.
`client().prepareIndex(...` is more normal now.
for master you don't need to specify the gateway.type we only have what used to be local!
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
relativize can be tricky if paths have different roots. is siteFile really guaranteed to be absolute too? In lucene i coded this "minimal path" with the following idiom: ``` root = root.toAbsolutePath().normalize(); path = root.relativize(path.toAbsolutePath().normalize()); ```
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
we can do this in a more optimize manner. We can create a builder, and then use `copyCurrentStructure` on the builder (passing it a parser), to just copy it over, compared with parsing into a map and then serializing the map. Also, since its internal, I would use smile builder, as its considerably more efficient than json.
I think it's better to use the index version created to test whether the old or the new parent join should be used. This way you can make sure that the correct explanation is returned in the exception if the parent field is not filled.
Might be slightly better to return a StringBuilder here as well to not create an additional object? Maybe this could also be done in several other places in this PR where partial WKT strings are built (e.g. all the contentToWKT calls)
would you mind adding the same for allocation ids? :+1:
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
looks new. I like this update!
I think it would be cleaner to move the assert into the catch, and add a `fail("expected script exception")` after the call to `run()`.
If these privileges are only needed for loading static definitions, then this should be done in a static block when the plugin is loaded, instead of on every invocation of the script.
and do that in all other classes we do this for serialization in this pull request.
Do we need to still read from the wire using something like this? ``` // TODO change CURRENT to specific version when feature branch is merged if (in.getVersion().onOrAfter(Version.V_6_3_0) && in.getVersion().before(Version.CURRENT)) { in.readBoolean(); // was waitForAck } ```
I don't get this part why do you change the way we read the `TranslogStats` here? can't this just be ``` Java translog = in.readOptionalStreamable(new TranslogStats()); suggest = new SuggestStats(); if (in.getVersion().onOrAfter(Version.V_1_2_0)) { suggest = in.readOptionalStreamable(suggest); } ```
I would use System.currentTimeInMillis, nanoTime has different semantics
and also assert that `startOfThrottle != 0`
nit: "so we assume"...
I think this would read much simpler if you would do `if (it != null)`
can this be `else if (res == null) {...`
I really don't think we should put methods that have side-effects into a short circuit logic. Can we use a traditional if statement here like ``` if ( docIdSetIterator.docID() == target) { return true; } else { return docIdSetIterator.advance(target) == target; } ```
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
the `grok` field can be final too
I was thinking of something like: ``` java public static enum TestQueryType { MATCH_ALL { @Override public QueryBuilder buildQuery() { return QueryBuilders.matchAllQuery(); } }, MATCH { @Override public QueryBuilder buildQuery() { return QueryBuilders.matchQuery(TestIndexField.STRING_FIELD.toString(), randomAsciiOfLengthBetween(MIN_SMALL_INTERVAL, MAX_SMALL_INTERVAL)); } }, TERM { @Override public QueryBuilder buildQuery() { return QueryBuilders.termQuery(TestIndexField.STRING_FIELD.toString(), randomAsciiOfLengthBetween(MIN_SMALL_INTERVAL, MAX_SMALL_INTERVAL)); } }, QUERY_STRING { @Override public QueryBuilder buildQuery() { return QueryBuilders.wildcardQuery(TestIndexField.STRING_FIELD.toString(), randomBoolean() ? "*" : "?"); } }, WILDCARD { @Override public QueryBuilder buildQuery() { return QueryBuilders.wildcardQuery(TestIndexField.STRING_FIELD.toString(), randomBoolean() ? "*" : "?"); } }; public abstract QueryBuilder buildQuery(); } ``` Then to build a random query, you could do: ``` java randomFrom(TestQueryType.values()).buildQuery(); ```
I think our other enums need this ids for backward compatibility of the streams, so that even if we add/remove entries to the enum they still get serialized with the same byte.
The `activeBenchmarks` reference can change anytime, so I think there should be a ``` java final ImmutableOpenMap<String, BenchmarkState> activeBenchmarks = this.activeBenchmarks; ``` at the beginning of the method to make sure we are always talking to the same instance.
I think it would be better to pass a boolean in to this method, since it's ambiguous from the name of the method whether it sets a var (could be named `setDeleteOnClose()` if it were setting something) or actually does the deleting.
It would also allow you to change the ``` java if (delete) { channel.deleteOnClose(); } channel.close(); ``` to ``` java channel.deleteOnClose(delete); channel.close(); ```
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
there is an `hasUnassigned` method already, so yeah, I'm +1 on being explicit here...
This is logic that I think should go into ReplicatedOperation.
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
I don't see this change implemented here.
this needs to stay because the method can be called from any other class, it's a public static method....thus validate might not be called at all before calling this method.
we shouldn't need this here in parse phase
I think âdoes not have soft deletes enabledâ was great!
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
I Am concerned that we will miss the actual message because its wrapped, my vote is the detailed message one
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
I think this check does not add much (I would skip it)
maybe make this variable final? just better indicate it will never change
@javanna I don't think it is? see org.elasticsearch.action.deletebyquery.DeleteByQueryResponse#iterator
internal class :) I think it's fine
oh nevermind, I just found the method that called it with null :)
Indeed, I think two BytesReference instances should be considered equal if they have the same content (which is what the way other children of BytesReference are implemented suggests). My point was this path of the equals method ignores the offset of `other` (it starts comparing its bytes at `0` instead of `other.offset`.
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
is this correct? this will return a copied array if offset > 0, yet the `arrayOffset` method will return the offset into an array that has offset 0... .
I like this much better!
I _think_ you can do `XContentParser::mapStrings` above instead of having this method.
Fine by me.
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
The indentation is off here and the rest of the way through this test.
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
in this re-write, we have a lot more things we probably want to report in our status.
I'nm still missing the buffer size, the max requested seq no, leader global checkpoint , follower global checkpoint etc. I'm fine with a follow up for those, but that's what I meant.
if it was always local it should all be taken care of by the put mapping api (retries etc). That said, this is also remote and I was mistaken. Sorry for the noise.
Nit: `s/soft-deletes enabled/soft deletes to be enabled`
I think 0 is a good minimum value.
right thanks for the explaining, I should have known, having worked on the search refactoring :)
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
This method is not necessary. With the code as is, we would be extracting the entire zip, but only using the one directory from it. Instead, we should do checks when extracting, see the `unzip` method. There we can have a prefix check like: ``` if (entry.getName().startsWith("elasticsearch/") == false) { // only extract the elasticsearch directory continue; } Path targetFile = target.resolve(entry.getName().substring("elasticsearch/".size())); ``` This will unzip everything in the `elasticsearch` directory directly into the temp installation directory, and all the other plugin cli installation code can work as-is.
I don't think this is a usage error (it's not something the user did wrong, it is something wrong with the plugin). We also already get a FNFE when the descriptor is missing, is this really necessary? I don't think this message, vs FNFE, will give any better indication to the user that the plugin is broken.
This will need updating once the setting is moved.
typo: if return -> is returned
typo: this this
Fair enough, good to know.
This should be `eventListener.indexShardStateChanged(indexShard, null, indexShard.state(), "shard created");
can we move this back into the try? I'm worried that exceptions wouldn't release the shard lock .
maybe it's me but this change seems fishy... we do much more than before now here, also not using indices options coming from the request... but first of all are we sure we want to support writing into index names containing date math expressions? in my mind it was more about reading, search api etc.
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
do we want to do something with is error? (not related to this change)
I think that we can check the second byte as well to make sure, same way we do in SMILE (by not only checking the first byte), check here: https://github.com/FasterXML/jackson-dataformat-cbor/blob/master/src/main/java/com/fasterxml/jackson/dataformat/cbor/CBORParserBootstrapper.java#L112 for the logic
for other reviewers wondering where this change comes from, the first char is already checked earlier in this method
I wonder if we should this api to the forbidden api pointing people at the utilities... (like we did in the write variants).
nit: space before brackets
typo: optain -> obtain
If the usage of forbidden APIs is in a few places, I would consider it better to suppress only at the lowest level (sometimes I like wrapping those in a private method I suppress). The reason is that if an unintentional forbidden call creeps in it will be caught.
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
Not sure this should be "Query" ð
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
why not round robin on this? I think the randomness still allows us to have collisions and will keep us wondering. +1 on the insight that suite and test scope don't co-exists! Also, this makes us one step closer to using it randomly in our global cluster scope.
1+ portCounter.incrementAndGet() % 9 ? (now we have a collision for 10 & 11 )
The max TCP port is 65535 , min 30K gives us ~30K or 30 JVMs.
If the constructor is modified, this method won't be needed anymore.
Ah, I see why this is a function ref - so that the `toString` generates the right method to invoke. That feels a little brittle but I understand what is up.
It would be nice to return a simple, non-empty structure here so that we test that aspect of the response parsing.
Sorry about these crazy incantations....
In which case I would say remove the BOOLEAN format here since its not actually a numeric format
hmm not sure, it does seem a bit weird to be there so I'm leaning towards "remove it". It doesn't feel like a great idea to be running numeric aggregations on a boolean field and I don't know if its something that works by design or just happens to work right now and might break in the future. /cc @jpountz who might have thoughts on that
Can we make this 1 hour? If it times out it's nice to get thread dump
same as above for non exception case
I am good
I know it was like that before, but we are here now. ð
I think it would be great to have different values for same fieldname and type. Working on the SpanQuery builders, I introduced BaseQueryTestCase#randomValueForField(String fieldName) which at least works for String, Boolean, Int and Double fieldname, otherwise returns String. Might be useful to use this here as well, potentially with minor modifications.
I understand the that the way the we test the created lucene query at the moment is not affected, however since we already have the test for `expected list of terms` hat checks the terms at least for string fields, I think it would be really good to have this tests. Changing this shouldn't be too hard, and also the random query we create here would feel more "natural". Please correct me if this change is hard to do, otherwise it would be really great to have random values here.
Wherever makes the most sense really. In this case I would put the default constants in `DirectSpellcheckerSettings` I think
nit: IMO `suggestMode must not be null` sounds more explicit.
These should all have sensible defaults rather than being null, as we have done with all the other builders. This also means we can remove @Nullable from all of the methods and add checks in there that throw an exception if null is passed in to make it safer. The defaults we currently use can be found in DirectSpellcheckerSettings.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
I think `requiresIndexMappingRefresh` is very misleading - it should be called `updateMapping` as it does update the mapping (and returns a boolean for refreshes)
minor nit: you could move this into the WatcherState enum and just have a method `isStopState()`
`state == State.STARTED`? Otherwise no need to define the local variable `state` above
do we want to do something with is error? (not related to this change)
do we really need so many tests? this is just about parsing? It can probably just have unit testing for this..
we end up supporting both `$stashedKey` and `foo${stashedKey}bar` ? we may want to move to the latter once all the clients runners implement this feature, to have a single way to get stashed values.
maybe ${stashedKey} alone should return an object then? Does that complicate things? Calling toString makes sense when the stashed thing is part of a string, otherwise returning the object sounds better.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
Here it is more clean, but again I think using `synonym_query_style` would be better
I think this should throw IAE if you pass null - that's 100% of the time a bug
For easier debugging it would be good to print the (unknown) value of `this.synonymQueryStyle`
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
I'm wondering if the parent really helps define equality here? Additionally, by adding this we will do more checks than necessary given that we compare both sub-aggs and parent aggs
ok can we rename the getter then to `getFailedNodeExceptions()`
we can use in.readVInt() here, no? it's always non-negative... (same goes for other counters and also note that you'd have to change the writeTo message of course)
Why not have the standard to string? A multiline return value is difficult to work with in a debugger...
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
this is unneeded - we just iterate of the list...
Oh oh! deleteUnderLock should be called when you hold the lock! instead we should use IndicesService.deleteIndexStore
I think this will result in a double info logging - we already logged at info level when discovering this.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
this method is not returning a boolean
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
I'm fine with `IllegalArgumentException`, in all the places of course. :smile:
then check for non null here...
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
Check nextToken is Token.END_OBJECT and throw appropriate error if not. Without this additional check the parser errors are somewhat confused if the JSON contains a parameter.
+1 on removing it
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
+1 that is what I would do too
This is what I meant, yeah. I'd have made it a `private static final ImmutableList<String>` instead of `Immutable<Highlighter>` but it doesn't make much difference.
can you remove this TODO? I'm not sure we are going to implement this after all, nobody needs it for now :)
the naming might be a bit confusing: `clusterSettings` and then `getClusterSettings()` as variable names
Ah nevermind, I see where we check it above :)
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
I guess it could be renamed to isFalse() / isTrue() now
the node where the shard should move to
yeah, that was what I meant
Could you explain why this is needed instead of checking `expireAfterAccess <= 0`? I think it'd make the class more readable.
I don't think it changed the readability much - it made the checks simpler but then it left me wondering why two variables were needed. I was doing the "why does this have to be here, let me think hard about it" think.
I suggest that we take advantage of this change to remove support for time-based expiration, which we don't need
extra space makes everything not line up!
Missing a space here after `id`
Elasticsearch tradition is to make this an EMPTY constant :)
this would allow to remove the two parse fields above I think
I think the following if is not valid anymore in fromXContent: ``` MatchQuery.Type type = MatchQuery.Type.BOOLEAN; if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_FIELD)) { type = MatchQuery.Type.PHRASE; } else if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_PREFIX_FIELD)) { type = MatchQuery.Type.PHRASE_PREFIX; } ```
sorry, my bad.
Nit: `primary term` -> `_primary_term`
`seqno` -> `_seq_no`
I think the message here should 1. be a static final constant and 2. say what this TermsEnum allows ie.: `"This TermsEnum only supports #seekExact(BytesRef) as well as #docFreq() and #totalTermFreq()"`
I think filter and query can never be null here? not sure whether we should validate this here.
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
then let's use it now otherwise this change is half baked
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
I think the whole method could just be: ``` return randomBoolean ? MetaData.ALL : randomFrom(currentTypes); ```
In which case your original solution would have worked too. Sorry
I think if you do `nextParams.putAll(params)` here you don't need to clear the `nextParams` map or do the `params.putAll(nextParams)` call below as the `nextParams` map will be used if `node.retrieve()` returns something and if it returns `null`, `params` will be untouched for the next attempt at retrieving the node.
Instead of creating the formerParams and replacing them afterwards could we not create a `nextParams` map which is a copy of the params map and pass it into the node.retrieve method? This would save us having to put things back after the method returns
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
no need to set timeout, the default is good enough
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
you can put these into `assertAcked(client().admin().indices().prepareUpdateSettings("test").....` to make sure this doesn't happen again
good catch on delta > 0
thanks for adding this
let's not log since it is an old index
and use the constant here
btw - the test uncovered some issue with the dangling indices import. You might run into a node not connected issues - working on an independent fix.
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
Maybe use `getSecure()` so that it's closer to the other methods in this class (`get()`).
can we just change this to System.getProperty("tests.seed") != null? Then that method can be removed.
ReflectiveOperationException can be used instead of both of these
You're right @benwtrent, we've been dropping the `@throws` clause in some of the methods in the client. We'll need to revisit and add them. I'll make a note to do that.
The indenting is out here
64e5c25 added support for this.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
wondering if we need recoveryState.isPeerRecovery() to simplify these lines.
I ran it and it took ~2-4 seconds, I was checking to see whether the `@Slow` tag was needed :)
ok, fair enough. ++ for setting up compatibility with GeoPointv2
is it worth doing the conversion from and to geohash every time here? Could it be better to not do the conversion and store two doubles per bucket instead of one long? I guess its a trade-off between execution time and memory
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
hmm maybe name it `markCommitted(long translogId) throws IOException` I think it sholud be IOException here
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
`engine failure` -> shard failure
missing t at the end of the method name
strictly speaking, this doesn't need to be volatile. We update it under a lock which guarantees the visibility of the changes.
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
Can you switch this around and use the preferred name as first constructor argument? This way it looks like there's something special with this field, which I guess its not.
This was called "path" before.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
why have the condition at all? Just always overwrite? Same for disterrpct above
I'm not sure myself why this hasn't been done this way. :-) It's fine, I was just curious if you had tested calling super and if it introduced issues.
or just: ``` java if (Objects.equals(similarity(), other.similarity() == false) { conflicts.add("mapper [" + names().fullName() + "] has different similarity"); } ```
if we use a negative value here we can also just do this: ``` if (output.getVersion().before(Version.V_1_1_0)) { b = Math.max(0, b); } ```
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
drop the actually? sounds so "uncertain" :)
I think it would be clearer to rename `file` to `dir` or `directory` here
+1 to not swallow the original exception
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
we should include `e` here, otherwise we lose the cause of the configuration error.
please log the exception here as well we really wanna see what was going wrong
Writeable#readFrom returns a new instance of the object, it allows to have final fields, but it requires to have a PROTO instance of the object to call readFrom against. I wish there was an interface to declare writeTo only though but we don't have it at the moment.
you can remove the QueryParsingException catch, it's unreachable
close is supposed to clear as well so this shouldn't be necessary to call clearReleasables
we can remove this catch
hmm why did you remove the mapping from here? I think that was a good change? you should add the settings from from `public Settings indexSettings()` are only used if you use `prepareCreate` so you should add the settings to the versionSettings below. other than that it looks awesome
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
maybe just start a unicast cluster for now
This is logic that I think should go into ReplicatedOperation.
this logic belongs in transportWriteAction
I think we should use `debug` for the logging here
Please fix identation.
this last line is redundant I think, we already check the same above
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
oh, the boxing horrors :)
here we could use sublists again - just scan to the place you need. No need to reverse then.
removed can just be a count. We always remove from the beginning of the queue.
sorry, my bad.
Since `value` internally is a String now, we can change read/write here as well.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
I think we can check the beforePart == null out of the if(!..equals) and it will make it cleaner.
Would it be beneficial here to return an empty string instead of null? If not, maybe just annotate this with `@Nullable`
This seems to only be used for tests. Maybe it should be a helper method in the test framework instead of part of the public api? I would be afraid of something accidentally using this in ES code.
Ok, my confusion stemmed from the fact the first result when searching down the diff was ScriptProcessorFactoryTests.java, which this PR changes from testing against `getMessage()`, to using `getDetailedMessage()`. I see now that is the only case. Can it be switched back? Changing the tests to use `ExceptionsHelper.detailedMessage` seems ok given they all already use it.
I'd rather merge TermsQueryBuilder and TermsLookupBuilder, this is going to be a problem anyway when registering builders for serialization if we want to keep registering the parser only and deduce the builder from it . I don't see any value in having two builders for the same query, it becomes confusing for java api users too. Also, the easy way of creating queries should be through querybuilders, we can keep the existing `QueryBuilders#termsLookupQuery` but it will return a TermsQueryBuilder instead. We can also add more methods to `QueryBuilders` to create a terms lookup query that holds all the needed params.
we shouldn't need this here in parse phase
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
the way we check the resulting query here reminds of the previous createExpectedQuery, as we still leverage lucene's equals and because of that we run into issues. Also, it makes little sense to test the result by calling the same method that we call in prod code (handleTermsQuery). I would keep these checks more lightweight then.
Ok, what is your proposal then? The current test is not ok I think.
Got it, sorry didn't fully realize how value is initialized in any case before. So scratch this remark.
fielddata format can still contain arbitrary values: ``` PUT testidx { "mappings": { "doc": { "properties": { "user": { "type": "string", "fielddata": { "format": "fst", "blah": "blub" } } } } } } ``` I am however not sure what is expected here because when I get the mapping the wrong entry will be returned...
Old indentation was better because it made it obvious that the conditions weren't part of the body.
I think we can remove this exception now.
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
I think we've started to use `setShard` style here? I'm not totally sure.
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
This API call is forbidden and fails the build. `random().nextBytes(randomBytes);` is fine though. I'll fix it before I merge.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
I wonder if using fromSeq and toSeqNo (instead of size) will result in this being less confusing.
For backporting to 6.3, I think this needs to be changed to 7.
nit: the map can be `PluginBundle::plugin`
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I see what you are talking about. Weird. I'm fine with it then. I mean, I don't like it, but I don't really have to like it. It makes sense to make it look like the test above even if the test above looks funny to me!
I mean, we still need to create the index, but i don't think we need to do it inside a new block.
I'd rather have ISO timestamps in the example as it's what I'd prefer users to use. Same for start and end.
can we assert that if we need to generate a new history uuid we always use `*_CREATE_TRANSLOG` as an open mode? that's why we rely on the translog uuid only for trimming purposes (and avoid thinking about what it means to generate a new history uuid)
a transformer and performer. Quite a guy :)
since we open the translog before the writer now - can we use the open translog for all this information rather than static reading it? this will make sure that we use something that went through all the right validations.
I think that we can save the instanceof checks, builder.value(Object) does it already
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
remove this additional line break? :)
s/to list of/to the list of/
Oh, that error handling!
let's keep as is, with the assertion message I think it's ok. I wonder if we should have an assertion at the end of this method to say something like "if we have an active primary shard that's not relocating, then the replication tracker is in primary mode".
Just a style note, we prefer the more verbose negation (`foo != true` or `foo == false`) over the short form (`!foo`), because the short form is easy to misread or overlook. :)
Even though this one should work, exact double comparisons tend to scare me a bit: should we use `null` instead of `-1` for non-existing x-axis units? (and store it in a Double)
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
this is good as we already have a unit test for the filter. Wondering if that current BulkProcessingState object needs its own unit tests outside its use within a filter.
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
same here: ``` parser.longValue(true); ```
This can stay as a break - exactInclude is the highest form of checking, no need to check more
Same here. Can stay a break
Same here. No need to continue
can you add a //norelease here too? context should really go away after all queries are refactored
I would add an `assert this.context != null` here just to make sure
I always wondered the same, I think we don't given that everything works without... that said we do have a lot of empty constructors with the `@Inject` annotation. Up to you... ;)
Same here... we don't really need `String[] addresses`
There's an extraneous blank line here.
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
I donât think this buys you anything in terms of concurrency. The list reference is already final.
This has issues as two calls could wind up finishing this listener. I think it would be better to use a AtomicBoolean and compareAndSet.
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
I suggest trace logging here
these replacements seem to be wrong the if / else logic is obsolete now
otherwise you could index into an alias that target a specific shard and yet index in other shards by specifying a routing key, which I guess could be seen as a bug
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
we throw the exception and thus take care of the interrupt. We don't need to set it...
Nit: I think it will be safer to have this boolean as a parameter and determine the action here. I'm weary of arbitrary string input.
Why is this `volatile`? It doesn't look necessary to me.
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
I've dug some more. This is caused by us running the tests with the built in gradle test runner rather than the randomized runner. We configure the randomized runner to run with the system properties but we don't ever configure the standard runner.
When I pulled this locally and reverted the changes to this file I didn't have any trouble. We've traditionally been very weary of making changes to this file so I'd really like to make sure we need this before we do it, even if it is temporary.
And some more: this is not caused by the build compare plugin. Maybe by gradle 4.8 or maybe by one of our hacks to make 4.8 work.
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
ok let me have a look then ;)
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
then do something like this `source[n/a max source size: ...`
I like including the original size here. Maybe instead if the source is chopped it should read like `first 2048 characters out of 10122123: _slice_of_the_source_`.
I don't think we need the exact number of bytes and if bytes is what we have we should use it. No reason to work hard to get characters.
I think all of these need to be trace and we should enable these in tests that are relevant.
IMO lets drop them all. IF you have to make them trace you can also just add them back if you need it.
same request - please have a method called `haveWriteBudget` and do `while(haveWriteBudget() && buffer.isEmpty() == false) { `
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
just a style question but this loop looks more like a `do/while` would be easier to read IMO
this assumes that the returned array will be of the same size as tops. This will be true in practice since they are both arrays of doubles, but I think the code would be more robust if it called `resize(bottoms, tops.size())` instead of `grow(bottoms, owningBucketOrdinal+1)`.
I know this is existing, but I think we can lift this up to a singleton so that we do not create a new instance on every publish to every node.
can we add a check for whether we sent a diff? I want to avoid a potential infinite loop.
cool. lets look at it on another issue.
I usually do this: ``` assert xContentBuilder.generator().isClosed(); return true; ```
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
we shouldn't need this here in parse phase
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
I have yet to get to that alternative, I am lagging behind :)
Typo: "Dynamics" -> "Dynamic"
can we assigne `indexService.mapperService()` to a var? just to remove the chaining :)
yeah nevermind I was confused about some internal classes
you can replace with //norelease so we don't forget but at least you can get this in while we fix this problem in master.
remove the set boost
remove the setBoost
There's an extraneous blank line here.
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
This thread can leak and fail the test, I think that you need to clean it up (join on it in tear down).
nit: space before brackets
typo: optain -> obtain
I think this can be removed (here and from the interface) and then `this.shardId` can be used in the only caller, the `.get()` method
`this` is unnecessary
Actually I'd still prefer to go with Colin's idea to use empty sets. We can still optimize later by making sure to use a Collections.emptySet (which is a singleton) if the size is 0.
OK. Just double checking :)
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
I had a quick look and opened #25519 with what I imagine the strategy is. It certainly looks big enough to be worth doing in its own PR.
Fair enough. I wouldn't change the capitalization though.
I wouldn't name it in capital case because it isn't a constant. Otherwise I'm fine with whatever rename you like.
This empty `if` followed by this line looks off.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
Oh right, sorry for the noise.
can we add a note here why this is optional? the validate request suggests otherwise...
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
If its early I think this is safe - but now maybe the read timeout on test side will be too low.
10 seconds is pretty fast for some of these CI machines to get the whole ES process up. Does this happen pretty early in the process? Either way, this change might be shortening the timeouts that the CI nodes need to get ES up in time.
I'd prefer `param.substring("the 13 character string".length());` or something like that.
What uses this? And why is forbidden APIs not angry about passing in String,int here... i feel like i banned that method. I dont like it as its wired to 127.0.0.1 in non-test code.
would be nice to allow to configure it to a percentage of the heap size
can we make that -1 a constant and use it in all the relevant places? it would be easier to remove it once we go to 4.0
It would be nice to find another way to do this other than replacing the thread context. I had a look but didn't find other ways though :) I guess you have tried as well.
I think that we are leaking a thread local here? We should close the current threadContext before overriding it.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
> write past EOF :dancers: +1!
Instead of having this public ctor should we have one that has this signature: ``` Java public CompressedXContent(ToXContent xcontent, XContentType type, Params params) { // do the serialization here with checked output stream etc } ``` that way we can hide the _CRC32_ impl detail entirely
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
no need to set timeout, the default is good enough
can we try turning those into constants? I think we should try doing this all the time though.
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
I think something like `randomSearchSourceBuilder` would be a more consistent with other random builders.
It drives me bonkers that this is called "scroll" everywhere instead of "scrollId", but it's a matter of taste, no impetus to change it if you like it :)
I think we could check that successful == total shards and that total shards is greater than zero
I'm happy we made those exist queries fast. :)
looks like there are two levels of indentation instead of one
Maybe in the future we want to add a new topology library, e.g. spatial3d, so I think it is better to name the method with a reference to the underlaying library.
I don't like leniency. Can it be `"true"`, `"false"` or `null` with the former parsing to the right `boolean` and null giving the default? A typo of `"tru"` will parse to `false` and that makes me :cry:.
The worst is how `on` and `no` both parse to legitimate values, very dangerous for transposing typos.
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
I think something like `randomSearchSourceBuilder` would be a more consistent with other random builders.
It drives me bonkers that this is called "scroll" everywhere instead of "scrollId", but it's a matter of taste, no impetus to change it if you like it :)
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
scratch that, I think this will be fine as-is in 6.x as well.
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
we also support a parameter called `updateAllTypes` here.
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
I don't think so, I think these should be bytes or size-value only.
++ to keep byteSizeSetting here
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
good catch! that means we are not properly testing this case either given that we didn't catch it.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
+1 to have `fromXContent` and `parse` be static
while I get that the preference for a for loop... but the inconsistency of how xcontent is parsed is annoying.. if we do it everywhere using a `while (...)` then we should stick to that... if we want to change to a for loop, then lets do it across the board
replace match here too
well, we can call it `ZenTestDiscovery` :) - my point is more that then we can move the `getZenPing` to the test only variant and not have it public on `ZenDiscovery`. There were also times where we considered mocking elect master service where this test-only discovery would have been useful.
Nit: this blank line is extraneous.
can we add that to ClusterStateCreationUtils? It might be useful for others as well
++ . nit: add the state to the message please.
Oh, that error handling!
same here re enumSet.toString
not sure either, I just thought we introduced `parserName()` to have our temporary `toQuery()` method working. ``` //norelease to be removed once all query builders override toQuery providing their own specific implementation. public Query toQuery(QueryParseContext parseContext) throws QueryParsingException, IOException { return parseContext.indexQueryParserService().queryParser(parserName()).parse(parseContext); } ```
you don't have to assert on anything if an exception is expected
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
I had a look at all these parse methods. We might need to clean them up, we have too many variants of it, most of them are used in tests. But in general they are used by any component that needs to parse queries: percolator, highlighting (supports a separate highlight_query that gets parsed as part of highlighting), query rescorer, translog (old delete_by_query)...... I think those parse methods should be converted to fromXContent and return a QueryBuilder instead.
I think we might want to add this to the docs for delayed allocation (just so users are aware)
why did you decide not to do the approximation we talked about? i.e., `System.nanoTime() - (Math.min(0, System.currentTimeMillis() - this.timestap))* 1000000L;`
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
It seems like there are unnecessarily many levels where `null` is allowed. You're allowing `aggregatorFactoryBuilder` to be `null` here, but also in `FeatureIndexBuilderJobConfig` `aggregationConfig` is allowed to be `null`. I think at most one of these possibilities should be allowed.
typo: randon -> random
Should `job` be changed to the plural `jobs`? In ML we were told to use the plurals of `anomaly_detectors` and `datafeeds`. Other APIs that return lists of configs are also plural - `nodes`, `indices`, `aliases`, etc.
I believe we've been just using the string version of field instead of these lately.
Nit: `cs version` -> `cluster_state_version`, please.
Maybe we should try to use a vLong? 8 bytes per bucket can be significant if there are lots of buckets
maybe make sure it's positive
mayb just do `if (++count >=`
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
You can use the diamond operator here.
You can use the diamond operator here.
This can all fit on one line.
oh... didnt see the `updateInvocation` counter... nvm
nit: extra newline
nit^2: `assertThat(putTemplateListeners, hasSize(additionsCount));`
ok thanks for the explanation. @s1monw any magic that we can do to fix this? :)
I think this constructor can go away
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
would it be possible to eagerly initialize the clients and make them final? I don't see why not, but maybe I am missing something.
are there concurrency concerns here that closeClients is called while we are initializing? I see that both `hasXPack` and `nodeVersions` are explicitly assigned to non-null values. anyways, I guess assertions do not hurt!
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
yep. missed it. sorry for the noise
nice one. Good to add.
can we add some randomization here around the version - check that new has a higher version then old and vice versa
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
I suggest adding a volatile flag called `running`, add a method called `stop` that sets it to `false` and interrupts the thread.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
instead of if statements maybe use switch statement? ``` java switch (toType) { case: "integer": // do stuff break; case: "float": // etc. } ```
maybe move all these if checks to execute method? (I personally find that easier to read, when we get in do\* method we know we're good to go) Like this: ``` java if (update != null) { doUpdate(data); } // next if ```
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
It could be useful for debugging too. In the future it's conceivable that the support diag tool might use the HLRC, and we wouldn't want to be dropping this value.
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
This is only used in the constructor, doesn't need to be a field.
No, that's fine.
I'm undecided about whether this is too much machinery, and a simple `Mode` variable would be enough.
I had a look and the settings code has been dramatically improved with 5.0 already, hence this fix is not required any longer. Nothing to do then, but thanks again for pointing this out.
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
1. There is a minor typo/grammatical mishap here - text should read "[cluster.name] must not _contain_ ':' character" 2. Id consider putting this exception text into a final static variable somewhere it would make sense to put it. This text is currently used in two places in the code - once here, and once in a unit test - and the way things are now, if you want to change the contents of this text, you need to change two strings in two different places in the code. If you had this text in a final String variable, and you referenced that variable here and in the test, you would only ever need to change the string in one place.
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
oh cool the read is in the ctor! nice!
can we name this `CompleteDiff` don't use simple please :)
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
connec to to -> connect to
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
no need for `else` here
I think s/lang/defaultLang/
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
I'm not super comfortable making this. I think maybe instead we should add the match skipping at the `FieldParser` level. Maybe some kind of subclass that skips or something. Not sure.
this example is not that close to reality. we cannot really parse such an agg as we need its type in the name (type#total_number_of_ratings). That is what makes the field not unknown, which is why I am not convinced that the mechanism should be a match all.
I guess it is "these" marked consumers now.
do we want to check the phase/action times since those are meant to change
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
oh, woops. thought I counted right. sry
I'm fine with leaving it, yeah. I did want a prettier one but if this is what we can do, it'll do.
I talked with @costin earlier about this - he wants to keep the order the same and my proposal doesn't. What about this? ``` while (result.size() > 1) { ListIterator<Expression> itr = result.iterator(); while (itr.hasNext()) { itr.add(combiner.apply(itr.remove(), itr.remove())); } } ``` Your version works but `for (int i = 0; i < result.size() - 1; i++) {` make me think it'll be a normal loop and then you remove and add and I'm confused. Using the `ListIterator` forces the reader to think.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
I took another look at MovAvgModelStreams, and although I'm not completely sure it look a lot like what NamedWritable is doing, so I was wondering if Stream could be replaced by it.
Curious about where the stream name gets read on the receiving side. Maybe read/write could be changed to be more symetric, but I haven't completely checked the deserialization code.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
Sure I was just wondering if there is a use case for this.
Why would a user set this setting to false ? It's not taken into account when the shard is closed due to relocations or when the index is removed so is it useful to have it as an updatable index setting ? IMO this could be a chance to remove the setting and force the value to true.
The `<=` will need to be escaped.
Lol - I spent some cycles trying to figure out how the hell we know this won't throw an index out of bounds exception, only to end up learning something about the BitSet api - it's funky ;)
This is fine as-is.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
It would be nice to find another way to do this other than replacing the thread context. I had a look but didn't find other ways though :) I guess you have tried as well.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
space between `if` and `(`
and use the constant here
Maybe call this "testEmptyBoolSubclausesMatchAll()"? Sorry if I misunderstood what the test is doing, I just think having a github issue number in the name is unhelpful to someone if they see a failure.
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
btw - the test uncovered some issue with the dangling indices import. You might run into a node not connected issues - working on an independent fix.
Yeah, it seems it is. We treat non existing indices as red. Thx for educating me.
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
I might do `assertThat(totalShards, greaterThan(1));`.
I see that we need it from another package, I think it's ok.
maybe you can just delegate to `read(byte[],int,int)`
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
can you use try with resource here since we are on java 7 now ie: ``` Java try (CBORParser parser = CborXContent.cborFactory.createParser(content)) { parser.nextToken(); generator.copyCurrentStructure(parser); } ```
@s1monw if you're proposing we use inheritance and you assume the base class will always be caching DF then we could just remove all the "if(this.docFreq)" checks in the existing code as a simple way to clean things up? That would leave us with just the "if(this.totalTermFreq)" checks.
I think we should have a baseclass that only handles DocFreq and then subclass it if we need TTF that should remove a lot of branches here though. I don't like the long methods that basically repeat code because of the TTF / DF swtiches. I mean it makes sense do split it since they have a higher cost if TTF is needed though.
+1 there is a good example in BlendedTermsQuery though
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
Fine with me :) I'm already wiping the repository itself after each test, so this shouldn't have much effect (I don't think).
To coerce, should be: ``` parser.longValue(true); ```
same here: ``` parser.longValue(true); ```
Error if old-style params passed alongside new-style script
We need to check here if `ttl` read from translog is lower than 0, if so, then we actually don't have a value...
Oops nevermind, I misread.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
Here you call super method while in toQuery/doToQuery, doEquals, doWrite etc... superclass calls abstract method. Any reason why this is different here? Might be more consistent to follow one pattern and have the superclass always call concrete implementation? Just an idea really.
Maybe this should use a Boolean instead (the object wrapper) and only write it if not null. I know the other integers are not doing it, but I think this one is different since `true` is a valid value while `-1` is an invalid value for the other fields.
can we fix this and use `more_like_this` rather than `moreLikeThis`
Can change this to the new autoclose functionality in Java 7 now that the codebase is on it: ``` try (ZipFile zipFile = new ZipFile(pluginFile)) { // ... } catch (Exception e) { // ... } ``` Thereby dropping the entire `zipFile`-related code from within the `finally` block.
It'd be better, to only skip the config files that have the same name, not the whole directory. So for example, if currently es has a config dir that looks like this (for plugins `foo`): ``` /config/foo/bar.yml ``` and the new plugin that installs needs to copy two files there: ``` /config/foo/bar.yml /config/foo/baz.yml ``` we'll skip `bar.yml` but we'll still copy `baz.yml`. This will help us a lot when we guide the user on how to upgrade - instead of telling the user, to copy & modify a bunch of files, we'll only need to tell him to modify files under `config/foo`
Feel like this should be more significant than `debug` because it really indicates a form of failure in some scenarios.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
can you add a //norelease here too? context should really go away after all queries are refactored
maybe we should just get rid of this local variable and write the next line: ``` nodesIds = filterNodeIds(clusterState.nodes(), resolveNodes(request, clusterState)); ```
"Simulate a task that attempts to execute only on filterNodes. We are testing that this works."
I think this file needs formatting `if(` -> `if (`
oh man that class is a nighmare. really I just realized how fucked up this is grrr.
I also wonder if we can trash this method then altogether a make `GatewayAllocator implement ClusterStateListener` and add it to the `ClusterService` once constructed or maybe inside the ClusterService...
I dropped QueryRegistration in https://github.com/elastic/elasticsearch/pull/17458.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
extra space makes everything not line up!
Missing a space here after `id`
Elasticsearch tradition is to make this an EMPTY constant :)
same here re enumSet.toString
I prefer my way but have asked @jasontedor to chime in.
++ . nit: add the state to the message please.
can you use `InetAddresses.forString` intead, which guarantees it won't do a dns lookup
I also think we can add a method that checks for precision to simplify this! please
same as above, no need for try catch
Same, copy-paste error here
This looks like a copy-paste error
this would make sense especially given that their setters accept primitive types
This is going to be 512 Unicode code units, but I think we should do bytes.
nit: maybe use Strings.isEmpty.
This should be `aliasAction.aliases == null || aliasAction.aliases.length == 0`
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
these unit tests are great! We are going to need more of them :)
after rebase you will have to get rid of any wildcard import, or the build fails :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
if we only use all names to put things in the map we lose all the deprecation warnings that we might have etc. we should rather keep track of the original ParseField and call ParseFieldMatcher#match.
this is same as what we do in term query. We randomly choose a value depending on the type. We might choose the mapped field for that value type, or just pick an unmapped field for it.
Got it, sorry didn't fully realize how value is initialized in any case before. So scratch this remark.
ah ok I see
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
No "unsupported HTTP method" message? :)
I like the idea of the predicate. It could for instance be something like `registry.supports(name, Aggregation.class)`. This way we could also support ignoreUnknownFields for forward compatibility
BiPredicate<String, NamedXContentRegistry> ? is that ugly? :)
I am trying to think if these can be a single field rather than two that are so tightly coupled. I couldn't come up with a good idea but maybe you will...
indentation is off after other changes
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
this will not work, right? cause the default is `9300-9400`, which is good, since we want to try another port on the second instance we start on the same machine.
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
Hmm why are we ignoring exceptions here? You can consolidate those two `deleteFilesIgnoringExceptions` into one call and it will do the right thing if either path hit an exc while being deleted...
gotcha, thanks for explaining.
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
I think we can remove this
ok as a follow-up
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
++ thanks for changing this :)
don't prettyprint please we don't test this here
I think checking for newline is better than relying on pretty printing having space between key/object...
I think we should keep it in the name even if it is verbose
I still don't like the verbosity of this... it can get really hairy... another option is to have a boolean overloaded version of the method instead: ``` public void writeOptionalStreamable(@Nullable Streamable streamable, boolean apply) throws IOException { ``` then have it used as: ``` public void writeTo(StreamOutput out) throws IOException { ... out. writeOptionalStreamable(streamable, out.getVersion().onOrAfter(Version.V_1_2_0)); } ```
there are... but I believe this is the most common one by far, hence my suggestion
> If there are multiple commits, what does IndexWriter.getCommitData() return? I am guessing it reads the "latest" commit's data? Yes, the latest.
It won't always be the case that there will be one index commit, sequence numbers will change this assumption.
> At the same time though, acquiring the write lock would be good, because even though there is a warning that this should not be run when ES is running, trying the lock seems like it would be a good idea Definitely, +1
good catch! that means we are not properly testing this case either given that we didn't catch it.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
can we change this to Loggers.getLogger(getClass());? it is what it should have been to begin with, which is my fault ;)
Do you think we could have something like: ``` java bulkRetry = Retry.on(EsRejectedExecutionException.class).policy(BackoffPolicy.wrap(backoffPolicy, task::countBulkRetry)); ``` I find it easier to know what's going on on bulk retries.
For readability, could we have ``` java List<SortBuilder<?>> sorts = mainRequest.getSearchRequest().source().sorts(); if (sorts == null || sorts.isEmpty()) { mainRequest.getSearchRequest().source().sort(fieldSort("_doc")); } ```
So I'm thinking of using this in the reindex API which'd make it used inside of Elasticsearch. Taking a ThreadPool is fairly normal for the internals of Elasticsearch. I suppose if you wanted to keep API backwards compatibility then you could make it optional and the whole thing to fail if one isn't provided but a backoff needs it.
Should we be spawning a new thread here? Other places ES is pretty careful to use some pool.
> I'd rather play safe here and use client-side locking on all list accesses in order to avoid that another change introduces a subtle visibility issue I always get a bit jumpy about just locking things because I don't have a great understanding of when Java is allowed to reorder instructions around locks vs volatile. Its worth looking into more.
This doesn't feel right to me, adding a parameter to the bootstrap check infrastructure that is specific to a check. I think that we should try to find a different approach (I'm happy to help brainstorm about this, but I have not yet done so).
canceled -> cancelled
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
The message is a little weird. I don't think "next release" should be mentioned.
Can you use `== false` here...the `!` is almost hidden in all the other text around it...
nit: missing a space after the first comma
would you mind adding `<>` after `new PriorityQueue` ? otherwise this is an unchecked assignment.
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
this only works if we have entries? shall we check? Also can we just do a for loop here instead
Or do it as a direct followup, I suppose.
you can have a look at SimpleQueryStringBuilder.VERSION_5_1_0_UNRELEASED to see how to do it
new is not possible with an older version...
This method can be package-private.
Here you can do something like this: ```diff diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java index 356b9a29dc..36794e880f 100644 --- a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java +++ b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java @@ -65,9 +65,11 @@ public class PublishClusterStateStats implements Writeable, ToXContentObject { @Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException { builder.startObject("published_cluster_states"); - builder.field("full_states", fullClusterStateReceivedCount); - builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); - builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + { + builder.field("full_states", fullClusterStateReceivedCount); + builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); + builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + } builder.endObject(); return builder; } ``` which makes the JSON-structure clearer in the code.
Nit - strictly speaking these are publishing stats, can we open the object with just published cluster stats (drop received). You can maybe received back in the keys, which can be shorted by dropping the cluster states from the key names - itâs implied from the object theyâre in.
maybe omit lowercase from the method names here? (since these tests also run for uppercase and trim)
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
Let's make this a `SetOnce<BlobContainer>`
Same here, make this a `SetOnce< BlobStore>`
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
This might be `WRITE` actually - we are creating an index or modifying an index after all.
This is tough one. During snapshot operation, we create a record about running snapshot in metadata. So, technically we write into metadata. It's not a persistent record though.... so it all depends on the definition of the metadata. Maybe it was a mistake to put snapshot into metadata though. Now I am thinking it should have been custom cluster state level element. So, we might want to move snapshot into cluster state custom and use READ here.
can you explain why? :)
I usually do this: ``` assert xContentBuilder.generator().isClosed(); return true; ```
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
`readFrom` is going to be removed from the `Writeable` interface, maybe in a few hours. Right now it has a default implementation telling you not to use it. So I'd just skip this bit.
Okay, don't forget the versioning when this is backported to 2.x!
I've been moving these up, right under the other constructors and moving writeTo under it.
wondering if this should call `this(stats.queryCount, etc.)`, since the addition is not required given that we are creating a new object
This should be the version we are going back to, so 6.5. In this PR, disable bwc tests in the root build.gradle file. Then re-enable in the backport, and do a followup to master to re-enable there as well. This minimizes the changes necessary to followup to master (instead of needing to remember and change all the places that have this version constant).
I am concerned this will cause a ton of calls to `nanoTime`. We can prevent this by using `ThreadPool#relativeTimeInMillis()` (if we need nanosec resolution we can add it here too). This means we need to pass a `LongSupplier` to the stats somehow but I think it's worth it.
And we could then just leave an assert here.
+1 then we shouldn't forget about it :)
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
To clarify, I meant the default indices options used if the user doesn't set them.
not 100% sure we wanna return e1 here as failure, maybe the original one would be better given that the fallback call failed? I guess it depends on how you look at it... since we don't check the version of the node we are talking to. Maybe it's good as is, not sure really
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
sorry, my bad.
Since `value` internally is a String now, we can change read/write here as well.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
`s/step/cluster state step/`
I think this should be at debug level
do we want to check the phase/action times since those are meant to change
This seems to test the case where the same path has a number of distinct mount points. Can this happen? I can't think how.
I'd just do `sum += Math.max(0, data[1])`
The existing code doesn't filter out paths whose `mount` property is `null`, so I don't think we should start doing so as per this test case.
future note - once refresh mapping is gone, we should inline this with index creation.
in the case of createIndices, this should send shard failed for the shard routing that triggered the index creation, but it doesn't because the indexService is empty. I think the interaction with shard failures is too brittle/tricky. My suggestion would be to just return an exception on failure and let the caller deal with it in the right way. PS - maybe this signals a testing gap as well..
everything in here just uses the state maybe we only pass the state to the method instead of the ClusterChangedEvent
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
maybe, to be more precise, it would be good to check the partition that included the new primary.
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
Ah sorry missed that
this makes me wonder: if a node has node.ingest set to false, for sure no processors should run, hence simulate should be off and IngestDisabledActionFilter should throw exception when a pipeline_id is used as it does now. But how about crud actions for pipelines? One has to go to specific nodes to store them, that have node.ingest set to true? this may not be needed, as those are just index, delete and get operations that any node supports...it's like making client nodes reject index requests, they can forward them to the proper nodes, no problem with that.
oh sorry I see that you don't register the transport action when ingest is off, sorry I had missed that.
Change to Throwable.
do we really need to do this? I mean if we hit the exception our search layer will retry for us? I don't think we should do this at all.
`expectedType.cast(e)` should remove the need for the unchecked suppression.
hm, thx! I missed something there, sorry.
argh. Missed the grey method start line in the github diff.
I am good
This is especially important in the case of `TransportReplicationAction` where the request sizes can get big. So we definitely want to count those bytes, but still exclude these requests from the checks.
Fall back to _old_ behavior
I think this is easier to understand as it makes a 1-1 copy of the current active shard allocations in the routing table: ``` for (IndexShardRoutingTable shardRoutings : indexRoutingTable) { Set<AllocationId> activeShards = shardRoutings.activeShards().stream() .map(shardRouting -> shardRouting.allocationId()) .filter(allocationId -> allocationId != null) .collect(Collectors.toSet()); if (activeShards.isEmpty() == false && activeShards.equals(indexMetaData.getActiveShards(shardRoutings.shardId().id())) == false) { // only update active allocation ids if there is an active shard if (indexMetaDataBuilder == null) { indexMetaDataBuilder = IndexMetaData.builder(indexMetaData); } indexMetaDataBuilder.setActiveAllocations(shardRoutings.shardId().id(), activeShards); } } ```
I'd just use the Id really
We talked about this and it's going to be tricky. Nevermind...
I personally think those queries should be build using query builders but we can do that in a second step.
cool stuff I didn't see that one!
points are allowed to reuse the byte[] to I would make a copy of it before adding it to encodedPointValues
thanks for unwrapping
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
I think we should inspect the `AssertionError` and make sure that it comes from Groovy (by inspecting the stack trace and looking for `assertFailed` and other relevant Groovy calls).
Ok that was fast :D
this code and the code in `SearchPhaseController#sortDocs` is almost identical. I think the only difference is the assignment of the shard ID. Maybe we can factor this out into a static method and use it in both places. It would be good to redcue the duplication on such a level and it would increase the test coverage. I would be in favor of that.
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
Nit: space between the cast operator and the target.
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
Because I expect the ZIP file to be in my .m2 dir so I can run mvn clean install anytime (even offline)
please fail if vals.length > 3
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
Can you rather call Releasables.close(tops, bottoms, posLefts, posRights, negLefts, negRights)? This way, it will try to close eg. negLefts even if closing posRights threw an exception
Here it still says `on a per index basis` -> should be corrected.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
can we implement `Closeable` and use an AtomicBoolean to signal it's closed I like the `if (closed.compareAndSet(false, true))` pattern
then call here `register(SimpleProcessor.TYPE, SimpleProcessor.Builder.Factory.class);`
Awesome! This is what I was missing! :+1: :heart:
yea, there is no need, if you bind an actual instance, it is by definition a singleton (how would it not be, can't really create another instance of it..)
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
just please don't add one. There are too many classes already.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
The indentation is off here and the rest of the way through this test.
I think we can check also randomly on a shard that relocates _to_ the local node
nit^2: `assertThat(putTemplateListeners, hasSize(additionsCount));`
I think 0 is a good minimum value.
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
We call them "master nodes" everywhere else. :frowning:
I wonder if we should use a hash here instead if some corruption wipes all bytes to 0 or some other value? maybe `MurmurHash3`
I don't think this is going to happen - lucene opted out of Serializable for a long time now I don't think we should add it back. I'd rather drop our dependency on it to be honest!
Sorry, I wasn't explicit, but you're missing "term" everywhere except for the ones that you just fixed.
if you do not supply the the content-type, you can just hand over the builder and do not need to create a string object here. Also I would just return `JSON is disabled` instead of mentioning the config option here. The shorter the better IMO.
I think this should happen first to make this PR less complex
maybe use `AbstractRestResponseActionListener` then you don't need the `onFailure`
Why remove it? I was adding them because I thought it was nice to mark the constructors for anyone unfamiliar with Elasticsearch. It'd help them get their bearings.
there are more similar problems below
`fields = in.readList(StreamInput::readString);` I think
we shouldn't need this here in parse phase
why is this? what's wrong with `1.f`
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
some adjustment is needed here once you merged master in
yes I am working on that
This test should assert that the headers are correct.
And we could then just leave an assert here.
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
The existing `ESTestCase#randomSubsetOf(int, Object...)` should just delegate to this new method here.
I don't get why do we need a special overload.
hm, thx! I missed something there, sorry.
This exception will be treated as ignore replica exception. :wink:
maybe put this check before the primaryTerm check
we throw the exception and thus take care of the interrupt. We don't need to set it...
make it final
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
I think this should take an `OperationMode` to push the conversion into the caller, rather than doing it in the constructor (it seems cleaner to me that way). This is just my personal preference though, so up to you if you want to change it.
Does this message go back to the end user? If so the fact that a map must be empty is more of an implementation detail than an meaningful error message for the end user. Something like "Mapping definition for field X has unsupported parameters: foo, bar" would be more appropriate.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Right, I mean change it so that it isn't static. Or have a different, non-static getAnalyzer() method that calls out to the static version in the base class.
Can we merge wrap() into getAnalyzer()? It feels wrong to have both methods
How about moving the static method to `HighlightUtils`? That seems to me to be a better place for it anyway, if it's being called from multiple highlighters.
Yes, I would ditch DOS (as you have done). I don't think we run any CI on non-ACL aware platforms. If it turns out we do, then we should just do an `assumeFalse` as the test is not possible on that platform.
I think this message should be a bit more clear. Can you include: - the path - the supportedAttributes - some explanation about what attributes we're looking for It can just be `"Don't know how to make file {} non-readable on a filesystem with attributes {}"`
Needs a guard.
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
I see, that is hideous. ð¦
Extra space is extra.
you evil person :)
maybe add a method to `IndexScriptExecution` like this: ``` Java public boolean enabled(ScriptEngineService service) { // return true for IndexScriptExecution.ALL // return service.sandboxed() for SANDBOXED // return false for others / by default return false; } ```
this new exception is going to trigger errors too if we try to serialize it to an older node
Fine by me.
did you run into this being a problem? how can we open an index that was created before 5.0.0 and never had insync replicas but does have allocationId? the only thing I can think of is a node network issue during shard initialization. I'm wondering if we need to optimize for this and no keep this code simple (i.e., demote shards with a lock exception)
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
Compared to our other parsing code this is a little weird because it doesn't know what field it is parsing up front. I get why you do this, but it is weird. Also it is weird because we don't serialize all that much information. You get almost nothing if there isn't an error.
we can't change the format of the response at this time. We can at some point, but for now we just have to parse what we have, and figure out what we should do to make things better for the future, meaning potentially breaking changes etc.
we are generally moving away from gazillion packages and classes I am not a fan of all these service and they make things more complicated than they need to be today. I have a hard time to understand what feels wrong here and where you draw the line
it's really taste I guess so fine with me
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
`seqno` -> `_seq_no`
Nit: `primary term` -> `_primary_term`
I liked the assertion you had there that if already have a result, this one has a higher seq no
Or we can let poorly formatted values pass through and throw exceptions at the end if values are missing, similar to how we do for queries
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
it's annoying that we write this code over and over again!
Nit: spacing between the `)` and `{`: `){` -> `) {`
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
Although the code is clear, the level of indirection here makes it hard for the reader to figure out that this (and similar other) test does. As a suggestion, what about combining test_object/test_object_IgnoreMalformed, then the code from `sourceWithObject` can be inlined in the test case. Also I would make the assertion on field1 and field2 explicit, even if that means a few more lines of code. In this case I would trade repetition for readability.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
`ClusterBlockLevel.values()` ? don't think we need the constant
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
Sorry you are right, we should be using ParsingException. That snippet was the pre-refactored version. The difference is that ParsingException does not need the SearchContext (not available on the coordinating node) and actually points to the location in the request for the error (the XContentLocation). Please use ParsingException in this PR since this is going to be parsed on the coordinating node
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
Not a big deal, I'm fine without it
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
Lets leave off the third sentence
I think these don't need to be volatile any more, now that we read under lock.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
alright that's what I thought too, sounds good
can this runnable be an `AbstractRunnable`
can we just us a `Map` here instead of the guava one
can we keep this simple and just assign a new map here and make it final removing all the weird checks if it's null
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
@bizybot can you open up a issue that describes this behavior of the object parser and label it with discuss? Then we can move this PR forward.
for readability I'd use this. as well
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
space missing before `new Named...`
space missing before `new Named...`
here is a space missing before `new NamedAnalyzer`
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
Can we add a LongGCDisruption variant that allows using the startDisruption and stopDisrupting to control the GC? These extra params feel clunky (and yeah, I probably did it before too :))
I'm not sure this method name is right. Maybe I just don't know this code that well though.
or junit for that matter. try/catch is much more readable (and the way most other tests do this)
Can we just use a simple try/catch here? I don't see why we need to use hamcrest complicatedness...
copy paste :)
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
I think it might be easier to read the code without this method to be honest. It saves a line every time you call it makes me go "what is going on here?" every time I see it. Not sure.
I'd prefer iterating over the map entries here.
Usually we'd stick this on the end of the last line.
same as above for non exception case
I am good
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
`public static void configureSigner(String signer, ClientConfiguration configuration) {`
`} catch(IllegalArgumentException e) {`
you are perfectly right Christoph, let's merge the two and keep the existing class.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
No, you are right, I didn't realize the need for api users before going through the whole changes.
the exception declaration is not necessary.
`.addPathPartAsIs("_xpack", "rollup", "job")`
no need for extra space
I don't think raising en exception to save a few lines of code here is a good idea, please change this back to how it was before.
nit: we almost never use `Locale.US` exept for some number formating. While I think it doesn't make a difference for the enum names in question here, I'd suggest going with `Locale.ROOT`
Also please `Locale.ROOT`
Wasn't me, it was the tests :)
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
we shouldn't be lenient in case `upperTerm` doesnt't implement BytesRef
I don't think that we should move this code into the InetAddresses.java source file. That code is from the Guava code base, and is licensed to the Guava authors (see the license header). By moving this code which is not from Guava here we will create a confusing situation with respect to the licensing of the code. Let's take this code to IpFieldMapper.java.
what about throwing an IllegalFormatException instead? I'm a bit concerned about catching IAE as this is a very generic exception.
ok, fair enough
"just created files" <- what do you mean exactly? if one waits 2h they will be able to read it? if not I would just go with "the permissions on the store don't allow reading"
this feels weird to have this here (concerning whether we should delete data of closed indices , on master nodes - I feel this should be made higher up). It is a different change though... (and has nothing to do with your change).
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
If your intuition is that these will be almost always needed, then obviously we should keep them.
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
fine with me
I think this declaration/initialization can be moved to inside the if
can resolve possibly return null? if so we should check for it
the important part is having multiple open readers on this as well.
Nothing to do here for this PR, but how can we keep this up to date? We already have this list in like 3 other places it seems...
nit: an -> and
last `%version` should be `%major_minor_version`
I think this constructor can go away
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
formatting - 1 line instead of 2
formatting, 1 line instead of 2
I see. The seqNo and the term do not necessarily always go together. the seqNo is the location of the operation and the term is the authority to put it there. I like the fact that the result object only contains the things that the internal engine creates / changes. Seq# are owned by the engine (on a primary). Terms are owned by the shard. I would prefer to remove the term. At least in the example you gave (`Translog.Index#Index(Index, IndexResult`) it's readily available from the index operation.
oh, multi-bucket comparisons are ready already? :)
Any way we can unify this with `BucketHelpers.resolveBucketValue()`? Or perhaps move this into the helper class and rename both of them to be more specific (`resolveHistoBucketValue()` and `resolveMultiBucketValue()` or something?) Also, I foresee this needing to handle gap policies too...unfortunately. :( For example, an agg like Autocorrelation needs to ingest a histogram (which might need gap policy) but emits a set of sibling buckets that represent correlation lags.
I am wondering if it makes sense to implement `getProperty()` for `Aggregations` as well and not just for `Aggregation`. For example in a test I would write something like ``` Aggregations agg = searchResponse.getAggregations(); Object o =agg.get("aggname").getProperty("path"); ``` but if Aggregations also implemented getProperty() I would save another line and it is needed anyway here internally.
I think I would make a breaking change here. Let's drop support for the string value in the builder and add it to the breaking changes. The parser still supports `none` and `all` but the builder only accepts a query. Then the method below needs to pretty much be moved to the parser.
I think the type and queryBuilder instance members could be made final
yes lets do it later otherwise we have to remove setters and break things.
Nit: "seq no" -> "seq_no" (inconsistencies will make searching more difficult)
make these variables protected please and access them directly in IndexShard. I don't like accessing fields on self through getters. Also, this makes the PR harder to review, as it adds much noise.
can we just inline this in the transport action file? I don't see the need for another file.
missing generics type same as above
missing generics type same as above
missing generics type same as above
+1 to that for the yaml configuration.
Maybe merge all the groovy securing code into one place? It feels funky to have the default receiver whitelist here but method blacklist above.
I think we can do this without adding an interface? Users should not need to do this? A script cannot realistically be used for both search and executable. I know this is more a problem with the existing scripting apis, but I think here we can just implement executable, and search should throw UOE.
one more thing (sorry!). For the language clients, I think it would be good to also have a small REST test that uses search_type count, just to verify that all of the clients (and our REST layer) still support it.
I personally think those queries should be build using query builders but we can do that in a second step.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
Would it be better to use the Assert.fail(String) method or throw an AssertionError here? That way the test will fail correctly in the test framework
My motivation is both making it so there is one obvious way to calculate distance (I was reminded recently of this beatiful mantra from the Zen of Python: `There should be oneâ and preferably only one âobvious way to do it.`). I also think not having instance methods will allow us to play more with the underlying field access so we dont need an intermediate object, GeoPoint).
Oh I see, it's the ZTable stuff. Sorry for the noise :)
so what about the other settings you can set on the Item like source filtering? I think we should expose all of them here though.
can we call this RecoveryNodeResponse? (it's no longer about a single shard)
I think some of them could be private
can we do this `((Long)value).longValue())` no boxing needed here
I think you should just do `instanceof Number` and else call `.toString()`
@rjernst can you fix this ^^
Ah yeah I suppose that might be ok, in this case it's user-defined input so that's pretty awkward but it beats breaking.
I'm tempted to also do it in a follow-up pr as this code is really just moved around.
Also captured in #14862.
these ElasticsaerchExceptions are bogus remove them
Typo, "Trasnlog" -> "Translog"
Should use `{}` logging style instead of string concatenation here
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
I'd rather have a different parameter there. However, that would add complexity. It might be better to not handle missing field or NaN and Inf at all and let the user sort it out with range filters.
instance variables should use camelcase
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
you can replace these two lines with a call to `ThreadPool.terminate`
Maybe pull this guy into BackoffPolicy? I figure it'd be useful for anyone uses BulkProcessor in tests. You'd want to make the DELAY configurable, but that is pretty simple.
space missing before `new Named...`
space missing before `new Named...`
here is a space missing before `new NamedAnalyzer`
we set the rewrite method twice it seems? probably a bug in the original parser
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
FWIW I've used this in the past for production ES clusters to have a set of common settings (elasticsearch.yml) and node-specific settings (elasticsearch.json) to merge two files with settings. That said, I still think it's safer/better to remove this feature and fail if more than one config file is found. It reduces the complexity for reasoning where a setting came from.
we need to support whatever extensions Settings supports and that includes json & java properties formats. I wouldn't worry about restricting it to these three (yml, json, properties) with regards to bwc.
with the current code a `logging.whatever.yaml` file would be loaded. I wonder if this is our intention or a side-effect of the current behaviour. Honestly I would be in favour of simplifying this further and even have something like `if (file.getFileName().toString().equals("logging.yaml") || file.getFileName().toString().equals("logging.yml") )` unless we want to extend this to json and properties files, which I think would be off-topic in this PR.
space after `,`
we have a test util method that we use to shuffle fields in the response so we make sure that our parsers don't rely on specific keys ordering.
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
I think this should be trace
I think this can be optimized further. Here we are updating status of shards that are participating in the restore process. There are only two possible outcome of this operation for a snapshot itâs ether done when all shards are done or it is not done. It doesnât matter if we are applying a single shard or multiple shards â there is still only one outcome per snapshot. If a snapshot is done we need to check if all shards in this snapshot has started and if they are not â create a listener. In other words instead of having an array with one element per shard it might make sense to have a map with one element per snapshot.
hmm this has an empty impl? Not sure if we need the `Injectors.close()` if we need it, it should deal with null values!
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
Again, need to figure out what to do if ATOMIC_MOVE is not supported
We should use a try-with-resources syntax with this.
I think using `nextLine` might be easier to read, and since we need all the lines in memory to perform the de-duplication anyhow, I would consider doing it in one step. Using java streams and a set as the Groovy implementation did to take care of the de-duplication would make this concise and easy to understand: ``` files.getFiles().stream() .flatMap(Files.readLines(null, StandardCharsets.UTF_8).stream()) .collect(Collectors.toSet()) .forEach( line -> { // write each line to target }) ``` You will probably have to collect to a different set implementation to preserve order but this is the general idea. Writing a test will make that obvious.
no need for a constant here, you can use `StandardCharsets.UTF_8`.
I think it'd be useful to see the filenames in the exception message.
This `{` block `}` fits the pattern we use elsewhere, but feels unnecessary in this context.
I think it'd be useful to see the filenames in the exception message.
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
@jtibshirani is correct
I think you can avoid that by overriding `AbstractXContentTestCase#assertToXContentEquivalence`? I think it's worth using `AbstractXContentTestCase` here, it's going to be much more thorough than hand-rolling parsing tests.
I need to sit down to make a approach, ill finally have time early next week. Id prefer the manual parsing in order to test the fromXContents, for now.
We do this check in RestoreService.isRepositoryInUse. I am not quite sure what's the reason to repeat it here.
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
I'd just use the Id really
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
> just let the default be 1 instead My rational with going with half as default is that I think that adding replicas should change the behavior - if someone runs with 6 copies , it's probably not a good default to let of them (but one) go away before signalling alarm. I chose the word "half" in order to avoid a loaded word like "quorum" which implies stuff that aren't part of our model (i.e., quorum reads). I don't mind if we round up (i.e., `(size() + 1) / 2`) or down (i.e. `size()/2` ) as long as it's not `size()/2 + 1` .
Can you add the `translogId` to the log message here? It makes tracking stuff down on shared filesystems much easier.
Nevermind, I see it later on in the `commitIndexWriter` method :)
I think the OOM reference was a copy paste error from another clause. This clause doesn't do `translog.newTransientTranslog(translogId);` so no need to revert it - although it seems to do no harm if there is no current transient translog.
I'm okay with this.
I see, that is hideous. ð¦
Extra space is extra.
If we don't cache the fields, we should remove the fields.clear() at the end.
(there are a couple of other places in the code that have the same issue)
You can use joinFieldType.name() right? Instead of `joinField`
Test is called "testPrimaryOperationLocks" and then most of the code is there to check replicaOperationLock ;-)
yes, I thought about failing the recovery in case where the block suddenly appears during the recovery. This has some other adverse consequences though. Needs more thought
we need to improve this, can you add it as an item to the meta issue? I wonder if we can fix this by acquiring an operation permit for each batch of operations that we send as part of phase 2 during peer recovery, and then also check whether there's a read-only block under the permit.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
I think this could use the `rebalance` function in `CatAllocationTestBase`? It looks like it's performing the same function
Remove and create again is not needed I think
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
Forbidden API: ``` Forbidden method invocation: java.lang.String#toUpperCase() [Uses default locale] in org.elasticsearch.cloud.aws.blobstore.S3BlobStore (S3BlobStore.java:204) ```
Ok, thanks for this precision.
It's a pure revert of my previous commit, where I did fix the formatting here. I'm okay with undoing the formatting fix in favor of a pure revert.
I'm good with latest. It's also probably a good idea to change testJoinElectedMaster_incompatibleMinVersion as well
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
and use the constant here
space missing before `new Named...`
space missing before `new Named...`
here is a space missing before `new NamedAnalyzer`
The distinction of what "class" means (why it does not include def or arrays) should probably be explained before this list.
I _think_ (Collections.&lt;String, DiskUsage&gt;emptyMap(), Collection.&lt;AllocationId, Long&gt;emptyMap()) is more "java" here even (and maybe especially) if it is a horrible mouth full.
I think think `type` (not the naming scheme, but the concept) should be explained outside of this list? It applies to eg javaType above as well.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
It seems like there are unnecessarily many levels where `null` is allowed. You're allowing `aggregatorFactoryBuilder` to be `null` here, but also in `FeatureIndexBuilderJobConfig` `aggregationConfig` is allowed to be `null`. I think at most one of these possibilities should be allowed.
Should `job` be changed to the plural `jobs`? In ML we were told to use the plurals of `anomaly_detectors` and `datafeeds`. Other APIs that return lists of configs are also plural - `nodes`, `indices`, `aliases`, etc.
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
I meant that other way around, not in the else, set termsLookup only if values == null
looking deeper, I see that we set a non null TermsLookup object only when we have it in query, which causes a validation error when values are set too. We should keep it that way then, this is as good as it gets.
I don't think this needs the string/boolean. They can be regular enum values. And the constants can be inside the enum, so that they can be used as if they were additional values.
Since we have this guard here, should `innerClose` be changed to have ``` java assert !closed; ``` instead of ``` java if (closed) { return; } ```
as said above, the double negation here feels weird to me, but again maybe it's just me
Doesn't actually throw `IOException`.
I think it'd be useful to see the filenames in the exception message.
I think it'd be useful to see the filenames in the exception message.
I think we should separate the two and push this as is. Your code refactoring has more changes than this functional change and on the security end I think we should be careful. let get this in and cleanup the stuff afterwards
please wrap with `{}`
please wrap in {}
can you try to exercise this method to make sure we open a new searcher and close / release everything
something like this: ```Java public SearchOnlyEngine(EngineConfig config) { super(config); try { Store store = config.getStore(); store.incRef(); DirectoryReader reader = null; boolean success = false; try { this.lastCommittedSegmentInfos = Lucene.readSegmentInfos(store.directory()); this.translogStats = new TranslogStats(0, 0, 0, 0, 0); final SequenceNumbers.CommitInfo seqNoStats = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(lastCommittedSegmentInfos.userData.entrySet()); long maxSeqNo = seqNoStats.maxSeqNo; long localCheckpoint = seqNoStats.localCheckpoint; this.seqNoStats = new SeqNoStats(maxSeqNo, localCheckpoint, localCheckpoint); reader = SeqIdGeneratingDirectoryReader.wrap(ElasticsearchDirectoryReader.wrap(DirectoryReader .open(store.directory()), config.getShardId()), config.getPrimaryTermSupplier().getAsLong()); this.indexCommit = reader.getIndexCommit(); this.searcherManager = new SearcherManager(reader, new SearcherFactory()); success = true; } finally { if (success == false) { IOUtils.close(reader, store::decRef); } } } catch (IOException e) { throw new UncheckedIOException(e); // this is stupid } } ``` I did something similar a while back so I had it ready... I am not sure it safe to use ð¯
nit extra newline
well we use a dummy lock so I guess it's fine
try finally here please since if close fails we don't release lock etc which can be missleading
we have `TestThreadPool` that makes it simpler
As this setting should usually be only set once, it is probably simpler to leave it non-dynamic (as @jasontedor suggested and as it was before this PR). In case where this must absolutely be updated on a production cluster, rolling restart (of master nodes) with config update is always possible.
Space after the equals. Its a silly small change but it helps my eyes.
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
I think we can go with a higher bulk size, because we only do deletes. Something like 5000 or even 10000.
This default of 1 second is too low, it should be 60 seconds by default.
Just a question: would it be possible to extend from `LongFieldMapper`? Would be nice to have some code reuse.
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
If it can be null we should skip it here.
Maybe use a simple for loop here like: ``` Java if (!contextMapping.isEmpty()) { builder.startArray(Fields.CONTEXT); for (ContextMapping c : contextMapping) { builder.value(c); } builder.endArray(); } ```
fyi, I added serialization to the enum I moved to MatchQuery (#13402) maybe we can reuse this.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
Since `value` internally is a String now, we can change read/write here as well.
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
Nit: " . " -> ". "
The `<=` will need to be escaped.
maybe just inline this into the `planIndexingAsNonPrimary` method? I think that would be cleaner.
I think you should inline this into `planIndexingAsNonPrimary` then we don't need all the asserts
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
thanks for moving this to a unit test!
these don't need to be static
Good idea to add this safety net.
indentation makes the `if` block a bit hard to read
Sure, I was just thinking out loud
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
s/listener/delegate/? I read this and immediately thought "infinite loop!" because this thing already **is** a listener. I know it is silly though.
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
confuses the shit out of me everytime :)
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
I know this is how it used to be, but can we make the if be more like the `masterNodeChangePredicate` name and check the the master node is not null and have changed? (we now test for a cluster state change)
using ActionListenerResponseHandler will simplify this lightly.
Somewhat simpler: ("timed out while retrying [{}] after failure (timeout [{}])", action, failure) . I'm doubting between DEBUG and WARN for this log...
The language in this sentence isn't clear, perhaps change "that is replacing" to "and it is replacing"
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
I am not sure whether the log message is too specific, i.e. the subclass must not necessarily be a service.
yeah, prefer top-level there as well.
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
I think we don't need to make the global SuggestBuilder implement NamedWritable, simply Writable should be enough. This is the only implementation (and will likely stay so) so we don't need to differentiate it from others on the stream.
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
I think s/lang/defaultLang/
Fine by me.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
Nit picky: I wonder if we should make this ctor get all the parameters and construct the message locally. Will be easier to read the code and use, imho.
one line too much
Can we switch between the string and the millis representation fo the modified date using the `human` flag like the explain API already does? That way we can just have one `modified_date` field in the output? Also the parser will not need to worry about the string version in this case since the client it will never set the human flag
It seems like there are unnecessarily many levels where `null` is allowed. You're allowing `aggregatorFactoryBuilder` to be `null` here, but also in `FeatureIndexBuilderJobConfig` `aggregationConfig` is allowed to be `null`. I think at most one of these possibilities should be allowed.
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
Nit: spacing between `!` and `value`.
Nit: spacing between `while` and `(`.
this deserves a sep issue I guess but good catch
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
+1 to support it and also +1 to not do it now
And we could then just leave an assert here.
too many shards [%d] allocated to this node, [%s=%d]
too many shards already allocated to this node for index ...
and 2 more occurrences below
this might also be called I think
this could possibly called I think
this might be called by `scheduledRefresh`, which can happen at any time
I called these methods test*ToAndFromXContent() as they effectively do one complete roundtrip: toXContent -> fromXContent -> toXContent
I am adding a util method for this in XContentHelper, maybe worth replacing this later (should not block this PR)
I really dislike this style of variable reuse in our tests. If I use my IDE to navigate to the definition of this variable I end up on a line assigning a value to this variable that is removed from its current value. This hinders readability, especially in longer tests. Letâs avoid introducing it here, we should be moving away from it.
can me extract this into a method, it is used in 3 places
optimization nit, but maybe we can just have one list, and reorder to push active one to the start, we do something similar in primaryFirst. This will mean we don't have to create 3 lists, just one
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
Right... but I'd be happy if we could unit test this, and if we do then we need to ensure the object start.
We don't need to use this local ref
Sorry, I just saw that you remove them already, thanks!
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
we shouldn't be lenient in case `upperTerm` doesnt't implement BytesRef
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
`createIndex("test")` ? then you can remove the following `assertAcked`
I think we prefer not to use underscores as part of method names, camel case is better
are those number randomizable ie `randomIntBetween(1,100)`
too many shards [%d] allocated to this node, [%s=%d]
and 2 more occurrences below
can you undo all indentation changes, it adds noise to the diff
I think that inserting random fields here would reveal problems on the parsing side with the current code.
you can make one of them public and call it from both tests, I don't mind
I called these methods test*ToAndFromXContent() as they effectively do one complete roundtrip: toXContent -> fromXContent -> toXContent
Nit: `who's the a better` -> `which is the better`
Nit: `candidate` -> `candidates`
It turns out it's hard(ish) to remove ElectMasterService from guice.. not doing.
maybe we could randomize the names of the 2 settings we have in this test
nit: extra newline
same here just use synchronized methods
what naming convention do we want to follow here? I saw around some innerQueryBuider(), here innerQuery(), maybe we even want to drop the inner prefix... let's decide for one of the options and go for it everywhere.
I would probably throw an exception instead of accepting null here.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
I'm confused. Does this mean we restart the leader checker on every incoming publication? We call becomeFollower on every incoming publication
Nice. I think this is a strong enough link between `currentPublication` and `mode`.
I think this'd be better put into the `Mode.CANDIDATE` branch below. I think we can also assert in the `LEADER` branch that either we're the master or nobody is. Anything could happen to a `FOLLOWER`.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
Cancelable -> Cancellable
I think this catch not needed. It will be caught higher up.
I think it'd be cleaner to put the `finishHim(e);` into an `else` statement than to return early in this logic
It's super minor, but our log standardization is usually all lowercase
Same here with period and lowercase
Just a suggestion, I don't mind if we remove it here entirely. I used to like those tests because they show how a typical xContent output of those classes looks like. But with these large ones its kind of debatable whether it is useful.
maxDepth can be final
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
I'm afraid we need to rely on the order if we want to be able to distinguish between negations (applied when a wildcard expression appears before the negation) and referring to indices that start with `-`. We will be able to get rid of it in 6.0 only when we will be sure such indices are not around anymore. I opened #20962. Can we also have a test where the wildcard expression is not the first expression but still before the negation? e.g. `test1,test2,index*,-index1`
Also `-test1,*test2*,-test20` or something along those lines? :)
do you understand this if block? I suspect it made sense before your change, to make it possible to refer to existing indices or aliases that started with `-` rather than treating the name as a negation. That said, I can't quite follow why it makes sense in some cases for `result` to be `null`. This was already there, not your doing but I wonder if it's related and may be cleaned up.
nit: s/read blob's/read the blob's
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
what naming convention do we want to follow here? I saw around some innerQueryBuider(), here innerQuery(), maybe we even want to drop the inner prefix... let's decide for one of the options and go for it everywhere.
`} catch (IllegalArgumentException e) {`
`public static void configureSigner(String signer, ClientConfiguration configuration) {`
`} catch(IllegalArgumentException e) {`
Why do we need a good github search when we have @clintongormley :)
I think we should throw an exception if `mapper.nested() != Nested.NO`, as this would not make sense (and I'm pretty sure some users have dynamic templates to make all their objects nested by default).
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
Allowing this to be customizable is nice but it is going to break parsing pretty hard if this doesn't stay MILLISECONDS.
I think it might be worth dropping the `timeUnit` for now? I'm just scared of it.
This should probably be an IdentityHashSet.
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
this can go back to boolean if we move back Settings to boolean too
> write past EOF :dancers: +1!
thanks for improving this, this part is easier to read now IMO.
> should we just do the naive thing and handle the last 8 bytes case via a naive loop of writeByte() for each byte, so that the footer logic is only in one place? +1
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
I might use an empty array here or switch the IdsQueryBuilder work with lists.
I'm fairly sure I have the wrong generics incantation there....
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
the printStackTrace should go away here
I think we are still missing preference? Should be similar to the get API.
we should support the preference and parent flags similar to the get API.
good point. I didn't think about that. The value to append can be an json object too, so yes the exception should be replaced with logic to deal with that.
remove this additional line break? :)
Oh, never mind, I misread. Sorry for that. ð
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
ok cool then we need to fix this place? https://github.com/elasticsearch/elasticsearch/pull/3953/files#diff-79371c2235df5580ddc99db30932bea5R89
catched -> caught
I am not sure RestoreService would be the right place for it since addBlock would need to be moved to the same place and it's currently used all over the place. I don't have an issue with renaming it to `addIndexMedataBlocks` but since IndexMetadata is the only parameter, repeating IndexMetadata in the name might be redundant.
should we check here that the totalShardWeight is not negative. I was just thinking if somebody uses the number of docs per shard and we overflow? I really wonder if we should put some upperbound into the setting to ensure folk don't go crazy? They should use some log scale rather than actual numbers? maybe we use `1<<16` as the upper limit for now? and move totalShardWeight to a long and use doubles elsewhere? I really just wanna protect us form going negative :)
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
"new" -> "now"
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I think we should return active.get() == false and also - set it if we became idle...
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
same here for the leading whitespace char.
Should use `{}` logging style instead of string concatenation here
No need for an empty default ctor when the super is also a default ctor.
This cast should not be necessary. You can use `in.readMap(StreamInput::readString, StreamInput::readString)`
Does this rest path potentially limit api additions/changes moving forward given that there is no description of what action is being taken as part of the path? Something like admin/scripts/lang/painless/action/execute may be significantly more flexible.
maybe add an explicit `continue;` here to indicate that it's being skipped
that's odd, the root cause is really useful only with SearchPhaseExecutionException. But I don't think we can do better than this ATM.
Actually plugins can implement `Closeable` and they will be closed when the node shuts down.
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
maybe add what we computed as the scope of the alias and the path to the error message
+1 then we shouldn't forget about it :)
right thanks for the explaining, I should have known, having worked on the search refactoring :)
Please revert this change.
I don't think so, I think these should be bytes or size-value only.
Can you move all that code to AwsEc2ServiceImpl.getEc2Attributes instead? Potentially we could unit test this method.
Why do we need getters? These are all final and immutable
Ah, I see the dilemma. If you want to encapsulate for that reason, that seems fine. Then please use the naming convention proposed in #14266? ie `settings()`, `environment()`, etc since they are read only
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
in the case of createIndices, this should send shard failed for the shard routing that triggered the index creation, but it doesn't because the indexService is empty. I think the interaction with shard failures is too brittle/tricky. My suggestion would be to just return an exception on failure and let the caller deal with it in the right way. PS - maybe this signals a testing gap as well..
everything in here just uses the state maybe we only pass the state to the method instead of the ClusterChangedEvent
oh nevermind, I just found the method that called it with null :)
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
++ for ordinal and tests then
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
oh cool the read is in the ctor! nice!
Ok, sounds fine.
or just: "return ok;"? :)
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
Wouldn't the definition of "upgradable" for string to text/keyword mean the norms setting fits with what is allowed? As this is now, it would mean eg keyword fields could have all of the old settings right, but they would be deprecated...that is just really weird for a new mapper type.
And the same for TextFieldMapper, although that is a little different since it uses parseTextField...
I think we can remove this exception now.
sounds great thanks
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
but if you are in strict mode you get an exception so you don't get back false :)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it will be good to have some kind of progress logs here (like log ever 10k ops or something) under debug.
`engine failure` -> shard failure
I think everything inherited from BaseTasksRequest should be converted.
This is a Request and setters in requests don't typically have "set" prefix and return the request itself. I don't like this notation, but this is the notation that is used in most of the existing requests including this one. Check detailed setting above.
I think you can just blast the entire method in this case.
ta -> to
good test, would be better to move it to a brand new class though, as this existing test class starts a single node cluster but you don't need to send any requests to it. This is a pure unit test, you can call it `StringFieldMapperXContentTests` and make it extend `ElasticsearchTestCase`.
sorry, scratch that, you need parser, which needs the indexService, which needs an index on the cluster. It's all good, leave the test where it is. ;)
I would inline `superSettings` and now there's another `put(Settings.EMPTY)` to nuke.
Can we also defer to `super.nodeSettings(nodeOrdinal)` so we don't also need to set `DISCOVERY_HOSTS_PROVIDER_SETTING` and `MAX_LOCAL_STORAGE_NODES_SETTING` here? (This also picks up a correct value for `DISCOVERY_ZEN_PING_UNICAST_HOSTS_SETTING`).
can we use package private methods and have unit tests for this.. an integration seems like an overkill.
can we do this `((Long)value).longValue())` no boxing needed here
I think you should just do `instanceof Number` and else call `.toString()`
@rjernst can you fix this ^^
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
I think it's odd to have a public constructor for a test only... remove the OriginalIndices parameter at least? it's always set to null I think.
I think you can just blast the entire method in this case.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
remove this additional line break? :)
Shouldn't this check instead be: `if (!(obj instanceof SuggestionBuilder))` Because sub-classes of this class will call its equals to test the equality of its specific private fields.
please wrap in {}
use `terminate(threadPool);` (this method is in ESTestCase)
Can the `Async` interface also be removed? I see it's an interface defined inside InternTestCluster.
++. Maybe also add a sanity check that a get on the doc at the end gives us what we expect? (deleted or found)
I presume this is still in progress? (which is fine)
you evil person :)
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
is this needed here? I think it does something only when the current token is start array or start object.
add action name pls.
catched -> caught
I think this file needs formatting `if(` -> `if (`
This seems not to be the right exception message here (looks like cp'ed from term query).
Maybe throw error here it `nested_filter` is the only allowed option here.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
ok didn't know that. yet another bug fixed in master then it seems
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
you are perfectly right Christoph, let's merge the two and keep the existing class.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
No, you are right, I didn't realize the need for api users before going through the whole changes.
I wonder if this is a good name for this reducer? I haven't got any good ideas for alternatives but to me a differencing reducer would subtract one series from another rather than subtracting offsets from a single series. It took me a while to be clear on what this reducer was actually doing. I will defer to someones better judgement though as I appreciate that this might be a standard statistical term
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
just saw it in the factory validation, nevermind :)
I _think_ we have a deprecation logger. We should probably log something when we see `position_offset_gap`.
Do we really need to ignore the setting in post 2.0 indexes? Why not just support both for a while? You already check above that both aren't specified.
We should tell the use to use `position_increment_gap` in this error message.
I don't think we need this branch anymore.
I believe `ScrollHelper.fetchAllByEntity` already wraps the listener in the client's `threadContext`.
Yes! you are right ð
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
I think the whole method could just be: ``` return randomBoolean ? MetaData.ALL : randomFrom(currentTypes); ```
I wonder if we should start already sharing some common code between our BaseQueryTestCase and this class....wouldn't want to complicate things though. Also our base test class in not in master of course so that woul already complicate things...
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
This needs to be another method (`parseInnerFilterToQueryBuilder`) which replaces `parseInnerFilter` and also takes care of switching the interal `isFilter` flag.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
I didn't check but unittests for this would be awesome!
MultiSearchResponseTests was written before the test base classes were made more flexible, we should probably migrate that too if it works well for your case
I'd probably write validate's results to a variable and reuse it.
then check for non null here...
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
`assertThat((List) filteredMap.get("array"), hasSize(1))` has better error messages.
But you are just fixing a typo so you can skip it.
one too many new line? :)
What is the reason you decided to not use this check anymore? I cannot find it in the refactored method.
nit: remove empty line. But I don't think its worth changing this if there are no other changes and CI is green, only if anything else needs changing anyway.
I think we should close the analyzer if tokenizerFactory is not null. Otherwise, it is never closed. ``` finally { if (tokenizerFactory != null) { analyzer.close(); } } ``` (this looks like a pre-existing bug, it was not introduced by your PR)
can we add some java docs? the name to functionality transition is not trivial anymore
I think this code will be simpler if we have two methods - sendFullClusterState and sendClusterStateDiff , each dealing with it's own serialization (and have the cache map passed to them). We can have sendClusterStateDiff fall back to sendFullClusterState if needed , which will mean no resend method..
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
maybe log it debug or trace? not sure how many times this can happen...
sure, maybe a separate discussion but I guess we will need to log something sooner or later. anyways we can discuss this later on. let's get this in first
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
copy paste :)
solely based on names, hard to distinguish from `testRebalanceNotAllowed`
I like dummy because it implies fake and the index is fake - not just empty.
I wonder if this should be `Exception`. see also #20659
You can remove the `hasResponseFromRequest` method - it is not needed anymore.
You're missing "create" requests here (not sure if you want to support them, just wanted to make sure you knew)
maybe call this `setHit`
You could make it the same with an `else if` instead of `else`: ``` } else if (theAnalyzer != null) { builder.searchAnalyzer(theAnalyzer); } ```
As far as I can (brief check only) they are always null, but it wasn't part of the API to change properties that are not part of the json being parsed. Not a big deal..
Ah ok, I missing that method below, sorry.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
can we do this `((Long)value).longValue())` no boxing needed here
This function is used to resolve index constraint on field stats. I am not sure if we should implement index constraint on a geopoint field but if we don't then we should throw an exception here.
Sure, good plan.
On deeper thought, this seems unduly lenient: it should only return credentials for the role that `GET /latest/meta-data/iam/security-credentials/` returned, and should return 404 otherwise. Also I think `credentialResponseFunction` can be inlined, it's only used in one place. Also also we could prevent cheating slightly more by inventing random credentials when the service starts up, rather than synthesising them from the role name.
... so that this doesn't need the `{credentials}` parameter in the URL ...
I thought we said we would move this method to IndexQueryParseService so we can avoid exposing the Client.
I'd have added an integer to `TypeParser` and sorted them by the integer resolving same integers alphabetically or something. And set the FieldNamesFieldMapper to MAXINT. But I think what you did here is ultimately simpler.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
this entire thing looks much better now! cool stuff
so I think we need to somehow extend the `fuzzyPrefixLength` with the length of our context otherwise we will apply LD to the prefix as well? Also we need a test for this I guess
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
calling `ConcurrentHashMap#size()` can be quite expensive IMO. I think we should keep track of the open ctx in a counter instead of using the map. I don't think being a little off here makes a difference. I think we don't need to add any sychronization changes here.
Maybe `createContext` should take the `SearchTask` as an argument? That'd make it very difficult to forget to set it.
I wonder if we should only do this if the cache is enabled. for all other operations its unneeded and might be overhead? - I mean not the rewrite but the setting the field stats provider. We check this with `IndicesService #canCache(ShardSearchRequest request, SearchContext context)`
Same here, original exception is dropped.
Again, this doesn't seem to actually use the `entry.getValue()`.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
I think this check does not add much (I would skip it)
instead of the assertBusy, maybe use a future above with setWaitForCompletion(true).
This change should not be necessary. We already have the ability to plugin in a filesystem in tests. See `PathUtilsForTesting.installMock()`
> it will for example cause tests that are running on a filesystem that handles paths differently to fail But we shouldn't be testing every FS. We shoudl be testing the logic in plugin installation, which is either is or is not posix. So you can use posix for testing the stuff works, and "basic" for testing it skips the extra code gracefully for non-posix FS.
I mean if path.data is set eg. in the config/elasticsearch.yml to be another location
Yes, I confused myself.
Rather than the `noinspection`, I'd prefer: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java index 7ec47ca..4db70ed 100644 --- a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java +++ b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java @@ -407,8 +407,7 @@ public class ClusterService extends AbstractLifecycleComponent<ClusterService> { synchronized (updateTasksPerExecutor) { List<UpdateTask> existingTasks = updateTasksPerExecutor.computeIfAbsent(executor, k -> new ArrayList<>()); - for (UpdateTask existing : existingTasks) { - //noinspection SuspiciousMethodCalls + for (@SuppressWarnings("unchecked") UpdateTask<T> existing : existingTasks) { if (tasksIdentity.containsKey(existing.task)) { throw new IllegalArgumentException("task [" + existing.task + "] is already queued"); } ``` because it's more obviously correct. :smile:
And so does my proposal, by typing `existing` more strongly than the compiler can do (because of erasure) but is clearly correct and eliminates the suspicious call inspection.
@uboness I mean that it is called by the transport client going through the transport service directly (as was the nodes info call before), it is not exposed through clients, so java api users can't call it explicitly (the `Client` doesn't expose such api).
settings seems unneeded.
I think this catch not needed. It will be caught higher up.
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
nit: extra line
Fair enough. I just see the increment/visit/decrement pattern a lot and it feels like something you could make more automatic/harder to forget/explicitly named.
`blocksmd.copyContext(trysmd);`? I know you use "context" to mean something and this might not be the right use of that word though.
Or `adapter.createStatementMetadata(blockctx, trysmd);` or `trysmd.substatement(blockctx);`.
I see what your are saying but I donât think we can rely on this. The nanoTime() is not guaranteed to actually have nano precision (just resolution). it is only guaranteed to never go backâ¦ > On 29 Jun 2015, at 10:39, Masaru Hasegawa notifications@github.com wrote: > > In core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStateTest.java: > > > @@ -154,7 +154,7 @@ public void run() { > > if (randomBoolean()) { > > timer.stop(); > > assertThat(timer.stopTime(), greaterThanOrEqualTo(timer.startTime())); > > - assertThat(timer.time(), equalTo(timer.stopTime() - timer.startTime())); > > - assertThat(timer.time(), lessThanOrEqualTo(timer.stopTime() - timer.startTime())); > > I think lessThanOrEqualTo is correct. (because it's rounded down to nearest decimal value) > > If we use nano seconds, when start time is 1ns and stop time is 1000000ns (1ms), time() would be 99999ns but it's 0ms because of TimeValue.nsecToMSec. > But if we use milliseconds, above becomes 1ms - 0ms = 1ms. In this case, time() < stop() - start(). > When start time is 1ns (0ms) and stop time is 1999999ns (1ms), it's 1999998ns but time() will be 1ms and stop() - start() = 1ms. > > That's said, I like time() > 0 since it makes it simpler. > > â > Reply to this email directly or view it on GitHub.
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
nit: `an` -> `a`
Can we remove `tag` as parameter here and make it part of the `config` parameter? In the end it is an optional argument and it feels that the this should be part of config, this way the signature of this method remains clean.
This can be outside the try/catch right? If there is a failure to create the pipeline, there is no pipeline to close.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
This could just be `close()`
much cleaner. thx.
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
can this see `unregister task for id: [{}]`
nit: can we rename this to `getTasks`
can we make this ret val unmodifiable please
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
`s/step/cluster state step/`
`ilm-move-to-error` -> `ilm-move-to-error-step`
I'm good with one decimal point with the caveat that this endpoint really should not be being indexed.
No matter what precision you pick will have that problem, for example rounding `89.99` to one decimal point will round to `90`, and so on.
As mentioned above, maybe we don't need this here.
should say shard active
this can ne ThreadPool.Names.SAME, the handling is lightweight enough to not require forking to the unbounded generic TP
add action name pls.
maybe we can factor out a method `boolean hasHits(QuerySearchResult result)` it's used in two places an a complex condition
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
Please revert this change.
When it gets long like this can you indent it like ``` assertResult(() -> builder() .startObject() .startObject("foo") .startObject("bar") .endObject() .endObject() .endObject(), ``` I know we `assertThat` has the matcher second, but maybe we should put the closure second for this? I think it is nice when the closure is second because it makes the code formatting prettier.
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
> Or "no longer than 512 bytes" +1
I'd be more comfortable if this generated random unicode instead.
you can replace these two lines with a call to `ThreadPool.terminate`
I am concerned about this change. We are leaking communication abstraction into the service layer here. I wonder if it can be avoided by passing necessary structures of CreateIndexRequest as part of CreateIndexClusterStateUpdateRequest or referring to it as TransportMessage or passing necessary pieces of information from TransportMessage as part of CreateIndexClusterStateUpdateRequest.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
what are testing here? sounds like primaryPhaseExecutesRequest
I would definitely prefer a pure function here that returns a `Set<ShardId>` instead of mutating the method parameter
Should be unnecessary since shardSafe is called? (as opposed to just `shard`)
My idea was to make the BulkRequestSource hold what it has to hold (the failed items), be able to retrieve them and act accordingly from processBulkIndexRequest, rather than have logic to deal with failures within the BulkRequestSource itself. Exposing different getters might help as well, that's another option. I tend to think that extracting the "processing" part would make things cleaner but I may be wrong.
minDocFreq must be positive
nit: `if minDocFreq is greater than 1, then it must not be a fraction`
nit: `accuracy` instead of `Accuracy`
I think this catch not needed. It will be caught higher up.
this seems like it could create a lot of garbage since we do this for every request. Can we maybe hold a version of this per clusterstate version and invaliate it once the clusterstate has changed...
state might be null here since the benchmark id might have been removed between the call to `containsKey` and get. I think it should rather be: ``` java BenchmarkState state = activeBenchmarks.get(benchmarkId); if (state == null) { throw new ElasticsearchException("Benchmark with id [" + benchmarkId + "] is missing"); } ```
I am wondering if we should add `buffer` (size or operations) to the Status object? We can do it in a follow up if you are okay.
We can setup other scenarios to test the cancellation if we remove `updateLeaderGlobalCheckpoint`. For example, make the read limits reached, then cancel, then verify that we won't issue any read request.
Can we fold all these assertions into a single one? I think this should cover enough. ``` assertThat(shardChangesRequests, contains(new long[][]{ {0L, 8L}, {9L, 8L}, {18L, 8L}, {27L, 8L}, {36L, 8L}, {45L, 8L}, {54L, 8L}, {63L, 8L} })); ``` Moreover, the leader should not return more than the requesting batch size. Here, we request 8 operations, but it returns 9 operations.
I'm not sure we need to send this over the wire though.
Let's use `SnapshotId` instead here.
Looks like a merge issue? (the '+'s)
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
Unused import here (not really a big deal)
Shouldn't this be using `ElasticsearchTestCase.randomFrom` instead of `com.carrotsearch.ant.tasks.junit4.dependencies.com.carrotsearch.randomizedtesting.generators.RandomPicks.randomFrom`? I don't want it to end up not using the right seed
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
actually, if its a single page, then we can just reference the first page byte array, if not, then we should return false. same with `array` and `arrayOffset`.
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
ah I mean't Throwable.... sorry
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
> should we just do the naive thing and handle the last 8 bytes case via a naive loop of writeByte() for each byte, so that the footer logic is only in one place? +1
thanks for improving this, this part is easier to read now IMO.
> write past EOF :dancers: +1!
this is unneeded see above
this should go away
lower case F please :) - "found shard on ..."
good these variants go away...
I wonder if this should just be the implementation provided in `TransportReplicationAction`? It appears there are only two classes that currently provide a non-trivial implementation of this method.
I wonder if this should be `Exception`. see also #20659
final, not volatile...
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
On reflection I think this means we don't need `lastCommittedState` any more.
I don't know how often this is called, depending on this maybe it makes sense to store the formatter somewhere for later reuse unless `format` changes? Is only called a few times maybe not worth the trouble.
Does it make sense to have the Enum and method name the same? I have no preference as to whether we call it `Weighting` or `WeightingType`
This might make the code in MovAvgModel easier as each weighting type will have its own class which knows how to calculate the moving average and we can just call a single consistent method on that class
Looks like there isn't an ExecutebleScript equivalent for search scripts anyway - ignore this.
Talked with @cbuescher in a chat - since these are just copied from their old place they should probably just keep their implementation in this PR. Moving to test framework is still possible in this PR.
Maybe explain that it is used in places where you want to make sure that scripts are valid but don't care about the specific script and this is the easiest way to do that.
Can you add some randomization ? We run this method multiple times and then perform some checks on the generated query (serialization, correctness, ...).
I think this declaration/initialization can be moved to inside the if
I always wonder if we should use the PROTOTYPE constant here instead, cause that is what we need I guess. If so we should change all other tests accordingly
thanks for adding this
let's not log since it is an old index
This could be `Strings.hasLength(tokenizerName)`
can this see `unregister task for id: [{}]`
Nit: addresses -> address
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
this whole block here looks pretty much the same in all invocations. Can we make this even simpler? Maybe create a method `createIndexAndWaitForActiveShards` in `MetaDataCreateIndexService`. I've implemented it here: https://github.com/ywelsch/elasticsearch/commit/6e67ecabbfa5cc2568c0c987401e3ea521c7a330
never mind, I saw them later on
using ActionListenerResponseHandler will simplify this lightly.
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
By the way: lucene expressions "know this"
The use of `#` might make queries confusing since it is also used for filter clauses.
given that we also filter responses by creating a new response filter chain and filtered action listener, this inner class is not just a request filter chain... can we maybe merge the two at this point? Seems like in the end we either filters nothing or both (request and response) anyway...
Correct me if I am wrong but these filters have to be executed in a serial fashion one after another, right? So you can make this async if you need to on top of the blocking loop? I would like to see an example where this is used to understand the rational please :)
I find these two empty `continueProcessing` methods confusing, if we manage to merge the two filter chains impl as said above, we would get rid of them I think
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
does this work? it works for percentiles, but with percentiles rank it's reversed
just saw it in the factory validation, nevermind :)
Can you remove the empty javdoc? We are going to fail the build on those at some point....
Is this any quicker if you use bulks? I tend to do that out of habit.
I find that `equalTo` is almost always a bad choice. In this case I think `assertThat(cancelTaskResponse.getTask(), hasSize(1));` will do the same thing but have much better error reporting. That way you get to see all the tasks when there are too many. Same for the above assertion.
points are allowed to reuse the byte[] to I would make a copy of it before adding it to encodedPointValues
thanks for unwrapping
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
I think this is expected to be a sorted list on the `job_id`.
maybe we should be more explicit and initialize indexBoost in an else branch here, rather than above when declaring it. I think de-serialization is the only scenario when it may not get assigned.
I'd probably add an `else` clause that sets `splitOnWhitespace` to the appropriate value just to be super clear.
this needs to be fixed before merging (as it should go to 5.2.1).
For static varialbles, `final` should indeed be used whenever possible.
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
ok can we rename the getter then to `getFailedNodeExceptions()`
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
This seems to only be used for tests. Maybe it should be a helper method in the test framework instead of part of the public api? I would be afraid of something accidentally using this in ES code.
Can this be split into the two cases `request.normalizer() != null` and `(request.tokenFilters() != null && request.tokenFilters().size() > 0) || (request.charFilters() != null && request.charFilters().size() > 0)` in two separate `else if` blocks instead of separating these cases later? I'm not entirely sure if this works, but I think it would make this part easier to read.
Why not? http://vimeo.com/105758303
Why did not remove this from being a `ParseField`? This seems to go against the prevailing pattern.
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
I think that we are leaking a thread local here? We should close the current threadContext before overriding it.
ow I see this PR is WIP, so I'm guessing that you'll add it :) Anyways this change does LGTM so far.
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
All our tests currently use `RandomizedTest#atLeast` method, you can do the same here.
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
Ok I see the problem... I still find this hackish (needing to throw an exception to test things), but there's no easy way around it if we want to test different requests and responses. I'd consider using a mock request (one per client type actually) instead and give up on testing those real requests and responses. It would be more unit test friendly cause you'd know the request and the response you need to return (unless it's a nodes info request), you don't need an exception and you can assert on the sendRequest directly. Using real requests it feels wrong to only test a few of them anyway and we know that it's the client that injects the headers (`execute` method), that's what we need to test.
Nit: this blank line is extraneous.
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
can we add that to ClusterStateCreationUtils? It might be useful for others as well
do you have indentation at 2 chars only for this method? We use 4 chars in our codebase. I'd appreciate if you could change that.
yeah that is true. nevermind then
true. nevermind then
do we really need to walk these directories, can we just do what `getFSInfoIgnoringQuota` does? I really don't think we should walk the direcotries
I think we should only make the change for total until we see evidence that adjustments need to be made for the others.
This seems to test the case where the same path has a number of distinct mount points. Can this happen? I can't think how.
should be clause.getOccur() == SHOULD
oh sorry, I had missed that you used the filtered collection below
It works for strings by using illegal characters. However here, ranges use a binary encoding and all values are allowed. So we should probably use `null` as a sentinel value.
same question as above
thanks for doing that Colin ;)
I think if we get in that other PR I just reviewd we can reuse here the new method that you introduced there? :)
You're right @benwtrent, we've been dropping the `@throws` clause in some of the methods in the client. We'll need to revisit and add them. I'll make a note to do that.
The indenting is out here
64e5c25 added support for this.
no need for a constant here, you can use `StandardCharsets.UTF_8`.
The method was not named as a setter in groovy so this could be DSL-like. ie, usage looks like (notice the lack of equals sign): ``` noticeTask { licensesDir 'foo' } ```
Note that this is different than setting a single property as it adds the inputs to the list.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
you can do some streaming java8 magic here.
I think you want to say that no commit point was found which could be recovered from the translog.
since we open the translog before the writer now - can we use the open translog for all this information rather than static reading it? this will make sure that we use something that went through all the right validations.
maybe I would split this in two ifs, the outer one about version, then the inner one around levels.
the version here might need to be adjusted depending on the version we get this PR in e.g. if it ends up being 1.6 should be `before(Version.V_1_6_0)`
that looks good, thanks
spaces after '//'
spaces after '//'
Can you throw something else? It just makes me uncomfortable to throw AssertionError.
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
this seems to bypass the IndexSearcherWrapper defined in IndexShard (and passed via the searchFactory)
can this be in try-with logic.... you are not closing this input stream at all
Can you keep the formatting? I tend to find it easier to read when formatted
Can you test something that is not byte-aligned, like /15 or /17? We used to have bugs in those cases.
What happens if `enabled` isn't set? I *think* we should continue to do nothing if `enabled` is actually true.
one too many new line? :)
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
right I see that
please return a Map instead no google guava stuff in public interfaces
can this runnable be an `AbstractRunnable`
can we just us a `Map` here instead of the guava one
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
To coerce, should be: ``` parser.longValue(true); ```
same here: ``` parser.longValue(true); ```
ok fair enough
for readability I'd use this. as well
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
it would be awesome to have some doc-strings on these settings
this should be `INDICES_CACHE_REQUEST_CLEAN_INTERVAL.get(settings)`
here you may be able to use copyCurrentStructure
we should totally not have this method, one more reason to not implement the interface.
maybe just `esVersion()`
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
this always yields true
Thanks for the explanation. Makes sense now, yes. And I learned something too.
If the usage of forbidden APIs is in a few places, I would consider it better to suppress only at the lowest level (sometimes I like wrapping those in a private method I suppress). The reason is that if an unintentional forbidden call creeps in it will be caught.
Should `job` be changed to the plural `jobs`? In ML we were told to use the plurals of `anomaly_detectors` and `datafeeds`. Other APIs that return lists of configs are also plural - `nodes`, `indices`, `aliases`, etc.
This method is defined in `MlSingleNodeTestCase`
This predicate can be simplified to `(count, limit) -> count > limit`.
add space between `if` and `(` (in other places as well)
any chance we can shard this code with AllocationService
Nit: please add spaces after the `if` and before the `{`.
Nit: please add a space before the `,` separating the function arguments.
Nit: please add spaces after the `for` and before the `{`.
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
confuses the shit out of me everytime :)
Maybe we can remain streaming parsing if the type was parsed before the query? If the `XContentStructure` class has 2 set methods setTypes() and setQuery(), then the latter method can be smart, so that if the type is already know it would immediately create the Lucene query. If the type isn't know it would just keep the unparsed query around in a BytesReference field. I see that would change this class completely, but I really like to do streaming parsing if possible.
I would leave it as-is, it needs to extend BaseQueryTestCase
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
Here's another place to maybe use a [field](https://github.com/elastic/elasticsearch/pull/14651/files#r45225330).
`this` is unnecessary
Would you mind moving maxReadRequestSize above maxOutstandingReadRequests so that we have the same order for both read and write.
It doesn't have to be JSON, we support Yaml, Cbor and Smile, so better to say we expected the beginning of an object or something along those lines.
I'd rather like to have a check outside the parsing loop that asserts that the first token the parser emmits is XContentParser.Token.START_OBJECT. I think its save to assume we are expecting full json objects. I'd also just throw a ParsingException in that case.
> we'll still see this infinite loop for "{" for example. I'd expect the parser to throw an exception on this? > Is it really a good idea to have the behavior of org.elasticsearch.rest.action.RestActions#parseTopLevelQueryBuilder be to loop forever on part of a valid JSON request? :) Of course not, and this is not what @cbuescher said.
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
I wonder if it should not also decrement the CountDownLatch if an exception is caught in the SimpleChannelUpstreamHandler ? Something like ``` new SimpleChannelUpstreamHandler() { @Override public void messageReceived(..) { ... latch.countDown(); } @Override public void exceptionCaught(...) { latch.countDown(); } ``` Just to be sure that the client does not hang indefintily.
same as above, function name says nothing about what it does.
Can we get back to this once we need this complexity and keep it as simple as possible for now please? Can we hardcode the OBJECT_FIELD_NAME exclusion and be done with it? queries also have access to individual field names if they need that.
it's a minor thing but why would you assign a variable multiple times when it's not needed? default is a better fit here, it improves readability as well.
maybe we could have a `default` here which could make this switch a bit more readable rather than assigning value before the switch in any case.
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
thanks for adding this
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
Instead of making up our own exception, why not use just use Files.delete? This will give you a better exception message. https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#delete(java.nio.file.Path)
I don't think that a security exception should be re-thrown as an `IOException`.
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
I wonder if we should use the cluster state for this check. I'm worried about people passing in a dated cluster state here. Maybe a cleaner model is to make this method synchronised (to avoid async collision with the create code) and check the existence of the index instance in the #indices map member of this class.
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
I think it'd be nice to remove this second ctor so we're explicit every time.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
Er - if you are going to log something then it doesn't matter which order you do it I guess.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
can you add the `@Override` back? (here and in all the other subclasses of `Discovery`)
While I understand why passing `Plugin` here is safe, after thinking about it a bit, I think I prefer replacing the `Plugin plugin` with `String source` to give the flexibility to choose whether this logic should be applied on the Plugin itself (using `onModule` or `processModules`) or on a different `PreProcessModule` (that latter feels more natural to me)
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
you can move this method (and the one below it) up to IndexShardTestCase (in test:framework). It could be useful for other people.
It's that, or we can replace replace FsRepository with this one, but we need to beef it up.
Same here - the same as base calss
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
Is it a problem if we just track a non-existing file? To me this looks like this is already broken for NativeFSLockFactory, because this one may reuse already created lock files (the existence of lock file does not mean its locked). So we can just record here "there may be a lock file to track".
It would be worth requiring that `jobId` and `jobType` are not `null`.
excude_interim - missing 'l' -> exclude_interim
Misspelled in the \@param tag also
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I think we should return active.get() == false and also - set it if we became idle...
same here - I think it's better to log the info message if the deletion was successful.
Helper method is no longer needed now that `Logger.debug` exists.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Also we should wrap the `-` in `{@code -}`
drop the actually? sounds so "uncertain" :)
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
fantastic thanks a lot
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
Oh nevermind, I see the problem now, the field name is not used to calculate equality so they can stomp on each other even if they have the same name :(
to me these should be sets and required to be non-null
Can this lead to user code change? ( as you changed the tests above )
Should we still log something here, in case `terminal.println` throws an IOException? Or the impossible becomes possible (hey, you never know with JDK9)
And by "log", I guess worst case scenario is `System.out.println("The impossible happened: " + ...);`
I think enforcing this as a List of `ShardLock`s would be better, type safety wise
good catch on delta > 0
`getMasterNode()` already returns null if `masterNodeId` is null. Maybe cleaner to make that explicit in the `getMasterNode()` method (and not rely on the map implementation to do that for us) and also use `@Nullable` on the return type. The effect is that we won't need these conditions here and can just write `return new Delta(other.getMasterNode(), getMasterNode(), ...`
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
use a try-with resources for the parser value
can this be `searchReqeust.source()::size`
Change "param required" to "parameters are required"
Can you reverse this, the negative makes it harder to read
Yes, I confused myself.
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
no need to remember all individual boosts, you can just multiply: ``` java float boost = 1f; while(query instanceof BoostQuery) { BoostQuery boostQuery = (BoostQuery) query; boost *= boostQuery.getBoost(); query = boostQuery.getQuery(); } ```
let's have an assert and drop the branch
I usually prefer the way without the else but I don't object to either one.
you should run `gradle precommit`
minDocFreq must be positive
yes. This is too low level - I think we will fix it at the higher levels. I dont' think deleteIndexDirectoryUnderLock should be lenient
I believe this can be provided by overwriting EsTestCase#xContentRegistry().
Sorry, my bad. What I meant was overwriting `xContentRegistry()` from ESTestCase, I mixed that up. That way you can e.g. provide the parser that you need in the test without the need of instanceParser(). I don't mind either way, feel free to use it or not.
Instead of providing the instance parser by overwriting this method in the subtests, can subtest simply provide their own xContentRegistry with the appropriate parser by overwriting `getNamedWriteableRegistry()` from AbstractWireSerializingTestCase? I might be missing something though.
fyi - this gives you double [[]]
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
Oh, that error handling!
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
+1 to capture `System.nanoTime()` at the beginning of the method
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
yeah, that was what I meant
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
Thank you @jasontedor, I'll have a closer look at how the tests are run. I assume it runs each test method several times, otherwise I would still suggest to restructure `#testInvalidEnum` so it always asserts the invalid enum case.
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
It looks like BASE_PATH can be removed as well.
I think we should support it for individual repositories. Not really sure what would be a use case of supporting it globally.
preferably put this into the `next()` method instead so it will also cover the other blocking calls in this class. Could you also write this as `assert Transports.assertNotTransportThread(...)`, this will save from extra CPU in non-debug mode.
I wonder if we need this at all. The blocking call to the client executes it anyway. The issue was that there was no testing. I think this entire transport action can use a ml threadpool instead
OK. > On 20 Jul 2015, at 14:01, Shay Banon notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java: > > > ## > > - AsyncShardFetch<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> fetch = asyncFetchStarted.get(shard.shardId()); > > - if (fetch == null) { > > - fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction); > > - asyncFetchStarted.put(shard.shardId(), fetch); > > - } > > - AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId())); > > - if (shardState.hasData() == false) { > > - logger.trace("{}: ignoring allocation, still fetching shard started state", shard); > > - unassignedIterator.remove(); > > - routingNodes.ignoredUnassigned().add(shard); > > - continue; > > - } > > - shardState.processAllocation(allocation); > > - changed |= primaryShardAllocator.allocateUnassigned(allocation); > > - changed |= replicaShardAllocator.allocateUnassigned(allocation); > > I will do the assert when I remove the primaryAllocated flag in a different change > > â > Reply to this email directly or view it on GitHub.
Is this necessary? I think that the cluster should know it only has one master node and sets this accordingly.
doesn't this add another field name that wasn't there before? Is this method used? do we need to implement toXContent? I'm looking a the implementation of RecoveryResponse
also applies to other places in the code below, if we decide to do it.
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
I think that we want to log *each* time that we drop a warning header, not only the first time for a given request. Also we can be more precise than the current implementation which says one or the other condition is met, but we always know exactly which condition it is so we can help the user more by letting them know.
`wrnHeaderSize` -> `warningHeaderSize`
I'd do ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new FsChannelImmutableReader(id, channelReference, length, totalOperations); channelReference.incRef(); // reader private reference return reader; } finally { channelReference.decRef(); } } else { throw new ElasticsearchIllegalStateException("can't increment translog [" + id + "] channel ref count"); } ```
+1 to clone()
please - I can help if you want
I think you can just blast the entire method in this case.
I'd just leave the ternary operation there.
I see it now - I think how you've got it now is the most right thing then.
these unit tests are great! We are going to need more of them :)
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
just as a sanity check that declares we do not support arbitrary unicode. I don't think we have that around
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
this always yields true
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
Does it need to be Writeable? It looks like we only serialize it using JSON.
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
You could probably avoid this by making the linux check a method that you stub out in OsProbe.
maybe in a followup we can think about removing these -1s... see what platforms fail, and better fine-grain the stuff (e.g. add assumption for WINDOWS, IBM jdk, whatever it might be). Then we know when and where stats are available.
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
I don't think we either but I know some folks like them so I certainly don't object to them.
Recently we've been doing something more like this: ``` clearIndicesCacheRequest.queryCache(request.paramAsBoolean("query", clearIndicesCacheRequest.queryCache())); clearIndicesCacheRequest.requestCache(request.paramAsBoolean("request", clearIndicesCacheRequest.requestCache())); ... ``` Rather than the loop. The whole loop thing is more appropriate for by-hand xcontent parsing then url parsing.
(hint: ParseField makes it easy)
nit: missing space
just name it `readSize`
can this be in try-with logic.... you are not closing this input stream at all
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
1. There is a minor typo/grammatical mishap here - text should read "[cluster.name] must not _contain_ ':' character" 2. Id consider putting this exception text into a final static variable somewhere it would make sense to put it. This text is currently used in two places in the code - once here, and once in a unit test - and the way things are now, if you want to change the contents of this text, you need to change two strings in two different places in the code. If you had this text in a final String variable, and you referenced that variable here and in the test, you would only ever need to change the string in one place.
I think we should be able to assert here that the `metaStateService` is in its "reset" state, with no pending writes (i.e. empty `cleanupActions` and `newIndices` and `globalGeneration` matching that in the `currentMetaState`.
nevermind I was confused... all is good
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
this keeps bugging me :) we should something on the executor as well....
This logging statement has a `[{}]` but no argument to fill it
we should log the exception here.
we shouldn't need this here in parse phase
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
I guess we just prefer primitive types over objects :)
that is a good idea, but maybe add the switch later on then? it really makes no sense right now :)
was this another problem? I wonder why this assertBusy is needed.
> Though I do prefer that it fails fast instead of lazily later. ++
Actually I just checked and removing name and description from the Plugin interface should be easy. The only thing to think about is what to give for those properties when plugins are loaded from the classpath (plugin.types). I think here the name should just be the classname, and description something like "plugin loaded from classpath"? I don't know what other info we really have.
Also, can you add an element to maven enforcer plugin for plugins/pom.xml so it fails build cleanly and early if this property is not set? We should also insert a check in pluginservice, if it differs from the directory name, someone manually meddled
This file is new in 2.0, we can change it
`retry < this.numberOfRetries` is implied here due to the outer check.
I also wonder if we should log `TRACE`/`DEBUG` issues for this.
nit: s/read blob's/read the blob's
same here regarding the logging as above if applicable
I think this message is misleading - we don't actually schedule the delete of this index but rather ignore it. Maybe change to "failed to lock a dangling index [{}], probably in the process in being deleted, ignoring." . I also think we should include the exception as it may not be a LockObtainFailedException but something else.
Left over Note
let's keep as is, with the assertion message I think it's ok. I wonder if we should have an assertion at the end of this method to say something like "if we have an active primary shard that's not relocating, then the replication tracker is in primary mode".
Oh, that error handling!
With the change I suggested above we can leave out the == PEER condition and instead add ` && currentRouting.isRelocationTarget == false` to `currentState == IndexShardState.POST_RECOVERY && state == IndexShardState.STARTED`
Did you push the change that added it? I don't see it.
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
I'd rather have a different parameter there. However, that would add complexity. It might be better to not handle missing field or NaN and Inf at all and let the user sort it out with range filters.
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
can we use "script_factor" I think it's nicer than the came case
Extra space is extra.
I see, that is hideous. ð¦
you evil person :)
Can you have a quick look again if this should be MATCH_PHRASE_PREFIX_FIELD instead? In which case it would also be good to catch this in tests if it is wrong.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
nit: reading all this makes me think if we could get parseContext.parseFieldMatcher() once with a shorter local name at the beginning and then shorten the lines here a bit. Just for readability. I know at this points it's probably some tedious search/replace action, just throwing this in as a thought.
Same feedback as the last `toString` - I think you can remove `created` and might want to look at `Operation`'s `toString`.
Same deal as the last `toString`.
I'd move this to line above, but I like the thought behind the change.
> we'll still see this infinite loop for "{" for example. I'd expect the parser to throw an exception on this? > Is it really a good idea to have the behavior of org.elasticsearch.rest.action.RestActions#parseTopLevelQueryBuilder be to loop forever on part of a valid JSON request? :) Of course not, and this is not what @cbuescher said.
I'd rather like to have a check outside the parsing loop that asserts that the first token the parser emmits is XContentParser.Token.START_OBJECT. I think its save to assume we are expecting full json objects. I'd also just throw a ParsingException in that case.
Thats a String token though...
+1 to: ``` List<DiscoveryNode> nodes = this.nodes; if (closed) { throw new IllegalStateException("transport client is closed"); } ensureNodesAreAvailable(nodes); ```
Yeah, I'm not advocating for removing the mutex. That isn't going to work. My thought came from vague notions of "can we just set the list to null when we've closed the client?" kinds of questions.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
why did you add it? I mean, it is very internal...., it will mean cluster state API will become so much more noisy
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
This can be replaced by ` ensureExpectedToken(XContentParser.Token.START_OBJECT, token, parser::getTokenLocation);` from `XContentParserUtils`
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
> talking below about using only the index, source, and id probably a typo, but just in case - index, type and id (not source)
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
Please fix identation.
this last line is redundant I think, we already check the same above
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
Given the method's name I expected it to check the values too.
I'd use `randomAsciiOfLength(5)` rather than fixed strings for this.
Sorry about these crazy incantations....
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
yeah, that was what I meant
and the `ExceptionsHelper.` qualifier is unnecessary
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
this will annoy the forbidden API after rebase + squash. Heads up
use ArrayList? one less usage for non standard code...
left over reference to a countdown latch
In our discussion about semaphores I understood a different model we keep a semaphore per index/shard directory (like the on the disk locks but in memory). That would be pruned when the folders are pruned. I see where you were heading. I'm fine with either way.
Oh, nevermind on the second point, I see `ShardLock` implements `Closable` already.
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I think the OOM reference was a copy paste error from another clause. This clause doesn't do `translog.newTransientTranslog(translogId);` so no need to revert it - although it seems to do no harm if there is no current transient translog.
I think this missed a misses a maybeFailEngine
Please fix identation.
Since this is only going to be used in tests, I think we can get away with: ```suggestion return Objects.hash(maxSeqNo, localCheckpoint, globalCheckpoint); ```
Note that you can use Objects.hashCode(function) directly which will make sure to return 0 if the value is null.
It might be a good idea (possibly in a different PR) to have a method on `ScriptEngineService` called something like `getSupportedScriptContexts()` which each implementation can use to define what script APIs they support. I imagine there are/will be other language that don't support some script APIs and this would not only allow them to use this too but would also remove language specific code form the ScriptService, which should probably remain language agnostic.
Ok fair enough, Hadn't considered the settings aspect of this.
same as above, this breaks bw comp for the java api
```suggestion public void setFile(File file) { this.file = file; } public void setFile(String file) { this.file = getProject().file(file); } ``` Along the same lines as above to avoid the use of Object.
I would prefer we use something like `Files.write` where we can be specific about the encoding. `FileWriter` will rely on the default encoding, something we generally try to avoid.
no need for a constant here, you can use `StandardCharsets.UTF_8`.
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
I think we should complain if we don't find the header name.
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
wrap the plugin names in `[` and `]` for consistency
can this be ``` if (pluginClass.getName().equals(plugin)) { luceneVersion = pluginProps.getProperty("lucene"); break; } logger.debug("skipping [{}]", pluginUrl); ``` I think taht is more clear
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Nit: you could use `Collections.emptyList()` instead of `new ArrayList<>()`
I hope I'm not splitting hairs, but there's also a typo in the field (deault is missing and 'f'). (This PR resulted from a question I asked here; thanks for all the awesome work you invest there!)
`s/shadow replicas/shadow shards/`
I think it is important to keep different classes on the client-side so that we can have more type safety and potentially add some methods to only eg. avg in the future
can we make the list immutable for safety? using Collections.unmodifiableList
`them` -> `them;`
I think this needs to be `Version.V_6_0_0_alpha3` now.
Just discussed it with Robert and indeed this fsync is not necessary.
This change would only break `wildcard` query on these fields, right ? +1 to make them string fields, `prefix` and `regex` query do not work currently because of this so it would be a bug fix. I am also ok to do that in a follow up, the changes in this pr have a different scope.
The `keyword` field applies the normalizer on `termQuery`. Depending on the normalizer the wildcard and escaped characters could be removed/replaced so I wonder if we should apply the same logic than `QueryParserBase#analyzeWildcard` for `keyword` fields. This is out of scope for this pr but it made me realize that we might have a bug here.
maybe one day we will a base class for runtime mapper field types that does this in one place.
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
sorry I didn't see that you created a copy (I missed the "new HashMap" part)
I think it is fine: we only build one search context per request per shard.
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
> I think we're talking about two different sets of leniency :) ++ :smile:
The worst is how `on` and `no` both parse to legitimate values, very dangerous for transposing typos.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
replace match here too
Another to remove
Can you remove this class entirely in favor of just returning AcknowledgedResponse? (similar to #32722)
We should be testing serialization here by extending `AbstractXContentTestCase`. Unfortunately, that means we need to also write a parser for the request but it's worth it.
Again, I wouldn't pull out the ternary.
isCreated instead of getCreated
why do you pass the response to this method? `this` already has all information.
Out of date doc.
Discussed via chat - we should not use the Version.CURRENT as a default to make sure the version is set. The part about a 1.2.0 master is not relevant as it will set the SETTING_VERSION_CREATED key as well.
3 more indentation issues above
you can remove the validate call for now, we will fix all queries soon, I promise
here is a space missing before `EMPTY_FLAGS`
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I mean random number of replicas with random combination of non-active states
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
This cast should not be necessary. You can use `in.readMap(StreamInput::readString, StreamInput::readString)`
No need for an empty default ctor when the super is also a default ctor.
No need to override readFrom or writeTo
Is this any quicker if you use bulks? I tend to do that out of habit.
Can you remove the empty javdoc? We are going to fail the build on those at some point....
I find that `equalTo` is almost always a bad choice. In this case I think `assertThat(cancelTaskResponse.getTask(), hasSize(1));` will do the same thing but have much better error reporting. That way you get to see all the tasks when there are too many. Same for the above assertion.
Is there a reason these three fields need to be test instance members be randomized in the init() method? Otherwise I would prfer making them local in createTestIntstance().
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
But that is not equivalent? Arrays.toString is a static method, and different than result.buildConflicts().toString()
maybe put this in an `if else` clause? For me this makes it clearer what is pre 2.0 and what is 2.0 behaviour.
why do we need to merge this again since we are still holding on to the lock? I don't necessarily understand why this is helping us as well but that might just be because I don't know this code very well.
In my dreams, merging would either throw an exception or return a new independent mapping so that we wouldn't need this validation phase :)
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
I think you can just do the `== null` part of this and the next `if` condition, since if the other were equal to null, we would have already returned in the first `if`? ``` if (x == null && y == null) return if (x == null) ... else if (y == null) ... else // x and y are not null ```
I think these don't need to be volatile any more, now that we read under lock.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
I think 0 is a good minimum value.
I don't think so, I think these should be bytes or size-value only.
++ to keep byteSizeSetting here
minor: I think it would be a bit more obvious to explicitly call `DateTimeZone.getDefault()` instead of `null`. Since that is what Joda does with the `null` value. http://joda-time.sourceforge.net/apidocs/src-html/org/joda/time/DateTimeZone.html#line.301
Just as a note, LuceneTestCase (which we inherit from) offers a nice helper to shorten these try/catch constructs, it goes something like this: ``` IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> ...do Something...); assertThat(... some assertions about e...); ``` I see that the rest of this test also still uses try/catch for most exception tests. This is okay as it is, I just wanted to mention it.
can you try and run the test with the seed mentioned in the bugurl and see what happens (also possibly run it with a `-Dtests.iters=2000` and see if that passes) - maybe we drive by fixed this.
timestampMillis -> unassignedTimeMillis delayCalculationTimestampNanos -> unassignedTimeNanos
lastComputedDelayNanos -> lastComputedLeftDelayNanos
Let's call this `timestampMillis`
maybe make if final
maybe s/INDEX/COPY and s/NONE/NOT_STARTED to be consistent you should also s/FAILURE/FAILED
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
Do these really have to be test instance fields? Can they be passed around? They are easy enough to construct.
as an alternative you can mark it as final abstract then you don't need the private ctor
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
I think an absurdly high limit could still be helpful? (in a follow-up PR)
Here again I think we should use `builder.timeField` to handle this
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
I think we should make all of the mutating methods in here package private to be consistent like `moveToPrimary` etc.
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
nit: maybe call this `awaitSearchActive` (or `markSearchActive` if my other suggestion is accepted to move setting the timer here) ? pending refresh is an internal implementation detail..
The reason used to be not to make writeNamedWriteable public. I think it is still the same. Design decision we made with Simon when we added the NamedWriteable abstraction. We didn't want e.g. plugins being able to serialize just anything by using this generic write method.
I don't like that we're making `StreamInput` a God class.
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Instead of making up our own exception, why not use just use Files.delete? This will give you a better exception message. https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#delete(java.nio.file.Path)
I don't think that a security exception should be re-thrown as an `IOException`.
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
not really wrong since we do not require things to be reproducible in that case, but I'd rather like to use context.reader().maxDoc() instead of context.docBase so that matches only depend on the current segment
I'm wondering why you decided to override this optional API. Is this impl expected to be faster than pulling the iterator and calling next in a loop? (this is what the default impl does)
we should use actual exceptions instead of assertions since we are validating some user input
I am fine with doing it in a follow-up PR if that works better for you
don't try to fix it, you just moved code around, but this catch block worries me :(
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
While you are here why not remove the whole `Fields` class and just use strings? That is the "new style". For things that are used in more than one place we'll typically use constants - and if those things are using in parsing the constant will typically be a ParseField, but otherwise we've started to not make these `Fields` classes.
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
this will annoy the forbidden API after rebase + squash. Heads up
w00t thanks !!
`this()` is obsolete
so this means we don't support `topLeft` anymore? I think we have to to be honest. Also we have to support `northWest`
The score of this query depends on the number of shards, the default similarity, ... To make sure that we have consistent scoring you can use a `function_score` query like the following: ```` QueryBuilder query = functionScoreQuery( termQuery("name", "one"), ScoreFunctionBuilders.fieldValueFactorFunction("my_static_doc_score") ).boostMode(CombineFunction.REPLACE); ```` ... and add the `my_static_doc_score` at indexing time.
one too many new line? :)
What happens if `enabled` isn't set? I *think* we should continue to do nothing if `enabled` is actually true.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
Nit: `}` is in a funny place.
Also, we will need the oposite conversion from the ES enums (e.g. TermSuggestionBuilder.SuggestMode) to the Lucene enums (org.apache.lucene.search.spell.SuggestMode) used in the DirectSpellcheckerSettings later anyway, so rather than having `fromUnderlying` better turn the direction around to each enum knows how to produce the corresponding low-level enum.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
Incides -> Indices ? ;)
typo in the method name here too
same as above, this seems the same method as before
confuses the shit out of me everytime :)
"new" -> "now"
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
nit: this change is not needed
given this I think we should add some checks to the place where this is created in `SearchService` ie. this: ``` Java SearchContext createAndPutContext(ShardSearchRequest request) throws ElasticsearchException { SearchContext context = createContext(request); activeContexts.put(context.id(), context); context.indexShard().searchService().onNewContext(context); return context; } ``` should look like: ``` Java SearchContext createAndPutContext(ShardSearchRequest request) throws ElasticsearchException { SearchContext context = createContext(request); boolean success = false; try { activeContexts.put(context.id(), context); context.indexShard().searchService().onNewContext(context); success = true; return context; } finally { if (!success) { freeContext(context); } } } ```
I'm not a big fan of this field. It feels like it could just get pushed down to be an `AtomicBoolean` inside `upgradeTemplates`, or if we need it to be a field, I think it works better if its meaning is reversed e.g. `detectedUpgradeErrors` As it stands we reset it to `true` even if we know something failed, which just feels wrong.
Er, probably not. But a bit confusing name because it looks like a typo.
I think this file needs formatting `if(` -> `if (`
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
I think that this should be an `IllegalStateException`.
Nit: `getNumConnection` -> `getNumConnections`.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
yea, I would at least debug log it..., it shouldn't happen
the important part is having multiple open readers on this as well.
as an alternative you can mark it as final abstract then you don't need the private ctor
we also need unittests for these queries!!!
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
Hurray no more weird `while (true)` loop
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
this is really the job of TRA to test this? it's an index meta data thing. Whis is it here? I think testing here should be very minimal and just check that the TRA funnel index level setting to a request object _IF_ the request has it's method set to default. All the rest of the logic is a `ReplicationOperation` thing.
I think we want to test index level blocks too here
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
I think we should separate the two and push this as is. Your code refactoring has more changes than this functional change and on the security end I think we should be careful. let get this in and cleanup the stuff afterwards
yeah again, its definitely bad the way it is now, easy to break. if we initialize netty classes too early before security kicks in, we might not notice anything, then suddenly users jvms are crashing (e.g. because of some bug in unsafe/native usage, or whatever). with a netty module things would get way better: one advantage is, netty isnt on the classpath anymore, instead we load it explicitly with `URLClassLoader.newInstance` in PluginService, followed by `Class.forName` and so on with the registered plugin class from the plugins configuration file. So it would be well-defined exactly when these classes will get loaded, and its all after security and everything else is fully initialized.
> Last - if there is any way to determine the list of classes loaded at the point security kicks in, Yeah, you can do something like this: `JAVA_OPTS=-verbose:class bin/elasticsearch`
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Ahh, sorry. You are 100% correct.
Sorry, I overlooked the null check. This is good!
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
Is the version needed? I don't see it being read here.
this will annoy the forbidden API after rebase + squash. Heads up
I don't believe its necessary, ++ for taking it out
Not necessary with `ConstructingObjectParser`
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
+1 to not swallow the original exception
Just discussed it with Robert and indeed this fsync is not necessary.
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
sorry, my bad.
Since `value` internally is a String now, we can change read/write here as well.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
good test, would be better to move it to a brand new class though, as this existing test class starts a single node cluster but you don't need to send any requests to it. This is a pure unit test, you can call it `StringFieldMapperXContentTests` and make it extend `ElasticsearchTestCase`.
sorry, scratch that, you need parser, which needs the indexService, which needs an index on the cluster. It's all good, leave the test where it is. ;)
one too many new line? :)
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
`indexMetaData.getIndex()` -> NullpointerException!
Can you open a lucene issue for this? Meanwhile, I think it's a good idea to copy the implementation of checkResetException() into the test code here, as it checks the contract pretty strictly.
Nit: Can we give this a more meaningful name instead of an abbreviation? I'm fine with `TestResponseHandler` for example.
Nice, I like the randomization on the thread pool.
A more meaningful name would be nice here too, for example `TestRequestHandler` is okay.
I wish that we did not have to go from MapperScript to IndexTimeScript, and rather reuse the same concept. I still wonder if this could be `void executeScript(SearchLookup, LeafReaderContext, ParseContext)`? We could make the notion of scripted field known to FieldMapper, let MappingLookup collect all mappers that have a script declared, then each one of those has the execute method called. That way you can also ensure the same behaviour once you add this functionality to other mappers? This suggestion goes against another one I made on making OneTimeFieldExecutor implement IndexTimeScript. MAybe with this suggestion IndexTimeScript could go away and we would have to see what to do with the one time executor.
I can see how having two methods is not fantastic, and why you had done it differently before. I had envisioned script as a member of FieldMapper directly, but we are going to see if that is possible once we add support for script to other mappers. The type of the consumer will make it possibly harder to share the impl but we'll see. I am happy though with the execute method, I find it much clearer than returning an executor like we had before, because it is evident what it does and easier to trace.
Are there any calls to this version of findTemplateBuilder with matchType `string`? Or `findTemplate` below? very confusing how we have so many public variants of this method...
I just realized that this would make the upgrade experience really difficult for indices that break this limit already. They would have to close their index before the upgrade, change the limit in the new version and open the index again. That's a bit too much I believe so to be safe we should check this setting only for indices created before it existed: ``` if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0_alpha1)) ``` ... and only log a deprecation warning if the filter breaks the limit on an index that was created an a previous version (see DeprecationLogger and its usage to see how to do that). This way we could also backport this new setting in 6.x and makes the upgrade easier.
thanks for adding this
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
Can we add an assertion that this is never negative? I don't think it ever will be, but just to be sure...
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
`limitedTo(long bytes)`? Clone is kinda non-specific.
tests should avoid using `now` as it can hurt reproducibility
When you run tests, a seed is automatically chosen and returned in case of errors. This way, you can re-run the test with this particular seed so that these random vars get exactly the same values. This would not be the case if `now` is used.
Same here with line breaks. Usually I see this as `} else {` in our code.
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
I wonder if this should rather be made part of Request#multiSearch like we did for bulk. I see that it may be nice to have read and write methods close to each other, on the other hand the only place where we need to write this format is in our client.
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
Can't recovery -> Can't recover
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
Typo, finalzlie -> finalize
why did you change this to take a `TranslogGeneration` with the uuid instead of just the `long minGeneration`? It's not using that uuid anywhere here AFAICS.
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
I think we should return active.get() == false and also - set it if we became idle...
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
This can be `assertTrue(called.compareAndSet(false, true))` to avoid the race condition between the assert and the set.
We should log the the failure here if the close fails
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
you are right thanks a lot for catching this
There is a problem with this test setup that I just found: the xContentType that is used for parsing here is not necessarily the same as the one that is used int randomUpdateResponse(). So the expected values might be off, e.g. if in randomUpdateResponse() SMILE is used and here xContentType is Yaml.
++ I like that solution here
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
> talking below about using only the index, source, and id probably a typo, but just in case - index, type and id (not source)
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
this is usually a bad sign. We should use sleep anywhere. Sometimes it's needed but we try give all the utilities to make sure no one used it explicitly. In this case we have assert busy: ``` assertBusy(() -> { final ClusterState currState = internalCluster().clusterService(masterNode1).state(); assertTrue("index not deleted", currState.metaData().hasIndex("test") == false && currState.status() == ClusterState.ClusterStateStatus.APPLIED); }); ```
I would reduce this timeout to 0 - we don't care - we check with assertBusy later for execution. Make it fast. Also reduce the publishing timeout by setting PUBLISH_TIMEOUT_SETTING to 0.
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
I don't understand here what you mean by synthetic variable. If you mean the two ENulls, the analysis and writing would be contained to only compile-time.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I think here we can go with an ordinary `BytesReference` and use it's efficient iterator `BytesRefIterator iterator()` the returned `BytesRef` is just a pointer into the underlying `byte[]` that you can wrap in with `ByteBuffer#wrap` and do your accounting what is left for writing in this method. so there is no need to use a `NetworkBytesReference`
I'm not a big fan of ActionListener<Void>? Maybe we can do this differently and replace it with two functions? Runnable for the onResponse() part and for onFailure use a Consumer.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
Hm. Not sure about the custom similarity part. For you maybe :) The whole purpose of IndexLookup was to have an easy to use api for access to term stats. I found it very convenient. Whether or not we should have IndexLookup is a different discussion because it can be used in other contexts too.
I don't think we should even have IndexLookup. It is no more work to write and use a custom similarity than to write and use a native script, and the point of similarity is for customizing exactly this.
I opened an issue for better visibility of this discussion: https://github.com/elastic/elasticsearch/issues/19359
please wrap in {}
please wrap with `{}`
you have 140 chars use them :)
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
I hope we never have to implement this for minor or patch versions of the JVM :X
These should all be wrapped in `<pre>` or `{@code ...}`
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
Same here about parsing end ranges that are out of the integer range
I think this can be done easier with an Iterator ```java final StringBuilder spaceDelimitedJvmOptionsBuilder = new StringBuilder(); Iterator<String> it = jvmOptions.iterator(); while (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(it.next()); if (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(" "); } } return spaceDelimitedJvmOptionsBuilder.toString(); ```
My preference would go to adding a serialization context to readFrom.
I understand this, but this sound confusing to me. You would have some member in each builder that is only set for the prototypes, need special constructors for the injection. I understand your proposed solution with the static method access much better.
well then you have to have a dedicated parser interface - I wonder if this is a general thing we should have on stream input though
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
Can this be "metadata"? We don't hyphenate anywhere else in the code.
Same here, maybe "index-metadata"
This includes both of the fixes but to make the change uncontorversial it should just include the `finally` part, not the checking if the file exists part. Personally I think removing the file up front is the right thing to do but I'd like to separate that out into a separate PR because I expect other folks to object to that way of doing it (see the linked issue) and I'd like to get the `finally` block portion of this fix in.
Let's move this to a `finally` block.
And anyway, moving it to a `finally` block does help because if the create fails because the file already exists, the delete in the `finally` block will clean it up so we only fail in this way once.
this always yields true
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
Sure. This one is more than good enough :)
I think `requiresIndexMappingRefresh` is very misleading - it should be called `updateMapping` as it does update the mapping (and returns a boolean for refreshes)
applyDeleteIndices -> deleteIndices
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
+1 on removing it
Might be nice to add a check for existence of these parameters for completeness.
ok I remember now. The point of IndicesRequest and CompositeIndicesRequest is to return the indices that a request works against. when a request is composed of multiple operations, it should implement CompositeIndicesRequest. In this case delete by query reads from some indices as part of search, and writes as part of deletes. But what indices would it delete from? It is not possible to create a DeleteRequest that points to multiple indices, yet it is hard to predict all the deletions that will be performed as part of the request execution. I doubt that this request should implement CompositeIndicesRequest then.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
And it looks like you cover the response below. So you can ignore this.
I wonder if it'd be nice to have the assertion in the docs with a note about how this is the response. And maybe a note that you don't have to assert anything if you don't care whether or not it was created up updated because non-200s throw exceptions.
I believe this text is out of date now that we have a macro.
yea sorry....... should have been "seems harmless". Yet we may want to change what we do here and whether we need logging or not. And not sneak it in among all these other changes.
Those two code snippets are very similar.. I think we should go more generic here, maybe you can add a static `XContentHelper.toString(ToXContent foo)` which acts like in the `SearchSourceBuilder` and does not throw an exception, but returns an error JSON ``` java @Override public String toString() { try { XContentBuilder builder = XContentFactory.contentBuilder(XContentType.JSON).prettyPrint(); toXContent(builder, ToXContent.EMPTY_PARAMS); return builder.string(); } catch (Exception e) { return "{ \"error\" : \"" + e.getMessage() + "\"}"; } } ``` There should be another `XContentHelper.toString(ToXContent foo, boolean wrapInObject)` method which adds the needed `builder.startObject()` and `builder.endObject` calls, if specified. With this change, both of this calls, would basically be one-liners. Hope it makes sense...
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
doc level failure (normal failures are OK from an algorithmic perspective).
yeah nevermind I was confused about some internal classes
fillResponse can throw an already closed exception. We should make sure we deal with exceptions here correctly
so this means we don't support `topLeft` anymore? I think we have to to be honest. Also we have to support `northWest`
I think we should change this so we output a `validation_method` field which can have the values `ignore_malformed`, `coerce` and `strict`. Then the parser should parse this as well as parsing the deprecated `coerce` and `ignore_malformed` boolean fields
can we make those two constructors call the 3rd one so that we can centralize validation (if we ever add some)
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
Same here about multi-line toString methods
Maybe let's just call Objects.equal(script, other.script) for simplicity? I know you did not introduce it though...
Please fix identation.
Since this is only going to be used in tests, I think we can get away with: ```suggestion return Objects.hash(maxSeqNo, localCheckpoint, globalCheckpoint); ```
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I mean random number of replicas with random combination of non-active states
I think we can check also randomly on a shard that relocates _to_ the local node
Earlier in the SecurityLifeCycleService the cluster changed event was handled in order - first, to handle the event in SecurityIndexManager later it would start the index audit trail. Is there any order defined which does not change the behavior of handling cluster event? Not sure if this would be of any concern.
The migration process will only move datafeeds from cluster state to index when the entire cluster has been upgraded to whatever version this goes into (6.6 or 6.7). So if we can find the minimum node version in the cluster in `toXContent()` then we can write the extra fields into the X-Content representation only after the entire cluster has been upgraded. That will make full cluster restarts work in the case where the entire cluster is on 6.6/6.7 (and it is essential this works because some people will run 6.7 for a year after 7.0 is released). So if `job_id` is `null` after a full cluster restart then that implies the cluster was not completely upgraded to 6.6/6.7, and hence the migration will not have started, and hence the information can be obtained from the `MlMetadata` in cluster state.
Please revert this change.
I'm not sure if the cast is worth it here. It is usually simpler to just work in integers even if we know if can't be more than 255.
It looks like you have proper ram usage stuff. Maybe it'd be simpler to refuse to expand the tree if it'd put the `bytesAllocated` above a certain size.
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
You can use `assertAcked()`
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
`this` is unnecessary
Nit: `}` is in a funny place.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I personally think those queries should be build using query builders but we can do that in a second step.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
This change would only break `wildcard` query on these fields, right ? +1 to make them string fields, `prefix` and `regex` query do not work currently because of this so it would be a bug fix. I am also ok to do that in a follow up, the changes in this pr have a different scope.
The `keyword` field applies the normalizer on `termQuery`. Depending on the normalizer the wildcard and escaped characters could be removed/replaced so I wonder if we should apply the same logic than `QueryParserBase#analyzeWildcard` for `keyword` fields. This is out of scope for this pr but it made me realize that we might have a bug here.
maybe one day we will a base class for runtime mapper field types that does this in one place.
confuses the shit out of me everytime :)
"new" -> "now"
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
Again, this doesn't seem to actually use the `entry.getValue()`.
this deserves a sep issue I guess but good catch
Nit: spacing between `!` and `value`.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
Given the method's name I expected it to check the values too.
The 2 `if-else` conditions can then also be simplified to just: ``` if (lowestVersionSeen == null ||Â replicaNodeVersion.before(lowestVersionSeen)) { lowestVersionSeen = replicaNodeVersion; candidate = shardRouting; } ```
I think that the activeReplica method could also be expressed very concisely using Java 8 streams :-)
make sure you fix the codestyle here
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
can you throw an exception in the else clause, eg. "All queries must extend AbstractQueryBuilder but ..."
It looks like this could fit in 140 columns.
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Yeah, I think the problem with the test here is that we don't make sure that nothing is left in the stream after we read it. That's why we didn't catch it here.
We will need stronger assertions here too.
would be nice to allow to configure it to a percentage of the heap size
You can use expectThrows()
You are throwing away the stack trace here. Just have this method throw Exception, and the tests that call it as well.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
Won't the `indexName` be wrong below, since it is just `_parent`? Maybe we should just have a special case here for `_parent` for now? Something like: ``` String indexName = fieldMapper.fieldType.names().indexName(); FieldDataType fieldDataType = fieldMapper.fieldType().fieldDataType(); if (fieldMapper instanceOf ParentFieldMapper) { ParentFieldMapper parentMapper = (ParentFieldMapper)fieldMapper; indexName = parentMapper.getJoinFieldType().names().indexName(); fieldDataType = parentMapper.getJoinFieldType().fieldDataType(); } ```
I dont' think this is possible? `getFields()` never returns null
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
Why do we need a good github search when we have @clintongormley :)
I think we should throw an exception if `mapper.nested() != Nested.NO`, as this would not make sense (and I'm pretty sure some users have dynamic templates to make all their objects nested by default).
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
It would be worth requiring that `jobId` and `jobType` are not `null`.
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
Nit: `reject` -> `rejected`
nit: `an` -> `a`
this should be part of the tests for the replication phase - with random cluster state and all..
well if you put in into an `assert` it's not called in production that is the purpose of `assertions`? I think we should call it at the bottom of the constructor and maybe in `iterator()` as well as `shards()`
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
same here. ElasticsearchAssertions.assertThrows wil help
Did you confirm we sometimes hit this and not just ACE? (The "indexed" CountDownLatch should make it likely...)
I was confused because `request.index()` does not exist here. There is `getCurrentItem().index()` though.
I wonder if we can add this (and similar ones) as invariant to the class (similar as was done for ReplicationTracker) we then call `assert invariant()` on each of these methods. For example, one invariant might state that if we are in TRANSLATED state, the executionResult is null.
instead of ruling out the states which don't allow this to be called, I think it's easier to understand if we put the states where we allow this to be called.
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
I still wonder if for this simple case we should just to return boost != other.boost , doesn't make sense to call `Objects.equals` to me.
It feels wrong that hashCode is using writtenBy while equals isn't
What about just converting to bytes and comparing? The way you have it now this isn't consistent with `equals`.... Also the _cat API we call `toString` which doesn't really use the unit anyway.
Yeah, looking at it again, that makes sense!
similarly, equals uses the hash while hashCode doesn't
this can be out of if now.
nit: can we have this ugliness in a getClusterService(Node node) method? we use it in `doStart` as well.
I'm thinking of the case that the previous cluster is the same as current (and thus has a master) and I basically the same question here - do we have a case where the cluster state has a master but also the no master block? if not, maybe we should an assertion to that matter as an else clause of `if (newClusterState.nodes().isLocalNodeElectedMaster() && previousClusterState != newClusterState)`
minor nit: "int he" -> "in the"
occurred with 2 Rs :)
++ on debug message
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
You can use `assertAcked()`
Can you use more explicit name? (Also for getRepositoriesResponse1/2).
I don't think we need to check the implementation class, instance should be enough.
after rebase you will have to get rid of any wildcard import, or the build fails :)
There is now a base class `RestActionTestCase` that helps remove some of the test boilerplate.
argh, I forgot UnicastZenPing doesn't support local addresses by default. Sorry for the noise.. (we should fix this at one point)
Right - RollupIT is the right place
you could use `scriptRequest.setJsonEntity`
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
maybe put the actual and expected length in the message
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
random drive by question - why is the primary term part of the index result? it's already part of index and index result is supposed to capture the dynamic things that the engine has assigned.
braces please. for the rest of the method too. (I realize you just tweaked this to be a lambda but it would be good to fix this as two line single statement `if`s are dangerous and evil).
nit: space after IOException
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
we need to add that we return false if no folder was found for this shard.
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
@clintongormley mentioned that NONE doesn't have many external usages (we only use it for index auto creation) so we might want to drop the special naming and use `0`. I will keep the object reuse in parsing.
and.. looking at the parsing logic this is indeed internal and we don't accept none from strings. Sorry for the noise.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
ah ok I see
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
one too many new line? :)
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
I see, and you are right, camel case is preferred. I probably misread the "NoNestedDocs" part of the name as "no nested docs" and that confused me for a second, but either way is fine.
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
make `Boolean` and only serialize when not null
nit: "an started" -> "a started"
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Recently we've been doing something more like this: ``` clearIndicesCacheRequest.queryCache(request.paramAsBoolean("query", clearIndicesCacheRequest.queryCache())); clearIndicesCacheRequest.requestCache(request.paramAsBoolean("request", clearIndicesCacheRequest.requestCache())); ... ``` Rather than the loop. The whole loop thing is more appropriate for by-hand xcontent parsing then url parsing.
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
this class is also missing a hashCode impl.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
I had a look and the settings code has been dramatically improved with 5.0 already, hence this fix is not required any longer. Nothing to do then, but thanks again for pointing this out.
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
1. There is a minor typo/grammatical mishap here - text should read "[cluster.name] must not _contain_ ':' character" 2. Id consider putting this exception text into a final static variable somewhere it would make sense to put it. This text is currently used in two places in the code - once here, and once in a unit test - and the way things are now, if you want to change the contents of this text, you need to change two strings in two different places in the code. If you had this text in a final String variable, and you referenced that variable here and in the test, you would only ever need to change the string in one place.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
This seems very error prone, since it relies on CPU scheduling, network latency, or even whether the test is using mocked networking...
This should be `== false` right? otherwise we will warn if the latch _found_ a state
@s1monw if you're proposing we use inheritance and you assume the base class will always be caching DF then we could just remove all the "if(this.docFreq)" checks in the existing code as a simple way to clean things up? That would leave us with just the "if(this.totalTermFreq)" checks.
I think we should have a baseclass that only handles DocFreq and then subclass it if we need TTF that should remove a lot of branches here though. I don't like the long methods that basically repeat code because of the TTF / DF swtiches. I mean it makes sense do split it since they have a higher cost if TTF is needed though.
I guess that's ok...
I'd probably add an `else` clause that sets `splitOnWhitespace` to the appropriate value just to be super clear.
We handle this by temporarily disabling bwc tests. I just pushed the disabling to your branch. Tomorrow I will test the bwc behavior locally before pushing.
Yes, 7.2 was branched, but the 7.3 constant hasn't been pushed yet. I will update this branch today once the constant exists.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
s/can't used/can't be used/;s/their/they/;s/subtile/subtle/
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
Do we need this? the settings are already immutable
maybe use `shouldCompress` here to make it a little clearer? ```java if (shouldCompress) { IOUtils.closeWhileHandlingException(stream, bytesStreamOutput); } else { assert stream == bytesStreamOutput : "the stream variable is not the same instance as bytesStreamOutput"; IOUtils.closeWhileHandlingException(stream); } ```
maybe just call this `public BytesReference materializeAndClose() throws IOException` and don't even return the stream.
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
if you use here `refresh();` from the base class we also make sure we get back no failures.
one too many new line? :)
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
`assertNoFailures` is more common in newer tests and much shorter.
I like `hasSize` better for this because it gives a nicer error message on failure.
I like `hasSize(1)` for this kind of thing because it makes a nicer error message.
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
Ahh okay, that makes sense, I missed that
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
This is not the right condition, a plugin bin directory is not required to exist.
We can remove the period here, this is a sentence fragment (as these usually are).
We can drop everything after and including the comma.
I don't see this change implemented here.
this needs to stay because the method can be called from any other class, it's a public static method....thus validate might not be called at all before calling this method.
we shouldn't need this here in parse phase
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
Yes, but replace `FileAlreadyExistsException` with `IOException` to maintain the same functionality. Sorry for saying it so confusingly before.
`FileAlreadyExistsException` is an `IOException` and this `IOException` block does the same thing as doing nothing -- `return CONTINUE;`.
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I mean random number of replicas with random combination of non-active states
I think we can check also randomly on a shard that relocates _to_ the local node
again, this is the reasoning: if we check for existence of a field in the parser, it means that the only way it can be null in the builder is when it comes in through java api. In that case we might want to fail fast and throw error in the constructor/setter already rather than in validate. If non validated values might come in through the parser as well then validate is the way to go. In this case it makes to do as Christoph suggested. In term query builder I think it still makes sense what we do (again, you can test it to see the differences), same for common terms query.
which other queries do you mean? You mean check against this specific field in similar queries or just in general. I think the question is "when can this happen?". If stuff can happen in both java api and rest layer, validate is the way to go. If we already perform some kind of validation that makes sense in the parser, then having null here can happen only from the java api and we should maybe try and fail straight-away.
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
I mean in the code but just noticed there was one already
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
I would call `indexedValueForSearch`.
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
Nit: there is an excess blank line here.
I think that all of these members variables except for `finalResponseListener` can be `private`.
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
Hurray no more weird `while (true)` loop
Can you give each of them a numeric id instead? This will allow to rename the enum constants without breaking the bw compat of the stream
Nit: `}` is in a funny place.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
nit: mergeSourceIndex -> resizeSourceIndex
Sorry, `MetaDataCreateIndexService` was a bad example. Still, the method `MapperService.merge` which does mapping validation is (AFAICS) not called by the `createIndex` method. This means that `verifyIndexMetadata` does not run the mapping checks in `MapperService.merge`. We check these however when we run `MetaDataIndexUpgradeService.checkMappingsCompatibility` which is called by `MetaDataIndexUpgradeService.upgradeIndexMetaData` when we start a node.
I could be wrong (not that familiar with the code in that area) but I think that in-memory data structures for mappings are not created by the `createIndex` method. These are merged later (see e.g. MetaDataCreateIndexService:325). We could check here as well that all is good on the mapping level.
class could be `final`
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
just a style question but this loop looks more like a `do/while` would be easier to read IMO
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
we should get rid of the retry logic here entirely, there is no need for the while loop when we aren't retrying.
we need to support whatever extensions Settings supports and that includes json & java properties formats. I wouldn't worry about restricting it to these three (yml, json, properties) with regards to bwc.
with the current code a `logging.whatever.yaml` file would be loaded. I wonder if this is our intention or a side-effect of the current behaviour. Honestly I would be in favour of simplifying this further and even have something like `if (file.getFileName().toString().equals("logging.yaml") || file.getFileName().toString().equals("logging.yml") )` unless we want to extend this to json and properties files, which I think would be off-topic in this PR.
maybe `== false` just so we don't typo it in the future
small typo, 'saving'
we have `TestThreadPool` that makes it simpler
Error if old-style params passed alongside new-style script
Ah yes, thanks!
I think s/lang/defaultLang/
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
s/support multiple command/supports multiple commands
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
I think this needs to call PathUtils.get (not Paths.get) so that it does not use the JVM default filesystem, in the case one is set differently in tests.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
ah I mean't Throwable.... sorry
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding jvm plugin [{}]", plugin.v1()); } ```
it's fine to remove it
if the argument name is `failNoIndices` you should provide `! indicesOptions.allowNoIndices()` as argument
if the argument name is `failNoIndices` you should provide `! indicesOptions. ignoreUnavailable()` as argument
FYI we don't throw version conflicts on replicas any more... (not related to your change)
You're missing "create" requests here (not sure if you want to support them, just wanted to make sure you knew)
instead of ruling out the states which don't allow this to be called, I think it's easier to understand if we put the states where we allow this to be called.
we should log the exception here.
we should probably bail here. One nit pick - I would prefer having this rejection logic closer to where it holds. I think there is only one method that can cause this.
Could initialize this with the size of the hits list to prevent resizing
[{}] for path.
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
Can we just explicitly test these? Let's have a test that the field is removed, no error, in the old ones, and another test that tan exception is thrown for newer indices. Randomizing the version is fine, but let's keep it to randomize within the versions we expect to have a particular behavior, so that we keep full coverage of what we are testing on every test run.
did you mean `MapperParsingException`? ;-)
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
minor nit: "int he" -> "in the"
yea, I would at least debug log it..., it shouldn't happen
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
this is a personal preference, I like to avoid overriding the setup and teardown methods of estestcase and use separate one
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
yeah that is true. nevermind then
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
Let's maybe call it `preCollect`? (symetric with `postCollect`)
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
does this work? it works for percentiles, but with percentiles rank it's reversed
would you mind reverting the variable name change, at least temporarily? it confuses the review
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
++ to just `get*`
Why do we need a concrete and an abstract method for each test where the caller only calls these methods anyway? I think we should just make `testReadFrom` and `testWriteTo` abstract.
I meant [this](https://github.com/elastic/elasticsearch/pull/31163/files#diff-2ec2c2b070f96bf66b888db94648ffe0R321) . The standard engine ends up returning a `SnapshotIndexCommit` which is why I used the term lucene snapshot. I hope this is clearer.
+1 on pulling this out, I'm sure this can be used in other places, although in many of the tests I'm thinking about right now we have NamedWriteable things under test, but only the copy method would need to be slightly different.
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
You can use expectThrows()
You are throwing away the stack trace here. Just have this method throw Exception, and the tests that call it as well.
For backporting to 6.3, I think this needs to be changed to 7.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think filter and query can never be null here? not sure whether we should validate this here.
Did this change in the builder or does the case check stay? Can't find it, maybe missed it.
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
this could be static
should this be "not mounting...consistently" or "mounting...inconsistently"? But I would think not the current double negative.
open reader doesn't need to check for <0 and throw an exception any more.
we could pass a glob with regex:xxx to newDirectoryStream if we want
you can have a look at SimpleQueryStringBuilder.VERSION_5_1_0_UNRELEASED to see how to do it
I think consensus is to avoid build failures entirely whenever possible
I'm actually wondering if it would be better to commit with the `onOrAfter` line and just accept the errors for a build or two. The last good commit stuff should mean that only the intake build fails on this. You could also set up the backport for 6.x branch before pushing the change on master so you can push both at the same time and minimise the chances of builds failing.
I tend to try an indent these manually so they *look* a little more like json. Not that this is required, but it does help when they get big like this.
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
What happens if `enabled` isn't set? I *think* we should continue to do nothing if `enabled` is actually true.
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
btw - the test uncovered some issue with the dangling indices import. You might run into a node not connected issues - working on an independent fix.
Yeah, it seems it is. We treat non existing indices as red. Thx for educating me.
I think this check should go into initializeSnapshot or repository.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
Got confused by this and had to go to the code :) - I think this will be clearer "returns the time in millisecond until this unassigned shard can be reassigned."
I think we no longer want this to be an `assertBusy()` - we expect that the previous reroute didn't do anything, so it should still be in this state from beforehand.
I think I see what you are doing here (protect against system clock going way back in time), but I wonder if we should be so strict. 0 is a dangerous value - I'm worried that a very fast machine will render this check ineffective, so I would go with `delta<0`. I also wonder if a short ntp correction will release pending shards. Maybe use `delta<-delayTimeout`? .
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
Can we switch between the string and the millis representation fo the modified date using the `human` flag like the explain API already does? That way we can just have one `modified_date` field in the output? Also the parser will not need to worry about the string version in this case since the client it will never set the human flag
It would be nice if this class was immutable, and this line shows why it isn't currently. This is how to make it immutable: ``` List<CompositeValuesSourceBuilder<?>> sources = new ArrayList<>(num); for (int i = 0; i < num; i++) { CompositeValuesSourceBuilder<?> builder = CompositeValuesSourceParserHelper.readFrom(in); sources.add(builder); } this.sources = Collections.unmodifableList(sources); ```
ok let's leave it as is for now.
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
I wonder if this case distinction should be part of ReplicatedOperation.
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
This has to use the new settings API.
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
we also need unittests for these queries!!!
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
I think this will be clearer if we say - "// precreate incoming indices and popluate them with the relevant types"
make this Error? we alway want to use this.
can we add some trace logging here? I can imagine it will save some WTF at some point.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
just being over paranoid I think this class should be final
> I thought I was getting at that without making it too wordy. The key is that you're not registering a `DeprecationRestHandler` as the name `registerDeprecatedHandler` implies. Instead, you're registering a handler that gets wrapped as a `DeprecationRestHandler` before registration. I guess `registerAsDeprecationHandler` would be slightly less wordy than `registerHandlerAsDeprecationHandler` but the point still remains.
this is just personal preference so feel free to ignore it, but I like the name `registerDeprecatedHandler`
The language in this sentence isn't clear, perhaps change "that is replacing" to "and it is replacing"
similar concerns as DeleteRequest
can you remove this empty line? :P
Maybe replace these with writeOptionalString as well while you are at it
+1 to setTopReader instead of next (it makes more sense imo since there is a single top reader)
Is there any way to do this check earlier? maybe in the preCollection method? Only wondering as we will have already done the main collect phase by this point so it would be nice to fail faster if we can
ok, fair enough then
Where are these mapper helpers used? I've only found them used by tests. Maybe we don't need them? I removed a number of them before for metadata fields.
Well, I think this needs to be fixed here. There is no index created version in field data settings, this is an artificial thing that it sounds like you have added to workaround some other issue.
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
same here re enumSet.toString
I prefer my way but have asked @jasontedor to chime in.
I am not a super fan of this. I wonder if we can afterwards rethink this.
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
nit: can you assign `event.state()` to a local var
Itâs fine @javanna, pull it in in this one. I would prefer we keep changes like this out of PRs, they can go in separately, I want less to think about when I review.
This condition will never evaluate to `true` as we'll get an NPE when dereferencing a `null` instance of type `ExecutorHolder` in the line above.
should we release the releasable just in case the exception comes from the listener? this would allow us to only implement on failure.
Hope this doesn't bite us for really slow (read: Windows) CI servers...
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
oh damned it's BWC I guess...
we can use in.readVInt() here, no? it's always non-negative... (same goes for other counters and also note that you'd have to change the writeTo message of course)
drop the actually? sounds so "uncertain" :)
Can you add a check for reparsing (ie taking a settings that have been run through archiver and using them in another settings builder) the settings works? ie the setting stays archived and doesn't disappear.
Typo: `afllowed` -> `allowed`
This has to use the new settings API.
I think this catch not needed. It will be caught higher up.
I think we should use the `ElasticsearchSingleNodeTest.class.getName()` as the cluster name then we know exactly what is going on.
we should set a node name too...
Unless your node is named "1", this is not a valid configuration. Please have a look at the [docs](https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-discovery.html) or reach out to @DaveCTurner or me on how to configure this. Note that if your tests are running a single node in development mode, then no configuration should be necessary.
I think this assertion should be in `getAnyNodeExcept()` - it's ok to return an empty list here.
`S3SignerType should not be available for China region`
Can you indent this one extra time? When the body of the block below it and a part of the `if` statement line up I have trouble separating them properly when reading quickly.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
nit: naming issue...
I think we should mention the index, cause that is the useful bit (e.g. which index is closed), also because we never really hide the fact that users are using aliases (e.g. when indexing into an alias, the response will contain the concrete index as `_index`, not the alias).
hey @martijnvg I double checked with @clintongormley and we both think it's better to add the actual index that was closed, not the alias. Knowing that an alias is closed has little sense, better to report back which concrete index was closed.
`com.sun.glass.ui.Size` appears to be unused.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
maybe, to be more precise, it would be good to check the partition that included the new primary.
Test is called "testPrimaryOperationLocks" and then most of the code is there to check replicaOperationLock ;-)
I think this can move to before the threads start - will be nastier
> However, I am not sure if we should do it. why is that? We're building all this machinery to have search availability during the transition, except for this very short moment? I had the same idea about retrying. An alternative would be to do refcounting for closing the engine, to ensure that we only actually close once all in-flight `acquireSearcher` calls have been completed.
How do we ensure that searches are not accessing acquireSearcher on the closed engine and switching to the new engine? Also, is there a test that checks that searches (with preference set to this node) continue to work during this transition.
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
don't you want to reset first and then set the parseFieldMatcher? :)
we should probably consolidate the error messages from the results so that we don't only present the first (from a seemingly arbitrary check order) error that was encountered to the user
I was wondering if `getSuperset/SubsetSize` is part of the Bucket interface but not rendered via the Rest response, should we either add rendering of these values to the bucket response or remove it from the interface to get equivalent behaviour of functionality of the transport client with the high level rest client here? I think this can be done in a separate issue though, maybe its not needed at all.
I'm okay with the UnsupportedOperationException for now if we can track this question (whether we can reach consistency between the functionality the transport client provides via the SignificantTerms.Bucket interface with the rest response) in a separate issue
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
It's super minor, but our log standardization is usually all lowercase
Same here with period and lowercase
I think it'd be cleaner to put the `finishHim(e);` into an `else` statement than to return early in this logic
oh I see. I missed it.
I'd prefer using `IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> prez.setRelevalntRatingThreshold(-1))` here like we do in many other tests and get rid of the @Rule
Ah yeah I suppose that might be ok, in this case it's user-defined input so that's pretty awkward but it beats breaking.
I think it could be null instead of `"*"`
Why not use the dedicated get aliases api? IndicesAdminClient#getAliases()
try to use `AbstractRestResponseActionListener` instead of `ActionListener` the `onFailure` method is already implemented there
I took a quick stab at sth. that avoids the Tuple and replacing the test builder [here](https://gist.github.com/cbuescher/88531fe7c2abd38936ef), but it still looks a little bit strange to me. EDIT: Doesn't work, equals-tests break with this little hack. Sorry, nevermind.
+1. Maybe this helper so far is limited to the query / suggester tests only, but then again it might be general enough for ESTestCase.
I believe this can be provided by overwriting EsTestCase#xContentRegistry().
do we want to check the phase/action times since those are meant to change
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
oh, woops. thought I counted right. sry
fileswitch -> default here
this is not needed. createIndex automatically reroutes.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
calling `ConcurrentHashMap#size()` can be quite expensive IMO. I think we should keep track of the open ctx in a counter instead of using the map. I don't think being a little off here makes a difference. I think we don't need to add any sychronization changes here.
Maybe `createContext` should take the `SearchTask` as an argument? That'd make it very difficult to forget to set it.
this can only be a runtime exception you can just bubble it up no need to use `convertToRuntime`
Why not have the standard to string? A multiline return value is difficult to work with in a debugger...
I believe we've been just using the string version of field instead of these lately.
Or we can let poorly formatted values pass through and throw exceptions at the end if values are missing, similar to how we do for queries
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
connec to to -> connect to
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
actually, if its a single page, then we can just reference the first page byte array, if not, then we should return false. same with `array` and `arrayOffset`.
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
Same concern about reproducibility as in the other PR.
import not needed.
> Makes sense? It does not make sense. Having try/catch like this means the test doesn't really know what it is testing.
use `ThreadPool#terminate` here otherwise you will get lingering threads etc.
we have `TestThreadPool` that makes it simpler
well we use a dummy lock so I guess it's fine
Do we need this on this one? It seems like these test suites are very small and any of them taking 40 minutes is grounds for making someone look at the VM at a minimum.
Thanks a lot for this! Definitely better to generate that in a temp dir on the fly instead of having those files as part of the git repo!
You could look at `GradleUnitTestCase` it does the same by pulling int the randomized runner only. What I was wondering about w.r.t order is that if it really makes sense to have it fixed. If all we are doing is going trough methods sequentially what advantage does it bring to have them in separate methods ? Maybe better error reporting ? Should we keep the randomized method order and make sure it actually works like that? I'm not saying we need to change it just looking to understand the implications.
I'm not so comfortable with separating this code from the one in `updatePrimaryTermIfNeeded` - they are tightly connected. Instead of sharing code this way, how about creating a callback that will run: ``` indexShardOperationPermits.acquire(listener, executorOnDelay, true, debugInfo); ``` or ``` indexShardOperationPermits.asyncBlockOperations(listener, timeout.duration(), timeout.timeUnit()); ```
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
typo: tracker -> tracked
Ahh okay, makes sense, good point.
No need for this `else` statement since `lALogger` is already initialized to null
I think this should throw IAE if you pass null - that's 100% of the time a bug
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
I would probably throw an exception instead of accepting null here.
you can just replace with `IOUtils#closeWhileHandlingExceptions`
Are we sure this is the correct logic? this logic means, if the file "definitely does not exist". But i think we want !Files.exists()? Unless the file "definitely exists"
I think this can be set to final and not intialized (`final Set<String> typesToUpdate;`) . It's only set once and it has to be set now.
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
this logic belongs in transportWriteAction
Using 0 as a non-value (because we serialize using `out.writeVLong` ) seems brittle to me. I rather use -1 and serialize using normal `out.writeLong`. With 0 we will always be asking ourselves if it's a valid value. We can also potentially have two methods here - failReplica and failShard, where failReplica requires a valid primary term and failShard doesn't take one (but uses -1 internally) so users won't need to know about this implementation detail.
Nit: `"call back"` -> `"callback"`
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
And we could then just leave an assert here.
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
I might make something like ``` private void expectMissingBodyError(Matcher<String> responseMatcher, ThrowingRunnable exec) { ResponseException responseException = expectThrows(ResponseException.class, exec); assertEquals(400, responseException.getResponse().getStatusLine().getStatusCode()); assertThat(responseException.getMessage(), responseMatcher); }
and randomly append '/' at the end
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
Could this be: assertThat(ackListener.await(0L, TimeUnit.SECONDS), containsInAnyOrder(n1, n2, n3));
We should assert that this is called (and I guess that we can say something about the response that is passed in).
`originalLocation` param is redundant
I think we can share this line and the return new BulkItemRequest line? these two clauses will need to set a final `updateResponse` field.
can we call this primaryItemRequest? It's the one that's sent to the primary. Also, if we pass it as a `BulkItemRequest` parameter, we can avoid sending `requestIndex` and `BulkShardRequest` (from which need the concreteIndex, which I think we can from the shard). Last can we assert that the `BulkItemRequest` has as a request object the `updateRequest` we got? this is all super trappy but we can take one step at a time :)
+1 this makes sense. Then we can drop the `PIPELINE_ALREADY_PROCESSED` transport header.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
I meant the listener we pass to the transport
also, using a non-inner class means we can free the memory (i.e. cluster state copy) rather then have them accumulate with every retry
We can pass a name in the constructor if need be? On 11 dec. 2015 9:53 AM +0100, Martijn van Groningennotifications@github.com, wrote: > Incore/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java(https://github.com/elastic/elasticsearch/pull/15363#discussion_r47332645): > > > @@ -304,7 +304,27 @@ public void onFailure(Throwable t) {>observer.waitForNextChange(new ClusterStateObserver.Listener() {>@Override>public void onNewClusterState(ClusterState state) {>- threadPool.executor(executor).execute(AsyncReplicaAction.this);>+ transportService.sendRequest(clusterService.localNode(), transportReplicaAction, request, new EmptyTransportResponseHandler(ThreadPool.Names.SAME) {>+>+ @Override>+ public void handleResponse(TransportResponse.Empty response) {>+ try {>+ channel.sendResponse(response);>+ } catch (IOException e) {>+ logger.debug("failed to send retry on replica response, action [{}], request [{}]", e, actionName, request); > > got it. btw about the generic helper, we always have a custom log message or want to deal a failure differently in many scenarios, so I think a generic helper isn't going to help much. > > â > Reply to this email directly orview it on GitHub(https://github.com/elastic/elasticsearch/pull/15363/files#r47332645).
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I wonder if we want a trace message here...
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
shouldn't we use here `!REST_EXCEPTION_SKIP_STACK_TRACE_DEFAULT` instead of `false`
I think you can just initialize to null
@s1monw I tried but realized that `NumericDocValues#advanceExact` method requires increasing docID values but it's not the case here. Do you have any suggestion for this? ``` /** Advance the iterator to exactly {@code target} and return whether * {@code target} has a value. * {@code target} must be greater than or equal to the current * {@link #docID() doc ID} and must be a valid doc ID, ie. &ge; 0 and * &lt; {@code maxDoc}. * After this method returns, {@link #docID()} retuns {@code target}. */ public abstract boolean advanceExact(int target) throws IOException; ```
I wonder if we can pull all these in the constructor into an array that we can access by index of the leaf reader. this is how we do things in lucene for stuff we access frequently.
please don't load stuff lazily. go and load it all in the ctor. they are in memory anyways.
Fine with me.
acceptDocs will be checked _before_ these bits are checked anyway
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
I'd expect this to be in a synchronized block
ok, then assert that it's either snapshot or generic threadpool
If you need this in test, you can still call it getBlobStore()
I think this declaration/initialization can be moved to inside the if
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
I would leave it as-is, it needs to extend BaseQueryTestCase
we usually do check the lucene version in a static block ``` Java static { assert Version.CURRENT.luceneVersion == org.apache.lucene.utli.Version.LUCENE_48 : "Remove this class in Lucene 4.9"; } ```
Check nextToken is Token.END_OBJECT and throw appropriate error if not. Without this additional check the parser errors are somewhat confused if the JSON contains a parameter.
Sure, I was just thinking out loud
@s1monw I'm sorry that I didn't take any time to reply last night. The situation with the response parameters is quite complicated. Look for example at `Settings#toXContent`. The situation here is that the `flat_settings` parameter is consumed there, but the signature `ToXContent#toXContent(XContentBuilder, Params)` is a general signature, we can't just go and add a boolean parameter for flat settings to the interface because it doesn't make sense in all situations. It is for this and similar reasons that I ultimately handled response parameters the way that I did. Barring a redesign, I would prefer that we remain consistent for now. > It's just yet another place we need to maintain and look for params. Right now it is how we handle output parameters.
This is one way to do it, but I'm wondering why you opted to do it this way instead of using the infrastructure that exists for handling response parameters? Namely, override `AbstractCatAction#responseParams` (being sure to include the response params from super).
This isn't where I would expect it to be consumed since it affects the output only, not the request handling.
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You can use `assertAcked()`
Can you use more explicit name? (Also for getRepositoriesResponse1/2).
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
Yes, that would be clearer
oh hahahah, I can't read, that's an L
This field is `static`, but it's set via a constructor. That seems odd.
Helper method is no longer needed now that `Logger.debug` exists.
I don't know, I believe METADATA_READ is probably enough but can't really judge, let's hear from @imotov ? ;)
Hurray no more weird `while (true)` loop
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
I assumed that there is no problem setting values and checking that the output of the conversion from high-level request to low-level request is the expected one. We don't validate etc. I would do only what is straight-forward.
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
This constructor doesn't seem to be necessary.
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
I think we should complain if we don't find the header name.
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
I am not sure if we should keep this analyzer - I think we can just use the `PrefixTokenFilter` by itself and move it somewhere in the completion namespace. Yet I think we should have some dedicated tests for this that use `ElasticsearchTokenStreamTestCase` there are some awesome helper methods that can find a lot of stuff that is not correctly set in the `TokenStream`.
maybe make if final
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
these unit tests are great! We are going to need more of them :)
Maybe change the fields type to `Map` instead? The fact that it is a hash map is an implementation detail.
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
remove the set boost
remove the setBoost
good point I am curious too now :) I hadn't noticed this at first
same as in the other PR, I would rather throw UnsupportedOperationException in the default case
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
I was just opening the issue but I'll wait to see the conclusion here first in case we decide copying the first directory manually is still a better trade-off.
Yannick and I discussed this option first, but this needs extra care, for instance to not copy the write lock. It's also a bit more involved if we want to track statistics as well for the first source. In the end it's not clear to me which option is better.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
same here and in the rest of this method
There's a nice helper for this kind of random value creation in `ESTestCase#randomValueOtherThan(T input, Supplier<T> randomSupplier`). The second argument is a function that generates a random value, the first argument is a value that is supposed to be excluded from the range of possible random values. This might simplify this mutate code (and others in this PR) quiet a bit.
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
the node where the shard should move to
shard can remain
I see you have backcompat below for when this setting is passed in through a string field. However, i think we also need to have it for custom analyzers here.
I don't think that matters. This is a new setting we are adding, as far as the API is concerned. I don't think it is a problem to validate the user didn't try to configure the same thing in two different ways.
Users that have indexes created before 2.0 should not be precluded from using the new setting name. This looks like it _only_ allows using the old name with indexes before 2.0.
I think we should fail the local shard on any unexpected error. Seems like the "safe" thing to do..
I think this should be done via IndexShard#failShard (which can be exposed via indexShardReference ). Will be cleaner and faster (it's local fail first, then notify the master)
I think we can do simpler by just returned a retryable exception to the reroute phase that started all of this. It will do the same thing. Also - I miss the annoying "request" reset (we should open an issue to remove it). I guess it's still coming..
I would probably throw an exception instead of accepting null here.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
Sorry you are right, we should be using ParsingException. That snippet was the pre-refactored version. The difference is that ParsingException does not need the SearchContext (not available on the coordinating node) and actually points to the location in the request for the error (the XContentLocation). Please use ParsingException in this PR since this is going to be parsed on the coordinating node
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
I swear I'm missing something. I thought that top-level variables wouldn't be working with this based on the grammar changes I see...
also static method `matches` in Pattern is no good. otherwise it all seems fine.
Alternatively I think we should whitelist entire `java.util.regex` api properly with all exceptions, interfaces, etc. Just exclude Pattern.compile! Then tests can simply do stuff like: ``` assertEquals(Pattern.MULTILINE, exec("/foo/m.flags()")); ``` The constants in that file and helper methods like `split` seem useful. Also `pattern()` seems really useful for tests, especially if we want to test nuances of escaping. I can do it if you want, i know the whitelisting stuff is not the most fun...
thanks for adding this
let's not log since it is an old index
This could be `Strings.hasLength(tokenizerName)`
Something like "This class assumes that the supplier is fast, with performance on the order of a volatile read." would give a lot of context to the decisions around how to use the Supplier.
Maybe mention that this amounts to a volatile read.
It is worth benchmarking this because it adds a volatile read. If it is too heavy we can make the check less frequent I imagine.
I wonder if it'd be easier to read if there were two methods? I'd kind of feel more comfortable having two just so you don't need auto-boxing. It might not make a huge difference, but in general `Rounding` doesn't its best not to allocate stuff. I think this method doesn't have to be so efficient, but still.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
Same deal, I'd just convert it to nanos.
I get that, I was just wondering why those default templates bother here
Why not public? Will make reflection faster for guice.
is index name and type something we really need to randomize in this test? i think we shoudl just test date backcompat here and leave problems with index and type names to other tests...
the XContent here does not match what you removed in the REST API. There was a bit about early termination, as well as count that you need to include. You likely need to also include the begin/end calls, or else this will fail tests. You can check the tests with `./gradlew :server:check` from the base of the checkout. If tests dont fail then we need some better tests around the response hehe
Wow, you are totally right, I see that now :)
spaces between commas
They are just hedging their bets.
I prefer it without the blank lines. No wonder we aren't consistent.
As far as inconsistencies, some classes even have a blank line between the opening and the body, but not the body of the class and the closing.
Should this else clause be returned to what it was before the original refactoring PR? https://github.com/elastic/elasticsearch/pull/32068/files#diff-c94184ea4ef180f10817aa2bbd41a8edL119
Just a style note, we prefer the more verbose negation (`foo != true` or `foo == false`) over the short form (`!foo`), because the short form is easy to misread or overlook. :)
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
why is this? what's wrong with `1.f`
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
oh cool the read is in the ctor! nice!
ok can we rename the getter then to `getFailedNodeExceptions()`
after is now minimum_age
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
why is this? what's wrong with `1.f`
please fail if required stuff is null
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
ok can you add alls these infos into this class
if just read metadata it will also be easier to implement a fetch all interfeces, sort interface name, fetch interface ip sequence
these unit tests are great! We are going to need more of them :)
Maybe change the fields type to `Map` instead? The fact that it is a hash map is an implementation detail.
the `grok` field can be final too
do we need ordered things? does order help anywhere? If not I would just use HashMap
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
I think we should collapse the two above methods, they are always called in sequence.
I don't think we should swallow the exceptions here, instead, this could be a try-with-resources block like: ``` java try (BufferedReader br = new BufferedReader(rulesReader)) { .. read the string .. } ```
This definitely feels like overkill now the `JoinHelper` is mode-aware and its mode is in sync with the coordinator.
maybe just `esVersion()`
the utility should be a static class
this file needs formatting
No, that's fine.
Actually, now that you refactored LongHash, I think this can be made much simpler: we can just iterate with `i` from `0` to `bucketOrds.size()` (which is the number of entries in the hash table, instead of `bucketOrds.capacity()` which is the number of slots) and directly use `i` as a bucket ordinal. ``` patch --- a/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/LongTermsAggregator.java +++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/LongTermsAggregator.java @@ -108,13 +108,7 @@ public class LongTermsAggregator extends BucketsAggregator { BucketPriorityQueue ordered = new BucketPriorityQueue(size, order.comparator(this)); LongTerms.Bucket spare = null; - for (long i = 0; i < bucketOrds.capacity(); ++i) { - final long ord = bucketOrds.id(i); - if (ord < 0) { - // slot is not allocated - continue; - } - + for (long ord = 0; ord < bucketOrds.size(); ++ord) { if (spare == null) { spare = new LongTerms.Bucket(0, 0, null); } ``` (The same change should apply to other aggs.)
closing bracket should be inlined
It's a common theme across the codebase, we don't create iterators (explicitly/implicitly) if we don't need to
seems redundant indeed
I'll leave this one
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Nit: `cs version` -> `cluster_state_version`, please.
+1 this really cleans up code in several places
use ArrayList? one less usage for non standard code...
The use of `#` might make queries confusing since it is also used for filter clauses.
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
and 2 more occurrences below
too many shards already allocated to this node for index ...
too many shards [%d] allocated to this node, [%s=%d]
This check is unnecessary as if a job is being opened we are certain there is ML Metadata already installed.
Missing return statement.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
This line will break our `precommit` checks because it violates the 140-character line-length limit.
I think it would be cleaner to set translated outside of the if statement. ``` boolean translated = incorrectOrientation && rng > DATELINE && rng != 360.0; if (translated || shellCorrected && component != 0) { ... ```
It would be nice to have this take the args in the same order as computePolyTop (array, offset, length)
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
I think this check is wrong. When we have relocation going on and relocation source is marked as relocated (i.e. we call executeRemotely in TransportReplicationAction), then we have primary relocation target replicating back to primary relocation source (see also ReplicationPhase).
This exception will be treated as ignore replica exception. :wink:
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
good point, I think it's ok if it is configurable. and then it should do by default the same as the rest of the same search request does.
I find it odd that we modify the original source builder with the resolved indices names and replace what we originally had. Would it be possible to transport the resolved indices differently? I think we should serialize this new info separately and carefully handle bw compatibility around that.
can we move the resolution method out of `SearchSourceBuilder` too and also transport the info out of it as well? Like we do with aliasFilters map for instance? Does it make sense? Trying to keep `SearchSourceBuilder` as POJO as possible and have logic outside of it.
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
forcing execution should be a parameter for now imo - I know we want/maybe/potentially change how we deal with replicas and queues, but for now I rather not change semantics and have primary ops non-forced and replicas ops forced.
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
finally! its gone!
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Not sure this should be "Query" ð
nit: `accuracy` instead of `Accuracy`
nit:`maxEdits` instead of `max_edits`
nit: `maxInspections must be positive`
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
To coerce, should be: ``` parser.longValue(true); ```
Please don't undo the migration to the diamond operator. :-)
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
yeah, that was what I meant
I think this method is not quite right yet. A few observations: - if (unassigned) primary, then finalExplanation / finalDecision should be influenced by staleness of copy. In case of a replica, however, staleness does not influence allocation decision. - if replica, then we can still show that store copy is corrupt / has an io / error without influencing final decision / explanation - for the primary / replica shard allocator, corrupt / io_error is treated as no data. I think we can first calculate store copy (which just represents the status on disk) and then influence finalExpl / finalDecision based on that. Here is my go at it: ``` public static NodeExplanation calculateNodeExplanation(ShardRouting shard, DiscoveryNode node, Decision nodeDecision, Float nodeWeight, IndicesShardStoresResponse.StoreStatus storeStatus, String assignedNodeId, Set<String> activeAllocationIds) { final StoreCopy storeCopy; if (storeStatus == null) { // No copies of the data storeCopy = StoreCopy.NONE; } else { final Throwable storeErr = storeStatus.getStoreException(); if (storeErr != null) { if (ExceptionsHelper.unwrapCause(storeErr) instanceof CorruptIndexException) { storeCopy = StoreCopy.CORRUPT; } else { storeCopy = StoreCopy.IO_ERROR; } } else if (activeAllocationIds.isEmpty()) { // The ids are only empty if dealing with a legacy index // TODO: fetch the shard state versions and display here? storeCopy = StoreCopy.UNKNOWN; } else if (activeAllocationIds.contains(storeStatus.getAllocationId())) { storeCopy = StoreCopy.AVAILABLE; } else { // Otherwise, this is a stale copy of the data (allocation ids don't match) storeCopy = StoreCopy.STALE; } } final FinalDecision finalDecision; final String finalExplanation; if (node.getId().equals(assignedNodeId)) { finalDecision = FinalDecision.ALREADY_ASSIGNED; finalExplanation = "the shard is already assigned to this node"; } else if (shard.primary() && shard.unassigned() && storeCopy == StoreCopy.STALE) { finalExplanation = "the copy of the shard is stale, allocation ids do not match"; finalDecision = FinalDecision.NO; } else { if (nodeDecision.type() == Decision.Type.NO) { finalDecision = FinalDecision.NO; finalExplanation = "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision"; } else { finalDecision = FinalDecision.YES; if (storeCopy == StoreCopy.AVAILABLE) { finalExplanation = "the shard can be assigned and the node contains a valid copy of the shard data"; } else { finalExplanation = "the shard can be assigned"; } } } return new NodeExplanation(node, nodeDecision, nodeWeight, storeStatus, finalDecision, finalExplanation, storeCopy); } ```
ok I remember now. The point of IndicesRequest and CompositeIndicesRequest is to return the indices that a request works against. when a request is composed of multiple operations, it should implement CompositeIndicesRequest. In this case delete by query reads from some indices as part of search, and writes as part of deletes. But what indices would it delete from? It is not possible to create a DeleteRequest that points to multiple indices, yet it is hard to predict all the deletions that will be performed as part of the request execution. I doubt that this request should implement CompositeIndicesRequest then.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
should probably be `Math.abs(value) >= 65520` rather than 65504. 65504 is indeed the maximum value but values up to 65520 excluded would be rounded to 65504
No. Floats that are between 65504 and 65520 will be rounded to 65504 however floats that are equal or greater than 65520 will be converted to +Infinity.
let's make it take a `float` so that we do not have to worry about null values
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Typo: "`local checkpoint`" -> "`local checkpoints`".
Typo: "`can not be update`" -> "`can not be updated`".
I'd recommend using the same syntax Lucene does: ``` bq.clauses().iterator().next().getQuery() ``` Just to follow their conventions
you can remove the validate call for now, we will fix all queries soon, I promise
if it doesn't have clauses we don't set the boost and ignore the queryName. I think it would be a bit more readable if we had two if branches, and the set boost and named query handling after the if which kicks in in both cases.
cool stuff I didn't see that one!
could be a instance variable, as used in all tests
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
oh sorry, I had missed that you used the filtered collection below
should we really return 1 if nothing was extracted? Let's return Integer.MIN_VALUE (or NEGATIVE_INFINITY once we are on floats or doubles) to make sure it won't be selected if another query could be extracted
It works for strings by using illegal characters. However here, ranges use a binary encoding and all values are allowed. So we should probably use `null` as a sentinel value.
no need to break here
Change to Throwable.
maybe use `AbstractRestResponseActionListener` then you don't need the `onFailure`
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
Ok, then it's fine.
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
Heads up when you merge with master, I just merged another test where the original test query is modified assuming it is json, so that will need the same treatment as you do here I thinkg: https://github.com/elastic/elasticsearch/pull/14255/files#diff-9dc314365d49d84bff0645c2f9dfd7adR356 (and Overwrites in HasChild/HasParentQueryBuilderTests)
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
I think filter and query can never be null here? not sure whether we should validate this here.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
Is this extra method needed? I would combine it with the previous one that seems to be its only caller atm.
I get a warning for a missing GEOMETRYCOLLECTION case label here. Even if that shouldn't be possible, maybe add this to the switch (and/or a default case) that throws.
I think this can be extracted into something like `float[][] lineToFloatArray(Line line)` since it appears 3 times in this file.
I wonder if we should start already sharing some common code between our BaseQueryTestCase and this class....wouldn't want to complicate things though. Also our base test class in not in master of course so that woul already complicate things...
Minor problem when I run this: test complains that it has to call super.tearDown().
I would probably take out the string comparison, once we know that the queries are equal, I think that's enough, we shouldn't test other methods on them, it's out of the scope of this test.
This logging statement has a `[{}]` but no argument to fill it
Out of curiosity, could we do all the types in parallel instead of blocking and waiting for each type to complete before moving to the next type? (It's probably out of scope for this PR, but I'm wondering for a future enhancement)
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
was the answer yes? :)
Pre-size the buffer? ``` java final String index = getIndex(); final String type = getType(); final String id = getId(); final StringBuilder location = new StringBuilder(3 + index.length() + type.length() + id.length() + (routing == null) ? 0 : (9 + routing.length())); ```
not sure, but should we make the location available to java api users too? Transport client is still a thing in 5.x and this way one has to build the location by passing in the routing value. Should the location rather be a field in the response object? Not sure though as it becomes a header in the final rest response. maybe it's ok this way.
What if this.docCount was already -1? then it should stay -1 right? (in the else case here)
maybe it is a matter of style, but i think its easier to handle the exceptional case like a guard up front: check stats.docCount == -1 and set to -1, otherwise sum. this is not really important to me.
Weird markdown seemed to silently remove some of my text...I was trying to say `FieldStats<java.lang.Long>` (which is what I think you meant by your last statement).
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
We can remove the `!` if we reverse this if statement, so ```java if (difference.isEmpty()) { status = RestStatus.OK; } else { ... the error stuff ... }
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Under what circumstances would the mappings for an index be null (as opposed to an empty map)? It seems the default for `GetIndexResponse` is to always have an empty map for mappings (and aliases and settings) and it would only get assigned to a non-null map.
oh, woops. thought I counted right. sry
do we want to check the phase/action times since those are meant to change
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
Hmm, not sure how I feel about that.
same here these strings are only used in one place just use them directly and trash the Fields class
use `assertNoShardFailures` here please
I think it'd be nice to have an assertion on the text of one description just so we can look at it.
It'd be nice to be sure it contained that `not_found` wasn't found.
``` if (Double.isNaN(v1)) { return Double.isNaN(v2) ? 0 : 1; } ```
You didn't introduce it, but seeing this line again reminds me that this is buggy if Long.compare returns Integer.MIN_VALUE, which is legal :) So it should rather be `Long.compare(o2.getDocCount(), o1.getDocCount())` (without the minus sign)
just beware that Long.compare is Java 1.7 only, you might want to use Longs.compare from Guava instead when merging to 1.x
same here, I think it will be easier to read with "shard state persisted despite of persist=false"
missing { } :)
I think we only have general IT tests ci runs. This class is not wel tested :(
this keeps bugging me :) we should something on the executor as well....
can we add something to indicate where this comes from? something like unexpected error while processing cluster state version [{}]
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
Simon added a fancy resolveIndex method
can we configure the delayed allocation to not be the default (`1m`) but something high enough to trigger what we are trying to fix, like `200ms`? This will speed up the test.
ver -> version
we should also catch `NoSuchFileException`
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
I wanted to remove the `allowCommit.set(false)` here with an ensureOpen at the beginning of the method. Only saw later it's already there. No doubles.
I think we can reduce the scope of this change by exposing a resolveShardId method that resolves index,type,id and routing to a shardId. And then we don't need to touch these. Also, I know that type is not used now, but why not pass it? is there a place we don't have it? I hope we can back port this change to 2.x, so having type here will reduce the change.
OK. just saw the shardId() method. Good. the rest still holds ;)
it's used in 2.x and asked Areek to keep it to limit the scope of the change as I hope we can back port it.
I wonder if we should make this a hard exception, potentially in the AllocationId constructor. When we start using this ID, a null value will create havoc in other places and will be hard to debug..
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Assert that the current thread holds the lock on `this`? The results from `ObjectLongMap#indexOf` remain valid only if no one else is mutating.
we can make this a function to `List<MergableCustomMetaData>` - we alreay check with instance of in the implementation of it.
I don't think you need an if else structure here? you can set the first and iterate over the rest? This can be simplified
nit: can we have this ugliness in a getClusterService(Node node) method? we use it in `doStart` as well.
sweet! and we should have REST tests for them which you haven't removed, so everything should be fine indeed
can `aliases` be final as well
oh sorry I see that you don't register the transport action when ingest is off, sorry I had missed that.
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
you are right. Brain circuit breaked - interpreted the || as && . All good.
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
Ok fair enough, Hadn't considered the settings aspect of this.
It might be a good idea (possibly in a different PR) to have a method on `ScriptEngineService` called something like `getSupportedScriptContexts()` which each implementation can use to define what script APIs they support. I imagine there are/will be other language that don't support some script APIs and this would not only allow them to use this too but would also remove language specific code form the ScriptService, which should probably remain language agnostic.
Maybe something like: The bucket can "overflow", in which case the excess capacity is just "spilled", rather than saved up. So it never holds more than a minute's capacity.
nit: extra line
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
I prefer my way but have asked @jasontedor to chime in.
// must use exception that is not **ignored by** replication logic. (also 2 more occurrences of this in IndexShard)
maybe put this check before the primaryTerm check
something is wrong in this sentence :)
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
right, other encodings have no use here. Sorry for the holdup...
+1 to hardcode UTF8
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
I don't think we need the constant.
Also `zen2` is only available in â¥7.0 so `onOrAfter(6.5.0)` looks wrong.
zen2 is the default. Why is this change necessary? These tests are probably already running with Zen2 unless explicitly disabled in some place
I see, that is hideous. ð¦
Extra space is extra.
I'm okay with this.
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
Hurray no more weird `while (true)` loop
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
Correct [equals](http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#equals%28java.lang.Object%29) implementation supposed to be reflexive. In other words the following test should pass: ``` StoreFileMetaData test = new StoreFileMetaData("test", 0, null, null); assertEquals(test, test); ``` Maybe `equals` is not a good substitution for `isSame` here.
missed that. Nanos is strictly speaking better, but not a biggy.
Since this is only going to be used in tests, I think we can get away with: ```suggestion return Objects.hash(maxSeqNo, localCheckpoint, globalCheckpoint); ```
I think we should not execute these writes directly here but extend ESIndexLevelReplicationTestCase#ReplicationAction then run them via the infra of the new action (see ESIndexLevelReplicationTestCase#IndexingAction).
you can use `ActionListener.wrap(r -> handler.accept(r.getLocalCheckpoint()), errorHandler::accept)` instead
you can use `ActionListener.wrap(handler::accept, errorHandler::accept)` instead
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
we can have three methods here, but all of them could just share their code by calling a common method `getNoDeciderWithForceAllocate(Decision)`
I don't think you need the `Integer.toString` bit.
We can allow flush here, I think.
I might do `assertThat(totalShards, greaterThan(1));`.
we should include `e` here, otherwise we lose the cause of the configuration error.
please log the exception here as well we really wanna see what was going wrong
I don't think it's important for now
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
I understand this is the oversight you've mentioned
We typically do this light weight coordination on the same thread. I.e., Names.SAME . This does nothingother than spawn another bulk request. This will cause a new thread to be spawned as we don't do anything else with the bulk pool on the client. To be honest, I don't think the transport client should have so many thread pools. I'll open a different issue for that.
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
I'm not sure why, but the usual convention for freeing resources when the request is done is to have a method called `finishHim`. Mortal combat reference? Anyway, the nice thing about this convention is that it gives us a place to look for resources to be freed. But above I mention reusing a thread pool of some sort anyway.
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
If the constructor is modified, this method won't be needed anymore.
We should have access to the services on the coordinating node, and they should be usable there, so I think this will come out in further refactoring.
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
no both Request and RequestBuilders are java api. one can choose which one to use. you can always do client.search(SearchRequest) without going through the builder.
the start cluster does this.
we have a new awaitNoMaster util method
maybe just start a unicast cluster for now
I'm on the fence as to whether we should only do this on non-realtime get. Real time gets don't really relate to refresh cycles (they force a refresh if needed). They are already "efficient" in the sense that they only refresh if they need to (i.e., there's a pending doc change in the version map).
should remove the "force:[{}]" in trace logger. @s1monw
I wonder if this case distinction should be part of ReplicatedOperation.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
Might be nice to add a check for existence of these parameters for completeness.
It doesn't look like you are using any of the regular `getThenSet` features of the AtomicReference, can this just be a mutable variable? (Not really a big deal either way)
s/payload is/payloads are
s/payload is/payloads are
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
We can avoid arraylist resizing by creating it with `diff.different.size() + diff.missing.size()` and then doing `addAll` for the diff parts
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
This situation feels very fragile to me. It means in the future if we do want a settings instance here because we want to control fine-grained logging settings for a CLI tool, we can not without accidentally reintroducing the problem.
This thread can leak and fail the test, I think that you need to clean it up (join on it in tear down).
and use the constant here
My concern here is if a user sets the budget to `H` headers and `B` bytes because they can not handle more than that (e.g., the common case being a proxy) then we have to subtract a header (or possibly many) to stay under the `(H, B)` budget after we include the missed warnings warning.
I think it's more useful if we spend the last of the budget saying the list is truncated, in anticipation of a time when someone forgets that the list they're looking at might be truncated and makes a poor decision on the assumption that it's complete. These excessive warnings are often repetitive, so the specifics of the 62nd warning seem less valuable to me. (Not that it shouldn't be in the server logs too.)
I think it'd be useful to get one more warning when the limit is hit, saying that there were more warnings but we dropped them because `http.max_warning_header_count` is set to `<n>`, and similarly for the size limit.
Is the version needed? I don't see it being read here.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
same here, just `this.charFilters.add(new NameOrDefinition(charFilter));`
We should log the the failure here if the close fails
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
`engine failure` -> shard failure
By keeping track of contexts in 2 different data-structures, I think you are potentially introducing race conditions, eg. if a clear scroll action is issued concurrently with an automatic release of the context due to the fact there are no more hits to process.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
can this see `unregister task for id: [{}]`
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
can we fold this into ClusterHealthResponse? that way we can test this as well as part of the unit testing.
can we do: ``` Java if (addFailureIfIndexIsClosed(updateRequest.index(), updateRequest.type(), updateRequest.id(), bulkRequest, responses, i)) { continue; } ```
I think it is not clear here exactly when IndexMissingException is expected to be thrown or not. I would rather move the if on top and have different asserts path based on that. FOr the expected exception one you can then do: ``` try { //do something fail("shouldn't get here"); } catch (IndexMissingException e) { //assert on exception } ```
I don't think this test is needed. `testSpanMultiTermQuery` does the same thing.
nit: missing space
all these random values need to be saved out of the loop...you know what happens otherwise? :)
I might make something like ``` private void expectMissingBodyError(Matcher<String> responseMatcher, ThrowingRunnable exec) { ResponseException responseException = expectThrows(ResponseException.class, exec); assertEquals(400, responseException.getResponse().getStatusLine().getStatusCode()); assertThat(responseException.getMessage(), responseMatcher); }
Can we keep the line numbers in the test assertions? I think they are important to maintain.
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
maybe make if final
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
sounds great thanks
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
We can save object creations here by making the ByteArrayDataInput final and using `ByteArrayDataInput.reset`.
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
I wish that we did not have to go from MapperScript to IndexTimeScript, and rather reuse the same concept. I still wonder if this could be `void executeScript(SearchLookup, LeafReaderContext, ParseContext)`? We could make the notion of scripted field known to FieldMapper, let MappingLookup collect all mappers that have a script declared, then each one of those has the execute method called. That way you can also ensure the same behaviour once you add this functionality to other mappers? This suggestion goes against another one I made on making OneTimeFieldExecutor implement IndexTimeScript. MAybe with this suggestion IndexTimeScript could go away and we would have to see what to do with the one time executor.
I can see how having two methods is not fantastic, and why you had done it differently before. I had envisioned script as a member of FieldMapper directly, but we are going to see if that is possible once we add support for script to other mappers. The type of the consumer will make it possibly harder to share the impl but we'll see. I am happy though with the execute method, I find it much clearer than returning an executor like we had before, because it is evident what it does and easier to trace.
I think you are missing a `\n` here.
I think that we need to guard against overflow here!
This is not quite what I think of as exponential backoff. The problem that I see with an implementation like this is that we can have a thundering herd problem. If there is some failure that causes a bunch of tasks to simultaneously fail (e.g., say that we have a bunch of outstanding fetch tasks waiting for a response, and the network connection breaks, failing all of them), all of the retries will keep waking up at the same time, itself potentially causing issues due to a herd. Typically it would be that there is a random component in exponential backoff, to avoid this herding. As a first approach, what I suggest here is: choose a random value k between 0 and 2^number of retries - 1. Then retry after k * delay seconds. We can cap this at max retry delay.
+1 to the statement and other problems previously mentioned (a network hick up will cause a failure for each outstanding request incrementing the counter by more than it can take). I asked Martijn to think about the retry counter as a follow up in order to reduce the scope of this PR.
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
Nit picky: if we capture the node name from the start async we can do `internalCluster().getInstance(DiscoveryNode.class, blueNodeName).id()`
can we remove this try catch? let the original exception just bubble up...
I don't think that we need such big docs, 100kb seems a lot still even if it's the upper bound.
maybe we should also decrease the chance that we add another child object compared to leaf fields.
Would it make sense to create a new method in `Randomness` with the following signature: `public static Random get(Settings settings, Setting<Long> setting)`? Now we "unpack" the key, just to get the settings in `Randomness` the old way again.
should this be "not mounting...consistently" or "mounting...inconsistently"? But I would think not the current double negative.
These should all be wrapped in `<pre>` or `{@code ...}`
Also we should wrap the `-` in `{@code -}`
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
I understand this is the oversight you've mentioned
it is to me, buy hey, taste :) up to you.
`}` and `else if` should be on the same line
++ on removing this catch. Not true any more
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
hmm maybe name it `markCommitted(long translogId) throws IOException` I think it sholud be IOException here
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
Man this feels like a mess compared to ObjectParser. We can't do anything about it in the middle of this PR though. Just makes me sad.
replace match here too
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
you can remove the validate call for now, we will fix all queries soon, I promise
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I don't understand here what you mean by synthetic variable. If you mean the two ENulls, the analysis and writing would be contained to only compile-time.
I don't think you can use this method because it won't necessarily store the type correctly since we do the slots ourself to avoid trash being on the stack with variables scopes and such. Instead you'll have to use writer.visitVarInsn(asmtype.getOpcode(Opcodes.ILOAD), slot);
@nik9000 Robert and I had a long conversation about boxing early during development. We decided to eliminate it as much as possible because of serious complications involving promotion and casting (which as you know is already very complicated). There's only a couple of places auto-boxing happens -- arguments to methods because it would be hard to force a user to cast something to an object to add to a list and with anything related to def type. Otherwise, there is no auto-boxing in painless. Perhaps, this should be the same for consistency? Sorry, I sort of missed this yesterday thinking about the cases, but def should work anyway already, otherwise primitives don't make sense here since we don't allow Integer to become an int anywhere else. With the def type we deemed auto-boxing to not be necessary anymore, and ideally something Java would've hidden from the user to begin with. It also happens that users can call boxed methods on unboxed types to further eliminate the need to ever have a boxed type.
might also want to add a toString implementation on ShardRecoveryHandler or add the shard in question to the assert.
same here - In think we should add the shard info either to handler or to the message.
We should catch any exceptions during the cancel and log them so we can continue to cancel any other handlers? Otherwise the first exception will cause us to bail
I always wonder if we should use the PROTOTYPE constant here instead, cause that is what we need I guess. If so we should change all other tests accordingly
same question as above
you can replace with //norelease so we don't forget but at least you can get this in while we fix this problem in master.
I think the naming is fine. This feature as described in the issue is about not counting tokens filtered from the token stream. This is what `enable_position_increments=false` does and I think it's all we need to do here. If your analyzer adds alternative tokens to each position they should not alter the final count since we're looking for the number of tokens in the original text.
If we don't count token with 0-increment this should be equal to 2
I don't think it should be static
Nit: add a space between `if` and `(`
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
I think this is a left over.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
Okay, doesn't matter if the builder only outputs verbose version as long as we support the other one still.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
maybe we should have a constant for it
This isn't quite right. Wrap the ends with checks in parentheses.
Oh, I misread it (mobile phone, sorry). The only thing that needs to change then is file:// -> file:/.
ð much better readable
This one is upper case and the one below is lower case.
OMG `== false`! ð±
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Nit: `candidate` -> `candidates`
Right - RollupIT is the right place
you could use `scriptRequest.setJsonEntity`
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
Do yo need the parameter `filters`? The only call of `evaluate`just uses the field `filters`.
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
ok can you add alls these infos into this class
we should make this entire class package private and try to contain visibility here as well.
maybe call this `getMetaDataOrDefault()`
This is not the way to get the custom upgraders passed around (we should not be passing around PluginService). See other examples in Node: you should collect all the upgraders, and put them into a container that will then be injected (and eventually when GatewayMetaState is deguiced, we will just have it there as an arg, instead of via injection).
Please no `null` for no change needed, returning `Function.identity` is clear, and there is no need to make an optimization check.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
I think it would have been worth it but now that you mention it - other requests may have changed this in the mean time too, so let's leave this assertion.
nit: indenting should be only 4 extra spaces
why is this? what's wrong with `1.f`
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
++ thanks for changing this :)
I you decide to go this route you should also remember to replace the reference equality checks (`this == ActiveShardCount.NONE`) by equals checks or by looking at value (`this.value == 0`).
we "special case" NONE here but not ONE, maybe it's simpler just to remove this method as well as the `validateValue` one and use `new ActiveShardCount(...)` in the two places it's currently used (and also ad ``` if (value < -2) { throw new IllegalArgumentException(...) } ``` to the constructor.
This method could take an IndexMetaData object as parameter instead. This would let us get rid of exceeds method as well.
We don't want to actually check what version of `openssl` they have installed. They might be generating certificates to be used on a different machine that has a different version of openssl. It's OK to always print a warning about the password exceeding the old openssl limit.
This one should be `true`. We want to check the password length any time we're generating a _new_ private key.
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
I think an explanation why it's ok to throw an exception here might be helpful for future us.
Maybe it doesn't have to come at all.... I think only `copyCurrentStructure` is part of the xcontent implementation. The rest is just "stuff that ES uses". I think.
nit: remove space before `parser`
wondering whether `CompiledScript` should hold the `Script` and `ExecutableScript` should hold the `CompiledScript`
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
looks new. I like this update!
see text from other suggestion for empty primary allocation
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
I'd probably write validate's results to a variable and reuse it.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
Any way we can unify this with `BucketHelpers.resolveBucketValue()`? Or perhaps move this into the helper class and rename both of them to be more specific (`resolveHistoBucketValue()` and `resolveMultiBucketValue()` or something?) Also, I foresee this needing to handle gap policies too...unfortunately. :( For example, an agg like Autocorrelation needs to ingest a histogram (which might need gap policy) but emits a set of sibling buckets that represent correlation lags.
You need to use .equals on a Double
just saw it in the factory validation, nevermind :)
Nit: please add a space before the `,` separating the function arguments.
Nit: please add spaces after the `if` and before the `{`.
Nit: please add spaces after the `for` and before the `{`.
once #12937 is in we can do the following here: ``` QueryBuilder<?> finalQuery; if (queryBuilder.indices().length == 1 && getIndex().getName().equals(queryBuilder.indices()[0])) { finalQuery = queryBuilder.innerQuery(); } else { finalQuery = queryBuilder.noMatchQuery(); } Query finalLuceneQuery = finalQuery.toQuery(context); if (finalLuceneQuery != null) { finalLuceneQuery.setBoost(queryBuilder.boost()); } assertEquals(query, finalLuceneQuery); ```
I say goodbye you say hello ;-)
once #12937 is in we can do the following here: ``` String[] indices; if (randomBoolean()) { indices = new String[]{getIndex().getName()}; } else { indices = generateRandomStringArray(5, 10, false, false); } IndicesQueryBuilder query = new IndicesQueryBuilder(RandomQueryBuilder.createQuery(random()), indices); ```
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
why is this? what's wrong with `1.f`
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
we shouldn't need this here in parse phase
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
I really think this should a hard-coded value and not passed in from the environment. I don't think we gain much by accepting it from outside, and I envisage it being the sort of thing I have to look up each time I come across it. The `BUCKET_NAME`/`KEY`/`TOKEN` inputs are clearer (despite that the `KEY` and `TOKEN` used here could be generated internally if we could do so deterministically).
... so that this doesn't need the `{credentials}` parameter in the URL ...
I think it is good enough to call `output.bytes().steamInput()`.
I would make this class extend `AbstractXContentTestCase`, then your randomPutIndexTemplateRequest would become `createTestInstance`, and ``` @Override protected PutIndexTemplateRequest doParseInstance(XContentParser parser) throws IOException { return new PutIndexTemplateRequest().source(parser.map()); } @Override protected boolean supportsUnknownFields() { return false; } @Override protected void assertEqualInstances(PutIndexTemplateRequest expected, PutIndexTemplateRequest parsed) { assertNotSame(expected, parsed); assertThat(parsed.version(), equalTo(expected.version())); assertThat(parsed.order(), equalTo(expected.order())); assertThat(parsed.patterns(), equalTo(expected.patterns())); assertThat(parsed.aliases(), equalTo(expected.aliases())); assertThat(parsed.mappings(), equalTo(expected.mappings())); assertThat(parsed.settings(), equalTo(expected.settings())); } ```
we don't need a context in this test, these two lines can go away
we have `ToXContent.EMPTY_PARAMS`
Generally multi-line output from `toString()` is a bit of a pain to work with. +1 for using the system's line separator, and I think `System.lineSeparator()` works too as we're in Java 8 here, but a one-line output would be better.
There's no need for reflection here - writing out all the fields, in a sensible order, is much preferred.
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
Same here, original exception is dropped.
I like this much better!
I think this can become an assertion now? we never expect it to happen...
can we pass a reason to this method and mention it here? I always to scroll to find out whether this is a "true" index or just one that was created when importing/creating one.
I could be wrong (not that familiar with the code in that area) but I think that in-memory data structures for mappings are not created by the `createIndex` method. These are merged later (see e.g. MetaDataCreateIndexService:325). We could check here as well that all is good on the mapping level.
so `round` should be called once per factory instead of once per aggregator
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
Man this feels like a mess compared to ObjectParser. We can't do anything about it in the middle of this PR though. Just makes me sad.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
All of the `*Plugin` interfaces we have added so far have used `get*`. I think we should be consistent.
++ to just `get*`
I think I saw this in Christoph's PR too. Hopefully you don't need it.
maybe add an explicit `continue;` here to indicate that it's being skipped
same - please name it something like `explainOrThrowRejectedCommand`
no need to reason an "ex.getMessage", we already log the exception...
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
I like `hasSize` better for this because it gives a nicer error message on failure.
I see, yea we can't avoid this then. Maybe share the default value through a constant so at least we don't duplicate it. Odd! :)
this is odd especially because it seems that once you set a value for this field, you can never reset it to its original default value.
given that the request goes through validate first, I think we could remove this assertion, this is already checked in as part of validate which will throw an error otherwise.
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
> I assume it runs each test method several times @StefanSchmidtOz We rely on CI for that.
there is an `hasUnassigned` method already, so yeah, I'm +1 on being explicit here...
it doesn't reset the ignored list..
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
Asserts are better for this. ð
The sequence number backwards layer won't be needed after 7.0.0.
Another `_` java 9 will be mad at
I'm experiencing the same @s1monw . I had missed this change and I would like to better understand the rationale behind it. Why do we have to restart the global cluster if a test fails within the suite? Also, this seems wrong as if there's one failure in the suite we restart the global cluster for all the subsequent tests...this slows down all the subsequent tests quite a lot (e.g. think of REST tests in network mode).
Believe it or not, it's fine to pass `null` to `IOUtils.closeWhileHandlingException` (it just skips them). We do that for cases where you might have N things that need closing from a large try block, and you don't know which are `null` and which are not (depends on where the exception was thrown). But for here I like the `null` check: less smelly.
Hmm... I'm not actually sure how this would play with Snapshots, so it may be a no-go.
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
right I had missed that previous check, sounds good then
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
Can change this to the new autoclose functionality in Java 7 now that the codebase is on it: ``` try (ZipFile zipFile = new ZipFile(pluginFile)) { // ... } catch (Exception e) { // ... } ``` Thereby dropping the entire `zipFile`-related code from within the `finally` block.
Not related to this PR but I think that we should check if what we are trying to remove is not part of the BLACKLIST. Someone could potentially provide a plugin which contains his own `bin/elasticsearch` script, which looks scary to me.
ok thanks for the explanation.
Feels a bit weird that one method is returning a list and the other one an array
(similar naming consistency issues below)
can we make the list immutable for safety? using Collections.unmodifiableList
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
just `for (IndexMetaData indexMetaData : state.metaData())`
this is not needed. createIndex automatically reroutes.
maybe make if final
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
similar concerns as IndexRequest
otherwise you could index into an alias that target a specific shard and yet index in other shards by specifying a routing key, which I guess could be seen as a bug
@jimferenczi How do you know the the user didn't make a mistake in his code and set routing when he did not mean to, but meant to only set parent? Being lenient is bad, but being silently lenient is even worse.
I saw this problem being dealt with in other place by setting currentFieldName to empty String. Worst that can happen then is that it is treated as fieldName in the query, which we should validate later and throw IAE then.
let's make sure we deprecate it as well in 2.x
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
remove the set boost
remove the setBoost
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
No need for an empty default ctor when the super is also a default ctor.
Maybe we could name the context (and the class) something more descriptive for it's purpose? While the rest api is for executing a script, I think this context is a generic test context? Perhaps it could be "painless_test" (and PainlessTestScript) or something like that? I like having "test" in there because it is clear this is not for production uses, but to test painless code. It would also be more clear for when we do support other contexts in the execute api.
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
this makes me wonder: if a node has node.ingest set to false, for sure no processors should run, hence simulate should be off and IngestDisabledActionFilter should throw exception when a pipeline_id is used as it does now. But how about crud actions for pipelines? One has to go to specific nodes to store them, that have node.ingest set to true? this may not be needed, as those are just index, delete and get operations that any node supports...it's like making client nodes reject index requests, they can forward them to the proper nodes, no problem with that.
oh sorry I see that you don't register the transport action when ingest is off, sorry I had missed that.
can `aliases` be final as well
Nit: addresses -> address
just a style question but this loop looks more like a `do/while` would be easier to read IMO
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
Same here for `compareAndSet`
We should remove the Store part. Perhaps make a constructor with a name? these errors are difficult tot trace so we should make it as clear as possible where the error came from (even if the stack trace is lost)
I only mentioned it because if we really have to keep this, then StandardOpenOption.DELETE_ON_CLOSE could be an implementation. But this one has race conditions too, this delete-on-close stuff is why Lucene's lockfactories were buggy for years. Lets defer it to a new issue, ideally we just nuke it completely.
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
right I had missed that previous check, sounds good then
I think this should be an `assert false;` + throw new UnsupportedOperationException
we should assert this is never called (same for the other places here where `UnsupportedOperationException` is thrown), as this indicates a bug.
well we use a dummy lock so I guess it's fine
Nit: please add spaces around the `=` sign.
The existing code doesn't filter out paths whose `mount` property is `null`, so I don't think we should start doing so as per this test case.
This seems to test the case where the same path has a number of distinct mount points. Can this happen? I can't think how.
The message is a little weird. I don't think "next release" should be mentioned.
I think we can remove this exception now.
Old indentation was better because it made it obvious that the conditions weren't part of the body.
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Nit: space between the cast operator and the target.
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
Checkstyle is unhappy with this.
Now I get it! I had to dig around a bit in `ScriptService` to understand what was up. Now it makes sense.
I think it'd be nice to have an assertion on the text of one description just so we can look at it.
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
could be `final`
same for here, not sure if the full Objects.equals needs to be called
I think you want to use `notVisitedTasks` here instead of `runningTasks`
that awfully sounds like two voices for debug.... your turn, @jasontedor.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
just for ref, im not sure this is really valid.
this one ends up sending parameters that are getting ignored, see `IndicesOptions.fromMap`. we should remove the last three parameters. This should be cleaned up, the problem is that some indices options are settable at REST, while some other are internal properties that define each API (the default argument in `fromMap`) which cannot be changed, so they should never be printed out nor parsed back.
`blocksmd.copyContext(trysmd);`? I know you use "context" to mean something and this might not be the right use of that word though.
Or `adapter.createStatementMetadata(blockctx, trysmd);` or `trysmd.substatement(blockctx);`.
Fair enough. I just see the increment/visit/decrement pattern a lot and it feels like something you could make more automatic/harder to forget/explicitly named.
Maybe `SystemUser.NAME`? I worry that in the future when we do object level security using a username that doesnât correspond to a real user may be a security hole.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
Here it still says `on a per index basis` -> should be corrected.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
can we implement `Closeable` and use an AtomicBoolean to signal it's closed I like the `if (closed.compareAndSet(false, true))` pattern
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
I might use an empty array here or switch the IdsQueryBuilder work with lists.
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
no need for if/else, just write ``` return getNodeDecisions() != null && getNodeDecisions().stream().anyMatch(...) ```
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
yeah, that was what I meant
no matter what I really want to have the manger go away here. I think it bloats the code we can just fold it in.
make sure you fix the codestyle here
please add `{}` around this
ok. I'm with you.
can we rename this to shouldIgnoreNewClusterState? it's not only about being dated.
can we call this log: ``` received a cluster state from a different master then the current one, ignoring (received {}, current {}) ``` also note that disco nodes already have [] in their toString.
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
Is the version needed? I don't see it being read here.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
It'd be "more normal" to declare this as `Writeable` and use `readOptionalWriteable` and `writeOptionalWriteable`. You've done plenty in this PR so it can wait though!
> write past EOF :dancers: +1!
thanks for improving this, this part is easier to read now IMO.
> should we just do the naive thing and handle the last 8 bytes case via a naive loop of writeByte() for each byte, so that the footer logic is only in one place? +1
but why? :)
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
s/payload is/payloads are
You could probably avoid this by making the linux check a method that you stub out in OsProbe.
method refs ftw
Can you add some randomization ? We run this method multiple times and then perform some checks on the generated query (serialization, correctness, ...).
unkown -> uknown
Listener can be null here.
I just realized, for this log message and all of the ones below it here, we only log `index` and totally omit `reason` because there is only one `{}` in the log message...
I think this can leak a reader if `reset(DirectoryReader delegate)` fails (especially when the `this.delegate != null` is true)
s/it's leave/its leaf/
Maybe call this 'totalOpenedReaders'? I was a bit confused reading the tests as it looked as though it was reporting the current open count
@javanna thank you that helps a lot.
Since scripting is disabled by default, we re-enable it back when we start each node in our test infrastructure, just because we have quite some tests that need it on. We are thinking about re-enabling it only for the tests that rely on it though...
can we also randomize if we even set this setting at all? i.e. wrap setting it using `randomBoolean`.
I think I forgot a .value possibly? From your message I did not get if you managed to make it work after all, if not ping me and let's make sure that it works on doc_values
I really think this should a hard-coded value and not passed in from the environment. I don't think we gain much by accepting it from outside, and I envisage it being the sort of thing I have to look up each time I come across it. The `BUCKET_NAME`/`KEY`/`TOKEN` inputs are clearer (despite that the `KEY` and `TOKEN` used here could be generated internally if we could do so deterministically).
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
++ on removing this catch. Not true any more
I think we should make newRecoveriesHanlder be: ``` private final Function<String, Releasable> delayNewRecoveries; ``` and then all of this becomes: ``` try (Releasable ignored = delayNewRecoveries.apply("primary relocation hand-off in progress or completed for " + shardId)) { final long currentClusterStateVersion = currentClusterStateVersionSupplier.get(); logger.trace("[{}][{}] waiting on {} to have cluster state with version [{}]", indexName, shardId, request.targetNode(), currentClusterStateVersion); cancellableThreads.execute(() -> recoveryTarget.waitForClusterState(currentClusterStateVersion)); logger.trace("[{}][{}] performing relocation hand-off to {}", indexName, shardId, request.targetNode()); cancellableThreads.execute(() -> shard.relocated("to " + request.targetNode())); } ```
Whoops, you already did, ignore this!
oh, woops. thought I counted right. sry
do we want to check the phase/action times since those are meant to change
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
fine with me as well. go ahead and push!
I am good with both options.
Oh I see, it's the ZTable stuff. Sorry for the noise :)
Nit: I think you can leave out ESTestCase here.
Like above, I'd simply use randomFrom(SortMode.values()).
Nit: I think you can leave out ESTestCase here.
This question reminds me of an interesting larger topic that I believe could be related: At least for precision IIRC one can compute a micro-averaged or macro-averaged version. Maybe it makes sense to let users decide which of the two (or both) they want? No idea how this plays out with the other quality metrics you looked at.
his -> This
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
you can comma separate these instead... i know the likelihood of us not using `/` is low, but its best to not have them in this.
In 7.0 this should use `_migration/deprecations` as of https://github.com/elastic/elasticsearch/pull/35976, although in 6.x it will have to use `_xpack`.
Pls be sure this is not null. Other converters do a null check and return and give this `addCommaSeparatedPathParts` a empty array if need be. check `forceMerge` for an example
I wonder if we should enable this only for new indices that we know are created with es 1.4
really shouldn't we just skip this in the `LegacyTranslogStream`
can this be in try-with logic.... you are not closing this input stream at all
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
why did you add it? I mean, it is very internal...., it will mean cluster state API will become so much more noisy
As Boa mentioned before we would need both a default to print out, and a boolean that tells whether the current value is default or not, as the `currentValue != defaultValue` is not enough. Something like the following should help in most cases I think? ``` public static void maybeAdd(XContentBuilder builder, String key, Object value, Object defValue, boolean isDefault, boolean includeDefault) { if (value != null || !isDefault) { builder.field(key, value); } else if (includeDefault) { builder.field(key, defValue); } } ``` That said, maybe it doesn't cover 100% but 90% of the cases, and for the 10% left we can still have the custom if? In my opinion it doesn't need to be perfect but still better than copy pasting that `if` so many times.
All of this is equivalent to the simpler ``` return Objects.equals(newMasterNode, previousMasterNode) == false; ``` (see equals implementation of DiscoveryNode)
can we change to use isRelocationTarget() instead? i.e., `isRelocationTarget() || primary == false`
`getMasterNode()` already returns null if `masterNodeId` is null. Maybe cleaner to make that explicit in the `getMasterNode()` method (and not rely on the map implementation to do that for us) and also use `@Nullable` on the return type. The effect is that we won't need these conditions here and can just write `return new Delta(other.getMasterNode(), getMasterNode(), ...`
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Let's make this an `UncheckedIOException` too.
The reason should be more explicit about why this needed.
connec to to -> connect to
> Makes sense? It does not make sense. Having try/catch like this means the test doesn't really know what it is testing.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
nit: could be one line
`min` can be named `simple` or `aggregation`
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
nit: maybe the null check isn't necessary
nit: looks like searchType cannot be null
Oh, I wasn't suggesting removing it in the copy constructor. I was missing the part that `sourceBuilder` here seems not be part of `searchRequest` yet when calling the copy constructor. All good now, thanks for the clarification.
Needs a guard.
Ah yes, thanks!
I think this message should be a bit more clear. Can you include: - the path - the supportedAttributes - some explanation about what attributes we're looking for It can just be `"Don't know how to make file {} non-readable on a filesystem with attributes {}"`
I have no idea how we get these weirdly aligned lines....
Thanks for fixing that...
Yeah - I'm sure that is what happened. Ok - cool with me!
I think we should have these checks in validate. and if we don't want to rely on validate in doXContent have if conditionals there and ignore what's null just to prevent NPEs, but I wouldn't want to do validation and throw IAE in doXContent, where we just print stuff out.
this could lead to NPE if from the java api no set call is performed
ah ok I think I get it, we wouldn't get here before cause what is now the empty_query was null and you could never call toQuery against it. Now we have the empty query that returns null and we have to move some null checks to the different toQuery methods.
why do you pass the response to this method? `this` already has all information.
this breaks backwards compatibility, you will need if based on version in both `readFrom` and `writeTo`
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
Good point, I was thinking about fielddata_fields but we can't get them anyway if a doc is only in the translog...
Oops nevermind, I misread.
Ah, nope, I'm just bad at Java. `[Metric1, Metric2]` is exactly what I was wanting. :)
``` java assertThat(provider.fetchCount, is(1)); ```
``` java assertThat(provider.fetchCount, is(2)); ```
Can you add a check for reparsing (ie taking a settings that have been run through archiver and using them in another settings builder) the settings works? ie the setting stays archived and doesn't disappear.
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Yeah, it's pretty new. :-)
Fine with me.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
I suspect that some aggregations could be grouped under the same parsed aggregation implementation, so we won't really have a 1-1 relationship between the internal agg and the parsed agg. Like an aggregation of type "sum" (ie InternalSum) and "min" (ie InternalMin) can be parsed back using a same `LongSingleValueParsedAggregation`. In definitive I'm not sure we should add the getType() here or also in the Aggregation interface.
I understand. But this requires to grab back the type and delimiter where initializing the parsed aggregation directly with the name "type#name" would allow to parse back the result too. Also, in a client side point of view, the name is "type#name". But I'm nitpicking, we can change this later if we want.
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
I am not sure if we should keep this analyzer - I think we can just use the `PrefixTokenFilter` by itself and move it somewhere in the completion namespace. Yet I think we should have some dedicated tests for this that use `ElasticsearchTokenStreamTestCase` there are some awesome helper methods that can find a lot of stuff that is not correctly set in the `TokenStream`.
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
I like this simplification!
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
Why do we register `S3Repository.Repository.*` settings here? Those are extracted from the repository settings when it is created/registered, but I don't think we need to register a global `compress` or `throttle_retries` setting...
great! thanks @dadoonet
Thanks for adding this warning. Since ` metadata.name() ` refers to the repository name, we could maybe change this to: "ignoring use of named client for repository ["
I think an absurdly high limit could still be helpful? (in a follow-up PR)
Thanks for moving this to `InnerHitContextBuilder` and its subclasses!
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
can we increase the timeout on the request? if one runs a debugger the test may fail to retry because a timeout happens, making it confusing.
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
yeah that is true. nevermind then
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
yeah, that was what I meant
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
removed? It does not seem to be used.
I am confused how this works when created is only within role mapping but we ignore role mapping
@bizybot can you open up a issue that describes this behavior of the object parser and label it with discuss? Then we can move this PR forward.
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
I just realized, for this log message and all of the ones below it here, we only log `index` and totally omit `reason` because there is only one `{}` in the log message...
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
I suggest that we take advantage of this change to remove support for time-based expiration, which we don't need
Could you explain why this is needed instead of checking `expireAfterAccess <= 0`? I think it'd make the class more readable.
I don't think it changed the readability much - it made the checks simpler but then it left me wondering why two variables were needed. I was doing the "why does this have to be here, let me think hard about it" think.
+1 to not swallow the original exception
Doesn't actually throw `IOException`.
This `{` block `}` fits the pattern we use elsewhere, but feels unnecessary in this context.
I think this `close()` should be in a `finally` block in case the write fails
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
good that you added this assertion :)
same here. ElasticsearchAssertions.assertThrows wil help
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
yeah nevermind I was confused about some internal classes
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
strictly speaking, this doesn't need to be volatile. We update it under a lock which guarantees the visibility of the changes.
Super-minor, but missing a space between `if` and `(` here.
I don't get this part why do you change the way we read the `TranslogStats` here? can't this just be ``` Java translog = in.readOptionalStreamable(new TranslogStats()); suggest = new SuggestStats(); if (in.getVersion().onOrAfter(Version.V_1_2_0)) { suggest = in.readOptionalStreamable(suggest); } ```
I understand this is the oversight you've mentioned
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
Nit: missing `@Override`
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
but why? :)
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
s/payload is/payloads are
+1 on just `field`
I don't think we need to add logging to the builders: this only applies to users of the java API that would already get compiler warnings because of the deprecated annotation
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
Someday we're really going to have to standardize on American "canceled" or British/Australian "cancelled"... :)
typo - failIfCancled -> failIfCanceled
Can't recovery -> Can't recover
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
alright that's what I thought too, sounds good
can we not wrap a translog but rather just keep this test translog next to the normal one? keep it simple and readable :)
Shouldn't we combine them? it looks so similar
can you please inline this while [adding docs](https://github.com/elastic/elasticsearch/pull/30176/files#diff-ed6e20d0c4d03d97ae9b7a9a33190c4bR1532)? We need to have more roll overs randomly
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
And one downside even with being initialized before each test method, is some tests do multiple asserts like this inside a single method. So we'd have to clean up those tests to be separate test methods, but thats still fine.
Here would be something of an alternative maybe for the future, when java 8 is minimal (it would be less annoying due to effectively final and lambda): ``` public void test() { assertError(IndexOutOfBoundsException.class, () -> { int foo[] = new int[5]; System.out.println(foo[6]); }); } // test helper for expected exception // TODO: can we replace Runnable with TestMethod or similar interface that throws Throwable // so checked exceptions arent annoying? static void assertError(Class<? extends Throwable> expectedClazz, Runnable foo) { assertError(expectedClazz, null, foo); } // test helper for expected exception, with expected message static void assertError(Class<? extends Throwable> expectedClazz, String expectedMessage, Runnable foo) { try { foo.run(); fail("didnt hit expected exception, expected: " + expectedClazz.getSimpleName()); } catch (Throwable t) { if (!expectedClazz.isAssignableFrom(t.getClass())) { throw new IllegalStateException("got the wrong exception, expected: " + expectedClazz.getSimpleName() + ", got: " + t, t); } if (t.getMessage() == null && expectedMessage != null) { throw new IllegalStateException("exception had null message, but expected: " + expectedMessage, t); } if (expectedMessage != null && !t.getMessage().contains(expectedMessage)) { throw new IllegalStateException("expection message did not contain expected text: " + expectedMessage, t); } } } ```
It is a matter of taste i suppose, but i still hate all junit support for exceptions like this. The rule sucks because it has side effects, if we write another test that uses it, it can easily have some bogus leftover state from a previous test method? Personally i still do it tests like this: ``` try { something(); fail("should have hit expected exception"); } catch (SomeException expected) { assertTrue(expected.getMessage().contains("expected text")); } ``` This sucks too, in that its easy to forget the fail() part and have the whole test do nothing.
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
maybe also rename the setting? (in addition to the constant)
oh sorry, I was not reading the diff correctly, it looked to me like setting sourceToLog was part of the constructor. Nevermind :)
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
If the constructor is modified, this method won't be needed anymore.
removed? It does not seem to be used.
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
Well, I think this needs to be fixed here. There is no index created version in field data settings, this is an artificial thing that it sounds like you have added to workaround some other issue.
save -> safe
I'm happy we have all these tests. It is also another data point to move in the direction we discussed - i.e., failures should mark things as stale.
Can you add a textual description (makes it easier to understand)? I was wondering for example at first why we don't increase primary term upon full cluster restart (then I noticed we do, as isSameAllocation yields false if oldPrimary is unassigned primary).
I find the boolean condition quite hard to read, maybe negate the whole logic to get rid of all this weird `&&` and `== false`: ``` if (newPrimary.unassigned() || newPrimary.isSameAllocation(oldPrimary) || (oldPrimary.relocating() && newPrimary.isRelocationTargetOf(oldPrimary))) { // same primary term } else { // incrementing the primary term ... } `` ```
I do not think we should log here. This is on the reload of a file and not an update to the ciphers settings
This is logic that I think should go into ReplicatedOperation.
I mean random number of replicas with random combination of non-active states
I am always getting confused by this one and refresh. Shouldn't this be `WRITE` and not `METADATA_WRITE`? We don't really change any metadata here.
I don't have strong feelings about it. I just find it confusing.
I don't think optimize should be `WRITE`. It is an administrative type action, you aren't actually passing data, just telling the system to do something.
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
Nit: spacing between the `)` and `{`: `){` -> `) {`
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
Could you explain why this is needed instead of checking `expireAfterAccess <= 0`? I think it'd make the class more readable.
I don't think it changed the readability much - it made the checks simpler but then it left me wondering why two variables were needed. I was doing the "why does this have to be here, let me think hard about it" think.
I suggest that we take advantage of this change to remove support for time-based expiration, which we don't need
Sorry, I overlooked the null check. This is good!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Ahh, sorry. You are 100% correct.
I think it's better to use the index version created to test whether the old or the new parent join should be used. This way you can make sure that the correct explanation is returned in the exception if the parent field is not filled.
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Also `-test1,*test2*,-test20` or something along those lines? :)
I'm afraid we need to rely on the order if we want to be able to distinguish between negations (applied when a wildcard expression appears before the negation) and referring to indices that start with `-`. We will be able to get rid of it in 6.0 only when we will be sure such indices are not around anymore. I opened #20962. Can we also have a test where the wildcard expression is not the first expression but still before the negation? e.g. `test1,test2,index*,-index1`
@nik9000 Note that because of 5bbb1312b1b752a87d8ab1721042fad3f2133a7e this code in a slightly different place in 2.x (for the backport).
ok let's avoid the concurrent put/computeIfAbsent issue for now, we can try to improve in the future if we observe slow concurrent access
I was getting confused by invalidateAll - on second inspection you hold both locks when clearing the maps.
Or not. It looks like you are allowed to modify the segment's innards while you have this lock.
use simpler constructor.
We could avoid the anonymous class by just passing `metaData` to `PriorityComparator` and doing the work there. It seems like we used the anonymous class to avoid a constructor, but I recognize this is largely style.
OK. > On 20 Jul 2015, at 14:01, Shay Banon notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java: > > > ## > > - AsyncShardFetch<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> fetch = asyncFetchStarted.get(shard.shardId()); > > - if (fetch == null) { > > - fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction); > > - asyncFetchStarted.put(shard.shardId(), fetch); > > - } > > - AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId())); > > - if (shardState.hasData() == false) { > > - logger.trace("{}: ignoring allocation, still fetching shard started state", shard); > > - unassignedIterator.remove(); > > - routingNodes.ignoredUnassigned().add(shard); > > - continue; > > - } > > - shardState.processAllocation(allocation); > > - changed |= primaryShardAllocator.allocateUnassigned(allocation); > > - changed |= replicaShardAllocator.allocateUnassigned(allocation); > > I will do the assert when I remove the primaryAllocated flag in a different change > > â > Reply to this email directly or view it on GitHub.
I think it'd be nice to remove this second ctor so we're explicit every time.
I think you can change this to a `Supplier<Analyzer>` now.
Ah! I get it now. LGTM
Typo: "recover" -> "recovery"
Nit: " . " -> ". "
Typo: "se" -> "so"
I think we should use `debug` for the logging here
this method is entirely unused and you don't need that `pipelineStoreProvider` at all
please remove that blank line
