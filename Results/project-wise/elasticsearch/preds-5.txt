also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
Since you don't care about the body of the source maybe use something like `setSource("foo", "bar")`.
I like `hasSize(1)` for this kind of thing because it makes a nicer error message.
if you use here `refresh();` from the base class we also make sure we get back no failures.
`assertNoFailures` is more common in newer tests and much shorter.
this is much better!! ð
The `<=` will need to be escaped.
Nit: " . " -> ". "
I think it might be nice to move this in `TcpHeader`
Typo: "recover" -> "recovery"
Not important, but couldn't this just be an array? String[] possiblePathValues = {"some_path", "anotherPath", null};
Should we also have tests for the case that some intermediate mappers already exist? For instance above you are testing to index a field called `foo.bar.baz`, so it would be interesting to check that everything also works if `foo` already exists.
I see, and you are right, camel case is preferred. I probably misread the "NoNestedDocs" part of the name as "no nested docs" and that confused me for a second, but either way is fine.
just as feedback, nothing to change really, but I liked the previous variable name better ;-)
I'd also like a test for the case that either a single bound or none of the bounds are specified (even if that means checking that an exception is thrown depending on the decision we make).
can we have braces around that ie: ``` if (newQ == subQuery) { return this; } ```
Can you propagate the boost to this query? If this query is enclosed in a BooleanQuery, it could have an impact on the normalization factor.
we set the rewrite method twice it seems? probably a bug in the original parser
indentation makes the `if` block a bit hard to read
(not as a float but due to the cast to int after `Math.ceil`)
yes, make sense
also, using a non-inner class means we can free the memory (i.e. cluster state copy) rather then have them accumulate with every retry
We can pass a name in the constructor if need be? On 11 dec. 2015 9:53 AM +0100, Martijn van Groningennotifications@github.com, wrote: > Incore/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java(https://github.com/elastic/elasticsearch/pull/15363#discussion_r47332645): > > > @@ -304,7 +304,27 @@ public void onFailure(Throwable t) {>observer.waitForNextChange(new ClusterStateObserver.Listener() {>@Override>public void onNewClusterState(ClusterState state) {>- threadPool.executor(executor).execute(AsyncReplicaAction.this);>+ transportService.sendRequest(clusterService.localNode(), transportReplicaAction, request, new EmptyTransportResponseHandler(ThreadPool.Names.SAME) {>+>+ @Override>+ public void handleResponse(TransportResponse.Empty response) {>+ try {>+ channel.sendResponse(response);>+ } catch (IOException e) {>+ logger.debug("failed to send retry on replica response, action [{}], request [{}]", e, actionName, request); > > got it. btw about the generic helper, we always have a custom log message or want to deal a failure differently in many scenarios, so I think a generic helper isn't going to help much. > > â > Reply to this email directly orview it on GitHub(https://github.com/elastic/elasticsearch/pull/15363/files#r47332645).
I meant the listener we pass to the transport
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
Ok, then it's fine.
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
This whole loop reads fairly low-level. If config files can be considered small, we could just read them much more concisely with the Stream API (untested): ``` java String rules = Files.readAllLines(path) .stream() .filter((v) -> v.startsWith("#") == false) .collect(Collectors.joining("\n")); ``` All the low-level stuff is gone. But this relies on Java 8 features and will only work on master.
We can rely on auto-closeables here (i.e. we could use just the try-with-resource statement). Not necessary if you use my suggestion with the Stream API.
ok, fair enough. ++ for setting up compatibility with GeoPointv2
is it worth doing the conversion from and to geohash every time here? Could it be better to not do the conversion and store two doubles per bucket instead of one long? I guess its a trade-off between execution time and memory
btw - the test uncovered some issue with the dangling indices import. You might run into a node not connected issues - working on an independent fix.
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
You are right, I was confused because of what I saw in ScriptImpl for painless (naming implying it was in variables for the script, but that is actually the params). I still think this needs to be its own context. We can eventually move these to direct arguments of the execute method (again, so params can be read-only in the future).
I think this should be its own context. Putting these into params would be a breaking change, and also not utilize the intent of having contexts (different variables for different uses).
looks new. I like this update!
Maybe this one too, I'm not sure.
I think s/lang/defaultLang/
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
This is logic that I think should go into ReplicatedOperation.
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
Could initialize this with the size of the hits list to prevent resizing
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
Whoa this is even stranger to read since it spans 3 lines
the node where the shard should move to
Perhaps annotate this one with `@Nullable` since it's the only one that can be null here
Additionally, I like calling these `getFinalDecision` in ClusterAllocationExplanation.java because it differentiated it from the node decisions, how do you feel about that? (It would also probably change `getExplanation()` to `getFinalExplanation()`)
Question, do you think it would be helpful to copy the pattern we have elsewhere having a `*Safe` version of the functions? So something like: ``` java public Decision getDecisionSafe() { if (isDecisionTaken() == false) { throw new IllegalArgumentException("decision must have been taken in order to return decision"); } return decision; } ```
nit: missing space
I don't think this test is needed. `testSpanMultiTermQuery` does the same thing.
yeah that is true. nevermind then
I mean random number of replicas with random combination of non-active states
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
nit: please use lowercase start for variable names
nit: please use lowercase start for variable names
You can use `XContentParserUtils.throwUnknownToken()` (that would throw a ParsingException instead but I think it's appropriate here)
++ thanks for adding these checks
maybe reverse this check? (`expected.equals(map) == false`)
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
I would leave it as-is, it needs to extend BaseQueryTestCase
ah ok I see
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
I think we have constants for this now: https://github.com/elastic/elasticsearch/blob/8238f497d85d785a61ebc017b8ac96fc5fcd28ae/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java#L32
Since we're moving that, we could inline this using turnary.
To make jobs built with this method reusable when we come to send data to them in other tests, I think it would be better to fix the time format to `EPOCH_MS` and time field name to a specific value, e.g. "time". However, since it takes hours to get the PR CI build to complete and we'll be changing this same file in future PRs that implement the other endpoints I'm happy to leave this as-is for now.
Given that there are 3 tests it would be nice to give all of them descriptive names.
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
This should be a `ConstructingObjectParser` so that the private empty ctr can be removed.
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
here too we do the same twice
you can replace with //norelease so we don't forget but at least you can get this in while we fix this problem in master.
this is same as what we do in term query. We randomly choose a value depending on the type. We might choose the mapped field for that value type, or just pick an unmapped field for it.
Got it, sorry didn't fully realize how value is initialized in any case before. So scratch this remark.
This method takes a phrase query and is supposed to create an equivalent phrase query that just has a different value of the slop, so we need to transfer the boost? Maybe the method should look like this now: ``` java private Query applySlop(Query q, int slop) { float boost = 1f; Query underlyingQuery = q; while (underlyingQuery instanceof BoostQuery) { BoostQuery bq = (BoostQuery) underlyingQuery; boost *= bq.getBoost(); underlyingQuery = bq.getQuery(); } if (underlyingQuery instanceof PhraseQuery) { PhraseQuery pq = (PhraseQuery) underlyingQuery; PhraseQuery.Builder builder = new PhraseQuery.Builder(); builder.setSlop(slop); final Term[] terms = pq.getTerms(); final int[] positions = pq.getPositions(); for (int i = 0; i < terms.length; ++i) { builder.add(terms[i], positions[i]); } pq = builder.build(); pq.setBoost(boost); return pq; } else if (underlyingQuery instanceof MultiPhraseQuery) { ((MultiPhraseQuery) underlyingQuery).setSlop(slop); return q; } else { return q; } } ```
if we can assert that, it would work for me too
I think it should either be an `else if` or the `if` should be on the next line.
remove the setBoost
indentation makes the `if` block a bit hard to read
maybe call this `getMetaDataOrDefault()`
I notice this pattern in every implementation. Perhaps this should be a Map instead of Collection (keyed by the custom type name)? Then the map can be copied, and keys replaced, removed, or added easily, without needing to have logic for the other custom metadata that the plugin does not care about.
Please no `null` for no change needed, returning `Function.identity` is clear, and there is no need to make an optimization check.
can you provide a better exception message here? e.g. "failed to persist cluster state " + event.state().version()
I think this is easier to understand as it makes a 1-1 copy of the current active shard allocations in the routing table: ``` for (IndexShardRoutingTable shardRoutings : indexRoutingTable) { Set<AllocationId> activeShards = shardRoutings.activeShards().stream() .map(shardRouting -> shardRouting.allocationId()) .filter(allocationId -> allocationId != null) .collect(Collectors.toSet()); if (activeShards.isEmpty() == false && activeShards.equals(indexMetaData.getActiveShards(shardRoutings.shardId().id())) == false) { // only update active allocation ids if there is an active shard if (indexMetaDataBuilder == null) { indexMetaDataBuilder = IndexMetaData.builder(indexMetaData); } indexMetaDataBuilder.setActiveAllocations(shardRoutings.shardId().id(), activeShards); } } ```
the important part is having multiple open readers on this as well.
as an alternative you can mark it as final abstract then you don't need the private ctor
something like this: ```Java public SearchOnlyEngine(EngineConfig config) { super(config); try { Store store = config.getStore(); store.incRef(); DirectoryReader reader = null; boolean success = false; try { this.lastCommittedSegmentInfos = Lucene.readSegmentInfos(store.directory()); this.translogStats = new TranslogStats(0, 0, 0, 0, 0); final SequenceNumbers.CommitInfo seqNoStats = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(lastCommittedSegmentInfos.userData.entrySet()); long maxSeqNo = seqNoStats.maxSeqNo; long localCheckpoint = seqNoStats.localCheckpoint; this.seqNoStats = new SeqNoStats(maxSeqNo, localCheckpoint, localCheckpoint); reader = SeqIdGeneratingDirectoryReader.wrap(ElasticsearchDirectoryReader.wrap(DirectoryReader .open(store.directory()), config.getShardId()), config.getPrimaryTermSupplier().getAsLong()); this.indexCommit = reader.getIndexCommit(); this.searcherManager = new SearcherManager(reader, new SearcherFactory()); success = true; } finally { if (success == false) { IOUtils.close(reader, store::decRef); } } } catch (IOException e) { throw new UncheckedIOException(e); // this is stupid } } ``` I did something similar a while back so I had it ready... I am not sure it safe to use ð¯
we should assert this is never called (same for the other places here where `UnsupportedOperationException` is thrown), as this indicates a bug.
and -> an
good point! I think we need to iterate over the filterFunctionBuilders and rewrite their corresponding filters
you are the man! that is awesome!!! that should just work. I really wonder if we can build a BWC test index with a percolator that ensures we can read this stuff if would be awesome to have asuch a test
looks like it can be final
can you add some inline docs explaining what the hack we are doing here? :)
I'm happy we made those exist queries fast. :)
please give us messages for the assertions
You already asserted this 2 lines ago, this is a duplicate.
I think we should use `writeAtomic` everywhere just to reduce the complexity.
I think s/lang/defaultLang/
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
having another look, index time lookup is needed when creating the search lookup, and I actually made another suggestion around possibly not needing IndexTimeScript entirely, so I don't think we will be able to do without adding indexTimeLooup.
You could add an assert that it's not ES 7.x here so we know to remove it
Notice the difference in the first parameter to MergeResult. This is the "simulate" argument. The first time we don't change anything in the merge, only check for any problems. Ideally we could move this simulation to something like we have here with check compatibility. I had a branch for a this long ago, but it was a complex change.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
you are perfectly right Christoph, let's merge the two and keep the existing class.
fair enough, leave it.
this class could be made `final`
Nit: this blank line is extraneous.
No need for an empty default ctor when the super is also a default ctor.
I know this is how it used to be, but can we make the if be more like the `masterNodeChangePredicate` name and check the the master node is not null and have changed? (we now test for a cluster state change)
nit: finishes running on the node
we are generally moving away from gazillion packages and classes I am not a fan of all these service and they make things more complicated than they need to be today. I have a hard time to understand what feels wrong here and where you draw the line
it's really taste I guess so fine with me
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
I don't think we need to change this here.
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
oh I see what you meant now in the other PR :) if Tuples don't pollute the method arguments, I am ok with this, actually it simplifies synchronization issues between the two maps otherwise, I will update my PR to do the same.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Actually I just checked and removing name and description from the Plugin interface should be easy. The only thing to think about is what to give for those properties when plugins are loaded from the classpath (plugin.types). I think here the name should just be the classname, and description something like "plugin loaded from classpath"? I don't know what other info we really have.
Also, can you add an element to maven enforcer plugin for plugins/pom.xml so it fails build cleanly and early if this property is not set? We should also insert a check in pluginservice, if it differs from the directory name, someone manually meddled
This file is new in 2.0, we can change it
We should also check the name matches that in jvm plugins. As a follow up, we should at least remove description from jvm Plugin interface, and possibly also name (possibly a little harder, just requires passing around PluginInfo instead of Plugin I think).
Hrm, can we just call this "name"? None of the other settings are prefixed with plugin.
I think we should just use Set? The ExtentionPoint class was added at a time we thought that would be the new plugin model. But I don't think we should use it anymore.
As long as we make sure plugins don't try to overwrite any of our handlers, I think we will be fine. They pass back a set, so if they decide to insert the same class twice, it's their own silliness.
new ArrayList<String>() => new ArrayList<>()
Ah yes, thanks!
I wonder if later on we are able to get rid of QueryRegistration and register stuff straight-away rather than when calling buildQueryParserRegistry. we will see later though!
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
maybe, to be more precise, it would be good to check the partition that included the new primary.
can this runnable be an `AbstractRunnable`
hm. so this hangs now every now and then for a minute. I think it is when the coordinating node is node_1. Then the cluster state observer waits for the next cluster state which does not come and the index request is only executed when the observer times out. We can send the request via node_2 but I think we actually need a way to handle this better.
do we need this Reader interface? can't this just be `Funciton<StreamInput, T> reader`
finally! its gone!
StreamInputReader already does this.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
yeah, prefer top-level there as well.
Simon would say replace with `== false` ;)
let's have an assert and drop the branch
it's fine, when I did the refactoring SpanQueryBuilder became an abstract class without any problem, but now it needs to be a marker interface again cause java doesn't support multiple inheritance ;) We just need a cast, sorry for the noise I had missed this change to be honest but now I get it, thanks a lot for digging!
alright that's what I thought too, sounds good
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
ah ok I see
it makes sense to make them public then I think
I think we have constants for this now: https://github.com/elastic/elasticsearch/blob/8238f497d85d785a61ebc017b8ac96fc5fcd28ae/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java#L32
otherwise, if you want it for testing, it can be done once in the ctor
This can just be `System.out.print(msg)` now I think. Thanks for removing the formatting from these print apis! I think that was the real problem, its trappy for a `printf()` to be named anything other than `*printf()`. And in this case the caller can just always `String.format` themselves.
args are not used.. we should either remove those from the method sig (which will be consistent with the `println` methods) or pass `String.format(text, args)` to `doPrint`
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
So what does this _look_ like? I imagine it doesn't look any different unless you set the logging level to something lower-than-default.
I actually wonder if we should have a `MaybeBoolean` class that implements `ToXContent` and can do these kind of merge operations ie similar of haskel maybe
can we implement this in a non-functional way? I have a hard time to understand that
do we need ordered things? does order help anywhere? If not I would just use HashMap
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
Can you rather call Releasables.close(tops, bottoms, posLefts, posRights, negLefts, negRights)? This way, it will try to close eg. negLefts even if closing posRights threw an exception
I don't see NO_MORE_DOCS changing in the future. I don't dislike having NO_MORE_DOCS=MAX_VALUE, it makes the sequences of integers returned by DocIdSetIterator monotonic from -1 (not started) to MAX_VALUE (exhausted) :)
Hmm, this assertion can never fail? (NO_NORE_DOCS is Integer.MAX_VALUE). It looks like the other modes have the same issue, I think the intent was to put a "&&" instead of the "||"
Sure, I was just wondering as this patterns appears now at least 3 times.
I think we should discuss such ideas in follow-up PRs. It's not clear to me that replacing duplicate code with more abstractions would be a win.
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
are we losing the STRICT bit here? it's important that we use STRICT here, so we make sure that we never output deprecated stuff ourselves. and we test deprecations separately.
same here, might be that we are good, but let's make sure we don't lose the STRICT one
I think the following if is not valid anymore in fromXContent: ``` MatchQuery.Type type = MatchQuery.Type.BOOLEAN; if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_FIELD)) { type = MatchQuery.Type.PHRASE; } else if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_PREFIX_FIELD)) { type = MatchQuery.Type.PHRASE_PREFIX; } ```
Ah! Got it.
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
I c... ok
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
shouldn't we use here `!REST_EXCEPTION_SKIP_STACK_TRACE_DEFAULT` instead of `false`
I meant that one indeed. GitHub is playing tricks - it didn't show me that change in the same commit (but now it does). Sorry for the noise.
this method is dangerous as it wrong usage leads to re-resolving all the time. Maybe just remove it and do the `resolveSnapshotId` in TransportDeleteSnapshotAction
maybe call this "resolveSnapshotNames"? I would also prefer to use `List<String> snapshotNames` as parameter to bring it closer to the return type.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
can we rename this to shouldIgnoreNewClusterState? it's not only about being dated.
Fine with me :) I'm already wiping the repository itself after each test, so this shouldn't have much effect (I don't think).
I think that's pretty much illegal it should not throw any and it should be handled internally
I think we should move this above the nodeChannels.close() so it will be logged before an eventual consequence.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
I think that `node);` fits in the previous line
Is the version needed? I don't see it being read here.
Add short-curcuit return if this == other.
Wondering if it would be possible to create the builder first, then call all these setters in the parsing loop above already. Not really that important though.
Sure, thats fine.
here too we do the same twice
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
++ can't hurt :)
typo: direct**or** -> direct
oh boy :)
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
I think it might be nice to have it behave the same for the Java API, where it needs to be explicitly set, but as you say, this can be a separate PR
As I mentioned above, I do think we should support both 0 and -1 for no throttle to be consistent with our other "disabling" APIs
This might be really confusing. We don't support any parameters that are provided by `BaseTasksRequest<GetTaskRequest>` so the only reason to use it would be to continue using TransportTasksAction which is overkill here anyway since we know the node that we need to get the task from. So, we can base this directly on TransportNodesAction instead.
oh nevermind I know why it's Streamable since it's send as a request...
Copy and paste leftover.
you can probably cast it here and reuse it later
oh I see the trouble that I caused you, because not all of them are actually ElasticsearchException. Good test though, much more coverage now!
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
I _think_ you can do `XContentParser::mapStrings` above instead of having this method.
you can make one of them public and call it from both tests, I don't mind
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
Note to remember: while this is kept as a QueryBuilder internally, I think we need to make sure to call `toFiler()` on it once on the shard (e.g. in the new build() method, doesn't seem to be there yet)
Add short-curcuit return if this == other.
I think `writeGenericValue` handles null values, so you could omitt the surrounding check.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
Since you touched the response, I am doing my duty to recommend moving these tests to `AbstractHlrcStreamableXContentTestCase` .
I think I saw this in Christoph's PR too. Hopefully you don't need it.
same heere, randomIntBetween(0, 5) would be more life-like
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
this logic belongs in transportWriteAction
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
this shouldn't be done here - it's part of the indexing logic.
The caller should continue consuming the snapshot until the `next` method returns null. In the last call, lastSeenSeqNo equals to toSeqNo and op is null. This guard is added to avoid checking in this case. I am +1 on the assertion.
@bleskes I moved this to `next` but we also need to dudup for nested docs then I moved this to `readDocAsOp` again. I think we should optimize for nested docs. I am open to suggestions here.
I think I miss something here because I think we need it for now but not in the future after we have a Lucene rollback. I will reach out to discuss this.
As discussed - this should be needed in the future. Maybe we should remove it and instead assert that we never have duplicate seq#
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
nit: formatting, add some whitespaces
Nit: please add spaces around the `=` sign.
Again, need to figure out what to do if ATOMIC_MOVE is not supported
Missing `assertAcked()` or call to .get()
make it final
Make it `public abstract class`
If the usage of forbidden APIs is in a few places, I would consider it better to suppress only at the lowest level (sometimes I like wrapping those in a private method I suppress). The reason is that if an unintentional forbidden call creeps in it will be caught.
add a private constructor so no one instantiates this class
Minor suggestion to make it clearer that we're not waiting for the write index not to exist: ```suggestion public static final String NAME = "check-not-write-index"; ```
just as a sanity check that declares we do not support arbitrary unicode. I don't think we have that around
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
is it an option to make this method package private? Then it would become more of an internal thing. Thanks for addressing this!
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
Er, probably not. But a bit confusing name because it looks like a typo.
I think this file needs formatting `if(` -> `if (`
ok can we rename the getter then to `getFailedNodeExceptions()`
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
Another simplification - if we push the code at https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterIndexHealth.java#L81 into ClusterIndexShardHealth's constructor, we can use it here and just make it a simple lookup in the enum set..
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
same here - I think it's better to log the info message if the deletion was successful.
index's toString gives you '[index_name]' no need for '[{}]'
nit: s/read blob's/read the blob's
I'd throw the exception in `initCannedACL()` method instead of checking for a `null` here.
This is where a safeClient() would be helpful, so that you have less chance that the underlying storage instance changed between the copy and delete calls
Remove and create again is not needed I think
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
I think we should stick with calling these getters like `getCharFilters` because it is the char filters that the plugin has, they aren't "extra" in the context of this one plugin.
I think it'd be nice to have this in :test:framework so others can use it.
`Map<String, TransportFactory<Transport>>`? Then `TransportFactory<Transport>` can be an interface. It has too many parameters for a sane person to use it like a `@FunctionalInterface` but it'd be nice not to have to override the ctor and stuff.
Probably worth putting an explanation in here.
We should remove the Store part. Perhaps make a constructor with a name? these errors are difficult tot trace so we should make it as clear as possible where the error came from (even if the stack trace is lost)
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
I wonder if we want to add an `@After` rule that checks that all semaphore permits are back.
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
iirc we add `Asynchronously ...` to this sentence in the other APIs. But its a minor nit...
I guess, are any of the other assertions necessary given that we are checking that source has not changed at all in this case (and no metadata was added).
I would be using a `Set` in this circumstances.
do we need ordered things? does order help anywhere? If not I would just use HashMap
We also need a simple rest test, testing integration like we have for the other processors
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Feel like this should be more significant than `debug` because it really indicates a form of failure in some scenarios.
@dadoonet I don't think it complicates things that much.. it's just traversing the file tree... and yes... sub-folders need to be supported as well. so if you see a folder with the same name/path in both places, recursively merge the two by adding the new files and skipping existing ones. I'd also argue that if in the es plugin config dir there's a file that doesn't exist in the new plugin dir structure, then rename it to "<original_file_name>.<original_extension>.old" (or something like that).
Would it be easier to copy the old config to somewhere else, then replace it rather than trying to mix adding new files while keeping old files? I feel like this will be very confusing for users, especially if `file1.yml` had changes coming from both directions.
I'm okay with `foo.backup`. It would also not be hidden from non-Windows users by default.
it's not really arbitrary is it ? :)
same here - just pass a new instance
If we are going to reformat, it should be within the 100-column limit.
"new" -> "now"
missing t at the end of the method name
I'd just do `sum += Math.max(0, data[1])`
no utils for this :( `out.writeLongArray()` maybe :)
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
maybe omit lowercase from the method names here? (since these tests also run for uppercase and trim)
asked f2f, we can probably delete logging at this point.
we can remove this catch
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
you don't have to assert on anything if an exception is expected
Oh I see, it's the ZTable stuff. Sorry for the noise :)
In my dreams, merging would either throw an exception or return a new independent mapping so that we wouldn't need this validation phase :)
I'm not sure myself why this hasn't been done this way. :-) It's fine, I was just curious if you had tested calling super and if it introduced issues.
alright that's what I thought too, sounds good
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
Ah, I see why this is a function ref - so that the `toString` generates the right method to invoke. That feels a little brittle but I understand what is up.
If the constructor is modified, this method won't be needed anymore.
oh boy :)
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
This method is defined in `MlSingleNodeTestCase`
Remove and create again is not needed I think
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
I suspect these will be too small and we'll have time outs.
can we use package private methods and have unit tests for this.. an integration seems like an overkill.
space missing between ) and {
nit: IllegalArgumentException ;-) You're checking the `settings` argument here, not the state of InternalTestCluster.
Can we also defer to `super.nodeSettings(nodeOrdinal)` so we don't also need to set `DISCOVERY_HOSTS_PROVIDER_SETTING` and `MAX_LOCAL_STORAGE_NODES_SETTING` here? (This also picks up a correct value for `DISCOVERY_ZEN_PING_UNICAST_HOSTS_SETTING`).
thanks for doing that Colin ;)
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
same question as above
I will take care of this.
Got it, sorry didn't fully realize how value is initialized in any case before. So scratch this remark.
Why not add ``` java if (highlightFields.contains(fieldName)) { continue; } ``` around line 94? That'll prevent two regexes that find the same field from highlighting it twice.
It looks to me like it duplicates the logic of creating a XContentBuilder in a given type and then write the filtered source as map. Could it be something like this? ``` ... Object value = source.filter(fetchSourceContext); try { if (nestedHit) { value = getNestedSource((Map<String, Object>) value, hitContext); } final int initialCapacity = Math.min(1024, source.internalSourceRef().length()); // deal with null here try (BytesStreamOutput streamOutput = new BytesStreamOutput(initialCapacity)) { XContentBuilder builder = new XContentBuilder(source.sourceContentType().xContent(), streamOutput); builder.value(value); hitContext.hit().sourceRef(builder.bytes()); } ... ```
why don't we just bubble this exception up as an `ElasticsearchException`
what happens if there is no mapper? I would tend to simply ignore (to match the logic we have for stored fields now)
Sure, I was just wondering as this patterns appears now at least 3 times.
can this runnable be an `AbstractRunnable`
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
can we just us a `Map` here instead of the guava one
can we keep this simple and just assign a new map here and make it final removing all the weird checks if it's null
I think we can just use an FsRepository for this. All our other shard-level tests do the same, so no need to optimize this. If we want to change that in the future, I think it's easier to switch to jimfs and continue using FsRepository.
I'd consider replacing the usage of `-1l` in this line and the prior with the field [proposed previously](https://github.com/elastic/elasticsearch/pull/14651/files#r45225330).
simpler to write `(origin == Origin.PRIMARY) == (versionType != null)`
Here's another place to maybe use a [field](https://github.com/elastic/elasticsearch/pull/14651/files#r45225330).
can we do this once we check the write is indeed allowed? Also I think it will be clearer if we have this in a dedicated method (`markLastWrite` or something like that)
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
Maybe point out that this is actually the place where we modify the valid input query by adding a new object level to it.
I think it'd be nice to separate mutation generation code from the parse testing code. It is complex enough that it'd nice to have a test for it that asserted that it returned the mutations you expect it to return.
Since you don't decrease this when you hit an `END_OBJECT` this isn't really `depth`. It is more like `objectIndex` or something.
Why do you have `get` and `is`? If we don't make these public final members, then at least there should only be one of these methods.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
Maybe throw error here it `nested_filter` is the only allowed option here.
Wondering if it would be possible to create the builder first, then call all these setters in the parsing loop above already. Not really that important though.
Sure, thats fine.
As mentioned above, maybe we don't need this here.
Yes, sorry for the confusion, I remember the discussion now. Maybe just rename then, although `elementName` is also fine.
I'd feel better if the `latch.countDown()` would be the first line in the catch block
err I guess you need to have failures added first so second...
maybe just `return blobMetaData.length() == fileInfo.length();`
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
no file? maybe IOException
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
I see that we need it from another package, I think it's ok.
maybe reverse this check? (`expected.equals(map) == false`)
right, I had totally misunderstood how the test works
Can you rewrite this block using `expectThrows`? Also, instead of `assertTrue`, it's more effective to use the built-in matchers like `assertThat(e.getMessage(), hasToString(containsString("invalid wait_for_active_shards"));`. The reason for this is because if the assertion fails with `assertTrue`, the failure message only says something like "expected true but was false" where as with the matchers we get something like "expected \"invalid wait_for_active_shards\" but was ..." so we already have immediately from the failure message more information about what is happening.
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
we should move to have an inner terms lookup builder. BTW You don't necessarily need to have a flag in your class, you just have to serialize what the method returns and read based on that on the other side. If you read correctly the method will return the right result. The flag would anyway depend on other instance members as far as I can see.
I think we will need to serialize this boolean flag so we can fix the problem we right now have in the readFrom
I am not sure how this can work, is the flag ever set? anyways I think we should remove this flag and change this logic as stated above
indicesDeleted doesn't check for indexUUIDs. We have a separate method for it in this class `cleanMismatchedIndexUUIDs` - in this spirit of bringing all deletion code together - I think it's good to make indicesDelete aware of UUID switches (mark old as deleted), move the `applyDeletedIndices` to be executed where `cleanMismatchedIndexUUIDs` is called now and then we can remove `cleanMismatchedIndexUUIDs` make all go through here.
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
ok let me have a look then ;)
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
I know previous behavior was to spawn a thread every time. I think it will be cleaner to return a boolean from the deletion methods to say whether the index deletion was succesful or is marked as pending and only spawn the thread for the latter.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
hmm no idea really need to think about that one? should this be a //nocommit
Please fix identation.
is this somewhere on a todo? I'm afraid we'll loose it
I am confused how this works when created is only within role mapping but we ignore role mapping
Correct [equals](http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#equals%28java.lang.Object%29) implementation supposed to be reflexive. In other words the following test should pass: ``` StoreFileMetaData test = new StoreFileMetaData("test", 0, null, null); assertEquals(test, test); ``` Maybe `equals` is not a good substitution for `isSame` here.
similarly, equals uses the hash while hashCode doesn't
It feels wrong that hashCode is using writtenBy while equals isn't
This is confusing is what this is.
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
Let's move this to a `finally` block.
This includes both of the fixes but to make the change uncontorversial it should just include the `finally` part, not the checking if the file exists part. Personally I think removing the file up front is the right thing to do but I'd like to separate that out into a separate PR because I expect other folks to object to that way of doing it (see the linked issue) and I'd like to get the `finally` block portion of this fix in.
And anyway, moving it to a `finally` block does help because if the create fails because the file already exists, the delete in the `finally` block will clean it up so we only fail in this way once.
I'd prefer to delete the temp file first as well but it looks like to be consistent with #19036 we should do the delete in a finally block. That way if the file exists we'll nuke it in the finally block as we abort startup. I guess this has the advantage of failing once for the user so they know it is a problem.... I'm not sold on it. The bottom line is that what we have now is wrong and if you move the delete to a `finally` block I can merge this without further debate. We can then open an issue or another PR to discuss deleting the file first. That way we have _a_ fix in and we can more leisurely decide what the right solution is.
Instead of making up our own exception, why not use just use Files.delete? This will give you a better exception message. https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#delete(java.nio.file.Path)
ok, then assert that it's either snapshot or generic threadpool
let's check this on every access, not only creation.
I'd expect this to be in a synchronized block
If you need this in test, you can still call it getBlobStore()
I think we should use `writeAtomic` everywhere just to reduce the complexity.
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
can we use "script_factor" I think it's nicer than the came case
could these three methods somehow be in the base test class, at least partially? what I am looking for is avoiding copy pasting when writing new tests, and possibly not forgetting to cover important scenarios.
would it be possible to make the second part of this method part of the field script object itself? It would also be fantastic to use the same mechanism on both sides, but I know it is a bit tricky for different reasons: 1) that array that we reuse without resizing 2) we try so hard to avoid boxing 3) the usage pattern is slightly different if we compare doc_values, query and index time execution. I do wonder if it is worth investing on this, possibly having our own PrimitiveIterator or something that allows us to expose a clearer script API to access the computed values. For later I guess.
nit: "so we assume"...
You could move this back to the while condition? ``` while (next != null && counter++ < 10) ```
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
this new exception is going to trigger errors too if we try to serialize it to an older node
you also have this variant `org.elasticsearch.common.xcontent.XContentBuilder#timeValueField(java.lang.String, java.lang.String, long, java.util.concurrent.TimeUnit)` which you can use without changing TimeValue
we don't need this `if` block, do we? All 6.x and 7.x indices have a single type.
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
we shouldn't be lenient in case `upperTerm` doesnt't implement BytesRef
I feel like this limitation is ok for now. We can revisit this later if necessary
should remove the "force:[{}]" in trace logger. @s1monw
can we report the right version we found ? note that we would probably need to change the the logic in the gateway allocator to check for both -1 version and exception (now -1 means both).
Typo, finalzlie -> finalize
Whoops, you already did, ignore this!
The logging brackets are off here: `[{} to [{}]]`.
nit: please use lowercase start for variable names
nit: please use lowercase start for variable names
Maybe add something like "produced by calling _analyze" and maybe the index name (not sure if this is easily available here, if not its fine) to make it even clearer what the offending call was.
++ thanks for adding these checks
maybe reverse this check? (`expected.equals(map) == false`)
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
I think it is fine: we only build one search context per request per shard.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
`if (serializedStates != null) {` is no longer needed
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
save -> safe
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
Maybe add minimumLuceneVersion() to index metadata as a placeholder for #11095? Then the impl can just be createdVersion().luceneVersion in this PR? It would just make it more clear here that the lucene version is the driving factor.
Do we need this? the settings are already immutable
Nit: too many newlines here
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
Nit: `getNumConnection` -> `getNumConnections`.
Is the version needed? I don't see it being read here.
can we add a check for whether we sent a diff? I want to avoid a potential infinite loop.
Having through about this a bit more, I think the _prompt_ is going to be annoying rather than helpful. I think we'd be better off just printing out a warning message, and continuing on. Sorry for messing things around like this, but sometimes things become clearer during the review cycle.
I think this needs to be `true` as well.
same here please add a nice constant that is human readable
The `withPassword` method is called every time we need a password, even if it's being used to _read_ a certificate file. In that case we don't want to print this warning, because that would cause additional output (and an additional prompt) for simple things like reading a CA file that has a long password. We need to only perform this check/warning if the password is being applied to a new file. I'm OK if we want get rid of the `promptYesNo` and just print out a warning, but we only want to do either of them when we know the password is being used to _write_ a file.
This one should be `true`. We want to check the password length any time we're generating a _new_ private key.
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
To coerce, should be: ``` parser.longValue(true); ```
Please don't undo the migration to the diamond operator. :-)
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
don't you want to reset first and then set the parseFieldMatcher? :)
Discussed this with @abeyad more. It looks like it should be part of RepositoryData after all, otherwise the index generation abstractions is getting exposed on the Repository interface layer, where it makes even less sense.
I would be using a `Set` in this circumstances.
lower cased now...
guava has a `Iterables.elementsEqual()` - which works slightly different, maybe your implementation is a bit faster
Does it need to be Writeable? It looks like we only serialize it using JSON.
nit: formatting, add some whitespaces
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:918E10886BC43EC1]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.LineStringBuilder.<init>(LineStringBuilder.java:49) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiLineString(GeoWKTShapeParserTests.java:112) ... ```
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
nit: formatting, add some whitespaces
I think we should change this so we output a `validation_method` field which can have the values `ignore_malformed`, `coerce` and `strict`. Then the parser should parse this as well as parsing the deprecated `coerce` and `ignore_malformed` boolean fields
Maybe also use a constant here
I am starting to see that the default boost doesn't get printed out but other default fields do. Makes sense to me but maybe we want to be consistent? I think we should have this a separate discussion, make some decision and do the same everywhere (I have the feeling we are not yet settled yet on one way or another)
this one ends up sending parameters that are getting ignored, see `IndicesOptions.fromMap`. we should remove the last three parameters. This should be cleaned up, the problem is that some indices options are settable at REST, while some other are internal properties that define each API (the default argument in `fromMap`) which cannot be changed, so they should never be printed out nor parsed back.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
`String.format(Locale.ROOT, "%s operation term [%d] is too old (current [%d])", shardId, term, primaryTerm)`
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
Does it make sense to have the Enum and method name the same? I have no preference as to whether we call it `Weighting` or `WeightingType`
`min` can be named `simple` or `aggregation`
could we not specify it with the following? ``` "movavg": { "bucketsPath": "the_sum", "weighting" : { "single_exp" : { "alpha" : 0.5 } } } ```
This might make the code in MovAvgModel easier as each weighting type will have its own class which knows how to calculate the moving average and we can just call a single consistent method on that class
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
`s/Class<C>/Class<? extends C>/`
++ thanks Nik
We need to cast indeed, but I want to give the compiler opportunities to find errors, which is never possible when one starts definiting methods whose generic parameter is only used in the return value. By the way I'm thinking that we could make casts more safe by making category a class instead of a string, and this class would be the base class of the object that the namedwriteables can deserialize
To me, this logic should really be in `IndicesQueriesRegistry` so we construct the registry with just the `Settings` object and then call a `registerQuery(ParseField, QueryParser<?>)` method which unpacks the `ParseField` and adds it to the registry map. That was the registry is dealing with how to internally structure the data and the internals can be easily changed later without affecting outside code.
Might be nice to add a check for existence of these parameters for completeness.
mention here too that this is what we do also in the corresponding builder
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
There is no way this compiles.
Sorry I had missed that
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
The first two of these fields are unused. I think that's right, and we should remove them and also `ec2Bucket`, by generating the key and token and then passing them into the bucket's constructor.
This _nearly_ feels worthy of abstraction over the various sets of credentials, and I think that'll definitely be worth doing when the ECS-style credentials are added. Optional now, but worth thinking about.
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
derives -> derived
mayb just do `if (++count >=`
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I mean random number of replicas with random combination of non-active states
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
if the size was previously less than PAGE_SIZE_IN_BYTES (possible with the contructor that exposes a size), this will actually grow the array (potentially going from a simple heap-allocated byte[] wrapper to a recycling instance)
ok keep it then. I am not sure though what needs to be optional, if the client here, or the service in the parser service. I thought the former, not the latter.
Ok, didn't know about those...I guess keep for consistency...
I think this name should be IndexMetaDataUpgradeService? Otherwise it sounds like there is a "metadata index".
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
hmm actually I think we should load deleted queries too
+1 to a follow-up
actually I'm wondering if we should use an IntObjectHashMap: given that the percolator works on a type, I'm afraid users have a lot of data in other types too so creating a Query[maxDoc] could cause an OOME on some of them. By using an IntObjectHashMap we will be more on the safe side: it will une more memory if all docs have a query but much less in the sparse case.
you can just use `MultiFileds.getFields(index.createSearcher().getIndexReader());`
Instead of having a reserved null value (-1 in this case), use an Object float for `minScore` in ShardTermsByQueryRequest and TermsByQueryRequest. Then we can just do a null check: ``` java if (request.minScore() != null) { ```
Nit picky: if we capture the node name from the start async we can do `internalCluster().getInstance(DiscoveryNode.class, blueNodeName).id()`
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
can we check that nodeOrdinal is < unicastHostPorts and throw an exception? I think in theory we don't need to enforce this but can search for ports on the fly, but let's leave that to a day we need it.
I think we can increase the 99 range to 1000 and also change calcBasePort to ignore the scope component as it is not relevant any more. I want if we should jut remember the last based port and continue from it (round robin-ing) to make in-JVM collisions less likely
Don't get me wrong - I like the loop above - I just don't think is sufficient to prove to ourselves that we recreated the problem.
this logic belongs in transportWriteAction
> Though I do prefer that it fails fast instead of lazily later. ++
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
No, I still think that it should not be a method on the `Strings` class.
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
If your intuition is that these will be almost always needed, then obviously we should keep them.
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
can we check and stop if the background thread had any issues? o.w. will have to dig through more than needed.
Is this any quicker if you use bulks? I tend to do that out of habit.
something is wrong in this sentence :)
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
thanks @nirmalc !
> Dynamically changing is very useful in case of cluster with multiple indices/data shapes. Which `multi_term` query are you using ? Is it to increase the default value of 1024 ? Any multi term query that don't use top terms rewriting is not a good fit for the span query in general. If you need to perform prefix queries within span queries it is preferable to index the prefix using the `edge_ngram` filter. This way you can transform any prefix query into a span term query on a single term.
My original intent was to add a `max_expansion` to force the rewrite of all multi terms to use a top terms rewrite when used inside a span query but in this case the `max_expansion` param can be interpreted as the number of top terms to keep during the rewrite. However I prefer your approach which throws an exception on `multi_term` queries that don't use top terms rewrite and matches more than 1024 terms. In this case we can fail the query with a nice message explaining that a top term rewrite should be used on the `multi_term` query if applicable. `max_expansion` is confusing in this scenario and doesn't bring much so I think we should simply honor the BooleanQuery max clause limit.
Why does it need to be public ? I'd prefer a private static class since it's not used outside of this class.
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
same request - please have a method called `haveWriteBudget` and do `while(haveWriteBudget() && buffer.isEmpty() == false) { `
I think all of these need to be trace and we should enable these in tests that are relevant.
IMO lets drop them all. IF you have to make them trace you can also just add them back if you need it.
this retry counter is tricky as we need to have a budget that allows all current read/writers to fail on a network hiccup. There's also the question on how people know what happen when the task is failed (where we might need support from persistent tasks). I think we can leave this for now but have to deal with it in a follow up.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
This predicate can be simplified to `(count, limit) -> count > limit`.
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
the logic here should be only if _all_ nodes responded with the shards active we should continue with the deletion process..., same check we do on the cluster state if a shard can be deleted
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
can you add a //norelease here too? context should really go away after all queries are refactored
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I would add an `assert this.context != null` here just to make sure
this must be `2000051` rather than `2000003`
I think its awkward we wrap these files in InputStreamIndexInput here, and have the method take InputStream, when it could just take DataInput? The one lone other usage of it, in a separate file (BlobStoreIndexShardRepository), could just wrap its InputStream with a o.a.l.util.InputStreamDataInput. and then the hashFile() would just be a simple readBytes() call into the byte array. I know this isn't new in the patch, but this path adds more indexinput-wrapping since its not calling hashFile(String) anymore.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
This is confusing is what this is.
same here - just pass a new instance
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
I think we don't need to make the global SuggestBuilder implement NamedWritable, simply Writable should be enough. This is the only implementation (and will likely stay so) so we don't need to differentiate it from others on the stream.
Why remove it? I was adding them because I thought it was nice to mark the constructors for anyone unfamiliar with Elasticsearch. It'd help them get their bearings.
I think this'd be more clear if you said something like "invokeStatic assumes that it is not invoking a method on an interface."
I'd remove this again. Because this is done in original ASM, just to prevent incorrect stack on voids
I don't think you can use this method because it won't necessarily store the type correctly since we do the slots ourself to avoid trash being on the stack with variables scopes and such. Instead you'll have to use writer.visitVarInsn(asmtype.getOpcode(Opcodes.ILOAD), slot);
I think that this should be an `IllegalStateException`.
can this be in try-with logic.... you are not closing this input stream at all
nit: I changed this on master to get the parser from AcknowledgedResponse using a new `generateParser` method that I introduced there on request of Baz. Maybe we could use the same here in the backport to make it match the version on master.
Nit picky: I wonder if we should make this ctor get all the parameters and construct the message locally. Will be easier to read the code and use, imho.
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
I think this should take an `OperationMode` to push the conversion into the caller, rather than doing it in the constructor (it seems cleaner to me that way). This is just my personal preference though, so up to you if you want to change it.
good catch on delta > 0
`limitedTo(long bytes)`? Clone is kinda non-specific.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
these ElasticsaerchExceptions are bogus remove them
confuses the shit out of me everytime :)
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
if we run into an exception here we have to close the stream. we usually do this: ```Java boolean success = false; try { // do something with the stream success = true; return stream; } finally { if (success == false) { IOUtils.closeWhileHandlingException(stream); } }
can we maybe try to trigger this differently? I mean can we for instance try to call `#available()` or can we maybe read the first byte on open and wrap in a `BufferedInputStream` and then do this: ```Java InputStream stream = is.isMarkSupported() ? is : new BufferedInputStream(is); // do the following in doPrivileged? stream.mark(1); stream.skip(1); stream.reset(); return stream; ```
I fell like a functional interface here doesn't really buy us anything comparing to a simple if statement with two calls.
Ah ok, I missing that method below, sorry.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
well then you have to have a dedicated parser interface - I wonder if this is a general thing we should have on stream input though
I understand this, but this sound confusing to me. You would have some member in each builder that is only set for the prototypes, need special constructors for the injection. I understand your proposed solution with the static method access much better.
My preference would go to adding a serialization context to readFrom.
this could be a for each loop instead
I am surprised that we don't have a default impl for this :)
The `new HashSet<>()` can be replaced with `Collections.emptySet()` (and then you'll have an import to remove).
Typo: `afllowed` -> `allowed`
No need for an empty default ctor when the super is also a default ctor.
Same deal with `.get()`. I try to only do this when I edit the line so it doesn't blow up the diffs, but this is a good opportunity to do it here I think.
I think you can drop the `(long)`s because these are `double`s now.
Feel free to tell me I'm totally wrong - but do we feel confident enough that a mistake here (in code) is a good enough reason to cause the [node to restart](https://github.com/elastic/elasticsearch/pull/19272) ? I'm worried about endless restarts, where a single mistake on a specific API can cause problems on an entire node.
I think if you throw a subclass of RuntimeException here it'll get bubbled back to the user and we'll get a bug report if it shows up. AssertionError's problem is that catching it and forwarding it around properly gets us dangerously close to catching OOMs. We probably could make an exception for catching AssertionError but I'm not sure it is worth it when we can just throw a RuntimeException of some sort instead. Also it just feels weird to throw an assertion error from outside of assertions! Its icky ð¨
> For the record, the JVM code itself seems to be using AssertionError for impossible branches. Weird. I can live with it but it is weird.
instead of changing the state first and then checking whether the previous state was the right one, let's only change the state if the current state matches (note that we're under the mutex here already, so it's safe to do this).
can add a sentence or two about what is currently known to be potentially missing? (in sync markers for shards on new nodes that should be accounted for GP calculations). I think it will help (at least it would me) to understand what this is about.
Test is called "testPrimaryOperationLocks" and then most of the code is there to check replicaOperationLock ;-)
maybe put this check before the primaryTerm check
I'm not so comfortable with separating this code from the one in `updatePrimaryTermIfNeeded` - they are tightly connected. Instead of sharing code this way, how about creating a callback that will run: ``` indexShardOperationPermits.acquire(listener, executorOnDelay, true, debugInfo); ``` or ``` indexShardOperationPermits.asyncBlockOperations(listener, timeout.duration(), timeout.timeUnit()); ```
Ok, than that's fine for me. So overall LGTM.
well if a test doesn't call `super.nodeSettings(nodeOrdinal)` that is a bug. We have to enforce it though. IMO we can use a similar way as the test base class does but we don't have to do it here...
underscore case? :)
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
can we check and stop if the background thread had any issues? o.w. will have to dig through more than needed.
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
This worries me a bit as this is inconsistent with the filters and ranges aggregations.
mention here too that this is what we do also in the corresponding builder
now I see what you meant yesterday saying that we have to parse meta here
This is going to be very funny for term vectors because `fieldText` is empty.
I think it'd be nice to remove this second ctor so we're explicit every time.
Ah! I get it now. LGTM
I think you can change this to a `Supplier<Analyzer>` now.
I don't think we need this part? Even if you've created an index with 6.4, you still want to be warned that things are going away if you upgrade to 6.5
This is not good for backword compatibility. Instead it should do: ``` if (indexSettings.getIndexVersionCreated().before(Version.V_6_0_0)) { String tokenizerName = settings.get("tokenizer", "whitespace"); tokenizerFactory = ...; } else { tokenizerFactory = null; } ```
ok as a follow-up
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
While I think a common methods would be great, I'm not sure this distinction (small vs. large longs) is needed very often. In the parsing tests its good to have some more "smaller" values to catch cases where they might be parsed back as int. I wonder how a common method would be called (randomNonNegativeLongButOftenSmall?), which range to sample the small values from (that might vary between tests) and where to put it. But maybe @tlrx has some suggestion.
++ I like that solution here
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
Is there a reason these three fields need to be test instance members be randomized in the init() method? Otherwise I would prfer making them local in createTestIntstance().
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
just saw it in the factory validation, nevermind :)
"now" should be "not"
typo : now -> not
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
This many levels of nesting hurts my head! How about refactoring the inner half into a private `findShardIds(@Nullable String index, Path indexPath)` method so it's easier to read? I'm worried about the potential for future typos for anyone else touching this code
left over reference to a countdown latch
I don't believe this is only kept for BWC. You use this to parse `_source` above.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I guess it could be renamed to isFalse() / isTrue() now
This can be replaced with ``` java boolean isTrue = isExplicitTrue(value); ``` similar to the previous example
oh, multi-bucket comparisons are ready already? :)
typo in the method name here too
Incides -> Indices ? ;)
do we really need so many tests? this is just about parsing? It can probably just have unit testing for this..
This seems very error prone, since it relies on CPU scheduling, network latency, or even whether the test is using mocked networking...
argh. Hidden by github ui. all good.
the printStackTrace should go away here
I think we are still missing preference? Should be similar to the get API.
we should support the preference and parent flags similar to the get API.
Change to Throwable.
Consider checking for `null` somewhere for `primarySize` before the division below.
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
Yeah, I think we can collapse both deciders into one here - it will make things simpler. Call it RecoveriesAllocationDecider that is incharge of all recovering shards (replicas and relocating primaries). It's good to do it in a different PR imo..
oh nevermind, I just found the method that called it with null :)
ok fair enough
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
Is there a reason these three fields need to be test instance members be randomized in the init() method? Otherwise I would prfer making them local in createTestIntstance().
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
I double checked and heard that `@Ignore` is needed as well, otherwise IntelliJ tries to run this test as well when running all tests from the IDE.
this should be an abstract class, not sure if we also need the `@Ignore` annotation.
Since this is static, the name should be `THREAD_POOL`.
I think that all of these members variables except for `finalResponseListener` can be `private`.
`EMPTY` could have a more descriptive name
Same here, nevermind again :)
The migration process will only move datafeeds from cluster state to index when the entire cluster has been upgraded to whatever version this goes into (6.6 or 6.7). So if we can find the minimum node version in the cluster in `toXContent()` then we can write the extra fields into the X-Content representation only after the entire cluster has been upgraded. That will make full cluster restarts work in the case where the entire cluster is on 6.6/6.7 (and it is essential this works because some people will run 6.7 for a year after 7.0 is released). So if `job_id` is `null` after a full cluster restart then that implies the cluster was not completely upgraded to 6.6/6.7, and hence the migration will not have started, and hence the information can be obtained from the `MlMetadata` in cluster state.
The problem here is that it would break multi-version clusters. We still need to read/write vLong depending on in/out.getVersion so that at least positive offsets work.
Maybe we should try to use a vLong? 8 bytes per bucket can be significant if there are lots of buckets
This is confusing is what this is.
I think you can just do this? ``` if (info.files().contains(markerFileName) == false) { return true; } ```
thank you for renaming this.
yea, I would at least debug log it..., it shouldn't happen
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
using ActionListenerResponseHandler will simplify this lightly.
I know this is how it used to be, but can we make the if be more like the `masterNodeChangePredicate` name and check the the master node is not null and have changed? (we now test for a cluster state change)
Somewhat simpler: ("timed out while retrying [{}] after failure (timeout [{}])", action, failure) . I'm doubting between DEBUG and WARN for this log...
The logging brackets are off here: `[{} to [{}]]`.
I find these two empty `continueProcessing` methods confusing, if we manage to merge the two filter chains impl as said above, we would get rid of them I think
we throw the exception and thus take care of the interrupt. We don't need to set it...
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
this might also be called I think
Can we make this 1 hour? If it times out it's nice to get thread dump
this might be called by `scheduledRefresh`, which can happen at any time
can we unify the resolvedDiscoveryNodes logic with the buildNodesToPing ? They are similar in the sense that they don't change during a ping cycle.
You can add the return value of `resolveDiscoveryNodes` to the HashSet being built
can you assign the key and the value here before we use it? it's way easier to read
can we add some java docs? the name to functionality transition is not trivial anymore
can we test what happens when one calls `setResources` passing in multiple ids? That's the one place where we need lists to work properly.
In these writeTo/readFrom methods, you need to make sure that you can talk to a node that is running an old version by adding checks on in/out.getVersion()
this is also java 1.7
can we debug log the default? also leaning to have info the "non default" setting, thats what we try to do most times in other components to try and keep the startup logs clean and informative.
I guess, are any of the other assertions necessary given that we are checking that source has not changed at all in this case (and no metadata was added).
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
Maybe this one too, I'm not sure.
Fine by me.
I think s/lang/defaultLang/
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
Could you move `writeTo` up here? It is easier to compare them if they are together.
:) good catch
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
you can remove randomization of boost and queryName
remove the set boost
remove the setBoost
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
I think filter and query can never be null here? not sure whether we should validate this here.
I see now... yea it's odd here cause this query has a single float field, looks better on more complex queries (especially cause you don't really see that among many fields)...
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
@clintongormley mentioned that NONE doesn't have many external usages (we only use it for index auto creation) so we might want to drop the special naming and use `0`. I will keep the object reuse in parsing.
and.. looking at the parsing logic this is indeed internal and we don't accept none from strings. Sorry for the noise.
we "special case" NONE here but not ONE, maybe it's simpler just to remove this method as well as the `validateValue` one and use `new ActiveShardCount(...)` in the two places it's currently used (and also ad ``` if (value < -2) { throw new IllegalArgumentException(...) } ``` to the constructor.
I you decide to go this route you should also remember to replace the reference equality checks (`this == ActiveShardCount.NONE`) by equals checks or by looking at value (`this.value == 0`).
Yeah, exactly, and I think usage should really be reserved for incompatible or invalid arguments, for example. This is more a state thing, so now I think I'm convincing myself that configuration is apt.
This should be a `USAGE` error, not a `DATA_ERROR` (and the period dropped from the exception message).
No, it should stay "id" in the message because plugins are installed by id (with the exception of some special plugins that can be installed by name only). Yet "name" is fine for removal because plugins are removed by name.
It is called pluginId in install because it is an identifier, which _may_ be a plugin name, but it also may be maven coordinates or a url.
No need to squash, we can do it on merge.
Ah! The star imports come back. Its fun watching these things wash in and out like the tide.
beware that wildcard imports will cause the build to fail
to me it's kind of unclear what this suggester CAN do now vs. what is will be able to do in the future :)
remove the iterations please
I wonder if this should be null unless we've asked for deduplication.
maybe we should just get rid of this local variable and write the next line: ``` nodesIds = filterNodeIds(clusterState.nodes(), resolveNodes(request, clusterState)); ```
I think this code will be simpler if we have two methods - sendFullClusterState and sendClusterStateDiff , each dealing with it's own serialization (and have the cache map passed to them). We can have sendClusterStateDiff fall back to sendFullClusterState if needed , which will mean no resend method..
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
ok fair enough I didn't try it :)
let's check this on every access, not only creation.
ok, then assert that it's either snapshot or generic threadpool
If you need this in test, you can still call it getBlobStore()
I'd expect this to be in a synchronized block
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
Can you give each of them a numeric id instead? This will allow to rename the enum constants without breaking the bw compat of the stream
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
extra space makes everything not line up!
maybe call this readDiffAndApply? this doesn't really read a diff and return it.
I see some places where null is not protected against...
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
nit: missing a space after the first comma
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
I like this much better!
no need for these local variables, they're only used once...
same here - we need move double starting and such to ShardStateActionTests
this should go away
Sorry I had missed that
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
I think this can move to before the threads start - will be nastier
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
indeed, did not see that.
can we check here if the listener is done? (just checking if I got it right this time :))
Does this need to set `change = true` also? It's missing from this `if` block
DEFAUTL -> DEFAULT
As well as the default buffer size
DEFAUTL -> DEFAULT again
Can we name this `writerConfig`? It's weird to shadow the class `config` since it looks like the same thing (though it isn't)
Snapshot Name - repository name + snapshot name ;-)
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
I'd prefer this to be `@Nullable` as well... relates to xcontent serialization
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
given our direction (REST client vs transport client) I think we are fine rejecting `-1` on the REST layer. But how about keeping the `int`, using `-1` as default, and rejecting negative values in the setters? That's how we changed some of the request validation as part of the search refactoring too. This way the java api would be rejecting -1 too, which is nice, especially cause we are reusing the same requests for the high level rest client.
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
nit: could be `new MultiSearchRequest().indicesOptions()` instead
this code and the code in `SearchPhaseController#sortDocs` is almost identical. I think the only difference is the assignment of the shard ID. Maybe we can factor this out into a static method and use it in both places. It would be good to redcue the duplication on such a level and it would increase the test coverage. I would be in favor of that.
I think you can drop the null check. It returns an empty array instead.
Same here about indentation now
I think saying that we can not convert the follower index to a non-follower would be clearer. My concern here is that if `bar` is following `foo` and this message says `cannot unfollow index [bar]` it would be confusing since it is `foo` that will no longer be being followed by `bar`.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
depending on the answer to my previous question about ErrorStep being flexible with its name attribute, may make sense to fix the name to `ErrorStep.NAME`
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I like this much better!
right, I had totally misunderstood how the test works
after rebase you will have to get rid of any wildcard import, or the build fails :)
Yeah, it's relatively new but it's the clear path forward especially with JUnit 5 coming with built-in support for the same.
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
class could be `final`
nit: extra empty line
for readability I'd use this. as well
same for here, not sure if the full Objects.equals needs to be called
Oh I see why - there is no builder. Can we follow the same pattern as in other places - make this class immutable and add a builder? All purging and such can be done at the builder level.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
is this needed here? I think it does something only when the current token is start array or start object.
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
I would add a flush(), since we expect people to see those bytes and we want to be independent of the filesystem impl (what if it uses buffering, thats its choice)
Ooops - that method is new in Java 8 and you'll be backporting this to 2.0 - so you'd need the `StandardCharsets.UTF_8` anyway. I still think its marginally easier to read my way because you don't need `getBytes` and `StandardOpenOptions.APPEND`.
That'd be cool! I was hoping something like ``` java Files.write(loggingConf, Arrays.asList( "logger.test: INFO, console", "appender.console.type: console"), StandardCharsets.UTF_8); ``` would be possible. Either way is cool with me.
This test is not really testing what we want to be testing here. The reason that it's not is because the cache key for a file named `".hidden_file"` is not `"hidden_file"`, but rather it is `""`. A file named `".hidden_file"` never would have been processed by the compilation engine because it doesn't have an extension. So this will ultimately throw, but not for the right reason.
I think this message should be a bit more clear. Can you include: - the path - the supportedAttributes - some explanation about what attributes we're looking for It can just be `"Don't know how to make file {} non-readable on a filesystem with attributes {}"`
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
iirc we add `Asynchronously ...` to this sentence in the other APIs. But its a minor nit...
Nit: Can we give this a more meaningful name instead of an abbreviation? I'm fine with `TestResponseHandler` for example.
nit: space after the second percent sign (on all these lines)
I think the variable name `http_port` is misleading. In RFC3986 this is called [authority](http://tools.ietf.org/html/rfc3986#section-3.2) but I think `host_port` or something along those lines is also fine. Btw, I checked out of interest and all your logic works also fine for IPv6 addresses.
You can use subprocess instead: s = subprocess.check_output('git diff --shortstat', shell=True)
Just a note here. We decided that by convention we will use the same naming as maven. `groupId` has now changed to `org.elasticsearch.distribution.[packaging]` so I think we should also reflect that change here and use `org/elasticsearch/distribution/[packaging]` where `packaging` is: - rpm - deb - zip - tar
For all of these find calls, you can use `in` operator instead: if '(On branch %s' % branchName) not in s:
> This method is private and only ever called from a single thread so there is no need to recheck. I'm just weary of having the failure handling case so far from the success case. I figure its harder for someone to break it if its closer together.
Ok - I see where it is called. These checks are a bit too distant for my taste.
I'm not sure why, but the usual convention for freeing resources when the request is done is to have a method called `finishHim`. Mortal combat reference? Anyway, the nice thing about this convention is that it gives us a place to look for resources to be freed. But above I mention reusing a thread pool of some sort anyway.
`synthesizeResponse`? I just want something to make it obvious that it the result of squashing together lots of responses.
Fine by me. I tend not to use `get` unless I'm implementing a method to get a property just because getters are so common in java. If I ever think of the method as building a thing out of state then I don't use `get`. Its kind of silly because the whole point of getters is that you can build the thing. `getAccumulatedResponse` is fine.
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
Maybe use the same convention as we use in the other builders here. Have these variables as Double objects and default to null here. Then check for null before including them in the XContent output and leave defining the defaults to the parser? This applies to all the models
we need to remove this from onGoingRecoveries and only call cancel if it was found, otherwise we may leave a lingering recovery id, pointing at a cancelled recovery.
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
I see it now - I think how you've got it now is the most right thing then.
maybe be nice and add that you reuse the bulk request. So "refresh is not supported on an item request, set the refresh flag on the BulkRequest instead".
if we add a null check to the String constructor we can remote this check here given that the parser already looks for the existence of the field too.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
Shouldn't we test only three cases: no_sort, new_sort, old_sort ? Mixing the old and the new format should not be allowed.
Not related to tests but this function should be deprecated.
Like above, I'd simply use randomFrom(SortMode.values()).
Nit: I think you can leave out ESTestCase here.
Nit: I think you can leave out ESTestCase here.
+1. Good catch. I missed it. It would still be good to kill the node when testing - so we should have some assertions here too.
same here re enumSet.toString
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
Assert that the current thread holds the lock on `this`? The results from `ObjectLongMap#indexOf` remain valid only if no one else is mutating.
Nit: there is an extra space after the `&&` and before `inSyncLocalCheckpoints`
`Arrays.asStream(response.pingResponses)` would not materialize it
just flip it then you don't need to negate
+1 this really cleans up code in several places
Maybe use ConcurrentHashMap? if we can then we don't the synchronized methods.
ah ok that make sense
Just for my own education, and it is certainly super minor: when reading this part I was wondering if it would make sense to get the maxClauseCount limit once at the beginning of this method since its unlikely to change to avoid method calls in each iteration). Maybe Java does some clever optimizations to avoid this though and the effect most likely negligible.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I guess it could be renamed to isFalse() / isTrue() now
replace match here too
I don't believe this is only kept for BWC. You use this to parse `_source` above.
I wonder if we want a trace message here...
I think this is a left over.
For backporting to 6.3, I think this needs to be changed to 7.
Alternatively we can move this logic to the `beforeRefresh` method as this is the only place it's used at.
this might also be called I think
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
I think this check does not add much (I would skip it)
maybe 7 indices with 50 docs is a bit too much (= slow test), let's reduce randomness to 3 indices, each max 2 shards, and 10 docs.
Wow, that's a big difference! Do you know whether it is lossy compression or not? If not then indeed compression seems to make a lot of sense. :-)
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
does this work? it works for percentiles, but with percentiles rank it's reversed
just saw it in the factory validation, nevermind :)
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
this can only be a runtime exception you can just bubble it up no need to use `convertToRuntime`
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
can you just leave the constant in this class? There isn't a need to put it in realm imo
These always read clearer to me as `<= 0`.
It looks like this could fit in 140 columns.
typo: direct**or** -> direct
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I think it would be more flexible if the keys were objects? (you could have composite keys, etc.)
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
sounds great thanks
Now I wonder if you should make readFrom/writeTo final and make an abstract method that is just responsible for reading the response. That pattern was used by the query builders until they switched to constructor based reading and it seems fairly a appropriate. I don't think it should block the PR though. It isn't really important I think.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
I really don't think we need this leniency, I'd like to understand why we're introducing it. I think we should just blow up the pings.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Perhaps add the duplicate size to the assert message here
whoops I read it backwards, so yeah, not really necessary
exiting -> exists
I think this would be cleaner as ```java aliasAndIndexLookup.compute(aliasMetaData.getAlias(), (aliasName, alias) -> { if (alias == null) { return new AliasOrIndex.Alias(aliasMetaData, indexMetaData); } else { ((AliasOrIndex.Alias) alias).addIndex(indexMetaData); return alias; } }); ```
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
Please add a string message about the context registry being null
Could be `contentType = scriptMetadata.getOptions().getOrDefault(Script.CONTENT_TYPE_OPTION, DEFAULT_CONTENT_TYPE);` And then you can remove the null check below
Would be nice to see this parsing code pulled into a function or helper on the parent class so it doesn't need to be the same in both implementations
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
`EMPTY` could have a more descriptive name
same here: no need for the [].
index's toString gives you '[index_name]' no need for '[{}]'
same here - I think it's better to log the info message if the deletion was successful.
Left over Note
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
same here with removing retry logic
same here, all retry logic should be removed
same here with removing retry logic
our `blobStore` already has a method that will return us an instance of `SSEAwsKeyManagementParams`; we should probably use it instead of `new`ing up our own here.
on second thought, after seeing how our `blobStore` appears to be the true keeper of the encryption key (because it has the most distinct things asking for it, maybe we shouldn't change the constructor signature of this method and _consistently_ reach into `S3BlobStore` for our key.
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
Maybe you could put the validation removed from toCContent here. (point.size > 0)
I see, so parser always sets both "order" and "mode", regardless of whether they are set by the user. But what if we only go through the java api, use a plain builder and set "reverse = false". Translated to json this should give us "mode = MIN", but only if not explicitely set by the user otherwise, no? Sorry, haven't got a good solution myself so far either.
Yes, sorry for the confusion, I remember the discussion now. Maybe just rename then, although `elementName` is also fine.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
do we protect this from double invocation? I think we should just make sure we only invoke once. can you wrap it in here and ensure that? maybe just use `NotifyOnceListener`
it's find in this case! LGTM
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
long live java 8
can we init this with `1`
shouldnt this solve the problem and not the above ``` String.format(Locale.ROOT, "https://download.elastic.co/org.elasticsearch.plugins/%s/%s-%s.zip", repo, version)); ```
have you run this through maven? I think `String.format()` without a locale is part of the forbidden API
Fine with me :) I'm already wiping the repository itself after each test, so this shouldn't have much effect (I don't think).
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
Nit: space between the cast operator and the target.
make these parmaters to this method? then it doesn't really need to know about index creation requests.
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
this file needs formatting
Typo: `afllowed` -> `allowed`
What about just converting to bytes and comparing? The way you have it now this isn't consistent with `equals`.... Also the _cat API we call `toString` which doesn't really use the unit anyway.
Yeah, looking at it again, that makes sense!
similarly, equals uses the hash while hashCode doesn't
It feels wrong that hashCode is using writtenBy while equals isn't
Correct [equals](http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#equals%28java.lang.Object%29) implementation supposed to be reflexive. In other words the following test should pass: ``` StoreFileMetaData test = new StoreFileMetaData("test", 0, null, null); assertEquals(test, test); ``` Maybe `equals` is not a good substitution for `isSame` here.
It should - see `IsNull`
Wondering if the class name shouldn't be `IfNull`...
If the constructor is modified, this method won't be needed anymore.
I'd remove the bitmask - it doesn't seem to add much value (see the previous method suggestions for implementing and); shorter and clearer than using bits.
depending on the answer to my previous question about ErrorStep being flexible with its name attribute, may make sense to fix the name to `ErrorStep.NAME`
oh, the boxing horrors :)
here we could use sublists again - just scan to the place you need. No need to reverse then.
removed can just be a count. We always remove from the beginning of the queue.
If we use Collection<Tombstonre> we can return an unmodifiableCollection() which doesn't copy stuff..
can we add the serialization logic we need to the Index object it self? we're likely to use it in other places.
I see this was already like this, but this can go on a single line.
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
acceptDocs will be checked _before_ these bits are checked anyway
Fine with me.
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
I _think_ that you can get away with just letting the exception bubble up and RestController will send it to the user. You won't get the error log but I'm not sure logging an error on 400 level parse errors is a good thing in the long run anyway. I try to usually run requests with `error_trace` on them so we don't eat the stack trace....
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
nit: extra newline
Would you kindly add some line feeds here to make it look like json instead of a wall of text? It'd be so much easier to read.
I am surprised that we don't have a default impl for this :)
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
We should make TaskInfo final then.
Can you reverse this, the negative makes it harder to read
It's super minor, but our log standardization is usually all lowercase
Could initialize this with the size of the hits list to prevent resizing
is this always used in an assertBusy context? wonder if we should add it here. This can be suprising...
It feels like this is the wrong place to do this. I think we should do this in `Bootstrap` and then just pass a `Path tmpDir` to `InternalSettingsPreparer#prepareEnvironment` and make sure it's mandatory for all instances of environment that are not the single arg ctor. Btw. it feels like there are some sleeping bugs if this ctor is used in prod code.
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
much cleaner. thx.
I've dug some more. This is caused by us running the tests with the built in gradle test runner rather than the randomized runner. We configure the randomized runner to run with the system properties but we don't ever configure the standard runner.
When I pulled this locally and reverted the changes to this file I didn't have any trouble. We've traditionally been very weary of making changes to this file so I'd really like to make sure we need this before we do it, even if it is temporary.
And some more: this is not caused by the build compare plugin. Maybe by gradle 4.8 or maybe by one of our hacks to make 4.8 work.
This assumes a version format that while fairly standard is not guaranteed.
I think we can do this more simply by looking at `endsWith(".jar")` of the uri string. We don't really need to convert the uri to a path, since we don't need to load the file. Then, the original if statement can simply be wrapped with like: ``` URL location = clazz.getProtectionDomain().getCodeSource().getLocation(); if (location.toString().endsWith(".jar") == false) { // original if and exception here } ``` Basically, if the file is in a jar, we don't need to worry about it here, as those would have already been added to the codebases map by `Security.getCodebaseJarMap`. This method is about adding classes that are on the classpath, but not via a jar (ie built by the IDE).
just call `parser.text()` instead of `parser.bytes().utf8ToString()` since it might be optimized under the hood
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
replace match here too
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
Can you make this non-pretty, it's always weird when you log things and then end up being multi-line
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
I asked before if the bit from runForDoc till the end can be a new method exposed by the Script class, in the effort of consolidating how field script classes expose their values. Do you have thoughts on this? We could also do it later
would it be possible to make the second part of this method part of the field script object itself? It would also be fantastic to use the same mechanism on both sides, but I know it is a bit tricky for different reasons: 1) that array that we reuse without resizing 2) we try so hard to avoid boxing 3) the usage pattern is slightly different if we compare doc_values, query and index time execution. I do wonder if it is worth investing on this, possibly having our own PrimitiveIterator or something that allows us to expose a clearer script API to access the computed values. For later I guess.
could these three methods somehow be in the base test class, at least partially? what I am looking for is avoiding copy pasting when writing new tests, and possibly not forgetting to cover important scenarios.
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
Is the `if` necessary? It seems to me that the following should work? ``` java for (String pattern : request.selectedFields()) { fieldNames.addAll(indexShard.mapperService().simpleMatchToIndexNames(pattern)); } ```
you can just use `MultiFileds.getFields(index.createSearcher().getIndexReader());`
this should be `isExists`
this should be `isArtificial`
just initialize it and make it final - it just compliicates the code
+1 that is what I would do too
This is what I meant, yeah. I'd have made it a `private static final ImmutableList<String>` instead of `Immutable<Highlighter>` but it doesn't make much difference.
can you remove this TODO? I'm not sure we are going to implement this after all, nobody needs it for now :)
Yeah - at least needs the ALL_UPPER_CASE naming. Probably should be moved to the top of the class too because that's where I usually look for static stuff.
I don't think it's important for now
hmm this has an empty impl? Not sure if we need the `Injectors.close()` if we need it, it should deal with null values!
trash the @param and @return
can cause and name be final
I wonder if we should have a static `EnumSet<State> PAUSE_ELIGABLE = ...` this makes it simpler IMO
can we name this maybe just `UpdateTask`
we don't want it to be retried... that was the cause of the failure
my thoughts too :)
Typo: "Dynamics" -> "Dynamic"
`String.format(Locale.ROOT, "%s operation term [%d] is too old (current [%d])", shardId, term, primaryTerm)`
I think it's confusing that the WriteReplicaResult flow is different than WritePrimaryResul. i.e., `finishWrite` is called in the constructor for one and in the respond method for the other. We should try to make them the same as far as possible.
+1 on removing the `Void context` from all methods. The `declareInnerHitsParseFields` is already complex to read I think, that won't add much.
Sorry, I just saw that you remove them already, thanks!
Right... but I'd be happy if we could unit test this, and if we do then we need to ensure the object start.
We don't need to use this local ref
It would be nice to have some doc that indicates that it's going to be parsed and stored in a temporary map before being created using createFromMap() method, and the reasoning around why we do this. Also, maybe we could rename to MAP_PARSER? Just an idea.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
hey @martijnvg I double checked with @clintongormley and we both think it's better to add the actual index that was closed, not the alias. Knowing that an alias is closed has little sense, better to report back which concrete index was closed.
I think we should mention the index, cause that is the useful bit (e.g. which index is closed), also because we never really hide the fact that users are using aliases (e.g. when indexing into an alias, the response will contain the concrete index as `_index`, not the alias).
Can we provide more details in this message (e.g. the name of the index/alias)
seems redundant indeed
Throw error if old-style params passed alongside new-style script definition
Error if old-style params passed alongside new-style script
this new exception is going to trigger errors too if we try to serialize it to an older node
I think s/lang/defaultLang/
Fine by me.
the suppress warnings could be right on the line of code doing the cast instead of the whole method
could name this `getUUID` to be consistent with other usages of UUID in the code base
Ditto here with `getUUID()`
Er, probably not. But a bit confusing name because it looks like a typo.
I think we should use `debug` for the logging here
points are allowed to reuse the byte[] to I would make a copy of it before adding it to encodedPointValues
should be clause.getOccur() == SHOULD
`seqno` -> `_seq_no`
Nit: `primary term` -> `_primary_term`
I think it should either be an `else if` or the `if` should be on the next line.
I spent some time thinking about whether we can consolidate this, like we do for runtime fields (e.g. the compilation could be done in a single place for all types). We can't really do the same that we do for runtime fields as NumberType is an enum and can't have a generic type, while the different Factory and LeafFactory don't have anything in common throughout the different types hence require a generic type somewhere. Whatever we do ends up being complicated for little gain e.g. saving a few lines of code). One thing is I find it a bit tricky to follow that thanks to this we compile the script at mapper creation time and not at execution time. We could potentially make MapperScript an abstract class with a generic type (the factory) and compile the script in its constructor. That is not perfect but maybe clarifies when the script gets compiled.
sorry, I was referring to the AbstractScriptFieldType#parseScript which does exactly the same
shall we make the error message agnostic "on field []" and reuse the existing parse method? It will need to be moved to a common place I guess.
ok, I was more worried about the handling to make sure that we don't support stored scripts, but indeed, the rest is just calling Script.parse so it is not a lot of code.
Could you move `writeTo` up here? It is easier to compare them if they are together.
++, the only thing is I would even go with a Map<String,String> if that works. not sure what you and Nik think about that.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
nit: could be one line
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
`min` can be named `simple` or `aggregation`
I think we should not execute these writes directly here but extend ESIndexLevelReplicationTestCase#ReplicationAction then run them via the infra of the new action (see ESIndexLevelReplicationTestCase#IndexingAction).
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
we have `TestThreadPool` that makes it simpler
use `ThreadPool#terminate` here otherwise you will get lingering threads etc.
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
can we fold this into ClusterHealthResponse? that way we can test this as well as part of the unit testing.
Should you use the static `templateName` import here and throughout? It looks like you might be mix 'n matching.
I'd just use the Id really
use simpler constructor.
there is a waitForStatus variant - should be simpler.
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
I wonder if we want to add an `@After` rule that checks that all semaphore permits are back.
I think this can move to before the threads start - will be nastier
this causes a deadlock when the operations that are blocked by the block are first in the future list while the last part of the future list prevents the block from being acquired. See the gist I made.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
I see that we need it from another package, I think it's ok.
Ah nevermind, I see where we check it above :)
ok fair enough
Yeah, I think we can collapse both deciders into one here - it will make things simpler. Call it RecoveriesAllocationDecider that is incharge of all recovering shards (replicas and relocating primaries). It's good to do it in a different PR imo..
NullPointerException here (decision can be null)
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
The indentation is off here and the rest of the way through this test.
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
I think this code will be simpler if we have two methods - sendFullClusterState and sendClusterStateDiff , each dealing with it's own serialization (and have the cache map passed to them). We can have sendClusterStateDiff fall back to sendFullClusterState if needed , which will mean no resend method..
I think we should use `debug` for the logging here
s/The tasks has/In case the task has/
I also wonder if we should pass in `ClusterStateService` instead of `ClusterState` and `ClusterStateStatus` separately. This will make it easy to take the full `ClusterStateService` object into account in validation methods.
Somewhat simpler: ("timed out while retrying [{}] after failure (timeout [{}])", action, failure) . I'm doubting between DEBUG and WARN for this log...
This constructor doesn't seem to be necessary.
I know this is how it used to be, but can we make the if be more like the `masterNodeChangePredicate` name and check the the master node is not null and have changed? (we now test for a cluster state change)
Nit: `accross` -> `across`
same here these strings are only used in one place just use them directly and trash the Fields class
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
I am not a huge fan of base64 but I guess you are right.
I think we can just pass the bytes directly to the json generator it will do the right thing with it.
Can we have `field_statistics` as an XContentStringBuilderString as well? if it applies to other places, would be great
Oh I see why - there is no builder. Can we follow the same pattern as in other places - make this class immutable and add a builder? All purging and such can be done at the builder level.
can we make those statically configurable ? (no need for dynamic settings)
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
can we move all purging to the purge method, which will always be called by the builder? The down side will be not having logging, but if people want that they can put the cluster service in trace logging and see the changes.
this method can the max size and min expiration window as parameters, which will make it easier to test and have those be settings,
assert for verification whether it is created
Right - RollupIT is the right place
same here please add a nice constant that is human readable
Can we also clear the temp `charBytes` array, something on the lines of: ``` final byte[] charBytes = CharArrays.toUtf8Bytes(password); try { return builder.startObject() .field("password").utf8Value(charBytes, 0, charBytes.length) .endObject(); } finally { Arrays.fill(charBytes, '\u0000'); } ```
I also need to go back and do this for the PutUserRequest
I am good with both options.
fine with me as well. go ahead and push!
interesting, what is the reason for this funny upper bound? :)
Oh I see, it's the ZTable stuff. Sorry for the noise :)
Would it make sense to move this method to some SpatialUtils utility class? I feel like it's pretty generic and we might find some other ways to use it. I think I would also replace first three doubles with Circle. And we should figure out what to do with the radiusMeters parameter in Circle since it is not meters in case of `shape`, but this is a topic for another PR.
I also dont' think we should swallow the exceptions here? Someone asked for a gce address and we failed to get it...
@dadoonet I think the log message can still say "Failed to fetch metadata from google" ? more than just client creation can go wrong here..
@rmuir are we OK with this? Is there a better way (not sure at all, just double checking).
I wonder if it should not also decrement the CountDownLatch if an exception is caught in the SimpleChannelUpstreamHandler ? Something like ``` new SimpleChannelUpstreamHandler() { @Override public void messageReceived(..) { ... latch.countDown(); } @Override public void exceptionCaught(...) { latch.countDown(); } ``` Just to be sure that the client does not hang indefintily.
also, I think the opened channel needs to be closed at one point
You can use `XContentParserUtils.throwUnknownToken()` (that would throw a ParsingException instead but I think it's appropriate here)
If you're just going to use another builder internally, why not return Settings from this and the other fromXContent and remove the builder arg? Seems a little odd to take a builder, and also return a builder, when the advantage of taking the builder (not creating another builder) is not used.
This can be replaced by ` ensureExpectedToken(XContentParser.Token.START_OBJECT, token, parser::getTokenLocation);` from `XContentParserUtils`
Looks like the toXContent() and fromXContent() are not completely mirrored; the former does not render any root object while the latter expects it.
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
fine with me
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
you are perfectly right Christoph, let's merge the two and keep the existing class.
``` java final RefCounter previous = ref.getAndSet(indexShardOperationCounter); assert previous == null; ```
yeah nevermind I was confused about some internal classes
if not needed +1 on removing
Since we now use a logger with an index prefix , this will result in double index name logging `[index][index][0]`
same holds for other logs bellow...
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
typo: direct**or** -> direct
the start cluster does this.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
we have a new awaitNoMaster util method
So, this could be simplified to `assertFalse` Or could be something like the following (which admittedly, is probably less simple) ``` import static org.hamcrest.CoreMatchers.everyItem; import static org.hamcrest.Matchers.greaterThanOrEqualTo; import static org.hamcrest.beans.HasPropertyWithValue.hasProperty; ... assertThat(response.records(), everyItem(hasProperty("recordScore", greaterThanOrEqualTo(50)))); ``` Man, that is frustrating that hamcrest does not support just passing a lambda as a type of matcher :(
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
I see, I didn't notice that, cool no problem
nitpicking here...but we could use an array instead of a list and avoid the conversion list to array afterwards
same as above, could be an array
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
similarly here I would like it better with a regular for loop and by making fillSegmentInfo take a single segment at a time
this is not needed. createIndex automatically reroutes.
We can use the SuppressForbidden annotation on top of the class to fix this.
we can throw exceptions on the background thread and the test should fail with uncaught exceptions on a thread.
I think if you don't have the Java build stuff setup you should make javana do the merge ð On Jul 14, 2016 8:21 PM, "Honza KrÃ¡l" notifications@github.com wrote: > In > test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java > https://github.com/elastic/elasticsearch/pull/19436#discussion_r70905675 > : > > > @@ -34,7 +34,7 @@ > > */ > > public final class Features { > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key"); > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key", "yaml"); > > Thank you @jasontedor https://github.com/jasontedor, I don't have my > env setup for java so I missed this. > > â > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub > https://github.com/elastic/elasticsearch/pull/19436/files/d53406b8d3919c5367c1bb574fd365fb2af7110e#r70905675, > or mute the thread > https://github.com/notifications/unsubscribe-auth/AANLotcG0AVdYcNe3YtwU1U545rSEKT2ks5qVtJ2gaJpZM4JMfjQ > .
This has a line-length violation. I pushed 575fa4e00a8be31a54859adf06f39c7280691040.
well well if you were an external contributor I would have run the whole suite that takes 45 minutes. But in your case, trust won. I should have totally counted the characters of that line as part of the review. P.S. we java folks are the first ones pushing without running tests at times (WAT?), so no biggie. I will check closer next time.
please use Arrays.asList while we re here
can this be synchronized please
your call on whether to change this, but we also have `Strings.EMPTY_ARRAY`
if it prints out null it may be ok, if it gives NPE we need a null check, that's what I meant.
we may have a small problem here, when toXContent is called on an object deserialized from a previous version that didn't send the _id .
thanks for checking, that is fine then
I think you can just blast the entire method in this case.
I was trying to understand why this works, because of the forward iteration here (with nested, we usually seek backwards (`BitSet.prevSetBit(...)`)). So this works because all live doc ids (root docs and nested docs) are evaluated in order.
I think ``` java if (prevParentDoc == -1) { childDocId = childDocs.nextDoc(); } else { if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc); } } ``` could just be replaced with ``` java if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc + 1); } ``` ? (No more check that the previous parent doc is -1, and advance to `prevParentDoc+1` instead of `prevParentDoc`)
I don't think "Not implemented yet" adds anything other the exception type (and could be misleading if we never intend to implement).
beware that childrenIterator cann be null here, so I think you need to have ``` + if (childrenIterator == null) { + return null; + } ```
please don't load stuff lazily. go and load it all in the ctor. they are in memory anyways.
May be `if (!FileSystemUtils.isAccessibleDirectory(dicDir, logger))`
Minor typo of `local` instead of `locale` in the exception message.
typo: dictionnary -> dictionary
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
don't you want to reset first and then set the parseFieldMatcher? :)
asked f2f, we can probably delete logging at this point.
we can remove this catch
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
don't ignore it? Just call `parser.text()` without the if, should work.
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
I think I saw this in Christoph's PR too. Hopefully you don't need it.
I don't think you need @Before here, the parent method already has it.
+1 on removing it
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
these ElasticsaerchExceptions are bogus remove them
Typo, "Trasnlog" -> "Translog"
Should use `{}` logging style instead of string concatenation here
I know this was copied over from another place, but I wonder if we should give preference to the recovering file. If I read this correctly , if we have both recovering and non-recovering, it is now random which one we choose.
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
you mean providing the size of the array I guess? cause I don't see a constructor that accepts an array in ArrayList.
We also need a simple rest test, testing integration like we have for the other processors
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
can you add spaces? `new KeyManager[] { km }, new TrustManager[] { tm }`
indentation is off after other changes
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
Can we keep the line numbers in the test assertions? I think they are important to maintain.
I am wondering if we should add `buffer` (size or operations) to the Status object? We can do it in a follow up if you are okay.
optimization nit, but maybe we can just have one list, and reorder to push active one to the start, we do something similar in primaryFirst. This will mean we don't have to create 3 lists, just one
can me extract this into a method, it is used in 3 places
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
same here - I think it's better to log the info message if the deletion was successful.
s/to list of/to the list of/
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
we need to add that we return false if no folder was found for this shard.
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
we should probably bail here. One nit pick - I would prefer having this rejection logic closer to where it holds. I think there is only one method that can cause this.
we should log the exception here.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
do we need this trace log here and if so can we fix it to say `temporarily` or something like this
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
Thanks for moving this to `InnerHitContextBuilder` and its subclasses!
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
Fair enough. I wouldn't change the capitalization though.
I wouldn't name it in capital case because it isn't a constant. Otherwise I'm fine with whatever rename you like.
I had a quick look and opened #25519 with what I imagine the strategy is. It certainly looks big enough to be worth doing in its own PR.
if you use here `refresh();` from the base class we also make sure we get back no failures.
Also, you dont necessarily have to change this but you can now replace `.execute.actionGet();` with just `.get();`
Btw, you don't necessarily need to use a jsonBuilder here, you can just do `setSource("text","parent")`
Indeed, it happens because all shards fail. I guess you want to verify that a normal query would fail but since we parse it only for the right indices we don't get back the failure using indices filter/query. I would then try and catch the exception that's thrown.
`assertNoFailures` is more common in newer tests and much shorter.
Typo, finalzlie -> finalize
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
`engine failure` -> shard failure
small typo, 'saving'
Just wrap and rethrow and let junit report the exception.
Also, `.get()` is much more common than `.execute().actionGet()`.
This `if` is never false because `numberOfShards` is between 4 and 10
This `if` statement will always be run, so it could probably be removed
I'm pretty sure this just throws an AssertionError so it wouldn't work either. I don't suspect it'd be very likely and I think the test would fail spectacularly on an InterruptedException anyway, so maybe just log an error? You could also make some list outside the runnable to accumulate the result. I bet we have some useful thing sitting around for this if you wanted to do more than log though.
do you have indentation at 2 chars only for this method? We use 4 chars in our codebase. I'd appreciate if you could change that.
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
this is not needed. createIndex automatically reroutes.
yeah that is true. nevermind then
I like dummy because it implies fake and the index is fake - not just empty.
can we set the timeout to 0 here? otherwise tests half the time takes 1s
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
true. nevermind then
check listener.isDone() as we don't expect a retry here I think
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
right thanks for the explaining, I should have known, having worked on the search refactoring :)
maybe also rename the setting? (in addition to the constant)
I don't think so, I think these should be bytes or size-value only.
I think 0 is a good minimum value.
We call them "master nodes" everywhere else. :frowning:
those are hard to debug I can tell u :dancers:
Thank you for cutting over to a better clock :)
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I think we should return active.get() == false and also - set it if we became idle...
Woops, never mind: maybe put params around `status.activeIndexing == false` ;)
I'm still not following you? What's wrong with the `static` reference? Whether you use a constant string field (`static final String` assigned from a literal string) or just use literal strings in all the places that you would use the constant, the effect is the same: a single `String` is put in the constant pool and that constant is pushed onto the stack when needed using `ldc`. The java compiler effectively interns all literal strings, and this is the same effect as using a constant string field.
I'm not following you? The bytes for the string have to sit somewhere and they always have to be there. When the compiler needs to use a string from the constant pool, it just emits a special instruction `ldc` to load a reference to the string onto the stack.
Nit: I'd just use the string rather than make a constant. We are slowly removing these objects.
typo: an -> a, concat -> concatenated
can this be synchronized please
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
For static varialbles, `final` should indeed be used whenever possible.
can we use getters here like `getNode` `isCanceled`
Elasticsearch tradition is to make this an EMPTY constant :)
Why not have the standard to string? A multiline return value is difficult to work with in a debugger...
well we use a dummy lock so I guess it's fine
try finally here please since if close fails we don't release lock etc which can be missleading
we have `TestThreadPool` that makes it simpler
use `ThreadPool#terminate` here otherwise you will get lingering threads etc.
and -> an
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
I think we should return active.get() == false and also - set it if we became idle...
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I'm used to wrapping debug logging stuff in `if (logger.isDebugEnabled())` tests to prevent the message construction in the (very common) case that debug is disabled. Here it probably doesn't matter because message construction is dwarfed by the refresh call.
can we make this log include the decision about whether to refresh (and also the current IW memory consumption, while at it)
you are perfectly right Christoph, let's merge the two and keep the existing class.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
No, you are right, I didn't realize the need for api users before going through the whole changes.
this curly bracket should be on the previous line
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
Lol - I spent some cycles trying to figure out how the hell we know this won't throw an index out of bounds exception, only to end up learning something about the BitSet api - it's funky ;)
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
Maybe point out that this is actually the place where we modify the valid input query by adding a new object level to it.
Move to the new randomized testing. Important for reproducibility
nit: s/read blob's/read the blob's
I'd throw the exception in `initCannedACL()` method instead of checking for a `null` here.
This is where a safeClient() would be helpful, so that you have less chance that the underlying storage instance changed between the copy and delete calls
Remove and create again is not needed I think
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
we also need unittests for these queries!!!
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
the important part is having multiple open readers on this as well.
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
Looking at this again, I think we can remove the node settings as updateDelay / getRemainingDelay only depends on index settings.
do we need the version check here? it's folded into allocatedPostIndexCreate() ? I think it will be simpler to read if we remove this from the if and add an assert on this, explaining why we expect it like that. Something like: ``` if (lastActiveAllocationIds.isEmpty()) { assert indexSettings.getIndexVersionCreated().before(Version.V_3_0_0) : "trying to allocated a primary with an empty allocation id set, but index is new"; ```
`allocation.hasPendingAsyncFetch()` will always return false here. The field that is used to determine this value is set by Primary/ReplicaShardAllocator. Even if this field were correctly set here, it would still be the wrong value to determine whether the shard can be allocated or not. The primary/replica shard allocator is only interested in knowing whether there are still pending fetches for the targeted shard id.
This is redundant. getDelayAllocationExpirationIn also calls getAllocationDelayTimeoutSetting()==0 and returns 0 in that case.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
I think 0 is a good minimum value.
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
We call them "master nodes" everywhere else. :frowning:
also make this setting `Setting.Property.Final`
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
s/The tasks has/In case the task has/
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
This method seems like it could be in `JobConfigProvider`? Then we don't have to duplicate it between this action and the put-datafeed action.
ok...but client depends on the transport service anyway no? I think I don't get it
I get that, I was just wondering why those default templates bother here
cool stuff I didn't see that one!
maybe in a followup we can think about removing these -1s... see what platforms fail, and better fine-grain the stuff (e.g. add assumption for WINDOWS, IBM jdk, whatever it might be). Then we know when and where stats are available.
could be a instance variable, as used in all tests
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
I wonder if it's nicer to append the random uuid.
if we run into an exception here we have to close the stream. we usually do this: ```Java boolean success = false; try { // do something with the stream success = true; return stream; } finally { if (success == false) { IOUtils.closeWhileHandlingException(stream); } }
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
I don't think that a security exception should be re-thrown as an `IOException`.
this does not change anything here? We are already catching the `NoSuchFileException` in the line below, which is an `IOException`.
not a big deal but maybe phrase it `remove() is not supported on GeoHashPathIterator`
maybe make if final
for readability I'd use this. as well
also, the setting should be using `componentSettings.get("page.limit", ...)`, so it will resolve to `cache.recycler.page.limit` (and I think the in_bytes usage here is not needed).
can we use "script_factor" I think it's nicer than the came case
Snapshot Name - repository name + snapshot name ;-)
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
sounds great thanks
I opened: #23338
or when some docs match the query but do not have a value
I think I've seen this somewhere else today ;-)
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
+1 then we shouldn't forget about it :)
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
This empty `if` followed by this line looks off.
Nit - strictly speaking these are publishing stats, can we open the object with just published cluster stats (drop received). You can maybe received back in the keys, which can be shorted by dropping the cluster states from the key names - itâs implied from the object theyâre in.
Here you can do something like this: ```diff diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java index 356b9a29dc..36794e880f 100644 --- a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java +++ b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java @@ -65,9 +65,11 @@ public class PublishClusterStateStats implements Writeable, ToXContentObject { @Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException { builder.startObject("published_cluster_states"); - builder.field("full_states", fullClusterStateReceivedCount); - builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); - builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + { + builder.field("full_states", fullClusterStateReceivedCount); + builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); + builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + } builder.endObject(); return builder; } ``` which makes the JSON-structure clearer in the code.
This method can be package-private.
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
I think we should change this to a warning level log (without the return it would be logged as warning in the overloaded shardFailed message)
I think we lost this debug message. I think it's fine to log once in both the shard failed and shard started cases.
Why is this `volatile`? It doesn't look necessary to me.
Maybe a name like "PlusOneMonth"
Search and executable, and execute look like they should delegate stuff to a single method. Orsomething.
I think s/lang/defaultLang/
Maybe this one too, I'm not sure.
I don't think we should even have IndexLookup. It is no more work to write and use a custom similarity than to write and use a native script, and the point of similarity is for customizing exactly this.
It might be worth logging it at warning, maybe. Its not "normal" not to have it but is "OK". Its just one line on startup and so long as the line clearly states that everything is ok, we're just disabling groovy, then I think it should be logged every startup.
then call here `register(SimpleProcessor.TYPE, SimpleProcessor.Builder.Factory.class);`
Having limitless extensibility is not a good thing... as a plugin developer, I want to know what I can and cannot do... what I can extend. Otherwise I can easily do something I really shouldn't, break something along the way, without even knowing I broke it. Having well defined extension points and effectively limiting the extensibility of es in general: - helps us make sure plugins cannot break things (as they'll be restricted to what we allow them to do) - helps the users know what they can do and rest assured that they're not doing something they're not supposed to So overall, personally I'm less concerned about not capturing all the extension points at first run.. I'm more concerned about first capturing control over it. Then we can start opening up extension points as we see fit in a controlled manner.
No, there are only two ways for sets/maps, because of how multibinder works. I think it is more confusing to have some things bound using a binder, and others with registration/settings. Classes that ES controls should be registered, and set. If there was a way to just not allow multiple multibinders to work I would say we should do that, but I don't think such a thing exists.
Also, we should really move this discussion to another issue. I think this PR is fine as is, this was just a suggestion for a follow up/thought.
replace match here too
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
ok I wasn't sure, perfect
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
Can you remove the empty javdoc? We are going to fail the build on those at some point....
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
I think NamedWriteableAwareStreamInput was introduced just a bit later. Only my guess.
same here - just pass a new instance
I think it should be: `<C> C readNamedWriteable(@SuppressWarnings("unused") Class<? extends C> categoryClass) throws IOException {`
Sorry about these crazy incantations....
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
yeah nevermind I was confused about some internal classes
Throwing a RetryOnPrimaryException feels ugly. I see why you did it and I can't come up with something better. On top of that, this made me realize that RetryOnPrimaryException has serious problems. I'll reach out to discuss. to be clear - this shouldn't stop this PR as it is an existing situation.
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
Autoboxing already happens and I wouldn't worry to much about it considering the depth is not that big. Same for `Linked` vs `Array` (in general arrays are faster except for inserting in the middle as that requires resizing/copying at which the linked structure excels). I think the `Tuple` makes the code a bit more compact and safe (the queues cannot get out of sync) and more readable/simple code always trumps optimization (especially micro ones as here).
Since the index and the Map are associated, how about using only one `Deque` which holds a `Tuple` instead of two `Deque`: ``` Deque<Tuple<Map<String, Object> index>>` queue = ... if (node instanceof Map) { queue.add(new Tuple<>(node, Integer.valueOf(i)); } ```
+1. It looks like a small method and while it might be inlined the extra `Tuple/Integer` are boiler-plate. If the method gets unrolled, both the index and the found value will be available without wrapping/boxing.
do we need ordered things? does order help anywhere? If not I would just use HashMap
are we sure we want to silently go ahead this way when templateService is null? Maybe we should fail so that we find out when it happens, unless it's situation that is actually expected to happen.
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
this will annoy the forbidden API after rebase + squash. Heads up
same here regarding nullable ..
We suppress and not report all errors which are OK. I don't think we need a special protection here about it.
we can't change the format of the response at this time. We can at some point, but for now we just have to parse what we have, and figure out what we should do to make things better for the future, meaning potentially breaking changes etc.
I would use the following message: "ignored as shard is not being recovered from a snapshot" and not have an explicit check for `shardRouting.primary() == false`. That case is automatically handled by this case too as replica shards are never recovered from snapshot (their recovery source is always PEER).
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
I would write this check as ``` if (shardRestoreStatus.state().completed() == false) { ``` and then add an assertion that `shardRestoreStatus.state() != SUCCESS` (as the shard should have been moved to started and the recovery source cleaned up at that point).
solely based on names, hard to distinguish from `testRebalanceNotAllowed`
ok fair enough
we can... but it's important to not forget that some classes should not to depend on es. Packages don't enforce anything but may make you think about it (or maybe not). Anyways I think it's nice to keep separated the es runtime for ingest and the ingest classes that are independent from es core. There is a pretty big difference between these two sets of classes. As I asked above, maybe there are other ways to keep things clean, not sure.
Good idea to add this safety net.
I think we can do this without adding an interface? Users should not need to do this? A script cannot realistically be used for both search and executable. I know this is more a problem with the existing scripting apis, but I think here we can just implement executable, and search should throw UOE.
can this be final
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
I don't think we should do `__default__` we can pass the default separately...
I saw this problem being dealt with in other place by setting currentFieldName to empty String. Worst that can happen then is that it is treated as fieldName in the query, which we should validate later and throw IAE then.
you can remove the validate call for now, we will fix all queries soon, I promise
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
I hope I'm not splitting hairs, but there's also a typo in the field (deault is missing and 'f'). (This PR resulted from a question I asked here; thanks for all the awesome work you invest there!)
nit: space before RESPONSES
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
I see, so parser always sets both "order" and "mode", regardless of whether they are set by the user. But what if we only go through the java api, use a plain builder and set "reverse = false". Translated to json this should give us "mode = MIN", but only if not explicitely set by the user otherwise, no? Sorry, haven't got a good solution myself so far either.
you should pass fieldNames as an argument
we can delete ForceMergeFailedEngineException now, right? It's not used.
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
same here - I think it's better to log the info message if the deletion was successful.
we need to add that we return false if no folder was found for this shard.
nit: I think remove "next", since this is no longer a second step in the method
we need transport stuff too, for example, TransportSettings#PUBLISH_HOST (but there are more) . I wonder if we should just pass through everything prefixed with network and transport.
I'm doubting here too, though I see the value in a controlled environment. The true long term fix here is testing so we know what we need. Do note that one can set ANY setting on the tribe.\* level. This is about defining inheritance.
I have no idea what else we may need also, it is not the first time we forget about some needed settings... looking back I am not sure that the approach of selecting settings is correct, judging from how many problems it caused to users. It may be cleaner but the truth is that it is easier to define what settings don't make sense in a tribe client node and exclude them rather than having to include all of the settings that people may need passed through. My 2 cents.
nit: why not just use the setting objects? we could then use a the exists methods instead of check for null values.
or just: "return ok;"? :)
ok let's avoid the concurrent put/computeIfAbsent issue for now, we can try to improve in the future if we observe slow concurrent access
I think the unlock calls should always be in a finally block
I always think of `Iterator` as sitting between two entries rather than on the last entry it returned. But I see your way of thinking and am fine with keeping `current`.
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
It could be useful for debugging too. In the future it's conceivable that the support diag tool might use the HLRC, and we wouldn't want to be dropping this value.
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
I've noticed this field isn't in 6.x so please remove from the backport
Can you make this non-pretty, it's always weird when you log things and then end up being multi-line
This should be immutable I think, it looks like its mandatory.
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
I think we can get rid of this field in the abstract class, as far as I see it can be "term", "completion" or "phrase", those should be the NamedWritable NAME constants in the subclasses, so the superclass won't need to store it anymore.
I think it'd be clearer to simply inline these overloads and spell out all the parameters at the call sites. We only make three of these objects, so four overloads of the constructor seems excessive :) Also if `Bucket` were not `static` then you wouldn't need to pass `buckets` in.
can we pass a reason to this method and mention it here? I always to scroll to find out whether this is a "true" index or just one that was created when importing/creating one.
I think that suggesters are just less far along than queries. It is fine though.
I think we've been registering default stuff in the module to keep it all in one spot.
I didn't check but unittests for this would be awesome!
I like these as they wrap guice ceremony.
I think we can do this without adding an interface? Users should not need to do this? A script cannot realistically be used for both search and executable. I know this is more a problem with the existing scripting apis, but I think here we can just implement executable, and search should throw UOE.
I think it is fine: we only build one search context per request per shard.
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
right I had missed that previous check, sounds good then
good catch! that means we are not properly testing this case either given that we didn't catch it.
I think it is not clear here exactly when IndexMissingException is expected to be thrown or not. I would rather move the if on top and have different asserts path based on that. FOr the expected exception one you can then do: ``` try { //do something fail("shouldn't get here"); } catch (IndexMissingException e) { //assert on exception } ```
I'll leave this one
seems redundant indeed
I notice this pattern in every implementation. Perhaps this should be a Map instead of Collection (keyed by the custom type name)? Then the map can be copied, and keys replaced, removed, or added easily, without needing to have logic for the other custom metadata that the plugin does not care about.
I think we can check also randomly on a shard that relocates _to_ the local node
`retentionPolicySupplier` is confusing. It's a prune query supplier.
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
Fine with me.
Can we return 0 when the value count is 0 to be consistent with the singe-value case, or throw a proper exception? I am concerned this code could raise a weird error message otherwise.
I liked the assertion you had there that if already have a result, this one has a higher seq no
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
can you try to exercise this method to make sure we open a new searcher and close / release everything
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
oh no I see, there is also a return. I think it's confusing that we can reach here because of either an assertion or a return statement
This was a bit hard for me to read due to the order in which comparators are checked. Could it be rewritten in a more idiomatic way, ie. ``` java if (o1.isPrimary() != o2.isPrimary()) { return o1.isPrimary() ? -1 : 1; } final int secondaryCmp = secondaryComparator.compare(o1, o2); if (secondaryCmp != 0) { return secondaryCmp; } final int indexCmp = o1.index().compareTo(o2.index())); if (indexCmp != 0) { return indexCmp; } final int idCmp = o1.getId() - o2.getId(); if (idCmp != 0) { return idCmp; } ``` It would be helpful at least for me to see more quickly in which order comparisons are performed.
``` if (Double.isNaN(v1)) { return Double.isNaN(v2) ? 0 : 1; } ```
just beware that Long.compare is Java 1.7 only, you might want to use Longs.compare from Guava instead when merging to 1.x
nit: than -> then (or just leave it out)
can we just use compare on Long? It gets confusing with < and == on `Long`
let's assume that if the method parameters are not marked as @Nullable that they are non-null. Otherwise we clutter the codebase everywhere with these checks.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
@clintongormley mentioned that NONE doesn't have many external usages (we only use it for index auto creation) so we might want to drop the special naming and use `0`. I will keep the object reuse in parsing.
and.. looking at the parsing logic this is indeed internal and we don't accept none from strings. Sorry for the noise.
we "special case" NONE here but not ONE, maybe it's simpler just to remove this method as well as the `validateValue` one and use `new ActiveShardCount(...)` in the two places it's currently used (and also ad ``` if (value < -2) { throw new IllegalArgumentException(...) } ``` to the constructor.
This needs to be another method (`parseInnerFilterToQueryBuilder`) which replaces `parseInnerFilter` and also takes care of switching the interal `isFilter` flag.
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
w00t thanks !!
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
alright that's what I thought too, sounds good
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
something is wrong in this sentence :)
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
s/y ou/you Also I think upfront is one word.
Maybe it doesn't have to come at all.... I think only `copyCurrentStructure` is part of the xcontent implementation. The rest is just "stuff that ES uses". I think.
I think an explanation why it's ok to throw an exception here might be helpful for future us.
it should rather save the XContentType detected from the bytes (XContentFactory.xContent(bytes)) above and re-use it.
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
I think you have to sort before shuffling, otherwise it will not be deterministic, cause the order in the list still depends on the order in the set, which depends on the jvm :)
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Oh, nevermind on the second point, I see `ShardLock` implements `Closable` already.
In our discussion about semaphores I understood a different model we keep a semaphore per index/shard directory (like the on the disk locks but in memory). That would be pruned when the folders are pruned. I see where you were heading. I'm fine with either way.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
This is not the right condition, a plugin bin directory is not required to exist.
We can remove the period here, this is a sentence fragment (as these usually are).
We can drop everything after and including the comma.
Let's remove the period from the end of these, they are typically not sentences.
This should be `pluginName`.
++ for ordinal and tests then
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
oh cool the read is in the ctor! nice!
I'd say yes... if you want to be able to parse script as a string, you want to be able to serialize it as as string. I believe serialization should be symmetric - you write what you read. For this reason, I believe the script type should be nullable. if you read a script like a string, the read state should be preserved for the writing.
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
I think this should be at debug level
I think the assertions are fine because ILM is in full control of the phase, action and step settings (they are INTERNAL settings so can't be touched by a user and will soon be moved to a custom index metadata object further locking down access to them. Therefore, I don't think its necessary to check that if one is set all three are set in production code but its useful to have the check in testing to make sure we don't do something silly so assertions feel right to me.
oh, woops. thought I counted right. sry
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
I think it'd be nice to remove this second ctor so we're explicit every time.
Ah! I get it now. LGTM
I think you can change this to a `Supplier<Analyzer>` now.
This could be `Strings.hasLength(tokenizerName)`
This is not good for backword compatibility. Instead it should do: ``` if (indexSettings.getIndexVersionCreated().before(Version.V_6_0_0)) { String tokenizerName = settings.get("tokenizer", "whitespace"); tokenizerFactory = ...; } else { tokenizerFactory = null; } ```
This shouldn't be here. You should use ESLoggerFactory instead.
Again, I wouldn't pull out the ternary.
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
I see it now - I think how you've got it now is the most right thing then.
I wonder if with this change you can remove `UpdateHelper.Operation` entirely and just use `DocWriteResult.Operation`. I'm not sure it'd be clear to use `CREATE` instead of `UPSERT` in all the places though.
this check is obsolet - we can just remove it
should be cached thread pool, the default constructor does the right thing here
also, I think the opened channel needs to be closed at one point
you need to generate two errors for this to test what you want :)
I think we should use `writeAtomic` everywhere just to reduce the complexity.
nit: space before brackets
typo: optain -> obtain
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
nit: indenting should be only 4 extra spaces
Since we're moving that, we could inline this using turnary.
Instead of doing the instanceof check here can we maybe wrap the body of the try / catch in another try catch and then rethrow? like this: ``` Java try { try { } catch (WriteFailure e) { // do all the things throw e.getCause(); // maybe check if e.getCause() can be null? } } catch (Throwable e) { // do all the other things } ```
good point, I think it's ok if it is configurable. and then it should do by default the same as the rest of the same search request does.
I find it odd that we modify the original source builder with the resolved indices names and replace what we originally had. Would it be possible to transport the resolved indices differently? I think we should serialize this new info separately and carefully handle bw compatibility around that.
I think it will be cleaner to have ShardInfo have a constructor that takes all parameters and set that on the finalResponse. This will make sure we will not forget anything in the future.
should be `logger.debug("...", e, shard.shardId())` :)
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
missing t at the end of the method name
Not a specific concern, but just more configuration options for the end user when it is not being that effective. The code is trivial and not of maintenance concern so I am fine with we being consistent in all cases.
I think it makes sense to let the realms handle this. I don't know what other headers we could expect - but that's kind of the point, we can just support a relatively generic method and let custom realms do whatever they need. My guess is that anything other than `WWW-Authenticate` would be due to weird proprietary protocols, but if they exist then we can support them.
> Did you consider a getAuthenticationFailureHeaders() method instead? +1. I feel like this is the way to go. Ultimately this might allow us to remove the authentication failure handler (way off low priority future idea)
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
Also we should wrap the `-` in `{@code -}`
These should all be wrapped in `<pre>` or `{@code ...}`
minor: I think it would be a bit more obvious to explicitly call `DateTimeZone.getDefault()` instead of `null`. Since that is what Joda does with the `null` value. http://joda-time.sourceforge.net/apidocs/src-html/org/joda/time/DateTimeZone.html#line.301
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I would also be fine with removing all the camelCase options for all formats in this PR to make it consistent.
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
I don't think it matters. We should not force making huge changes to the entire codebase in order to not add things which will just be deprecated and/or confusing to the user.
I also dont' think we should swallow the exceptions here? Someone asked for a gce address and we failed to get it...
@dadoonet I think the log message can still say "Failed to fetch metadata from google" ? more than just client creation can go wrong here..
@rmuir are we OK with this? Is there a better way (not sure at all, just double checking).
I wonder if it should not also decrement the CountDownLatch if an exception is caught in the SimpleChannelUpstreamHandler ? Something like ``` new SimpleChannelUpstreamHandler() { @Override public void messageReceived(..) { ... latch.countDown(); } @Override public void exceptionCaught(...) { latch.countDown(); } ``` Just to be sure that the client does not hang indefintily.
also, I think the opened channel needs to be closed at one point
also, can we remove the boolean return value from doStart and remove the timeout handling from the public void onTimeout(TimeValue timeout) method of the callback given to the observer in line 245? just call doStart.
this doesn't mean the index is not active, but rather that it doesn't exist or is closed. I don't think we need to retry in that case. [Old cold would throw `IndexNotFoundException` in this case](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java#L203).
Got confused. It actually likely the previous routing node has an older cluster state in which we should override the existing value.. nevermind
can we have an explicit boolean for this? feels hacky...
If we're doing a reroute - I don't think we should retry on retryPrimaryException. That one only holds for the primary action.
I hope I'm not splitting hairs, but there's also a typo in the field (deault is missing and 'f'). (This PR resulted from a question I asked here; thanks for all the awesome work you invest there!)
nit: space before RESPONSES
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
I see, so parser always sets both "order" and "mode", regardless of whether they are set by the user. But what if we only go through the java api, use a plain builder and set "reverse = false". Translated to json this should give us "mode = MIN", but only if not explicitely set by the user otherwise, no? Sorry, haven't got a good solution myself so far either.
you should pass fieldNames as an argument
well, I'm not sure we can assume that all addresses are by default "public". I tend towards saying implementers need to make this call.
I think it would be more flexible if the keys were objects? (you could have composite keys, etc.)
maybe simpler to just write ``` final boolean peersRemoved = peersByAddress.values().removeIf(Peer::handleWakeUp); ``` and then further below just ``` return peersRemoved; ```
It was removed from ParseField in #17933. It also shouldn't be added here.
I'm pretty sure camelCase shouldn't be supported any more.
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
Please rework this word wrap too.
nit: missing a space after the first comma
Can you use `== false` here...the `!` is almost hidden in all the other text around it...
te -> the
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
I find these two empty `continueProcessing` methods confusing, if we manage to merge the two filter chains impl as said above, we would get rid of them I think
this class could be made `final`
Ditto here with `getUUID()`
the suppress warnings could be right on the line of code doing the cast instead of the whole method
We typically use `Locale.ROOT` rather than `ENGLISH` for case conversion.
can you just leave the constant in this class? There isn't a need to put it in realm imo
Use `Collections.singletonMap` here and `Collections.singletonList`
I guess it could be renamed to isFalse() / isTrue() now
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
sounds great thanks
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
but if you are in strict mode you get an exception so you don't get back false :)
typo (of <-> if)
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
looks more tedious than just filling an array, but I didnt do an awful lot of java 8 stuff yet :-)
The parentheses around `t` are unnecessary.
Ok, then for the profile settings you only read the publish_port and publish_host instead of the other settings. I see the difference now. Before it seemd like you wanted to read exactly the same settings, then I wondered why that part couldn't be shared.
Strings.EMPTY_ARRAY could be used too (if you want)
this will not work, right? cause the default is `9300-9400`, which is good, since we want to try another port on the second instance we start on the same machine.
This change breaks backward compatibility between 2.1 & 2.2 (pull request is labelled v2.2.0)
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
I think this was more readable the old way.
I *think* it should be enough to just call the API without any assertion. We already should already throw an exception if the response isn't a 200.
oh, woops. thought I counted right. sry
can we add an assertion going out that going out of the primary shard allocator we don't have any primary shards in the unassigned list, unless we expect them to be there? (primaryAllocatedPostApi is false or restoreSource != null)
OK. > On 20 Jul 2015, at 14:01, Shay Banon notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java: > > > ## > > - AsyncShardFetch<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> fetch = asyncFetchStarted.get(shard.shardId()); > > - if (fetch == null) { > > - fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction); > > - asyncFetchStarted.put(shard.shardId(), fetch); > > - } > > - AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId())); > > - if (shardState.hasData() == false) { > > - logger.trace("{}: ignoring allocation, still fetching shard started state", shard); > > - unassignedIterator.remove(); > > - routingNodes.ignoredUnassigned().add(shard); > > - continue; > > - } > > - shardState.processAllocation(allocation); > > - changed |= primaryShardAllocator.allocateUnassigned(allocation); > > - changed |= replicaShardAllocator.allocateUnassigned(allocation); > > I will do the assert when I remove the primaryAllocated flag in a different change > > â > Reply to this email directly or view it on GitHub.
May be `if (!FileSystemUtils.isAccessibleDirectory(dicDir, logger))`
Minor typo of `local` instead of `locale` in the exception message.
typo: dictionnary -> dictionary
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
I have yet to get to that alternative, I am lagging behind :)
lots of things here will need to be moved to the data node too once we refactor this query I think
we shouldn't need this here in parse phase
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
good catch! that means we are not properly testing this case either given that we didn't catch it.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
Consider checking for `null` somewhere for `primarySize` before the division below.
You don't need these `text-align`s. The one in the header is enough.
Change to Throwable.
Why not use the dedicated get aliases api? IndicesAdminClient#getAliases()
try to use `AbstractRestResponseActionListener` instead of `ActionListener` the `onFailure` method is already implemented there
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
catched -> caught
Another simplification - if we push the code at https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterIndexHealth.java#L81 into ClusterIndexShardHealth's constructor, we can use it here and just make it a simple lookup in the enum set..
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
grr nevermind I didn't see the last line pfff...
or N times
I think you can use `RestClient.SyncResponseListener` here instead
This seems to test the case where the same path has a number of distinct mount points. Can this happen? I can't think how.
The existing code doesn't filter out paths whose `mount` property is `null`, so I don't think we should start doing so as per this test case.
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
good catch! that means we are not properly testing this case either given that we didn't catch it.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
I guess we're doing `instanceof` not `getClass()`, but still, it sounds like maybe we should in some cases.
While you are cleaning up maybe we should put these into their own class that `XContentBuilder` extends? That way all of the wrapper methods are all in one spot.
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
+1 to have `fromXContent` and `parse` be static
Maybe as a followup (at sometime, not that important) the callers of this could be made to use the one line impl here. Just seems like a silly method to maintain.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
I think the nodes can stay as an array. The constructor just converts to an array again.
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
missing { } :)
I think the logging in this class is unneeded. if you debug it you can add it back
Technically not an "and".
This method also does not need to exist, as you can use `this(indices, IndicesOptions.strictExpandOpen())`, and fix the validation in the other constructor.
nit: remove extra new line
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
This is a question, not a change request: What is our philosophy regarding having setters vs. immutable request objects going forward for the HLRC? I've been under the impression we preferred immutable objects, but it doesn't seem to be consistent.
Two test requests: What happens when you have something like `Integer a = Integer.valueOf(0); int b = a ?: 1;` `Integer a = Integer.valueOf(0); int b = a ?: Integer.valueOf(1);` I believe these are expected to be ClassCastExceptions where Integer cannot be cast to int, but I'd like to be sure.
@nik9000 Robert and I had a long conversation about boxing early during development. We decided to eliminate it as much as possible because of serious complications involving promotion and casting (which as you know is already very complicated). There's only a couple of places auto-boxing happens -- arguments to methods because it would be hard to force a user to cast something to an object to add to a list and with anything related to def type. Otherwise, there is no auto-boxing in painless. Perhaps, this should be the same for consistency? Sorry, I sort of missed this yesterday thinking about the cases, but def should work anyway already, otherwise primitives don't make sense here since we don't allow Integer to become an int anywhere else. With the def type we deemed auto-boxing to not be necessary anymore, and ideally something Java would've hidden from the user to begin with. It also happens that users can call boxed methods on unboxed types to further eliminate the need to ever have a boxed type.
@nik9000 What do you think about this proposal for now? What if for the null safe operator (?.), if the guarded type is a primitive we disallow it, and then for the elvis operator (?:) if the lhs is a primitive we disallow that too. I honestly don't think anyone will notice because currently there is no way to get a primitive out of a field from a non-static type (nothing exists in the whitelist afaik), and I would argue in the case where you want a primitive out of a call, it doesn't make sense to have the receiver be a boxed type. You would still have to check to see if the receiver was null afterwards anyway. For most cases the type will be def and the auto-boxing will just happen anyway. Both of these operators can be very useful for def types without needing to have them do magic for primitives. I would hate to not have them because of boxing issues when it's improbable that users would run into them. I would think the average use case would be something along the lines of list?.list?.map?.get(value)) in which case this operator is awesome.
same note as in the json processor PR.
I'd keep away from using the default one for all the unit tests just in case of funny pauses and stuff. Maybe one, very small, very paranoid check that use nanoTime is col though.
I meant `client().admin().indices().preparePutTemplate()` or `client().admin().indices().putTemplate()`.
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
`assertNoFailures` is more common in newer tests and much shorter.
one too many new line? :)
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
we should check here that acked == true but shardAcked == false
This also might need an `ensureGreen`
Can you rewrite these to use `assertThat(..., equalTo(...))`. I prefer this form because it's clearer which is the expectation and which is the value under test whereas with `assertEquals` it often gets confused.
Let's use `assertThat(..., equalTo(...))`.
hm. so this hangs now every now and then for a minute. I think it is when the coordinating node is node_1. Then the cluster state observer waits for the next cluster state which does not come and the index request is only executed when the observer times out. We can send the request via node_2 but I think we actually need a way to handle this better.
would be great if this logic could be unit tested.
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Yeah, it's pretty new. :-)
Fine with me.
can we also step out if `matchedDocId < DocIdSetIterator.NO_MORE_DOC`
use `Objects.equals` for all once changed to potentially null references.
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
make `Boolean` and only serialize when not null
nit: "an started" -> "a started"
Not necessary with `ConstructingObjectParser`
ok thanks for the explanation.
you can use MustacheScriptEngineService.NAME
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
maybe also rename the setting? (in addition to the constant)
right thanks for the explaining, I should have known, having worked on the search refactoring :)
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
Can we move these up at the top of the class with the other object variable declarations? I think it is more readable than having them 300 lines down into the class.
Can we make this 1 hour? If it times out it's nice to get thread dump
same as above for non exception case
I am good
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
`FutureUtils.cancel` has a check for a null future, no need to add this check
maybe better to say "failed to find primary despite of request being routing here. local cluster state version [{}]] is older than sending node (version [{}]), scheduling a retry... "
Got confused. It actually likely the previous routing node has an older cluster state in which we should override the existing value.. nevermind
something I noticed while reviewing the bwc code - we can pass the indexMetadata (or primary term) as an argument. We look it up on in the calling method. Save on double lookups.
Good one @bleskes.
Why is this `volatile`? It doesn't look necessary to me.
is there always at least one element in this list? (I haven't checked whether we assert it somewhere else)
I am fine with doing it in a follow-up PR if that works better for you
Just for my own education, and it is certainly super minor: when reading this part I was wondering if it would make sense to get the maxClauseCount limit once at the beginning of this method since its unlikely to change to avoid method calls in each iteration). Maybe Java does some clever optimizations to avoid this though and the effect most likely negligible.
this code and the code in `SearchPhaseController#sortDocs` is almost identical. I think the only difference is the assignment of the shard ID. Maybe we can factor this out into a static method and use it in both places. It would be good to redcue the duplication on such a level and it would increase the test coverage. I would be in favor of that.
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
This is similar to the internal implementation, nice
Misspelled in the \@param tag also
excude_interim - missing 'l' -> exclude_interim
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
would be nice to allow to configure it to a percentage of the heap size
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
those are hard to debug I can tell u :dancers:
confuses the shit out of me everytime :)
well we use a dummy lock so I guess it's fine
try finally here please since if close fails we don't release lock etc which can be missleading
and -> an
I think this should be final
we have `TestThreadPool` that makes it simpler
This has a line-length violation. I pushed 575fa4e00a8be31a54859adf06f39c7280691040.
I think if you don't have the Java build stuff setup you should make javana do the merge ð On Jul 14, 2016 8:21 PM, "Honza KrÃ¡l" notifications@github.com wrote: > In > test/framework/src/main/java/org/elasticsearch/test/rest/support/Features.java > https://github.com/elastic/elasticsearch/pull/19436#discussion_r70905675 > : > > > @@ -34,7 +34,7 @@ > > */ > > public final class Features { > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key"); > > - private static final List<String> SUPPORTED = Arrays.asList("stash_in_path", "groovy_scripting", "headers", "embedded_stash_key", "yaml"); > > Thank you @jasontedor https://github.com/jasontedor, I don't have my > env setup for java so I missed this. > > â > You are receiving this because you are subscribed to this thread. > Reply to this email directly, view it on GitHub > https://github.com/elastic/elasticsearch/pull/19436/files/d53406b8d3919c5367c1bb574fd365fb2af7110e#r70905675, > or mute the thread > https://github.com/notifications/unsubscribe-auth/AANLotcG0AVdYcNe3YtwU1U545rSEKT2ks5qVtJ2gaJpZM4JMfjQ > .
well well if you were an external contributor I would have run the whole suite that takes 45 minutes. But in your case, trust won. I should have totally counted the characters of that line as part of the review. P.S. we java folks are the first ones pushing without running tests at times (WAT?), so no biggie. I will check closer next time.
can this be: ``` Java public static final Setting<URL> URL = new Setting<>("url", "http:", URL::new, false, Setting.Scope.CLUSTER); ... URL url = ...; if (URL.exits(settings) == false && REPOSITORIES_URL.exists(settings) == false) { throw new RepositoryException(name.name(), "missing url"); } ```
this can be: ``` Java public static final Setting<List<URIPattern>> ALLOWED_URLS_SETTING = Setting.listSetting("repositories.url.allowed_urls",Collections.emptyList(), URIPattern::new, false, Setting.Scope.CLUSTER); ```
Same feedback as the last `toString` - I think you can remove `created` and might want to look at `Operation`'s `toString`.
Same deal as the last `toString`.
I'd move this to line above, but I like the thought behind the change.
I think it is fine: we only build one search context per request per shard.
would you mind adding the same for allocation ids? :+1:
I think we should have a dedicated method for this in IndicesService. ``` public FieldStats<?> getFieldStats(Engine.Searcher searcher, String field) { // do the caching in here and also lookup the MappedFieldType again! } ``` this way we don't allow everybody to cache whatever on our request cache!
I would add an `assert this.context != null` here just to make sure
I think filter and query can never be null here? not sure whether we should validate this here.
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
you can replace these two lines with a call to `ThreadPool.terminate`
Right - RollupIT is the right place
Writeable#readFrom returns a new instance of the object, it allows to have final fields, but it requires to have a PROTO instance of the object to call readFrom against. I wish there was an interface to declare writeTo only though but we don't have it at the moment.
So, this could be simplified to `assertFalse` Or could be something like the following (which admittedly, is probably less simple) ``` import static org.hamcrest.CoreMatchers.everyItem; import static org.hamcrest.Matchers.greaterThanOrEqualTo; import static org.hamcrest.beans.HasPropertyWithValue.hasProperty; ... assertThat(response.records(), everyItem(hasProperty("recordScore", greaterThanOrEqualTo(50)))); ``` Man, that is frustrating that hamcrest does not support just passing a lambda as a type of matcher :(
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
now I see what you meant yesterday saying that we have to parse meta here
but if you are in strict mode you get an exception so you don't get back false :)
mention here too that this is what we do also in the corresponding builder
I understand. But this requires to grab back the type and delimiter where initializing the parsed aggregation directly with the name "type#name" would allow to parse back the result too. Also, in a client side point of view, the name is "type#name". But I'm nitpicking, we can change this later if we want.
Do we really need to also duplicate the typed_keys logic here? Can't we just print out the name of the parsed aggregation (it can be initialized with type#name)
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
Nit: spacing between the `)` and `{`: `){` -> `) {`
good catch on delta > 0
`limitedTo(long bytes)`? Clone is kinda non-specific.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
I think we can simplify here and print everything out, default values included, that's what we went for in all of the other queries too.
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
Yes, sorry for the confusion, I remember the discussion now. Maybe just rename then, although `elementName` is also fine.
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
+1 on just `field`
No, you are right, I didn't realize the need for api users before going through the whole changes.
you are perfectly right Christoph, let's merge the two and keep the existing class.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
you don't have to assert on anything if an exception is expected
you could use `scriptRequest.setJsonEntity`
Can you open a lucene issue for this? Meanwhile, I think it's a good idea to copy the implementation of checkResetException() into the test code here, as it checks the contract pretty strictly.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
Hurray no more weird `while (true)` loop
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
Typo, "Trasnlog" -> "Translog"
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
I think we already do since we don't lowercase the suffix. That's fine with me. I think it's consistent with what we usually do with conf files. Let's try and add some docs for this to make it clear.
I see what you mean, that we somehow break bw comp but I would leave only the lowercase variants to make this consistent with other places where we load files e.g. we would never load `elasticsearch.YML` . I think this change is acceptable and in the scope of the PR since we are in fact limiting the files that are getting loaded as logging configuration.
we need to support whatever extensions Settings supports and that includes json & java properties formats. I wouldn't worry about restricting it to these three (yml, json, properties) with regards to bwc.
with the current code a `logging.whatever.yaml` file would be loaded. I wonder if this is our intention or a side-effect of the current behaviour. Honestly I would be in favour of simplifying this further and even have something like `if (file.getFileName().toString().equals("logging.yaml") || file.getFileName().toString().equals("logging.yml") )` unless we want to extend this to json and properties files, which I think would be off-topic in this PR.
The shapeFieldMapper seems unused here.
same problem as above I think, only that unmatched closing brackets will create holes here.
Ok, I see. Nevermind, since its a private method I leave it up to you to change or not, I was confused a bit but the method is short enough to understand what its doing.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: these could probably even be package private
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
make `Boolean` and only serialize when not null
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
Probably it would be worth implementing AbstractStreamableTestCase#getMutateFunction in this case, so that the equals/hashCode tests are more complete. I think without it a part of them is skipped.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
+1 on removing it
Search and executable, and execute look like they should delegate stuff to a single method. Orsomething.
Fine by me.
I think s/lang/defaultLang/
having another look, index time lookup is needed when creating the search lookup, and I actually made another suggestion around possibly not needing IndexTimeScript entirely, so I don't think we will be able to do without adding indexTimeLooup.
can we just use `getUuid()` no need to have two
I'd prefer using `IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> prez.setRelevalntRatingThreshold(-1))` here like we do in many other tests and get rid of the @Rule
This seems wrong to me: this class is abstract and contains tests that should work with any type of repository. We should not force the repository type to `fs` but rely on the `createTestRepository(repoName)` method instead like it is done in the other test.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
ok fine! :)
make this an atomicreference to throwable so we can see what it was in the failure message? (use assertNull)
make this Error? we alway want to use this.
Are these debug level events? They all seem like bugs.
++ on error
same here - would be good to have a brief summary of the shard that failed and why.
use simpler constructor.
I expect to be tested as it's static, but I don't see test? I think its good to have one. Also, it seems it can be package private.
wondering if we should add the first 10 shard ids to the explanation
I think we can make this method even friendlier with the following signature: `logClusterHealthStateChange(ClusterStateHealth previousStateHealth, Result result, String reason)` .
That assumes `list` can't contain null..if that is not the case ignore
Er, well, it doesn't work like that. Ignore.
similar concern about in-place reduction
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
ok let's avoid the concurrent put/computeIfAbsent issue for now, we can try to improve in the future if we observe slow concurrent access
I think it would be worth renaming this method, otherwise it will cause confusion in the future about whether it's expected to be a bug or not (since the only reference to the exact bug number is in the line you've deleted). Alternatively, the format this method tests could be moved back into the method above (which is where it was originally).
I think it might be nice to move this in `TcpHeader`
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
It looks like you have proper ram usage stuff. Maybe it'd be simpler to refuse to expand the tree if it'd put the `bytesAllocated` above a certain size.
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
Right - RollupIT is the right place
Now that I'm seeing these, I wonder if the default names should be `attr` and `value`. We could add aliases if we need longer. Since it's such a small API it's probably fine with the short versions.
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
Nit: I think you can leave out ESTestCase here.
Nit: I think you can leave out ESTestCase here.
Like above, I'd simply use randomFrom(SortMode.values()).
Nit: I think you can leave out ESTestCase here.
Nit: I think you can leave out ESTestCase here.
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Should you use the static `templateName` import here and throughout? It looks like you might be mix 'n matching.
I think this is expected to be a sorted list on the `job_id`.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Lets leave off the third sentence
we need to add that we return false if no folder was found for this shard.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
Is the version needed? I don't see it being read here.
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
Nit: too many newlines here
use `terminate(threadPool);` (this method is in ESTestCase)
nit: Everything okay, but I found this (and the following same constructs) a little hard to read. Can I suggest writing the boolean flag first without conditions (e.g. `out.writeBoolean(fuzzyOptions != null)` and then have the if-block only? But either was is fine.
when it is possible, I would do it...not a huge deal but still ;)
and the last one ;)
Sorry, didn't see that, you're right.
We would need a call to super() somewhere here. Or, like we did with the query builders, have the superclass declare two abstract doEquals/doHashCode methods that it then calls and the subclasses need to implement.
nit: use assertThat(...) with isNull() as matcher instead? I think in general that is the preferred way of writing test assertions.
same as above, could be an array
grr nevermind I didn't see the last line pfff...
or N times
As a follow up we need to take into account that indices can be removed from a data stream (except the last/most current index). So we should either check here that the backing index really exists or in the delete index api also modify a data stream if the index is part of a data stream
hmm do we need to skip the size if we are in production? I mean that assert will not trip if we run without -ea
I'm not following, do you want it to be a regular exception instead of an assert? We still need to do the `readVInt` regardless of `-ea` or without, it's just the 0 size comparison that is an assert for tests
This should be fatal.
This should be fatal.
This should be fatal.
formatting should be fixed like the rest in these three lines
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
Hmm good point, I had forgotten that this class could actually be returned to the user (masked behind an API interface).
That assumes `list` can't contain null..if that is not the case ignore
you should pass fieldNames as an argument
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
For static varialbles, `final` should indeed be used whenever possible.
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
1. There is a minor typo/grammatical mishap here - text should read "[cluster.name] must not _contain_ ':' character" 2. Id consider putting this exception text into a final static variable somewhere it would make sense to put it. This text is currently used in two places in the code - once here, and once in a unit test - and the way things are now, if you want to change the contents of this text, you need to change two strings in two different places in the code. If you had this text in a final String variable, and you referenced that variable here and in the test, you would only ever need to change the string in one place.
There should be an extra space between the `if` and the `(`, and the `))` and the `{`.
same here just use synchronized methods
I think it's fine this way. This PR is already good incremental progress.
This is logic that I think should go into ReplicatedOperation.
this logic belongs in transportWriteAction
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
> Though I do prefer that it fails fast instead of lazily later. ++
No, I still think that it should not be a method on the `Strings` class.
This logging statement has a `[{}]` but no argument to fill it
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
does this need to be public and also does this class need to be subclassable
`engine failure` -> shard failure
nit: can you assign `event.state()` to a local var
I think it would be cleaner to move the assert into the catch, and add a `fail("expected script exception")` after the call to `run()`.
This is missing a `+` between `newUsed` and `"/"`, so it's not compiling currently
It'd be nice to be sure it contained that `not_found` wasn't found.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
nice! I like this. super helpful for keeping track
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
s/payload is/payloads are
I think you can just blast the entire method in this case.
formatting, 1 line instead of 2
Throwing a RetryOnPrimaryException feels ugly. I see why you did it and I can't come up with something better. On top of that, this made me realize that RetryOnPrimaryException has serious problems. I'll reach out to discuss. to be clear - this shouldn't stop this PR as it is an existing situation.
But yeah, keep it now.
Should we add a `default:` clause just in case here? It looks like the original code had one
this must be `2000051` rather than `2000003`
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Yeah, I think the problem with the test here is that we don't make sure that nothing is left in the stream after we read it. That's why we didn't catch it here.
I think it would be easier to reason about it it was expressed as something like ``` if (clientVersion.before(Version.V_5_3_0)) { ... } else if (clientVersion.before(Version.V_5_3_3)) { ... } else { ... } ``` There is also no `else` after this statement, which means we write ord twice... And if tests don't catch this, we might need to figure out how to write a better test that would.
+1 too - I never noticed these tests...
@talevy Can you extract this IOException change from the PR and commit this to the branch? I can then benefit from it in the geoip PR too.
this should just throw IOEXception no need for a shadowing ConfigException
the `grok` field can be final too
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
these unit tests are great! We are going to need more of them :)
A question out of curiosity: the analyzer we get here doesn't have to be closed (via closeAnalyzer) because its not a new instance? I don't know enough about the lifecycle of these objects yet I'm afraid.
This can maybe go inside the following `else` branch.
same here, just `this.charFilters.add(new NameOrDefinition(charFilter));`
Can this be split into the two cases `request.normalizer() != null` and `(request.tokenFilters() != null && request.tokenFilters().size() > 0) || (request.charFilters() != null && request.charFilters().size() > 0)` in two separate `else if` blocks instead of separating these cases later? I'm not entirely sure if this works, but I think it would make this part easier to read.
Thanks, I think its better than nothing
if just read metadata it will also be easier to implement a fetch all interfeces, sort interface name, fetch interface ip sequence
Maybe merge all the groovy securing code into one place? It feels funky to have the default receiver whitelist here but method blacklist above.
I think we can check the beforePart == null out of the if(!..equals) and it will make it cleaner.
can you add a //norelease here too? context should really go away after all queries are refactored
snpashot -> snapshot
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
I think this adds a `timeZone.previousTransition()` computation even for fixed time zone cases. I think to save computation we could return even earlier in unproblematic cases when `timeZone.isFixed()` like before.
What if this.docCount was already -1? then it should stay -1 right? (in the else case here)
maybe it is a matter of style, but i think its easier to handle the exceptional case like a guard up front: check stats.docCount == -1 and set to -1, otherwise sum. this is not really important to me.
Probably should also be getAssignedNodeId.
I like this style. I think I'm going to steal it.
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
same - please name it something like `explainOrThrowRejectedCommand`
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
forcing execution should be a parameter for now imo - I know we want/maybe/potentially change how we deal with replicas and queues, but for now I rather not change semantics and have primary ops non-forced and replicas ops forced.
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
I wonder if we want to add an `@After` rule that checks that all semaphore permits are back.
I think this can move to before the threads start - will be nastier
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
Ah ok, I missing that method below, sorry.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
this class is also missing a hashCode impl.
This should be a `ConstructingObjectParser` so that the private empty ctr can be removed.
ok let's drop it in master and keep it here for BWC
we are talking about toString method?! No way we add a distinction in there... if we pass this to the user then fix it in the rest layer
Honestly I prefer inline, but all the user-facing stuff has been called dynamic, so I'd probably stick with that.
I think s/lang/defaultLang/
Fine by me.
I think we can remove this exception now.
good catch with the sync here!
Maybe use a simple for loop here like: ``` Java if (!contextMapping.isEmpty()) { builder.startArray(Fields.CONTEXT); for (ContextMapping c : contextMapping) { builder.value(c); } builder.endArray(); } ```
lower cased now...
guava has a `Iterables.elementsEqual()` - which works slightly different, maybe your implementation is a bit faster
no i do not. but this IDE cannot compromise the actual build, which is 'gradle check'. changing tests.seed in this way can compromise the build, because then the values for other things looking for this (such as lucene) depends on class initialization order.
don't change tests.seed, i dont care what intellij does, this is wrong to do.
I think we should use `writeAtomic` everywhere just to reduce the complexity.
I think s/lang/defaultLang/
Maybe this one too, I'm not sure.
are those number randomizable ie `randomIntBetween(1,100)`
thanks for doing that Colin ;)
same question as above
Could we either do the percentiles of percentiles here or have another test that calculates the max bucket of a terms agg which is calculating percentiles over a histogram? This way it would check that the agg can both reference an inner sibling pipeline agg and be referenced by an out sibling pipeline agg.
I would just `throw e;` here
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
Would you kindly add some line feeds here to make it look like json instead of a wall of text? It'd be so much easier to read.
good catch! that means we are not properly testing this case either given that we didn't catch it.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
I think we've started to use `setShard` style here? I'm not totally sure.
Do we need this? the settings are already immutable
I like this style. I think I'm going to steal it.
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
this new exception is going to trigger errors too if we try to serialize it to an older node
I think s/lang/defaultLang/
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
We tend to prefer `false ==` over `!` because it is harder to miss the `!`.
same here - just pass a new instance
can we add that to ClusterStateCreationUtils? It might be useful for others as well
this could be a for each loop instead
ok...but client depends on the transport service anyway no? I think I don't get it
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
I think this needs to be `true` as well.
We don't want to actually check what version of `openssl` they have installed. They might be generating certificates to be used on a different machine that has a different version of openssl. It's OK to always print a warning about the password exceeding the old openssl limit.
This one should be `true`. We want to check the password length any time we're generating a _new_ private key.
Having through about this a bit more, I think the _prompt_ is going to be annoying rather than helpful. I think we'd be better off just printing out a warning message, and continuing on. Sorry for messing things around like this, but sometimes things become clearer during the review cycle.
The `withPassword` method is called every time we need a password, even if it's being used to _read_ a certificate file. In that case we don't want to print this warning, because that would cause additional output (and an additional prompt) for simple things like reading a CA file that has a long password. We need to only perform this check/warning if the password is being applied to a new file. I'm OK if we want get rid of the `promptYesNo` and just print out a warning, but we only want to do either of them when we know the password is being used to _write_ a file.
But that is not equivalent? Arrays.toString is a static method, and different than result.buildConflicts().toString()
maybe put this in an `if else` clause? For me this makes it clearer what is pre 2.0 and what is 2.0 behaviour.
why do we need to merge this again since we are still holding on to the lock? I don't necessarily understand why this is helping us as well but that might just be because I don't know this code very well.
Notice the difference in the first parameter to MergeResult. This is the "simulate" argument. The first time we don't change anything in the merge, only check for any problems. Ideally we could move this simulation to something like we have here with check compatibility. I had a branch for a this long ago, but it was a complex change.
I think we should collapse the two above methods, they are always called in sequence.
> At the same time though, acquiring the write lock would be good, because even though there is a warning that this should not be run when ES is running, trying the lock seems like it would be a good idea Definitely, +1
> If there are multiple commits, what does IndexWriter.getCommitData() return? I am guessing it reads the "latest" commit's data? Yes, the latest.
It won't always be the case that there will be one index commit, sequence numbers will change this assumption.
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
Again, need to figure out what to do if ATOMIC_MOVE is not supported
there is no exception possibility here? I think this is overparanoia
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
I wonder if we want a trace message here...
can we please not use `forEach` I think we should stick to for loops it just makes the code more readable and consistent
Typo, finalzlie -> finalize
Not a big deal, I'm fine without it
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
Lets leave off the third sentence
how about changing this to `if (upgradesInProgress.decrementAndGet() == 1) {` so we can remove the return statement. I find this easier to read as the action only happens when the in progress value is 1.
I think we should do this as one of the first steps in the if block. The reasoning is that if an exception occurs before this, we will never get the chance to continue operating as nothing will trigger this method again
to me these should be sets and required to be non-null
A problem for another PR, I assume.
can you use try with resource here since we are on java 7 now ie: ``` Java try (CBORParser parser = CborXContent.cborFactory.createParser(content)) { parser.nextToken(); generator.copyCurrentStructure(parser); } ```
I guess it would be good to assert that the returned delegate is not another instance of `JsonGeneratorDelegate`
oh i see, the JsonStreamContext now doesn't implement `writeValue()`.
Incides -> Indices ? ;)
typo in the method name here too
please replace `assert false` with `fail()` if we run without assertions this test fails :)
I think we can omit catching this and failing when caught, that's default behaviour, what matters if the `finally` I guess
same as above, this seems the same method as before
Sorry, what I meant by the previous request was to do an assertion on the whole error string (e.g. wie assertEquals), unless there are any reasons preventing this.
nit: `an` -> `a`
Can we keep the line numbers in the test assertions? I think they are important to maintain.
Is this is necessary given we loop over OpType.values()? If other values are added in the future we should fail because expectedBulkItemResponse/originalBytes is not set anyway.
There is a problem with this test setup that I just found: the xContentType that is used for parsing here is not necessarily the same as the one that is used int randomUpdateResponse(). So the expected values might be off, e.g. if in randomUpdateResponse() SMILE is used and here xContentType is Yaml.
I don't think you need @Before here, the parent method already has it.
there are more similar problems below
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
maxDepth can be final
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
I prefer my way but have asked @jasontedor to chime in.
// must use exception that is not **ignored by** replication logic. (also 2 more occurrences of this in IndexShard)
maybe put this check before the primaryTerm check
same here re enumSet.toString
we throw the exception and thus take care of the interrupt. We don't need to set it...
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
Nit: it isn't a jsonBuilder - it is whatever kind of xcontent was passed in. Nit: maybe only set prettyPrint if the original had it set? I don't know if you can tell though. Neither are a big deal.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
it should rather save the XContentType detected from the bytes (XContentFactory.xContent(bytes)) above and re-use it.
I will take care of this.
same question as above
thanks for doing that Colin ;)
how much work would be to "decode" the values and expand the test? I am wondering if it's worth doing or not.
let's not make this hold this PR, but let's keep track of this potential issue and address the need for generifying in a separate issue
should we use a native trove collection here from String to long
why is this public? it's only used internally, right
But the Iterators it returns aren't.
Nit: drop the `,` here.
I think we want to blow up, right? this means that something that was explicitly configured doesn't work... null doesn't seem like the right return value (i.e., it means: please continue and try something else)
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
Since `value` internally is a String now, we can change read/write here as well.
sorry, my bad.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
good catch! that means we are not properly testing this case either given that we didn't catch it.
By keeping track of contexts in 2 different data-structures, I think you are potentially introducing race conditions, eg. if a clear scroll action is issued concurrently with an automatic release of the context due to the fact there are no more hits to process.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
can this see `unregister task for id: [{}]`
nit: can we rename this to `getTasks`
can we make this ret val unmodifiable please
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
thsi is actually concerning... what if the user uses yaml reponse format or cbor then we render still in JSON? I think we need to find a better way to serialise this. I really don't know from the top of my head how to solve this to be honest...
Nit: extra line
I understand this is the oversight you've mentioned
after is now minimum_age
Same here about multi-line toString methods
Here again I think we should use `builder.timeField` to handle this
The factory is what holds onto the params, so that they can be passed to the constructor. Think of the factory as the signature for the constructor. It's not boilerplate; it is actually needed based on current uses of scripts throughout the system. Also note that the factory signature is what allows the script instance to have arbitrary objects passed in. If `ScriptService.compile` were to return an instance directly, instead of a factory, we would need some way to pass in this information in a generic way, which would probably mean duck typing through a String->Object map and then require casts. With the factory, we get static type checking of the arguments a script needs to be constructed.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
I am not sure if we should catch an exception here IMO the exception should bubble up
should we catch exceptions here to make sure we cancel everything we need
I didn't look at other users of that method, but +1 ! this boolean annoyed me for a while :)
we lose some concurrency control here where we only cancel the recovery if it's not done. I'm wondering if we should use `cancelRecoveriesForShard` and if it returns true, we then remove the shard. Also - In all cases where the the source of recovery changes due to a primary failure, the master cancels the allocation and changes the allocation id, meaning we don't get here. I wonder if we should also catch the case where a primary relocates on the master and not have to worry about all of this here. I think it will be simpler all in all
> can be cancelled just because primary relocation completed before shard was activated by the master node yes. I'm aware of that - I'm thinking that with seq# fast recovery it wouldn't matter much as a ready shard will quickly re-recover. However, seeing how the new code looks like with the cancelRecoveriesForShard + shardRouting.isPeerRecovery changes, I think it became much simpler. I'm good. We can see how things develop later on and potentially move some logic to the master (which will simplify this class) or not.
+1 I like plugin examples!
`client().prepareIndex(...` is more normal now.
This shouldn't be needed anymore. By default we wait for the index to be created now.
you can simplify this a bit here: ``` Java NodeStats unluckyNode = randomFrom(Iterables.toArray(nodestats.getNodes())); ```
I think you should implement this in an awaitBusy block ie repeat until you see eveictions but never wait longer than 10 sec by default.
Not a specific concern, but just more configuration options for the end user when it is not being that effective. The code is trivial and not of maintenance concern so I am fine with we being consistent in all cases.
++ to talking this through but to put it out there, what I am thinking is that we re-build the user after the lookup. For this case we have PkiUser and LookedUpUser. The final user will be the combination of the PkiUser's metadata, the LookedUpUser's metadata, and the LookedUpUser's roles. The looked up user's metadata would trump the PkiUser's metadata in case of a conflict. This does get trickier when you do this in an AD/LDAP realm since some of the metadata comes from the group resolution. In that case, I would only include the metadata that does not involve group resolution from the authenticating realm.
Nit: Needs a blank line.
Yes! you are right ð
I believe `ScrollHelper.fetchAllByEntity` already wraps the listener in the client's `threadContext`.
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
last parameter can be set to from.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
It would be nice to return a simple, non-empty structure here so that we test that aspect of the response parsing.
oh boy :)
+1 to this, there is always the low-level rest client for this, and we can revisit adding it at a later time if we change our minds.
nit: extra line
I think this can be simplified into ``` if (obj instanceof Map || obj instanceof String) { valueWrapper = Map.of("shape", obj); } else { ```
asked f2f, we can probably delete logging at this point.
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
I see that we need it from another package, I think it's ok.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
something is wrong in this sentence :)
Is this really necessary? Seems like it will produce a lot of noise.
maybe sort them by the list index `8`
Please revert this change.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
good point. I didn't think about that. The value to append can be an json object too, so yes the exception should be replaced with logic to deal with that.
or N times
I think we should complain if we don't find the header name.
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
oh oh I hadn't read your reply when I replied ;)
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
Answering my own question: you build the array to simulate the task being on all of the simulated nodes. I don't know that that is required here but doesn't hurt anything.
"Simulate a task that attempts to execute only on filterNodes. We are testing that this works."
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
I think we want to test index level blocks too here
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
nit: use assertThat(...) with isNull() as matcher instead? I think in general that is the preferred way of writing test assertions.
this is not needed. createIndex automatically reroutes.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
As a follow up we need to take into account that indices can be removed from a data stream (except the last/most current index). So we should either check here that the backing index really exists or in the delete index api also modify a data stream if the index is part of a data stream
s/payload is/payloads are
s/payload is/payloads are
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
I think if we get in that other PR I just reviewd we can reuse here the new method that you introduced there? :)
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
do we want to check listener.isDone? (because it is supposed to return immediately). get() waits.
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
can we add that to ClusterStateCreationUtils? It might be useful for others as well
true. nevermind then
I am not sure RestoreService would be the right place for it since addBlock would need to be moved to the same place and it's currently used all over the place. I don't have an issue with renaming it to `addIndexMedataBlocks` but since IndexMetadata is the only parameter, repeating IndexMetadata in the name might be redundant.
should we check here that the totalShardWeight is not negative. I was just thinking if somebody uses the number of docs per shard and we overflow? I really wonder if we should put some upperbound into the setting to ensure folk don't go crazy? They should use some log scale rather than actual numbers? maybe we use `1<<16` as the upper limit for now? and move totalShardWeight to a long and use doubles elsewhere? I really just wanna protect us form going negative :)
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
Fall back to _old_ behavior
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
we shouldn't be lenient in case `upperTerm` doesnt't implement BytesRef
Conversion to bytesref is done elsewhere with `indexedValueForSearch`. I'm unsure of the impact of rejecting anything but bytesrefs.
we don't need this `if` block, do we? All 6.x and 7.x indices have a single type.
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
shall we test POSITIVE_INFINITY too? seems like we return null for that too but the default value once parsed is only one...
same as in the other PR, I would rather throw UnsupportedOperationException in the default case
I was trying to understand why this step got necessary, can you briefly explain? I'm just curious what happens here since it didn't happen in the test before.
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
final, not volatile...
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
On reflection I think this means we don't need `lastCommittedState` any more.
Can we make this 1 hour? If it times out it's nice to get thread dump
that awfully sounds like two voices for debug.... your turn, @jasontedor.
tokeinzer -> tokenizer
I like dummy because it implies fake and the index is fake - not just empty.
Builin -> Builtin (forgot a 't')
++ to just `get*`
All of the `*Plugin` interfaces we have added so far have used `get*`. I think we should be consistent.
Thanks for the explanation. Let's do it here. Since the error has an inner cause which provides from_seq_no and to_seq_no information, I think we are good.
+100 to any way that doesn't rely on message strings. Thanks for iterating on this to get there!
> I am thinking to have a dedicated exception so that we can access "fromSeqNo" and "toSeqNo" but maybe overkilled. We should not introduce that dedicated exception I think.
ok now i can see that it is null when removing the task, sorry for the noise
I think this file needs formatting `if(` -> `if (`
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
Did this change in the builder or does the case check stay? Can't find it, maybe missed it.
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
CONSTANT_SCORE_REWRITE is the rewrite for all multi-term queries but FuzzyQuery: see the FuzzyQuery constructor which calls `setRewriteMethod(new MultiTermQuery.TopTermsBlendedFreqScoringRewrite(maxExpansions));`
From the discussion before I think that removing the special case for FuzzyQuery inside filter context is okay here since CONSTANT_SCORE_REWRITE ist the default MultiTermQuery rewrite method anyway. @jpountz could you have a look at this change since I think it's related to the filter/query merging.
Should this be cached somehow? /cc @jpountz
I think you don't need to create cache keys and could directly use LeafReader instances as cache keys.
I think you can just do this? ``` if (info.files().contains(markerFileName) == false) { return true; } ```
There's an extraneous blank line here.
similarly here I would like it better with a regular for loop and by making fillSegmentInfo take a single segment at a time
after rebase you will have to get rid of any wildcard import, or the build fails :)
There is now a base class `RestActionTestCase` that helps remove some of the test boilerplate.
argh, I forgot UnicastZenPing doesn't support local addresses by default. Sorry for the noise.. (we should fix this at one point)
When it gets long like this can you indent it like ``` assertResult(() -> builder() .startObject() .startObject("foo") .startObject("bar") .endObject() .endObject() .endObject(), ``` I know we `assertThat` has the matcher second, but maybe we should put the closure second for this? I think it is nice when the closure is second because it makes the code formatting prettier.
Nit: could this move back down to where it was before, since it's not being changed? Would make the diff smaller.
This should say `storeStats`, not `storeState`.
Typo, finalzlie -> finalize
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
I think we should collapse the two above methods, they are always called in sequence.
That might make sense though my preference is to handle this corner cases leniently. I was a bit confused by `UNKNOWN`, I would argue an empty list has `FALSE` nullability (it can never be null) but then again maybe it's something that's worth having a check.
I'd remove the bitmask - it doesn't seem to add much value (see the previous method suggestions for implementing and); shorter and clearer than using bits.
If the constructor is modified, this method won't be needed anymore.
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
Since we're moving that, we could inline this using turnary.
Nit: this could be on the previous line.
I think it'd be useful to see the filenames in the exception message.
I think we don't need this line or the following two, since they duplicate docs found elsewhere.
I think it'd be useful to see the filenames in the exception message.
I think it'd be useful to see the filenames in the exception message.
Could you replace null above with `TRANSLOG_BUFFER_SIZE_SETTING`? (This is a separate issue, but I never backported to 1.7.x...)
Pre-existing issue: I think 30s default is too large, because an index that was inactive and suddenly becomes active with a 512 KB indexing buffer for up to 30s of heavy indexing is suddenly writing many, many segments. It would be better if the first indexing op to arrive to an inactive shard could force IMC to wake up and re-evaluate. I'll open a separate issue about this ...
if we do this, then specifying just host without a port will cause to return a list of 100 addresses by default
can we have two static helpers that allow to create the processor either providing the Client or the RestHighLevelClient ? I am thinking of users, there are many existing usages of BulkProcessor out there. I may be ok to change the way it gets created, but as a user I would be surprised to have to pass in a method reference. That should be more of an implementation detail.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
I'd go for either check in the constructor or here.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
thanks for unwrapping
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
I think completely removing it is unrealistic, but we may not get a disconnection event for quite some time (up to ~15 minutes by default on Linux). I do not think it should be delayed beyond the safety phase.
I just realized, for this log message and all of the ones below it here, we only log `index` and totally omit `reason` because there is only one `{}` in the log message...
I guess we should call this method `updateAppliedStates()` and the field should be `appliedStatesByVersion`.
do we need this trace log here and if so can we fix it to say `temporarily` or something like this
in the case of createIndices, this should send shard failed for the shard routing that triggered the index creation, but it doesn't because the indexService is empty. I think the interaction with shard failures is too brittle/tricky. My suggestion would be to just return an exception on failure and let the caller deal with it in the right way. PS - maybe this signals a testing gap as well..
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
looking deeper, I see that we set a non null TermsLookup object only when we have it in query, which causes a validation error when values are set too. We should keep it that way then, this is as good as it gets.
I meant that other way around, not in the else, set termsLookup only if values == null
you can remove the validate call for now, we will fix all queries soon, I promise
This line is called multiple times as we keep adding indices. It could be called once at the end of the loop I guess.
is this correct? this will return a copied array if offset > 0, yet the `arrayOffset` method will return the offset into an array that has offset 0... .
I think we should return the BytesRef array we get from reading from byte array, and `arrayOffset` will use the same logic, and return the offset form the BytesRef
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
Indeed, I think two BytesReference instances should be considered equal if they have the same content (which is what the way other children of BytesReference are implemented suggests). My point was this path of the equals method ignores the offset of `other` (it starts comparing its bytes at `0` instead of `other.offset`.
good that you added this assertion :)
you don't have to assert on anything if an exception is expected
not sure either, I just thought we introduced `parserName()` to have our temporary `toQuery()` method working. ``` //norelease to be removed once all query builders override toQuery providing their own specific implementation. public Query toQuery(QueryParseContext parseContext) throws QueryParsingException, IOException { return parseContext.indexQueryParserService().queryParser(parserName()).parse(parseContext); } ```
then check for non null here...
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
same for here, not sure if the full Objects.equals needs to be called
I'm wondering if we need to use `Objects.equals` here which would be quite heavy-weight on the entire CockroachTasksInProgress... in this case, for example, all we care about is if there are new task entries whose executor is the local node id... in that case, maybe we can have a method on `CockroachTasksInProgress` such as `hasNewEntriesForExecutor(localNodeId)`
I think this catch not needed. It will be caught higher up.
I think you want to use `notVisitedTasks` here instead of `runningTasks`
I think we should use `debug` for the logging here
Can we keep the line numbers in the test assertions? I think they are important to maintain.
I wonder if this should be `Exception`. see also #20659
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
Not important, but couldn't this just be an array? String[] possiblePathValues = {"some_path", "anotherPath", null};
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
Why isn't this replacing `--hash`? The release hash here should be the only thing needed to download the artifacts.
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
last `%version` should be `%major_minor_version`
nit: space after the second percent sign (on all these lines)
Just a note here. We decided that by convention we will use the same naming as maven. `groupId` has now changed to `org.elasticsearch.distribution.[packaging]` so I think we should also reflect that change here and use `org/elasticsearch/distribution/[packaging]` where `packaging` is: - rpm - deb - zip - tar
this is just personal preference so feel free to ignore it, but I like the name `registerDeprecatedHandler`
> I thought I was getting at that without making it too wordy. The key is that you're not registering a `DeprecationRestHandler` as the name `registerDeprecatedHandler` implies. Instead, you're registering a handler that gets wrapped as a `DeprecationRestHandler` before registration. I guess `registerAsDeprecationHandler` would be slightly less wordy than `registerHandlerAsDeprecationHandler` but the point still remains.
The language in this sentence isn't clear, perhaps change "that is replacing" to "and it is replacing"
> Though I do prefer that it fails fast instead of lazily later. ++
No, I still think that it should not be a method on the `Strings` class.
Maybe "you should use time based indexes or cron a delete-by-query with a range query on a timestamp field"? Or something that mentions time based indexes....
I also think that this should log the input instead of the normalized input.
fielddata format can still contain arbitrary values: ``` PUT testidx { "mappings": { "doc": { "properties": { "user": { "type": "string", "fielddata": { "format": "fst", "blah": "blub" } } } } } } ``` I am however not sure what is expected here because when I get the mapping the wrong entry will be returned...
Old indentation was better because it made it obvious that the conditions weren't part of the body.
update version to beta 1
can we move this back into the try? I'm worried that exceptions wouldn't release the shard lock .
nit: ditto for `final` method args here
index's toString gives you '[index_name]' no need for '[{}]'
same here - I think it's better to log the info message if the deletion was successful.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
confuses the shit out of me everytime :)
"new" -> "now"
Typo "uncomitted" -> "uncommitted"
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
I think we should throw an exception when `id < 0`, which should never happen? (unless Bad Stuffâ¢)
Can we use `in.getVersion()` to check in the read (and write) for serializing this as a single string for old versions, and array for new ones? Then we can backaport it to 0.90.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
I would probably throw an exception instead of accepting null here.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
we should be careful here and check for sources that are binary (SMILE etc..)
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
> talking below about using only the index, source, and id probably a typo, but just in case - index, type and id (not source)
I like including the original size here. Maybe instead if the source is chopped it should read like `first 2048 characters out of 10122123: _slice_of_the_source_`.
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
maybe add the type that is found in the error message with fieldType.typeName()
And we could then just leave an assert here.
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
+1 then we shouldn't forget about it :)
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
we should totally not have this method, one more reason to not implement the interface.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I don't think it's important for now
check listener.isDone() as we don't expect a retry here I think
true. nevermind then
yeah that is true. nevermind then
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
Could this be: assertThat(ackListener.await(0L, TimeUnit.SECONDS), containsInAnyOrder(n1, n2, n3));
We could get rid of this `== false` by inverting this statement.
There is actually a [standard](http://checkstyle.sourceforge.net/config_modifier.html) for this if you particularly enjoy standards.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I think I'd rather stay on the safe side
I liked the assertion you had there that if already have a result, this one has a higher seq no
can we also step out if `matchedDocId < DocIdSetIterator.NO_MORE_DOC`
hmm actually I think we should load deleted queries too
I think the message here should 1. be a static final constant and 2. say what this TermsEnum allows ie.: `"This TermsEnum only supports #seekExact(BytesRef) as well as #docFreq() and #totalTermFreq()"`
argh. Hidden by github ui. all good.
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
new is not possible with an older version...
ver -> version
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
just `for (IndexMetaData indexMetaData : state.metaData())`
this is not needed. createIndex automatically reroutes.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
wondering if we should enforce immutability on this level... feels more natural to do it in the build()
can we swap member and constant we know the constant is not null :)
paranoid! :) (re double immutability)
I see it now - I think how you've got it now is the most right thing then.
Are we returning here a mutable map? I don't think we should do that here. We should at least wrap it in `Collections#unmodifiableMap()`
formatting, 1 line instead of 2
formatting - 1 line instead of 2
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
random drive by question - why is the primary term part of the index result? it's already part of index and index result is supposed to capture the dynamic things that the engine has assigned.
I see. The seqNo and the term do not necessarily always go together. the seqNo is the location of the operation and the term is the authority to put it there. I like the fact that the result object only contains the things that the internal engine creates / changes. Seq# are owned by the engine (on a primary). Terms are owned by the shard. I would prefer to remove the term. At least in the example you gave (`Translog.Index#Index(Index, IndexResult`) it's readily available from the index operation.
sounds good, we were even thinking about merging those, we will not move them to separate packages for sure.
if you make the `AliasActions` class static you can remove this odd looking `request.new` :)
this is a java 7 feature you need to do `new String[] {alias};`
should be action
Regex.simpleMatch already has a null protection, no need to put it here...
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
same note as in the json processor PR.
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
This method also does not need to exist, as you can use `this(indices, IndicesOptions.strictExpandOpen())`, and fix the validation in the other constructor.
I think we can do this without adding an interface? Users should not need to do this? A script cannot realistically be used for both search and executable. I know this is more a problem with the existing scripting apis, but I think here we can just implement executable, and search should throw UOE.
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
we should make this entire class package private and try to contain visibility here as well.
ok can you add alls these infos into this class
I think the message should be "security manager is disabled", because the assume would only print the message and ignore test if the security manager is disabled.
If these privileges are only needed for loading static definitions, then this should be done in a static block when the plugin is loaded, instead of on every invocation of the script.
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
Nit: spacing between `!` and `value`.
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
we need to check on the node version, and only call it on nodes that are version 1.3 and above, otherwise they won't have this API
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
There is a problem with this test setup that I just found: the xContentType that is used for parsing here is not necessarily the same as the one that is used int randomUpdateResponse(). So the expected values might be off, e.g. if in randomUpdateResponse() SMILE is used and here xContentType is Yaml.
you are right thanks a lot for catching this
While I think a common methods would be great, I'm not sure this distinction (small vs. large longs) is needed very often. In the parsing tests its good to have some more "smaller" values to catch cases where they might be parsed back as int. I wonder how a common method would be called (randomNonNegativeLongButOftenSmall?), which range to sample the small values from (that might vary between tests) and where to put it. But maybe @tlrx has some suggestion.
++ I like that solution here
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
I think this can all fit on one line more cleanly if you break after the equal sign.
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
good catch! that means we are not properly testing this case either given that we didn't catch it.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
`ilm-move-to-error` -> `ilm-move-to-error-step`
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
`s/step/cluster state step/`
since `getActionFromPolicy` can, theoretically, return `null`, would it be safer to switch these around to ``` newAction.equals(currentAction) == false ```
can we add some java docs? the name to functionality transition is not trivial anymore
The indentation is off here and the rest of the way through this test.
I think this code will be simpler if we have two methods - sendFullClusterState and sendClusterStateDiff , each dealing with it's own serialization (and have the cache map passed to them). We can have sendClusterStateDiff fall back to sendFullClusterState if needed , which will mean no resend method..
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
you could use `scriptRequest.setJsonEntity`
Ah yeah, the docs are a little confusing with regards to how it works internally. The persistent/allocated Task is always running, start and stop just toggles internal state. If the task doesn't exist, the job doesn't exist basically.
Technically, you don't have to start the job if you just want to make sure the task is running. We start the persistent task when the job is created in the CreateRollupJob API. Although I wonder if there might be a potentially rare timing issue here? The CreateRollupJob API returns when the persistent task framework acknowledges that task was created. But I believe there might be a lag between that and when the allocated task is actually created on the target node? So it might be possible for the StartJob API (or `assertRollupJob()` if starting is skipped) to fail because the allocated task hasn't started yet? Maybe we need an `assertBusy` checking for the job, like below? I may be wrong about that though, you're much more familiar with how the persistent tasks work :)
Er, well, it doesn't work like that. Ignore.
I was wondering if `getSuperset/SubsetSize` is part of the Bucket interface but not rendered via the Rest response, should we either add rendering of these values to the bucket response or remove it from the interface to get equivalent behaviour of functionality of the transport client with the high level rest client here? I think this can be done in a separate issue though, maybe its not needed at all.
I'm okay with the UnsupportedOperationException for now if we can track this question (whether we can reach consistency between the functionality the transport client provides via the SignificantTerms.Bucket interface with the rest response) in a separate issue
Aggregations is not abstract anymore, you can remove the curly brackets. also if we had Aggregations as a member we wouldn't have to create it on the fly here
I think if we had Aggregations as a member we could call Aggregations#toXContentInternal instead
we may want to rename match_formats as well here, can do in another PR though.
oh right sorry I had missed it's a single value for these processors. sounds good.
I like this simplification!
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
This name won't work as I can specify multiple scripts of a single type (e.g. `inline`) and the `ParseField` name for them all will be `"inline"` so they will overwrite each other. I think we need to go back to the parser here and parse a `Map<String, Script>` so each script can have a name. In the request this would look like: ``` { ... "script": { "my_script_1": { "inline": "script contents", "lang": "expressions" }, "my_script_2": "script contents", ... } ``` Note that scripts can either be a JSON object or a String. The `Script.parse()` method handles both cases.
ok I wasn't sure, perfect
If the constructor is modified, this method won't be needed anymore.
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
I think we should use `debug` for the logging here
please remove that blank line
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
please return a Map instead no google guava stuff in public interfaces
Er, probably not. But a bit confusing name because it looks like a typo.
no file? maybe IOException
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
I'd feel better if the `latch.countDown()` would be the first line in the catch block
err I guess you need to have failures added first so second...
maybe just `return blobMetaData.length() == fileInfo.length();`
I think this message is wrong? applyMappings only touches existing indices.
nit: can you assign `event.state()` to a local var
we should also have messages here in this assert
future note - once refresh mapping is gone, we should inline this with index creation.
applyDeleteIndices -> deleteIndices
I'm afraid we need to rely on the order if we want to be able to distinguish between negations (applied when a wildcard expression appears before the negation) and referring to indices that start with `-`. We will be able to get rid of it in 6.0 only when we will be sure such indices are not around anymore. I opened #20962. Can we also have a test where the wildcard expression is not the first expression but still before the negation? e.g. `test1,test2,index*,-index1`
Also `-test1,*test2*,-test20` or something along those lines? :)
do you understand this if block? I suspect it made sense before your change, to make it possible to refer to existing indices or aliases that started with `-` rather than treating the name as a negation. That said, I can't quite follow why it makes sense in some cases for `result` to be `null`. This was already there, not your doing but I wonder if it's related and may be cleaned up.
I think this is expected to be a sorted list on the `job_id`.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
I understand with `wrap`. I think it'd be a little more clear if you just caught the `IOException` and sent it to `onFailure` but what you have will work as well.
You *shouldn't* need to `catch (Exception` here because the caller already does and will forward any exceptions you throw to `onFailure`.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
We typically do this light weight coordination on the same thread. I.e., Names.SAME . This does nothingother than spawn another bulk request. This will cause a new thread to be spawned as we don't do anything else with the bulk pool on the client. To be honest, I don't think the transport client should have so many thread pools. I'll open a different issue for that.
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
Sure, I was just wondering as this patterns appears now at least 3 times.
I think we should discuss such ideas in follow-up PRs. It's not clear to me that replacing duplicate code with more abstractions would be a win.
you could call `BitMixer.mix64(value)`, which should have the same quality but might be a bit faster
I think we should. For instance in the case of a date field that only stores dates with second precision, all values would be multiples of 1000.
@jaymode no. the opposite. I prefer not outputing fields with empty values. This is the norm now, and outputing empty field values is only useful in a tabular log format (column names at the top).
I think we can change this to `return ", opaque_id=[" + opaqueId "]";` and in the log message `, opaque_id=[{}]` will just be `{}` since we always add this at the end and we keep consistency with the way we handle indices.
I think that we are leaking a thread local here? We should close the current threadContext before overriding it.
It would be nice to find another way to do this other than replacing the thread context. I had a look but didn't find other ways though :) I guess you have tried as well.
I'm afraid this won't work - you only want to decrement this when someone responds to the channel... it needs to be built into the RestChannel..
I'm happy we have all these tests. It is also another data point to move in the direction we discussed - i.e., failures should mark things as stale.
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Assert that the current thread holds the lock on `this`? The results from `ObjectLongMap#indexOf` remain valid only if no one else is mutating.
and this one
Typo: "`local checkpoint`" -> "`local checkpoints`".
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
And we could then just leave an assert here.
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
you can do some streaming java8 magic here.
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Might be better to use the default of the request (in this case this coincides, but explicit is better in case of refactoring): getSnapshotsRequest.ignoreUnavailable(request.paramAsBoolean("ignore_unavailable", getSnapshotsRequest.ignoreUnavailable());
I don't think we either but I know some folks like them so I certainly don't object to them.
oh oh I hadn't read your reply when I replied ;)
to make this simpler, I think we should add a method `addCustomFields` to the `AcknowledgedResponse` object instead and just call `response.addCustomFields(builder)` in `AcknowledgedRestListener`. As a follow-up we can then make AcknowledgedResponse implement `StatusToXContent`.
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Makes sense to me. I only point it out in case you hadn't noticed it and it could save you any code.
I don't think we should even have IndexLookup. It is no more work to write and use a custom similarity than to write and use a native script, and the point of similarity is for customizing exactly this.
Search and executable, and execute look like they should delegate stuff to a single method. Orsomething.
Maybe a name like "PlusOneMonth"
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
this is super ugly I think `AsyncShardFetch.Started` and `AsyncShardFetch.Store` should be an impl detail of `GatewayAllocator` no need to bind this or anything
that sucks, sorry :) We can't build stuff that is dependent on the order of how the listeners are added! Can we find a better way of doing this? I think each listener needs to have priority or so and every prioritoy can only be added once? Maybe we don't need this to be a list at all? This stuff is so fragile we have to iterate until it's safe
for instance in RestoreService we use `addLast` at runtime which messes with this assumption, that entire order thing is broken and error prone. The best thing I can come up with so far is to add defined stage like this: ``` Java enum ApplyStage { NewClusterState, NodesConnected, StateRecovered, ShardsStarted, RepositoriesCreated, NodesDisconnected; } ``` where listeners can be registered but I am not too happy about it...
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
lower case F please :) - "found shard on ..."
missing { } :)
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
[{}] for path.
Throw error if old-style params passed alongside new-style script definition
Error if old-style params passed alongside new-style script
same as above, this breaks bw comp for the java api
this new exception is going to trigger errors too if we try to serialize it to an older node
Maybe this one too, I'm not sure.
It is how other plugins do it, yeah. There isn't a clear definition of "correct" here.
just FYI - you can do setSettings("index.number_of_replicas", 0)
Ahh ok it makes sense that this has gone from the subclasses. However I think I prefer it to remain on the subclasses for the sake of being explicit.
Awesome to see this TODO go away!
Can we also defer to `super.nodeSettings(nodeOrdinal)` so we don't also need to set `DISCOVERY_HOSTS_PROVIDER_SETTING` and `MAX_LOCAL_STORAGE_NODES_SETTING` here? (This also picks up a correct value for `DISCOVERY_ZEN_PING_UNICAST_HOSTS_SETTING`).
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
I think this check does not add much (I would skip it)
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
maybe 7 indices with 50 docs is a bit too much (= slow test), let's reduce randomness to 3 indices, each max 2 shards, and 10 docs.
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
see above - I think you should add it though
actually, if its a single page, then we can just reference the first page byte array, if not, then we should return false. same with `array` and `arrayOffset`.
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
maybe 7 indices with 50 docs is a bit too much (= slow test), let's reduce randomness to 3 indices, each max 2 shards, and 10 docs.
Missing `assertAcked()` or call to .get()
there is just 1 node
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
I guess it could be renamed to isFalse() / isTrue() now
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
space missing between ) and {
Yeah, let's the keep the tests just focused on whether or not `MinMasterNodeCheck` does the right thing based on whether or not `discovery.zen.minimum_master_nodes` is set and we can think about broader tests for the default checks from `BootstrapCheck` itself in a separate pull request.
There's a `BootstrapCheck#check(boolean, List<BootstrapCheck.Check>)` override that is visible for testing exactly so that the test can be written without having to rely on passing in a setting the triggers enforcement.
boo! :) just ignore :)
if you want to know i happened, let's use logging..
Add short-curcuit return if this == other.
Er, well, it doesn't work like that. Ignore.
I think `writeGenericValue` handles null values, so you could omitt the surrounding check.
This seems not to be the right exception message here (looks like cp'ed from term query).
so `round` should be called once per factory instead of once per aggregator
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
Typo, "Trasnlog" -> "Translog"
these ElasticsaerchExceptions are bogus remove them
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
just name it `readSize`
you can omit `ElasticsearchException` here it's unchecked
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I think this can move to before the threads start - will be nastier
operation can be `final`
nit: extra line
This method looks much simpler now ð
Throwing a RetryOnPrimaryException feels ugly. I see why you did it and I can't come up with something better. On top of that, this made me realize that RetryOnPrimaryException has serious problems. I'll reach out to discuss. to be clear - this shouldn't stop this PR as it is an existing situation.
can we call this primaryItemRequest? It's the one that's sent to the primary. Also, if we pass it as a `BulkItemRequest` parameter, we can avoid sending `requestIndex` and `BulkShardRequest` (from which need the concreteIndex, which I think we can from the shard). Last can we assert that the `BulkItemRequest` has as a request object the `updateRequest` we got? this is all super trappy but we can take one step at a time :)
Is it right to just eat the exception thrown from the listener? At least log a warning or something.
> I have just moved code around, so this implementation is not new. Fair enough. I'd still log a warning just to help debug any mistakes in the listener. If all goes well and the listener catches any exceptions then we will never call it.
does this need to be public and also does this class need to be subclassable
We typically do this light weight coordination on the same thread. I.e., Names.SAME . This does nothingother than spawn another bulk request. This will cause a new thread to be spawned as we don't do anything else with the bulk pool on the client. To be honest, I don't think the transport client should have so many thread pools. I'll open a different issue for that.
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
add `assert entry.state() == State.ABORTED` here. You can directly write the message as "snapshot was aborted during initialization" which makes it clearer which situation is handled here.
I think this can be optimized further. Here we are updating status of shards that are participating in the restore process. There are only two possible outcome of this operation for a snapshot itâs ether done when all shards are done or it is not done. It doesnât matter if we are applying a single shard or multiple shards â there is still only one outcome per snapshot. If a snapshot is done we need to check if all shards in this snapshot has started and if they are not â create a listener. In other words instead of having an array with one element per shard it might make sense to have a map with one element per snapshot.
I think this should be trace
this made me worry we don't log these failures anymore.. In this specific case I think we are best to just let the exception bubble up, but it does raise a more general issue - if people put exceptions in the builder, it's their responsiblity to report it. we should probably add something to the internal cluster service to auto log it.
perhaps move the assertion one level up, i.e., ``` } else { assert priamryShardRouting.relocating(); if (currentState == State.INIT || currentStatus.state() == State.ABORTED) { .. }Â else { .. } } ```
It would be nice to have this take the args in the same order as computePolyTop (array, offset, length)
Again, it would be cleaner to init `i` to `offset + 1` so that you don't have to add `offset` in every iteration.
I think it would be cleaner to set translated outside of the if statement. ``` boolean translated = incorrectOrientation && rng > DATELINE && rng != 360.0; if (translated || shellCorrected && component != 0) { ... ```
Is the `component != 0` check needed? Seems like the only way to get past the `||` is for that condition to be true.
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
s/to list of/to the list of/
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
I just realized, for this log message and all of the ones below it here, we only log `index` and totally omit `reason` because there is only one `{}` in the log message...
Double negative. ð
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
To make jobs built with this method reusable when we come to send data to them in other tests, I think it would be better to fix the time format to `EPOCH_MS` and time field name to a specific value, e.g. "time". However, since it takes hours to get the PR CI build to complete and we'll be changing this same file in future PRs that implement the other endpoints I'm happy to leave this as-is for now.
you can move this method (and the one below it) up to IndexShardTestCase (in test:framework). It could be useful for other people.
Another simplification - if we push the code at https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterIndexHealth.java#L81 into ClusterIndexShardHealth's constructor, we can use it here and just make it a simple lookup in the enum set..
Would be nice to see this parsing code pulled into a function or helper on the parent class so it doesn't need to be the same in both implementations
Could be `contentType = scriptMetadata.getOptions().getOrDefault(Script.CONTENT_TYPE_OPTION, DEFAULT_CONTENT_TYPE);` And then you can remove the null check below
Please add a string message about the context registry being null
bodies in both cases are the same, why not write just: case "script": case "template": .....
I think this could use the `rebalance` function in `CatAllocationTestBase`? It looks like it's performing the same function
Why do we need getters? These are all final and immutable
Believe it or not, it's fine to pass `null` to `IOUtils.closeWhileHandlingException` (it just skips them). We do that for cases where you might have N things that need closing from a large try block, and you don't know which are `null` and which are not (depends on where the exception was thrown). But for here I like the `null` check: less smelly.
`new AtomicReference<>();` with the extra `<>`.
please wrap in {}
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
I think this message might be misleading.
out of memory (source: [" + source + "])
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
OMG `== false`! ð±
It feels squicky to ignore the exception. Personally I'd `assert false : "Exceptions not expected here."` and `logger.error` about it.
I find it confusing the we have the same field names for this in both ReplicationPhase and PrimaryPhase.
actually I just got a bit confused because both classes are in the same file...
this doesn't mean the index is not active, but rather that it doesn't exist or is closed. I don't think we need to retry in that case. [Old cold would throw `IndexNotFoundException` in this case](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java#L203).
Why is this `volatile`? It doesn't look necessary to me.
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
I wonder if we can somehow come up with something that better normalizes across failed cloud instances? If a machine is pulled, but its replacement can come up within the allotted time, then it would be ideal to not trigger the recovery because we're waiting on the dead machine (based on its InetAddress).
I think we should extend our cloud integration plugins to add some kind of a stable identifier as a node attribute (if not already doing so) and auto-configure this setting to it. /cc @dadoinet @tlrx
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
"joined the cluster back" -> "rejoined the cluster"
can we implement `Closeable` and use an AtomicBoolean to signal it's closed I like the `if (closed.compareAndSet(false, true))` pattern
is this new assert needed? after all the following cast will fail if the request is not a Replaceable...
Can this lead to user code change? ( as you changed the tests above )
can we mark this as nullable (and doc when it's null)? also, can we move it next to the setter, and make the naming consistent with the rest of this class? (i.e., shardId)
Can we provide more details in this message (e.g. the name of the index/alias)
This is a question, not a change request: What is our philosophy regarding having setters vs. immutable request objects going forward for the HLRC? I've been under the impression we preferred immutable objects, but it doesn't seem to be consistent.
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
no need for `else` here
I think s/lang/defaultLang/
Fine by me.
Maybe this one too, I'm not sure.
you don't have to assert on anything if an exception is expected
you can make one of them public and call it from both tests, I don't mind
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
What was the reason again why we cannot simply compare the parsed objects xContent representation to the original? I forgot, seems to make this test a bit more complicated than I thought.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
I think that we can save the instanceof checks, builder.value(Object) does it already
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
remove this additional line break? :)
ops turns out I had seen it because I was working on it for the date processor, i will add the needed method for string arrays.
I thought I saw some `List<String>` already but I can't find it anywhere, seems like we will add that when we need it then.
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
can we do this `((Long)value).longValue())` no boxing needed here
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
Usually we'd stick this on the end of the last line.
This needs to handle the -1 case.
This is not the right condition, a plugin bin directory is not required to exist.
We can remove the period here, this is a sentence fragment (as these usually are).
We can drop everything after and including the comma.
Let's remove the period from the end of these, they are typically not sentences.
This should be `pluginName`.
I'm wondering if we should adapt the whole message and say "Recovery failed on " + targetNode , if there is no sourceNode
The sequence number backwards layer won't be needed after 7.0.0.
Asserts are better for this. ð
Another `_` java 9 will be mad at
I think java 9 is going to choke on `_` here, if I recall correctly
Ok fair enough, I'm happy leaving this as is then
Actually I'd still prefer to go with Colin's idea to use empty sets. We can still optimize later by making sure to use a Collections.emptySet (which is a singleton) if the size is 0.
just initialize it and make it final - it just compliicates the code
whoops I read it backwards, so yeah, not really necessary
Perhaps add the duplicate size to the assert message here
Same concern regarding the leniency.
This can just be a plain old logging statement `logger.debug("[discovery-file] using dynamic discovery nodes {}", discoNodes);`.
I really don't think we need this leniency, I'd like to understand why we're introducing it. I think we should just blow up the pings.
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
Nit: addresses -> address
nit: I changed this on master to get the parser from AcknowledgedResponse using a new `generateParser` method that I introduced there on request of Baz. Maybe we could use the same here in the backport to make it match the version on master.
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
This does not necessarily need to be within a static initialization block.
I am confused how this works when created is only within role mapping but we ignore role mapping
seems redundant indeed
I'll leave this one
hey @martijnvg I double checked with @clintongormley and we both think it's better to add the actual index that was closed, not the alias. Knowing that an alias is closed has little sense, better to report back which concrete index was closed.
I think we should mention the index, cause that is the useful bit (e.g. which index is closed), also because we never really hide the fact that users are using aliases (e.g. when indexing into an alias, the response will contain the concrete index as `_index`, not the alias).
yes, that's what I was thinking, I'd maybe check state != CLOSE rather than checking for OPEN, but that's a super minor concern that doesn't change the result at this time
++. Looks good.
sorry - got confused - I thought this code skips the primary. I think it will be clear if the if here would say `ShardRouting.primary() == false`
make sure you fix the codestyle here
please add `{}` around this
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
ahh yeah in `assertAfterTest()` nevermind
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
maybe use `shouldCompress` here to make it a little clearer? ```java if (shouldCompress) { IOUtils.closeWhileHandlingException(stream, bytesStreamOutput); } else { assert stream == bytesStreamOutput : "the stream variable is not the same instance as bytesStreamOutput"; IOUtils.closeWhileHandlingException(stream); } ```
when do not want to do it (and throw an exception as said above)
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
s/payload is/payloads are
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I don't think it matters. We should not force making huge changes to the entire codebase in order to not add things which will just be deprecated and/or confusing to the user.
I would also be fine with removing all the camelCase options for all formats in this PR to make it consistent.
I just realized we aren't even talking about setting names, but the valid values for the `format` setting. This argument to use ParseValue does not make sense. We don't support camelCase in eg the `index` option. We should not do it here, it will just add more work for users if we allow them to _start_ using a new value that will just go away in the future (and will require them to change the value to what they would have found in the first place if they had tried using camelCase and seen an error).
`it's` -> `its`
`translogs` -> `translog's`
you can do some streaming java8 magic here.
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
nit: extra line
This assumes a version format that while fairly standard is not guaranteed.
This isn't quite right. Wrap the ends with checks in parentheses.
So it's starts with and (ends with or ends with).
Also I think it is one slash only, annoyingly.
Oh, I misread it (mobile phone, sorry). The only thing that needs to change then is file:// -> file:/.
I think that we should avoid re-computing this value every time we get status (think of a monitoring system polling the stats every second). We are creating unnecessary garbage on every poll for every shard.
This means a serialization change too, to support -1.
I don't think it should be 0, I think it should be -1 so that we can distinguish a fetch just happened less than 1ms ago from a fetch just happened.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
Nit: `parallel` -> `concurrent`
Typo: `afllowed` -> `allowed`
should we here or in the superclass fail if the cluster has not fully upgraded to 2.3? just as a safety guard I think that would be a good check in several places otherwise I can see us debugging weird issues `DiscoveryNodes#smallestNonClientNodeVersion()` has a neat method to check.
It defaults to `false`. :)
I think this file needs formatting `if(` -> `if (`
Ok, than that's fine for me. So overall LGTM.
well if a test doesn't call `super.nodeSettings(nodeOrdinal)` that is a bug. We have to enforce it though. IMO we can use a similar way as the test base class does but we don't have to do it here...
underscore case? :)
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
can we check and stop if the background thread had any issues? o.w. will have to dig through more than needed.
This is `INTEGER` in other mappings.
This is an interesting question. At the moment this is what other APIs use to determine that a job is in the process of being deleted. Maybe storing that flag in an index won't be sufficiently atomic in the future. An alternative might be to make the job deletion process a persistent task, and use the existence of that persistent task to determine whether a job is being deleted. This field is probably just one of several places where indices won't give the same ordering guarantee that cluster state gave us.
why not calling `RestActions#buildBroadcastShardsHeader` instead ? Aren't we losing support for the `group_shard_failures` flag? It is not relevant for the high-level REST client as there is no way to set it but I think it's important given that the parsing code is in ES core. Which reminds me, we should probably test this as well in `RefreshResponseTests`. This param can be passed in as part of the `ToXContent.Params` when calling `toXContent`
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
Add short-curcuit return if this == other.
and randomly append '/' at the end
missing fail :) use expectThrows instead
s/y ou/you Also I think upfront is one word.
Fine by me.
Maybe this one too, I'm not sure.
once #12937 is in we can do the following here: ``` QueryBuilder<?> finalQuery; if (queryBuilder.indices().length == 1 && getIndex().getName().equals(queryBuilder.indices()[0])) { finalQuery = queryBuilder.innerQuery(); } else { finalQuery = queryBuilder.noMatchQuery(); } Query finalLuceneQuery = finalQuery.toQuery(context); if (finalLuceneQuery != null) { finalLuceneQuery.setBoost(queryBuilder.boost()); } assertEquals(query, finalLuceneQuery); ```
I say goodbye you say hello ;-)
once #12937 is in we can do the following here: ``` String[] indices; if (randomBoolean()) { indices = new String[]{getIndex().getName()}; } else { indices = generateRandomStringArray(5, 10, false, false); } IndicesQueryBuilder query = new IndicesQueryBuilder(RandomQueryBuilder.createQuery(random()), indices); ```
:) good catch
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
At this point I don't know that `@param` adds anything either.
Sorry you are right, we should be using ParsingException. That snippet was the pre-refactored version. The difference is that ParsingException does not need the SearchContext (not available on the coordinating node) and actually points to the location in the request for the error (the XContentLocation). Please use ParsingException in this PR since this is going to be parsed on the coordinating node
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
lower cased now...
I know the "dots in field names" discussion has been a long running one. Do we not yet have a more general/graceful way of throwing these exceptions? This is more of a question out of my own curiosity and not intended to hold up the PR.
Weird markdown seemed to silently remove some of my text...I was trying to say `FieldStats<java.lang.Long>` (which is what I think you meant by your last statement).
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
Yes, sorry for the confusion, I remember the discussion now. Maybe just rename then, although `elementName` is also fine.
I would probably make this package private
I think we discussed this before, but it didn't change, thus I'm bringing it up again ;) can we add a constructor that accepts `shardInfo` as argument and change the subclasses constructors to accept it there, just to enforce that this info is needed so we don't forget it anywhere. Maybe then we could also remove the setter...
nit cat we explicitly call the other constructor with null? i.e., `this(null)`
I didn't check but unittests for this would be awesome!
I see some places where null is not protected against...
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
I wanted to remove the `allowCommit.set(false)` here with an ensureOpen at the beginning of the method. Only saw later it's already there. No doubles.
maybe replace this with ensureOpen in the beginning? feels cleaner to me
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
Incides -> Indices ? ;)
I think this check does not add much (I would skip it)
typo in the method name here too
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
Oh, I'm fine with symmetry, I just wanted to make sure that I was reading it correctly.
just please don't add one. There are too many classes already.
ok, fair enough
what about throwing an IllegalFormatException instead? I'm a bit concerned about catching IAE as this is a very generic exception.
++ thanks Nik
nit: use the constant from the mapper? content type I think it is called
maybe one day we will a base class for runtime mapper field types that does this in one place.
oh boy :)
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
and the `ExceptionsHelper.` qualifier is unnecessary
can this be a constant
`expectedType.cast(e)` should remove the need for the unchecked suppression.
maybe put this check before the primaryTerm check
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
Sorry about these crazy incantations....
I'd use `randomAsciiOfLength(5)` rather than fixed strings for this.
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
You should just use [Collectors.toSet()](https://docs.oracle.com/javase/8/docs/api/java/util/stream/Collectors.html#toSet--) ``` Stream.of(AggregationType.values()).map(AggregationType::name).collect(Collectors.toSet()); ```
Given the method's name I expected it to check the values too.
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
I assumed that there is no problem setting values and checking that the output of the conversion from high-level request to low-level request is the expected one. We don't validate etc. I would do only what is straight-forward.
`application` needs to be null/empty
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
We should set random boolean here too. We should be testing both the default (unset) and using the method will all allowed values (i.e. true and false)
I think you are missing a `\n` here.
script seems to be optional, I get NPEs in some roundtrip tests for this.
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
I don't mind as long as we use `writeString/readString` and `writeOptionalString/readOptionalString` consistently. So you can maybe just change the `readFrom` to explicitly use readBoolean.
I understand this is the oversight you've mentioned
why do you pass the response to this method? `this` already has all information.
right I see that
The score of this query depends on the number of shards, the default similarity, ... To make sure that we have consistent scoring you can use a `function_score` query like the following: ```` QueryBuilder query = functionScoreQuery( termQuery("name", "one"), ScoreFunctionBuilders.fieldValueFactorFunction("my_static_doc_score") ).boostMode(CombineFunction.REPLACE); ```` ... and add the `my_static_doc_score` at indexing time.
"white spaces" -> "whitespace"
one too many new line? :)
Can we just explicitly test these? Let's have a test that the field is removed, no error, in the old ones, and another test that tan exception is thrown for newer indices. Randomizing the version is fine, but let's keep it to randomize within the versions we expect to have a particular behavior, so that we keep full coverage of what we are testing on every test run.
I don't see any implementations extending this at the moment, are there any plans to add some later? If this is just going to be a collection of static methods and ParseFields I'd suggest making this an interface.
Okay, can you briefly explain the (maybe future) relationship of the ShapeParser and the above GeoJsonParser class? Currently they both seem to mostly consist of a "static ShapeBuilder parse(XContentParser parser, GeoShapeFieldMapper shapeMapper)" method, don't have any state themselves but ShapeParser calls GeoJsonParser. It would be useful to understand where this is going.
Thanks, I get the general idea now.
The shapeFieldMapper seems unused here.
nit: these could probably even be package private
you also have this variant `org.elasticsearch.common.xcontent.XContentBuilder#timeValueField(java.lang.String, java.lang.String, long, java.util.concurrent.TimeUnit)` which you can use without changing TimeValue
newQueue -> newTombstone
If we use Collection<Tombstonre> we can return an unmodifiableCollection() which doesn't copy stuff..
oh, the boxing horrors :)
I think we could persist a time-to-live in the cluster state, and on each cluster state update the current master can subtract the offset between the current `System#nanoTime` and the `System#nanoTime` from the last time the master updated its local cluster state and persist the maximum of the new time remaining and zero. Now the tombstone will live exactly as long as there has been an active master and we do not have to worry about any crazy time issues.
or when some docs match the query but do not have a value
I think it's fine to add such a method to NoCacheFilter
here too we do the same twice
foo all switch statements in those tests, I think it would be less error-prone if we fail() in the default case? (not as much for now as for when we'll modify these tests)
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
Checkstyle is unhappy with this.
Checkstyle is unhappy with this.
This test should assert that the headers are correct.
minor: you may also want a second (mock) processor here, and assert that the second processor never executes.
you don't have to assert on anything if an exception is expected
does it make sense to remove the setters? I imagine it feels more ergonomic to use the `IndicesStatsRequestBuilder` for building up a modified `IndicesStatsRequest`
I actually think we can get rid of this entirely. We start the `IndicesService` before `IndicesClusterStateService` and stop it in the reverse order in `Node.java`. I think we can just rely on the state of `IndicesClusterStateService` and don't add this to the interface at all.
we can rather make it private and throw an exception like `ensureStarted()` and call it before we go anywhere that violates the condition but even that is best effort.
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
same as above, no need for try catch
We also need a simple rest test, testing integration like we have for the other processors
I prefer `assertEquals` in cases like this. `assertThat` is great if you need to take a matcher or want to assert something complicated, but I like `assertEquals` for equality.
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
maybe omit lowercase from the method names here? (since these tests also run for uppercase and trim)
Also, since "recover" and "restore" are very similar and easy to confuse, I think it'd be nice if this were named "`recoverState`"
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
you can move this method (and the one below it) up to IndexShardTestCase (in test:framework). It could be useful for other people.
I think we can just use an FsRepository for this. All our other shard-level tests do the same, so no need to optimize this. If we want to change that in the future, I think it's easier to switch to jimfs and continue using FsRepository.
It's that, or we can replace replace FsRepository with this one, but we need to beef it up.
remove line wrap
remove line wrap
remove line wrap
We should log the the failure here if the close fails
For backporting to 6.3, I think this needs to be changed to 7.
it's a minor thing but why would you assign a variable multiple times when it's not needed? default is a better fit here, it improves readability as well.
maybe we could have a `default` here which could make this switch a bit more readable rather than assigning value before the switch in any case.
Can we get back to this once we need this complexity and keep it as simple as possible for now please? Can we hardcode the OBJECT_FIELD_NAME exclusion and be done with it? queries also have access to individual field names if they need that.
one too many ;
either way please create a static array containing these fields on top close to where we create `mappedFieldnames` so this selection is not buried in this method and we see that we might have to change it if/when we add new fields.
I can't wait for try-with-resources :)
Wouldn't it be better to not call setScorer at all? I suspect most collector impls do not expect a null Scorer.
oh no I see, there is also a return. I think it's confusing that we can reach here because of either an assertion or a return statement
Yeah, it's pretty new. :-)
I don't think we should be promoting using this feature of scripting. If someone wants this level of control over scores, they should implement their own Similarity; that is its purpose.
I think it'd be nice to remove this second ctor so we're explicit every time.
Ah! I get it now. LGTM
I think you can change this to a `Supplier<Analyzer>` now.
This could be `Strings.hasLength(tokenizerName)`
This is not good for backword compatibility. Instead it should do: ``` if (indexSettings.getIndexVersionCreated().before(Version.V_6_0_0)) { String tokenizerName = settings.get("tokenizer", "whitespace"); tokenizerFactory = ...; } else { tokenizerFactory = null; } ```
This is going to be 512 Unicode code units, but I think we should do bytes.
nit: maybe use Strings.isEmpty.
This should be `aliasAction.aliases == null || aliasAction.aliases.length == 0`
Without this we get: ``` { "error": { "root_cause": [ { "type": "null_pointer_exception", "reason": null } ], "type": "null_pointer_exception", "reason": null }, "status": 500 } ``` ``` [2016-02-09 15:56:02,492][INFO ][rest.suppressed ] /_aliases Params: {} java.lang.NullPointerException at org.elasticsearch.action.admin.indices.alias.IndicesAliasesRequest.validate(IndicesAliasesRequest.java:289) at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:62) at org.elasticsearch.client.node. ```
nit: Excluding the first word the error message is duplicated and could be extracted.
I like dummy because it implies fake and the index is fake - not just empty.
tokeinzer -> tokenizer
Builin -> Builtin (forgot a 't')
All of the `*Plugin` interfaces we have added so far have used `get*`. I think we should be consistent.
I think we should stick with calling these getters like `getCharFilters` because it is the char filters that the plugin has, they aren't "extra" in the context of this one plugin.
Would it be beneficial here to return an empty string instead of null? If not, maybe just annotate this with `@Nullable`
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
Nit: `reject` -> `rejected`
This is logic that I think should go into ReplicatedOperation.
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
oh cool the read is in the ctor! nice!
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
I'd say yes... if you want to be able to parse script as a string, you want to be able to serialize it as as string. I believe serialization should be symmetric - you write what you read. For this reason, I believe the script type should be nullable. if you read a script like a string, the read state should be preserved for the writing.
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
can we add some trace logging here? I can imagine it will save some WTF at some point.
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
this made me worry we don't log these failures anymore.. In this specific case I think we are best to just let the exception bubble up, but it does raise a more general issue - if people put exceptions in the builder, it's their responsiblity to report it. we should probably add something to the internal cluster service to auto log it.
nit: `an` -> `a`
Er, probably not. But a bit confusing name because it looks like a typo.
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
catched -> caught
Another simplification - if we push the code at https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterIndexHealth.java#L81 into ClusterIndexShardHealth's constructor, we can use it here and just make it a simple lookup in the enum set..
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
nit: maybe use Strings.isEmpty.
Strings.hasLength(xyz) can be used with explitict comparison with boolean False
I think we've started to use `setShard` style here? I'm not totally sure.
Can we use `in.getVersion()` to check in the read (and write) for serializing this as a single string for old versions, and array for new ones? Then we can backaport it to 0.90.
Why not public? Will make reflection faster for guice.
I think we can't do that this way, for the query cache to work we have to pass in the `Searcher searcher` that we acquire in `SearchService` just above the creation of `DefaultShardContext` otherwise we will be subject to refreshes and the cache will have broken values.
I think we have to have a test for this, I suggest that we use a single node test that we can control that refreshes after we created the context with a new doc in it matching the query and ensure we are still rewriting to match all / none and then check if we have a cache hit? something like this...
DEFAUTL -> DEFAULT
I think it's fine to add such a method to NoCacheFilter
yea the idea was to move to `String[]` where we don't need to call `add` anymore... not sure it is possible though.
Since `value` internally is a String now, we can change read/write here as well.
sorry, my bad.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
good catch! that means we are not properly testing this case either given that we didn't catch it.
if we'll need this in other tests, we should probably try to shorten this setup part of test by re-using what we have in our java api, that allows to provide `Object... source` , but we also want to be able to randomize the xcontent type, which is why we need to adapt it a bit
We can allow flush here, I think.
I don't think you need the `Integer.toString` bit.
What happens if `enabled` isn't set? I *think* we should continue to do nothing if `enabled` is actually true.
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
nevermind I see it was already there, then it should be ok
clarify the error message specifying what needs to be non null? the inner query...also remove empty, doesnt make sense here
alright that's what I thought too, sounds good
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
make the error a bit more understandable for users? Like "processor x doesn't support some of the provided configuration parameters" and list them like you do already...
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
I think BuildFactory should be allowed to throw a ParseException since subclasses should have the ability to throw it if there is a problem with creating the builder at this point
I'm wondering if the parent really helps define equality here? Additionally, by adding this we will do more checks than necessary given that we compare both sub-aggs and parent aggs
I notice this pattern in every implementation. Perhaps this should be a Map instead of Collection (keyed by the custom type name)? Then the map can be copied, and keys replaced, removed, or added easily, without needing to have logic for the other custom metadata that the plugin does not care about.
we should add ClusterService and IndexNameExpressionResolver to IndexQueryParseService so they get injected. Then this method could pretty much be moved to INdexQueryParseService like this: ``` public boolean matchesIndices(String... indices) { final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices); for (String index : concreteIndices) { if (Regex.simpleMatch(index, this.index.name())) { return true; } } return false; } ``` QueryShardContext would need to expose the same methd and delegate the IndexQueryParseService
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
This line is called multiple times as we keep adding indices. It could be called once at the end of the loop I guess.
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think I would not check the instances' classes but instead compute how many values the interval has using NumericUtils.subtract (it returns a byte[] that is comparable).
maybe update the docs to say this is a terms query rather than a bool
(same question for FLOAT)
If we plan on keeping the time zone, I think we should add it here.
ok I wasn't sure, perfect
I would be using a `Set` in this circumstances.
You don't need to create an explicit default ctor since the super class has a default ctor.
No need for an empty default ctor when the super is also a default ctor.
I find these two empty `continueProcessing` methods confusing, if we manage to merge the two filter chains impl as said above, we would get rid of them I think
No need to override readFrom or writeTo
let's not make this hold this PR, but let's keep track of this potential issue and address the need for generifying in a separate issue
same question as above
how much work would be to "decode" the values and expand the test? I am wondering if it's worth doing or not.
thanks for doing that Colin ;)
we should `@Test` to forbidden API
Yeah, exactly, and I think usage should really be reserved for incompatible or invalid arguments, for example. This is more a state thing, so now I think I'm convincing myself that configuration is apt.
This should be a `USAGE` error, not a `DATA_ERROR` (and the period dropped from the exception message).
No, it should stay "id" in the message because plugins are installed by id (with the exception of some special plugins that can be installed by name only). Yet "name" is fine for removal because plugins are removed by name.
It is called pluginId in install because it is an identifier, which _may_ be a plugin name, but it also may be maven coordinates or a url.
No need to squash, we can do it on merge.
can you please use indexRandom to index docs
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
`createIndex("test")` ? then you can remove the following `assertAcked`
can we check and stop if the background thread had any issues? o.w. will have to dig through more than needed.
rather use `logger.debug` than `System.out`
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
can we add an assert to make sure that highlighterType != null here? it really should since we know that plain highlighter always returns true, but the assert would make it more explicit that it is expected
I liked the assertion you had there that if already have a result, this one has a higher seq no
And we could then just leave an assert here.
I wonder if we need this - we could assign the `NOT_FOUND` in the beginning of this method and then assign `currentDocFreq` as well as `currentTotalTermFreq` each time we update their local corresponding variables ie. as the last statement in the `for (Holder anEnum : enums)` loop. Same is true for the `text` and that way we can just trash everything below the for loop and return `found` I also think it's ok to just use `-1` as `NOT_FOUND`
the == false is done on purpose to make these comparisons more explicit
thinking out loud, maybe I am getting confused, but in order for a field to get highlighted, doesn't it need to be stored too or we need to have the _source at least? but metadata fields, which match `*` are not part of the `_source` hence they need to be stored or excluded from highlighting by definition. I have the feeling we should do something more to address that...
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
Sure, thats fine.
Wondering if it would be possible to create the builder first, then call all these setters in the parsing loop above already. Not really that important though.
can we use `== false` instead of `!` it's so much easier to read and burned my fingers too often
maybe use `coordinates.children.isEmpty()`instead
Might be slightly better to return a StringBuilder here as well to not create an additional object? Maybe this could also be done in several other places in this PR where partial WKT strings are built (e.g. all the contentToWKT calls)
nit: these could probably even be package private
nit: maybe package private, see above
Safe because ~~our~~ we know
update version to beta 1
And we could then just leave an assert here.
I meant `node` from the for loop.
Are there any calls to this version of findTemplateBuilder with matchType `string`? Or `findTemplate` below? very confusing how we have so many public variants of this method...
`it's` -> `its`
`translogs` -> `translog's`
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
hmm maybe name it `markCommitted(long translogId) throws IOException` I think it sholud be IOException here
operation can be `final`
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
"joined the cluster back" -> "rejoined the cluster"
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
we only need an array here - we don't do anything with the version and we copy it into one anyway: https://github.com/elastic/elasticsearch/pull/12335/files#diff-ad5388a03f5e080b452190f4eb47f33aR244 Might as well use an arraylist from the beginning.
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
we shouldn't need this here in parse phase
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
why is this? what's wrong with `1.f`
not sure why we go through the creation of QueryCreationContext to then retrieve the QueryParseContext, when we have the QueryParseContext in the first place
I meant that other way around, not in the else, set termsLookup only if values == null
yes, lets do this in a follow up change.
+1 then we shouldn't forget about it :)
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
And we could then just leave an assert here.
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
I personally think those queries should be build using query builders but we can do that in a second step.
one more thing (sorry!). For the language clients, I think it would be good to also have a small REST test that uses search_type count, just to verify that all of the clients (and our REST layer) still support it.
I think the message should be "security manager is disabled", because the assume would only print the message and ignore test if the security manager is disabled.
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You can use `assertAcked()`
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
Can you use more explicit name? (Also for getRepositoriesResponse1/2).
I don't think we need to check the implementation class, instance should be enough.
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
just FYI - you can do setSettings("index.number_of_replicas", 0)
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
can we configure the delayed allocation to not be the default (`1m`) but something high enough to trigger what we are trying to fix, like `200ms`? This will speed up the test.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
subtractShardsMovingAwayRen -> subtractShardsMovingAway
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
something is wrong in this sentence :)
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
I'm clearly not getting my point across. Please understand that multiple tests are run in the same jvm during jenkins!!!!!!!!!!!!
I wonder if we want to ban `new Random(int)` to make it harder for folks to do `new Random(System.currentTimeMillis)`. If so then `Randomness` is probably the right way to go. Otherwise I like `GOOD_FAST_HASH_SEED`.
Just to make it better, setting it here in clinit is not so ideal, because its not perfectly reproducible when multiple tests are run in the same jvm. you will still have perceived reproducibility issues vs jenkins if you go about it this way: because the random will be initialized _once_ and then we will run 8 test classes against it. then, when you later try to reproduce the one that failed, the sequence will be different (even though the initial value is the same), because the other tests are not also invoked. but if you do it this way, it at least allows "whole build" reproducibility, which is an improvement. That means e.g. if you nuke your local execution hints file and run 'gradle test -Dtests.seed=xxxxxx -Dtests.jvm=yyyyyy', it will match what jenkins did. But nobody does that.
In general can you please make sure you are not using your own code style. Please adopt to the codestyle which is mainly default SUN except of 4 spaces indent.
same here this is a left over!
Again missing units :(
Again, putting the unit in the name would help here, unless someone reads the docs they can't tell whether it's millis or nanos
can we replace the Math.max with an assertion? it should never happen and we shouldn't protect for it.
Yes, that would be clearer
oh hahahah, I can't read, that's an L
I would execute the `IOUtils.close(resources);` in a finally block after we sent back the response or the other way around.
s/listener/delegate/? I read this and immediately thought "infinite loop!" because this thing already **is** a listener. I know it is silly though.
should we release the releasable just in case the exception comes from the listener? this would allow us to only implement on failure.
Typo, finalzlie -> finalize
It feels squicky to ignore the exception. Personally I'd `assert false : "Exceptions not expected here."` and `logger.error` about it.
64e5c25 added support for this.
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
It might also depend on which implementation of `AcknowledgedResponse` you are using, since we have two, yay duplication!!! You should have a look at `StartRollupJobResponse`, which is an example of changing the word from `acknowledged` to `started`. this should get you on the right track.
Hey I saw some updates on this PR and I just wanted to throw a reminder out that we are not going to do a singleton(404) here, because we want a delete that is not found to throw an exception. Also, last time we spoke you were going to change this to AcknowledgedResponse. <3
heh, duh... Sorry, ive been on vacation and full of turkey since last week.
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
I see, so parser always sets both "order" and "mode", regardless of whether they are set by the user. But what if we only go through the java api, use a plain builder and set "reverse = false". Translated to json this should give us "mode = MIN", but only if not explicitely set by the user otherwise, no? Sorry, haven't got a good solution myself so far either.
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
@s1monw I'm sorry that I didn't take any time to reply last night. The situation with the response parameters is quite complicated. Look for example at `Settings#toXContent`. The situation here is that the `flat_settings` parameter is consumed there, but the signature `ToXContent#toXContent(XContentBuilder, Params)` is a general signature, we can't just go and add a boolean parameter for flat settings to the interface because it doesn't make sense in all situations. It is for this and similar reasons that I ultimately handled response parameters the way that I did. Barring a redesign, I would prefer that we remain consistent for now. > It's just yet another place we need to maintain and look for params. Right now it is how we handle output parameters.
This is one way to do it, but I'm wondering why you opted to do it this way instead of using the infrastructure that exists for handling response parameters? Namely, override `AbstractCatAction#responseParams` (being sure to include the response params from super).
This isn't where I would expect it to be consumed since it affects the output only, not the request handling.
Now that I'm seeing these, I wonder if the default names should be `attr` and `value`. We could add aliases if we need longer. Since it's such a small API it's probably fine with the short versions.
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
The `withPassword` method is called every time we need a password, even if it's being used to _read_ a certificate file. In that case we don't want to print this warning, because that would cause additional output (and an additional prompt) for simple things like reading a CA file that has a long password. We need to only perform this check/warning if the password is being applied to a new file. I'm OK if we want get rid of the `promptYesNo` and just print out a warning, but we only want to do either of them when we know the password is being used to _write_ a file.
Having through about this a bit more, I think the _prompt_ is going to be annoying rather than helpful. I think we'd be better off just printing out a warning message, and continuing on. Sorry for messing things around like this, but sometimes things become clearer during the review cycle.
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
I think it can be even less in tests. No one is worried about sending multiple requests there.
can we make this configurable? also 500 millis is way too small and will busy spin. I guess 10s ? (the real solutions will be to have long polling, but that will come later).
can you assign the key and the value here before we use it? it's way easier to read
this will result in wrong counts even though it's volatile. We should use an atomic long or sync this block
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
can't we just call this feature `trim`? `trim` personally makes more sense to me.
can we just us a `Map` here instead of the guava one
Note that this is different than setting a single property as it adds the inputs to the list.
The method was not named as a setter in groovy so this could be DSL-like. ie, usage looks like (notice the lack of equals sign): ``` noticeTask { licensesDir 'foo' } ```
no need for a constant here, you can use `StandardCharsets.UTF_8`.
I would prefer we use something like `Files.write` where we can be specific about the encoding. `FileWriter` will rely on the default encoding, something we generally try to avoid.
```suggestion public void setFile(File file) { this.file = file; } public void setFile(String file) { this.file = getProject().file(file); } ``` Along the same lines as above to avoid the use of Object.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
s/payload is/payloads are
The `Coordinator` becomes leader in `joinHandler.test()` not in `handleJoinRequest`, and that's outside this mutex, so it's technically possible that it could become a candidate again before this synchronised block.
This definitely feels like overkill now the `JoinHelper` is mode-aware and its mode is in sync with the coordinator.
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
Should really ask for `toString()`s on these handlers too, although this adds noise.
maybe put this check before the primaryTerm check
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
Why is this `volatile`? It doesn't look necessary to me.
it makes it too easy to call delete when its not necessary.
`super.readBlock` instead of `readBlock` to prevent double `maybeIOExceptionOrBlock`.
this does not change anything here? We are already catching the `NoSuchFileException` in the line below, which is an `IOException`.
This is where a safeClient() would be helpful, so that you have less chance that the underlying storage instance changed between the copy and delete calls
Do we really need to also duplicate the typed_keys logic here? Can't we just print out the name of the parsed aggregation (it can be initialized with type#name)
I understand. But this requires to grab back the type and delimiter where initializing the parsed aggregation directly with the name "type#name" would allow to parse back the result too. Also, in a client side point of view, the name is "type#name". But I'm nitpicking, we can change this later if we want.
nit: we can check the expected token and then create the searchProfileResults map
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
Error if old-style params passed alongside new-style script
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
then check for non null here...
To coerce, should be: ``` parser.longValue(true); ```
same here: ``` parser.longValue(true); ```
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
can we add some more info about what expected found and the field name? maybe "expected a simple value for field '..' but found a [TYPE]"..
is this needed here? I think it does something only when the current token is start array or start object.
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
maybe just inline this into the `planIndexingAsNonPrimary` method? I think that would be cleaner.
random drive by question - why is the primary term part of the index result? it's already part of index and index result is supposed to capture the dynamic things that the engine has assigned.
I see. The seqNo and the term do not necessarily always go together. the seqNo is the location of the operation and the term is the authority to put it there. I like the fact that the result object only contains the things that the internal engine creates / changes. Seq# are owned by the engine (on a primary). Terms are owned by the shard. I would prefer to remove the term. At least in the example you gave (`Translog.Index#Index(Index, IndexResult`) it's readily available from the index operation.
I think you should inline this into `planIndexingAsNonPrimary` then we don't need all the asserts
can we rename this to `boolean isCanceled()` and then instead of the exception just return a boolean? I think it would be more intuitive and we really don't need yet another exception
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
nit: can we add the timeout value here.
I wonder whether we should use `unicastConnectExecutor` for this and keep it contained (and throttled).
Actually plugins can implement `Closeable` and they will be closed when the node shuts down.
Same concern regarding the leniency.
Nit: addresses -> address
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
this is not needed. createIndex automatically reroutes.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
I think we can check also randomly on a shard that relocates _to_ the local node
It would be worth requiring that `jobId` and `jobType` are not `null`.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
I think an exception other than an `AssertionError` will stop the busy loop. So if an `IOException` can be thrown that _shouldn't_ terminate the busy loop then it needs to be caught here. But maybe there isn't.
create does an inline reroute, so you can check directly here that no shard is assigned. No need for timeouts
exiting -> exists
I think this would be cleaner as ```java aliasAndIndexLookup.compute(aliasMetaData.getAlias(), (aliasName, alias) -> { if (alias == null) { return new AliasOrIndex.Alias(aliasMetaData, indexMetaData); } else { ((AliasOrIndex.Alias) alias).addIndex(indexMetaData); return alias; } }); ```
Perhaps add the duplicate size to the assert message here
whoops I read it backwards, so yeah, not really necessary
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I think we should have a dedicated method for this in IndicesService. ``` public FieldStats<?> getFieldStats(Engine.Searcher searcher, String field) { // do the caching in here and also lookup the MappedFieldType again! } ``` this way we don't allow everybody to cache whatever on our request cache!
We should be writing out the settings in the "new format". There is no longer index_analyzer. So in the case of search_analyzer being set alone, when we serialize, we should write both analyzer and search_analyzer.
You can simplify this to: ``` boolean writeSearchAnalyzer = // logic if (writeSearchAnalyzer || analyzer logic) { // write analyzer } if (writeSearchAnalyzer) { // write search_analyzer } ``` This will also keep the same order (analyzer followed by search_analyzer) that we had before.
can you use `== false` instead of `!`
I'd go for either check in the constructor or here.
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
much cleaner. thx.
I think enforcing this as a List of `ShardLock`s would be better, type safety wise
minor typo - "indexes shards lock" -> "shard locks"
good lets do that
is this somewhere on a todo? I'm afraid we'll loose it
nit: can we use the "without" terminology? I think this better matches other code like the builders for java time stuff having eg`withTimeZone`. Drop implies mutating the current object.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
Note that you can use Objects.hashCode(function) directly which will make sure to return 0 if the value is null.
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
we could pass a glob with regex:xxx to newDirectoryStream if we want
This many levels of nesting hurts my head! How about refactoring the inner half into a private `findShardIds(@Nullable String index, Path indexPath)` method so it's easier to read? I'm worried about the potential for future typos for anyone else touching this code
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
confuses the shit out of me everytime :)
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
Also we should wrap the `-` in `{@code -}`
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
These should all be wrapped in `<pre>` or `{@code ...}`
yeah nevermind I was confused about some internal classes
But yeah, keep it now.
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
Not important, but couldn't this just be an array? String[] possiblePathValues = {"some_path", "anotherPath", null};
nit: these could probably even be package private
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
The shapeFieldMapper seems unused here.
nit: formatting, add some whitespaces
nit: formatting, add some whitespaces
you are right, sorry
maybe expectThrows would be easier.
Exception e = expectThrows(Exception.class, () -> doSomething()); assertEquals(e.getMessage(), containsString("bla"));
I tend to like expectThrows better for doing this.
don't prettyprint please we don't test this here
this should happen after we update `isSecurityEnabledByTrialVersion`
got it. Thanks.
I meant that we can have the if clause once in `Security.java` and call `check()` on all the checks (or the one `check()` if we decide to implement `FipsChecks` in a simpler manner ) IF `fips_mode` is set
Depending on other changes/suggestions, we should probably conditionally apply the FipsChecks if FIPS_MODE_ENABLED already in `Security.java` so that we don't have to check the settings value each time.
Alternatively we can move this logic to the `beforeRefresh` method as this is the only place it's used at.
sure, or just make it `[foobarbaz/0/mynode]` or something, `[foobarbaz//]` if there is only one or something
It's minor, but we usually lowercase exceptions and elide ending punctuation
It drives me bonkers that this is called "scroll" everywhere instead of "scrollId", but it's a matter of taste, no impetus to change it if you like it :)
super minor, but indentation is off here
Maybe this was already covered somewhere, but is `GENERIC` the right threadpool for this? (I don't have a better suggestion, just asking)
++. Maybe also add a sanity check that a get on the doc at the end gives us what we expect? (deleted or found)
you evil person :)
I presume this is still in progress? (which is fine)
we do this so often. I wonder if it's time for a utility method.
strictly speaking I think we need to read this from disk after the flush - i.e., make sure that what's on disk is OK.
I think this assumption is pretty broken. What if the type is `null`? We don't define any order in the types when they are specified in the URL but this code assume that there is an order. I think we have to make this explicit which type should be used.
as discussed over voice we should really try to disambiguate and barf if we can't so no index should trigger and exception asap
I don't get it sorry :)
oh I see I think we can just use the mltQuery.getAnalyzer() instead since it will resolve the fieldname. so you can just do ``` Analyzer a = fieldsAnalyzer.get(fieldName); if (a == null) { a = mltQuery.getAnalyzer(); } mlt.setAnalyzer(a); ```
You can remove the `hasResponseFromRequest` method - it is not needed anymore.
we don't count shard not allocated / not started/ closed etc. as shard failures - see Search logic. This will end up as a difference between total shards and shard failed. The reason is that there is no way to distinguish this case with the one that our cluster state said they were unassigned.
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
also, can we remove the boolean return value from doStart and remove the timeout handling from the public void onTimeout(TimeValue timeout) method of the callback given to the observer in line 245? just call doStart.
can we use `== false`
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
can "printer" be null? I don't think so, but maybe guard agains it in the ctor.
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
I see now... yea it's odd here cause this query has a single float field, looks better on more complex queries (especially cause you don't really see that among many fields)...
yes my reasoning is that a compile error makes you think about validation rather then forgetting because there's a default empty impl that does no validation. I tend to prefer an empty validate in all queries that don't need to validate, although that's verbose. Plus that is what we do with ActionRequest as well.
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
actually I just got a bit confused because both classes are in the same file...
I find it confusing the we have the same field names for this in both ReplicationPhase and PrimaryPhase.
can we use `== false`
I hope jit takes care of this to be honest
just a nit, can we move the `initialRecoveryFilters != null` first since it might be able to skip the lookup then
This predicate can be simplified to `(count, limit) -> count > limit`.
oh nevermind, I just found the method that called it with null :)
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
I think you can change this to a `Supplier<Analyzer>` now.
Ah! I get it now. LGTM
I think it'd be nice to remove this second ctor so we're explicit every time.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
acceptDocs will be checked _before_ these bits are checked anyway
Fine with me.
Maybe throw error here it `nested_filter` is the only allowed option here.
As mentioned above, maybe we don't need this here.
Yes, sorry for the confusion, I remember the discussion now. Maybe just rename then, although `elementName` is also fine.
I would add an `assert this.context != null` here just to make sure
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
+1 to have `fromXContent` and `parse` be static
"just created files" <- what do you mean exactly? if one waits 2h they will be able to read it? if not I would just go with "the permissions on the store don't allow reading"
Is the version needed? I don't see it being read here.
this feels weird to have this here (concerning whether we should delete data of closed indices , on master nodes - I feel this should be made higher up). It is a different change though... (and has nothing to do with your change).
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
I think we should make sure that the String that is used as Id in serialization gets treated in a special way, also in the builders themselves so they are not accidentally changed between versions. Thats why I liked the old `getWritableName()` (that seems to be on its way out). Maybe we should even have an own class `QueryId` which simply wraps the NAME string constant but forces us (and users implementing their own queries) to think about this as a special case. We could change the existing `String getName()` method in `QueryBuilder` that currenty just forwards to `getWritableName` to do this. This is just some thought for discussion, nothing to block this PR though.
To me, this logic should really be in `IndicesQueriesRegistry` so we construct the registry with just the `Settings` object and then call a `registerQuery(ParseField, QueryParser<?>)` method which unpacks the `ParseField` and adds it to the registry map. That was the registry is dealing with how to internally structure the data and the internals can be easily changed later without affecting outside code.
Hmmm, I do see what you mean. Personally I would still prefer the register method in the registry but I think this is a personal preference thing rather than a substantial concern so I'm happy to yield on it :smile:
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
if we only use all names to put things in the map we lose all the deprecation warnings that we might have etc. we should rather keep track of the original ParseField and call ParseFieldMatcher#match.
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
I'd say yes... if you want to be able to parse script as a string, you want to be able to serialize it as as string. I believe serialization should be symmetric - you write what you read. For this reason, I believe the script type should be nullable. if you read a script like a string, the read state should be preserved for the writing.
this new exception is going to trigger errors too if we try to serialize it to an older node
I think s/lang/defaultLang/
Fine by me.
this change requires going over all the places we use `equals` in ShardRouting....
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
hmm no idea really need to think about that one? should this be a //nocommit
Maybe let's just call Objects.equal(script, other.script) for simplicity? I know you did not introduce it though...
is this somewhere on a todo? I'm afraid we'll loose it
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
oh man that class is a nighmare. really I just realized how fucked up this is grrr.
I also wonder if we can trash this method then altogether a make `GatewayAllocator implement ClusterStateListener` and add it to the `ClusterService` once constructed or maybe inside the ClusterService...
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
How about building a set of invalid keys and adding them all to the exception? This would be a little friendlier to a user with multiple secure settings
This worries me a bit as this is inconsistent with the filters and ranges aggregations.
this needs to stay because the method can be called from any other class, it's a public static method....thus validate might not be called at all before calling this method.
you don't need do handle queryName yourself anymore, nor boost
we should add ClusterService and IndexNameExpressionResolver to IndexQueryParseService so they get injected. Then this method could pretty much be moved to INdexQueryParseService like this: ``` public boolean matchesIndices(String... indices) { final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices); for (String index : concreteIndices) { if (Regex.simpleMatch(index, this.index.name())) { return true; } } return false; } ``` QueryShardContext would need to expose the same methd and delegate the IndexQueryParseService
if we add a null check to the String constructor we can remote this check here given that the parser already looks for the existence of the field too.
I'd go for either check in the constructor or here.
ok, talked to David about it. We will add a note to breaking change docs.
IMO we should not handle this in here... we should special case this in `ThreadPool.java` and maybe just use `null` as the value for the queue or move the `UNBOUNDED` sentinel there.
honestly I don't think we should allow negative values here! In such a case we should maybe use a sentinel or `null` as the negative invariant. Throw a hard exception if a negative value is passed!
Maybe "units" or something.
afaics kb is not supported for SizeValue. it is "k" or "K"? Same for the other entries.
Extremely minor, but this could drop the `public abstract` part now as `interface` implies it.
Technically not an "and".
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
same - wdyt about a condition suffix/
I meant the listener we pass to the transport
also, using a non-inner class means we can free the memory (i.e. cluster state copy) rather then have them accumulate with every retry
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
yes, we can't do too much about this, so it is better be defensive here.
is it really possible that we receive join requests if `ZenDiscover#doStart()` hasn't been completed yet? this feels odd to me
this can be removed now, no? it will be cause a duplicate with the full cluster state log..
This constructor doesn't seem to be necessary.
while we are at it, can we move this log to debug? its very noisy and it can happen with join retry logic
don't drink and code ð» (same line twice)
maybe `== false` just so we don't typo it in the future
derives -> derived
before, we would ignore any IOException, now we only ignore NoSuchFileException. I think, for optional clean-up, the previous one is better.
This is where a safeClient() would be helpful, so that you have less chance that the underlying storage instance changed between the copy and delete calls
Usually we'd stick this on the end of the last line.
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
Right - RollupIT is the right place
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
nit: maybe package private, see above
maybe all the action names should contain `index_template` instead of `template_v2`? In this it would be `indices:admin/index_template/delete`. When v1 has been removed the v2 name is going to be confusing and changing that isn't fun from a bwc point of view.
should we also fail if the name is empty? maybe use `String.isEmpty(name)`
This method also does not need to exist, as you can use `this(indices, IndicesOptions.strictExpandOpen())`, and fix the validation in the other constructor.
yea Im all for not exetnding that class. And Im also all for putting things that are primitive and easily validatable into the constructors. Optionals, i think im ok with setters but i think this also deserves a wider audience to discuss.
This is a question, not a change request: What is our philosophy regarding having setters vs. immutable request objects going forward for the HLRC? I've been under the impression we preferred immutable objects, but it doesn't seem to be consistent.
(same question for FLOAT)
this method seems to be only used at indexing time, so I don't think it should accept `nowInMillis` since index dates need to be concrete dates rather than math expressions
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
I mean in the code but just noticed there was one already
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
cool thanks for clarifying!
I think this is a sign that `getActionFilters` maybe should take `ThreadPool` as an argument.
On reflection I think this means we don't need `lastCommittedState` any more.
I think this will be clearer if we say - "// precreate incoming indices and popluate them with the relevant types"
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
much cleaner. thx.
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
I think enforcing this as a List of `ShardLock`s would be better, type safety wise
minor typo - "indexes shards lock" -> "shard locks"
I see what the difference is now but I think the name needs to be changed here. Can we called this method `addPipelineAggregatorReader` or something like that since this is actually for registering the serialisation method for the PipelineAggregator itself not for the result. It's not analogous to the InternalAggregation. Likewise the `addBucketReader` method should be renamed to `addResultReader` since this is not about serialising a bucket but about serialising an InternalAggregation the same as in the metric and bucket aggregations
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
For human readable-ness, an additional field should be added, we shouldn't replace the field with a human readable version. You should be able to do ```java builder.timeField("modified_millis", "modified", modifiedDate); ``` (replacing the field names with the fields we want to use) and then you don't have to check the human readable flag yourself
I wouldn't name it in capital case because it isn't a constant. Otherwise I'm fine with whatever rename you like.
same here - we need move double starting and such to ShardStateActionTests
ver -> version
This assert message says 2 shards, but the check is for `equalTo(6)`
this can be removed now
I think this is easier to understand as it makes a 1-1 copy of the current active shard allocations in the routing table: ``` for (IndexShardRoutingTable shardRoutings : indexRoutingTable) { Set<AllocationId> activeShards = shardRoutings.activeShards().stream() .map(shardRouting -> shardRouting.allocationId()) .filter(allocationId -> allocationId != null) .collect(Collectors.toSet()); if (activeShards.isEmpty() == false && activeShards.equals(indexMetaData.getActiveShards(shardRoutings.shardId().id())) == false) { // only update active allocation ids if there is an active shard if (indexMetaDataBuilder == null) { indexMetaDataBuilder = IndexMetaData.builder(indexMetaData); } indexMetaDataBuilder.setActiveAllocations(shardRoutings.shardId().id(), activeShards); } } ```
Just wrap and rethrow and let junit report the exception.
Also, `.get()` is much more common than `.execute().actionGet()`.
This `if` is never false because `numberOfShards` is between 4 and 10
This `if` statement will always be run, so it could probably be removed
I'm pretty sure this just throws an AssertionError so it wouldn't work either. I don't suspect it'd be very likely and I think the test would fail spectacularly on an InterruptedException anyway, so maybe just log an error? You could also make some list outside the runnable to accumulate the result. I bet we have some useful thing sitting around for this if you wanted to do more than log though.
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
maybe just `esVersion()`
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
s/y ou/you Also I think upfront is one word.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
now that #30490 is in, could you replace the header argument with the RequestOptions one? In the method that accept a listener we add RequestOptions between the request and the listener though.
same here - pls refer to `current`
s/token role/token. Mention asynchronously
heh, duh... Sorry, ive been on vacation and full of turkey since last week.
It might also depend on which implementation of `AcknowledgedResponse` you are using, since we have two, yay duplication!!! You should have a look at `StartRollupJobResponse`, which is an example of changing the word from `acknowledged` to `started`. this should get you on the right track.
Maybe just handle the boolean for this PR, but we should think about removing it....
What about the case when `request.fetchSource().fetchSource()` is false? Why do we even have a boolean there? Maybe we should just use null instead? It doesn't make sense to have a `FetchSourceContext` with `fetchSource = false` and `includes = ["something"]`.
can you explain why we do this now only if `autoCreateIndex.needToCheck()`
I think we can share this line and the return new BulkItemRequest line? these two clauses will need to set a final `updateResponse` field.
can we call this primaryItemRequest? It's the one that's sent to the primary. Also, if we pass it as a `BulkItemRequest` parameter, we can avoid sending `requestIndex` and `BulkShardRequest` (from which need the concreteIndex, which I think we can from the shard). Last can we assert that the `BulkItemRequest` has as a request object the `updateRequest` we got? this is all super trappy but we can take one step at a time :)
typo: filers -> filters
I think we should stick with calling these getters like `getCharFilters` because it is the char filters that the plugin has, they aren't "extra" in the context of this one plugin.
All of the `*Plugin` interfaces we have added so far have used `get*`. I think we should be consistent.
++ to just `get*`
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
see above - I think you should add it though
actually, if its a single page, then we can just reference the first page byte array, if not, then we should return false. same with `array` and `arrayOffset`.
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
I like this way more anyway
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
+1 to capture `System.nanoTime()` at the beginning of the method
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
Yeah, I think we can collapse both deciders into one here - it will make things simpler. Call it RecoveriesAllocationDecider that is incharge of all recovering shards (replicas and relocating primaries). It's good to do it in a different PR imo..
we shouldn't need this here in parse phase
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
one step further: I think we could deprecate/norelease these two parseFilter methods and make sure that our refactored queries don't use them, cause they have been moved to toFilter in the corresponding builder.
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
I would add an `assert this.context != null` here just to make sure
can you explain why we do this now only if `autoCreateIndex.needToCheck()`
Ok - I see where it is called. These checks are a bit too distant for my taste.
> This method is private and only ever called from a single thread so there is no need to recheck. I'm just weary of having the failure handling case so far from the success case. I figure its harder for someone to break it if its closer together.
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
We typically do this light weight coordination on the same thread. I.e., Names.SAME . This does nothingother than spawn another bulk request. This will cause a new thread to be spawned as we don't do anything else with the bulk pool on the client. To be honest, I don't think the transport client should have so many thread pools. I'll open a different issue for that.
This line will break our `precommit` checks because it violates the 140-character line-length limit.
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
fine with me as well. go ahead and push!
I am good with both options.
My motivation is both making it so there is one obvious way to calculate distance (I was reminded recently of this beatiful mantra from the Zen of Python: `There should be oneâ and preferably only one âobvious way to do it.`). I also think not having instance methods will allow us to play more with the underlying field access so we dont need an intermediate object, GeoPoint).
well maybe you don't like the success pattern though... but I think it should be closed even on Throwable
can we init this with `1`
can we hide `shared.refcount` behind a method ie. decRef() / incRef() to be consistent with other stuff
> I have just moved code around, so this implementation is not new. Fair enough. I'd still log a warning just to help debug any mistakes in the listener. If all goes well and the listener catches any exceptions then we will never call it.
Is it right to just eat the exception thrown from the listener? At least log a warning or something.
Oh this is tricky! Could we use `null` here instead? I'm not a big of making a `Script` that no one can compile. It'll have stuff like `engine=painless` which is isn't.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I think s/lang/defaultLang/
this new exception is going to trigger errors too if we try to serialize it to an older node
Fine by me.
You won't even need the guard if you are just merging to 3.0.0, right? 3.0.0 doesn't have to be wire compatible with 2.x
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
can we use getters here like `getNode` `isCanceled`
Elasticsearch tradition is to make this an EMPTY constant :)
drop the actually? sounds so "uncertain" :)
`String.format(Locale.ROOT, "%s operation term [%d] is too old (current [%d])", shardId, term, primaryTerm)`
I didn't look at other users of that method, but +1 ! this boolean annoyed me for a while :)
everything in here just uses the state maybe we only pass the state to the method instead of the ClusterChangedEvent
in the case of createIndices, this should send shard failed for the shard routing that triggered the index creation, but it doesn't because the indexService is empty. I think the interaction with shard failures is too brittle/tricky. My suggestion would be to just return an exception on failure and let the caller deal with it in the right way. PS - maybe this signals a testing gap as well..
applyDeleteIndices -> deleteIndices
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
This is going to be very funny for term vectors because `fieldText` is empty.
I think we usually prefer a space after `if` and before `(`.
I like dummy because it implies fake and the index is fake - not just empty.
This should only be done in close()
should be `logger.debug("...", e, shard.shardId())` :)
actually I just got a bit confused because both classes are in the same file...
I find it confusing the we have the same field names for this in both ReplicationPhase and PrimaryPhase.
Nit: `"call back"` -> `"callback"`
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
My preference would go to adding a serialization context to readFrom.
I understand this, but this sound confusing to me. You would have some member in each builder that is only set for the prototypes, need special constructors for the injection. I understand your proposed solution with the static method access much better.
well then you have to have a dedicated parser interface - I wonder if this is a general thing we should have on stream input though
I think saying that it should not be allowed in the query DSL is a bit misleading, cause it is allowed and we parse it properly. I know what you mean though and why you wrote that, I need yet to come up with a better explanation for this...
maybe call this readDiffAndApply? this doesn't really read a diff and return it.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:918E10886BC43EC1]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.LineStringBuilder.<init>(LineStringBuilder.java:49) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiLineString(GeoWKTShapeParserTests.java:112) ... ```
nit: formatting, add some whitespaces
> Would you do this just when it is overriden (ie not the default)? Or at all times? What about if they explicitly select netty in their settings? Anything but the first is not a one line change. Yep. Log all the time. > I don't think we should just willy nilly log things > I don't think this is useful. It saddens me that this takes so much effort and discussion. It is also sad that there is no constructive discussion but rather these yes/no statements. As I said, I find it useful, for the reasons I mentioned. That should be enough for this kind of change. I'm signing out of this now. I don't think it's constructive anymore.
I think it's important to know that the transport system is replaced and that the settings have effect. This also has security implications, as plugins can add settings. I think this should stay an info log like it was. Adding something similar to the SelectedType is good but over there debug is the right call indeed - it may be used for many things.
oh, I see. It felt like a utility class but it's officially a bless thing. Thanks for pointing it out.
how about preparing the scene and have two methods - registerRestHandler and registerCatHandler? the latter can accept things that extend AbstractCatAction and the first can assert the parameter doesn't inherit from AbstractCatAction and throw the right exception.
ok, sure. I thought you liked the separation. This works for me.
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
`min_version` is the earliest version of the product that can read the model snapshot. This is for the autodetect process to protect an older version trying to read model state with new features it is isn't aware of. For informational purposes only and shouldn't be set by the client. We don't have any APIs that accept a `ModelSnapshot` doc - update and revert use the ID- so I think we should leave this in.
It could be useful for debugging too. In the future it's conceivable that the support diag tool might use the HLRC, and we wouldn't want to be dropping this value.
I've noticed this field isn't in 6.x so please remove from the backport
This should be a `ConstructingObjectParser` so that the private empty ctr can be removed.
can we debug log the default? also leaning to have info the "non default" setting, thats what we try to do most times in other components to try and keep the startup logs clean and informative.
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
This could be `Strings.hasLength(tokenizerName)`
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
ok...but client depends on the transport service anyway no? I think I don't get it
I'd say it's fine with IAE
but why? :)
can you add a small introduction about what this is? e.g. Parser for terms query and terms lookup
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
To be clear - I think we want to know how the oldest file is, regardless of the generations. It will always be the oldest generation and the first in the reader list, but I don't think we want to rely on it. Part of the role of the stats is to validate things are correct.
Can we add a Math.max(0, currentTime - Math.min()) ? we rely on this being non negative, but time may go back and the FS may have other quirks.
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
+1 I like plugin examples!
`client().prepareIndex(...` is more normal now.
This shouldn't be needed anymore. By default we wait for the index to be created now.
you can simplify this a bit here: ``` Java NodeStats unluckyNode = randomFrom(Iterables.toArray(nodestats.getNodes())); ```
I think you should implement this in an awaitBusy block ie repeat until you see eveictions but never wait longer than 10 sec by default.
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
[{}] for path.
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
I think enforcing this as a List of `ShardLock`s would be better, type safety wise
Please revert this change.
it would be awesome to have some doc-strings on these settings
Space after the equals. Its a silly small change but it helps my eyes.
no need to make this public; package-visible is good enough.
oh nevermind, I just found the method that called it with null :)
It is called pluginId in install because it is an identifier, which _may_ be a plugin name, but it also may be maven coordinates or a url.
No, it should stay "id" in the message because plugins are installed by id (with the exception of some special plugins that can be installed by name only). Yet "name" is fine for removal because plugins are removed by name.
No need to squash, we can do it on merge.
The indentation is off here.
In fact, it should probably say something like `Remove the plugin specified by {@code pluginName}.`
I think I missed the discussion but why isn't all this (this method and the next two) part of BaseNodeResponse's toXContent implementation? It can declare an abstract method that the subclasses can override for their own xcontent? We use that pattern pretty frequently with things like the query builders.
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
Yep, this looks great
we should totally not have this method, one more reason to not implement the interface.
I would probably throw an exception instead of accepting null here.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
I think this should happen first to make this PR less complex
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
We should catch any exceptions during the cancel and log them so we can continue to cancel any other handlers? Otherwise the first exception will cause us to bail
It is to make sure that the version comparison logic orders alphas, betas, and RCs correctly.
add a whitespace after the if and before the parentheses
ie. when showTermDocCountError is true
Yeah, I think the problem with the test here is that we don't make sure that nothing is left in the stream after we read it. That's why we didn't catch it here.
+1 too - I never noticed these tests...
is there a way to filter out the index metadata here? We just want the global metadata.
Since `getSnapshotInfoInternal` (just below) is only used by `getSnapshotInfo`, we can move the code in `getSnapshotInfoInternal` directly into `getSnapshotInfo` and get rid of `getSnaphotInfoInternal`
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
Are there other files that might not be in there and we're ok with that? Should we log a warning or something? I suspect its just fine for the directory not to exist but if some file inside the directory doesn't exist when the directory does thats probably bad. Like, in production. In tests is fine to just eat the exception.
we could pass a glob with regex:xxx to newDirectoryStream if we want
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
Doesn't actually throw `IOException`.
looking deeper, I see that we set a non null TermsLookup object only when we have it in query, which causes a validation error when values are set too. We should keep it that way then, this is as good as it gets.
I meant that other way around, not in the else, set termsLookup only if values == null
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
1+ portCounter.incrementAndGet() % 9 ? (now we have a collision for 10 & 11 )
why not round robin on this? I think the randomness still allows us to have collisions and will keep us wondering. +1 on the insight that suite and test scope don't co-exists! Also, this makes us one step closer to using it randomly in our global cluster scope.
The max TCP port is 65535 , min 30K gives us ~30K or 30 JVMs.
it -> is (existing typo)
I think this is a left over.
We can remove the `!` if we reverse this if statement, so ```java if (difference.isEmpty()) { status = RestStatus.OK; } else { ... the error stuff ... }
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Under what circumstances would the mappings for an index be null (as opposed to an empty map)? It seems the default for `GetIndexResponse` is to always have an empty map for mappings (and aliases and settings) and it would only get assigned to a non-null map.
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
nice! I like this. super helpful for keeping track
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Well, I think this needs to be fixed here. There is no index created version in field data settings, this is an artificial thing that it sounds like you have added to workaround some other issue.
you can maybe use `StreamInput#readList()`? like `in.readList(in::readString);`
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
new is not possible with an older version...
I think we should remove this if, call deepCopy recursively in any case, so that the main else works in this case too. Again being paranoid, I know...
do we need ordered things? does order help anywhere? If not I would just use HashMap
are we sure we want to silently go ahead this way when templateService is null? Maybe we should fail so that we find out when it happens, unless it's situation that is actually expected to happen.
Since the index and the Map are associated, how about using only one `Deque` which holds a `Tuple` instead of two `Deque`: ``` Deque<Tuple<Map<String, Object> index>>` queue = ... if (node instanceof Map) { queue.add(new Tuple<>(node, Integer.valueOf(i)); } ```
Autoboxing already happens and I wouldn't worry to much about it considering the depth is not that big. Same for `Linked` vs `Array` (in general arrays are faster except for inserting in the middle as that requires resizing/copying at which the linked structure excels). I think the `Tuple` makes the code a bit more compact and safe (the queues cannot get out of sync) and more readable/simple code always trumps optimization (especially micro ones as here).
space after `,`
I think you can just initialize to null
we have a test util method that we use to shuffle fields in the response so we make sure that our parsers don't rely on specific keys ordering.
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
Right, thanks @javanna, I've forgot this discussion. As long as it is permissive, even not tested, it's OK to be merged.
We might should move these last two declarations to a common spot something like ``` static <T extends AbstractObjectParser<? extends QueryBuilder>> declareStandardFields(T parser) { parser.declareFloat((builder, value) -> builder.boost(value), AbstractQueryBuilder.BOOST_FIELD); parser.declareString((builder, value) -> builder.queryName(value), AbstractQueryBuilder.NAME_FIELD); return parser; } ``` and then we can declare them when we're initializing the object.
I'm fairly sure I have the wrong generics incantation there....
I might use an empty array here or switch the IdsQueryBuilder work with lists.
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
As mentioned offline, I think the name `checksum` captures what we want.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
I think it is fine: we only build one search context per request per shard.
Yeah, it seems it is. We treat non existing indices as red. Thx for educating me.
I think there is a race condition here - it may take some time for the dangling logic to kick in (it's async via network calls). I would assertBusy until the index is visible in the cluster state, then go into ensure green.
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
Same here about multi-line toString methods
Here again I think we should use `builder.timeField` to handle this
take out boost and queryname once you rebased
yes my reasoning is that a compile error makes you think about validation rather then forgetting because there's a default empty impl that does no validation. I tend to prefer an empty validate in all queries that don't need to validate, although that's verbose. Plus that is what we do with ActionRequest as well.
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think filter and query can never be null here? not sure whether we should validate this here.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
replace match here too
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
can you use indexRandom? this will randomize insertion order and add some deleted docs to the index
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
should we assert that reader.getCoreCacheKey() == engineSearcher.getDirectoryReader()? Forcing the core cache key handling to be delegated to the inner reader could be trappy otherwise
thanks for unwrapping
s/can't used/can't be used/;s/their/they/;s/subtile/subtle/
clarify the error message specifying what needs to be non null? the inner query...also remove empty, doesnt make sense here
I just realize that there might be a bug in the existing code already. We only seem to add the query to the named queries if it's a BooleanQuery, the other cases return early. Not sure, but we might want to change that.
I saw this problem being dealt with in other place by setting currentFieldName to empty String. Worst that can happen then is that it is treated as fieldName in the query, which we should validate later and throw IAE then.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
I might use an empty array here or switch the IdsQueryBuilder work with lists.
can you add a //norelease here too? context should really go away after all queries are refactored
I would add an `assert this.context != null` here just to make sure
I always wondered the same, I think we don't given that everything works without... that said we do have a lot of empty constructors with the `@Inject` annotation. Up to you... ;)
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
I think s/lang/defaultLang/
Fine by me.
Maybe this one too, I'm not sure.
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
actually, you may not even need the array here.
I am not sure that this test is that useful. I think that these two bytes reference objects are even equal when compared directly so they don't need to be compared using assertToXContentEquivalent. We should rather test that order doesn't matter by shuffling keys and/or verify the behaviour of assertObjectEquals .
I see, and you are right, camel case is preferred. I probably misread the "NoNestedDocs" part of the name as "no nested docs" and that confused me for a second, but either way is fine.
just as feedback, nothing to change really, but I liked the previous variable name better ;-)
Should we also have tests for the case that some intermediate mappers already exist? For instance above you are testing to index a field called `foo.bar.baz`, so it would be interesting to check that everything also works if `foo` already exists.
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
oh oh I hadn't read your reply when I replied ;)
I wonder if this should rather be made part of Request#multiSearch like we did for bulk. I see that it may be nice to have read and write methods close to each other, on the other hand the only place where we need to write this format is in our client.
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
nit: extra newline
Missing a space here after `id`
You won't even need the guard if you are just merging to 3.0.0, right? 3.0.0 doesn't have to be wire compatible with 2.x
should this listener be volatile? I also wonder if we should fail / throw an exceptin if the listener is non-null when we try to set it? -- there is a nice class in lucene called `org.apache.lucene.util.SetOnce<Listener>` which does that for you
can we use getters here like `getNode` `isCanceled`
can this see `unregister task for id: [{}]`
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
this can be out of if now.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
ok now i can see that it is null when removing the task, sorry for the noise
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
I find that `equalTo` is almost always a bad choice. In this case I think `assertThat(cancelTaskResponse.getTask(), hasSize(1));` will do the same thing but have much better error reporting. That way you get to see all the tasks when there are too many. Same for the above assertion.
+1 I like plugin examples!
super nit: I tend to like validation to be first
Is this any quicker if you use bulks? I tend to do that out of habit.
nit: space before instanceof
nit: space before instanceof
I think we can do this more simply by looking at `endsWith(".jar")` of the uri string. We don't really need to convert the uri to a path, since we don't need to load the file. Then, the original if statement can simply be wrapped with like: ``` URL location = clazz.getProtectionDomain().getCodeSource().getLocation(); if (location.toString().endsWith(".jar") == false) { // original if and exception here } ``` Basically, if the file is in a jar, we don't need to worry about it here, as those would have already been added to the codebases map by `Security.getCodebaseJarMap`. This method is about adding classes that are on the classpath, but not via a jar (ie built by the IDE).
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I think this would be cleaner as ```java aliasAndIndexLookup.compute(aliasMetaData.getAlias(), (aliasName, alias) -> { if (alias == null) { return new AliasOrIndex.Alias(aliasMetaData, indexMetaData); } else { ((AliasOrIndex.Alias) alias).addIndex(indexMetaData); return alias; } }); ```
nit: extra space
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
assert for verification whether it is created
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
We also need a simple rest test, testing integration like we have for the other processors
The `new HashSet<>()` can be replaced with `Collections.emptySet()` (and then you'll have an import to remove).
It defaults to `false`. :)
Let's also make this a JUnit assertion instead of a Java assertion.
You can get away with it right now because there is only one test, but this should be initialized once before the test suite, not once before each test in the suite.
You can just use the literal boolean `false` instead of the string `"false"`.
I think this could use the `rebalance` function in `CatAllocationTestBase`? It looks like it's performing the same function
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
you are right thanks a lot for catching this
There is a problem with this test setup that I just found: the xContentType that is used for parsing here is not necessarily the same as the one that is used int randomUpdateResponse(). So the expected values might be off, e.g. if in randomUpdateResponse() SMILE is used and here xContentType is Yaml.
While I think a common methods would be great, I'm not sure this distinction (small vs. large longs) is needed very often. In the parsing tests its good to have some more "smaller" values to catch cases where they might be parsed back as int. I wonder how a common method would be called (randomNonNegativeLongButOftenSmall?), which range to sample the small values from (that might vary between tests) and where to put it. But maybe @tlrx has some suggestion.
I am still missing `_version`, `_version_type`, `fields`, and `_parent` here we should add them!
As Boa mentioned before we would need both a default to print out, and a boolean that tells whether the current value is default or not, as the `currentValue != defaultValue` is not enough. Something like the following should help in most cases I think? ``` public static void maybeAdd(XContentBuilder builder, String key, Object value, Object defValue, boolean isDefault, boolean includeDefault) { if (value != null || !isDefault) { builder.field(key, value); } else if (includeDefault) { builder.field(key, defValue); } } ``` That said, maybe it doesn't cover 100% but 90% of the cases, and for the 10% left we can still have the custom if? In my opinion it doesn't need to be perfect but still better than copy pasting that `if` so many times.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
I think this declaration/initialization can be moved to inside the if
can resolve possibly return null? if so we should check for it
the important part is having multiple open readers on this as well.
we also need unittests for these queries!!!
I would leave it as-is, it needs to extend BaseQueryTestCase
why do you pass the response to this method? `this` already has all information.
remove "or timing out".
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
I don't think we need this part? Even if you've created an index with 6.4, you still want to be warned that things are going away if you upgrade to 6.5
No, that's fine.
This is only used in the constructor, doesn't need to be a field.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
I think we should extend our cloud integration plugins to add some kind of a stable identifier as a node attribute (if not already doing so) and auto-configure this setting to it. /cc @dadoinet @tlrx
depends (which is why I asked). If it's about API bwc I think we should break it and be clear about the impact of the version. Which is also makes me think we should not render the field if we don't have a version (because we removed it)
Wondering if this could be abstract, so subclasses don't forget to implement it. Looks like many would have an empty implementation though, so just a thought.
What about : ``` json "retries": { "bulk": 0, "search": 0, } ``` Note: I tend to like JSON inner objects since clients and parsers can skip whole objects while parsing...
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
this setting should probable `componentSettings.get("page.type", ..)`, which resolves to the full setting of `cache.recycler.page.type`.
also, the setting should be using `componentSettings.get("page.limit", ...)`, so it will resolve to `cache.recycler.page.limit` (and I think the in_bytes usage here is not needed).
Why not public? Will make reflection faster for guice.
Gotcha, thanks for the explanation!
I think we have at least one similar test that does the same, we can maybe share the dummy client to minimize the code repetition. It's not that we cannot use mockito, we could, we would need to have a bigger discussion around it, some people are in favour of that and some others are totally against it. I personally don't think mockito would solve all our problems, we should strive to make elasticsearch more unit testable, easier to say that to do though :)
cool stuff I didn't see that one!
can this be final
could be a instance variable, as used in all tests
Since this is static, the name should be `THREAD_POOL`.
Can you change the line wrapping on this somehow? Like stick `new InputStreamStreamInput` on a new line and indent it? I think as is it'd break how I visually scan try-with-resources.
I think I'd rather stay on the safe side
thanks for unwrapping
maybe add the type that is found in the error message with fieldType.typeName()
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
This doesn't look right to me. If `subPath.path` is null, or if `seenDevices.add()` returned false then we don't call `seenMounts.add()` despite having seen the mount point in question.
we could pass a glob with regex:xxx to newDirectoryStream if we want
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
This many levels of nesting hurts my head! How about refactoring the inner half into a private `findShardIds(@Nullable String index, Path indexPath)` method so it's easier to read? I'm worried about the potential for future typos for anyone else touching this code
I wonder if it's easier to move the "check if there's only a left-over `MetaDataStateFormat.STATE_DIR_NAME`" logic into the `if (FileSystemUtils.exists(path)) {` condition above. Then you won't have to remove stuff again from `existingPaths`.
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
+1 to have `fromXContent` and `parse` be static
Since `value` internally is a String now, we can change read/write here as well.
sorry, my bad.
we set the rewrite method twice it seems? probably a bug in the original parser
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
and i guess where we instantiate singleton, we just let Kernel32Library be null if it cant load? I dont know if its cleaner actually, it means callers woudl have to check for that. i just think its wierd to have all methods have to check isLoaded and do nothing. Currently there are only a few, but if the class increases...
can we change this to Loggers.getLogger(getClass());? it is what it should have been to begin with, which is my fault ;)
`} catch (IllegalArgumentException e) {`
This thread can leak and fail the test, I think that you need to clean it up (join on it in tear down).
we throw the exception and thus take care of the interrupt. We don't need to set it...
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
I think I saw this in Christoph's PR too. Hopefully you don't need it.
I don't think you need @Before here, the parent method already has it.
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
+1 on removing it
I think that it's cleaner to write this as: ``` ElasticsearchParseException ex = (ElasticsearchParseException)ExceptionsHelper.unwrap(e, ElasticsearchParseException.class); assertNotNull(ex); assertThat(ex.getMessage(), equalTo("processor [test] doesn't support one or more provided configuration parameters [unused]")); ```
Maybe: ``` java Exception e = expectThrows(IllegalArgumentException.class, () -> RestAnalyzeAction.buildFromContent(content, analyzeRequest, new ParseFieldMatcher(Settings.EMPTY))); assertThat(e.getMessage(), startsWith("Unknown parameter [token_filter]")); ``` That way you don't have to assert the type of the exception.
Maybe call this "testEmptyBoolSubclausesMatchAll()"? Sorry if I misunderstood what the test is doing, I just think having a github issue number in the name is unhelpful to someone if they see a failure.
I don't think you need to divide at all - randomDouble is between 0 and 1, I believe.
I think we should collapse the two above methods, they are always called in sequence.
can we rename it to something like allNodeResponded ? we're not sure we're going to delete...
I don't think we need all these counters? we can have awaitingReponses which goes to 0 and a activeCopies one that goes up. We stop when awaitingResponses reaches 0 and delete when activeCopies is what we expect
I think we should encapsulate the testing code from the `clusterChanged` method and just call it again to sanity check it's safe to delete
can we call this ShardActiveResponseHandler? (and the derived family should be renamed as well)
I don't think we need to go to all the nodes in the cluster. Just the nodes that host a copy of this shard.
This needs to be another method (`parseInnerFilterToQueryBuilder`) which replaces `parseInnerFilter` and also takes care of switching the interal `isFilter` flag.
ok lets get this PR in and address this problem separately, I think we overlooked this when migrating the bool query. This check should be moved to the toQuery method. We should start looking into dividing the context into a query parse context and a to query context I think
other question, sorry! but I still find this confusing... previously we had null here for two situations: 1) empty filter/query 2) queries that after getting parsed would become a null query (their parse method returns null) the first case falls now under the EmptyQueryBuilder case, which we handle here. But there can still be queries whose toQuery returns null, which need to be ignored, but that we know only in the toQuery, but we still set the minimumShouldMatch only based on case 1). I think setting the minimumShouldMatch like should happen later in the toQuery, which kinda makes sense, it needs to be done only on the resulting lucene query, not against the query builder. So we can potentially add empty query here to the clauses as long as we move this check for null should clauses only in the toQuery method, if that makes sense
yea I meant leave as-is and open new issue :)
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
any chance we can remove the interface and just name this class NioChannel
there is only one impl
I'd return a dedicated return type not a tuple.. tuples are ugly on these interfaces introduce a new class!
I know that this is how it used to be but we add an explanation that this is called before the index is added to the cluster state? created is misleading.
solely based on names, hard to distinguish from `testRebalanceNotAllowed`
I guess that's not encapsulated into the message, so it's hard to check huh..
I would use the following message: "ignored as shard is not being recovered from a snapshot" and not have an explicit check for `shardRouting.primary() == false`. That case is automatically handled by this case too as replica shards are never recovered from snapshot (their recovery source is always PEER).
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
When getting a `searcher`, you need to keep it around, and then call `release` on it on the `finally` clause.
Once we have a `running` flag, we can check on it and not on `isAlive`.
I suggest adding a volatile flag called `running`, add a method called `stop` that sets it to `false` and interrupts the thread.
You can't create the thread here, it should be created in `start` (you can't start again a closed thread). It should also be set to be daemon, and it should have a name as well. Check EstimatedTimeThread in ThreadPool for an example.
I think we can go with a higher bulk size, because we only do deletes. Something like 5000 or even 10000.
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
would be great if this logic could be unit tested.
I think filter and query can never be null here? not sure whether we should validate this here.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
formatting, 1 line instead of 2
formatting - 1 line instead of 2
can this be in try-with logic.... you are not closing this input stream at all
I wonder if we should enable this only for new indices that we know are created with es 1.4
same here re enumSet.toString
Remove and create again is not needed I think
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
I was only talking about the context _path_. But what you have is fine for now, the entire class really needs a rethink. :)
I would also like it better if the side effects of this getDynamicParentMapper were limited to just dynamic field creation, and path management stayed local (so that we keep both the add and remove together in the same method).
Do we really need a tuple? Shouldn't it always be `paths.length - 1`, ie anymore more than one path piece means we had to get that many extra parent mappers? Alternatively, I had also considered adding a serialized form, ie do a join of the first `paths.length - 1` elements of path and add those as "one thing", so you are always just removing a single element at the end. I think this would work since all path serialization does is add dots between elements.
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
In a followup PR we should merge SortBuilder and SortBuilderParser, I think. The latter one was only introduced as an intermediate step to avoid having to refactor all builders at once. Not sure if we can add the interface ToXContent there as well then.
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I think this can move to before the threads start - will be nastier
cancel that :) I figured it out.
I wondered if there was something better than iterating too but there's not since `IndexWriter#getLiveCommitData` only returns an `Iterable`.
a transformer and performer. Quite a guy :)
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
I wanted to remove the `allowCommit.set(false)` here with an ensureOpen at the beginning of the method. Only saw later it's already there. No doubles.
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
I would add an `assert this.context != null` here just to make sure
can you add a //norelease here too? context should really go away after all queries are refactored
In a followup PR we should merge SortBuilder and SortBuilderParser, I think. The latter one was only introduced as an intermediate step to avoid having to refactor all builders at once. Not sure if we can add the interface ToXContent there as well then.
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
+1 to have `fromXContent` and `parse` be static
We should be testing serialization here by extending `AbstractXContentTestCase`. Unfortunately, that means we need to also write a parser for the request but it's worth it.
final and java docs
it's a shame java need this...
we should make this entire class package private and try to contain visibility here as well.
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
Can we call this just `score`? I've been trying to give the script context identifiers names that don't include "script" since that is implicit.
nevermind I was confused... all is good
I think it is fine: we only build one search context per request per shard.
would be great if this logic could be unit tested.
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
This predicate can be simplified to `(count, limit) -> count > limit`.
What if the user specifies 0 here? Previously that meant unbounded.
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
ok fair enough
given that the suffix is also known before we go and provide index, type, and id... (even in case of e.g. _search) I wonder if we can get rid of the list, and just provide parts and suffix as constructor argument, then convert it into string straightaway. Not even sure we need a builder for this.
Nit: maybe move this up next to the other methods (ping/exists/get) that output new Requests.
Maybe we can replace calls of this helper with the new Endpoint class? Might get a tad bit longer in the end, so I'm fine either way.
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
I think we will need to serialize this boolean flag so we can fix the problem we right now have in the readFrom
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
I think we can simplify here and print everything out, default values included, that's what we went for in all of the other queries too.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
no file? maybe IOException
maybe just `return blobMetaData.length() == fileInfo.length();`
I'd feel better if the `latch.countDown()` would be the first line in the catch block
err I guess you need to have failures added first so second...
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
I think this check should go into initializeSnapshot or repository.
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
Since `getSnapshotInfoInternal` (just below) is only used by `getSnapshotInfo`, we can move the code in `getSnapshotInfoInternal` directly into `getSnapshotInfo` and get rid of `getSnaphotInfoInternal`
is there a way to filter out the index metadata here? We just want the global metadata.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
if we do this, why did we need to change how createNewEngine behaved (i.e., update currentEngineReference etc.)
it will be good to have some kind of progress logs here (like log ever 10k ops or something) under debug.
I looked at the implications of exposing an engine that isn't fully recovered yet and it's OK, with the exception of syncFlush(). Depending how this ends up being, we may need to make sure that runs under a permit.
I'm not so comfortable with separating this code from the one in `updatePrimaryTermIfNeeded` - they are tightly connected. Instead of sharing code this way, how about creating a callback that will run: ``` indexShardOperationPermits.acquire(listener, executorOnDelay, true, debugInfo); ``` or ``` indexShardOperationPermits.asyncBlockOperations(listener, timeout.duration(), timeout.timeUnit()); ```
Nit: there is an extra space after the `&&` and before `inSyncLocalCheckpoints`
I think this is okay though, it checks if the current `zeroTermsQuery` is the same as the default, which is ZeroTermsQuery.NONE.
we frequently use randomizing client, I think that it should frequently use the default (null) preference
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
nit: not needed
this really really feels like ParseField. What does it buy us over ParseField? Sorry I may be missing it!
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
[{}] for path.
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
I think this check does not add much (I would skip it)
maybe 7 indices with 50 docs is a bit too much (= slow test), let's reduce randomness to 3 indices, each max 2 shards, and 10 docs.
this seems to be a very expensive operation I wonder if we should special case this here rather than adding a generic way of doing this.
Looks better to me but I think I'd rather like a Map<String, AtomicLong>, ideally pre-filled with every possible action name so that the map is effectively immutable afterwards and concurrency is only handled at the AtomicLong level? It would also create fewer boxed longs.
Nit: `seqNum` -> `seqNo`
This is why I said moving to compute instead of computeIfPresent so that we could assert that we do have a mapping for nodeId in that map at that point. To be clear I think that what you did is correct, I'd just like to add assertions to it to make sure the invariant is respected.
maybe mention that it is important to remove entries that have a value of zero to avoid memory leaks
maybe expectThrows would be easier.
Is this is necessary given we loop over OpType.values()? If other values are added in the future we should fail because expectedBulkItemResponse/originalBytes is not set anyway.
is it an option to make this method package private? Then it would become more of an internal thing. Thanks for addressing this!
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
This was called "path" before.
Ah CONTENT_TYPE I see. Sorry for the noise ;)
I'm pretty sure camelCase shouldn't be supported any more.
Ok great, thanks for the correction @rjernst
It was removed from ParseField in #17933. It also shouldn't be added here.
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
Do yo need the parameter `filters`? The only call of `evaluate`just uses the field `filters`.
In case you don't need the parameter, you can remove the null check as the constructor already checks that as a precondition.
+1 to have `fromXContent` and `parse` be static
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
It would also allow you to change the ``` java if (delete) { channel.deleteOnClose(); } channel.close(); ``` to ``` java channel.deleteOnClose(delete); channel.close(); ```
I think it would be better to pass a boolean in to this method, since it's ambiguous from the name of the method whether it sets a var (could be named `setDeleteOnClose()` if it were setting something) or actually does the deleting.
I only mentioned it because if we really have to keep this, then StandardOpenOption.DELETE_ON_CLOSE could be an implementation. But this one has race conditions too, this delete-on-close stuff is why Lucene's lockfactories were buggy for years. Lets defer it to a new issue, ideally we just nuke it completely.
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
also do the same in `BufferingFsTranslogFile`
Sorry, what I meant by the previous request was to do an assertion on the whole error string (e.g. wie assertEquals), unless there are any reasons preventing this.
Is this is necessary given we loop over OpType.values()? If other values are added in the future we should fail because expectedBulkItemResponse/originalBytes is not set anyway.
nit: `an` -> `a`
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
you are right thanks a lot for catching this
I also need to go back and do this for the PutUserRequest
Can we also clear the temp `charBytes` array, something on the lines of: ``` final byte[] charBytes = CharArrays.toUtf8Bytes(password); try { return builder.startObject() .field("password").utf8Value(charBytes, 0, charBytes.length) .endObject(); } finally { Arrays.fill(charBytes, '\u0000'); } ```
nit: remove extra new line
@bizybot can you open up a issue that describes this behavior of the object parser and label it with discuss? Then we can move this PR forward.
I am confused how this works when created is only within role mapping but we ignore role mapping
we throw the exception and thus take care of the interrupt. We don't need to set it...
Could you explain why you log a deprecation her? Might be missing some context, but I thought this PR wasn't about deprecation but about adding some option to the field mapper.
same here just use synchronized methods
or just: ``` java if (Objects.equals(similarity(), other.similarity() == false) { conflicts.add("mapper [" + names().fullName() + "] has different similarity"); } ```
this looks great! Can you fix the indentation to 4 spaces and also assert that the key has a `.` in it ie `s.indexOf(".") > 1` I think it's ready then. Thanks for fixing this great job figuring it out!
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
thanks @nik9000 ! @elastic/es-clients is this ok? I guess all the client runners will have to be changed accordingly.
Fine with me :) I'm already wiping the repository itself after each test, so this shouldn't have much effect (I don't think).
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
Does it need to be Writeable? It looks like we only serialize it using JSON.
maybe just `return blobMetaData.length() == fileInfo.length();`
would be nice to allow to configure it to a percentage of the heap size
@gmarz @kimchy but it is okay for them to be different simply because we allow it :) The worse case is that we kill starting with MinHeap (growing to max immediately) instead of otherwise the worse case being mlockall'ing too little.
If they are different then mlockall will not really work on unix either. That is because it may map additional stuff later!
Can we just add max(HeapInit, HeapMax) feels like a quick win here.
I would add a flush(), since we expect people to see those bytes and we want to be independent of the filesystem impl (what if it uses buffering, thats its choice)
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
check listener.isDone() as we don't expect a retry here I think
true. nevermind then
AFAICS (correct me if I'm wrong) you had to it this way because we don't know on what node version the primary is (i.e. if it is going to send maxSeqNo or not), and the shard is reset when we acquire the replica operation permit (i.e. possibly before we receive the first resync request). It's a shame because it means we can't ensure consistency for older indices. The only other solution I can think of right now would be to always send the maximum sequence number with the replication request (same as we do for the global checkpoint). We could then pass this to acquireReplicaOperationPermit (same as the global checkpoint).
I looked at the implications of exposing an engine that isn't fully recovered yet and it's OK, with the exception of syncFlush(). Depending how this ends up being, we may need to make sure that runs under a permit.
make this synchronized too. it's safer since you modify both references
How do we ensure that searches are not accessing acquireSearcher on the closed engine and switching to the new engine? Also, is there a test that checks that searches (with preference set to this node) continue to work during this transition.
> However, I am not sure if we should do it. why is that? We're building all this machinery to have search availability during the transition, except for this very short moment? I had the same idea about retrying. An alternative would be to do refcounting for closing the engine, to ensure that we only actually close once all in-flight `acquireSearcher` calls have been completed.
can we use `== false` instead of `!` it's so much easier to read and burned my fingers too often
One way to implement this: Ignore the LockFactory of the inner directories and require the LockFactory to be set on DistributorDirectory itsself (by extending BaseDirectory and taking a external LockFactory on ctor). In that case the Distributor would know the exact type of lock, because it is responsible for locking. The underlying directories would just need no locking at all (NoLockFactory). But this would be a change out of the scope of this issue. But I like the current impl better. Locking should be the responsibility of the directory that actually holds the lock. This implementation is now implemented the same way like FileSwitchDirectory. FileSwitchDirectory just has the additional "feature" that it delegates the makeLock() call by its file extension, too (and no longer places it in primary dir), see MIGRATE.txt in Lucene. Please also keep in mind, that the lock file itsself is an implementation detail, so maybe we get another lockFactory in the future that does not create any files at all (e.g., by locking the directory itsself or writing some information to its metadata). So to me it looks wrong to see the lock file as required to be listed in listAll(). Lucene itsself does not depend on that (because lock files are unknown to lucene), Lucene just uses the makeLock() method, nothing more.
I think enforcing this as a List of `ShardLock`s would be better, type safety wise
much cleaner. thx.
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
Listener can be null here.
unkown -> uknown
Instead of acquiring the shard lock for a second time, I would prefer if we would do it once, and move this call under that lock and just rename `tryOpenIndex` to `tryOpenIndexUnderLock`, removing the locking mechanism from it. Same thing for `TransportNodesListShardStoreMetaData`. You can then also remove the `ShardLocker` interface, which irked me for a while.
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
Do we need this? the settings are already immutable
ah I mean't Throwable.... sorry
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding jvm plugin [{}]", plugin.v1()); } ```
May be a try with resources here? ``` java try (InputStream is = Files.newInputStream(pluginPropFile)) { pluginProps.load(is); description = pluginProps.getProperty("description", PluginInfo.DESCRIPTION_NOT_AVAILABLE); version = pluginProps.getProperty("version", PluginInfo.VERSION_NOT_AVAILABLE); } catch (Exception e) { // Can not load properties for this site plugin. Ignoring. logger.debug("can not load {} file.", e, esPluginPropertiesFile); } ```
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
It would be nice to have some doc that indicates that it's going to be parsed and stored in a temporary map before being created using createFromMap() method, and the reasoning around why we do this. Also, maybe we could rename to MAP_PARSER? Just an idea.
we could pass a glob with regex:xxx to newDirectoryStream if we want
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
It'd be "more normal" to declare this as `Writeable` and use `readOptionalWriteable` and `writeOptionalWriteable`. You've done plenty in this PR so it can wait though!
these replacements seem to be wrong the if / else logic is obsolete now
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
Alternatively we can move this logic to the `beforeRefresh` method as this is the only place it's used at.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
I think filter and query can never be null here? not sure whether we should validate this here.
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think this has to happen before you start the cluster, or else the cluster will start with full knowledge.
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
the start cluster does this.
we have a new awaitNoMaster util method
a transformer and performer. Quite a guy :)
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
I wanted to remove the `allowCommit.set(false)` here with an ensureOpen at the beginning of the method. Only saw later it's already there. No doubles.
maybe replace this with ensureOpen in the beginning? feels cleaner to me
I feel like we implement this pattern enough times that we should make a helper for it at some point. No need now, but at some point.
Hope this doesn't bite us for really slow (read: Windows) CI servers...
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
can we please unpack the tuple right away instead of using v1 v2? just easier to read
> Would you do this just when it is overriden (ie not the default)? Or at all times? What about if they explicitly select netty in their settings? Anything but the first is not a one line change. Yep. Log all the time. > I don't think we should just willy nilly log things > I don't think this is useful. It saddens me that this takes so much effort and discussion. It is also sad that there is no constructive discussion but rather these yes/no statements. As I said, I find it useful, for the reasons I mentioned. That should be enough for this kind of change. I'm signing out of this now. I don't think it's constructive anymore.
I think it's important to know that the transport system is replaced and that the settings have effect. This also has security implications, as plugins can add settings. I think this should stay an info log like it was. Adding something similar to the SelectedType is good but over there debug is the right call indeed - it may be used for many things.
oh, I see. It felt like a utility class but it's officially a bless thing. Thanks for pointing it out.
how about preparing the scene and have two methods - registerRestHandler and registerCatHandler? the latter can accept things that extend AbstractCatAction and the first can assert the parameter doesn't inherit from AbstractCatAction and throw the right exception.
ok, sure. I thought you liked the separation. This works for me.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
ok...but client depends on the transport service anyway no? I think I don't get it
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
Hope this doesn't bite us for really slow (read: Windows) CI servers...
Does this happen because the scroll doesn't hit docs in that segment so it can't be blocked? Should canceling a scroll request nuke the scroll id? If you tried to pump it again would it be busted? Maybe something for a followup though.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
This logging should be removed.
Thanks for moving this to `InnerHitContextBuilder` and its subclasses!
I think you can drop the null check. It returns an empty array instead.
I wonder if `PARSER.declareString((b, v) -> b.sortMode(SortMode.fromString(b), SORTMODE_FIELD);` is better? I kind of prefer it because then you don't need to think about `ValueType`.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
yes lets do it later otherwise we have to remove setters and break things.
sure things changes now that we know for sure the target branch, that said making everything final would be better to do once we merged back to master to prevent merge conflicts here. Same with renaming XYZQueryBuilder to XYZQuery, and moving to proper getters and setters.
I think the type and queryBuilder instance members could be made final
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
Thanks a lot for this! Definitely better to generate that in a temp dir on the fly instead of having those files as part of the git repo!
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
64e5c25 added support for this.
It might also depend on which implementation of `AcknowledgedResponse` you are using, since we have two, yay duplication!!! You should have a look at `StartRollupJobResponse`, which is an example of changing the word from `acknowledged` to `started`. this should get you on the right track.
heh, duh... Sorry, ive been on vacation and full of turkey since last week.
Hey I saw some updates on this PR and I just wanted to throw a reminder out that we are not going to do a singleton(404) here, because we want a delete that is not found to throw an exception. Also, last time we spoke you were going to change this to AcknowledgedResponse. <3
> just let the default be 1 instead My rational with going with half as default is that I think that adding replicas should change the behavior - if someone runs with 6 copies , it's probably not a good default to let of them (but one) go away before signalling alarm. I chose the word "half" in order to avoid a loaded word like "quorum" which implies stuff that aren't part of our model (i.e., quorum reads). I don't mind if we round up (i.e., `(size() + 1) / 2`) or down (i.e. `size()/2` ) as long as it's not `size()/2 + 1` .
> 6 shard copies? That's rather useless in a system like ES We do have people using more then 3 shards so that lead to the idea of having the default scale with it. Thinking about it more I think the main usage for having so many copies is auto-expand-replicas-like usages, where you want to have shard copies available on all active nodes. In those case I think you mostly care about the data being on everything thatâs up and not be bound by durability guarantees. In that case I would be fine with waitForActiveShards default to 1 and allow people to set things differently on the index level if the want different default (when we do that change). > This setting is of limited use anyhow as it does not provide the guarantee that most users are after Correct - this setting is meant to be used to limit the scope of events that will be indexed into less than a given number of shards. It should be coupled with a check of the response of each write operation.
This method could take an IndexMetaData object as parameter instead. This would let us get rid of exceeds method as well.
exception messages should start with lowercase (for consistency)
we "special case" NONE here but not ONE, maybe it's simpler just to remove this method as well as the `validateValue` one and use `new ActiveShardCount(...)` in the two places it's currently used (and also ad ``` if (value < -2) { throw new IllegalArgumentException(...) } ``` to the constructor.
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
Same here about multi-line toString methods
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
I will take care of this.
ahh yeah in `assertAfterTest()` nevermind
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
underscore case? :)
for master you don't need to specify the gateway.type we only have what used to be local!
try to use `AbstractRestResponseActionListener` instead of `ActionListener` the `onFailure` method is already implemented there
now that #30490 is in, could you replace the header argument with the RequestOptions one? In the method that accept a listener we add RequestOptions between the request and the listener though.
as odd as this sounds, could you rename the methods to flushSynced as that's how this API is referred to in our [SPEC](https://github.com/elastic/elasticsearch/blob/master/rest-api-spec/src/main/resources/rest-api-spec/api/indices.flush_synced.json) ? request and response can and should stay the same.
same here - pls refer to `current`
I just realized that these API should belong to the tasks namespace rather than cluster, according to our API spec, see #30906 .
iirc we add `Asynchronously ...` to this sentence in the other APIs. But its a minor nit...
If we're doing a reroute - I don't think we should retry on retryPrimaryException. That one only holds for the primary action.
can we have an explicit boolean for this? feels hacky...
Nit: I think it will be safer to have this boolean as a parameter and determine the action here. I'm weary of arbitrary string input.
can we use `== false`
I know this is how it used to be, but can we make the if be more like the `masterNodeChangePredicate` name and check the the master node is not null and have changed? (we now test for a cluster state change)
Is this a typo? Not sure how this compiles...
Ahhh, it's been a long time since I have seen this syntax...
Can you add a check for reparsing (ie taking a settings that have been run through archiver and using them in another settings builder) the settings works? ie the setting stays archived and doesn't disappear.
Sorry, `MetaDataCreateIndexService` was a bad example. Still, the method `MapperService.merge` which does mapping validation is (AFAICS) not called by the `createIndex` method. This means that `verifyIndexMetadata` does not run the mapping checks in `MapperService.merge`. We check these however when we run `MetaDataIndexUpgradeService.checkMappingsCompatibility` which is called by `MetaDataIndexUpgradeService.upgradeIndexMetaData` when we start a node.
I could be wrong (not that familiar with the code in that area) but I think that in-memory data structures for mappings are not created by the `createIndex` method. These are merged later (see e.g. MetaDataCreateIndexService:325). We could check here as well that all is good on the mapping level.
this would make sense especially given that their setters accept primitive types
wonder if we should make these Integer and Boolean just int and boolean primite types.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
ok didn't know that. yet another bug fixed in master then it seems
shortcut: VersionHandshakeResponseTransportResponseHandler handler = pendingHandshakes.remove(requestId);
nice and clean :) another variant you may want to consider is creating an index with way more shards than nodes and see that we get to yellow (now we will wait for a quorum of copies)
Nit: `if(` -> `if (` (whitespace)
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
I'm confused because I thought you were implying there are cluster level tasks always running in the background, that are simply part of the cluster operating normally. A leak is a leak, and we should catch and reject it.
what to do here otherwise? not really likely to happen that it's not a number I guess... maybe leniency is good here
I get it now, yea I feel more comfortable making these changes in the query-refactoring branch cause we have more extensive tests, otherwise we should introduce tests in master too. It doesn't fix any bug anyways...
right, missed that :)
ok let's not change anything. To clarify what I meant: I know we need to support both formats: filters as top level, filters under the filters element. But don't we end up supporting filters under any element as well? Anyways, I am ok with keeping it like that.
is this needed here? I think it does something only when the current token is start array or start object.
for instance in RestoreService we use `addLast` at runtime which messes with this assumption, that entire order thing is broken and error prone. The best thing I can come up with so far is to add defined stage like this: ``` Java enum ApplyStage { NewClusterState, NodesConnected, StateRecovered, ShardsStarted, RepositoriesCreated, NodesDisconnected; } ``` where listeners can be registered but I am not too happy about it...
that sucks, sorry :) We can't build stuff that is dependent on the order of how the listeners are added! Can we find a better way of doing this? I think each listener needs to have priority or so and every prioritoy can only be added once? Maybe we don't need this to be a list at all? This stuff is so fragile we have to iterate until it's safe
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
this seems like it could create a lot of garbage since we do this for every request. Can we maybe hold a version of this per clusterstate version and invaliate it once the clusterstate has changed...
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
Heads up when you merge with master, I just merged another test where the original test query is modified assuming it is json, so that will need the same treatment as you do here I thinkg: https://github.com/elastic/elasticsearch/pull/14255/files#diff-9dc314365d49d84bff0645c2f9dfd7adR356 (and Overwrites in HasChild/HasParentQueryBuilderTests)
right I had missed that previous check, sounds good then
I think this should be strict too. The problem is that the not query has some alternate version that uses deprecated syntax. I think that should be moved to a separate test like you did with recent PRs.
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
Nit: addresses -> address
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
connec to to -> connect to
Please fix identation.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
One option might be for this class to hold the already serialised form of the exception, but I'm not sure if that is better or worse than the current solution
after is now minimum_age
I am confused how this works when created is only within role mapping but we ignore role mapping
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I don't think it matters. We should not force making huge changes to the entire codebase in order to not add things which will just be deprecated and/or confusing to the user.
I would also be fine with removing all the camelCase options for all formats in this PR to make it consistent.
I just realized we aren't even talking about setting names, but the valid values for the `format` setting. This argument to use ParseValue does not make sense. We don't support camelCase in eg the `index` option. We should not do it here, it will just add more work for users if we allow them to _start_ using a new value that will just go away in the future (and will require them to change the value to what they would have found in the first place if they had tried using camelCase and seen an error).
nit: extra line
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
I think saying that we can not convert the follower index to a non-follower would be clearer. My concern here is that if `bar` is following `foo` and this message says `cannot unfollow index [bar]` it would be confusing since it is `foo` that will no longer be being followed by `bar`.
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
My preference would go to adding a serialization context to readFrom.
I understand this, but this sound confusing to me. You would have some member in each builder that is only set for the prototypes, need special constructors for the injection. I understand your proposed solution with the static method access much better.
well then you have to have a dedicated parser interface - I wonder if this is a general thing we should have on stream input though
I think saying that it should not be allowed in the query DSL is a bit misleading, cause it is allowed and we parse it properly. I know what you mean though and why you wrote that, I need yet to come up with a better explanation for this...
maybe call this readDiffAndApply? this doesn't really read a diff and return it.
Ah, nope, I'm just bad at Java. `[Metric1, Metric2]` is exactly what I was wanting. :)
Now that there are two cases, I wonder if we should push the isAggregatable() check out of the type conditionals (e.g. apply to everything), then have an `if...if else...else` for the types? That way we won't need another conditional inside the first that specializes for the date type. Not sure how that would look, so the current way is fine if that ends up being messier. :) Has a nice side effect that the validation error will include both a message about non-aggregatable field as well as the metric missing at the same time.
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
Ah CONTENT_TYPE I see. Sorry for the noise ;)
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
if we only use all names to put things in the map we lose all the deprecation warnings that we might have etc. we should rather keep track of the original ParseField and call ParseFieldMatcher#match.
I think you are missing a `\n` here.
but if you are in strict mode you get an exception so you don't get back false :)
I think we should always return 1 here. REST tests should run with default number of replicas (1) even against a single node, because that's what clients tests do too. We can never expect green unless we manually set number of replicas to 0 in a test, and we should align to clients builds here I think to prevent failures that don't repro for us. Thoughts? BTW running against a single node is very helpful because it allows us to realize when we make the wrong assumption in a REST test, which in the past was only going to fail for clients and never for us.
well if a test doesn't call `super.nodeSettings(nodeOrdinal)` that is a bug. We have to enforce it though. IMO we can use a similar way as the test base class does but we don't have to do it here...
well we don't need to extend this anywhere, plus these changes don't have anything to do with this PR at this point, would prefer to leave them out.
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
alright that's what I thought too, sounds good
same here with removing retry logic
same here with removing retry logic
same here, all retry logic should be removed
our `blobStore` already has a method that will return us an instance of `SSEAwsKeyManagementParams`; we should probably use it instead of `new`ing up our own here.
on second thought, after seeing how our `blobStore` appears to be the true keeper of the encryption key (because it has the most distinct things asking for it, maybe we shouldn't change the constructor signature of this method and _consistently_ reach into `S3BlobStore` for our key.
can we name this `CompleteDiff` don't use simple please :)
`min` can be named `simple` or `aggregation`
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
I am slightly more in favour of having precise checks where needed rather than sharing code with unnecessary checks.
Also, we could put this check in a protected static method and reuse it in ParsedDerivative
`.addPathPartAsIs("_xpack", "rollup", "job")`
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
we also support a parameter called `updateAllTypes` here.
In 7.0 this should use `_migration/deprecations` as of https://github.com/elastic/elasticsearch/pull/35976, although in 6.x it will have to use `_xpack`.
no need for extra space
just my personal preference, I don't like instanceof checks that's it. you are free to leave them if you prefer them ;)
I think if we get in that other PR I just reviewd we can reuse here the new method that you introduced there? :)
we should `@Test` to forbidden API
here too we do the same twice
:) good catch
can we report the right version we found ? note that we would probably need to change the the logic in the gateway allocator to check for both -1 version and exception (now -1 means both).
Instead of acquiring the shard lock for a second time, I would prefer if we would do it once, and move this call under that lock and just rename `tryOpenIndex` to `tryOpenIndexUnderLock`, removing the locking mechanism from it. Same thing for `TransportNodesListShardStoreMetaData`. You can then also remove the `ShardLocker` interface, which irked me for a while.
missing { } :)
same here - I think it's better to log the info message if the deletion was successful.
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
+1 this makes sense. Then we can drop the `PIPELINE_ALREADY_PROCESSED` transport header.
I'm not a big fan of ActionListener<Void>? Maybe we can do this differently and replace it with two functions? Runnable for the onResponse() part and for onFailure use a Consumer.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
can we add a one lliner java doc explaining why this is needed (rather then pass through the the primary lock factory)? it's non-trivial to figure it is done to track the location of the lock file, if it's using files..
It looks like this includes the change from #8383? (nothing that needs to change, just curious)
++ on debug message
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
yea, I would at least debug log it..., it shouldn't happen
You can get away with it right now because there is only one test, but this should be initialized once before the test suite, not once before each test in the suite.
You can just use the literal boolean `false` instead of the string `"false"`.
Can you make this a JUnit assertion instead of a Java assertion? It's preferable to use a test assertion with matchers for this because then nice error messages are produced automatically when the assertion fails.
It defaults to `false`. :)
Let's also make this a JUnit assertion instead of a Java assertion.
we could pass a glob with regex:xxx to newDirectoryStream if we want
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I think it'd be easier to read if this were `ObjectParser` stuff.
It is all good!
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
This'd only come up if the target augmentation method is defined on an interface, right? Maybe we should not allow that at all.
I think this'd be more clear if you said something like "invokeStatic assumes that it is not invoking a method on an interface."
I see why you did this with the map here. I wonder if this is more of an argument for a builder because you can set the lang on the builder before you do the parsing.
I _think_ you can do `XContentParser::mapStrings` above instead of having this method.
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
if the argument name is `failNoIndices` you should provide `! indicesOptions.allowNoIndices()` as argument
I see your point on changing the name, that makes sense cause allowNoIndices != indicesOptions.allowNoIndices
if the argument name is `failNoIndices` you should provide `! indicesOptions. ignoreUnavailable()` as argument
Java docs says ResourceNotFoundException
it's fine to remove it
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
Nit: space between the cast operator and the target.
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
Might be better to use the default of the request (in this case this coincides, but explicit is better in case of refactoring): getSnapshotsRequest.ignoreUnavailable(request.paramAsBoolean("ignore_unavailable", getSnapshotsRequest.ignoreUnavailable());
Usually we'd stick this on the end of the last line.
Right - RollupIT is the right place
CCE is never a good idea to throw out - especially since it forces the caller to handle it. It should be handled inside convert directly.
I think it might be easier to read the code without this method to be honest. It saves a line every time you call it makes me go "what is going on here?" every time I see it. Not sure.
There should be a way to do the conversion without doing the raw math in there (not to mention the whole /1000, * 1000 losses approximation). Why not use the `ZoneId` from the calendar to compute the offset: ``` ZonedDateTime zdt = Instant.ofEpochMillis(value).atZone(cal.getTimeZone().toZoneId()); ``` or potentially use `getOffset()` instead of `getRawOffset()`
do you know if there is a good reason to return 0 if we got a negative value, or could we just return 'result' directly? (if this doesn't make any tests fail, this is good enough for me)
do we need ordered things? does order help anywhere? If not I would just use HashMap
It feels wrong that hashCode is using writtenBy while equals isn't
similarly, equals uses the hash while hashCode doesn't
missed that. Nanos is strictly speaking better, but not a biggy.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
Please add a string message about the context registry being null
I really don't think we need this leniency, I'd like to understand why we're introducing it. I think we should just blow up the pings.
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
master is the future 7.0, so I would do the following: ```java if (INDEX_MAPPER_DYNAMIC_SETTING.exists(indexSettings.getSettings())) { if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0)) { // 7.x index throw new IllegalArgumentException("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " was removed after version 6.0.0"); } else { // 6.x index DEPRECATION_LOGGER.deprecated("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " is deprecated since indices may not have more than one type anymore."); } } ``` Then when backporting I'll just remove the 7.x branch and make sure that we only emit a deprecation warning on 6.x indices (you don't need to worry about it).
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
I think we should not execute these writes directly here but extend ESIndexLevelReplicationTestCase#ReplicationAction then run them via the infra of the new action (see ESIndexLevelReplicationTestCase#IndexingAction).
I think "from" should be "from2" here. Also I would make the calculation simpler here as well, I think otherwise min might be smaller than max in the calls to "randomIntBetween"
we have `TestThreadPool` that makes it simpler
use `ThreadPool#terminate` here otherwise you will get lingering threads etc.
I think that all of these members variables except for `finalResponseListener` can be `private`.
Nit: there is an excess blank line here.
catched -> caught
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
nit: formatting, add some whitespaces
if we fail to start do we close the started ones
nit: formatting, add some whitespaces
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
this causes a deadlock when the operations that are blocked by the block are first in the future list while the last part of the future list prevents the block from being acquired. See the gist I made.
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
oh cool the read is in the ctor! nice!
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
can we be slightly more verbose on why this is use full? (different deserialization logic based on key in parent map)
Same here... we don't really need `String[] addresses`
``` java assertThat(provider.fetchCount, is(1)); ```
``` java assertThat(provider.fetchCount, is(2)); ```
this is not needed. createIndex automatically reroutes.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
I would be using a `Set` in this circumstances.
We also need a simple rest test, testing integration like we have for the other processors
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
do not work.
do we want to check that the shards were actually failed? Ideally we would just check that the allocation service was asked to fail them. Mockito maybe helpful? I don't want to hold you back for this though...
java 8 FTW
I wonder if this case distinction should be part of ReplicatedOperation.
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
I know this is a pattern we use everywhere but I don't like the name `success` to mean "I've forked this request and now it's the listener's problem" but I don't know a better name.
ok let's leave it as is for now.
or junit for that matter. try/catch is much more readable (and the way most other tests do this)
Can we just use a simple try/catch here? I don't see why we need to use hamcrest complicatedness...
Same suggestion here for `assertNotEquals`.
Maybe rewrite this using `assertNotEquals`? It makes it symmetric with the previous line so that it's clearer, and it gives better failure messages from JUnit when the assertion fails.
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
I'm clearly not getting my point across. Please understand that multiple tests are run in the same jvm during jenkins!!!!!!!!!!!!
I wonder if we want to ban `new Random(int)` to make it harder for folks to do `new Random(System.currentTimeMillis)`. If so then `Randomness` is probably the right way to go. Otherwise I like `GOOD_FAST_HASH_SEED`.
Just to make it better, setting it here in clinit is not so ideal, because its not perfectly reproducible when multiple tests are run in the same jvm. you will still have perceived reproducibility issues vs jenkins if you go about it this way: because the random will be initialized _once_ and then we will run 8 test classes against it. then, when you later try to reproduce the one that failed, the sequence will be different (even though the initial value is the same), because the other tests are not also invoked. but if you do it this way, it at least allows "whole build" reproducibility, which is an improvement. That means e.g. if you nuke your local execution hints file and run 'gradle test -Dtests.seed=xxxxxx -Dtests.jvm=yyyyyy', it will match what jenkins did. But nobody does that.
In general can you please make sure you are not using your own code style. Please adopt to the codestyle which is mainly default SUN except of 4 spaces indent.
same here this is a left over!
Also, it can use `execute()` rather than `submit()` as it's not interested in getting a `Future` to track completion. Since you're off I'll push another commit that changes both things.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
pageParams is missing from the equality check
use `Objects.equals` for all once changed to potentially null references.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
would it be possible to make the second part of this method part of the field script object itself? It would also be fantastic to use the same mechanism on both sides, but I know it is a bit tricky for different reasons: 1) that array that we reuse without resizing 2) we try so hard to avoid boxing 3) the usage pattern is slightly different if we compare doc_values, query and index time execution. I do wonder if it is worth investing on this, possibly having our own PrimitiveIterator or something that allows us to expose a clearer script API to access the computed values. For later I guess.
I asked before if the bit from runForDoc till the end can be a new method exposed by the Script class, in the effort of consolidating how field script classes expose their values. Do you have thoughts on this? We could also do it later
I spent some time thinking about whether we can consolidate this, like we do for runtime fields (e.g. the compilation could be done in a single place for all types). We can't really do the same that we do for runtime fields as NumberType is an enum and can't have a generic type, while the different Factory and LeafFactory don't have anything in common throughout the different types hence require a generic type somewhere. Whatever we do ends up being complicated for little gain e.g. saving a few lines of code). One thing is I find it a bit tricky to follow that thanks to this we compile the script at mapper creation time and not at execution time. We could potentially make MapperScript an abstract class with a generic type (the factory) and compile the script in its constructor. That is not perfect but maybe clarifies when the script gets compiled.
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
oh boy :)
It's minor, but we usually lowercase exceptions and elide ending punctuation
I think something like `randomSearchSourceBuilder` would be a more consistent with other random builders.
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
It drives me bonkers that this is called "scroll" everywhere instead of "scrollId", but it's a matter of taste, no impetus to change it if you like it :)
I think we could check that successful == total shards and that total shards is greater than zero
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
if we run into an exception here we have to close the stream. we usually do this: ```Java boolean success = false; try { // do something with the stream success = true; return stream; } finally { if (success == false) { IOUtils.closeWhileHandlingException(stream); } }
can we maybe try to trigger this differently? I mean can we for instance try to call `#available()` or can we maybe read the first byte on open and wrap in a `BufferedInputStream` and then do this: ```Java InputStream stream = is.isMarkSupported() ? is : new BufferedInputStream(is); // do the following in doPrivileged? stream.mark(1); stream.skip(1); stream.reset(); return stream; ```
I fell like a functional interface here doesn't really buy us anything comparing to a simple if statement with two calls.
I think all of these need to be trace and we should enable these in tests that are relevant.
IMO lets drop them all. IF you have to make them trace you can also just add them back if you need it.
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
same request - please have a method called `haveWriteBudget` and do `while(haveWriteBudget() && buffer.isEmpty() == false) { `
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
please use Arrays.asList while we re here
can this be synchronized please
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
I wasn't entirely sure either but good to know! :)
Since the method [setMaxElapsedTimeMillis](https://developers.google.com/api-client-library/java/google-http-java-client/reference/1.20.0/com/google/api/client/util/ExponentialBackOff.Builder#setMaxElapsedTimeMillis%28int%29) only accept a maxWait > 0 this `if` condition must be changed.. I'd write: ``` java if (maxWait > 0) { retryHttpInitializerWrapper = new RetryHttpInitializerWrapper(credential, maxWait); } else { retryHttpInitializerWrapper = new RetryHttpInitializerWrapper(credential); } ```
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
now I see what you meant yesterday saying that we have to parse meta here
while I get that the preference for a for loop... but the inconsistency of how xcontent is parsed is annoying.. if we do it everywhere using a `while (...)` then we should stick to that... if we want to change to a for loop, then lets do it across the board
it's annoying that we write this code over and over again!
Would it be better to use the Assert.fail(String) method or throw an AssertionError here? That way the test will fail correctly in the test framework
My motivation is both making it so there is one obvious way to calculate distance (I was reminded recently of this beatiful mantra from the Zen of Python: `There should be oneâ and preferably only one âobvious way to do it.`). I also think not having instance methods will allow us to play more with the underlying field access so we dont need an intermediate object, GeoPoint).
Oh I see, it's the ZTable stuff. Sorry for the noise :)
interesting, what is the reason for this funny upper bound? :)
Would it make sense to move this method to some SpatialUtils utility class? I feel like it's pretty generic and we might find some other ways to use it. I think I would also replace first three doubles with Circle. And we should figure out what to do with the radiusMeters parameter in Circle since it is not meters in case of `shape`, but this is a topic for another PR.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
I prefer `assertEquals` in cases like this. `assertThat` is great if you need to take a matcher or want to assert something complicated, but I like `assertEquals` for equality.
We also need a simple rest test, testing integration like we have for the other processors
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
w00t thanks !!
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
we can do this in a more optimize manner. We can create a builder, and then use `copyCurrentStructure` on the builder (passing it a parser), to just copy it over, compared with parsing into a map and then serializing the map. Also, since its internal, I would use smile builder, as its considerably more efficient than json.
I think conceptually this should be QueryParseContext instead, if it needs to do more (toQuery) then we need to figure out how to create the QueryShardContext too out of it, but the other way around seems confusing to me. Sorry I see we are going back and forth on this.
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
`Arrays.toString(paths)` already adds [] , no need to add them
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
[{}] for path.
Shouldn't this be using `ElasticsearchTestCase.randomFrom` instead of `com.carrotsearch.ant.tasks.junit4.dependencies.com.carrotsearch.randomizedtesting.generators.RandomPicks.randomFrom`? I don't want it to end up not using the right seed
same here. ElasticsearchAssertions.assertThrows wil help
maybe add the type that is found in the error message with fieldType.typeName()
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
can this be final
@uboness I mean that it is called by the transport client going through the transport service directly (as was the nodes info call before), it is not exposed through clients, so java api users can't call it explicitly (the `Client` doesn't expose such api).
I really like this class since it's so self-contained and has all the tests etc. no weird guice bloat etc. NICE!
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
This exception will be treated as ignore replica exception. :wink:
maybe put this check before the primaryTerm check
try finally here please since if close fails we don't release lock etc which can be missleading
well we use a dummy lock so I guess it's fine
instead of ruling out the states which don't allow this to be called, I think it's easier to understand if we put the states where we allow this to be called.
I think you forgot to add the name of the script here to the failure log
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
Er - if you are going to log something then it doesn't matter which order you do it I guess.
Search and executable, and execute look like they should delegate stuff to a single method. Orsomething.
this new exception is going to trigger errors too if we try to serialize it to an older node
right thanks for the explaining, I should have known, having worked on the search refactoring :)
We call them "master nodes" everywhere else. :frowning:
this should be `INDICES_CACHE_REQUEST_CLEAN_INTERVAL.get(settings)`
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
this looks great! Can you fix the indentation to 4 spaces and also assert that the key has a `.` in it ie `s.indexOf(".") > 1` I think it's ready then. Thanks for fixing this great job figuring it out!
class could be `final`
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
you should pass fieldNames as an argument
snpashot -> snapshot
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
There is because it becomes one very simple line: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java index 6220c4d..5604bf7 100644 --- a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java +++ b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java @@ -89,15 +89,7 @@ final public class IndexGraveyard implements MetaData.Custom { @Override public boolean equals(Object obj) { - if (this == obj) { - return true; - } - if (obj == null || getClass() != obj.getClass()) { - return false; - } - @SuppressWarnings("unchecked") - IndexGraveyard that = (IndexGraveyard) obj; - return Objects.equals(tombstones, that.tombstones); + return obj instanceof IndexGraveyard && Objects.equals(tombstones, ((IndexGraveyard)obj).tombstones); } @Override ```
You're right, I confused myself.
I think that since you're deferring to `Objects.equals` anyway all the other checks above can be removed.
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
Beware that bucketOrd has the following definition: ``` java final long bucketOrd(long owningBucketOrdinal, int filterOrd) { return owningBucketOrdinal * filters.length + filterOrd; } ``` So we need to somehow multiply by `filters.length + 1` instead of `filters.length` when we compute the other bucket otherwise there will be several "logical" buckets reusing the same "physical" bucket
I think ``` java if (prevParentDoc == -1) { childDocId = childDocs.nextDoc(); } else { if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc); } } ``` could just be replaced with ``` java if (childDocs.docID() > prevParentDoc) { childDocId = childDocs.docID(); } else { childDocId = childDocs.advance(prevParentDoc + 1); } ``` ? (No more check that the previous parent doc is -1, and advance to `prevParentDoc+1` instead of `prevParentDoc`)
is it worth doing the conversion from and to geohash every time here? Could it be better to not do the conversion and store two doubles per bucket instead of one long? I guess its a trade-off between execution time and memory
ok, fair enough. ++ for setting up compatibility with GeoPointv2
does this work? it works for percentiles, but with percentiles rank it's reversed
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
ah I mean't Throwable.... sorry
This can just be a plain old logging statement `logger.debug("[discovery-file] using dynamic discovery nodes {}", discoNodes);`.
I think we don't need this line or the following two, since they duplicate docs found elsewhere.
Same concern regarding the leniency.
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
This whole loop reads fairly low-level. If config files can be considered small, we could just read them much more concisely with the Stream API (untested): ``` java String rules = Files.readAllLines(path) .stream() .filter((v) -> v.startsWith("#") == false) .collect(Collectors.joining("\n")); ``` All the low-level stuff is gone. But this relies on Java 8 features and will only work on master.
We can rely on auto-closeables here (i.e. we could use just the try-with-resource statement). Not necessary if you use my suggestion with the Stream API.
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
there is a test helper method that can create plugin property files
We will need stronger assertions here too.
This lambda does not need to be a statement block.
I think there is a bug here. What is `\\`? I guess Windows? You need to take caution for different filesystems.
This lambda does not need to be a statement block.
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Feel like this should be more significant than `debug` because it really indicates a form of failure in some scenarios.
I still think skipping is better tbh... otherwise the users will be more confused on how to merge the old one with the new one. I don't think the file formats will change that much... but when they do, we'll simply be able to tell them what to change in the files they already configured in order to be compatible with the new version (not sure that will even be needed, we could perhaps support both formats in the code and make it transparent).
It'd be better, to only skip the config files that have the same name, not the whole directory. So for example, if currently es has a config dir that looks like this (for plugins `foo`): ``` /config/foo/bar.yml ``` and the new plugin that installs needs to copy two files there: ``` /config/foo/bar.yml /config/foo/baz.yml ``` we'll skip `bar.yml` but we'll still copy `baz.yml`. This will help us a lot when we guide the user on how to upgrade - instead of telling the user, to copy & modify a bunch of files, we'll only need to tell him to modify files under `config/foo`
Would it be easier to copy the old config to somewhere else, then replace it rather than trying to mix adding new files while keeping old files? I feel like this will be very confusing for users, especially if `file1.yml` had changes coming from both directions.
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
This predicate can be simplified to `(count, limit) -> count > limit`.
oh nevermind, I just found the method that called it with null :)
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
I would write this check as ``` if (shardRestoreStatus.state().completed() == false) { ``` and then add an assertion that `shardRestoreStatus.state() != SUCCESS` (as the shard should have been moved to started and the recovery source cleaned up at that point).
same here re enumSet.toString
same here. I would prefer to have a separate `runTranslogRecovery` method that we use for the local replay after reset. This method could then use a different stats object as well as a different origin.
I am not a super fan of this. I wonder if we can afterwards rethink this.
I prefer my way but have asked @jasontedor to chime in.
+1. Good catch. I missed it. It would still be good to kill the node when testing - so we should have some assertions here too.
you are right, the original indices are read/written in the super class, good! You can then remove the PercolateShardRequest that takes shardId and originalIndices as arguments I think.
I think it's odd to have a public constructor for a test only... remove the OriginalIndices parameter at least? it's always set to null I think.
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
This should be the version we are going back to, so 6.5. In this PR, disable bwc tests in the root build.gradle file. Then re-enable in the backport, and do a followup to master to re-enable there as well. This minimizes the changes necessary to followup to master (instead of needing to remember and change all the places that have this version constant).
this breaks backwards compatibility, you will need if based on version in both `readFrom` and `writeTo`
Quick question (unrelated to this PR) for clarification: the goal was to get rid of the Prototypes, but this will happen in later PRs? Is there already a proof-of-concept type of PR I can look at how this will work, I just played around with it a bit wasn't quiet sure how this will work with the common `boost` and `query_name` fields.
Having all the query names ony here in `SearchModule` also makes it hard to test them for accidental changes. We are not doing that yet, but I think we should, and for that they should stay in their respective classes.
The previous builder also supported "multiMatch". I'm late to the party, but this is one problem I see in removing the alternative `names()` method from the builders, it moves the parser names (and alternatives) far away from the builders themselves. I guess this move is part of makign QueryParse a functional interface, but couldn't we leave the `names()` method and use it even though it will not be part of the QueryParser() interface? Or add it to AbstractQueryBuilder instead? Having all these string constants here in this class without a connection to their builder is a source of errors IMHO.
I had the same thought in the beginning, but then I thought it made sense to have the parsing code in one place, and the names it's registered against as part of the registration code. Is this source of error just because we are moving the code around and we may forget things/ not properly review? Or is there more to it? There should be failing tests for these problems anyways!!! We should work on those I guess ;)
> If we felt like testing fromXContent without SearchModule we could implement a super easy mock implementation That we can easily do with a little registry too I think? fromXContent won't depend on SearchModule anyway, that is the point of having a separate registry for only the pieces that fromXContent needs (registered score functions). In the end there isn't a huge difference between the two solutions. there is and will be a lookup method somewhere, but instead of being a method reference as argument, it will be an explicit registry. I find it more readable this way, but I do get how this is just a matter of opinions.
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
nit: can you use assertThat or expose the actual values in the message.
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
did you plan to add here the list of nodes or something? looks like there is a missing argument.
ok...but client depends on the transport service anyway no? I think I don't get it
marks the shard store
I wonder what our system invariants are w.r.t primaryTerm in IndexShard. Primary term has for example a direct impact on the reroute phase. A new primary term means that we need to route to a new primary location. The big question is: What is the relation between primaryTerm that we use for routing to primaryTerm in IndexShard? Maybe we could require both to be the same and otherwise abort primaryOperation? Other invariants to think about: - If IndexShard gets created as primary shard (that is not a relocation target), then it should have the same primary term until its closed, right? - If IndexShard gets created as primary shard (that IS a relocation target), then it should switch its primary term only once, namely when it gets activated. I wonder how can we better capture these invariants in the code.
I spent some cycles reading this and convincing my self that we can do this regardless of the searcher scope - i.e., that if we end up here with an internal searcher it will be OK (it is!). I would personally think it will be simpler to follow if we mark access in `awaitPendingRefresh`. That would mean all flow /state management is around the engine and you don't have to go through engine code to see how things work. This is of course subjective, so just a suggestion.
I think this message might be misleading.
We should log the the failure here if the close fails
wondering if we should enforce immutability on this level... feels more natural to do it in the build()
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
can we swap member and constant we know the constant is not null :)
Can you add a textual description (makes it easier to understand)? I was wondering for example at first why we don't increase primary term upon full cluster restart (then I noticed we do, as isSameAllocation yields false if oldPrimary is unassigned primary).
see text from other suggestion for empty primary allocation
ok can we rename the getter then to `getFailedNodeExceptions()`
can we use getters here like `getNode` `isCanceled`
same here these strings are only used in one place just use them directly and trash the Fields class
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
I am surprised that we don't have a default impl for this :)
should be `'norms': True`
so we can assert _that_ we can still use it
I guess it could be renamed to isFalse() / isTrue() now
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
This should be `Type.FS.match(` instead of `Type.FS.name().equals`
just use `Collections.unmodifiableList()`
Having limitless extensibility is not a good thing... as a plugin developer, I want to know what I can and cannot do... what I can extend. Otherwise I can easily do something I really shouldn't, break something along the way, without even knowing I broke it. Having well defined extension points and effectively limiting the extensibility of es in general: - helps us make sure plugins cannot break things (as they'll be restricted to what we allow them to do) - helps the users know what they can do and rest assured that they're not doing something they're not supposed to So overall, personally I'm less concerned about not capturing all the extension points at first run.. I'm more concerned about first capturing control over it. Then we can start opening up extension points as we see fit in a controlled manner.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
I think we have this logic in the settings already maybe we can factor it out and reuse? seems scary and it would be good to be consistent.
I'd expect this to be in a synchronized block
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
we should probably bail here. One nit pick - I would prefer having this rejection logic closer to where it holds. I think there is only one method that can cause this.
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
+1 on just `field`
is this a pattern or just a separator? wondering about naming
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
Same here as above, since both methods are related and read similar.
we should totally not have this method, one more reason to not implement the interface.
oh right sorry I had missed it's a single value for these processors. sounds good.
java 8 FTW
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
oh I see what you meant now in the other PR :) if Tuples don't pollute the method arguments, I am ok with this, actually it simplifies synchronization issues between the two maps otherwise, I will update my PR to do the same.
if we only use all names to put things in the map we lose all the deprecation warnings that we might have etc. we should rather keep track of the original ParseField and call ParseFieldMatcher#match.
you could remove the null check by changing the second check to `Defaults.NAME.equals(parser.currentName())`
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
"joined the cluster back" -> "rejoined the cluster"
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
we only need an array here - we don't do anything with the version and we copy it into one anyway: https://github.com/elastic/elasticsearch/pull/12335/files#diff-ad5388a03f5e080b452190f4eb47f33aR244 Might as well use an arraylist from the beginning.
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
Does it even have to be a map? It feels like a set would do just fine here.
Does it matter whether it went from above the high watermark to normal or above the low to normal? Could you get away with just storing a single Map? I figure that'd be simpler.
can we turn it around and do `if (usage != null)`
oh nevermind, I just found the method that called it with null :)
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
Heads up when you merge with master, I just merged another test where the original test query is modified assuming it is json, so that will need the same treatment as you do here I thinkg: https://github.com/elastic/elasticsearch/pull/14255/files#diff-9dc314365d49d84bff0645c2f9dfd7adR356 (and Overwrites in HasChild/HasParentQueryBuilderTests)
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
right I had missed that previous check, sounds good then
I think this should be strict too. The problem is that the not query has some alternate version that uses deprecated syntax. I think that should be moved to a separate test like you did with recent PRs.
should we here or in the superclass fail if the cluster has not fully upgraded to 2.3? just as a safety guard I think that would be a good check in several places otherwise I can see us debugging weird issues `DiscoveryNodes#smallestNonClientNodeVersion()` has a neat method to check.
You can get away with it right now because there is only one test, but this should be initialized once before the test suite, not once before each test in the suite.
It defaults to `false`. :)
clusterName is not needed here.
Another simplification - if we push the code at https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterIndexHealth.java#L81 into ClusterIndexShardHealth's constructor, we can use it here and just make it a simple lookup in the enum set..
same as above, function name says nothing about what it does.
This constructor doesn't seem to be necessary.
can we add something to indicate where this comes from? something like unexpected error while processing cluster state version [{}]
this can be removed now, no? it will be cause a duplicate with the full cluster state log..
maybe `== false` just so we don't typo it in the future
getDelayCalculationTimestampInNanos -> getLastComputedLeftDelayNanos
Oh, got confused , which is the point :) getDelayCalculationTimestampInNanos -> getUnassignedTimeInNanos
oh hahahah, I can't read, that's an L
Yes, that would be clearer
can we replace the Math.max with an assertion? it should never happen and we shouldn't protect for it.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I don't know how often this is called, depending on this maybe it makes sense to store the formatter somewhere for later reuse unless `format` changes? Is only called a few times maybe not worth the trouble.
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
this new exception is going to trigger errors too if we try to serialize it to an older node
I think BuildFactory should be allowed to throw a ParseException since subclasses should have the ability to throw it if there is a problem with creating the builder at this point
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
Is it a problem if we just track a non-existing file? To me this looks like this is already broken for NativeFSLockFactory, because this one may reuse already created lock files (the existence of lock file does not mean its locked). So we can just record here "there may be a lock file to track".
I do not think we should log here. This is on the reload of a file and not an update to the ciphers settings
yea, I would at least debug log it..., it shouldn't happen
++ on debug message
Nevermind, I just noticed this is required for bw compatibility.
It seems to me like this class would be simpler if headers were always not null (and just empty in case there is no header).
I think you want ToXContentObject here.
Nit: "are a" -> "a".
Nits: "based class" -> "base class" and "involves are a" -> "involves a"
can you explain why we do this now only if `autoCreateIndex.needToCheck()`
this code block is repeated and always deals with index requests I think. We can probably factor it out to a method.
can we do: ``` Java if (addFailureIfIndexIsClosed(updateRequest.index(), updateRequest.type(), updateRequest.id(), bulkRequest, responses, i)) { continue; } ```
it's only as a safe guard for the future, or a warning for someone using totally the wrong classes. I think it's OK in these cases to fail the entire request? (unlink non-programmatic errors)
can we call this primaryItemRequest? It's the one that's sent to the primary. Also, if we pass it as a `BulkItemRequest` parameter, we can avoid sending `requestIndex` and `BulkShardRequest` (from which need the concreteIndex, which I think we can from the shard). Last can we assert that the `BulkItemRequest` has as a request object the `updateRequest` we got? this is all super trappy but we can take one step at a time :)
You can use end instead of `out.position()` here.
`limitedTo(long bytes)`? Clone is kinda non-specific.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
good catch on delta > 0
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
do we need this? it's like the base class (as we never have a cause)
I think 5xx (server error) is worst than 4xx, but let's just go with the first.
OK for now, but I guaranteed someone will use this and be surprised. But sure, we can wait.
I think we need to make all the methods synchronized here? we don't have any concurrency guarantees right now
0 seems more intuitive to me (-1 means unset in many places)
I think you forgot to add the name of the script here to the failure log
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
I think we should collapse the two above methods, they are always called in sequence.
I think it would be cleaner to move the assert into the catch, and add a `fail("expected script exception")` after the call to `run()`.
Maybe replace these with writeOptionalString as well while you are at it
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
Here it is more clean, but again I think using `synonym_query_style` would be better
why do you pass the response to this method? `this` already has all information.
I'm fine with `IllegalArgumentException`, in all the places of course. :smile:
then check for non null here...
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
It is all good!
I think it'd be easier to read if this were `ObjectParser` stuff.
I think a nicer approach (can be a follow-up done by me) would be not to call `updateGlobalCheckpointOnReplica` here, but instead call ``` globalCheckpointTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED); ``` either here or in the IndexShard constructor (where we create the GlobalCheckpointTracker) when the recovery source is EMPTY_STORE.
I would prefer not to call `updateGlobalCheckpointOnReplica` on the `GlobalCheckpointTracker` if the shard is a blessed primary. A shard that's created from snapshot / local_store / local_shards is by definition blessed from the master. It should just activate the tracker. The activation logic for a replica can be different than for a primary.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
Nit: `added [{}] the` -> `added [{}] to the`
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
cool thanks for the explanation!
Besides jokes I see your point on NoOp naming, let's leave empty then, it doesn't convince me 100% but I cannot come up with a better name
nevermind, I guess it depends on how you look at it. at the end of the day this parse method does parse + toQuery, having QueryShardContext is fine given that it will still happen on the shard. Also given that the QueryParseContext is much more lightweight, it makes more sense if done this way. Plus the parse method will go away, so leave it as-is.
I think conceptually this should be QueryParseContext instead, if it needs to do more (toQuery) then we need to figure out how to create the QueryShardContext too out of it, but the other way around seems confusing to me. Sorry I see we are going back and forth on this.
yes please I haven't seen them used before in our codebase. At some point we will automate formatting and these classes will have to somehow be ignored I think.
And it looks like you cover the response below. So you can ignore this.
I wonder if it'd be nice to have the assertion in the docs with a note about how this is the response. And maybe a note that you don't have to assert anything if you don't care whether or not it was created up updated because non-200s throw exceptions.
I believe this text is out of date now that we have a macro.
Change this to `// tag:example[]`
you should run `gradle precommit`
please use Arrays.asList while we re here
I think you want ToXContentObject here.
can this be synchronized please
after the change to `PreBuiltCacheFactory.getCache` you can remove `<Analyzer>` from here, it's redundant.
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
fine with me
good catch! that means we are not properly testing this case either given that we didn't catch it.
Nit: `added [{}] the` -> `added [{}] to the`
Nit: this does not need to be on a separate line
Nit: there is an extra space after the `&&` and before `inSyncLocalCheckpoints`
Typo: "`check point`" -> "`checkpoint`".
Typo: "`local checkpoint`" -> "`local checkpoints`".
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
All of the `*Plugin` interfaces we have added so far have used `get*`. I think we should be consistent.
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
Again, need to figure out what to do if ATOMIC_MOVE is not supported
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
Someday we're really going to have to standardize on American "canceled" or British/Australian "cancelled"... :)
I am not sure if we should catch an exception here IMO the exception should bubble up
maybe `== false` just so we don't typo it in the future
I think it is fine: we only build one search context per request per shard.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
yeah that is true. nevermind then
can we add that to ClusterStateCreationUtils? It might be useful for others as well
check listener.isDone() as we don't expect a retry here I think
true. nevermind then
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
after rebase you will have to get rid of any wildcard import, or the build fails :)
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Now I wonder if you should make readFrom/writeTo final and make an abstract method that is just responsible for reading the response. That pattern was used by the query builders until they switched to constructor based reading and it seems fairly a appropriate. I don't think it should block the PR though. It isn't really important I think.
update java docs
But even if we don't rename, users who implement the interface will have to adapt their code due to the method signature change? So I think we could break this too? I don't expect many users, if any, to implement this interface at the moment.
this can be removed now, no? it will be cause a duplicate with the full cluster state log..
scrap the method, but the block (saw the listener call now).
can we add something to indicate where this comes from? something like unexpected error while processing cluster state version [{}]
This constructor doesn't seem to be necessary.
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
Nit: I think it'd be better for the message to read: ```[move_allocation] can't move abc123 from node1 to node2: node1 is not a data node``` (NB less punctuation, and no need to say `since its not allowed`)
Could you wrap these lines to <120 characters? We're trying to cut down on overlong lines.
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
see text from other suggestion for empty primary allocation
any chance we can shard this code with AllocationService
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
can we move this in a sep method and make this `private boolean balance()` only have a single return statement, all these returns are hard to read
add space between `if` and `(` (in other places as well)
can we add an assertion going out that going out of the primary shard allocator we don't have any primary shards in the unassigned list, unless we expect them to be there? (primaryAllocatedPostApi is false or restoreSource != null)
OK. > On 20 Jul 2015, at 14:01, Shay Banon notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java: > > > ## > > - AsyncShardFetch<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> fetch = asyncFetchStarted.get(shard.shardId()); > > - if (fetch == null) { > > - fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction); > > - asyncFetchStarted.put(shard.shardId(), fetch); > > - } > > - AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId())); > > - if (shardState.hasData() == false) { > > - logger.trace("{}: ignoring allocation, still fetching shard started state", shard); > > - unassignedIterator.remove(); > > - routingNodes.ignoredUnassigned().add(shard); > > - continue; > > - } > > - shardState.processAllocation(allocation); > > - changed |= primaryShardAllocator.allocateUnassigned(allocation); > > - changed |= replicaShardAllocator.allocateUnassigned(allocation); > > I will do the assert when I remove the primaryAllocated flag in a different change > > â > Reply to this email directly or view it on GitHub.
I think the following if is not valid anymore in fromXContent: ``` MatchQuery.Type type = MatchQuery.Type.BOOLEAN; if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_FIELD)) { type = MatchQuery.Type.PHRASE; } else if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_PREFIX_FIELD)) { type = MatchQuery.Type.PHRASE_PREFIX; } ```
this would allow to remove the two parse fields above I think
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
Well that's the problem, we don't know what's important for a custom rescorer. `SearchContext` is mutable which is why I think it's too sensitive but the same applies to `SearchSourceBuilder` so you're probably right. We can find ways to pass more information in the `RescoreContext` anyways so +1 to keep this simplification.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
`assertNoFailures` is more common in newer tests and much shorter.
I like `hasSize(1)` for this kind of thing because it makes a nicer error message.
Since you don't care about the body of the source maybe use something like `setSource("foo", "bar")`.
if you use here `refresh();` from the base class we also make sure we get back no failures.
Also, you dont necessarily have to change this but you can now replace `.execute.actionGet();` with just `.get();`
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
Is there a reason these three fields need to be test instance members be randomized in the init() method? Otherwise I would prfer making them local in createTestIntstance().
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
I was not sure where it came from. Would be nice to remove it, there is no execution hint anymore.
Lol - I spent some cycles trying to figure out how the hell we know this won't throw an index out of bounds exception, only to end up learning something about the BitSet api - it's funky ;)
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
I really think this should a hard-coded value and not passed in from the environment. I don't think we gain much by accepting it from outside, and I envisage it being the sort of thing I have to look up each time I come across it. The `BUCKET_NAME`/`KEY`/`TOKEN` inputs are clearer (despite that the `KEY` and `TOKEN` used here could be generated internally if we could do so deterministically).
Can you open a lucene issue for this? Meanwhile, I think it's a good idea to copy the implementation of checkResetException() into the test code here, as it checks the contract pretty strictly.
I will take care of this.
this is same as what we do in term query. We randomly choose a value depending on the type. We might choose the mapped field for that value type, or just pick an unmapped field for it.
Got it, sorry didn't fully realize how value is initialized in any case before. So scratch this remark.
here too we do the same twice
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
_value is only for agg scripts, we shouldn't have it for anything else
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
If the constructor is modified, this method won't be needed anymore.
I'm fine with leaving it, yeah. I did want a prettier one but if this is what we can do, it'll do.
I talked with @costin earlier about this - he wants to keep the order the same and my proposal doesn't. What about this? ``` while (result.size() > 1) { ListIterator<Expression> itr = result.iterator(); while (itr.hasNext()) { itr.add(combiner.apply(itr.remove(), itr.remove())); } } ``` Your version works but `for (int i = 0; i < result.size() - 1; i++) {` make me think it'll be a normal loop and then you remove and add and I'm confused. Using the `ListIterator` forces the reader to think.
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
3 more indentation issues above
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
can we call this log: ``` received a cluster state from a different master then the current one, ignoring (received {}, current {}) ``` also note that disco nodes already have [] in their toString.
is it really possible that we receive join requests if `ZenDiscover#doStart()` hasn't been completed yet? this feels odd to me
yes, we can't do too much about this, so it is better be defensive here.
we have a new awaitNoMaster util method
`them` -> `them;`
I think this needs to be `Version.V_6_0_0_alpha3` now.
Just discussed it with Robert and indeed this fsync is not necessary.
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
+1 to not swallow the original exception
just fix a number, I don't think randomizing this adds much.
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
can you check that you can reopen the translog and that you can at least read all operations that weren't trimmed? this should not result in a translog corruption.
please make sure all files closed and no file is leaked.
If that's the case, we don't need - that's making sure :D - where do you see it's done in ESTestCase? (I didn't check myself)
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
could be a instance variable, as used in all tests
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
typo: optain -> obtain
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
missing { } :)
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
is there a way to filter out the index metadata here? We just want the global metadata.
lets put this into a unit tests class
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
this should just throw IOEXception no need for a shadowing ConfigException
@talevy Can you extract this IOException change from the PR and commit this to the branch? I can then benefit from it in the geoip PR too.
the `grok` field can be final too
these unit tests are great! We are going to need more of them :)
Maybe replace `SearchContext` with `IndexSearcher` if we don't want to expose `SearchContext` in plugins.
I think it is fine: we only build one search context per request per shard.
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
wondering if the other way around would be better: create a new array instead of set and add open indices to it from within the loop.
yes, that's what I was thinking, I'd maybe check state != CLOSE rather than checking for OPEN, but that's a super minor concern that doesn't change the result at this time
These are expected, even required when implementing `ActionListener`. Either we should create an `AbstractActionListener` that does this for us the same way we have a `AbstractRunnable` or we should add a permanent hack to allow this specific construct in `ActionListener` subclasses. The former seems like a better choice but it'd mean more work before we can get this merged.
I feel like we implement this pattern enough times that we should make a helper for it at some point. No need now, but at some point.
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
s/The tasks has/In case the task has/
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
let's reference "1m", "5m" and "15m" directly
I believe we've been just using the string version of field instead of these lately.
Or we can let poorly formatted values pass through and throw exceptions at the end if values are missing, similar to how we do for queries
Why not have the standard to string? A multiline return value is difficult to work with in a debugger...
while I get that the preference for a for loop... but the inconsistency of how xcontent is parsed is annoying.. if we do it everywhere using a `while (...)` then we should stick to that... if we want to change to a for loop, then lets do it across the board
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
no need for `else` here
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
I think s/lang/defaultLang/
I guess it could be renamed to isFalse() / isTrue() now
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I don't believe this is only kept for BWC. You use this to parse `_source` above.
This can be replaced with ``` java boolean isTrue = isExplicitTrue(value); ``` similar to the previous example
I think it would be cleaner to set translated outside of the if statement. ``` boolean translated = incorrectOrientation && rng > DATELINE && rng != 360.0; if (translated || shellCorrected && component != 0) { ... ```
You indent this differently than the thing above it.
nit: some whitespaces around the operators etc... would be nice
Thanks, I probably read the test to quickly and missed the startArray() part. You are absolutely right, this is how I expected the test. Sorry for the noise.
just as feedback, nothing to change really, but I liked the previous variable name better ;-)
I see, and you are right, camel case is preferred. I probably misread the "NoNestedDocs" part of the name as "no nested docs" and that confused me for a second, but either way is fine.
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
can we add an assert to make sure that highlighterType != null here? it really should since we know that plain highlighter always returns true, but the assert would make it more explicit that it is expected
the == false is done on purpose to make these comparisons more explicit
thinking out loud, maybe I am getting confused, but in order for a field to get highlighted, doesn't it need to be stored too or we need to have the _source at least? but metadata fields, which match `*` are not part of the `_source` hence they need to be stored or excluded from highlighting by definition. I have the feeling we should do something more to address that...
I'd go for either check in the constructor or here.
missing t at the end of the method name
While I understand why passing `Plugin` here is safe, after thinking about it a bit, I think I prefer replacing the `Plugin plugin` with `String source` to give the flexibility to choose whether this logic should be applied on the Plugin itself (using `onModule` or `processModules`) or on a different `PreProcessModule` (that latter feels more natural to me)
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think we should use `debug` for the logging here
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
3 more indentation issues above
Looks like there isn't an ExecutebleScript equivalent for search scripts anyway - ignore this.
Talked with @cbuescher in a chat - since these are just copied from their old place they should probably just keep their implementation in this PR. Moving to test framework is still possible in this PR.
And one more...they seem to be all over, I presume a mistake in regex find/replace.
can we use `== false`
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
I'm confused. The cluster state was already applied on the node, no? I don't understand the extra restriction here.
s/to list of/to the list of/
save -> safe :tongue:
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
Ah! More like: ``` private static final ObjectParser<Parameter, Void> PARAMETER_PARSER = new ObjectParser<>("parameter", true, Parameter:true); static { PARAMETER_PARSER.declareBoolean(Parameter::setRequired, new ParseField("required"); } ``` And they you can call it like `PARAMETER_PARSER.parse(parser, null).isRequired()` like you have. That way we reuse the parser. It probably isn't a big deal, but it is what we do everywhere else so we may as well do it here.
I don't think this should have been changed
synchronizing on this method is ok, it should be rarely called
This condition will never evaluate to `true` as we'll get an NPE when dereferencing a `null` instance of type `ExecutorHolder` in the line above.
I you decide to go this route you should also remember to replace the reference equality checks (`this == ActiveShardCount.NONE`) by equals checks or by looking at value (`this.value == 0`).
we "special case" NONE here but not ONE, maybe it's simpler just to remove this method as well as the `validateValue` one and use `new ActiveShardCount(...)` in the two places it's currently used (and also ad ``` if (value < -2) { throw new IllegalArgumentException(...) } ``` to the constructor.
see text from other suggestion for empty primary allocation
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
maybe put this check before the primaryTerm check
if you make `MulticastChannel` generic and the listener as well you safe the hard cast in Shared... just like `Shared extends MulticastChannel<MultiListener>` ...just an idea...
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
it's really taste I guess so fine with me
we are generally moving away from gazillion packages and classes I am not a fan of all these service and they make things more complicated than they need to be today. I have a hard time to understand what feels wrong here and where you draw the line
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
right, its a mock.. then use `ClusterName.DEFAULT` and you need one less constant.
this should be an abstract class, not sure if we also need the `@Ignore` annotation.
I double checked and heard that `@Ignore` is needed as well, otherwise IntelliJ tries to run this test as well when running all tests from the IDE.
I would maybe move this to be the actual test method, with `@Test` annotation, and have either an abstract setup method to be implemented by subclasses or even use junit annotations like `@Before` if possible in the subclasses.
Ok I see the problem... I still find this hackish (needing to throw an exception to test things), but there's no easy way around it if we want to test different requests and responses. I'd consider using a mock request (one per client type actually) instead and give up on testing those real requests and responses. It would be more unit test friendly cause you'd know the request and the response you need to return (unless it's a nodes info request), you don't need an exception and you can assert on the sendRequest directly. Using real requests it feels wrong to only test a few of them anyway and we know that it's the client that injects the headers (`execute` method), that's what we need to test.
good point! I think we need to iterate over the filterFunctionBuilders and rewrite their corresponding filters
you are the man! that is awesome!!! that should just work. I really wonder if we can build a BWC test index with a percolator that ensures we can read this stuff if would be awesome to have asuch a test
looks like it can be final
can you add some inline docs explaining what the hack we are doing here? :)
I'm happy we made those exist queries fast. :)
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Do we need this? the settings are already immutable
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
Oh, I think I see why, it's for closing. I think it's still to pass in a search and close it on exception as you did now.
The caller should continue consuming the snapshot until the `next` method returns null. In the last call, lastSeenSeqNo equals to toSeqNo and op is null. This guard is added to avoid checking in this case. I am +1 on the assertion.
@bleskes I moved this to `next` but we also need to dudup for nested docs then I moved this to `readDocAsOp` again. I think we should optimize for nested docs. I am open to suggestions here.
We have dedup in this PR already (line 161-163). The `lastSeenSeqNo` is used for dedup and range check. I am fine to remove the primary sort and dedup mechanism.
I think I miss something here because I think we need it for now but not in the future after we have a Lucene rollback. I will reach out to discuss this.
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
I wonder if `PARSER.declareString((b, v) -> b.sortMode(SortMode.fromString(b), SORTMODE_FIELD);` is better? I kind of prefer it because then you don't need to think about `ValueType`.
Same deal here, it'd be cool if there was a static `parser` method or `PARSER` member that we could use as a parser here.
Thanks for moving this to `InnerHitContextBuilder` and its subclasses!
+1 to this, there is always the low-level rest client for this, and we can revisit adding it at a later time if we change our minds.
Maybe update, looks good to me now.
Can you switch this around and use the preferred name as first constructor argument? This way it looks like there's something special with this field, which I guess its not.
I'm not sure if this might be a case where both names are allowed, at least the doc state both version, not mentioning any deprecation.
this really really feels like ParseField. What does it buy us over ParseField? Sorry I may be missing it!
I've just noticed in the parsing code that option 1 above is already present (you can specify the `type` in the body of the query). I think given this we should definitely deprecate the `match_phrase` and `match_phrase_prefix` names since you can at the moment do something wholly confusing like: ``` { "query": { "match_phrase": { "my_field": { "query": "foo", "type": "boolean" } } } } ``` The above query looks like a `match_phrase` query but will actually override the `type` and run as a `boolean` match query.
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
you can omit `ElasticsearchException` here it's unchecked
That assumes `list` can't contain null..if that is not the case ignore
for some caches it would be nice to make sure to not compute twice the same value
For things like fielddata I think it's an important requirement
this case got lost
add space after `//`
space missing between `)` and `{`
simpler as it decouples these two things. And no need for having this method return a boolean.
why change the semantics here to only call close when setting the tragedy the first time? Let's keep the existing semantics and make `setTragicException` return void
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
since you are returning the script, I think this can just be called `extractConditional`
I think that we can save the instanceof checks, builder.value(Object) does it already
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
also, at the moment we don't check for ids uniqueness, which is probably fine given what we need ids for, just double checking that we don't rely on uniqueness anywhere
cool can you update the title of the PR then? :)
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
Maybe you could put the validation removed from toCContent here. (point.size > 0)
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
Same here, this it the field type tokenized flag, no? Not sure if this matters.
Can you make this `== false`? It took me a second to see the `!` :)
I think we should have a dedicated method for this in IndicesService. ``` public FieldStats<?> getFieldStats(Engine.Searcher searcher, String field) { // do the caching in here and also lookup the MappedFieldType again! } ``` this way we don't allow everybody to cache whatever on our request cache!
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
Sorry, I overlooked the null check. This is good!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Ahh, sorry. You are 100% correct.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I'd prefer to have a simple `assertEquals` and to a String comparison here. No need for all the constants either, makes it harder to read IMHO.
Good point, I forgot about the pretty printing. `equalToIgnoringWhiteSpace` sounds good.
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
I'd recommend using the same syntax Lucene does: ``` bq.clauses().iterator().next().getQuery() ``` Just to follow their conventions
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
I think it should either be an `else if` or the `if` should be on the next line.
if it doesn't have clauses we don't set the boost and ignore the queryName. I think it would be a bit more readable if we had two if branches, and the set boost and named query handling after the if which kicks in in both cases.
of course how could I forget about this, I pushed it 30 mins ago :)
Clearing the current publication could be a method on the publication, avoiding the `thisPublication` malarky. The only other use is to call `toString()`.
I know this is for concurrency reasons. Just wondering: Would it make sense to move the update of the term under the mutex? In that case, this condition would not need to be checked here.
Not 100% sure of the rules here, but `private` seems too restricted for this.
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
Does this question have an answer? I _think_ any failures are passed to the response handler.
Unused import here (not really a big deal)
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
Shouldn't this be using `ElasticsearchTestCase.randomFrom` instead of `com.carrotsearch.ant.tasks.junit4.dependencies.com.carrotsearch.randomizedtesting.generators.RandomPicks.randomFrom`? I don't want it to end up not using the right seed
I don't know that we should fix this now, but I think failures of this test will miss the gradle reproduction steps, right? I've been thinking of pulling those into a tiny shared project without dependencies just so we don't have trouble with stuff like this but I haven't looked into it deeply enough to be sure.
The first two of these fields are unused. I think that's right, and we should remove them and also `ec2Bucket`, by generating the key and token and then passing them into the bucket's constructor.
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
This method is not necessary. With the code as is, we would be extracting the entire zip, but only using the one directory from it. Instead, we should do checks when extracting, see the `unzip` method. There we can have a prefix check like: ``` if (entry.getName().startsWith("elasticsearch/") == false) { // only extract the elasticsearch directory continue; } Path targetFile = target.resolve(entry.getName().substring("elasticsearch/".size())); ``` This will unzip everything in the `elasticsearch` directory directly into the temp installation directory, and all the other plugin cli installation code can work as-is.
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
right I had missed that previous check, sounds good then
If they are different then mlockall will not really work on unix either. That is because it may map additional stuff later!
@gmarz @kimchy but it is okay for them to be different simply because we allow it :) The worse case is that we kill starting with MinHeap (growing to max immediately) instead of otherwise the worse case being mlockall'ing too little.
Can we just add max(HeapInit, HeapMax) feels like a quick win here.
would be nice to allow to configure it to a percentage of the heap size
The (int) conversion is not needed here.
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
I think we can omit catching this and failing when caught, that's default behaviour, what matters if the `finally` I guess
same as above, this seems the same method as before
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
yea I think it would be good to have a test that makes sure that the index expression specified in remove_index resolves against indices only, rather than aliases and indices. I don't think the current test does that.
++ . nit: add the state to the message please.
++, one less releasable to remember to free.
same here re enumSet.toString
what are testing here? sounds like primaryPhaseExecutesRequest
can we sometime just rely on the wrong allocation id? (and have a valid node)
I see that there is already a rest test, great!
foo all switch statements in those tests, I think it would be less error-prone if we fail() in the default case? (not as much for now as for when we'll modify these tests)
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
Ah ok, I missing that method below, sorry.
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
I'm on the fence as to whether we should only do this on non-realtime get. Real time gets don't really relate to refresh cycles (they force a refresh if needed). They are already "efficient" in the sense that they only refresh if they need to (i.e., there's a pending doc change in the version map).
should remove the "force:[{}]" in trace logger. @s1monw
I wonder if this case distinction should be part of ReplicatedOperation.
long live java 8
my thoughts too :)
nit: space after IOException
braces please. for the rest of the method too. (I realize you just tweaked this to be a lambda but it would be good to fix this as two line single statement `if`s are dangerous and evil).
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
We should also remove the other builders to be consistent. WDYT @polyfractal ? I can do that in a follow up.
go for it, thanks @tlrx !
As we never expect a null value to be passed as parameter to this internal method, I'm not a fan of sprinkling this check here. This is defensive programming at its worst.
nit: `== false`
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
no need for `else` here: ``` java if (numPredictions < 1) { throw new IllegalArgumentException("numPredictions may not be less than 1."); } if (numPredictions == 1) { predictions[0] = next(values); return predictions; } ```
the `numPredications < 1` check feels like an assertion... should probably be the first statement in the method
I mean in the code but just noticed there was one already
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
And i just did not have the time to yet yesterday remove the stupid asserts from SpanScorer. Please, lets not drag this stuff in again. If oyu want to push fine, but you will see a second push from me removing all this crap.
Why do we need the copy-paste at all? This whole thing seems like a code duplication of PayloadTermQuery.
would be great if this logic could be unit tested.
just my personal preference, I don't like instanceof checks that's it. you are free to leave them if you prefer them ;)
Sorry, I missed that you need to track scores as well. Then indeed, a LongHash would make sense.
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
64e5c25 added support for this.
It might also depend on which implementation of `AcknowledgedResponse` you are using, since we have two, yay duplication!!! You should have a look at `StartRollupJobResponse`, which is an example of changing the word from `acknowledged` to `started`. this should get you on the right track.
heh, duh... Sorry, ive been on vacation and full of turkey since last week.
Hey I saw some updates on this PR and I just wanted to throw a reminder out that we are not going to do a singleton(404) here, because we want a delete that is not found to throw an exception. Also, last time we spoke you were going to change this to AcknowledgedResponse. <3
I think that will fail compilation? ð
Oh, never mind, I misread. Sorry for that. ð
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
I guess it could be renamed to isFalse() / isTrue() now
++ for ordinal and tests then
I wonder if you can remove the `Response` type parameter here too!
either way that's fine
again, picking around unrelated changes with `git add --patch` is hugely helpful in reducing noise.
Sorry, I am not sure why but my mind inserted a `static` into that field definition. That's clearly not there so of course what you have is fine.
I am fine with doing it in a follow-up PR if that works better for you
don't try to fix it, you just moved code around, but this catch block worries me :(
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
You didn't introduce it, but seeing this line again reminds me that this is buggy if Long.compare returns Integer.MIN_VALUE, which is legal :) So it should rather be `Long.compare(o2.getDocCount(), o1.getDocCount())` (without the minus sign)
actually I don't fully understand why we can't just do `this.order = order` all the time
Can you throw something else? It just makes me uncomfortable to throw AssertionError.
nit: indenting should be only 4 extra spaces
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
this can be out of if now.
can we add some randomization here around the version - check that new has a higher version then old and vice versa
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
did you run into this being a problem? how can we open an index that was created before 5.0.0 and never had insync replicas but does have allocationId? the only thing I can think of is a node network issue during shard initialization. I'm wondering if we need to optimize for this and no keep this code simple (i.e., demote shards with a lock exception)
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
Whoa this is even stranger to read since it spans 3 lines
Miss the sorting based on the version. Sorry for the noise..
A better wording for the error is: `[from] can't be negative` Changing that will require updating tests
I'm wondering that maybe we should not expose SearchAfterBuilder at all to the client API and make it internal to SearchSourceBuilder? So SearchSourceBuilder would still hold a SearchAfterBuilder instance, but the two above methods would look like: ``` java public Object[] searchAfter() { return searchAfterBuilder.getSortValues(); } public SearchSourceBuilder searchAfter(Object[] values) { this.searchAfterBuilder = new SearchAfterBuilder(values); return this; } ```
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
nit: `maxInspections must be positive`
I think "from" should be "from2" here. Also I would make the calculation simpler here as well, I think otherwise min might be smaller than max in the calls to "randomIntBetween"
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
whoops I read it backwards, so yeah, not really necessary
Perhaps add the duplicate size to the assert message here
exiting -> exists
I think this would be cleaner as ```java aliasAndIndexLookup.compute(aliasMetaData.getAlias(), (aliasName, alias) -> { if (alias == null) { return new AliasOrIndex.Alias(aliasMetaData, indexMetaData); } else { ((AliasOrIndex.Alias) alias).addIndex(indexMetaData); return alias; } }); ```
I think that inserting random fields here would reveal problems on the parsing side with the current code.
what happens if there is no mapper? I would tend to simply ignore (to match the logic we have for stored fields now)
Can you test something that is not byte-aligned, like /15 or /17? We used to have bugs in those cases.
we should `@Test` to forbidden API
If these privileges are only needed for loading static definitions, then this should be done in a static block when the plugin is loaded, instead of on every invocation of the script.
this could be a for each loop instead
I am surprised that we don't have a default impl for this :)
The `new HashSet<>()` can be replaced with `Collections.emptySet()` (and then you'll have an import to remove).
Typo: `afllowed` -> `allowed`
No need for an empty default ctor when the super is also a default ctor.
It'd be nice to be sure it contained that `not_found` wasn't found.
same here with awaitBusy
are those number randomizable ie `randomIntBetween(1,100)`
use `assertNoShardFailures` here please
I would just `throw e;` here
acceptDocs will be checked _before_ these bits are checked anyway
Fine with me.
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
here is a space missing before `EMPTY_FLAGS`
I had the same thought, but I guess the point is to properly validate things when they get set to the builder, so that non supported values will never be serialized. I assume that we do that already, otherwise we should.
So as far as I see is this is the crucial change in this PR? I was wondering if might have undesired effects that we allow more field value types to be serialized/deserialized than before by using `writeGenericValue`. What would happen for example when fieldValue is a GeoPoint. It would have caused the serialization to trip previously, now it will be okay (and I guess it might cause error later). I guess switching to `writeGenericValue` is a good tradeoff here but would like to hear your ideas about that.
Can you switch this around and use the preferred name as first constructor argument? This way it looks like there's something special with this field, which I guess its not.
this should be `isArtificial`
It looks like you have proper ram usage stuff. Maybe it'd be simpler to refuse to expand the tree if it'd put the `bytesAllocated` above a certain size.
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
I'm not sure if the cast is worth it here. It is usually simpler to just work in integers even if we know if can't be more than 255.
I'm fine with the answer being "no, you are crazy Nik" or "not right now".
this class is also missing a hashCode impl.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
Oh I see it below, makes sense, `wrapper` just sounds like a noun instead of a flag
We should change this to smile
for readability I'd use this. as well
I know it was like that before, but we are here now. ð
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
hmm actually I think we should load deleted queries too
I'm wondering why you decided to override this optional API. Is this impl expected to be faster than pulling the iterator and calling next in a loop? (this is what the default impl does)
I'm clearly not getting my point across. Please understand that multiple tests are run in the same jvm during jenkins!!!!!!!!!!!!
I wonder if we want to ban `new Random(int)` to make it harder for folks to do `new Random(System.currentTimeMillis)`. If so then `Randomness` is probably the right way to go. Otherwise I like `GOOD_FAST_HASH_SEED`.
Just to make it better, setting it here in clinit is not so ideal, because its not perfectly reproducible when multiple tests are run in the same jvm. you will still have perceived reproducibility issues vs jenkins if you go about it this way: because the random will be initialized _once_ and then we will run 8 test classes against it. then, when you later try to reproduce the one that failed, the sequence will be different (even though the initial value is the same), because the other tests are not also invoked. but if you do it this way, it at least allows "whole build" reproducibility, which is an improvement. That means e.g. if you nuke your local execution hints file and run 'gradle test -Dtests.seed=xxxxxx -Dtests.jvm=yyyyyy', it will match what jenkins did. But nobody does that.
In general can you please make sure you are not using your own code style. Please adopt to the codestyle which is mainly default SUN except of 4 spaces indent.
same here this is a left over!
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
I think filter and query can never be null here? not sure whether we should validate this here.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
I think we can simplify here and print everything out, default values included, that's what we went for in all of the other queries too.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
one too many new line? :)
Can you `s/.execute().get()/.get()/`? I try to do that if I'm going to be touching the line.
do we really need so many tests? this is just about parsing? It can probably just have unit testing for this..
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
The method name implies yellow though. I bet there are places where we don't _need_ green.
Thanks, I get the general idea now.
I don't see any implementations extending this at the moment, are there any plans to add some later? If this is just going to be a collection of static methods and ParseFields I'd suggest making this an interface.
Okay, can you briefly explain the (maybe future) relationship of the ShapeParser and the above GeoJsonParser class? Currently they both seem to mostly consist of a "static ShapeBuilder parse(XContentParser parser, GeoShapeFieldMapper shapeMapper)" method, don't have any state themselves but ShapeParser calls GeoJsonParser. It would be useful to understand where this is going.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: these could probably even be package private
nit: you might be able to save a few toString lines by extending ToXContentToBytes here. no big deal though
Writeable does that too but allows to have final fields and drop empty constructors
+1 on pulling this out, I'm sure this can be used in other places, although in many of the tests I'm thinking about right now we have NamedWriteable things under test, but only the copy method would need to be slightly different.
lets keep this class here and make it pkg private and final. it's very special
I understand this, but this sound confusing to me. You would have some member in each builder that is only set for the prototypes, need special constructors for the injection. I understand your proposed solution with the static method access much better.
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
If the constructor is modified, this method won't be needed anymore.
It would be nice if this class was immutable, and this line shows why it isn't currently. This is how to make it immutable: ``` List<CompositeValuesSourceBuilder<?>> sources = new ArrayList<>(num); for (int i = 0; i < num; i++) { CompositeValuesSourceBuilder<?> builder = CompositeValuesSourceParserHelper.readFrom(in); sources.add(builder); } this.sources = Collections.unmodifableList(sources); ```
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
oh boy :)
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
can we just pass the action to the `AsyncShardFetch` class instead of subclassing this seems so close, maybe the two actions can share a common interface
i think `== true` can be skipped
this method seems to be wrong here the class is concerned with fetching data in an async fashion, I think what we do with it or what we call as a result should just be somewhere else. I wonder if we can just have an ActionListener that we pass to execute this onSuccess and onFailure since those seem to be the two mode we have.
we only need an array here - we don't do anything with the version and we copy it into one anyway: https://github.com/elastic/elasticsearch/pull/12335/files#diff-ad5388a03f5e080b452190f4eb47f33aR244 Might as well use an arraylist from the beginning.
cool. lets look at it on another issue.
typo, all flies -> files
minor semantic difference: over [here](https://github.com/s1monw/elasticsearch/blob/fix_recovery_finalization/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java#L304) we throw the unwrapped corruption exception, not the remote version. I think we should do the same here and throw corruptIndexException
Don't we need to throw the exceptions list here, like we do before: ``` ExceptionsHelper.rethrowAndSuppress(exceptions); ```
typo - failIfCancled -> failIfCanceled
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
I assumed that there is no problem setting values and checking that the output of the conversion from high-level request to low-level request is the expected one. We don't validate etc. I would do only what is straight-forward.
Nit: space between the cast operator and the target.
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
ok fair enough...
this is not needed. createIndex automatically reroutes.
maybe make this variable final? just better indicate it will never change
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
nthe -> the
yeah, that was what I meant
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
Question, do you think it would be helpful to copy the pattern we have elsewhere having a `*Safe` version of the functions? So something like: ``` java public Decision getDecisionSafe() { if (isDecisionTaken() == false) { throw new IllegalArgumentException("decision must have been taken in order to return decision"); } return decision; } ```
Additionally, I like calling these `getFinalDecision` in ClusterAllocationExplanation.java because it differentiated it from the node decisions, how do you feel about that? (It would also probably change `getExplanation()` to `getFinalExplanation()`)
shard can remain
The `Coordinator` becomes leader in `joinHandler.test()` not in `handleJoinRequest`, and that's outside this mutex, so it's technically possible that it could become a candidate again before this synchronised block.
This definitely feels like overkill now the `JoinHelper` is mode-aware and its mode is in sync with the coordinator.
Should really ask for `toString()`s on these handlers too, although this adds noise.
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
Not 100% sure of the rules here, but `private` seems too restricted for this.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
ok, fair enough
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
I think adding a constant somewhere for # makes sense. It may make sense to also add a constant for typed_keys, but I don't have a strong opinion on that.
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
Not sure this should be "Query" ð
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
Also, please annotate with `@IndexSettings Settings indexSettings`, there's nothing worse than `indexSettings` being renamed to `settings` at a later time and then not knowing which Settings it actually is.
`s/shadow replicas/shadow shards/`
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
confuses the shit out of me everytime :)
nit: extra line
Oh, never mind, I misread. Sorry for that. ð
I think that will fail compilation? ð
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
I was wondering if `getSuperset/SubsetSize` is part of the Bucket interface but not rendered via the Rest response, should we either add rendering of these values to the bucket response or remove it from the interface to get equivalent behaviour of functionality of the transport client with the high level rest client here? I think this can be done in a separate issue though, maybe its not needed at all.
I'm okay with the UnsupportedOperationException for now if we can track this question (whether we can reach consistency between the functionality the transport client provides via the SignificantTerms.Bucket interface with the rest response) in a separate issue
does this work? it works for percentiles, but with percentiles rank it's reversed
Wow, that's a big difference! Do you know whether it is lossy compression or not? If not then indeed compression seems to make a lot of sense. :-)
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
Also, since "recover" and "restore" are very similar and easy to confuse, I think it'd be nice if this were named "`recoverState`"
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
actually I'm wondering if we should use an IntObjectHashMap: given that the percolator works on a type, I'm afraid users have a lot of data in other types too so creating a Query[maxDoc] could cause an OOME on some of them. By using an IntObjectHashMap we will be more on the safe side: it will une more memory if all docs have a query but much less in the sparse case.
I think we can just use an FsRepository for this. All our other shard-level tests do the same, so no need to optimize this. If we want to change that in the future, I think it's easier to switch to jimfs and continue using FsRepository.
`expectedType.cast(e)` should remove the need for the unchecked suppression.
A blank line above and below. ð
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Same here with period and lowercase
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
Nit: it isn't a jsonBuilder - it is whatever kind of xcontent was passed in. Nit: maybe only set prettyPrint if the original had it set? I don't know if you can tell though. Neither are a big deal.
do we need == true ? :)
So maybe you don't need to handle the null case at all and just expect people not to pass null because it is a vararg. And it isn't passed as `@Nullable`.
you should replace the curly bracket with a square bracket here.... :D
If you want to test the multi-write behavior you could make a testing aggregation here that needs to be rewritten twice. I'm not sure how important that is to you, but it ought to be possible.
a transformer and performer. Quite a guy :)
Typo "uncomitted" -> "uncommitted"
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
Another `_` java 9 will be mad at
we should assert this is never called (same for the other places here where `UnsupportedOperationException` is thrown), as this indicates a bug.
No, there are only two ways for sets/maps, because of how multibinder works. I think it is more confusing to have some things bound using a binder, and others with registration/settings. Classes that ES controls should be registered, and set. If there was a way to just not allow multiple multibinders to work I would say we should do that, but I don't think such a thing exists.
Also, we should really move this discussion to another issue. I think this PR is fine as is, this was just a suggestion for a follow up/thought.
Having limitless extensibility is not a good thing... as a plugin developer, I want to know what I can and cannot do... what I can extend. Otherwise I can easily do something I really shouldn't, break something along the way, without even knowing I broke it. Having well defined extension points and effectively limiting the extensibility of es in general: - helps us make sure plugins cannot break things (as they'll be restricted to what we allow them to do) - helps the users know what they can do and rest assured that they're not doing something they're not supposed to So overall, personally I'm less concerned about not capturing all the extension points at first run.. I'm more concerned about first capturing control over it. Then we can start opening up extension points as we see fit in a controlled manner.
Awesome! This is what I was missing! :+1: :heart:
I think we have this logic in the settings already maybe we can factor it out and reuse? seems scary and it would be good to be consistent.
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
This should be a `ConstructingObjectParser` so that the private empty ctr can be removed.
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
nit: I changed this on master to get the parser from AcknowledgedResponse using a new `generateParser` method that I introduced there on request of Baz. Maybe we could use the same here in the backport to make it match the version on master.
should be `final`
Not necessary with `ConstructingObjectParser`
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
could be a instance variable, as used in all tests
why a single data node? If you need that, you can use `numDataNodes=1` instead
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
Shouldn't this be using `ElasticsearchTestCase.randomFrom` instead of `com.carrotsearch.ant.tasks.junit4.dependencies.com.carrotsearch.randomizedtesting.generators.RandomPicks.randomFrom`? I don't want it to end up not using the right seed
nit: space after `if`
This method seems like it could be in `JobConfigProvider`? Then we don't have to duplicate it between this action and the put-datafeed action.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
Right - RollupIT is the right place
This seems like it should be handled in the `JobConfigProvider` so that any callers don't have to deal with the same error handling.
Maybe replace these with writeOptionalString as well while you are at it
I understand this is the oversight you've mentioned
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
nit: possibly use readOptionalWriteable here
these replacements seem to be wrong the if / else logic is obsolete now
same here - pls refer to `current`
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
64e5c25 added support for this.
s/token role/token. Mention asynchronously
heh, duh... Sorry, ive been on vacation and full of turkey since last week.
This can be `Files.notExist(...)`
I know this was copied over from another place, but I wonder if we should give preference to the recovering file. If I read this correctly , if we have both recovering and non-recovering, it is now random which one we choose.
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
Typo, "Trasnlog" -> "Translog"
can we use package private methods and have unit tests for this.. an integration seems like an overkill.
I suspect these will be too small and we'll have time outs.
I think we can clean up the http/transport/gatway settings here
boo! :) just ignore :)
if you want to know i happened, let's use logging..
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
also, at the moment we don't check for ids uniqueness, which is probably fine given what we need ids for, just double checking that we don't rely on uniqueness anywhere
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
make the error a bit more understandable for users? Like "processor x doesn't support some of the provided configuration parameters" and list them like you do already...
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
> we still want to use an beta over an alpha There shouldn't be anything needing to choose a beta over an alpha? There should be nothing using any qualified build to check bwc.
I don't know what you mean by "consider qualifier in the build". There should be no attempt to test bwc of any qualified version, so I don't believe the build needs to know about it in our build Version, since that class is all about which versions we bwc test against.
I would make the class `final`, and these members `public final`
I think that it's cleaner to write this as: ``` ElasticsearchParseException ex = (ElasticsearchParseException)ExceptionsHelper.unwrap(e, ElasticsearchParseException.class); assertNotNull(ex); assertThat(ex.getMessage(), equalTo("processor [test] doesn't support one or more provided configuration parameters [unused]")); ```
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
Do we really need to ignore the setting in post 2.0 indexes? Why not just support both for a while? You already check above that both aren't specified.
I _think_ we have a deprecation logger. We should probably log something when we see `position_offset_gap`.
We shouldn't need to log if we through an exception. I don't like the hard cutover but I can live with it. If I discount the hard cutover my only thing is the exception message.
I don't think we need this part? Even if you've created an index with 6.4, you still want to be warned that things are going away if you upgrade to 6.5
I don't think we should do `__default__` we can pass the default separately...
If you want to test the multi-write behavior you could make a testing aggregation here that needs to be rewritten twice. I'm not sure how important that is to you, but it ought to be possible.
I'm wondering if the parent really helps define equality here? Additionally, by adding this we will do more checks than necessary given that we compare both sub-aggs and parent aggs
you should replace the curly bracket with a square bracket here.... :D
I am not a huge fan of base64 but I guess you are right.
I think we can just pass the bytes directly to the json generator it will do the right thing with it.
same here regarding nullable ..
We suppress and not report all errors which are OK. I don't think we need a special protection here about it.
Elasticsearch tradition is to make this an EMPTY constant :)
drop the actually? sounds so "uncertain" :)
we can use in.readVInt() here, no? it's always non-negative... (same goes for other counters and also note that you'd have to change the writeTo message of course)
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
I think this needs to be `Version.V_6_0_0_alpha3` now.
Just discussed it with Robert and indeed this fsync is not necessary.
`them` -> `them;`
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
Why is this `volatile`? It doesn't look necessary to me.
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
The logging brackets are off here: `[{} to [{}]]`.
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
And i just did not have the time to yet yesterday remove the stupid asserts from SpanScorer. Please, lets not drag this stuff in again. If oyu want to push fine, but you will see a second push from me removing all this crap.
Why do we need the copy-paste at all? This whole thing seems like a code duplication of PayloadTermQuery.
For things like fielddata I think it's an important requirement
I liked the assertion you had there that if already have a result, this one has a higher seq no
please wrap in {}
please wrap with `{}`
you have 140 chars use them :)
maybe move the loop in a method then we can return early and don't need a label / boolean var in the outer loop
typo: optain -> obtain
ok, then assert that it's either snapshot or generic threadpool
let's check this on every access, not only creation.
If you need this in test, you can still call it getBlobStore()
I'd expect this to be in a synchronized block
I think we should use `writeAtomic` everywhere just to reduce the complexity.
I think allowing this on a whole class is too broad. Is there a use case I'm not thinking of? I just figure it'd almost always be better to have it on a method or constructor.
> fail if the annotation was unnecessary Yeah, that is very important. It would be nice to be able to annotate at the exception level. Much cleaner if not for those nasty problems. I still think we shouldn't allow the annotation on classes at all and should force them to make a static method call if they want to swallow. But I'm not so against it that I'd block this whole PR over it.
Consider adding ``` static final NoAuthCredentials NONE = new NoAuthCredentials(); ``` and making the `NoAuthCredentials` `class` package protected (drop `public`). It may not be used enough to warrant having a `static` field hanging around though, but I liked what you did with the original `BasicAuthCredentials` and `EMPTY` before changing it a bit.
Also not gonna make java 7 very happy.
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
then check for non null here...
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
is this needed here? I think it does something only when the current token is start array or start object.
I'd probably write validate's results to a variable and reuse it.
I think this patch could work just fine? ``` DIFF diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java index 8a1df50..94a0ab1 100644 --- a/core/src/main/java/org/elasticsearch/node/Node.java +++ b/core/src/main/java/org/elasticsearch/node/Node.java @@ -98,6 +98,7 @@ import org.elasticsearch.search.SearchService; import org.elasticsearch.snapshots.SnapshotShardsService; import org.elasticsearch.snapshots.SnapshotsService; import org.elasticsearch.tasks.TaskResultsService; +import org.elasticsearch.threadpool.ExecutorBuilder; import org.elasticsearch.threadpool.ThreadPool; import org.elasticsearch.threadpool.ThreadPoolModule; import org.elasticsearch.transport.TransportService; @@ -210,12 +211,12 @@ public class Node implements Closeable { throw new IllegalStateException("Failed to created node environment", ex); } final NetworkService networkService = new NetworkService(settings); - final ThreadPool threadPool = new ThreadPool(settings); + final List<ExecutorBuilder<?>> executorBuilders = pluginsService.getExecutorBuilders(); + final ThreadPool threadPool = new ThreadPool(settings, executorBuilders.toArray(new ExecutorBuilder[0])); NamedWriteableRegistry namedWriteableRegistry = new NamedWriteableRegistry(); boolean success = false; try { - final MonitorService monitorService = new MonitorService(settings, nodeEnvironment, threadPool); ModulesBuilder modules = new ModulesBuilder(); modules.add(new Version.Module(version)); modules.add(new CircuitBreakerModule(settings)); @@ -223,6 +224,7 @@ public class Node implements Closeable { for (Module pluginModule : pluginsService.nodeModules()) { modules.add(pluginModule); } + final MonitorService monitorService = new MonitorService(settings, nodeEnvironment, threadPool); modules.add(new PluginsModule(pluginsService)); SettingsModule settingsModule = new SettingsModule(this.settings); modules.add(settingsModule); diff --git a/core/src/main/java/org/elasticsearch/plugins/Plugin.java b/core/src/main/java/org/elasticsearch/plugins/Plugin.java index 1efc151..695a255 100644 --- a/core/src/main/java/org/elasticsearch/plugins/Plugin.java +++ b/core/src/main/java/org/elasticsearch/plugins/Plugin.java @@ -23,9 +23,12 @@ import org.elasticsearch.common.component.LifecycleComponent; import org.elasticsearch.common.inject.Module; import org.elasticsearch.common.settings.Settings; import org.elasticsearch.index.IndexModule; +import org.elasticsearch.threadpool.ExecutorBuilder; +import org.elasticsearch.threadpool.ThreadPool; import java.util.Collection; import java.util.Collections; +import java.util.List; /** * An extension point allowing to plug in custom functionality. @@ -80,4 +83,8 @@ public abstract class Plugin { */ @Deprecated public final void onModule(IndexModule indexModule) {} + + public List<ExecutorBuilder<?>> getExecutorBuilders() { + return Collections.emptyList(); + } } diff --git a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java index f373da6..bb22854 100644 --- a/core/src/main/java/org/elasticsearch/plugins/PluginsService.java +++ b/core/src/main/java/org/elasticsearch/plugins/PluginsService.java @@ -40,6 +40,7 @@ import org.elasticsearch.common.settings.Setting; import org.elasticsearch.common.settings.Setting.Property; import org.elasticsearch.common.settings.Settings; import org.elasticsearch.index.IndexModule; +import org.elasticsearch.threadpool.ExecutorBuilder; import java.io.IOException; import java.lang.reflect.InvocationTargetException; @@ -261,6 +262,14 @@ public class PluginsService extends AbstractComponent { return modules; } + public List<ExecutorBuilder<?>> getExecutorBuilders() { + ArrayList<ExecutorBuilder<?>> builders = new ArrayList<>(); + for (Tuple<PluginInfo, Plugin> plugin : plugins) { + builders.addAll(plugin.v2().getExecutorBuilders()); + } + return getExecutorBuilders(); + } + public Collection<Class<? extends LifecycleComponent>> nodeServices() { List<Class<? extends LifecycleComponent>> services = new ArrayList<>(); for (Tuple<PluginInfo, Plugin> plugin : plugins) { diff --git a/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java b/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java index 31f3f31..61e5141 100644 --- a/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java +++ b/core/src/main/java/org/elasticsearch/threadpool/ExecutorBuilder.java @@ -30,7 +30,7 @@ import java.util.List; * * @param <U> the underlying type of the executor settings */ -abstract class ExecutorBuilder<U extends ExecutorBuilder.ExecutorSettings> { +public abstract class ExecutorBuilder<U extends ExecutorBuilder.ExecutorSettings> { private final String name; diff --git a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java index 0b564b2..1d641aa 100644 --- a/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java +++ b/core/src/main/java/org/elasticsearch/threadpool/ThreadPool.java @@ -151,7 +151,7 @@ public class ThreadPool extends AbstractLifecycleComponent<ThreadPool> { return Collections.unmodifiableCollection(builders.values()); } - public ThreadPool(Settings settings) { + public ThreadPool(Settings settings, ExecutorBuilder<?>... customBuilders) { super(settings); final Map<String, ExecutorBuilder> builders = new HashMap<>(); @@ -175,7 +175,13 @@ public class ThreadPool extends AbstractLifecycleComponent<ThreadPool> { builders.put(Names.FETCH_SHARD_STARTED, new ScalingExecutorBuilder(Names.FETCH_SHARD_STARTED, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5))); builders.put(Names.FORCE_MERGE, new FixedExecutorBuilder(settings, Names.FORCE_MERGE, 1, -1)); builders.put(Names.FETCH_SHARD_STORE, new ScalingExecutorBuilder(Names.FETCH_SHARD_STORE, 1, 2 * availableProcessors, TimeValue.timeValueMinutes(5))); - this.builders = builders; + for (ExecutorBuilder<?> builder : customBuilders) { + if (builders.containsKey(builder.name())) { + throw new IllegalArgumentException("builder with name: " + builder.name() + " already exists"); + } + builders.put(builder.name(), builder); + } + this.builders = Collections.unmodifiableMap(builders); assert Node.NODE_NAME_SETTING.exists(settings); threadContext = new ThreadContext(settings); @@ -190,10 +196,6 @@ public class ThreadPool extends AbstractLifecycleComponent<ThreadPool> { this.estimatedTimeThread.start(); } - void add(ExecutorBuilder builder) { - builders.put(builder.name(), builder); - } - @Override protected void doStart() { final Map<String, ExecutorHolder> executors = new HashMap<>(); ```
wondering whether it'd be better to just call the index `".ingest"`... it'll give us flexibility if we'll need to store other things later on aside from pipelines
I wonder if we want to add an `@After` rule that checks that all semaphore permits are back.
should this method be public? The scheduling methods are public as well as the advanceTime. I think ` hasRunnableTasks`, `hasDeferredTasks`, `getCurrentTimeMillis` and `runNextTask` should be as well.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
you also have this variant `org.elasticsearch.common.xcontent.XContentBuilder#timeValueField(java.lang.String, java.lang.String, long, java.util.concurrent.TimeUnit)` which you can use without changing TimeValue
newQueue -> newTombstone
If we use Collection<Tombstonre> we can return an unmodifiableCollection() which doesn't copy stuff..
oh, the boxing horrors :)
I think we could persist a time-to-live in the cluster state, and on each cluster state update the current master can subtract the offset between the current `System#nanoTime` and the `System#nanoTime` from the last time the master updated its local cluster state and persist the maximum of the new time remaining and zero. Now the tombstone will live exactly as long as there has been an active master and we do not have to worry about any crazy time issues.
As this setting should usually be only set once, it is probably simpler to leave it non-dynamic (as @jasontedor suggested and as it was before this PR). In case where this must absolutely be updated on a production cluster, rolling restart (of master nodes) with config update is always possible.
fancy pants :)
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
I don't think so, I think these should be bytes or size-value only.
++ to keep byteSizeSetting here
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
You can use `assertAcked()`
Can you use more explicit name? (Also for getRepositoriesResponse1/2).
I don't think we need to check the implementation class, instance should be enough.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
I think it would have been worth it but now that you mention it - other requests may have changed this in the mean time too, so let's leave this assertion.
ok didn't know that. yet another bug fixed in master then it seems
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
wonder if we should make these Integer and Boolean just int and boolean primite types.
this would make sense especially given that their setters accept primitive types
you can use `assertAcked(prepareCreate(...))` here
I get that, I was just wondering why those default templates bother here
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
you can simplify this a bit here: ``` Java NodeStats unluckyNode = randomFrom(Iterables.toArray(nodestats.getNodes())); ```
+1 I like plugin examples!
is this somewhere on a todo? I'm afraid we'll loose it
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
Since this is only going to be used in tests, I think we can get away with: ```suggestion return Objects.hash(maxSeqNo, localCheckpoint, globalCheckpoint); ```
Please fix identation.
Maybe let's just call Objects.equal(script, other.script) for simplicity? I know you did not introduce it though...
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
I also think we should not catch the excep here.
Construction now loses the side effect of a `NullPointerException` when this class is misused by giving `null` values for everything except `sourcePath`, which could lead to new, unexpected `NullPointerException`s upon use.
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
I'd just use the Id really
Needs a guard.
Needs a guard.
Needs a guard.
You don't trust Files.move :)
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
which other queries do you mean? You mean check against this specific field in similar queries or just in general. I think the question is "when can this happen?". If stuff can happen in both java api and rest layer, validate is the way to go. If we already perform some kind of validation that makes sense in the parser, then having null here can happen only from the java api and we should maybe try and fail straight-away.
again, this is the reasoning: if we check for existence of a field in the parser, it means that the only way it can be null in the builder is when it comes in through java api. In that case we might want to fail fast and throw error in the constructor/setter already rather than in validate. If non validated values might come in through the parser as well then validate is the way to go. In this case it makes to do as Christoph suggested. In term query builder I think it still makes sense what we do (again, you can test it to see the differences), same for common terms query.
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
Maybe you could put the validation removed from toCContent here. (point.size > 0)
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
this deserves a sep issue I guess but good catch
do we need ordered things? does order help anywhere? If not I would just use HashMap
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Nit: `added [{}] the` -> `added [{}] to the`
I think we should remove this method and insist on using the setScoreMode(QueryRescoreMode) method instead. This will make the API cleaner as only the permitted values (the ones in the enum) can be used. The parser can then use the fromString() method to convert REST request values to the enum but Java API users will have the safety of the enum
Nit: I think you can leave out ESTestCase here.
I think we should remove this method and the ignoreMalformed() method and instead have a validationMethod() method here instead
Nit: I think you can leave out ESTestCase here.
I wonder if `PARSER.declareString((b, v) -> b.sortMode(SortMode.fromString(b), SORTMODE_FIELD);` is better? I kind of prefer it because then you don't need to think about `ValueType`.
could be a instance variable, as used in all tests
I'm pretty sure this just throws an AssertionError so it wouldn't work either. I don't suspect it'd be very likely and I think the test would fail spectacularly on an InterruptedException anyway, so maybe just log an error? You could also make some list outside the runnable to accumulate the result. I bet we have some useful thing sitting around for this if you wanted to do more than log though.
Got it. LGTM
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
Missing the `indexName` argument to the debug log here
typo here "ot" -> "to"
`FutureUtils.cancel` has a check for a null future, no need to add this check
can we log the full index object, includeing the index uuid? also it would be good to have the current cluster uuid and the one in the index meta data state.
this is unneeded - we just iterate of the list...
Wherever makes the most sense really. In this case I would put the default constants in `DirectSpellcheckerSettings` I think
nit: IMO `suggestMode must not be null` sounds more explicit.
nit: `accuracy` instead of `Accuracy`
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
These should all have sensible defaults rather than being null, as we have done with all the other builders. This also means we can remove @Nullable from all of the methods and add checks in there that throw an exception if null is passed in to make it safer. The defaults we currently use can be found in DirectSpellcheckerSettings.
This potentially overflows. I mean it's ok for our purposes (it overflows deterministically) but a sufficiently powerful linter would complain. Suggest `^` instead of `+`.
this is not needed. createIndex automatically reroutes.
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
missing fail :) use expectThrows instead
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
maybe just call this `public BytesReference materializeAndClose() throws IOException` and don't even return the stream.
lets keep this class here and make it pkg private and final. it's very special
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
maybe use `shouldCompress` here to make it a little clearer? ```java if (shouldCompress) { IOUtils.closeWhileHandlingException(stream, bytesStreamOutput); } else { assert stream == bytesStreamOutput : "the stream variable is not the same instance as bytesStreamOutput"; IOUtils.closeWhileHandlingException(stream); } ```
I see some places where null is not protected against...
it makes it too easy to call delete when its not necessary.
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
nit: s/read blob's/read the blob's
I think we should use `writeAtomic` everywhere just to reduce the complexity.
derives -> derived
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
I see that we need it from another package, I think it's ok.
can we used delay to control the flow here? I think it be easier to read that to make `tryAcquire` check on delay. WDYT? ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..ebab08d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -190,10 +190,7 @@ final class IndexShardOperationPermits implements Closeable { final Releasable releasable; try { synchronized (this) { - releasable = tryAcquire(); - if (releasable == null) { - assert delayed; - // operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + if (delayed) { if (delayedOperations == null) { delayedOperations = new ArrayList<>(); } @@ -205,6 +202,13 @@ final class IndexShardOperationPermits implements Closeable { } else { delayedOperations.add(new ContextPreservingActionListener<>(contextSupplier, onAcquired)); } + releasable = null; + } else { + releasable = tryAcquire(); + assert releasable != null; + } + if (releasable == null) { + assert delayed; return; } } @@ -212,7 +216,10 @@ final class IndexShardOperationPermits implements Closeable { onAcquired.onFailure(e); return; } - onAcquired.onResponse(releasable); + if (releasable != null) { + // if it's null operations are delayed, this operation will be retried by doBlockOperations once the delay is remoked + onAcquired.onResponse(releasable); + } } @Nullable private Releasable tryAcquire() throws InterruptedException { ```
For backporting to 6.3, I think this needs to be changed to 7.
Strings.EMPTY_ARRAY could be used too (if you want)
same here - I think it's better to log the info message if the deletion was successful.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
and.. looking at the parsing logic this is indeed internal and we don't accept none from strings. Sorry for the noise.
@clintongormley mentioned that NONE doesn't have many external usages (we only use it for index auto creation) so we might want to drop the special naming and use `0`. I will keep the object reuse in parsing.
let's assume that if the method parameters are not marked as @Nullable that they are non-null. Otherwise we clutter the codebase everywhere with these checks.
we "special case" NONE here but not ONE, maybe it's simpler just to remove this method as well as the `validateValue` one and use `new ActiveShardCount(...)` in the two places it's currently used (and also ad ``` if (value < -2) { throw new IllegalArgumentException(...) } ``` to the constructor.
Man this feels like a mess compared to ObjectParser. We can't do anything about it in the middle of this PR though. Just makes me sad.
can you throw an exception here too? I'm worried of users providing the partition numbers as strings, which would be ignored
so `round` should be called once per factory instead of once per aggregator
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
actually I don't fully understand why we can't just do `this.order = order` all the time
We can't safely say that all such exceptions will extend `ElasticsearchException` (e.g., a bad `NullPointerException`), but I like your idea of wrapping the ones that do not extend (as long as it's not wrapping it in an exception that sounds like the user can do something about it).
> Would using `ExceptionsHelper#convertToElastic(...)` helper method in `ConfigurationUtils#newConfigurationException(...)` or similar here be sufficient? +1
Please don't lose the original exception. It's already difficult enough to debug script exceptions without them being swallowed.
ok thanks for the explanation.
you can use MustacheScriptEngineService.NAME
3 more indentation issues above
You are throwing away the stack trace here. Just have this method throw Exception, and the tests that call it as well.
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
We need to cast indeed, but I want to give the compiler opportunities to find errors, which is never possible when one starts definiting methods whose generic parameter is only used in the return value. By the way I'm thinking that we could make casts more safe by making category a class instead of a string, and this class would be the base class of the object that the namedwriteables can deserialize
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
oh sure, thanks for clarifying...
NIT: Noisy reformatting
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
can you add more rolling while adding? Also *sometimes* increment the primary term
Note that you want to make sure that you test the difference between the terms in the ops and the terms in the files. These are not the same.
From the top of my head I think you can leave this out as well
I think the message should be "security manager is disabled", because the assume would only print the message and ignore test if the security manager is disabled.
I get that, I was just wondering why those default templates bother here
for master you don't need to specify the gateway.type we only have what used to be local!
This `if` is never false because `numberOfShards` is between 4 and 10
I honestly don't get it... the way I look at it, we moved from having the `env` "polluting" the `Factory` interface to having it now "pollute" the `Factory.Provider`... why don't we just either wire the concrete factories into a map binder, or, if we don't want to wire them, see if we can pass in the Env. directly to the Module ctor (just like it can accept `Settings`)
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
+1 lets make this consistent with how now things work in IndexModule.
really I think we should not register class instances but rather instance of a the factory or rather use a simple interface we define ourself? like look at how IndexModule works now
hmm why did you remove the mapping from here? I think that was a good change? you should add the settings from from `public Settings indexSettings()` are only used if you use `prepareCreate` so you should add the settings to the versionSettings below. other than that it looks awesome
Maybe call this "testEmptyBoolSubclausesMatchAll()"? Sorry if I misunderstood what the test is doing, I just think having a github issue number in the name is unhelpful to someone if they see a failure.
... so that this doesn't need the `{credentials}` parameter in the URL ...
Sure, good plan.
On deeper thought, this seems unduly lenient: it should only return credentials for the role that `GET /latest/meta-data/iam/security-credentials/` returned, and should return 404 otherwise. Also I think `credentialResponseFunction` can be inlined, it's only used in one place. Also also we could prevent cheating slightly more by inventing random credentials when the service starts up, rather than synthesising them from the role name.
In these cases its acceptable to use randomize testing's `rarely()` or its like to cover either branch randomly.
I really dislike this style of variable reuse in our tests. If I use my IDE to navigate to the definition of this variable I end up on a line assigning a value to this variable that is removed from its current value. This hinders readability, especially in longer tests. Letâs avoid introducing it here, we should be moving away from it.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
I really think this should a hard-coded value and not passed in from the environment. I don't think we gain much by accepting it from outside, and I envisage it being the sort of thing I have to look up each time I come across it. The `BUCKET_NAME`/`KEY`/`TOKEN` inputs are clearer (despite that the `KEY` and `TOKEN` used here could be generated internally if we could do so deterministically).
... and this doesn't need to know it either.
The indentation is off here and the rest of the way through this test.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
maybe we can turn this around and do ``` Java if (electMaster.hasEnoughMasterNodes(possibleMasterNodes)) { // lets tie break between discovered nodes return electMaster.electMaster(possibleMasterNodes); } else { logger.trace("not enough master nodes [{}]", possibleMasterNodes); return null; } ```
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
can we make this getAgeInMillis and do the conversions here? we make use of millis everywhere so it will make for an easier to work with api. The nanos resolution is not guaranteed anyway.
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
nit: "so we assume"...
I think that these log parameters are backwards.
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
Please fix identation.
One option might be for this class to hold the already serialised form of the exception, but I'm not sure if that is better or worse than the current solution
obscure error message... let's start by `"could not read alias fields filtering from xcontent. expected an object but found [" + parser.currentToken() + "] instead"`
I am confused how this works when created is only within role mapping but we ignore role mapping
512 \* 1024 :tongue:
You can't create the thread here, it should be created in `start` (you can't start again a closed thread). It should also be set to be daemon, and it should have a name as well. Check EstimatedTimeThread in ThreadPool for an example.
I suggest adding a volatile flag called `running`, add a method called `stop` that sets it to `false` and interrupts the thread.
Once we have a `running` flag, we can check on it and not on `isAlive`.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
s/y ou/you Also I think upfront is one word.
Maybe rename `myself` this to _local_ like in `network.host` setting? At some point we should support port ranges too, but it can be done in a follow up PR.
This test should assert that the headers are correct.
missing fail :) use expectThrows instead
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
Can we have a small note on what this test does? link is good but description is better. Same thing with method name: `testNoRegionReturnsEmptyList` or something like that
hmm why did you remove the mapping from here? I think that was a good change? you should add the settings from from `public Settings indexSettings()` are only used if you use `prepareCreate` so you should add the settings to the versionSettings below. other than that it looks awesome
Is this necessary? I think that the cluster should know it only has one master node and sets this accordingly.
can we just `return new BytesRef()` in this case? I don't know if the text characters are null if we can really rely on text offset and length? Maybe a better check, not relying on null check is: ``` if (parser.getTextLength() == 0) { return new BytesRef(); } ```
typo: tracker -> tracked
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
Another `_` java 9 will be mad at
This is logic that I think should go into ReplicatedOperation.
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
never mind, I saw them later on
what changed here? I can't spot the difference compared to before
Probably for another PR since it's unrelated but I wonder if `scriptable`, `formattable` and `timezoneAware` should be properties of the Builder object rather than/ as well as the parser so the builder can ensure an IllegalArgumentException is thrown if e.g. an unscriptable agg has the script method called on it? /cc @jpountz
I think some of them could be private
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
can we make those two constructors call the 3rd one so that we can centralize validation (if we ever add some)
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
I think it is fine: we only build one search context per request per shard.
Nit: `findHostName` -> `getHostName`
The reason should be more explicit about why this needed.
nice! I like this. super helpful for keeping track
just initialize it and make it final - it just compliicates the code
can we just throw ElasticsearchException since it has the HTTP code baked in and it's also a RT exception
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
Probably for another PR since it's unrelated but I wonder if `scriptable`, `formattable` and `timezoneAware` should be properties of the Builder object rather than/ as well as the parser so the builder can ensure an IllegalArgumentException is thrown if e.g. an unscriptable agg has the script method called on it? /cc @jpountz
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
class could be `final`
I like this style. I think I'm going to steal it.
I dont have a good answer for this yet. While we can totally test this, the value in the server -> client.fromXContent is greater than just testing the client.toXContent -> client.fromXContent. I think these kinds of tests are not really providing much value, and we also test the former in the IT tests.
Do you need this? I dont see it being used anywhere.
Probably should also be getAssignedNodeId.
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
I suspect that some aggregations could be grouped under the same parsed aggregation implementation, so we won't really have a 1-1 relationship between the internal agg and the parsed agg. Like an aggregation of type "sum" (ie InternalSum) and "min" (ie InternalMin) can be parsed back using a same `LongSingleValueParsedAggregation`. In definitive I'm not sure we should add the getType() here or also in the Aggregation interface.
I didn't check but unittests for this would be awesome!
nit: could be one line
this curly bracket should be on the previous line
No, you are right, I didn't realize the need for api users before going through the whole changes.
you are perfectly right Christoph, let's merge the two and keep the existing class.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
Should there be sanity checks that you cannot resume a watcher that is already running (so that the watcher doesn't run twice).
maybe in a followup we can think about removing these -1s... see what platforms fail, and better fine-grain the stuff (e.g. add assumption for WINDOWS, IBM jdk, whatever it might be). Then we know when and where stats are available.
@jtibshirani is correct
I need to sit down to make a approach, ill finally have time early next week. Id prefer the manual parsing in order to test the fromXContents, for now.
I think you can avoid that by overriding `AbstractXContentTestCase#assertToXContentEquivalence`? I think it's worth using `AbstractXContentTestCase` here, it's going to be much more thorough than hand-rolling parsing tests.
Wow, you are totally right, I see that now :)
the XContent here does not match what you removed in the REST API. There was a bit about early termination, as well as count that you need to include. You likely need to also include the begin/end calls, or else this will fail tests. You can check the tests with `./gradlew :server:check` from the base of the checkout. If tests dont fail then we need some better tests around the response hehe
spaces between commas
now I see what you meant yesterday saying that we have to parse meta here
it's annoying that we write this code over and over again!
I see some places where null is not protected against...
for readability I'd use this. as well
Elasticsearch tradition is to make this an EMPTY constant :)
drop the actually? sounds so "uncertain" :)
Change to Throwable.
Conversion to bytesref is done elsewhere with `indexedValueForSearch`. I'm unsure of the impact of rejecting anything but bytesrefs.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
oh boy :)
sorry, my bad.
replace match here too
++, the only thing is I would even go with a Map<String,String> if that works. not sure what you and Nik think about that.
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
nit: updates -> update
could we implement Writeable rather than Streamable? (Writeable is supposed to be a replacement for Streamable if I'm not mistaken)
It could be useful for debugging too. In the future it's conceivable that the support diag tool might use the HLRC, and we wouldn't want to be dropping this value.
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
we can't change the format of the response at this time. We can at some point, but for now we just have to parse what we have, and figure out what we should do to make things better for the future, meaning potentially breaking changes etc.
Compared to our other parsing code this is a little weird because it doesn't know what field it is parsing up front. I get why you do this, but it is weird. Also it is weird because we don't serialize all that much information. You get almost nothing if there isn't an error.
Looks like the toXContent() and fromXContent() are not completely mirrored; the former does not render any root object while the latter expects it.
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
I've dug some more. This is caused by us running the tests with the built in gradle test runner rather than the randomized runner. We configure the randomized runner to run with the system properties but we don't ever configure the standard runner.
When I pulled this locally and reverted the changes to this file I didn't have any trouble. We've traditionally been very weary of making changes to this file so I'd really like to make sure we need this before we do it, even if it is temporary.
And some more: this is not caused by the build compare plugin. Maybe by gradle 4.8 or maybe by one of our hacks to make 4.8 work.
This assumes a version format that while fairly standard is not guaranteed.
I think we can do this more simply by looking at `endsWith(".jar")` of the uri string. We don't really need to convert the uri to a path, since we don't need to load the file. Then, the original if statement can simply be wrapped with like: ``` URL location = clazz.getProtectionDomain().getCodeSource().getLocation(); if (location.toString().endsWith(".jar") == false) { // original if and exception here } ``` Basically, if the file is in a jar, we don't need to worry about it here, as those would have already been added to the codebases map by `Security.getCodebaseJarMap`. This method is about adding classes that are on the classpath, but not via a jar (ie built by the IDE).
Please no `null` for no change needed, returning `Function.identity` is clear, and there is no need to make an optimization check.
we can maybe use similar technique as we do in `QueryParsingException` and also report the location
@return needs to go into new line..
I notice this pattern in every implementation. Perhaps this should be a Map instead of Collection (keyed by the custom type name)? Then the map can be copied, and keys replaced, removed, or added easily, without needing to have logic for the other custom metadata that the plugin does not care about.
maybe call this `getMetaDataOrDefault()`
Think it'd be good to keep the `translog stream is corrupted` string here unless there's a good reason to change it. It's useful to be able to search for exception messages when working on support cases, and this sort of change makes that technique less useful.
open reader doesn't need to check for <0 and throw an exception any more.
Maybe just a single `read` method instead of `readChecksummed` and `readNonChecksummed`? They do the same thing? In the future, we'll have to also pass in the version to `read` so it can read any version-specific things ...
in this case is it worth peaking at the file again and check if the first byte is valid even for version 0? maybe we should do that check first and then move to V1 and fail hard if we see a CorruptIndexExp
Oh nevermind, `CodecUtil.checkHeader` is already doing the real check. You really do not trust anyone ;)
license header is broken here
++ for a checkedfunction
I guess you could make this a final class that takes a functional interface as its only parameter and runs it and you could still use lambdas for it. My instincts are that that is marginally better from a design standpoint (composition vs inheritance) and a little easier to read but I'm not sure.
Sigh :) I'll add a `public getMergeInfo` to `OneMerge` to Lucene ...
nit: extra space
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:918E10886BC43EC1]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.LineStringBuilder.<init>(LineStringBuilder.java:49) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiLineString(GeoWKTShapeParserTests.java:112) ... ```
nit: formatting, add some whitespaces
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
It'd be "more normal" to declare this as `Writeable` and use `readOptionalWriteable` and `writeOptionalWriteable`. You've done plenty in this PR so it can wait though!
can this be in try-with logic.... you are not closing this input stream at all
I wonder if we should enable this only for new indices that we know are created with es 1.4
save -> safe
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
just call `parser.text()` instead of `parser.bytes().utf8ToString()` since it might be optimized under the hood
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
replace match here too
this whole block here looks pretty much the same in all invocations. Can we make this even simpler? Maybe create a method `createIndexAndWaitForActiveShards` in `MetaDataCreateIndexService`. I've implemented it here: https://github.com/ywelsch/elasticsearch/commit/6e67ecabbfa5cc2568c0c987401e3ea521c7a330
never mind, I saw them later on
using ActionListenerResponseHandler will simplify this lightly.
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
I find these two empty `continueProcessing` methods confusing, if we manage to merge the two filter chains impl as said above, we would get rid of them I think
why is this method synced? I don't see a reason though...
I think we can now revert this change, `for` instead of `while`, 2 lines less? ;)
why do we need this toString() here? We run it right away and don't log it anywhere.
The fix apparently works, but what the diff here doesn't clearly show is that it relies on the order of the types. Imagine the case where we get three types for the `_river` index e.g. `_default_`, `dummy_river` and `atype`. Even though the _meta doc for the dummy river is found (second one), the _meta doc for `atype` (last one) is not found, thus a retry is scheduled, but more importantly the `currentState` is returned (without the dummy river!). That return (within the `if !getResponse.isExists()` block) needs to be removed.
Just about code style, I would prefer ``` if (iterator.hasNext()) { continue; } ``` rather than the short form. But I would indeed keep the `continue` to avoid starting one retry thread per type not found. One is enough.
and 2 more occurrences below
too many shards already allocated to this node for index ...
too many shards [%d] allocated to this node, [%s=%d]
can you undo all indentation changes, it adds noise to the diff
This predicate can be simplified to `(count, limit) -> count > limit`.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
is this needed here? I think it does something only when the current token is start array or start object.
we can't change the format of the response at this time. We can at some point, but for now we just have to parse what we have, and figure out what we should do to make things better for the future, meaning potentially breaking changes etc.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Sorry, I overlooked the null check. This is good!
Ahh, sorry. You are 100% correct.
I think I would make a breaking change here. Let's drop support for the string value in the builder and add it to the breaking changes. The parser still supports `none` and `all` but the builder only accepts a query. Then the method below needs to pretty much be moved to the parser.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
We should break anything we need to to make the Java API clean, easy to use, and less trappy. Given this is only going into 3.0 we should take this opportunity.
Maybe you could put the validation removed from toCContent here. (point.size > 0)
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
nit: indenting should be only 4 extra spaces
Since we're moving that, we could inline this using turnary.
It would be nice if this class was immutable, and this line shows why it isn't currently. This is how to make it immutable: ``` List<CompositeValuesSourceBuilder<?>> sources = new ArrayList<>(num); for (int i = 0; i < num; i++) { CompositeValuesSourceBuilder<?> builder = CompositeValuesSourceParserHelper.readFrom(in); sources.add(builder); } this.sources = Collections.unmodifableList(sources); ```
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
same here - just pass a new instance
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
ah got it!
I think you should pass the Result here. Maybe also add an assertion in the ctor that the result is either `Result.DELETED` or `Result.NOT_FOUND`.
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
I see it now - I think how you've got it now is the most right thing then.
I wonder if with this change you can remove `UpdateHelper.Operation` entirely and just use `DocWriteResult.Operation`. I'm not sure it'd be clear to use `CREATE` instead of `UPSERT` in all the places though.
Again, I wouldn't pull out the ternary.
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
Sorry you are right, we should be using ParsingException. That snippet was the pre-refactored version. The difference is that ParsingException does not need the SearchContext (not available on the coordinating node) and actually points to the location in the request for the error (the XContentLocation). Please use ParsingException in this PR since this is going to be parsed on the coordinating node
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
is this needed here? I think it does something only when the current token is start array or start object.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
it makes it too easy to call delete when its not necessary.
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
Nit: missing `@Override`
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I don't believe this is only kept for BWC. You use this to parse `_source` above.
I guess it could be renamed to isFalse() / isTrue() now
This can be replaced with ``` java boolean isTrue = isExplicitTrue(value); ``` similar to the previous example
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
So negative delays count delays? I figured they should count as not-delayed.
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
+1 to capture `System.nanoTime()` at the beginning of the method
This is redundant. getDelayAllocationExpirationIn also calls getAllocationDelayTimeoutSetting()==0 and returns 0 in that case.
and do that in all other classes we do this for serialization in this pull request.
I don't get this part why do you change the way we read the `TranslogStats` here? can't this just be ``` Java translog = in.readOptionalStreamable(new TranslogStats()); suggest = new SuggestStats(); if (in.getVersion().onOrAfter(Version.V_1_2_0)) { suggest = in.readOptionalStreamable(suggest); } ```
I think consensus is to avoid build failures entirely whenever possible
I'm actually wondering if it would be better to commit with the `onOrAfter` line and just accept the errors for a build or two. The last good commit stuff should mean that only the intake build fails on this. You could also set up the backport for 6.x branch before pushing the change on master so you can push both at the same time and minimise the chances of builds failing.
Yikes! I'm super glad we had these tests fixed!
I think you should pass the Result here. Maybe also add an assertion in the ctor that the result is either `Result.DELETED` or `Result.NOT_FOUND`.
I'd just leave the ternary operation there.
I think you can just blast the entire method in this case.
ok as a follow-up
I wonder if with this change you can remove `UpdateHelper.Operation` entirely and just use `DocWriteResult.Operation`. I'm not sure it'd be clear to use `CREATE` instead of `UPSERT` in all the places though.
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
true. nevermind then
check listener.isDone() as we don't expect a retry here I think
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
Good to read, but this more or less repeats what ParseFieldMatcher.match() already does. I think it just adds another stop on the road to the actual match-implementation, which is not even in ParseFieldMatcher but in the ParseField itself. I was thinking about simple shortening like `matcher.match(currentFieldName, PARSE_FIELD)`, but I think its fine the way it is right now in the PR, not worth going trough all the files again IMHO.
nit: reading all this makes me think if we could get parseContext.parseFieldMatcher() once with a shorter local name at the beginning and then shorten the lines here a bit. Just for readability. I know at this points it's probably some tedious search/replace action, just throwing this in as a thought.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
then check for non null here...
no need to be volatile anymore
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
this looks a bit odd of a toString() implementation as it's very much targeted towards that one logging call site. Maybe change it to be more generic.
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
"new" -> "now"
ok fair enough I didn't try it :)
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
could name this `getUUID` to be consistent with other usages of UUID in the code base
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
I would write this check as ``` if (shardRestoreStatus.state().completed() == false) { ``` and then add an assertion that `shardRestoreStatus.state() != SUCCESS` (as the shard should have been moved to started and the recovery source cleaned up at that point).
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
I would use the following message: "ignored as shard is not being recovered from a snapshot" and not have an explicit check for `shardRouting.primary() == false`. That case is automatically handled by this case too as replica shards are never recovered from snapshot (their recovery source is always PEER).
can you also add ``` @Override public Decision canForceAllocatePrimary(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) { assert shardRouting.primary() : "must not call canForceAllocatePrimary on a non-primary shard " + shardRouting; return canAllocate(shardRouting, node, allocation); } ``` as this is a hard constraint with no exceptions
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
I see, so parser always sets both "order" and "mode", regardless of whether they are set by the user. But what if we only go through the java api, use a plain builder and set "reverse = false". Translated to json this should give us "mode = MIN", but only if not explicitely set by the user otherwise, no? Sorry, haven't got a good solution myself so far either.
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
make `Boolean` and only serialize when not null
nit: "an started" -> "a started"
extra space makes everything not line up!
use `Objects.equals` for all once changed to potentially null references.
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
I'd feel better if the `latch.countDown()` would be the first line in the catch block
err I guess you need to have failures added first so second...
maybe just `return blobMetaData.length() == fileInfo.length();`
no file? maybe IOException
Oops nevermind, I misread.
We need to check here if `ttl` read from translog is lower than 0, if so, then we actually don't have a value...
replace match here too
Right... but I'd be happy if we could unit test this, and if we do then we need to ensure the object start.
We don't need to use this local ref
If the constructor is modified, this method won't be needed anymore.
One option might be for this class to hold the already serialised form of the exception, but I'm not sure if that is better or worse than the current solution
It would be nice to return a simple, non-empty structure here so that we test that aspect of the response parsing.
It's better to use variable names with context so for example `check1` could be `keystoreCheck`, etc.
we should probably consolidate the error messages from the results so that we don't only present the first (from a seemingly arbitrary check order) error that was encountered to the user
I think that we should have left an assertion here that the Java version is not JDK 11 (I think we will be able to remove this for JDK 11). I also think that this code should have been guarded by an if block checking that we are on JDK 10 and otherwise not add this permission.
No, it cannot be private, since it's used by `AttachmentProcessor` in the same package. That was the part that I was missing. I think its misleading.
I can push the change if you don't have it ready yet.
I think we can now remove this condition as the client can not be null because we throw now `new ElasticsearchException("Unable to configure Azure compute service", e);` in the CTOR
Needs a guard.
I think we should throw an exception when `id < 0`, which should never happen? (unless Bad Stuffâ¢)
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
confuses the shit out of me everytime :)
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
good catch! that means we are not properly testing this case either given that we didn't catch it.
can we call this last seen clusterState? it doesn't need to be volatile as it is changed under a lock.
can we use ReleasableLock and try with resources? (or a plain old synchronize :) )
can we add a check for whether we sent a diff? I want to avoid a potential infinite loop.
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
Can we do all of these things (stripping last char, backslash escape and quote escape) in one pass with a string builder? Right now 3 copies are made of the string.
`blocksmd.copyContext(trysmd);`? I know you use "context" to mean something and this might not be the right use of that word though.
Or `adapter.createStatementMetadata(blockctx, trysmd);` or `trysmd.substatement(blockctx);`.
Same thing, let's output the type of `msg` here; the `FullHttpRequest` part can be read from the assertion line (at least my first step when an assertion trips is to find the line in the codebase, so we only need what can only be known at runtime).
I don't think this is correct? Do tests pass? This should fail on unmapped fields.
Nit: too many newlines here
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
same - wdyt about a condition suffix/
I think that this should be an `IllegalStateException`.
Nit: `getNumConnection` -> `getNumConnections`.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
can we name this `CompleteDiff` don't use simple please :)
`((NamedDiff<?>)value. getMinimalSupportedVersion()` should avoid the raw cast warning and be perfectly safe.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
can we also add a line saying this variant allows for custom value deserialization based on the map using a KeyedReader? I got confused by why this is useful (until I saw how it is used).
Minor suggestion to make it clearer that we're not waiting for the write index not to exist: ```suggestion public static final String NAME = "check-not-write-index"; ```
Can we switch between the string and the millis representation fo the modified date using the `human` flag like the explain API already does? That way we can just have one `modified_date` field in the output? Also the parser will not need to worry about the string version in this case since the client it will never set the human flag
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
If it's possible to directly forward to `LoggingDeprecationHandler.INSTANCE` I'd rather do that because it would avoid duplicating the knowledge that the logger for `ParseField.class` goes to the deprecation log.
Since we're moving that, we could inline this using turnary.
if we make such change, can we do it in a separate PR please? ;)
oh, multi-bucket comparisons are ready already? :)
missing fail :) use expectThrows instead
I am not sure whether the log message is too specific, i.e. the subclass must not necessarily be a service.
I see that we need it from another package, I think it's ok.
relativize can be tricky if paths have different roots. is siteFile really guaranteed to be absolute too? In lucene i coded this "minimal path" with the following idiom: ``` root = root.toAbsolutePath().normalize(); path = root.relativize(path.toAbsolutePath().normalize()); ```
watch out for manual path concatenations - / doesn't work on windows :)
Nitpicking but I wonder if we should just use the File's constructor for this use case: http://docs.oracle.com/javase/7/docs/api/java/io/File.html#File(java.io.File, java.lang.String)
ah I mean't Throwable.... sorry
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I don't know how often this is called, depending on this maybe it makes sense to store the formatter somewhere for later reuse unless `format` changes? Is only called a few times maybe not worth the trouble.
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
this new exception is going to trigger errors too if we try to serialize it to an older node
I think BuildFactory should be allowed to throw a ParseException since subclasses should have the ability to throw it if there is a problem with creating the builder at this point
can we use org.elasticsearch.indices.recovery.RecoverySource.Actions#START_RECOVERY ? it's a better indication that the recovery is started.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
hm. so this hangs now every now and then for a minute. I think it is when the coordinating node is node_1. Then the cluster state observer waits for the next cluster state which does not come and the index request is only executed when the observer times out. We can send the request via node_2 but I think we actually need a way to handle this better.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
we need to check on the node version, and only call it on nodes that are version 1.3 and above, otherwise they won't have this API
maybe we should have a helper method for this? this looks used in several places
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
oh oh I hadn't read your reply when I replied ;)
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
import not needed.
Not needed anymore.
Not needed anymore.
`} catch (IllegalArgumentException e) {`
Same concern about reproducibility as in the other PR.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
`limitedTo(long bytes)`? Clone is kinda non-specific.
good catch on delta > 0
you can omit `ElasticsearchException` here it's unchecked
I don't think it needs to be an `AtomicLong` - it's only updated on this thread.
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
ok I remember now. The point of IndicesRequest and CompositeIndicesRequest is to return the indices that a request works against. when a request is composed of multiple operations, it should implement CompositeIndicesRequest. In this case delete by query reads from some indices as part of search, and writes as part of deletes. But what indices would it delete from? It is not possible to create a DeleteRequest that points to multiple indices, yet it is hard to predict all the deletions that will be performed as part of the request execution. I doubt that this request should implement CompositeIndicesRequest then.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
do we need == true ? :)
should we catch exceptions here to make sure we cancel everything we need
we need to remove this from onGoingRecoveries and only call cancel if it was found, otherwise we may leave a lingering recovery id, pointing at a cancelled recovery.
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
I wonder why this change? initial value is unused and once existing files are set, they are never changed.
Can't recovery -> Can't recover
similar concern about modifying the value that is set
same should be done for minChildren and maxChildren too. Wondering now if it makes sense to move to `int` rather than `Integer` for all three fields
Full default value handling story here: https://github.com/elastic/dev/blob/master/design/queries/general-guidelines.md#default-handling
Can you use StreamInput#readList ? You need to check for the version here since this code can receive requests from nodes in previous version. Something like ````if (in.getVersion.onOrAfter(Version.V_6....)````
yes lets do it later otherwise we have to remove setters and break things.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
please return a Map instead no google guava stuff in public interfaces
I think we can just use an FsRepository for this. All our other shard-level tests do the same, so no need to optimize this. If we want to change that in the future, I think it's easier to switch to jimfs and continue using FsRepository.
It's that, or we can replace replace FsRepository with this one, but we need to beef it up.
I think this should throw IAE if you pass null - that's 100% of the time a bug
hopefully having a default for fuzziness makes it non optional and simplifies things slightly here too
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
replace match here too
this can go back to boolean if we move back Settings to boolean too
I don't understand here what you mean by synthetic variable. If you mean the two ENulls, the analysis and writing would be contained to only compile-time.
Two test requests: What happens when you have something like `Integer a = Integer.valueOf(0); int b = a ?: 1;` `Integer a = Integer.valueOf(0); int b = a ?: Integer.valueOf(1);` I believe these are expected to be ClassCastExceptions where Integer cannot be cast to int, but I'd like to be sure.
@nik9000 Robert and I had a long conversation about boxing early during development. We decided to eliminate it as much as possible because of serious complications involving promotion and casting (which as you know is already very complicated). There's only a couple of places auto-boxing happens -- arguments to methods because it would be hard to force a user to cast something to an object to add to a list and with anything related to def type. Otherwise, there is no auto-boxing in painless. Perhaps, this should be the same for consistency? Sorry, I sort of missed this yesterday thinking about the cases, but def should work anyway already, otherwise primitives don't make sense here since we don't allow Integer to become an int anywhere else. With the def type we deemed auto-boxing to not be necessary anymore, and ideally something Java would've hidden from the user to begin with. It also happens that users can call boxed methods on unboxed types to further eliminate the need to ever have a boxed type.
@nik9000 What do you think about this proposal for now? What if for the null safe operator (?.), if the guarded type is a primitive we disallow it, and then for the elvis operator (?:) if the lhs is a primitive we disallow that too. I honestly don't think anyone will notice because currently there is no way to get a primitive out of a field from a non-static type (nothing exists in the whitelist afaik), and I would argue in the case where you want a primitive out of a call, it doesn't make sense to have the receiver be a boxed type. You would still have to check to see if the receiver was null afterwards anyway. For most cases the type will be def and the auto-boxing will just happen anyway. Both of these operators can be very useful for def types without needing to have them do magic for primitives. I would hate to not have them because of boxing issues when it's improbable that users would run into them. I would think the average use case would be something along the lines of list?.list?.map?.get(value)) in which case this operator is awesome.
I would stick with a separate exception simply because it's easy for the user to tell the difference between something he/she caused rather than an actual internal error.
nit: should be "commit_ting_ writer with commit data"
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
> If there are multiple commits, what does IndexWriter.getCommitData() return? I am guessing it reads the "latest" commit's data? Yes, the latest.
It won't always be the case that there will be one index commit, sequence numbers will change this assumption.
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
I dislike this idiom here, because if e.g. encoding is wrong it will silently replace with U+FFFD. Is this done anywhere else in the codebase? If so, maybe useful to have a method, that would e.g. set onMalformedInput/onUnmappableCharacter and so on.
This many levels of nesting hurts my head! How about refactoring the inner half into a private `findShardIds(@Nullable String index, Path indexPath)` method so it's easier to read? I'm worried about the potential for future typos for anyone else touching this code
I'm trying to understand this isHidden check. Is it actually unrelated, and instead has something to do with the processing of '.' that follows? We shouldnt have code with assumptions that hidden equates to .'s in filenames, thats broken.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
add a return method here just in case? I don't like this construct but can't think of how to improve it (all other options I see suck too)
yeah that is true. nevermind then
do we want to check listener.isDone? (because it is supposed to return immediately). get() waits.
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
check listener.isDone() as we don't expect a retry here I think
not really important
Er - if you are going to log something then it doesn't matter which order you do it I guess.
same as above, this breaks bw comp for the java api
can you remove that shared string and use `readString() / writeString()`
+1 on removing it
Okay, doesn't matter if the builder only outputs verbose version as long as we support the other one still.
We would need a call to super() somewhere here. Or, like we did with the query builders, have the superclass declare two abstract doEquals/doHashCode methods that it then calls and the subclasses need to implement.
Sorry, didn't see that, you're right.
Since `value` internally is a String now, we can change read/write here as well.
hopefully having a default for fuzziness makes it non optional and simplifies things slightly here too
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
Similar to above, `new TreeMap` should be wrapped with `Collections.unmodifiableSortedMap()`.
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
why do you pass the response to this method? `this` already has all information.
I only mentioned it because if we really have to keep this, then StandardOpenOption.DELETE_ON_CLOSE could be an implementation. But this one has race conditions too, this delete-on-close stuff is why Lucene's lockfactories were buggy for years. Lets defer it to a new issue, ideally we just nuke it completely.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
only the `#start()` call should be concurrent. The publish should be done in a sync manner and the `NodeAndClient buildNode = buildNode(settings, version);` should be done before in a sync manner. This is important since we want the same setup no matter of how threads are scheduled and `NodeAndClient buildNode = buildNode(settings, version);` uses random internally
thanks for adding this
hmm I see it's to opt out...
Extremely insignificant, but just for clarity: I think you mean "does" (indeed contain a fatal error) on this line.
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
engine -> underlying store.
This is the only place that commits w/o pinching the xlog right? Why do we do this? Is it so the snapshot won't fail when a recovery is in process? I think somehow we should make our xlog reference counted in the future, so that a recovery can "incref" it to prevent deletion before the point-in-time it reserved, and then flush doesn't need this boolean param anymore: it would just decref its reference. Later ...
`new AtomicReference<>();` with the extra `<>`.
is this needed? as far as I can tell, the implementation does nothing?: ``` try { if (lock != null) { <-- **lock is null** try { lock.release(); lock = null; } finally { clearLockHeld(path); } } } finally { IOUtils.close(channel); <-- channel is null channel = null; } ```
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
This could just be `close()`
nit: space before brackets
This can just be named `allAliasNames` since it's just a set of the alias names, the "duplicate" part was throwing me off
Perhaps add the duplicate size to the assert message here
whoops I read it backwards, so yeah, not really necessary
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I expect to be tested as it's static, but I don't see test? I think its good to have one. Also, it seems it can be package private.
I think this is easier to understand as it makes a 1-1 copy of the current active shard allocations in the routing table: ``` for (IndexShardRoutingTable shardRoutings : indexRoutingTable) { Set<AllocationId> activeShards = shardRoutings.activeShards().stream() .map(shardRouting -> shardRouting.allocationId()) .filter(allocationId -> allocationId != null) .collect(Collectors.toSet()); if (activeShards.isEmpty() == false && activeShards.equals(indexMetaData.getActiveShards(shardRoutings.shardId().id())) == false) { // only update active allocation ids if there is an active shard if (indexMetaDataBuilder == null) { indexMetaDataBuilder = IndexMetaData.builder(indexMetaData); } indexMetaDataBuilder.setActiveAllocations(shardRoutings.shardId().id(), activeShards); } } ```
we typically just use string concat. I think we can just do "shards started [{}]"..
it would be great if we can get more info about why this reroute happened. Maybe add a String reason parameter to the reroute method? This is called in many places for different reasons. (node left/join/shard store fetched etc..)
wondering if we should add the first 10 shard ids to the explanation
As @rjernst says, this is incredibly broken behavior. It invalidates all the work we did to reject unrecognized URL parameters, now it accepts any parameters including garbage parameters.
please use the root locale
also please use `== false` for comparison
That's fine; throw an `AssertionError` then. Also, I think that you can keep the existing structure: `if / else if / else`.
I don't think is necessary. `request` is passed as`params`. So, "verbose" is already in `params` if it was specified, you just need to be careful resolving defaults. You would also miss other parameters here such as human and pretty.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
Why do we need both? Is it because there are so many things going on in this file? I don't understand why we wouldnt just need the CompiledAutomaton for the terms.intersect operation, why do we need a ByteRunAutomaton too? Having both seems silly anyway, but if we must do it, try to assign the ByteRunAutomaton from the CompiledAutomaton. The majority of the time it will be non-null: ``` /** * Matcher for quickly determining if a byte[] is accepted. * only valid for {@link AUTOMATON_TYPE#NORMAL}. */ public final ByteRunAutomaton runAutomaton; ```
this can be out of if now.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
I meant `node` from the for loop.
There's an extraneous blank line here.
same here regarding nullable ..
Elasticsearch tradition is to make this an EMPTY constant :)
We suppress and not report all errors which are OK. I don't think we need a special protection here about it.
drop the actually? sounds so "uncertain" :)
we can use in.readVInt() here, no? it's always non-negative... (same goes for other counters and also note that you'd have to change the writeTo message of course)
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
Nit: spacing between the `)` and `{`: `){` -> `) {`
good catch on delta > 0
`limitedTo(long bytes)`? Clone is kinda non-specific.
why do you pass the response to this method? `this` already has all information.
remove "or timing out".
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
I don't think we need this part? Even if you've created an index with 6.4, you still want to be warned that things are going away if you upgrade to 6.5
`.addPathPartAsIs("_xpack", "rollup", "job")`
you can comma separate these instead... i know the likelihood of us not using `/` is low, but its best to not have them in this.
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
In 7.0 this should use `_migration/deprecations` as of https://github.com/elastic/elasticsearch/pull/35976, although in 6.x it will have to use `_xpack`.
heh, duh... Sorry, ive been on vacation and full of turkey since last week.
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
we can do this in a more optimize manner. We can create a builder, and then use `copyCurrentStructure` on the builder (passing it a parser), to just copy it over, compared with parsing into a map and then serializing the map. Also, since its internal, I would use smile builder, as its considerably more efficient than json.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
I wonder if we should start already sharing some common code between our BaseQueryTestCase and this class....wouldn't want to complicate things though. Also our base test class in not in master of course so that woul already complicate things...
Nit: `getNumConnection` -> `getNumConnections`.
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
oh cool the read is in the ctor! nice!
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
can we be slightly more verbose on why this is use full? (different deserialization logic based on key in parent map)
I think this check comes too early. Templates have not been applied yet. I suggest doing this once IndexMetadata has been created.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
never mind, I saw them later on
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
I think @bizybot is correct - we probably need some of the failure cases in `ApiKeyService.authenticateWithApiKeyIfPresent` to have a `terminate` status instead of `continue`. If I'm passing an API Key over TLS, then it would be very strange (and hard to debug) if the authentication use the API Key right up until it expired and then suddenly switched to PKI auth.
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
The factory is what holds onto the params, so that they can be passed to the constructor. Think of the factory as the signature for the constructor. It's not boilerplate; it is actually needed based on current uses of scripts throughout the system. Also note that the factory signature is what allows the script instance to have arbitrary objects passed in. If `ScriptService.compile` were to return an instance directly, instead of a factory, we would need some way to pass in this information in a generic way, which would probably mean duck typing through a String->Object map and then require casts. With the factory, we get static type checking of the arguments a script needs to be constructed.
Maybe we could name the context (and the class) something more descriptive for it's purpose? While the rest api is for executing a script, I think this context is a generic test context? Perhaps it could be "painless_test" (and PainlessTestScript) or something like that? I like having "test" in there because it is clear this is not for production uses, but to test painless code. It would also be more clear for when we do support other contexts in the execute api.
can we set the timeout to 0 here? otherwise tests half the time takes 1s
indeed, did not see that.
`Arrays.asStream(response.pingResponses)` would not materialize it
I know this was copied over from another place, but I wonder if we should give preference to the recovering file. If I read this correctly , if we have both recovering and non-recovering, it is now random which one we choose.
You don't trust Files.move :)
Nit picky - we can iterate directly on the getFailures array - no need to check for length
is this needed? as far as I can tell, the implementation does nothing?: ``` try { if (lock != null) { <-- **lock is null** try { lock.release(); lock = null; } finally { clearLockHeld(path); } } } finally { IOUtils.close(channel); <-- channel is null channel = null; } ```
Consider adding ``` static final NoAuthCredentials NONE = new NoAuthCredentials(); ``` and making the `NoAuthCredentials` `class` package protected (drop `public`). It may not be used enough to warrant having a `static` field hanging around though, but I liked what you did with the original `BasicAuthCredentials` and `EMPTY` before changing it a bit.
Extremely minor, but this could drop the `public abstract` part now as `interface` implies it.
Consider changing to `void applyAuthorization(URLConnection connection);` (and then changing the children to "apply" themselves there; the `EmptyAuthCredentials` would naturally be a no-op). This should help to avoid an N +/- 1 list of `if` statements in the `HttpDownloadHelper` as more types of `AuthCredentials` are naturally supported.
We have some other APIs using the american spelling "normali**z**e", should we be consistent here? (eg. IndexSearcher.createNormalizedWeight or `normalize_lat` on geo points)
yeah I remember... ;)
good catch on delta > 0
maybe we implement `Iterable<V>`
also this class should be final.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
Ah, I see why this is a function ref - so that the `toString` generates the right method to invoke. That feels a little brittle but I understand what is up.
I'd remove the bitmask - it doesn't seem to add much value (see the previous method suggestions for implementing and); shorter and clearer than using bits.
make it final
Wondering if the class name shouldn't be `IfNull`...
It should - see `IsNull`
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
maybe, to be more precise, it would be good to check the partition that included the new primary.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
waitForyellow can go away...
I think we can check also randomly on a shard that relocates _to_ the local node
cool thanks :)
Can we just keep it simple here and eagerly allocate the array to full size (and fill it completely) above? These should be small sizes (single digits). I don't think we need to optimize as if this array could be hundreds of elements.
`i` should be a long since `size()` returns a long
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
maybe we should just get rid of this local variable and write the next line: ``` nodesIds = filterNodeIds(clusterState.nodes(), resolveNodes(request, clusterState)); ```
I wonder if this should just be the implementation provided in `TransportReplicationAction`? It appears there are only two classes that currently provide a non-trivial implementation of this method.
s/The tasks has/In case the task has/
I think this file needs formatting `if(` -> `if (`
Nit: I think it will be safer to have this boolean as a parameter and determine the action here. I'm weary of arbitrary string input.
Not needed anymore.
Not needed anymore.
Same concern about reproducibility as in the other PR.
> Makes sense? It does not make sense. Having try/catch like this means the test doesn't really know what it is testing.
connec to to -> connect to
This part I like since it is growing based on the number of aggregator instances, which is not accounted today.
can we clean up the other try catch? it's not needed now (as we catch things here too)
This is missing a `+` between `newUsed` and `"/"`, so it's not compiling currently
it's not really arbitrary is it ? :)
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
same typo - copy paste probably
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
I only mentioned it because if we really have to keep this, then StandardOpenOption.DELETE_ON_CLOSE could be an implementation. But this one has race conditions too, this delete-on-close stuff is why Lucene's lockfactories were buggy for years. Lets defer it to a new issue, ideally we just nuke it completely.
This message probably made sense once but it doesn't anymore. I'd suggest `Cannot update the job config because job...`
typo: optain -> obtain
I think this is expected to be a sorted list on the `job_id`.
nit: space before brackets
ok now i can see that it is null when removing the task, sorry for the noise
I think it would be more flexible if the keys were objects? (you could have composite keys, etc.)
I'd prefer this to be `@Nullable` as well... relates to xcontent serialization
if we do make it nullable @colings86 we have to make sure some value gets provided as part of the `canExecuteScript` call, where the type is required to decide whether the script can be executed or not.
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
sounds great thanks
`Arrays.toString(paths)` already adds [] , no need to add them
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
i think `== true` can be skipped
Another simplification - if we push the code at https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterIndexHealth.java#L81 into ClusterIndexShardHealth's constructor, we can use it here and just make it a simple lookup in the enum set..
Maybe add minimumLuceneVersion() to index metadata as a placeholder for #11095? Then the impl can just be createdVersion().luceneVersion in this PR? It would just make it more clear here that the lucene version is the driving factor.
can you undo all indentation changes, it adds noise to the diff
Extremely minor grammar thing, these should be: ``` all rebalancing is allowed no rebalancing is allowed primary rebalancing is allowed replica rebalancing is disallowed replica rebalancing is allowed primary rebalancing is disallowed ``` I'd also recommend `forbidden` instead of `disallowed` because it's much less likely to mix up with `allowed` at a quick glance.
This predicate can be simplified to `(count, limit) -> count > limit`.
I would use the following message: "ignored as shard is not being recovered from a snapshot" and not have an explicit check for `shardRouting.primary() == false`. That case is automatically handled by this case too as replica shards are never recovered from snapshot (their recovery source is always PEER).
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
nit: extra line
I think this can be simplified into ``` if (obj instanceof Map || obj instanceof String) { valueWrapper = Map.of("shape", obj); } else { ```
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
same here with removing retry logic
same here with removing retry logic
same here, all retry logic should be removed
same here with removing retry logic
I also wonder if we should log `TRACE`/`DEBUG` issues for this.
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
just saw it in the factory validation, nevermind :)
oh nevermind, I just found the method that called it with null :)
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
What if the user specifies 0 here? Previously that meant unbounded.
This predicate can be simplified to `(count, limit) -> count > limit`.
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
ok keep it then. I am not sure though what needs to be optional, if the client here, or the service in the parser service. I thought the former, not the latter.
Ok, didn't know about those...I guess keep for consistency...
I think this name should be IndexMetaDataUpgradeService? Otherwise it sounds like there is a "metadata index".
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
Nit: " . " -> ". "
Typo: "temporary" -> "temporarily"
The `<=` will need to be escaped.
Maybe just clear a range of bits with `FixedBitSet#(int, int)` instead of clearing bit by bit? The implementation looks to be more efficient and would just require care around the offset wrapping.
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
just `for (IndexMetaData indexMetaData : state.metaData())`
this is not needed. createIndex automatically reroutes.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
As well as the default buffer size
DEFAUTL -> DEFAULT again
Can probably just call this `INDEX_CONCURRENCY` instead of `INDEX_INDEX_CONCURRENCY`
Does this need to set `change = true` also? It's missing from this `if` block
DEFAUTL -> DEFAULT
It is to make sure that the version comparison logic orders alphas, betas, and RCs correctly.
add a whitespace after the if and before the parentheses
ie. when showTermDocCountError is true
Yeah, I think the problem with the test here is that we don't make sure that nothing is left in the stream after we read it. That's why we didn't catch it here.
+1 too - I never noticed these tests...
I think conceptually this should be QueryParseContext instead, if it needs to do more (toQuery) then we need to figure out how to create the QueryShardContext too out of it, but the other way around seems confusing to me. Sorry I see we are going back and forth on this.
nevermind, I guess it depends on how you look at it. at the end of the day this parse method does parse + toQuery, having QueryShardContext is fine given that it will still happen on the shard. Also given that the QueryParseContext is much more lightweight, it makes more sense if done this way. Plus the parse method will go away, so leave it as-is.
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
we can do this in a more optimize manner. We can create a builder, and then use `copyCurrentStructure` on the builder (passing it a parser), to just copy it over, compared with parsing into a map and then serializing the map. Also, since its internal, I would use smile builder, as its considerably more efficient than json.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
if you use here `refresh();` from the base class we also make sure we get back no failures.
ensureSearchable is calling ensureGreen, so for that to be the same as waiting for shards on index creation, on the prepareCreate("index") call, we would have to setWaitForActiveShards(ActiveShardCount.ALL)
The method name implies yellow though. I bet there are places where we don't _need_ green.
Also, you dont necessarily have to change this but you can now replace `.execute.actionGet();` with just `.get();`
If it is really important that these docs end up on separate shards can you add an assertion that they are on separate shards? That would explain the `true, false, builder` thing.
Maybe we should just do the version bump? Technically we don't need to keep disc compatibility with the alphas so something like this isn't required but I like having it for history's sake. Maybe leave a note about what can go in 6, i.e. everything but size_field_type with doc values.
maybe add the type that is found in the error message with fieldType.typeName()
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
I see - we reuse the same engine variable. I think it's cleaner to have it contained.
Since we rely on the fact that index, timestampField, eventTypeField, etc cannot be null and fetchSize cannot be negative, we should validate that it's indeed the case. We could also make serialization more forgiving and avoid serializing the same default values on every request.
nit: there's already a `.translate()` method, so I would rename this to `translated` or `isTranslated`
++ you're right. Without reverting back to a member variable or unnecessarily implementing something I don't believe there is any thing else.
nitpick: it would be nice for the second clause to be aligned vertically with the clause above
Ah right, these methods don't touch member variables so they are better left as static. Aside from readability I think in that case no vtable is needed so its better performance? Keep as is!
I think all of these static methods can now be instance methods.
typo: filers -> filters
I think we should stick with calling these getters like `getCharFilters` because it is the char filters that the plugin has, they aren't "extra" in the context of this one plugin.
All of the `*Plugin` interfaces we have added so far have used `get*`. I think we should be consistent.
++ to just `get*`
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
count > 0? just being paranoid :)
Is this is necessary given we loop over OpType.values()? If other values are added in the future we should fail because expectedBulkItemResponse/originalBytes is not set anyway.
maxDepth can be final
you can make one of them public and call it from both tests, I don't mind
Just a suggestion, I don't mind if we remove it here entirely. I used to like those tests because they show how a typical xContent output of those classes looks like. But with these large ones its kind of debatable whether it is useful.
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
why do we need this here? I think this entire `hashAndLengthEqual` can and has to go away
Strings.EMPTY_ARRAY could be used too (if you want)
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
I think it's fine to add such a method to NoCacheFilter
ok fair enough
Can you fix the indentation
Just discussed it with Robert and indeed this fsync is not necessary.
+1 to not swallow the original exception
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
I think this needs to be `Version.V_6_0_0_alpha3` now.
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
Maybe pass the `Executor` in to the ctor instead of `ThreadPool`? You could keep this method so you can still override it in tests to throw.
do we want to do something with is error? (not related to this change)
we use this implementation a lot - maybe we should make utility base class for it (different PR). a default method implementation will be tricky because of the local node. Maybe it should be a parameter to the onClusterServiceClose. Food for thought.
The logging brackets are off here: `[{} to [{}]]`.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
You could add an assert that it's not ES 7.x here so we know to remove it
nit: missing a space after the first comma
Please rework this word wrap too.
te -> the
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
I'm not sure this logic is correct... fieldType is mutable right? We should compute a final boolean in the ctor if we need this instead.
Oh I see. I like it better the current way better then. I was confused by the fact that you could have both ALWAYS and PARTIAL in the same doc, maybe we could add an assertion that it never happers.
Can you make this `== false`? It took me a second to see the `!` :)
maybe update the docs to say this is a terms query rather than a bool
You can use joinFieldType.name() right? Instead of `joinField`
max_expansions may still be used along with fuzziness, so it may not be ok to deprecate. Can you double check? This is why splitting MatchQuery would help. It is hard to figure out what happens when.
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
can we make those two constructors call the 3rd one so that we can centralize validation (if we ever add some)
Since we rely on the fact that index, timestampField, eventTypeField, etc cannot be null and fetchSize cannot be negative, we should validate that it's indeed the case. We could also make serialization more forgiving and avoid serializing the same default values on every request.
Similar to above, `new TreeMap` should be wrapped with `Collections.unmodifiableSortedMap()`.
We should deal with rejections if the executor is closed.
I think that `node);` fits in the previous line
I think we use the empty string somewhere yes, not sure if that was a wise choice. I don't mind leaving null, no biggie
just flip it then you don't need to negate
this part has to stay here - we want to extend our pinging as we learn of new nodes
Since "version" and "primary" are used not only here, but below in the `fromXContent`, they may go better in a static `Fields` encapsulation so if they are changed in the future they only have to be changed in one place.
I'd probably write validate's results to a variable and reuse it.
This "_global" should be a static constant var.
+1 on removing the `Void context` from all methods. The `declareInnerHitsParseFields` is already complex to read I think, that won't add much.
Sorry, I just saw that you remove them already, thanks!
I think we should complain if we don't find the header name.
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
oh oh I hadn't read your reply when I replied ;)
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
can we add a note here why this is optional? the validate request suggests otherwise...
I see, it became a writable...
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
The problem here is that it would break multi-version clusters. We still need to read/write vLong depending on in/out.getVersion so that at least positive offsets work.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
I see it now - I think how you've got it now is the most right thing then.
Again, I wouldn't pull out the ternary.
I wonder if with this change you can remove `UpdateHelper.Operation` entirely and just use `DocWriteResult.Operation`. I'm not sure it'd be clear to use `CREATE` instead of `UPSERT` in all the places though.
I think you can just blast the entire method in this case.
the == false is done on purpose to make these comparisons more explicit
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
can we add an assert to make sure that highlighterType != null here? it really should since we know that plain highlighter always returns true, but the assert would make it more explicit that it is expected
We should be writing out the settings in the "new format". There is no longer index_analyzer. So in the case of search_analyzer being set alone, when we serialize, we should write both analyzer and search_analyzer.
You can simplify this to: ``` boolean writeSearchAnalyzer = // logic if (writeSearchAnalyzer || analyzer logic) { // write analyzer } if (writeSearchAnalyzer) { // write search_analyzer } ``` This will also keep the same order (analyzer followed by search_analyzer) that we had before.
sorry I meant `org.elasticsearch.common.xcontent.ObjectParser` all the time my fault
+1 on using static strings - I didn't realize that the XContentStrings things are not usable when parsing.
this feels weird. I think this partially comes from the fact that the allocation id field name is serialized by this object. Instead I would change the toXContent of this one to start with startObject. Then in [ShardRouting](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/ShardRouting.java#L719) we can do: ``` if (allocationId() != null) { builder.field("allocation_id"); allocationId.toXContent(builder, params); } ```
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
Or we can let poorly formatted values pass through and throw exceptions at the end if values are missing, similar to how we do for queries
I think this'd be more clear if you said something like "invokeStatic assumes that it is not invoking a method on an interface."
This should be `Type.FS.match(` instead of `Type.FS.name().equals`
wondering if we need recoveryState.isPeerRecovery() to simplify these lines.
yeah, that was what I meant
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
I see that we need it from another package, I think it's ok.
I wonder if it is worth compressing the hitCount into byteSequence? That way you only have to store an array of ints? You'd have to cap `hitCount` at 255 but maybe that is ok? Or you could use an array of long and have tons of precision on your `hitCount`.
the generic thread pull should never reject, unless it's shut down. that's it's semantics. I would also vote for a trace log in the raiseNodeDisconnected, but that's another change :) It's just confusing imo if you shut down a cluster and see these messages.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
`engine failure` -> shard failure
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
wonder if we should make these Integer and Boolean just int and boolean primite types.
this would make sense especially given that their setters accept primitive types
From the discussion before I think that removing the special case for FuzzyQuery inside filter context is okay here since CONSTANT_SCORE_REWRITE ist the default MultiTermQuery rewrite method anyway. @jpountz could you have a look at this change since I think it's related to the filter/query merging.
CONSTANT_SCORE_REWRITE is the rewrite for all multi-term queries but FuzzyQuery: see the FuzzyQuery constructor which calls `setRewriteMethod(new MultiTermQuery.TopTermsBlendedFreqScoringRewrite(maxExpansions));`
s/payload is/payloads are
I'm fine with `IllegalArgumentException`, in all the places of course. :smile:
then check for non null here...
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
It is all good!
I think it'd be easier to read if this were `ObjectParser` stuff.
I took a quick stab at sth. that avoids the Tuple and replacing the test builder [here](https://gist.github.com/cbuescher/88531fe7c2abd38936ef), but it still looks a little bit strange to me. EDIT: Doesn't work, equals-tests break with this little hack. Sorry, nevermind.
+1. Maybe this helper so far is limited to the query / suggester tests only, but then again it might be general enough for ESTestCase.
I believe this can be provided by overwriting EsTestCase#xContentRegistry().
I think we should collapse the two above methods, they are always called in sequence.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
I think filter and query can never be null here? not sure whether we should validate this here.
shall we use MatchAllQueryBuilder as a default value in general, outside of this constructor? If not set, it will be match all? When set, we check that it's not set to null in setter.
+1 on introducing a constant somewhere and reuse it in the parser as well.
I think we can get rid of this field in the abstract class, as far as I see it can be "term", "completion" or "phrase", those should be the NamedWritable NAME constants in the subclasses, so the superclass won't need to store it anymore.
I'm not 100% familiar with suggesters at this point, but from looking at the docs, I think `name` here refers to some custom name for each suggest entry in the request (like "my-location-suggestion" etc..) and its used amongst other things to name the results in the response. The NamedWritable#getWritbaleName() should provide a unique name for the type of writable object. In this case I think the abstract class shouldn't implement this, but the three implementations (Suggest/Term/Completion) whould return how they are identified here.
Those two code snippets are very similar.. I think we should go more generic here, maybe you can add a static `XContentHelper.toString(ToXContent foo)` which acts like in the `SearchSourceBuilder` and does not throw an exception, but returns an error JSON ``` java @Override public String toString() { try { XContentBuilder builder = XContentFactory.contentBuilder(XContentType.JSON).prettyPrint(); toXContent(builder, ToXContent.EMPTY_PARAMS); return builder.string(); } catch (Exception e) { return "{ \"error\" : \"" + e.getMessage() + "\"}"; } } ``` There should be another `XContentHelper.toString(ToXContent foo, boolean wrapInObject)` method which adds the needed `builder.startObject()` and `builder.endObject` calls, if specified. With this change, both of this calls, would basically be one-liners. Hope it makes sense...
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
can we be slightly more verbose on why this is use full? (different deserialization logic based on key in parent map)
nit - we flush also it will reduce the size of uncommitted gens but strictly speaking it doesn't mean it will be below the threshold
can we extract the uncommitted gen from the `lastCommittedSegmentInfos`? Also uncommitted gen is confusing because the gen's id is in the commit point.
I'm not happy with the extra boolean flag to include / exclude the current generation as a fall back. It's too subtle an error prone. How about doing the following (I think you had it in the past and we moved away from it towards the uncommittedX api - sorry for that): 1) If the min gen for the local checkpoint + 1 is > current committed gen , return true. 2) If the min gen is equal to the *current* translog gen, the current gen is not empty (using `totalOperationsByMinGen`) and the local checkpoint is equal to the max seq#, return true.
this might also be called I think
this could possibly called I think
I thought we said we would move this method to IndexQueryParseService so we can avoid exposing the Client.
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
`it's` -> `its`
`translogs` -> `translog's`
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
hmm maybe name it `markCommitted(long translogId) throws IOException` I think it sholud be IOException here
operation can be `final`
We will need stronger assertions here too.
there is a test helper method that can create plugin property files
I think that the both kinds of tests (verbose and non-verbose) should specify exactly what the output is. Note that as written the non-verbose tests would pass even if the production code was changed to always output the verbose output. So, the output would be wrong but the test would not fail.
I think there is a bug here. What is `\\`? I guess Windows? You need to take caution for different filesystems.
This lambda does not need to be a statement block.
@markharwood remember to take hash % copies# collisions into account. So if you see two shards being search on the same node, they should have the same hash modulo number of shard copies.
nit: can you use assertThat or expose the actual values in the message.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
this is not needed. createIndex automatically reroutes.
Nit: `accross` -> `across`
can we name this maybe just `UpdateTask`
I think we should use `debug` for the logging here
please remove that blank line
I wonder if we should have a static `EnumSet<State> PAUSE_ELIGABLE = ...` this makes it simpler IMO
this file needs formatting
Yeah, looking at it again, that makes sense!
What about just converting to bytes and comparing? The way you have it now this isn't consistent with `equals`.... Also the _cat API we call `toString` which doesn't really use the unit anyway.
similarly, equals uses the hash while hashCode doesn't
It feels wrong that hashCode is using writtenBy while equals isn't
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
use ArrayList? one less usage for non standard code...
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I'd say yes... if you want to be able to parse script as a string, you want to be able to serialize it as as string. I believe serialization should be symmetric - you write what you read. For this reason, I believe the script type should be nullable. if you read a script like a string, the read state should be preserved for the writing.
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
I think it should either be an `else if` or the `if` should be on the next line.
indentation makes the `if` block a bit hard to read
we don't need a context in this test, these two lines can go away
(not as a float but due to the cast to int after `Math.ceil`)
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
you don't need do handle queryName yourself anymore, nor boost
we should add ClusterService and IndexNameExpressionResolver to IndexQueryParseService so they get injected. Then this method could pretty much be moved to INdexQueryParseService like this: ``` public boolean matchesIndices(String... indices) { final String[] concreteIndices = indexNameExpressionResolver.concreteIndices(clusterService.state(), IndicesOptions.lenientExpandOpen(), indices); for (String index : concreteIndices) { if (Regex.simpleMatch(index, this.index.name())) { return true; } } return false; } ``` QueryShardContext would need to expose the same methd and delegate the IndexQueryParseService
if we add a null check to the String constructor we can remote this check here given that the parser already looks for the existence of the field too.
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
clarify the error message specifying what needs to be non null? the inner query...also remove empty, doesnt make sense here
Nit: in other places advancing the parser is directly done in the "ensureExpectedToken" call. Saves one line and I think it is equally readable. There's several places in this method where this might be possible, not sure how much lines this saves. Also, if you don't like it, just a matter of tase I think
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
Why not have the standard to string? A multiline return value is difficult to work with in a debugger...
let's reference "1m", "5m" and "15m" directly
I am not a huge fan of base64 but I guess you are right.
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
same note as in the json processor PR.
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
This method also does not need to exist, as you can use `this(indices, IndicesOptions.strictExpandOpen())`, and fix the validation in the other constructor.
I think we can do this without adding an interface? Users should not need to do this? A script cannot realistically be used for both search and executable. I know this is more a problem with the existing scripting apis, but I think here we can just implement executable, and search should throw UOE.
You can get away with it right now because there is only one test, but this should be initialized once before the test suite, not once before each test in the suite.
Can you make this a JUnit assertion instead of a Java assertion? It's preferable to use a test assertion with matchers for this because then nice error messages are produced automatically when the assertion fails.
Since this is static, the name should be `THREAD_POOL`.
You can just use the literal boolean `false` instead of the string `"false"`.
It defaults to `false`. :)
Besides jokes I see your point on NoOp naming, let's leave empty then, it doesn't convince me 100% but I cannot come up with a better name
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
cool thanks for the explanation!
I think saying that it should not be allowed in the query DSL is a bit misleading, cause it is allowed and we parse it properly. I know what you mean though and why you wrote that, I need yet to come up with a better explanation for this...
Ah ok, I missing that method below, sorry.
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
Should we increase visibility in this case? Makes only sense if we can then really test more, though, otherwise okay to leave it I guess.
Then we should leave it, the situation in general improves here already.
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
Same here as above, since both methods are related and read similar.
Change "param required" to "parameters are required"
add a short method that checks the content type and get rid of the list? If this class becomes too big I am good with getting the bulk part out. some of this methods are going to be useful for msearch too at some point.
this code block is repeated and always deals with index requests I think. We can probably factor it out to a method.
I think s/lang/defaultLang/
Fine by me.
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
just being over paranoid I think this class should be final
add a private constructor so it is not possible to instantiate it. Maybe even make it final, although it is redundant with the private constructor.
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
but why? :)
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
ok didn't know that. yet another bug fixed in master then it seems
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
something is wrong in this sentence :)
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
On reflection I think this means we don't need `lastCommittedState` any more.
I believe `ScrollHelper.fetchAllByEntity` already wraps the listener in the client's `threadContext`.
Yes! you are right ð
I think this is a sign that `getActionFilters` maybe should take `ThreadPool` as an argument.
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
I don't believe this is only kept for BWC. You use this to parse `_source` above.
shard can remain
I think you are missing a `\n` here.
I don't think this is correct? Do tests pass? This should fail on unmapped fields.
Maybe better to use MapperService.isMetadataField since "_" is a valid prefix for a user field name.
Without much context to this code, it appears that `parameters` was likely meant to be sent as the first parameter to `newInstance`. The code here checks `script.getParams()` for null, but it does not check it downstream and could result in NPE if `script.params()` is ever null.
We discussed this issue in person and came to conclusion that this dead code is indeed dead code, and wouldn't make a difference if we started to use the parameters. Also we should fully remove the deprecated params.ctx support for 7.x (issue not logged yet).
Can we do all of these things (stripping last char, backslash escape and quote escape) in one pass with a string builder? Right now 3 copies are made of the string.
I'd move this to line above, but I like the thought behind the change.
Same deal as the last `toString`.
Same feedback as the last `toString` - I think you can remove `created` and might want to look at `Operation`'s `toString`.
There's no need for reflection here - writing out all the fields, in a sensible order, is much preferred.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
You can use the diamond operator here.
You can use the diamond operator here.
class could be `final`
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
cancel that :) I figured it out.
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
I wonder if we want to add an `@After` rule that checks that all semaphore permits are back.
I think this can move to before the threads start - will be nastier
I am sorry, I didn't think this through. The two sections have the same name, so the json wouldn't even be valid if they were both there. I think we should not check it explicitly, otherwise we would have to do it for every single field in our parsers, which we don't do. Relates to #19614
Do you think we could get away with making this an assertion instead? A plugin developer would hit it during testing.
I think that it can rather be empty, hence we always print out the array, which sounds ok to me. I think the null check can go away.
no, I think we should print out what the user sent, not our own resolved objects.
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
don't try to fix it, you just moved code around, but this catch block worries me :(
you can remove the validate call for now, we will fix all queries soon, I promise
you can just use `MultiFileds.getFields(index.createSearcher().getIndexReader());`
Yes, sorry for the confusion, I remember the discussion now. Maybe just rename then, although `elementName` is also fine.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
see above - I think you should add it though
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
This can be outside the try/catch right? If there is a failure to create the pipeline, there is no pipeline to close.
And regardless of if the parsing exception is important, if closing is necessary, failure to close should be added as suppressed exceptions to the parse failure.
But that means the pipeline can never be used again (it is now closed).
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
also, at the moment we don't check for ids uniqueness, which is probably fine given what we need ids for, just double checking that we don't rely on uniqueness anywhere
this should be `IOUtils.close(phase1Snapshot, () -> resources.remove(phase1Snapshot))'
I would execute the `IOUtils.close(resources);` in a finally block after we sent back the response or the other way around.
Typo, finalzlie -> finalize
doc level failure (normal failures are OK from an algorithmic perspective).
I am not sure if we should catch an exception here IMO the exception should bubble up
I think you should remove the `!` here, throw exception if `failNoIndices` is `true`
I think we should mention the index, cause that is the useful bit (e.g. which index is closed), also because we never really hide the fact that users are using aliases (e.g. when indexing into an alias, the response will contain the concrete index as `_index`, not the alias).
hey @martijnvg I double checked with @clintongormley and we both think it's better to add the actual index that was closed, not the alias. Knowing that an alias is closed has little sense, better to report back which concrete index was closed.
yes, that's what I was thinking, I'd maybe check state != CLOSE rather than checking for OPEN, but that's a super minor concern that doesn't change the result at this time
wondering if the other way around would be better: create a new array instead of set and add open indices to it from within the loop.
good point I am curious too now :) I hadn't noticed this at first
`expectedType.cast(e)` should remove the need for the unchecked suppression.
with the recent changes, I think that you only need the filter above when testing with failures. here and in the other test.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
I just think its weird to declare the field expects the value to be an int when actually we are also expecting string values that are not the exact string representation of an int (i.e. cannot be parsed using `Integer.valueOf(String)`). It took me a little while to work out how this worked when I reviewed it so personally I think its worth making the change for code readability.
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
This does not necessarily need to be within a static initialization block.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
there are more similar problems below
In these cases its acceptable to use randomize testing's `rarely()` or its like to cover either branch randomly.
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
This does not compile; `FakeRestRequest` does not have a constructor with two arguments. This is a recent change and I think you just missed it when you rebased.
Although the code is clear, the level of indirection here makes it hard for the reader to figure out that this (and similar other) test does. As a suggestion, what about combining test_object/test_object_IgnoreMalformed, then the code from `sourceWithObject` can be inlined in the test case. Also I would make the assertion on field1 and field2 explicit, even if that means a few more lines of code. In this case I would trade repetition for readability.
`Description` -> `Descriptor`
I think this is a duplicate of `connect()` above (minus an assertion) although I prefer this name a bit.
Wasn't me, it was the tests :)
nit: can we move the look up of the primary to the callers that pass null? this method is hairy enough :)
I guess it could be renamed to isFalse() / isTrue() now
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
cool thanks for clarifying!
oh I see what you meant now in the other PR :) if Tuples don't pollute the method arguments, I am ok with this, actually it simplifies synchronization issues between the two maps otherwise, I will update my PR to do the same.
Ah yes, thanks!
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
and remove the below null check
otherwise I would be happy to just return in the else block and remove the instanceof check in the while loop below
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
remove this additional line break? :)
do we want to unify this code with the refresh method by making this get a manager to work on? (+ a string description for failures)
hmm I see it's to opt out...
same here re enumSet.toString
we need to remove this from onGoingRecoveries and only call cancel if it was found, otherwise we may leave a lingering recovery id, pointing at a cancelled recovery.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
Could you explain why this needs to be public now? I think we should try to keep this package private if possible
Can you throw something else? It just makes me uncomfortable to throw AssertionError.
actually I don't fully understand why we can't just do `this.order = order` all the time
Could you make the reduction create a new aggregation instead of filling the first one? This proved to be error-prone in the past.
I am wondering if it makes sense to implement `getProperty()` for `Aggregations` as well and not just for `Aggregation`. For example in a test I would write something like ``` Aggregations agg = searchResponse.getAggregations(); Object o =agg.get("aggname").getProperty("path"); ``` but if Aggregations also implemented getProperty() I would save another line and it is needed anyway here internally.
should be `final`
Not necessary with `ConstructingObjectParser`
excude_interim - missing 'l' -> exclude_interim
Misspelled in the \@param tag also
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
Nit: "seq no" -> "seq_no" (inconsistencies will make searching more difficult)
make these variables protected please and access them directly in IndexShard. I don't like accessing fields on self through getters. Also, this makes the PR harder to review, as it adds much noise.
can we just inline this in the transport action file? I don't see the need for another file.
Warning! Possible bikeshedding ahead! I think it should be `index.seqno.*` so it matches the package name? And I think drop the `index_`? Similarly for the other [setting](https://github.com/elastic/elasticsearch/pull/15111/files#diff-7efaad9c1a20fcc9fde96322ebc02e0fR42).
I meant [this](https://github.com/elastic/elasticsearch/pull/31163/files#diff-2ec2c2b070f96bf66b888db94648ffe0R321) . The standard engine ends up returning a `SnapshotIndexCommit` which is why I used the term lucene snapshot. I hope this is clearer.
nit: iff does not need an "otherwise". Either make iff to if or remove Otherwise.
"if if" again
this should happen after we update `isSecurityEnabledByTrialVersion`
I guess it could be renamed to isFalse() / isTrue() now
nit: maybe call this `awaitSearchActive` (or `markSearchActive` if my other suggestion is accepted to move setting the timer here) ? pending refresh is an internal implementation detail..
"new" -> "now"
confuses the shit out of me everytime :)
OMG `== false`! ð±
here I'd do the same as above an pass in an some kind of BytesReference factory that can produce new BytesReferences and return a `CompositeBytesReference` instead the `int` to signal how much has been read. We can figure out how to do SSL and stuff afterwards this is too hard to do in one step
We should call ignoreReplicaException() imho.
same here just use synchronized methods
iirc we add `Asynchronously ...` to this sentence in the other APIs. But its a minor nit...
Just a note here. We decided that by convention we will use the same naming as maven. `groupId` has now changed to `org.elasticsearch.distribution.[packaging]` so I think we should also reflect that change here and use `org/elasticsearch/distribution/[packaging]` where `packaging` is: - rpm - deb - zip - tar
doc level failure (normal failures are OK from an algorithmic perspective).
Usually we also make a few API calls to the server, e.g. https://github.com/elastic/elasticsearch/blob/2aba52de8f9315b0e384e1c657d7b0401d26a1b0/qa/vagrant/src/main/java/org/elasticsearch/packaging/test/PackageTestCase.java#L121-L122 I'm not completely sold on the value of those though
yea I think it would be good to have a test that makes sure that the index expression specified in remove_index resolves against indices only, rather than aliases and indices. I don't think the current test does that.
Incides -> Indices ? ;)
I think we can remove this
`createIndex("test")` ? then you can remove the following `assertAcked`
can we use different ids for the different indices? I find this super confusing to reason about. Maybe also add the routing value you expect to be used to the id.
simpler as it decouples these two things. And no need for having this method return a boolean.
why change the semantics here to only call close when setting the tragedy the first time? Let's keep the existing semantics and make `setTragicException` return void
this case got lost
add space after `//`
space missing between `)` and `{`
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
scratch that, I think this will be fine as-is in 6.x as well.
we also support a parameter called `updateAllTypes` here.
no need for extra space
`fielddata` is the preferred name as of my merging #28943 today.
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
I don't mind as long as we use `writeString/readString` and `writeOptionalString/readOptionalString` consistently. So you can maybe just change the `readFrom` to explicitly use readBoolean.
and the last one ;)
can you remove this empty line? :P
I understand this is the oversight you've mentioned
I think we can simplify this and make sure we have 1 shard, no replicas.
I think we can clean up the http/transport/gatway settings here
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
if you want to know i happened, let's use logging..
boo! :) just ignore :)
Nit: `accross` -> `across`
I'd rather just `new ConcurrentLinkedQueue<>()`.
I think that we can do better than this. If I'm reading this correctly, this means that we wait until an entire batch is complete before submitting another batch of requests. Thus, a slow request can hold the next batch and thus the response. I think instead we should try to maintain as many requests in the queue as possible, up to the concurrent request limit.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
I don't think we need this part? Even if you've created an index with 6.4, you still want to be warned that things are going away if you upgrade to 6.5
thanks for adding this
You could add an assert that it's not ES 7.x here so we know to remove it
let's not log since it is an old index
This could be `Strings.hasLength(tokenizerName)`
final and java docs
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
nit: remove extra new line
Can we also clear the temp `charBytes` array, something on the lines of: ``` final byte[] charBytes = CharArrays.toUtf8Bytes(password); try { return builder.startObject() .field("password").utf8Value(charBytes, 0, charBytes.length) .endObject(); } finally { Arrays.fill(charBytes, '\u0000'); } ```
I also need to go back and do this for the PutUserRequest
it's just yet another unmanaged thread in the system..
Sure, but you get that also with a 5-10ms sleep. Basically I don't think we should continue to go the path of long sleep-based tests, we know this is not good...
I opened #19880 with an alternative which does not use sleeps.
I don't get it, it seems the test provides no guarantees whatsoever? Why not be fast then :)
this is usually a bad sign. We should use sleep anywhere. Sometimes it's needed but we try give all the utilities to make sure no one used it explicitly. In this case we have assert busy: ``` assertBusy(() -> { final ClusterState currState = internalCluster().clusterService(masterNode1).state(); assertTrue("index not deleted", currState.metaData().hasIndex("test") == false && currState.status() == ClusterState.ClusterStateStatus.APPLIED); }); ```
I think 1/2 + 1 == 1 :)
I get that, I was just wondering why those default templates bother here
for master you don't need to specify the gateway.type we only have what used to be local!
why a single data node? If you need that, you can use `numDataNodes=1` instead
I think the message should be "security manager is disabled", because the assume would only print the message and ignore test if the security manager is disabled.
the ones returned here are the fields that can be shuffled or that should not be shuffled? Not sure if the name is consistent with the behaviour
The main advantage to me is that implementers of nextValueHashed wouldn't have to be concerned anymore about whether they can fill the bytes or are just allowed to change the pointers, since they would know for a fact they are always operating on a private BytesRef instance, they are allowed to do whatever they want to.
Instead of exposing it as a shared scratch, maybe it could be exposed as the current value? Meaning that instead of eg. doing ``` java BytesRef scratch = bytesValues.getSharedScratch(); bytesValues.setDocId(42); int hash = bytesValues.nextValueHashed(scratch); // the value is now in scratch ``` Consumers would do ``` java bytesValues.setDocId(42); int nextHash = bytesValues.nextValueHashed(); BytesRef value = bytesValues.current(); ``` (The name is maybe not the best candidate, but the idea is to do something like `TermsEnum.term()` or `DocIdSetIterator.docId()`.)
This can be replaced with ``` java boolean isFalse = isExplicitFalse(value); ``` to simplify and not duplicate the logic
just for kicks can we have `reason = "works around https://bugs.openjdk.java.net/browse/JDK-8034057"` it's just more obvious which bug is meant
I'd not do this, just pass syntactically valid values to the Prototype ctor
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
I would probably throw an exception instead of accepting null here.
I'm happy we made those exist queries fast. :)
good catch! that means we are not properly testing this case either given that we didn't catch it.
I wondered if there was something better than iterating too but there's not since `IndexWriter#getLiveCommitData` only returns an `Iterable`.
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
a transformer and performer. Quite a guy :)
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
we may want to rename match_formats as well here, can do in another PR though.
oh right sorry I had missed it's a single value for these processors. sounds good.
I like this simplification!
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
But yeah, keep it now.
Technically not an "and".
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
this will not get executed as a test if the method does not begin with `test`
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
This does not compile; `FakeRestRequest` does not have a constructor with two arguments. This is a recent change and I think you just missed it when you rebased.
s/HashMap<String, Object> fields/Map<String, Object> fields
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
as we discussed - corruptions can't lead to mapping parsing failures. They fail way earlier when reading from the translogs
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
If that's the case, we don't need - that's making sure :D - where do you see it's done in ESTestCase? (I didn't check myself)
please make sure all files closed and no file is leaked.
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
we don't want it to be retried... that was the cause of the failure
my thoughts too :)
Typo: "Dynamics" -> "Dynamic"
Maybe warp the listener using ActionListener#wrap which does the write things and will simplify the code here too.
nit: maybe call this `awaitSearchActive` (or `markSearchActive` if my other suggestion is accepted to move setting the timer here) ? pending refresh is an internal implementation detail..
I'm not sure if this is practical in all cases, but IMO a lambda would work pretty well here: ``` nrReplicasChanged.forEach((fNumberOfReplicas, indices) -> { ```
I think assertThat(throwables.get(0).getMessage(), containsString(...)) might be a bit better, especially if we don't specify an error message ourselves. Same for assertThat(throwables.get(0), instanceOf(...)).
this is not needed. createIndex automatically reroutes.
This also might need an `ensureGreen`
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
can we just delegate to `valueOf` and if it throws an exception we return the default? I don't think we should do the linear checks here
Same idea here as with StreamInput: ``` java @FunctionalInterface public interface StreamOutputWriter<T> { void write(StreamOutput t, T value) throws IOException; } public <T, R> void writeMapOfLists(Map<T, List<R>> map, StreamOutputWriter<T> keyWriter, StreamOutputWriter<R> valueWriter) throws IOException { writeVInt(map.size()); for (Map.Entry<T, List<R>> entry : map.entrySet()) { keyWriter.write(this, entry.getKey()); writeVInt(entry.getValue().size()); for (R v : entry.getValue()) { valueWriter.write(this, v); } } } ``` The caller would use it with: ``` java out.writeMapOfLists(map, StreamOutput::writeString, StreamOutput::writeString) ```
I don't think we should do `__default__` we can pass the default separately...
I don't get it sorry :)
I think it'd be nice to remove this second ctor so we're explicit every time.
we should clearly state that these are the shard of the new index
why do you pass the response to this method? `this` already has all information.
remove "or timing out".
Why is it not possible to specify 0? I might want to create an index without waiting for any shard of that index to be active.
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
alright that's what I thought too, sounds good
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
+1 to this, there is always the low-level rest client for this, and we can revisit adding it at a later time if we change our minds.
No need for an empty default ctor when the super is also a default ctor.
This cast should not be necessary. You can use `in.readMap(StreamInput::readString, StreamInput::readString)`
thanks for digging in. i only dug into the aws one and have not looked at the root case of the gce problems. If it involves weakhashmaps, maybe its something easy we can fix for them as well to avoid pain.
Ok that was fast :D
nit: `== false`
ok can you add alls these infos into this class
you can call `bytesAsInt()` then you safe the cast and it checks that it's lossless
nit: here I would maybe use do while just to make absolutely sure that the first round always runs.
I called these methods test*ToAndFromXContent() as they effectively do one complete roundtrip: toXContent -> fromXContent -> toXContent
I am adding a util method for this in XContentHelper, maybe worth replacing this later (should not block this PR)
maxDepth can be final
we usually have a switch based on the token found. For instance here we would have one for start_array, and we would do something if the current field name is `failures` otherwise ignore. And another `if token.isValue()` for total, successful and failed. You can find something like this for instance in `SearchResponse`. This makes it easier to reason about what we are parsing I think.
We can save object creations here by making the ByteArrayDataInput final and using `ByteArrayDataInput.reset`.
ideally, you should read directly into `scrach.bytes` instead of allocating a `byte[]`
this check is obsolet - we can just remove it
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
see above - I think you should add it though
just call `parser.text()` instead of `parser.bytes().utf8ToString()` since it might be optimized under the hood
now I see what you meant yesterday saying that we have to parse meta here
Writeable#readFrom returns a new instance of the object, it allows to have final fields, but it requires to have a PROTO instance of the object to call readFrom against. I wish there was an interface to declare writeTo only though but we don't have it at the moment.
Doesn't PipelineConfiguration deserve its own class file under o.e.ingest ? It's returned by the java api too.
while I get that the preference for a for loop... but the inconsistency of how xcontent is parsed is annoying.. if we do it everywhere using a `while (...)` then we should stick to that... if we want to change to a for loop, then lets do it across the board
Oh oh! deleteUnderLock should be called when you hold the lock! instead we should use IndicesService.deleteIndexStore
this is unneeded - we just iterate of the list...
I think this will result in a double info logging - we already logged at info level when discovering this.
can we log the full index object, includeing the index uuid? also it would be good to have the current cluster uuid and the one in the index meta data state.
save -> safe :tongue:
I really like this class since it's so self-contained and has all the tests etc. no weird guice bloat etc. NICE!
if you make `MulticastChannel` generic and the listener as well you safe the hard cast in Shared... just like `Shared extends MulticastChannel<MultiListener>` ...just an idea...
Yeah, it's relatively new but it's the clear path forward especially with JUnit 5 coming with built-in support for the same.
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
could be a instance variable, as used in all tests
no need to make this public; package-visible is good enough.
Please revert this change.
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
I would write this check as ``` if (shardRestoreStatus.state().completed() == false) { ``` and then add an assertion that `shardRestoreStatus.state() != SUCCESS` (as the shard should have been moved to started and the recovery source cleaned up at that point).
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
I think you can avoid that by overriding `AbstractXContentTestCase#assertToXContentEquivalence`? I think it's worth using `AbstractXContentTestCase` here, it's going to be much more thorough than hand-rolling parsing tests.
@jtibshirani is correct
I need to sit down to make a approach, ill finally have time early next week. Id prefer the manual parsing in order to test the fromXContents, for now.
thanks for moving this to a unit test!
don't prettyprint please we don't test this here
Although the code is clear, the level of indirection here makes it hard for the reader to figure out that this (and similar other) test does. As a suggestion, what about combining test_object/test_object_IgnoreMalformed, then the code from `sourceWithObject` can be inlined in the test case. Also I would make the assertion on field1 and field2 explicit, even if that means a few more lines of code. In this case I would trade repetition for readability.
Would you kindly add some line feeds here to make it look like json instead of a wall of text? It'd be so much easier to read.
you can make one of them public and call it from both tests, I don't mind
Ah yeah, the docs are a little confusing with regards to how it works internally. The persistent/allocated Task is always running, start and stop just toggles internal state. If the task doesn't exist, the job doesn't exist basically.
Shouldn't this be equal to the `jsonBuilder().string()` above, without adding `.prettyPrint()`? And a nitpick: please add a space after the comma..
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
This seems to only be used for tests. Maybe it should be a helper method in the test framework instead of part of the public api? I would be afraid of something accidentally using this in ES code.
Ok, my confusion stemmed from the fact the first result when searching down the diff was ScriptProcessorFactoryTests.java, which this PR changes from testing against `getMessage()`, to using `getDetailedMessage()`. I see now that is the only case. Can it be switched back? Changing the tests to use `ExceptionsHelper.detailedMessage` seems ok given they all already use it.
I think you should just do `instanceof Number` and else call `.toString()`
@rjernst can you fix this ^^
Maybe as a followup (at sometime, not that important) the callers of this could be made to use the one line impl here. Just seems like a silly method to maintain.
can we assert that if we need to generate a new history uuid we always use `*_CREATE_TRANSLOG` as an open mode? that's why we rely on the translog uuid only for trimming purposes (and avoid thinking about what it means to generate a new history uuid)
I wanted to remove the `allowCommit.set(false)` here with an ensureOpen at the beginning of the method. Only saw later it's already there. No doubles.
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
maybe replace this with ensureOpen in the beginning? feels cleaner to me
I think you want to say that no commit point was found which could be recovered from the translog.
In my dreams, merging would either throw an exception or return a new independent mapping so that we wouldn't need this validation phase :)
I think that will fail compilation? ð
Oh, never mind, I misread. Sorry for that. ð
wrap the plugin names in `[` and `]` for consistency
just as feedback, nothing to change really, but I liked the previous variable name better ;-)
shall we check that we get some results back? Just making sure that we actually search against the alias. If it doesn't exist we could get back empty results without any error...
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
Left over Note
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
this is super ugly I think `AsyncShardFetch.Started` and `AsyncShardFetch.Store` should be an impl detail of `GatewayAllocator` no need to bind this or anything
just for kicks can we have `reason = "works around https://bugs.openjdk.java.net/browse/JDK-8034057"` it's just more obvious which bug is meant
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
@rmuir are we OK with this? Is there a better way (not sure at all, just double checking).
cool. this is sufficient for ILM for now, so that makes sense
that awfully sounds like two voices for debug.... your turn, @jasontedor.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
can we do the assignment in another line, very sneaky :)
this made me worry we don't log these failures anymore.. In this specific case I think we are best to just let the exception bubble up, but it does raise a more general issue - if people put exceptions in the builder, it's their responsiblity to report it. we should probably add something to the internal cluster service to auto log it.
"now" should be "not"
typo : now -> not
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
This many levels of nesting hurts my head! How about refactoring the inner half into a private `findShardIds(@Nullable String index, Path indexPath)` method so it's easier to read? I'm worried about the potential for future typos for anyone else touching this code
left over reference to a countdown latch
I think we need additional null checks here. Before the refactoring we only needed to check lucene queries in parse() method for null. Now also their `toQuery()` can potentially return `null` (e.g. if this FilteredQueryBuilder would be nested in itself). Same goes for the filter.
btw. I am currently thinking about how we can at least make the inner QueryBuilders we use always non-null, but will need to do this in separate PR and ask Adrien about it.
I just realize that there might be a bug in the existing code already. We only seem to add the query to the named queries if it's a BooleanQuery, the other cases return early. Not sure, but we might want to change that.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
hopefully having a default for fuzziness makes it non optional and simplifies things slightly here too
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
Should we increase visibility in this case? Makes only sense if we can then really test more, though, otherwise okay to leave it I guess.
Then we should leave it, the situation in general improves here already.
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
Same here as above, since both methods are related and read similar.
This test should assert that the headers are correct.
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
wouldn't it be cleaner to just work with sets here? (instead of converting to arrays)
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
we need to check on the node version, and only call it on nodes that are version 1.3 and above, otherwise they won't have this API
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
I'd just use the Id really
save -> safe :tongue:
Elasticsearch tradition is to make this an EMPTY constant :)
drop the actually? sounds so "uncertain" :)
same here regarding nullable ..
I see some places where null is not protected against...
I think we discussed this before, but it didn't change, thus I'm bringing it up again ;) can we add a constructor that accepts `shardInfo` as argument and change the subclasses constructors to accept it there, just to enforce that this info is needed so we don't forget it anywhere. Maybe then we could also remove the setter...
would be nice to allow to configure it to a percentage of the heap size
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
those are hard to debug I can tell u :dancers:
confuses the shit out of me everytime :)
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
wondering if we need recoveryState.isPeerRecovery() to simplify these lines.
> can be cancelled just because primary relocation completed before shard was activated by the master node yes. I'm aware of that - I'm thinking that with seq# fast recovery it wouldn't matter much as a ready shard will quickly re-recover. However, seeing how the new code looks like with the cancelRecoveriesForShard + shardRouting.isPeerRecovery changes, I think it became much simpler. I'm good. We can see how things develop later on and potentially move some logic to the master (which will simplify this class) or not.
we lose some concurrency control here where we only cancel the recovery if it's not done. I'm wondering if we should use `cancelRecoveriesForShard` and if it returns true, we then remove the shard. Also - In all cases where the the source of recovery changes due to a primary failure, the master cancels the allocation and changes the allocation id, meaning we don't get here. I wonder if we should also catch the case where a primary relocates on the master and not have to worry about all of this here. I think it will be simpler all in all
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
For static varialbles, `final` should indeed be used whenever possible.
Optional: darkon has this style that I like where you start a new block every time you startObject or startArray and it makes these much more readable!
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
and.. looking at the parsing logic this is indeed internal and we don't accept none from strings. Sorry for the noise.
nit: extra space
Yeah, I'd make these a hard check and throw a `new IllegalArgumentException("Usage doesn't look like UnifiedHighlighter")`.
same question as above
fantastic thanks a lot
thanks for doing that Colin ;)
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
can we please unpack the tuple right away instead of using v1 v2? just easier to read
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I think that these log parameters are backwards.
Nit: spacing between `while` and `(`.
Nit: spacing between `!` and `value`.
this deserves a sep issue I guess but good catch
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
fine with me
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
final and java docs
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
nit: remove extra new line
Can we also clear the temp `charBytes` array, something on the lines of: ``` final byte[] charBytes = CharArrays.toUtf8Bytes(password); try { return builder.startObject() .field("password").utf8Value(charBytes, 0, charBytes.length) .endObject(); } finally { Arrays.fill(charBytes, '\u0000'); } ```
I also need to go back and do this for the PutUserRequest
Optional: darkon has this style that I like where you start a new block every time you startObject or startArray and it makes these much more readable!
I get that, I was just wondering why those default templates bother here
I think you can shorten the mapping here: `addMapping(type, "name", "type=string, analyzer=stop"` that hurts my eyes less :)
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
I think that inserting random fields here would reveal problems on the parsing side with the current code.
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
nit: you can just let the validate throw it's exception - this will fail the test and give us more info
same here - we need move double starting and such to ShardStateActionTests
we should check the exception is what we expect (assert part or all of the message)
not was indeed my point - we don't need to task what shard allocation does with the shard failures, we just need to test we told it to fail the right shards. But this is nit picking :)
do we want to check that the shards were actually failed? Ideally we would just check that the allocation service was asked to fail them. Mockito maybe helpful? I don't want to hold you back for this though...
I donât think this buys you anything in terms of concurrency. The list reference is already final.
This has issues as two calls could wind up finishing this listener. I think it would be better to use a AtomicBoolean and compareAndSet.
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
this class could be made `final`
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
it's important to log the shard routing of the out of sync shards
Can you add the `translogId` to the log message here? It makes tracking stuff down on shared filesystems much easier.
Nevermind, I see it later on in the `commitIndexWriter` method :)
I think we need to throw an exception here, just as we do above with the currentFlushing check.
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
new is not possible with an older version...
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
argh. Hidden by github ui. all good.
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
-- reinitialize shard
nit: maxTermFreq must be positive
nit: `if minDocFreq is greater than 1, then it must not be a fraction`
minDocFreq must be positive
nit: `maxInspections must be positive`
These should all have sensible defaults rather than being null, as we have done with all the other builders. This also means we can remove @Nullable from all of the methods and add checks in there that throw an exception if null is passed in to make it safer. The defaults we currently use can be found in DirectSpellcheckerSettings.
I believe `ScrollHelper.fetchAllByEntity` already wraps the listener in the client's `threadContext`.
Yes! you are right ð
I don't think we need this branch anymore.
Is this an oversight? `DEFAULT_KEEPALIVE_SETTING.get(settings)`
I see that `ScrollHelper.fetchAllByEntity` already wraps the listener inside a `ContextPreservingActionListener`.
Instead of having this public ctor should we have one that has this signature: ``` Java public CompressedXContent(ToXContent xcontent, XContentType type, Params params) { // do the serialization here with checked output stream etc } ``` that way we can hide the _CRC32_ impl detail entirely
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
if the size was previously less than PAGE_SIZE_IN_BYTES (possible with the contructor that exposes a size), this will actually grow the array (potentially going from a simple heap-allocated byte[] wrapper to a recycling instance)
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
ReflectiveOperationException can be used instead of both of these
can we just change this to System.getProperty("tests.seed") != null? Then that method can be removed.
In case you don't need the parameter, you can remove the null check as the constructor already checks that as a precondition.
underscore case? :)
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
I think the less-specific types are better when you can get away with them so that you do not come to rely on implementation details of the concrete type.
I'm fine with it, given the explanation. I only saw that it seemed to be a variable name change that was unnecessary.
can we add bogus non relevant settings? Would be good to know they don't mess up with things.
nit: can you use assertThat or expose the actual values in the message.
wouldn't it be cleaner to just work with sets here? (instead of converting to arrays)
I see this was already like this, but this can go on a single line.
Yeah, it's pretty new. :-)
Fine with me.
acceptDocs will be checked _before_ these bits are checked anyway
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
Snapshot Name - repository name + snapshot name ;-)
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
I'd prefer this to be `@Nullable` as well... relates to xcontent serialization
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
same here, might be that we are good, but let's make sure we don't lose the STRICT one
to make this simpler, I think we should add a method `addCustomFields` to the `AcknowledgedResponse` object instead and just call `response.addCustomFields(builder)` in `AcknowledgedRestListener`. As a follow-up we can then make AcknowledgedResponse implement `StatusToXContent`.
I don't think is necessary. `request` is passed as`params`. So, "verbose" is already in `params` if it was specified, you just need to be careful resolving defaults. You would also miss other parameters here such as human and pretty.
Maybe this one too, I'm not sure.
Fine by me.
nit: maxTermFreq must be positive
nit: `if minDocFreq is greater than 1, then it must not be a fraction`
We would need a call to super() somewhere here. Or, like we did with the query builders, have the superclass declare two abstract doEquals/doHashCode methods that it then calls and the subclasses need to implement.
Sorry, didn't see that, you're right.
nit:`maxEdits` instead of `max_edits`
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
this might be called by `scheduledRefresh`, which can happen at any time
this could possibly called I think
this might also be called I think
we should assert this is never called (same for the other places here where `UnsupportedOperationException` is thrown), as this indicates a bug.
good point, we will once we have the processor that updates them, which is being worked on.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
This can be outside the try/catch right? If there is a failure to create the pipeline, there is no pipeline to close.
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
Most likely meant `&&` instead of `&`.
here is a space missing before `EMPTY_FLAGS`
so `round` should be called once per factory instead of once per aggregator
Nit: you could use `Collections.emptyList()` instead of `new ArrayList<>()`
Ahh okay, makes sense, good point.
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
No "unsupported HTTP method" message? :)
maybe just `esVersion()`
how about changing this to `if (upgradesInProgress.decrementAndGet() == 1) {` so we can remove the return statement. I find this easier to read as the action only happens when the in progress value is 1.
I think that we can do better than this. If I'm reading this correctly, this means that we wait until an entire batch is complete before submitting another batch of requests. Thus, a slow request can hold the next batch and thus the response. I think instead we should try to maintain as many requests in the queue as possible, up to the concurrent request limit.
I think we should do this as one of the first steps in the if block. The reasoning is that if an exception occurs before this, we will never get the chance to continue operating as nothing will trigger this method again
s/The upgrade/The template upgrade
Lets leave off the third sentence
same here, all retry logic should be removed
same here with removing retry logic
same here with removing retry logic
same here with removing retry logic
I also wonder if we should log `TRACE`/`DEBUG` issues for this.
@s1monw if you're proposing we use inheritance and you assume the base class will always be caching DF then we could just remove all the "if(this.docFreq)" checks in the existing code as a simple way to clean things up? That would leave us with just the "if(this.totalTermFreq)" checks.
I think we should have a baseclass that only handles DocFreq and then subclass it if we need TTF that should remove a lot of branches here though. I don't like the long methods that basically repeat code because of the TTF / DF swtiches. I mean it makes sense do split it since they have a higher cost if TTF is needed though.
I guess that's ok...
+1 there is a good example in BlendedTermsQuery though
Different leaves might use different codecs, and some of them might support `totalTermFreq` while other leaves might not. So this should return `-1` if any of the leaves returned `-1`.
I think we should separate the two and push this as is. Your code refactoring has more changes than this functional change and on the security end I think we should be careful. let get this in and cleanup the stuff afterwards
yeah again, its definitely bad the way it is now, easy to break. if we initialize netty classes too early before security kicks in, we might not notice anything, then suddenly users jvms are crashing (e.g. because of some bug in unsafe/native usage, or whatever). with a netty module things would get way better: one advantage is, netty isnt on the classpath anymore, instead we load it explicitly with `URLClassLoader.newInstance` in PluginService, followed by `Class.forName` and so on with the registered plugin class from the plugins configuration file. So it would be well-defined exactly when these classes will get loaded, and its all after security and everything else is fully initialized.
> Last - if there is any way to determine the list of classes loaded at the point security kicks in, Yeah, you can do something like this: `JAVA_OPTS=-verbose:class bin/elasticsearch`
> Also, for my understanding - what is the difference in terms of class loading between running that static `NettyTrasnport.DEFAULT_RANGE` that was before? Accessing static compile-time constant variables will not trigger class initialization, but any other access to a class member will trigger class initialization immediately before the first such use (the JLS provides very strong guarantees about [when](https://docs.oracle.com/javase/specs/jls/se7/html/jls-12.html#jls-12.4.1) and [how](https://docs.oracle.com/javase/specs/jls/se7/html/jls-12.html#jls-12.4.2) this occurs). > This is so easy to slip without anyone noticing. Yes. The [suggestion](https://github.com/elastic/elasticsearch/pull/14549/files#r44182190) for a test for this has come up before.
typo: "always called" twice
same here - I think it's better to log the info message if the deletion was successful.
Left over Note
same here: no need for the [].
index's toString gives you '[index_name]' no need for '[{}]'
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
nit: extra line
I think this can be simplified into ``` if (obj instanceof Map || obj instanceof String) { valueWrapper = Map.of("shape", obj); } else { ```
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
formatting should be fixed like the rest in these three lines
can you please inline this while [adding docs](https://github.com/elastic/elasticsearch/pull/30176/files#diff-ed6e20d0c4d03d97ae9b7a9a33190c4bR1532)? We need to have more roll overs randomly
same heere, randomIntBetween(0, 5) would be more life-like
we should totally not have this method, one more reason to not implement the interface.
For the record, I'm asking because I expect the setter to be called once while these create methods can be called _many_ times
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
I'd probably write validate's results to a variable and reuse it.
is this needed here? I think it does something only when the current token is start array or start object.
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
i think `== true` can be skipped
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
this method seems to be wrong here the class is concerned with fetching data in an async fashion, I think what we do with it or what we call as a result should just be somewhere else. I wonder if we can just have an ActionListener that we pass to execute this onSuccess and onFailure since those seem to be the two mode we have.
can we just pass the action to the `AsyncShardFetch` class instead of subclassing this seems so close, maybe the two actions can share a common interface
Miss the sorting based on the version. Sorry for the noise..
would you mind adding `<>` after `new PriorityQueue` ? otherwise this is an unchecked assignment.
this only works if we have entries? shall we check? Also can we just do a for loop here instead
That assumes `list` can't contain null..if that is not the case ignore
I think it would have been worth it but now that you mention it - other requests may have changed this in the mean time too, so let's leave this assertion.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
I think we can share this line and the return new BulkItemRequest line? these two clauses will need to set a final `updateResponse` field.
I wonder if it'd be nice to have the assertion in the docs with a note about how this is the response. And maybe a note that you don't have to assert anything if you don't care whether or not it was created up updated because non-200s throw exceptions.
can we call this primaryItemRequest? It's the one that's sent to the primary. Also, if we pass it as a `BulkItemRequest` parameter, we can avoid sending `requestIndex` and `BulkShardRequest` (from which need the concreteIndex, which I think we can from the shard). Last can we assert that the `BulkItemRequest` has as a request object the `updateRequest` we got? this is all super trappy but we can take one step at a time :)
use the constant defined in SnapshotId...
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
is there a way to filter out the index metadata here? We just want the global metadata.
Since `getSnapshotInfoInternal` (just below) is only used by `getSnapshotInfo`, we can move the code in `getSnapshotInfoInternal` directly into `getSnapshotInfo` and get rid of `getSnaphotInfoInternal`
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I think we should return active.get() == false and also - set it if we became idle...
should be cached thread pool, the default constructor does the right thing here
also, I think the opened channel needs to be closed at one point
why not protect against double closing in the snapshot it self? this is a common problem
This is logic that I think should go into ReplicatedOperation.
Thinking about this more, I wonder if we should have this run-even-if-there-is-nothing-to-do complexity. I'll reach out to discuss.
the suppress warnings could be right on the line of code doing the cast instead of the whole method
could name this `getUUID` to be consistent with other usages of UUID in the code base
let's make sure we deprecate it as well in 2.x
you can rebase and get the changes upstream now ;)
same as in the regex PR, I wonder if we should have parser.text() or parser.textOrNull()
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
so this means we don't support `topLeft` anymore? I think we have to to be honest. Also we have to support `northWest`
I think the OOM reference was a copy paste error from another clause. This clause doesn't do `translog.newTransientTranslog(translogId);` so no need to revert it - although it seems to do no harm if there is no current transient translog.
I think this missed a misses a maybeFailEngine
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
also applies to other places in the code below, if we decide to do it.
Typo, finalzlie -> finalize
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
I think that inserting random fields here would reveal problems on the parsing side with the current code.
MultiSearchResponseTests was written before the test base classes were made more flexible, we should probably migrate that too if it works well for your case
you can override assertEqualInstances
@jtibshirani is correct
nit: formatting, add some whitespaces
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:918E10886BC43EC1]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.LineStringBuilder.<init>(LineStringBuilder.java:49) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiLineString(GeoWKTShapeParserTests.java:112) ... ```
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
nit: formatting, add some whitespaces
Fair enough. I know it used to work in previous version but I'm fine with this implementation. And even better it will be consistent with Kibana plugin manager which also checks that `://` exists.
Also I use sometimes (in workshops) file:../relative/path
No, it should stay "id" in the message because plugins are installed by id (with the exception of some special plugins that can be installed by name only). Yet "name" is fine for removal because plugins are removed by name.
No need to squash, we can do it on merge.
I don't like doing this "try a url and on error do something". Can we instead add an extra condition to the clause, so in addition to having 3 coordinates separated by colon, it does not contain `/`? All URLs will have a slash. Then we don't have to worry about this code trapping a malformed URL and attempting as maven coordinates, and the URL handling below can handle malformed urls.
Let's replace the `assertTrue` by more effective matchers, and replace the `assertEquals` by `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
Can you rewrite these to use `assertThat(..., equalTo(...))`. I prefer this form because it's clearer which is the expectation and which is the value under test whereas with `assertEquals` it often gets confused.
This is another case where I would use a more effective matcher.
This this can be simpler with org.elasticsearch.ExceptionsHelper#rethrowAndSuppress - we just need to keep a list of throwable and deal with them in the end.
Hmm why are we ignoring exceptions here? You can consolidate those two `deleteFilesIgnoringExceptions` into one call and it will do the right thing if either path hit an exc while being deleted...
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
can we please not use `forEach` I think we should stick to for loops it just makes the code more readable and consistent
I think we should throw an exception when `id < 0`, which should never happen? (unless Bad Stuffâ¢)
We've been moving away from these inner fields classes, we don't need them to encapsulate some strings.
I think you want ToXContentObject here.
nit cat we explicitly call the other constructor with null? i.e., `this(null)`
we can use in.readVInt() here, no? it's always non-negative... (same goes for other counters and also note that you'd have to change the writeTo message of course)
you should pass fieldNames as an argument
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
Ah ok, I missing that method below, sorry.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
We've gone back to 140 character limits now so you don't need the newline if you don't want it.
Can you remove this annotation? It's not needed anymore and this will fail when you'll rebase on master.
``` java assertThat(provider.fetchCount, is(1)); ```
``` java assertThat(provider.fetchCount, is(2)); ```
Can you remove this annotation? It's not needed anymore and this will fail when you'll rebase on master.
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
Ok I see the problem... I still find this hackish (needing to throw an exception to test things), but there's no easy way around it if we want to test different requests and responses. I'd consider using a mock request (one per client type actually) instead and give up on testing those real requests and responses. It would be more unit test friendly cause you'd know the request and the response you need to return (unless it's a nodes info request), you don't need an exception and you can assert on the sendRequest directly. Using real requests it feels wrong to only test a few of them anyway and we know that it's the client that injects the headers (`execute` method), that's what we need to test.
I would maybe move this to be the actual test method, with `@Test` annotation, and have either an abstract setup method to be implemented by subclasses or even use junit annotations like `@Before` if possible in the subclasses.
I double checked and heard that `@Ignore` is needed as well, otherwise IntelliJ tries to run this test as well when running all tests from the IDE.
this should be an abstract class, not sure if we also need the `@Ignore` annotation.
right, its a mock.. then use `ClusterName.DEFAULT` and you need one less constant.
oh cool the read is in the ctor! nice!
ok can we rename the getter then to `getFailedNodeExceptions()`
after is now minimum_age
If we use Collection<Tombstonre> we can return an unmodifiableCollection() which doesn't copy stuff..
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
nice! I like this. super helpful for keeping track
we should totally not have this method, one more reason to not implement the interface.
Set capacity to `2`
ok...but client depends on the transport service anyway no? I think I don't get it
I think you don't need to create cache keys and could directly use LeafReader instances as cache keys.
Should this be cached somehow? /cc @jpountz
I think this can leak a reader if `reset(DirectoryReader delegate)` fails (especially when the `this.delegate != null` is true)
I will make it in a follow-up.
Maybe call this 'totalOpenedReaders'? I was a bit confused reading the tests as it looked as though it was reporting the current open count
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
please make sure all files closed and no file is leaked.
can we swap member and constant we know the constant is not null :)
what happens if we assign to null? wondering why these checks are needed
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Are we returning here a mutable map? I don't think we should do that here. We should at least wrap it in `Collections#unmodifiableMap()`
Yep good idea, I'll do that
should be aliases
should be action
I know that this is how it used to be but we add an explanation that this is called before the index is added to the cluster state? created is misleading.
```suggestion * Executed when a shard returns a fetch result. ```
save -> safe :tongue:
Safe because ~~our~~ we know
update version to beta 1
And we could then just leave an assert here.
I meant `node` from the for loop.
Are there any calls to this version of findTemplateBuilder with matchType `string`? Or `findTemplate` below? very confusing how we have so many public variants of this method...
This should be `public static <T> PreBuiltCache<T> getCache(CachingStrategy cachingStrategy)`. As a result a few warnings on the caller methods are gone.
I think all three implementations of `PreBuiltCache` could potentially be `private`
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
maybe make if final
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
we will have to be careful though. If a very short-running method with < 256 calls is timed using this approach, we will have significant overhead from `System.nanoTime()` calls.
nit: "so we assume"...
We can use the SuppressForbidden annotation on top of the class to fix this.
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
I think that these log parameters are backwards.
This method takes a phrase query and is supposed to create an equivalent phrase query that just has a different value of the slop, so we need to transfer the boost? Maybe the method should look like this now: ``` java private Query applySlop(Query q, int slop) { float boost = 1f; Query underlyingQuery = q; while (underlyingQuery instanceof BoostQuery) { BoostQuery bq = (BoostQuery) underlyingQuery; boost *= bq.getBoost(); underlyingQuery = bq.getQuery(); } if (underlyingQuery instanceof PhraseQuery) { PhraseQuery pq = (PhraseQuery) underlyingQuery; PhraseQuery.Builder builder = new PhraseQuery.Builder(); builder.setSlop(slop); final Term[] terms = pq.getTerms(); final int[] positions = pq.getPositions(); for (int i = 0; i < terms.length; ++i) { builder.add(terms[i], positions[i]); } pq = builder.build(); pq.setBoost(boost); return pq; } else if (underlyingQuery instanceof MultiPhraseQuery) { ((MultiPhraseQuery) underlyingQuery).setSlop(slop); return q; } else { return q; } } ```
if we can assert that, it would work for me too
Errr. Oh man. I should know this one but I don't!
OK - I think we are double counting the boost here. Its hard to tell though.
There's just `HighlighterSearchIT` IIRC.
please make sure all files closed and no file is leaked.
If that's the case, we don't need - that's making sure :D - where do you see it's done in ESTestCase? (I didn't check myself)
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
just fix a number, I don't think randomizing this adds much.
Note that you want to make sure that you test the difference between the terms in the ops and the terms in the files. These are not the same.
> but then if that's the case I wonder, how do we test that the setting is not really needed, cause it shouldn't be? :) @javanna imo this should be a pre-release smoke test.
but, it seems we look for an hexadecimal number? (which is OK because normal long are also parseable as hex, but you know, pedantic)
Hopefully the answer is no, we do this here only so the test is reproducible? but then if that's the case I wonder, how do we test that the setting is not really needed, cause it shouldn't be? :)
seems like this is not needed anymore given that we don't go through InternalSettingsPreparer anymore? sysprops will always be ignored I think
Same request for setting keys rather than literals here please.
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
Ahh okay, that makes sense, I missed that
You can just use the literal boolean `false` instead of the string `"false"`.
Let's also make this a JUnit assertion instead of a Java assertion.
yeah that is true. nevermind then
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
can we check and stop if the background thread had any issues? o.w. will have to dig through more than needed.
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
hm. so this hangs now every now and then for a minute. I think it is when the coordinating node is node_1. Then the cluster state observer waits for the next cluster state which does not come and the index request is only executed when the observer times out. We can send the request via node_2 but I think we actually need a way to handle this better.
wonder if we should make these Integer and Boolean just int and boolean primite types.
this would make sense especially given that their setters accept primitive types
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
this should happen after we update `isSecurityEnabledByTrialVersion`
nit - we flush also it will reduce the size of uncommitted gens but strictly speaking it doesn't mean it will be below the threshold
I'm not happy with the extra boolean flag to include / exclude the current generation as a fall back. It's too subtle an error prone. How about doing the following (I think you had it in the past and we moved away from it towards the uncommittedX api - sorry for that): 1) If the min gen for the local checkpoint + 1 is > current committed gen , return true. 2) If the min gen is equal to the *current* translog gen, the current gen is not empty (using `totalOperationsByMinGen`) and the local checkpoint is equal to the max seq#, return true.
This needs to handle the -1 case.
Sure, I was just thinking out loud
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
Same suggestion here for `assertNotEquals`.
We also need a simple rest test, testing integration like we have for the other processors
I prefer `assertEquals` in cases like this. `assertThat` is great if you need to take a matcher or want to assert something complicated, but I like `assertEquals` for equality.
I like `hasSize` better for this because it gives a nicer error message on failure.
I think that all of these members variables except for `finalResponseListener` can be `private`.
Nit: there is an excess blank line here.
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
can you leave this class for now, add the same TODO as in the parser? We can't have a parser without a builder in the query-refactoring branch.
nit: you might be able to save a few toString lines by extending ToXContentToBytes here. no big deal though
good idea, I think this should solve my concern above about setting things that are not supported through the java api.
I think saying that it should not be allowed in the query DSL is a bit misleading, cause it is allowed and we parse it properly. I know what you mean though and why you wrote that, I need yet to come up with a better explanation for this...
I think we can do this without adding an interface? Users should not need to do this? A script cannot realistically be used for both search and executable. I know this is more a problem with the existing scripting apis, but I think here we can just implement executable, and search should throw UOE.
not sure, but should we make the location available to java api users too? Transport client is still a thing in 5.x and this way one has to build the location by passing in the routing value. Should the location rather be a field in the response object? Not sure though as it becomes a header in the final rest response. maybe it's ok this way.
I guess you would have to carry the routing around in the response, serialize it etc. maybe it is not worth the trouble.
Pre-size the buffer? ``` java final String index = getIndex(); final String type = getType(); final String id = getId(); final StringBuilder location = new StringBuilder(3 + index.length() + type.length() + id.length() + (routing == null) ? 0 : (9 + routing.length())); ```
was the answer yes? :)
This is _much_ better.
I think you want (soft)deleted
I liked the assertion you had there that if already have a result, this one has a higher seq no
I think we should discuss such ideas in follow-up PRs. It's not clear to me that replacing duplicate code with more abstractions would be a win.
Sure, I was just wondering as this patterns appears now at least 3 times.
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
I think this can use the FileSystemUtils method you added to get all paths as an array for a directory, instead of creating the stream here.
we could pass a glob with regex:xxx to newDirectoryStream if we want
`index` can be null here, which causes an NPE because the `ShardId` constructor constructs a new `Index` object which in turn interns the name and dereferences the null object.
Yes, but replace `FileAlreadyExistsException` with `IOException` to maintain the same functionality. Sorry for saying it so confusingly before.
I think it's better to use the index version created to test whether the old or the new parent join should be used. This way you can make sure that the correct explanation is returned in the exception if the parent field is not filled.
I think we should do this even if we use docvlaues? I think we should have consistent slicing no matter how it's done!
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
In a followup PR we should merge SortBuilder and SortBuilderParser, I think. The latter one was only introduced as an intermediate step to avoid having to refactor all builders at once. Not sure if we can add the interface ToXContent there as well then.
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
this is not needed. createIndex automatically reroutes.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
There's an extraneous blank line here.
can we add some randomization here around the version - check that new has a higher version then old and vice versa
I'm on the fence regarding this one - on one hand it's a public api and people can do whatever with it so you don't want them to slow down the release of the lock. On the other hand as an API it is really weird to have `POST_RECOVERY` come in after `STARTED` (which may happen if the shard is allocated on master - though the chance is still very small)... will think more.
same here re enumSet.toString
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
I would prefer for IndexShard to just override `changeState` for now, call super, and then do the listener thing. This means one less abstract thing in this class.
These are not the only exceptions that can be thrown. There a bunch of situations in which an `IOException` can be thrown. It's probably worth changing the signature to reflect this too.
Name of the plugin to remove.
I'd just say "Remove the plugin named {@code plugin named}".
Let's remove the period from the end of these, they are typically not sentences.
In fact, it should probably say something like `Remove the plugin specified by {@code pluginName}.`
Typo, finalzlie -> finalize
we can do try-with but we need to have 2 try blocks. since the write lock needs to be released last. but in a try / with blokc it's released before the finally block is executed
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
++ on removing this catch. Not true any more
these ElasticsaerchExceptions are bogus remove them
Thanks for the clarification @nik9000.
yeah, prefer top-level there as well.
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
Space missing between `}` and `is`.
Nit: missing `@Override`
I think it is important to keep different classes on the client-side so that we can have more type safety and potentially add some methods to only eg. avg in the future
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
I would probably throw an exception instead of accepting null here.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
this might also be called I think
this could possibly called I think
this might be called by `scheduledRefresh`, which can happen at any time
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
nit extra newline
> extending AbstractQueryBuilder does it for you Awesome!
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
right I had missed that previous check, sounds good then
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
To me, this logic should really be in `IndicesQueriesRegistry` so we construct the registry with just the `Settings` object and then call a `registerQuery(ParseField, QueryParser<?>)` method which unpacks the `ParseField` and adds it to the registry map. That was the registry is dealing with how to internally structure the data and the internals can be easily changed later without affecting outside code.
I am starting to see that the default boost doesn't get printed out but other default fields do. Makes sense to me but maybe we want to be consistent? I think we should have this a separate discussion, make some decision and do the same everywhere (I have the feeling we are not yet settled yet on one way or another)
why not calling `RestActions#buildBroadcastShardsHeader` instead ? Aren't we losing support for the `group_shard_failures` flag? It is not relevant for the high-level REST client as there is no way to set it but I think it's important given that the parsing code is in ES core. Which reminds me, we should probably test this as well in `RefreshResponseTests`. This param can be passed in as part of the `ToXContent.Params` when calling `toXContent`
As Boa mentioned before we would need both a default to print out, and a boolean that tells whether the current value is default or not, as the `currentValue != defaultValue` is not enough. Something like the following should help in most cases I think? ``` public static void maybeAdd(XContentBuilder builder, String key, Object value, Object defValue, boolean isDefault, boolean includeDefault) { if (value != null || !isDefault) { builder.field(key, value); } else if (includeDefault) { builder.field(key, defValue); } } ``` That said, maybe it doesn't cover 100% but 90% of the cases, and for the 10% left we can still have the custom if? In my opinion it doesn't need to be perfect but still better than copy pasting that `if` so many times.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
Hmm good point, I had forgotten that this class could actually be returned to the user (masked behind an API interface).
All our tests currently use `RandomizedTest#atLeast` method, you can do the same here.
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
Ok I see the problem... I still find this hackish (needing to throw an exception to test things), but there's no easy way around it if we want to test different requests and responses. I'd consider using a mock request (one per client type actually) instead and give up on testing those real requests and responses. It would be more unit test friendly cause you'd know the request and the response you need to return (unless it's a nodes info request), you don't need an exception and you can assert on the sendRequest directly. Using real requests it feels wrong to only test a few of them anyway and we know that it's the client that injects the headers (`execute` method), that's what we need to test.
`createIndex("test")` ? then you can remove the following `assertAcked`
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
Left over Note
same here - I think it's better to log the info message if the deletion was successful.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
can we use `== false` instead of `!` it's so much easier to read and burned my fingers too often
Ok sounds good....as long as all the REST tests pass, I'm always afraid of any change to `PathTrie` :) Thanks a lot for the detailed explanation! Maybe it would be better to treat it as a bugfix and get it in separately? I don't have a strong opinion though since it's something that came up with this new api and wouldn't make sense without. Just thinking it would better highlighted as a different change and leave some more history on it this was applied.
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
I think this is okay though, it checks if the current `zeroTermsQuery` is the same as the default, which is ZeroTermsQuery.NONE.
we frequently use randomizing client, I think that it should frequently use the default (null) preference
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
nit: not needed
this really really feels like ParseField. What does it buy us over ParseField? Sorry I may be missing it!
ok now i can see that it is null when removing the task, sorry for the noise
I think you want to use `notVisitedTasks` here instead of `runningTasks`
perhaps a different name for this listener, as it doesn't only handle failures but also successful response publishing
could be `final`
nit: extra empty line
can this be final
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
the utility should be a static class
this seems like it could create a lot of garbage since we do this for every request. Can we maybe hold a version of this per clusterstate version and invaliate it once the clusterstate has changed...
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
same here: ``` parser.longValue(true); ```
This seems to be the only "shared" portion for string/value. Perhaps it could be moved out? Or just have a helper method, or even just leave the duplication (it is only 2 lines really, not bad).
is this needed here? I think it does something only when the current token is start array or start object.
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
Besides jokes I see your point on NoOp naming, let's leave empty then, it doesn't convince me 100% but I cannot come up with a better name
I think saying that it should not be allowed in the query DSL is a bit misleading, cause it is allowed and we parse it properly. I know what you mean though and why you wrote that, I need yet to come up with a better explanation for this...
cool thanks for the explanation!
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
Ah ok, I missing that method below, sorry.
I'm not sure if the cast is worth it here. It is usually simpler to just work in integers even if we know if can't be more than 255.
I'm fine with the answer being "no, you are crazy Nik" or "not right now".
I wonder if it is worth compressing the hitCount into byteSequence? That way you only have to store an array of ints? You'd have to cap `hitCount` at 255 but maybe that is ok? Or you could use an array of long and have tons of precision on your `hitCount`.
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
It looks like you have proper ram usage stuff. Maybe it'd be simpler to refuse to expand the tree if it'd put the `bytesAllocated` above a certain size.
we may want to rename match_formats as well here, can do in another PR though.
oh right sorry I had missed it's a single value for these processors. sounds good.
I like this simplification!
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
This could be collapsed into the previous `if` statement: ``` java if ((searchResponse.getShardFailures() != null && searchResponse.getShardFailures().length > 0) || searchResponse.isTimedOut()) { .... } ```
(Not that you have it, it's a matter of preference)
Hope this doesn't bite us for really slow (read: Windows) CI servers...
would it make sense to add this nice iterator to core? the ingest plugin could reuse it in this case.
I think we could check that successful == total shards and that total shards is greater than zero
should be clause.getOccur() == SHOULD
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
I am not sure how this can work, is the flag ever set? anyways I think we should remove this flag and change this logic as stated above
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
I don't like leniency. Can it be `"true"`, `"false"` or `null` with the former parsing to the right `boolean` and null giving the default? A typo of `"tru"` will parse to `false` and that makes me :cry:.
The worst is how `on` and `no` both parse to legitimate values, very dangerous for transposing typos.
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
> I think we're talking about two different sets of leniency :) ++ :smile:
This should only be done in close()
nit: we almost never use `Locale.US` exept for some number formating. While I think it doesn't make a difference for the enum names in question here, I'd suggest going with `Locale.ROOT`
There's no need to specify `this` : `if (isString() && other.isString())`
I don't think raising en exception to save a few lines of code here is a good idea, please change this back to how it was before.
Also please `Locale.ROOT`
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
indicesDeleted doesn't check for indexUUIDs. We have a separate method for it in this class `cleanMismatchedIndexUUIDs` - in this spirit of bringing all deletion code together - I think it's good to make indicesDelete aware of UUID switches (mark old as deleted), move the `applyDeletedIndices` to be executed where `cleanMismatchedIndexUUIDs` is called now and then we can remove `cleanMismatchedIndexUUIDs` make all go through here.
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
ok let me have a look then ;)
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
I know previous behavior was to spawn a thread every time. I think it will be cleaner to return a boolean from the deletion methods to say whether the index deletion was succesful or is marked as pending and only spawn the thread for the latter.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
Why remove it? I was adding them because I thought it was nice to mark the constructors for anyone unfamiliar with Elasticsearch. It'd help them get their bearings.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
I think we can check the beforePart == null out of the if(!..equals) and it will make it cleaner.
I think using a `LongAdder` would probably be more efficient than `AtomicLong`, since the value is not going to be inspected as often as its incremented
We need to cast indeed, but I want to give the compiler opportunities to find errors, which is never possible when one starts definiting methods whose generic parameter is only used in the return value. By the way I'm thinking that we could make casts more safe by making category a class instead of a string, and this class would be the base class of the object that the namedwriteables can deserialize
I wonder if we should make this a hard exception, potentially in the AllocationId constructor. When we start using this ID, a null value will create havoc in other places and will be hard to debug..
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Assert that the current thread holds the lock on `this`? The results from `ObjectLongMap#indexOf` remain valid only if no one else is mutating.
Typo: "`check point`" -> "`checkpoint`".
Perhaps annotate this one with `@Nullable` since it's the only one that can be null here
do we really need to walk these directories, can we just do what `getFSInfoIgnoringQuota` does? I really don't think we should walk the direcotries
is this needed? as far as I can tell, the implementation does nothing?: ``` try { if (lock != null) { <-- **lock is null** try { lock.release(); lock = null; } finally { clearLockHeld(path); } } } finally { IOUtils.close(channel); <-- channel is null channel = null; } ```
`new AtomicReference<>();` with the extra `<>`.
please wrap in {}
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
Missing the `indexName` argument to the debug log here
typo here "ot" -> "to"
I think this message is misleading - we don't actually schedule the delete of this index but rather ignore it. Maybe change to "failed to lock a dangling index [{}], probably in the process in being deleted, ignoring." . I also think we should include the exception as it may not be a LockObtainFailedException but something else.
`FutureUtils.cancel` has a check for a null future, no need to add this check
this is unneeded - we just iterate of the list...
> There are people in the team that prefer it this way rather than having a random timeout on the latch Then I guess I'm fine with it, it just made failing tests hang locally for me for quiet a while (I guess there are some hard timeouts after all).
lets revert this. We do not need it here
Is this needed? I think the observer takes care of this? If not, I can work on folding this into the observer as a follow up.
we typically wait indefinitely so if things get stuck we get a suite timeout + stack dump so we know where things got stuck
same - wdyt about a condition suffix/
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
Nice, I like the randomization on the thread pool.
I wonder if it should not also decrement the CountDownLatch if an exception is caught in the SimpleChannelUpstreamHandler ? Something like ``` new SimpleChannelUpstreamHandler() { @Override public void messageReceived(..) { ... latch.countDown(); } @Override public void exceptionCaught(...) { latch.countDown(); } ``` Just to be sure that the client does not hang indefintily.
Nit: Can we give this a more meaningful name instead of an abbreviation? I'm fine with `TestResponseHandler` for example.
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
last parameter can be set to from.
should we catch exceptions here to make sure we cancel everything we need
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
canceled -> cancelled
we need to remove this from onGoingRecoveries and only call cancel if it was found, otherwise we may leave a lingering recovery id, pointing at a cancelled recovery.
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
You could probably avoid this by making the linux check a method that you stub out in OsProbe.
method refs ftw
Can you add some randomization ? We run this method multiple times and then perform some checks on the generated query (serialization, correctness, ...).
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
maybe expectThrows would be easier.
oh cool the read is in the ctor! nice!
ok can we rename the getter then to `getFailedNodeExceptions()`
after is now minimum_age
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
Maybe this one too, I'm not sure.
Not 100% sure of the rules here, but `private` seems too restricted for this.
Does this question have an answer? I _think_ any failures are passed to the response handler.
We should assert that this is called (and I guess that we can say something about the response that is passed in).
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
Why is this `volatile`? It doesn't look necessary to me.
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
actually I just got a bit confused because both classes are in the same file...
this could be a for each loop instead
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
Not sure if we want this optimization, but we could always run these three requests in parallel, putting the responses in three `AtomicReference`s and using three `CountDownLatch`s to wait until all three complete.
I implemented the early cat APIs that way and @kimchy wanted to nest instead. If the cluster's busy then you only have one dangling request.
The `new HashSet<>()` can be replaced with `Collections.emptySet()` (and then you'll have an import to remove).
I see, yea we can't avoid this then. Maybe share the default value through a constant so at least we don't duplicate it. Odd! :)
this is odd especially because it seems that once you set a value for this field, you can never reset it to its original default value.
given that the request goes through validate first, I think we could remove this assertion, this is already checked in as part of validate which will throw an error otherwise.
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
no need for extra space
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
could be a instance variable, as used in all tests
please use `assumeFalse(Constants.WINDOWS);`
why a single data node? If you need that, you can use `numDataNodes=1` instead
Shouldn't this be using `ElasticsearchTestCase.randomFrom` instead of `com.carrotsearch.ant.tasks.junit4.dependencies.com.carrotsearch.randomizedtesting.generators.RandomPicks.randomFrom`? I don't want it to end up not using the right seed
and -> an
Also, since "recover" and "restore" are very similar and easy to confuse, I think it'd be nice if this were named "`recoverState`"
`Arrays.toString(paths)` already adds [] , no need to add them
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
can we do this `((Long)value).longValue())` no boxing needed here
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
Usually we'd stick this on the end of the last line.
This needs to handle the -1 case.
should say shard active
this can ne ThreadPool.Names.SAME, the handling is lightweight enough to not require forking to the unbounded generic TP
we need to check on the node version, and only call it on nodes that are version 1.3 and above, otherwise they won't have this API
the logic here should be only if _all_ nodes responded with the shards active we should continue with the deletion process..., same check we do on the cluster state if a shard can be deleted
can we call this ShardActiveResponseHandler? (and the derived family should be renamed as well)
I think we can share this line and the return new BulkItemRequest line? these two clauses will need to set a final `updateResponse` field.
can we call this primaryItemRequest? It's the one that's sent to the primary. Also, if we pass it as a `BulkItemRequest` parameter, we can avoid sending `requestIndex` and `BulkShardRequest` (from which need the concreteIndex, which I think we can from the shard). Last can we assert that the `BulkItemRequest` has as a request object the `updateRequest` we got? this is all super trappy but we can take one step at a time :)
nit: flip this to true? easier on the eyes
Throwing a RetryOnPrimaryException feels ugly. I see why you did it and I can't come up with something better. On top of that, this made me realize that RetryOnPrimaryException has serious problems. I'll reach out to discuss. to be clear - this shouldn't stop this PR as it is an existing situation.
too bad ..
please use Arrays.asList while we re here
can this be synchronized please
if just read metadata it will also be easier to implement a fetch all interfeces, sort interface name, fetch interface ip sequence
@dadoonet I think the log message can still say "Failed to fetch metadata from google" ? more than just client creation can go wrong here..
I also dont' think we should swallow the exceptions here? Someone asked for a gce address and we failed to get it...
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
Ah! Got it.
you don't have to assert on anything if an exception is expected
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
let's not make this hold this PR, but let's keep track of this potential issue and address the need for generifying in a separate issue
We shouldn't need to log if we through an exception. I don't like the hard cutover but I can live with it. If I discount the hard cutover my only thing is the exception message.
Do we really need to ignore the setting in post 2.0 indexes? Why not just support both for a while? You already check above that both aren't specified.
I _think_ we have a deprecation logger. We should probably log something when we see `position_offset_gap`.
We should tell the use to use `position_increment_gap` in this error message.
Users that have indexes created before 2.0 should not be precluded from using the new setting name. This looks like it _only_ allows using the old name with indexes before 2.0.
same note as in the json processor PR.
I don't know that we should fix this now, but I think failures of this test will miss the gradle reproduction steps, right? I've been thinking of pulling those into a tiny shared project without dependencies just so we don't have trouble with stuff like this but I haven't looked into it deeply enough to be sure.
Note that this is different than setting a single property as it adds the inputs to the list.
The method was not named as a setter in groovy so this could be DSL-like. ie, usage looks like (notice the lack of equals sign): ``` noticeTask { licensesDir 'foo' } ```
Is this really necessary? Seems like it will produce a lot of noise.
yea I think it would be good to have a test that makes sure that the index expression specified in remove_index resolves against indices only, rather than aliases and indices. I don't think the current test does that.
I think we can omit catching this and failing when caught, that's default behaviour, what matters if the `finally` I guess
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
I guess, are any of the other assertions necessary given that we are checking that source has not changed at all in this case (and no metadata was added).
Can we keep the line numbers in the test assertions? I think they are important to maintain.
fancy pants :)
can this be: ``` Java public static final Setting<URL> URL = new Setting<>("url", "http:", URL::new, false, Setting.Scope.CLUSTER); ... URL url = ...; if (URL.exits(settings) == false && REPOSITORIES_URL.exists(settings) == false) { throw new RepositoryException(name.name(), "missing url"); } ```
this can be: ``` Java public static final Setting<List<URIPattern>> ALLOWED_URLS_SETTING = Setting.listSetting("repositories.url.allowed_urls",Collections.emptyList(), URIPattern::new, false, Setting.Scope.CLUSTER); ```
++ to keep byteSizeSetting here
I don't think so, I think these should be bytes or size-value only.
yeah nevermind I was confused about some internal classes
operation can be `final`
nit: extra line
Throwing a RetryOnPrimaryException feels ugly. I see why you did it and I can't come up with something better. On top of that, this made me realize that RetryOnPrimaryException has serious problems. I'll reach out to discuss. to be clear - this shouldn't stop this PR as it is an existing situation.
same here, I think it will be easier to read with "shard state persisted despite of persist=false"
nice one. Good to add.
can we add some randomization here around the version - check that new has a higher version then old and vice versa
yep. missed it. sorry for the noise
Typo: `afllowed` -> `allowed`
Nit: `parallel` -> `concurrent`
I think 0 is a good minimum value.
I don't think so, I think these should be bytes or size-value only.
++ to keep byteSizeSetting here
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
I think this is a sign that `getActionFilters` maybe should take `ThreadPool` as an argument.
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
Whoops, you already did, ignore this!
cool. lets look at it on another issue.
typo, all flies -> files
Don't we need to throw the exceptions list here, like we do before: ``` ExceptionsHelper.rethrowAndSuppress(exceptions); ```
minor semantic difference: over [here](https://github.com/s1monw/elasticsearch/blob/fix_recovery_finalization/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java#L304) we throw the unwrapped corruption exception, not the remote version. I think we should do the same here and throw corruptIndexException
I think adding a constant somewhere for # makes sense. It may make sense to also add a constant for typed_keys, but I don't have a strong opinion on that.
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
Not sure this should be "Query" ð
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
I think this can be combined into LoadedPlugin, adding the ClassLoader there.
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
This is not the right condition, a plugin bin directory is not required to exist.
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
I think we can better call this in the Store.OnCloseListener.afterIndexClosed(). Feels cleaner to call this once we think all shards have bee removed.
Can this use `nodeEnvironment.shardPaths(shardId)` instead? Then it doesn't need to use `toPaths`
We should log the the failure here if the close fails
same here - I think it's better to log the info message if the deletion was successful.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
You could make it the same with an `else if` instead of `else`: ``` } else if (theAnalyzer != null) { builder.searchAnalyzer(theAnalyzer); } ```
As far as I can (brief check only) they are always null, but it wasn't part of the API to change properties that are not part of the json being parsed. Not a big deal..
so I think we need to somehow extend the `fuzzyPrefixLength` with the length of our context otherwise we will apply LD to the prefix as well? Also we need a test for this I guess
You can simplify this to: ``` boolean writeSearchAnalyzer = // logic if (writeSearchAnalyzer || analyzer logic) { // write analyzer } if (writeSearchAnalyzer) { // write search_analyzer } ``` This will also keep the same order (analyzer followed by search_analyzer) that we had before.
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
[{}] for path.
`Arrays.toString(paths)` already adds [] , no need to add them
This has to use the new settings API.
Since you don't care about the body of the source maybe use something like `setSource("foo", "bar")`.
`assertNoFailures` is more common in newer tests and much shorter.
I like `hasSize(1)` for this kind of thing because it makes a nicer error message.
You can skip these two and just create the index. It ought to just automatically create.
if you use here `refresh();` from the base class we also make sure we get back no failures.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
you should pass fieldNames as an argument
Shouldn't this be using `ElasticsearchTestCase.randomFrom` instead of `com.carrotsearch.ant.tasks.junit4.dependencies.com.carrotsearch.randomizedtesting.generators.RandomPicks.randomFrom`? I don't want it to end up not using the right seed
Oh I see it below, makes sense, `wrapper` just sounds like a noun instead of a flag
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
Why is this `volatile`? It doesn't look necessary to me.
please log the exception here as well we really wanna see what was going wrong
this keeps bugging me :) we should something on the executor as well....
ahh yeah in `assertAfterTest()` nevermind
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
underscore case? :)
for master you don't need to specify the gateway.type we only have what used to be local!
try to use `AbstractRestResponseActionListener` instead of `ActionListener` the `onFailure` method is already implemented there
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
I think we could check that successful == total shards and that total shards is greater than zero
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
excude_interim - missing 'l' -> exclude_interim
Misspelled in the \@param tag also
nit: space after the second percent sign (on all these lines)
Just a note here. We decided that by convention we will use the same naming as maven. `groupId` has now changed to `org.elasticsearch.distribution.[packaging]` so I think we should also reflect that change here and use `org/elasticsearch/distribution/[packaging]` where `packaging` is: - rpm - deb - zip - tar
For all of these find calls, you can use `in` operator instead: if '(On branch %s' % branchName) not in s:
last `%version` should be `%major_minor_version`
last `%version` should be `%major_minor_version`
`.addPathPartAsIs("_xpack", "rollup", "job")`
`fielddata` is the preferred name as of my merging #28943 today.
Can you update the `\rest-api-spec\src\main\resources\rest-api-spec\api\indices.clear_cache.json` as well? ( do we need to specify all supported params, or only the preferred ones. There is also a `recycler` flag in the rest specs which I do not see in the code )
we also support a parameter called `updateAllTypes` here.
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
I'm fairly sure I have the wrong generics incantation there....
We might should move these last two declarations to a common spot something like ``` static <T extends AbstractObjectParser<? extends QueryBuilder>> declareStandardFields(T parser) { parser.declareFloat((builder, value) -> builder.boost(value), AbstractQueryBuilder.BOOST_FIELD); parser.declareString((builder, value) -> builder.queryName(value), AbstractQueryBuilder.NAME_FIELD); return parser; } ``` and then we can declare them when we're initializing the object.
I might use an empty array here or switch the IdsQueryBuilder work with lists.
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
+1 to capture `System.nanoTime()` at the beginning of the method
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
Ah nevermind, I see where we check it above :)
otherwise, if you want it for testing, it can be done once in the ctor
Helper method is no longer needed now that `Logger.debug` exists.
This test should assert that the headers are correct.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
this keeps bugging me :) we should something on the executor as well....
Can we explicitly set the blocks here? Advantage is that - no need for TribeService to depend on DiscoveryService - no need for newly introduced method `removeInitialStateBlock(int id)` as we know exactly which blocks we previously applied. Even better would be to also set the STATE_NOT_RECOVERED_BLOCK block for GatewayService here. We could then not set these blocks in the first place if `tribeService.getNodes().isEmpty() == false`.
this is super ugly I think `AsyncShardFetch.Started` and `AsyncShardFetch.Store` should be an impl detail of `GatewayAllocator` no need to bind this or anything
that sucks, sorry :) We can't build stuff that is dependent on the order of how the listeners are added! Can we find a better way of doing this? I think each listener needs to have priority or so and every prioritoy can only be added once? Maybe we don't need this to be a list at all? This stuff is so fragile we have to iterate until it's safe
for instance in RestoreService we use `addLast` at runtime which messes with this assumption, that entire order thing is broken and error prone. The best thing I can come up with so far is to add defined stage like this: ``` Java enum ApplyStage { NewClusterState, NodesConnected, StateRecovered, ShardsStarted, RepositoriesCreated, NodesDisconnected; } ``` where listeners can be registered but I am not too happy about it...
I think it's fine to add such a method to NoCacheFilter
lets turn this into a constructor that takes these 3 values and make them final in the class. Then you can just remove all of the extra validation stuff and the `addValidationError` below.
This is similar to the internal implementation, nice
I think an absurdly high limit could still be helpful? (in a follow-up PR)
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
we may have a small problem here, when toXContent is called on an object deserialized from a previous version that didn't send the _id .
Does this message go back to the end user? If so the fact that a map must be empty is more of an implementation detail than an meaningful error message for the end user. Something like "Mapping definition for field X has unsupported parameters: foo, bar" would be more appropriate.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
Please rework this word wrap too.
Let's replace the `assertTrue` by more effective matchers, and replace the `assertEquals` by `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
Can you rewrite these to use `assertThat(..., equalTo(...))`. I prefer this form because it's clearer which is the expectation and which is the value under test whereas with `assertEquals` it often gets confused.
This is another case where I would use a more effective matcher.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
Is the version needed? I don't see it being read here.
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
Nit: too many newlines here
use `terminate(threadPool);` (this method is in ESTestCase)
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
Hurray no more weird `while (true)` loop
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
Typo, "Trasnlog" -> "Translog"
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
Minor typo of `local` instead of `locale` in the exception message.
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
I would be using a `Set` in this circumstances.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
maybe make if final
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
maybe also test a nested conditional setup? (So have conditional and then another conditional in the matched or unmatched list)
Why not public? Will make reflection faster for guice.
We need to think about optimizing here for the most common case. Which is a single alias. In this case, we don't really need to allocate a list. Might be an overkill, but stil.. :)
We can leave `API` out of the test name.
This can be final. This makes it easier to immediately see what is and is not immutable.
can you add more rolling while adding? Also *sometimes* increment the primary term
Note that you want to make sure that you test the difference between the terms in the ops and the terms in the files. These are not the same.
this could be static
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I think the OOM reference was a copy paste error from another clause. This clause doesn't do `translog.newTransientTranslog(translogId);` so no need to revert it - although it seems to do no harm if there is no current transient translog.
I think this missed a misses a maybeFailEngine
also applies to other places in the code below, if we decide to do it.
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
++ thanks for adding these checks
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
yeah that is what I figured!
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
fielddata format can still contain arbitrary values: ``` PUT testidx { "mappings": { "doc": { "properties": { "user": { "type": "string", "fielddata": { "format": "fst", "blah": "blub" } } } } } } ``` I am however not sure what is expected here because when I get the mapping the wrong entry will be returned...
nit: missing a space after the first comma
waitForyellow can go away...
nit pick - can we start with node1 and relocate to node2 ? :)
just FYI - you can do setSettings("index.number_of_replicas", 0)
I guess it's because the async shard fetch logic - the shards are not assigned when the call returns.
can we remove this try catch? let the original exception just bubble up...
I wonder about the cases where this can happen as the `close` method on `InternalTestCluster` that calls `shutdown` on the executor is synchronized (same as this method). Have you observed this exception being thrown? If we don't expect this to occur under normal operations, I would prefer not to swallow the exception here.
space missing between ) and {
We discussed this on another channel, and decided to only do the auto-bootstrapping when autoManageMinMaster mode is active. We also decided to have multiple nodes participate in / run the bootstrapping process.
not sure if this should be pretty printed as we put in the exception message. we'll have to see an example to be sure. Alternatively we can log a warning line like we do in ensure green. Also, you can consider using Strings.toString().
only the `#start()` call should be concurrent. The publish should be done in a sync manner and the `NodeAndClient buildNode = buildNode(settings, version);` should be done before in a sync manner. This is important since we want the same setup no matter of how threads are scheduled and `NodeAndClient buildNode = buildNode(settings, version);` uses random internally
given that the request goes through validate first, I think we could remove this assertion, this is already checked in as part of validate which will throw an error otherwise.
is it necessary to mock the rescorer builder, seems like an easy object to create manually, unless I am missing something. In general, I tend to use mockito only as a last-resort, when things are really hard to reconstruct, that's why I'm asking.
why this opening bracket here and the closing one in line 186? Apart from that LGTM
good point, I think it's ok if it is configurable. and then it should do by default the same as the rest of the same search request does.
I find it odd that we modify the original source builder with the resolved indices names and replace what we originally had. Would it be possible to transport the resolved indices differently? I think we should serialize this new info separately and carefully handle bw compatibility around that.
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Recently we've been doing something more like this: ``` clearIndicesCacheRequest.queryCache(request.paramAsBoolean("query", clearIndicesCacheRequest.queryCache())); clearIndicesCacheRequest.requestCache(request.paramAsBoolean("request", clearIndicesCacheRequest.requestCache())); ... ``` Rather than the loop. The whole loop thing is more appropriate for by-hand xcontent parsing then url parsing.
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
I don't think we either but I know some folks like them so I certainly don't object to them.
And it looks like you cover the response below. So you can ignore this.
I wonder if it'd be nice to have the assertion in the docs with a note about how this is the response. And maybe a note that you don't have to assert anything if you don't care whether or not it was created up updated because non-200s throw exceptions.
I believe this text is out of date now that we have a macro.
yes please I haven't seen them used before in our codebase. At some point we will automate formatting and these classes will have to somehow be ignored I think.
Change this to `// tag:example[]`
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
right I had missed that previous check, sounds good then
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
Maybe point out that this is actually the place where we modify the valid input query by adding a new object level to it.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
Nit: `}` is in a funny place.
Also, we will need the oposite conversion from the ES enums (e.g. TermSuggestionBuilder.SuggestMode) to the Lucene enums (org.apache.lucene.search.spell.SuggestMode) used in the DirectSpellcheckerSettings later anyway, so rather than having `fromUnderlying` better turn the direction around to each enum knows how to produce the corresponding low-level enum.
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
`this` is unnecessary
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Yeah, I think the problem with the test here is that we don't make sure that nothing is left in the stream after we read it. That's why we didn't catch it here.
We will need stronger assertions here too.
Do we really need this randomization? seems like the wrong place to test the version created setting is working properly.
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Remove and create again is not needed I think
should it be `final` ? seems to be a const semantics
don't drink and code ð» (same line twice)
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
++ to this pattern
Another `_` java 9 will be mad at
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
I think java 9 is going to choke on `_` here, if I recall correctly
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
is this needed here? I think it does something only when the current token is start array or start object.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
now I see what you meant yesterday saying that we have to parse meta here
Do we need this on this one? It seems like these test suites are very small and any of them taking 40 minutes is grounds for making someone look at the VM at a minimum.
this is fine for now, but I'd rather have more runs on CI than spreading these repeats all over the place. We are most likely going to forget about them, already too many things we have to watch out for in this branch.
remove the iterations please
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
I don't know that we should fix this now, but I think failures of this test will miss the gradle reproduction steps, right? I've been thinking of pulling those into a tiny shared project without dependencies just so we don't have trouble with stuff like this but I haven't looked into it deeply enough to be sure.
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
we shouldn't need this here in parse phase
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
we can do this in a more optimize manner. We can create a builder, and then use `copyCurrentStructure` on the builder (passing it a parser), to just copy it over, compared with parsing into a map and then serializing the map. Also, since its internal, I would use smile builder, as its considerably more efficient than json.
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
This seems quite sneaky that you modify the lists returned by `getGetMethods()` and `getGetReturns()`. Additionally, I'm not sure how it actually works since you increment `get`, but then but remove, so the size is changing. Can you instead create a copy of the lists in SSource ctor and use those local versions? I think you could then just create the lists on SSource only containing variables contained in `reserved.getUsedVariables()`? Then just iterate the member lists here to add to the `mainMethod`.
This should do an unsigned comparison: ``` java int a = left[i] & 0xFF; int b = right[i] & 0xFF; ```
_value is only for agg scripts, we shouldn't have it for anything else
just because it seems like it's used only internally, that's it. No strong opinions though ;)
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
can we wrap this long line
Also, we will need the oposite conversion from the ES enums (e.g. TermSuggestionBuilder.SuggestMode) to the Lucene enums (org.apache.lucene.search.spell.SuggestMode) used in the DirectSpellcheckerSettings later anyway, so rather than having `fromUnderlying` better turn the direction around to each enum knows how to produce the corresponding low-level enum.
where is this method used? I can't find it
guava has a `Iterables.elementsEqual()` - which works slightly different, maybe your implementation is a bit faster
lower cased now...
I _think_ you could just pull the `PositionLengthAttribute` and if it has a value greater than 1 on any token, it is a graph.
> Ok this doesn't work because the standard synonym token filter also sets the position length attribute Arrrrgh, you are right. Here's maybe another idea: why not always treat things as if they were a graph,since a single linear chain of tokens really is just a graph. And then, when the graph enumerates to just one path, it should naturally "become" what already happens today? I.e. don't break out any special treatment for "graph" vs "not graph".
it will also give a chance to the AssertingIndexSearcher to perform additional checks
you can use `getRandom().nextBytes(bytes)` here
Can you fix the indentation
I mean random number of replicas with random combination of non-active states
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
This is true. The alternative way I was thinking about would be to pull a terms enum from the sorted set doc values, and set bits in the bit set based on the hash of the values rather than their ordinal. This way, the partitioning would be based on the value but the terms aggregation would still be able to leverage ordinals to do the bucketing. The drawback is that it requires to compute a hash on every term of the field.
+1 for the terms enum pulled from the sorted set. It should be fast to enumerate the terms since it is a sequential reads in the term dict of each segment. The hashing will be slow though, but again it's great if we can have a way to exhaust a term aggregations consistently even if it's not as fast as we would like ;).
you need a long, or this could overflow. Or even not store it at all, and use `termsEnum.ord()` to know the ord of the current term
I would use `Math.floorMod(term.hashCode(), incNumPartitions)` to avoid issues in the case that the hashcode is `Integer.MIN_VALUE`
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
maybe we should have a constant for it
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
alright that's what I thought too, sounds good
new is not possible with an older version...
I don't think this test is needed. `testSpanMultiTermQuery` does the same thing.
nit: missing space
can you please inline this while [adding docs](https://github.com/elastic/elasticsearch/pull/30176/files#diff-ed6e20d0c4d03d97ae9b7a9a33190c4bR1532)? We need to have more roll overs randomly
I tend to prefer letting the test throw the ClassCastException rather than asserting this first.
This should check `isSecurityEnabled`. The other methods like isAuthAllowed do not take into account the default distribution behavior where security is disabled with a new trial license unless it is explicitly enabled.
Is it intentional that this is looking only at `isAuthAllowed` and not `isSecurityEnabled` ? The implementation here will disable the cache for trial licenses even if they have not enabled security.
nit: I'd prefer that we move the sendRequest call to the try block and remove the return from the catch block
I don't think we need this branch anymore.
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
the processor ids have no meaning on our side and are completely meta. So its fine. It is more of tag then it is an id, so others that are integrating with ingest.
Should we keep in incrementing even for cases where we find the id? or only increment for cases when the id is not provided? I am not sure myself, just wondering, maybe not that important either at the moment.
also, at the moment we don't check for ids uniqueness, which is probably fine given what we need ids for, just double checking that we don't rely on uniqueness anywhere
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
make the error a bit more understandable for users? Like "processor x doesn't support some of the provided configuration parameters" and list them like you do already...
This exception will be treated as ignore replica exception. :wink:
I think this check is wrong. When we have relocation going on and relocation source is marked as relocated (i.e. we call executeRemotely in TransportReplicationAction), then we have primary relocation target replicating back to primary relocation source (see also ReplicationPhase).
typo I guess `s/chanHaveDuplicates/canHaveDuplicates/`
simpler to write `(origin == Origin.PRIMARY) == (versionType != null)`
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
minor nit: "for" -> "on"
I don't get this part why do you change the way we read the `TranslogStats` here? can't this just be ``` Java translog = in.readOptionalStreamable(new TranslogStats()); suggest = new SuggestStats(); if (in.getVersion().onOrAfter(Version.V_1_2_0)) { suggest = in.readOptionalStreamable(suggest); } ```
and do that in all other classes we do this for serialization in this pull request.
maybe we should be more explicit and initialize indexBoost in an else branch here, rather than above when declaring it. I think de-serialization is the only scenario when it may not get assigned.
I'd probably add an `else` clause that sets `splitOnWhitespace` to the appropriate value just to be super clear.
remove the setBoost
remove the set boost
you can remove randomization of boost and queryName
:) good catch
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
`com.sun.glass.ui.Size` appears to be unused.
Nitpicking - unused imports were added to this and other IndexActions.
We had to choose a shared prefix in order for there to be a consistent way to detect types deprecation messages in REST tests (and ignore them). I think @jdconrad is just using this prefix here for consistency.
I like the fact that any `AbstractBigArray` can use differently typed pages! that's pretty cool though!
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
I'd supply a lambda, yeah.
nit: space before RESPONSES
ok can we rename the getter then to `getFailedNodeExceptions()`
clusterName is not needed here.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
To avoid this getting out-of-sync in the future, it would be nice to use `PARENT_TYPE_FIELD.getPreferredName()` instead of hard-coding `parent_type`. The same idea applies to `query` below.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
good catch! that means we are not properly testing this case either given that we didn't catch it.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
I liked the assertion you had there that if already have a result, this one has a higher seq no
`seqno` -> `_seq_no`
Nit: `primary term` -> `_primary_term`
I wonder if we need this - we could assign the `NOT_FOUND` in the beginning of this method and then assign `currentDocFreq` as well as `currentTotalTermFreq` each time we update their local corresponding variables ie. as the last statement in the `for (Holder anEnum : enums)` loop. Same is true for the `text` and that way we can just trash everything below the for loop and return `found` I also think it's ok to just use `-1` as `NOT_FOUND`
I think the message here should 1. be a static final constant and 2. say what this TermsEnum allows ie.: `"This TermsEnum only supports #seekExact(BytesRef) as well as #docFreq() and #totalTermFreq()"`
I think this assumption is pretty broken. What if the type is `null`? We don't define any order in the types when they are specified in the URL but this code assume that there is an order. I think we have to make this explicit which type should be used.
you can remove the validate call for now, we will fix all queries soon, I promise
of course how could I forget about this, I pushed it 30 mins ago :)
if it doesn't have clauses we don't set the boost and ignore the queryName. I think it would be a bit more readable if we had two if branches, and the set boost and named query handling after the if which kicks in in both cases.
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
this could lead to NPE if from the java api no set call is performed
it's fine, when I did the refactoring SpanQueryBuilder became an abstract class without any problem, but now it needs to be a marker interface again cause java doesn't support multiple inheritance ;) We just need a cast, sorry for the noise I had missed this change to be honest but now I get it, thanks a lot for digging!
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
alright that's what I thought too, sounds good
clarify the error message specifying what needs to be non null? the inner query...also remove empty, doesnt make sense here
Can we return 0 when the value count is 0 to be consistent with the singe-value case, or throw a proper exception? I am concerned this code could raise a weird error message otherwise.
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
ideally, you should read directly into `scrach.bytes` instead of allocating a `byte[]`
We can save object creations here by making the ByteArrayDataInput final and using `ByteArrayDataInput.reset`.
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
and randomly append '/' at the end
I might make something like ``` private void expectMissingBodyError(Matcher<String> responseMatcher, ThrowingRunnable exec) { ResponseException responseException = expectThrows(ResponseException.class, exec); assertEquals(400, responseException.getResponse().getStatusLine().getStatusCode()); assertThat(responseException.getMessage(), responseMatcher); }
s/y ou/you Also I think upfront is one word.
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
I am not sure whether the log message is too specific, i.e. the subclass must not necessarily be a service.
how about `onGet` as a name instead of primer
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
how about `onReset` instead of `finalizer`? `finalizer` makes me think of garbage collection
I think this should take an `OperationMode` to push the conversion into the caller, rather than doing it in the constructor (it seems cleaner to me that way). This is just my personal preference though, so up to you if you want to change it.
If it is relevant for String impls then I don't see why it should not also apply in the long impl.
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
mention here too that this is what we do also in the corresponding builder
I am wondering if it makes sense to implement `getProperty()` for `Aggregations` as well and not just for `Aggregation`. For example in a test I would write something like ``` Aggregations agg = searchResponse.getAggregations(); Object o =agg.get("aggname").getProperty("path"); ``` but if Aggregations also implemented getProperty() I would save another line and it is needed anyway here internally.
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
I mean in the code but just noticed there was one already
Usually we'd stick this on the end of the last line.
nit:`maxEdits` instead of `max_edits`
That might make sense though my preference is to handle this corner cases leniently. I was a bit confused by `UNKNOWN`, I would argue an empty list has `FALSE` nullability (it can never be null) but then again maybe it's something that's worth having a check.
nit: `maxInspections must be positive`
same here: no need for the [].
index's toString gives you '[index_name]' no need for '[{}]'
Left over Note
same here - I think it's better to log the info message if the deletion was successful.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
I think we can now remove this condition as the client can not be null because we throw now `new ElasticsearchException("Unable to configure Azure compute service", e);` in the CTOR
``` java || this.secondariesStorageSettings.isEmpty() ``` :crying_cat_face:
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
Remove and create again is not needed I think
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
I think it would have been worth it but now that you mention it - other requests may have changed this in the mean time too, so let's leave this assertion.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
if it was always local it should all be taken care of by the put mapping api (retries etc). That said, this is also remote and I was mistaken. Sorry for the noise.
You are already in `ESRestTestCase` so you don't need the to reference the class.
This seems a bit broad.
Here we lose the option to fail if an expected warning didn't materialise. Is that OK? Its conceivable some tests can be certain in their expectations of failure and we do need a way to fail when we fail to fail (so to speak).
Missing `assertAcked()` or call to .get()
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
nit: when the method is complex (there are 5 different arguments here), I find that explicitly implementing the interface is easier to read than lambdas
And we could then just leave an assert here.
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
maybe add the type that is found in the error message with fieldType.typeName()
+1 then we shouldn't forget about it :)
can we just `return new BytesRef()` in this case? I don't know if the text characters are null if we can really rely on text offset and length? Maybe a better check, not relying on null check is: ``` if (parser.getTextLength() == 0) { return new BytesRef(); } ```
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
you don't have to assert on anything if an exception is expected
I notice this pattern in every implementation. Perhaps this should be a Map instead of Collection (keyed by the custom type name)? Then the map can be copied, and keys replaced, removed, or added easily, without needing to have logic for the other custom metadata that the plugin does not care about.
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
Ah yeah I suppose that might be ok, in this case it's user-defined input so that's pretty awkward but it beats breaking.
should this be "not mounting...consistently" or "mounting...inconsistently"? But I would think not the current double negative.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
Can we move these up at the top of the class with the other object variable declarations? I think it is more readable than having them 300 lines down into the class.
> If we felt like testing fromXContent without SearchModule we could implement a super easy mock implementation That we can easily do with a little registry too I think? fromXContent won't depend on SearchModule anyway, that is the point of having a separate registry for only the pieces that fromXContent needs (registered score functions). In the end there isn't a huge difference between the two solutions. there is and will be a lookup method somewhere, but instead of being a method reference as argument, it will be an explicit registry. I find it more readable this way, but I do get how this is just a matter of opinions.
the lookupScoreFunctionParser method allows to use SearchModule as the registry using method references. So effectively we need and already have a registry, but this solution saves us one class as we don't have a separate registry class for score functions.
I have a question: what is wrong with java classes in their own .java file? :) Along with IndicesQUeriesregistry I would call this ScoreFunctionsRegistry probably.
The previous builder also supported "multiMatch". I'm late to the party, but this is one problem I see in removing the alternative `names()` method from the builders, it moves the parser names (and alternatives) far away from the builders themselves. I guess this move is part of makign QueryParse a functional interface, but couldn't we leave the `names()` method and use it even though it will not be part of the QueryParser() interface? Or add it to AbstractQueryBuilder instead? Having all these string constants here in this class without a connection to their builder is a source of errors IMHO.
Having all the query names ony here in `SearchModule` also makes it hard to test them for accidental changes. We are not doing that yet, but I think we should, and for that they should stay in their respective classes.
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
> I think we're talking about two different sets of leniency :) ++ :smile:
The worst is how `on` and `no` both parse to legitimate values, very dangerous for transposing typos.
I don't like leniency. Can it be `"true"`, `"false"` or `null` with the former parsing to the right `boolean` and null giving the default? A typo of `"tru"` will parse to `false` and that makes me :cry:.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
We can save object creations here by making the ByteArrayDataInput final and using `ByteArrayDataInput.reset`.
ideally, you should read directly into `scrach.bytes` instead of allocating a `byte[]`
I think you also need to implement `getOrder()` here in order to return `AtomicFieldData.Order.NONE`.
does this work? it works for percentiles, but with percentiles rank it's reversed
Yeah, I checked https://github.com/torvalds/linux/blob/9705596d08ac87c18aee32cc97f2783b7d14624e/include/uapi/asm-generic/unistd.h and they all look right to me.
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
gotcha, thanks for explaining.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
Ah yes, thanks!
Can we call this just `score`? I've been trying to give the script context identifiers names that don't include "script" since that is implicit.
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
did you plan to add here the list of nodes or something? looks like there is a missing argument.
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
thinking out loud, maybe I am getting confused, but in order for a field to get highlighted, doesn't it need to be stored too or we need to have the _source at least? but metadata fields, which match `*` are not part of the `_source` hence they need to be stored or excluded from highlighting by definition. I have the feeling we should do something more to address that...
debug or info? I would be more for debug
the == false is done on purpose to make these comparisons more explicit
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
can we add an assert to make sure that highlighterType != null here? it really should since we know that plain highlighter always returns true, but the assert would make it more explicit that it is expected
More indentation that is hard for me to read.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
I don't think the compile script should be stashed here. Instead, just check that the script can be resolved with the script service (don't just check inline; for example, it would then also ensure if they use a file script it exists).
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
I think s/lang/defaultLang/
I like this much better!
Fine by me.
same here, just `this.charFilters.add(new NameOrDefinition(charFilter));`
+1 much better than the while loops in the rest action
this new exception is going to trigger errors too if we try to serialize it to an older node
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
Fine by me.
this can only be a runtime exception you can just bubble it up no need to use `convertToRuntime`
should we implement SearchContext.toString? This way it would also be easier to look at SearchContext objects when debugging
I think it is fine: we only build one search context per request per shard.
can you just leave the constant in this class? There isn't a need to put it in realm imo
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
Nit: please add spaces after the `if` and before the `{`.
Nit: please add spaces after the `for` and before the `{`.
Nit: please add a space before the `,` separating the function arguments.
@return needs to go into new line..
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
I think we should move this above the nodeChannels.close() so it will be logged before an eventual consequence.
nit: let's just log the index here (so we get the uuid and such with Nik's latest change)
the generic thread pull should never reject, unless it's shut down. that's it's semantics. I would also vote for a trace log in the raiseNodeDisconnected, but that's another change :) It's just confusing imo if you shut down a cluster and see these messages.
I think we lost this debug message. I think it's fine to log once in both the shard failed and shard started cases.
We should log the the failure here if the close fails
is this always used in an assertBusy context? wonder if we should add it here. This can be suprising...
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
you can just use a glob here ie: ``` blobNamePrefix = blobNamePrefix == null ? "" : blobNamePrefix; try (DirectoryStream<Path> stream = Files.newDirectoryStream(path, blobNamePrefix + "*") { //.... } ```
maybe not appropriate here, but we can do this with one underlying read of metadata via Files.readAttributes (you then have isRegularFile() and size() available from BasicFileAttributes)
typo: optain -> obtain
Construction now loses the side effect of a `NullPointerException` when this class is misused by giving `null` values for everything except `sourcePath`, which could lead to new, unexpected `NullPointerException`s upon use.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
I don't know what you mean by "consider qualifier in the build". There should be no attempt to test bwc of any qualified version, so I don't believe the build needs to know about it in our build Version, since that class is all about which versions we bwc test against.
> we still want to use an beta over an alpha There shouldn't be anything needing to choose a beta over an alpha? There should be nothing using any qualified build to check bwc.
can we maybe try to trigger this differently? I mean can we for instance try to call `#available()` or can we maybe read the first byte on open and wrap in a `BufferedInputStream` and then do this: ```Java InputStream stream = is.isMarkSupported() ? is : new BufferedInputStream(is); // do the following in doPrivileged? stream.mark(1); stream.skip(1); stream.reset(); return stream; ```
if we run into an exception here we have to close the stream. we usually do this: ```Java boolean success = false; try { // do something with the stream success = true; return stream; } finally { if (success == false) { IOUtils.closeWhileHandlingException(stream); } }
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
I don't think that a security exception should be re-thrown as an `IOException`.
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
Nit: " . " -> ". "
Typo: "temporary" -> "temporarily"
The `<=` will need to be escaped.
Maybe just clear a range of bits with `FixedBitSet#(int, int)` instead of clearing bit by bit? The implementation looks to be more efficient and would just require care around the offset wrapping.
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Ahh, sorry. You are 100% correct.
Sorry, I overlooked the null check. This is good!
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
I think you can just initialize to null
Nit: I think you can remove the itemSupplier and call builder.build() instead later.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
is this needed here? I think it does something only when the current token is start array or start object.
use simpler constructor.
I think this is easier to understand as it makes a 1-1 copy of the current active shard allocations in the routing table: ``` for (IndexShardRoutingTable shardRoutings : indexRoutingTable) { Set<AllocationId> activeShards = shardRoutings.activeShards().stream() .map(shardRouting -> shardRouting.allocationId()) .filter(allocationId -> allocationId != null) .collect(Collectors.toSet()); if (activeShards.isEmpty() == false && activeShards.equals(indexMetaData.getActiveShards(shardRoutings.shardId().id())) == false) { // only update active allocation ids if there is an active shard if (indexMetaDataBuilder == null) { indexMetaDataBuilder = IndexMetaData.builder(indexMetaData); } indexMetaDataBuilder.setActiveAllocations(shardRoutings.shardId().id(), activeShards); } } ```
new is not possible with an older version...
ah - now I see what you did it :)
can we sometime just rely on the wrong allocation id? (and have a valid node)
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
err I guess you need to have failures added first so second...
I'd feel better if the `latch.countDown()` would be the first line in the catch block
maybe just `return blobMetaData.length() == fileInfo.length();`
no file? maybe IOException
I'd also like a test for the case that either a single bound or none of the bounds are specified (even if that means checking that an exception is thrown depending on the decision we make).
rather use `logger.debug` than `System.out`
Should we also have tests for the case that some intermediate mappers already exist? For instance above you are testing to index a field called `foo.bar.baz`, so it would be interesting to check that everything also works if `foo` already exists.
one too many new line? :)
What happens if `enabled` isn't set? I *think* we should continue to do nothing if `enabled` is actually true.
would it make sense to add this nice iterator to core? the ingest plugin could reuse it in this case.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
I think this is expected to be a sorted list on the `job_id`.
Could initialize this with the size of the hits list to prevent resizing
pageParams is missing from the equality check
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
Ah ok, I missing that method below, sorry.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
I'm okay with the UnsupportedOperationException for now if we can track this question (whether we can reach consistency between the functionality the transport client provides via the SignificantTerms.Bucket interface with the rest response) in a separate issue
I think this should throw IAE if you pass null - that's 100% of the time a bug
fyi, I removed the ZeroTermsQuery class from MatchQueryBuilder entirely in #13402, moved everything plus serialization to #13402, so we might remove this setter and only have one.
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
good catch! that means we are not properly testing this case either given that we didn't catch it.
s/to list of/to the list of/
Oh, that error handling!
let's keep as is, with the assertion message I think it's ok. I wonder if we should have an assertion at the end of this method to say something like "if we have an active primary shard that's not relocating, then the replication tracker is in primary mode".
fyi - this gives you double [[]]
ah - now I see what you did it :)
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
ok can we rename the getter then to `getFailedNodeExceptions()`
We should make TaskInfo final then.
Er, probably not. But a bit confusing name because it looks like a typo.
can we please unpack the tuple right away instead of using v1 v2? just easier to read
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
Another `_` java 9 will be mad at
This is logic that I think should go into ReplicatedOperation.
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
never mind, I saw them later on
shall we test POSITIVE_INFINITY too? seems like we return null for that too but the default value once parsed is only one...
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
I don't think you need @Before here, the parent method already has it.
This assumes a version format that while fairly standard is not guaranteed.
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
Sure, good plan.
On deeper thought, this seems unduly lenient: it should only return credentials for the role that `GET /latest/meta-data/iam/security-credentials/` returned, and should return 404 otherwise. Also I think `credentialResponseFunction` can be inlined, it's only used in one place. Also also we could prevent cheating slightly more by inventing random credentials when the service starts up, rather than synthesising them from the role name.
you could use `scriptRequest.setJsonEntity`
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
now I see what you meant yesterday saying that we have to parse meta here
Oh I see, it's the ZTable stuff. Sorry for the noise :)
I think this method is not quite right yet. A few observations: - if (unassigned) primary, then finalExplanation / finalDecision should be influenced by staleness of copy. In case of a replica, however, staleness does not influence allocation decision. - if replica, then we can still show that store copy is corrupt / has an io / error without influencing final decision / explanation - for the primary / replica shard allocator, corrupt / io_error is treated as no data. I think we can first calculate store copy (which just represents the status on disk) and then influence finalExpl / finalDecision based on that. Here is my go at it: ``` public static NodeExplanation calculateNodeExplanation(ShardRouting shard, DiscoveryNode node, Decision nodeDecision, Float nodeWeight, IndicesShardStoresResponse.StoreStatus storeStatus, String assignedNodeId, Set<String> activeAllocationIds) { final StoreCopy storeCopy; if (storeStatus == null) { // No copies of the data storeCopy = StoreCopy.NONE; } else { final Throwable storeErr = storeStatus.getStoreException(); if (storeErr != null) { if (ExceptionsHelper.unwrapCause(storeErr) instanceof CorruptIndexException) { storeCopy = StoreCopy.CORRUPT; } else { storeCopy = StoreCopy.IO_ERROR; } } else if (activeAllocationIds.isEmpty()) { // The ids are only empty if dealing with a legacy index // TODO: fetch the shard state versions and display here? storeCopy = StoreCopy.UNKNOWN; } else if (activeAllocationIds.contains(storeStatus.getAllocationId())) { storeCopy = StoreCopy.AVAILABLE; } else { // Otherwise, this is a stale copy of the data (allocation ids don't match) storeCopy = StoreCopy.STALE; } } final FinalDecision finalDecision; final String finalExplanation; if (node.getId().equals(assignedNodeId)) { finalDecision = FinalDecision.ALREADY_ASSIGNED; finalExplanation = "the shard is already assigned to this node"; } else if (shard.primary() && shard.unassigned() && storeCopy == StoreCopy.STALE) { finalExplanation = "the copy of the shard is stale, allocation ids do not match"; finalDecision = FinalDecision.NO; } else { if (nodeDecision.type() == Decision.Type.NO) { finalDecision = FinalDecision.NO; finalExplanation = "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision"; } else { finalDecision = FinalDecision.YES; if (storeCopy == StoreCopy.AVAILABLE) { finalExplanation = "the shard can be assigned and the node contains a valid copy of the shard data"; } else { finalExplanation = "the shard can be assigned"; } } } return new NodeExplanation(node, nodeDecision, nodeWeight, storeStatus, finalDecision, finalExplanation, storeCopy); } ```
I think this should explain why shard fetching is preventing allocation (otherwise this message will be too cryptic for the user). For primary shards it is to determine which nodes have a non-stale copy of the data. For replica shards it is to determine which nodes have a copy of the data and which copy shares the most data with the primary to speed up recovery.
Looking at the overall code of `calculateNodeExplanation` again, I think we should also improve the message in case where the shard can be assigned but we have throttling. Can be a follow-up.
btw I've also had my confusions with this `processExistingRecoveries` method before ;-) At some point you don't even look at method names anymore, you just expect the code to be in that place.. :-)
We should take allocatedPostIndexCreate into account here (see PrimaryShardAllocator / ReplicaShardAllocator), i.e. ``` if (shard.unassigned() && shard.allocatedPostIndexCreate(indexMetaData) && hasPendingAsyncFetch) { ``` For replica shards (`ReplicaShardAllocator`) it's even a little bit more complex. Shard fetching is only relevant if not all deciders say YES (i.e. throttling leads to shard store data not being fetched) . We should thus include the condition `nodeDecision.type() != Decision.Type.YES` for replica shards to be exact. ``` if (shard.primary() == false && shard.unassigned() && shard.allocatedPostIndexCreate(indexMetaData) && nodeDecision.type() != Decision.Type.YES) { finalExplanation = "the shard cannot be assigned because allocation deciders say " + nodeDecision.type.name(); finalDecision = ClusterAllocationExplanation.FinalDecision.NO } else if (shard.unassigned() && shard.allocatedPostIndexCreate(indexMetaData) && hasPendingAsyncFetch) { ... shard fetching } ```
oh oh I hadn't read your reply when I replied ;)
can `aliases` be final as well
Might be better to use the default of the request (in this case this coincides, but explicit is better in case of refactoring): getSnapshotsRequest.ignoreUnavailable(request.paramAsBoolean("ignore_unavailable", getSnapshotsRequest.ignoreUnavailable());
Actually, ignore this, the rest actions are actually just forwarding to the transport actions
I _think_ that you can get away with just letting the exception bubble up and RestController will send it to the user. You won't get the error log but I'm not sure logging an error on 400 level parse errors is a good thing in the long run anyway. I try to usually run requests with `error_trace` on them so we don't eat the stack trace....
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
removed? It does not seem to be used.
are we sure we want to silently go ahead this way when templateService is null? Maybe we should fail so that we find out when it happens, unless it's situation that is actually expected to happen.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
I can push the change if you don't have it ready yet.
No, it cannot be private, since it's used by `AttachmentProcessor` in the same package. That was the part that I was missing. I think its misleading.
I think that we should have left an assertion here that the Java version is not JDK 11 (I think we will be able to remove this for JDK 11). I also think that this code should have been guarded by an if block checking that we are on JDK 10 and otherwise not add this permission.
can we use `== false` instead of `!`
Ah! Got it.
and 2 more occurrences below
too many shards already allocated to this node for index ...
I believe this message needs to be changed now, since the first value is the "used" value now
This predicate can be simplified to `(count, limit) -> count > limit`.
can you undo all indentation changes, it adds noise to the diff
I think this assertion should be in `getAnyNodeExcept()` - it's ok to return an empty list here.
maybe inject failure both before or after executing the actual action.
I think I'd prefer two tests to test these two paths.
Hmm good point, I had forgotten that this class could actually be returned to the user (masked behind an API interface).
I guess we should call this method `updateAppliedStates()` and the field should be `appliedStatesByVersion`.
then do something like this `source[n/a max source size: ...`
I like including the original size here. Maybe instead if the source is chopped it should read like `first 2048 characters out of 10122123: _slice_of_the_source_`.
I don't think we need the exact number of bytes and if bytes is what we have we should use it. No reason to work hard to get characters.
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
Left over Note
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Oh I see, it's the ZTable stuff. Sorry for the noise :)
interesting, what is the reason for this funny upper bound? :)
For the record, I'm asking because I expect the setter to be called once while these create methods can be called _many_ times
Er, well, it doesn't work like that. Ignore.
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
This test is not really testing what we want to be testing here. The reason that it's not is because the cache key for a file named `".hidden_file"` is not `"hidden_file"`, but rather it is `""`. A file named `".hidden_file"` never would have been processed by the compilation engine because it doesn't have an extension. So this will ultimately throw, but not for the right reason.
We will need stronger assertions here too.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
I mean random number of replicas with random combination of non-active states
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
I understand this is the oversight you've mentioned
I don't mind as long as we use `writeString/readString` and `writeOptionalString/readOptionalString` consistently. So you can maybe just change the `readFrom` to explicitly use readBoolean.
ah ok that make sense
Maybe use ConcurrentHashMap? if we can then we don't the synchronized methods.
can we call the latch in a finally block just to be absolutely sure
maybe ``` Java IOUtils.closeWhileHandlingException(openIndexOutputs.values()); openIndexOutputs.clear(); ```
use `localNode.equals(incomingObject)` we know that `localnode` is non-null
I think we use the empty string somewhere yes, not sure if that was a wise choice. I don't mind leaving null, no biggie
I think that `node);` fits in the previous line
I mean to say that I think you can just call `Strings#toString`.
The second one, implement toString with the utility. On May 8, 2016 9:28 PM, "Johnny Lim" notifications@github.com wrote: > In core/src/main/java/org/elasticsearch/action/get/GetResponse.java > https://github.com/elastic/elasticsearch/pull/18102#discussion_r62442944 > : > > > @@ -168,4 +169,17 @@ public void writeTo(StreamOutput out) throws IOException { > > super.writeTo(out); > > getResult.writeTo(out); > > } > > + > > - @Override > > - public String toString() { > > - try { > > @nik9000 https://github.com/nik9000 Are you suggesting not implementing > SearchResponse.toString() but using Strings.toString() in application > code, or implementing SearchResponse.toString() via using > Strings.toString()? > > â > You are receiving this because you were mentioned. > Reply to this email directly or view it on GitHub > https://github.com/elastic/elasticsearch/pull/18102/files/c5f0c73b8b0f9c57500656081005aa64e28f509b#r62442944
I think this is the same as `Strings.toString(this)`? Otherwise I think this looks fine.
I think s/" + "//.
Nit: extra line
I get that, I was just wondering why those default templates bother here
cool stuff I didn't see that one!
maybe in a followup we can think about removing these -1s... see what platforms fail, and better fine-grain the stuff (e.g. add assumption for WINDOWS, IBM jdk, whatever it might be). Then we know when and where stats are available.
could be a instance variable, as used in all tests
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
well.. as I said, **IMO** the separation is cleaner. But if you keep the prototype way, you'll eventually need to keep the current `build()` method and introduce a new `Processor build(Map)` method **next** to it... it's a bit messy tbh... the same applies to the `Pipeline.Builder`. Another option is leave things as they are (so leave the current `void fromMap(Map)` method) and then introduce a factory to a builder... however you look at it, we need a factory somewhere... a construct that is registered by "type" that can create the appropriate builder/processor for that type... something along the lines of: ``` Processor.Builder builder = registry.get("type").create(); ``` Another option is to mandate all builders to have an empty ctor and use reflection to create those. So instead of injecting a set of builders, you'd work with a set of builder classes and then the code will just create new instances using reflection on default ctor.
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Please rework this word wrap too.
I like including the original size here. Maybe instead if the source is chopped it should read like `first 2048 characters out of 10122123: _slice_of_the_source_`.
I don't think we need the exact number of bytes and if bytes is what we have we should use it. No reason to work hard to get characters.
we should be careful here and check for sources that are binary (SMILE etc..)
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
space missing before `new Named...`
space missing before `new Named...`
here is a space missing before `new NamedAnalyzer`
here is a space missing before `coerce(context`
here is a space missing before `postingsProvider`
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
I think you can just initialize to null
The shapeFieldMapper seems unused here.
same problem as above I think, only that unmatched closing brackets will create holes here.
Ok, I see. Nevermind, since its a private method I leave it up to you to change or not, I was confused a bit but the method is short enough to understand what its doing.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: these could probably even be package private
Good point, I forgot about the pretty printing. `equalToIgnoringWhiteSpace` sounds good.
I'd prefer to have a simple `assertEquals` and to a String comparison here. No need for all the constants either, makes it harder to read IMHO.
I don't think you need to explicitely test toXContent, this is done by toString implicitely and this is the change that we want to check.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
> I don't have a strong opinion on this one either way I do because less code that is easy to understand is easier to maintain than more code. ð¼
I think that since you're deferring to `Objects.equals` anyway all the other checks above can be removed.
You're right, I confused myself.
There is because it becomes one very simple line: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java index 6220c4d..5604bf7 100644 --- a/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java +++ b/core/src/main/java/org/elasticsearch/cluster/metadata/IndexGraveyard.java @@ -89,15 +89,7 @@ final public class IndexGraveyard implements MetaData.Custom { @Override public boolean equals(Object obj) { - if (this == obj) { - return true; - } - if (obj == null || getClass() != obj.getClass()) { - return false; - } - @SuppressWarnings("unchecked") - IndexGraveyard that = (IndexGraveyard) obj; - return Objects.equals(tombstones, that.tombstones); + return obj instanceof IndexGraveyard && Objects.equals(tombstones, ((IndexGraveyard)obj).tombstones); } @Override ```
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
`this` is unnecessary
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
oh damned it's BWC I guess...
I don't think raising en exception to save a few lines of code here is a good idea, please change this back to how it was before.
I think it would be easier to reason about it it was expressed as something like ``` if (clientVersion.before(Version.V_5_3_0)) { ... } else if (clientVersion.before(Version.V_5_3_3)) { ... } else { ... } ``` There is also no `else` after this statement, which means we write ord twice... And if tests don't catch this, we might need to figure out how to write a better test that would.
here you may be able to use copyCurrentStructure
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
Would it make sense to move this method to some SpatialUtils utility class? I feel like it's pretty generic and we might find some other ways to use it. I think I would also replace first three doubles with Circle. And we should figure out what to do with the radiusMeters parameter in Circle since it is not meters in case of `shape`, but this is a topic for another PR.
Similar to above, `new TreeMap` should be wrapped with `Collections.unmodifiableSortedMap()`.
can the aid matching be the implementation and the rest just assertions ? it should be enough
I wonder if with this change you can remove `UpdateHelper.Operation` entirely and just use `DocWriteResult.Operation`. I'm not sure it'd be clear to use `CREATE` instead of `UPSERT` in all the places though.
it's a shame we have to wrap the call back here, but I don't see how to simplify this without doing something not nice instead, like making the PrimaryShardRefernce having a non-final releasable field...
we throw the exception and thus take care of the interrupt. We don't need to set it...
We should log the the failure here if the close fails
I think that `node);` fits in the previous line
I think we use the empty string somewhere yes, not sure if that was a wise choice. I don't mind leaving null, no biggie
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
do we need this trace log here and if so can we fix it to say `temporarily` or something like this
if you wanna be more explicit you can use `Function::identity` to make sure it's not a typo
minor semantic difference: over [here](https://github.com/s1monw/elasticsearch/blob/fix_recovery_finalization/src/main/java/org/elasticsearch/indices/recovery/ShardRecoveryHandler.java#L304) we throw the unwrapped corruption exception, not the remote version. I think we should do the same here and throw corruptIndexException
typo, all flies -> files
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
same here - I think it's better to log the info message if the deletion was successful.
no utils for this :( `out.writeLongArray()` maybe :)
I'd just do `sum += Math.max(0, data[1])`
maybe omit lowercase from the method names here? (since these tests also run for uppercase and trim)
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
+1 on making configurable as well (it may very well change from one use case to the other.. this is a good default set however)
maybe like this: ``` Java try { IOUtils.close(() -> processes.stream().map(s -> (Closeable)s::destroy).iterator()); } finally { processes.clear(); } ```
or rather pass it to `spawnNativePluginControllers` and change it's signature to `spawnNativePluginControllers(Path pluginPath, Map<String,String> env)` I don't think we need to depend on `Environment`
can we make the environment variables passed on to this configurable ie. as ctor arguments? I also wonder if the variable should be prefixed with `ES_`
the reason why I suggested to make it configurable is that we could pass in our own values in tests that's all... not a big deal
please use `assumeFalse(Constants.WINDOWS);`
You can use: ``` java exampleAllocator = ExceptionsHelper.useOrSuppress(exampleAllocator, new RuntimeException(file.getKey() + " is still open", allocator)); ``` And then you don't need the `if` statement.
I think we should throw an exception when `id < 0`, which should never happen? (unless Bad Stuffâ¢)
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
we don't need this anymore mockFs takes care of all this. /cc @rmuir
even though this is just `debug`, logging an encryption key is worrisome
Let's make this an `UncheckedIOException` too.
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
> Makes sense? It does not make sense. Having try/catch like this means the test doesn't really know what it is testing.
The reason should be more explicit about why this needed.
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
I think that we need to guard against overflow here!
This is not quite what I think of as exponential backoff. The problem that I see with an implementation like this is that we can have a thundering herd problem. If there is some failure that causes a bunch of tasks to simultaneously fail (e.g., say that we have a bunch of outstanding fetch tasks waiting for a response, and the network connection breaks, failing all of them), all of the retries will keep waking up at the same time, itself potentially causing issues due to a herd. Typically it would be that there is a random component in exponential backoff, to avoid this herding. As a first approach, what I suggest here is: choose a random value k between 0 and 2^number of retries - 1. Then retry after k * delay seconds. We can cap this at max retry delay.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
I wonder if this should rather be made part of Request#multiSearch like we did for bulk. I see that it may be nice to have read and write methods close to each other, on the other hand the only place where we need to write this format is in our client.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
maybe wrap all these maps in `Collections#unmodifiableMap(...)`? To enforce that no changes can be made.
Please fix identation.
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
thanks, let's say I prefer to be verbose now so we don't forget. Once we are done we can remove if that makes sense :)
yes my reasoning is that a compile error makes you think about validation rather then forgetting because there's a default empty impl that does no validation. I tend to prefer an empty validate in all queries that don't need to validate, although that's verbose. Plus that is what we do with ActionRequest as well.
no i do not. but this IDE cannot compromise the actual build, which is 'gradle check'. changing tests.seed in this way can compromise the build, because then the values for other things looking for this (such as lucene) depends on class initialization order.
don't change tests.seed, i dont care what intellij does, this is wrong to do.
I think we should use `writeAtomic` everywhere just to reduce the complexity.
I think s/lang/defaultLang/
Maybe this one too, I'm not sure.
I think we should remove all these boolean and pass an set of flags as a vararg... It becomes less and less readable (not in this PR)
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
Now that I'm seeing these, I wonder if the default names should be `attr` and `value`. We could add aliases if we need longer. Since it's such a small API it's probably fine with the short versions.
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
Don't get me wrong - I like the loop above - I just don't think is sufficient to prove to ourselves that we recreated the problem.
I mean to close `node` and safe the conditional... but it's Releasable so you can use `Releasables.close()`
We will need stronger assertions here too.
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding jvm plugin [{}]", plugin.v1()); } ```
I would add a flush(), since we expect people to see those bytes and we want to be independent of the filesystem impl (what if it uses buffering, thats its choice)
`Description` -> `Descriptor`
why do you pass the response to this method? `this` already has all information.
this breaks backwards compatibility, you will need if based on version in both `readFrom` and `writeTo`
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
here too, sorry :)
This is confusing is what this is.
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
I'd say yes... if you want to be able to parse script as a string, you want to be able to serialize it as as string. I believe serialization should be symmetric - you write what you read. For this reason, I believe the script type should be nullable. if you read a script like a string, the read state should be preserved for the writing.
sorry, my bad.
This logging statement has a `[{}]` but no argument to fill it
Nice, I like the randomization on the thread pool.
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
I wonder if we should have a `LatchedActionListener` that has this logic where we can just do `new LatchedActionListener(delegate, latch)`? I bet there or other places doing the same thing
this might be called by `scheduledRefresh`, which can happen at any time
At this point I don't know that `@param` adds anything either.
nit: can we call it getParseFieldMatcher? now that we have an interface it should be easy to rename all the existing impls at the same time. If you feel like it should be a follow-up, I am fine with that.
We did used to do this but we've moved away from it. So you'll see examples in the code when we had this but it is no longer the preferred way.
yeah, prefer top-level there as well.
I think conceptually this should be QueryParseContext instead, if it needs to do more (toQuery) then we need to figure out how to create the QueryShardContext too out of it, but the other way around seems confusing to me. Sorry I see we are going back and forth on this.
import not needed.
Same concern about reproducibility as in the other PR.
> Makes sense? It does not make sense. Having try/catch like this means the test doesn't really know what it is testing.
You are throwing away the stack trace here. Just have this method throw Exception, and the tests that call it as well.
connec to to -> connect to
good point! I think we need to iterate over the filterFunctionBuilders and rewrite their corresponding filters
you are the man! that is awesome!!! that should just work. I really wonder if we can build a BWC test index with a percolator that ensures we can read this stuff if would be awesome to have asuch a test
looks like it can be final
can you add some inline docs explaining what the hack we are doing here? :)
I'm happy we made those exist queries fast. :)
would you mind reverting the variable name change, at least temporarily? it confuses the review
Sure, good plan.
On deeper thought, this seems unduly lenient: it should only return credentials for the role that `GET /latest/meta-data/iam/security-credentials/` returned, and should return 404 otherwise. Also I think `credentialResponseFunction` can be inlined, it's only used in one place. Also also we could prevent cheating slightly more by inventing random credentials when the service starts up, rather than synthesising them from the role name.
... so that this doesn't need the `{credentials}` parameter in the URL ...
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
Or do it as a direct followup, I suppose.
you can have a look at SimpleQueryStringBuilder.VERSION_5_1_0_UNRELEASED to see how to do it
new is not possible with an older version...
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
Would you kindly add some line feeds here to make it look like json instead of a wall of text? It'd be so much easier to read.
same here, might be that we are good, but let's make sure we don't lose the STRICT one
are we losing the STRICT bit here? it's important that we use STRICT here, so we make sure that we never output deprecated stuff ourselves. and we test deprecations separately.
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
don't you want to reset first and then set the parseFieldMatcher? :)
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
nit: space before brackets
typo: optain -> obtain
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
nit: indenting should be only 4 extra spaces
Since we're moving that, we could inline this using turnary.
As far as I understand in the REST layer, we don't print out any index for which there are no aliases to return, but only in case the alias (name) parameter was provided.(https://github.com/elastic/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/rest/action/admin/indices/RestGetAliasesAction.java#L139). I believe this change tries to mimic the same behaviour for the transport client, but in the REST layer we don't look at what the name parameter matches, only at whether it's provided or not: ``` curl localhost:9200/_alias?pretty { "index2" : { "aliases" : { } }, "index" : { "aliases" : { "alias" : { } } } } curl localhost:9200/_alias/_all?pretty { "index" : { "aliases" : { "alias" : { } } } } ``` That may be right or wrong, but I think we should try to return the same results if we make this change, so I'd say without changing the behaviour at REST (although we may want to discuss what the right thing to do is) the best we can do at transport is to only look at whether any specific alias was requested rather than whether the expression matched all or not. Furthermore, I'd expect that once these changes are made to `MetaData`, the REST action should be updated as some logic can be removed? By the way, related but it should not affect this PR, there's also #28799 under review that is moving the REST logic to the transport layer, yet the REST logic remains in `GetAliasesResponse#toXContent` which doesn't change what the transport client returns. I would probably consider renaming the `AliasesRequest#aliases` method (to `replaceAliases`?) and make sure that it's only used internally (although it needs to be public), and have users call the current setter. We clearly can't have both call the same method or we lose information about what was set in the first place. That would make it possible to keep track of whether specific aliases were requested or not through a flag, similarly to what you do now.
should be action
can `aliases` be final as well
Can this lead to user code change? ( as you changed the tests above )
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
I think this message might be misleading.
I think this missed a misses a maybeFailEngine
I think we should, yes
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
`engine failure` -> shard failure
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Feel like this should be more significant than `debug` because it really indicates a form of failure in some scenarios.
It'd be better, to only skip the config files that have the same name, not the whole directory. So for example, if currently es has a config dir that looks like this (for plugins `foo`): ``` /config/foo/bar.yml ``` and the new plugin that installs needs to copy two files there: ``` /config/foo/bar.yml /config/foo/baz.yml ``` we'll skip `bar.yml` but we'll still copy `baz.yml`. This will help us a lot when we guide the user on how to upgrade - instead of telling the user, to copy & modify a bunch of files, we'll only need to tell him to modify files under `config/foo`
I'm okay with `foo.backup`. It would also not be hidden from non-Windows users by default.
I still think skipping is better tbh... otherwise the users will be more confused on how to merge the old one with the new one. I don't think the file formats will change that much... but when they do, we'll simply be able to tell them what to change in the files they already configured in order to be compatible with the new version (not sure that will even be needed, we could perhaps support both formats in the code and make it transparent).
I think we should fix our datastrucuture first and don't make Path trie super complicated and flexible. This should be fixed first before we make this change here.
I'm afraid this won't work - you only want to decrement this when someone responds to the channel... it needs to be built into the RestChannel..
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
can you just leave the constant in this class? There isn't a need to put it in realm imo
This constructor doesn't seem to be necessary.
I am not sure why you changed this.
Can we also defer to `super.nodeSettings(nodeOrdinal)` so we don't also need to set `DISCOVERY_HOSTS_PROVIDER_SETTING` and `MAX_LOCAL_STORAGE_NODES_SETTING` here? (This also picks up a correct value for `DISCOVERY_ZEN_PING_UNICAST_HOSTS_SETTING`).
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
can you add spaces? `new KeyManager[] { km }, new TrustManager[] { tm }`
indentation is off after other changes
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
Do we need this? the settings are already immutable
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
> At the same time though, acquiring the write lock would be good, because even though there is a warning that this should not be run when ES is running, trying the lock seems like it would be a good idea Definitely, +1
see text from other suggestion for empty primary allocation
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
Here it still says `on a per index basis` -> should be corrected.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
can we implement `Closeable` and use an AtomicBoolean to signal it's closed I like the `if (closed.compareAndSet(false, true))` pattern
You can use `UncheckedIOException`
I always wonder if we should use the PROTOTYPE constant here instead, cause that is what we need I guess. If so we should change all other tests accordingly
Looks good. Thanks :)
The other `BUFFER_SIZE_SETTING` (~ line 111) must also be updated. (I hate those settings overrides...)
Oh nevermind, `CodecUtil.checkHeader` is already doing the real check. You really do not trust anyone ;)
nthe -> the
oh yeah I missed that :/
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
If that's the case, we don't need - that's making sure :D - where do you see it's done in ESTestCase? (I didn't check myself)
please make sure all files closed and no file is leaked.
just fix a number, I don't think randomizing this adds much.
can you check that you can reopen the translog and that you can at least read all operations that weren't trimmed? this should not result in a translog corruption.
Same here. It might be better to make this `TRACE`.
I think this can be optimized further. Here we are updating status of shards that are participating in the restore process. There are only two possible outcome of this operation for a snapshot itâs ether done when all shards are done or it is not done. It doesnât matter if we are applying a single shard or multiple shards â there is still only one outcome per snapshot. If a snapshot is done we need to check if all shards in this snapshot has started and if they are not â create a listener. In other words instead of having an array with one element per shard it might make sense to have a map with one element per snapshot.
this can be removed now, no? it will be cause a duplicate with the full cluster state log..
I think this should be trace
while we are at it, can we move this log to debug? its very noisy and it can happen with join retry logic
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
If it is relevant for String impls then I don't see why it should not also apply in the long impl.
good catch on delta > 0
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
As this setting should usually be only set once, it is probably simpler to leave it non-dynamic (as @jasontedor suggested and as it was before this PR). In case where this must absolutely be updated on a production cluster, rolling restart (of master nodes) with config update is always possible.
right thanks for the explaining, I should have known, having worked on the search refactoring :)
fancy pants :)
We call them "master nodes" everywhere else. :frowning:
I think 0 is a good minimum value.
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
use a try-with resources for the parser value
Ah - I see the other side of it. Up on line 925 I thought you were building a LinkedHashMap from a HashMap rather than casting. Up where you call `parser.mapOrdered`. Anyway, `mapOrdered` should make this reproduceable like the `Collections.sort` was trying to do.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
Right... but I'd be happy if we could unit test this, and if we do then we need to ensure the object start.
A question out of curiosity: the analyzer we get here doesn't have to be closed (via closeAnalyzer) because its not a new instance? I don't know enough about the lifecycle of these objects yet I'm afraid.
This can maybe go inside the following `else` branch.
Got it. Thanks
Can this be split into the two cases `request.normalizer() != null` and `(request.tokenFilters() != null && request.tokenFilters().size() > 0) || (request.charFilters() != null && request.charFilters().size() > 0)` in two separate `else if` blocks instead of separating these cases later? I'm not entirely sure if this works, but I think it would make this part easier to read.
Thanks, I think its better than nothing
There is actually a [standard](http://checkstyle.sourceforge.net/config_modifier.html) for this if you particularly enjoy standards.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
yeah nevermind I was confused about some internal classes
But yeah, keep it now.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
In this example, you can use `assert` directly in the script itself, so you could do ``` java .setScript("assert ctx._version == 1 : \"version should be 1\"" + ... etc ... ``` If you would like to (I think either way is fine, just depends on personal preference).
hmm actually I think we should load deleted queries too
it is also very specialized given that before dance that creates the suppliers, maybe wise to leave it here for now.
I think I saw this in Christoph's PR too. Hopefully you don't need it.
I don't think you need @Before here, the parent method already has it.
+1 on removing it
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
since we catch throwable I think you can scratch the `success` thing and just do the `latch.countDown();` in there? sorry I could have realised that earlier :)
This logging statement has a `[{}]` but no argument to fill it
add the exception? :)
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
last parameter can be set to from.
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
Can we get back to this once we need this complexity and keep it as simple as possible for now please? Can we hardcode the OBJECT_FIELD_NAME exclusion and be done with it? queries also have access to individual field names if they need that.
it's a minor thing but why would you assign a variable multiple times when it's not needed? default is a better fit here, it improves readability as well.
maybe we could have a `default` here which could make this switch a bit more readable rather than assigning value before the switch in any case.
Same here as above, since both methods are related and read similar.
either way please create a static array containing these fields on top close to where we create `mappedFieldnames` so this selection is not buried in this method and we see that we might have to change it if/when we add new fields.
we can make this catch throwable and remove the catch from https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/rest/RestController.java#L175
can we clean up the other try catch? it's not needed now (as we catch things here too)
I meant that one indeed. GitHub is playing tricks - it didn't show me that change in the same commit (but now it does). Sorry for the noise.
if you do not supply the the content-type, you can just hand over the builder and do not need to create a string object here. Also I would just return `JSON is disabled` instead of mentioning the config option here. The shorter the better IMO.
this is not good... you rely on the base class implementation (that only these two parameters for it's state). You have to proxy all method implementation to the delegate
I wonder about the cases where this can happen as the `close` method on `InternalTestCluster` that calls `shutdown` on the executor is synchronized (same as this method). Have you observed this exception being thrown? If we don't expect this to occur under normal operations, I would prefer not to swallow the exception here.
space missing between ) and {
We discussed this on another channel, and decided to only do the auto-bootstrapping when autoManageMinMaster mode is active. We also decided to have multiple nodes participate in / run the bootstrapping process.
not sure if this should be pretty printed as we put in the exception message. we'll have to see an example to be sure. Alternatively we can log a warning line like we do in ensure green. Also, you can consider using Strings.toString().
only the `#start()` call should be concurrent. The publish should be done in a sync manner and the `NodeAndClient buildNode = buildNode(settings, version);` should be done before in a sync manner. This is important since we want the same setup no matter of how threads are scheduled and `NodeAndClient buildNode = buildNode(settings, version);` uses random internally
I wonder if this case distinction should be part of ReplicatedOperation.
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
ok let's leave it as is for now.
I know this is a pattern we use everywhere but I don't like the name `success` to mean "I've forked this request and now it's the listener's problem" but I don't know a better name.
nit: `an` -> `a`
just initialize it and make it final - it just compliicates the code
can we just throw ElasticsearchException since it has the HTTP code baked in and it's also a RT exception
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
Probably for another PR since it's unrelated but I wonder if `scriptable`, `formattable` and `timezoneAware` should be properties of the Builder object rather than/ as well as the parser so the builder can ensure an IllegalArgumentException is thrown if e.g. an unscriptable agg has the script method called on it? /cc @jpountz
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
++ to talking this through but to put it out there, what I am thinking is that we re-build the user after the lookup. For this case we have PkiUser and LookedUpUser. The final user will be the combination of the PkiUser's metadata, the LookedUpUser's metadata, and the LookedUpUser's roles. The looked up user's metadata would trump the PkiUser's metadata in case of a conflict. This does get trickier when you do this in an AD/LDAP realm since some of the metadata comes from the group resolution. In that case, I would only include the metadata that does not involve group resolution from the authenticating realm.
Not a specific concern, but just more configuration options for the end user when it is not being that effective. The code is trivial and not of maintenance concern so I am fine with we being consistent in all cases.
lets revert this. We do not need it here
can you just leave the constant in this class? There isn't a need to put it in realm imo
Is this an oversight? `DEFAULT_KEEPALIVE_SETTING.get(settings)`
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
To be clear - I think we want to know how the oldest file is, regardless of the generations. It will always be the oldest generation and the first in the reader list, but I don't think we want to rely on it. Part of the role of the stats is to validate things are correct.
why did you change this to take a `TranslogGeneration` with the uuid instead of just the `long minGeneration`? It's not using that uuid anywhere here AFAICS.
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
I'm not happy with the extra boolean flag to include / exclude the current generation as a fall back. It's too subtle an error prone. How about doing the following (I think you had it in the past and we moved away from it towards the uncommittedX api - sorry for that): 1) If the min gen for the local checkpoint + 1 is > current committed gen , return true. 2) If the min gen is equal to the *current* translog gen, the current gen is not empty (using `totalOperationsByMinGen`) and the local checkpoint is equal to the max seq#, return true.
Just a question: would it be possible to extend from `LongFieldMapper`? Would be nice to have some code reuse.
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
acceptDocs will be checked _before_ these bits are checked anyway
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
Is this done already? Maybe specify what "sanity checks" means otherwise.
I wonder if `profile` and `explain` should be forbidden too? Both have non-negligible impact on performance, and seem irrelevant to ranking as well.
I would be using a `Set` in this circumstances.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
As soon as external JSON names are stable we should use the same names inside for variable names I think. Can be done in a separate PR though.
it would be awesome to have some doc-strings on these settings
maybe make this variable final? just better indicate it will never change
ok fair enough...
maybe we should also decrease the chance that we add another child object compared to leaf fields.
can we configure the delayed allocation to not be the default (`1m`) but something high enough to trigger what we are trying to fix, like `200ms`? This will speed up the test.
close is supposed to clear as well so this shouldn't be necessary to call clearReleasables
you can remove the QueryParsingException catch, it's unreachable
this part of the change looks a bit scary to me. I'm wondering how hard it would be to do this 'state' management and wrapping of collectors outside of IndexSearcher so that we don't have to check what the query is.
Wouldn't it be better to not call setScorer at all? I suspect most collector impls do not expect a null Scorer.
yeah, that was what I meant
Here you can do something like this: ```diff diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java index 356b9a29dc..36794e880f 100644 --- a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java +++ b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java @@ -65,9 +65,11 @@ public class PublishClusterStateStats implements Writeable, ToXContentObject { @Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException { builder.startObject("published_cluster_states"); - builder.field("full_states", fullClusterStateReceivedCount); - builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); - builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + { + builder.field("full_states", fullClusterStateReceivedCount); + builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); + builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + } builder.endObject(); return builder; } ``` which makes the JSON-structure clearer in the code.
This method can be package-private.
Nit - strictly speaking these are publishing stats, can we open the object with just published cluster stats (drop received). You can maybe received back in the keys, which can be shorted by dropping the cluster states from the key names - itâs implied from the object theyâre in.
We've been moving away from these inner fields classes, we don't need them to encapsulate some strings.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
maybe just push the `maxUnsafeAutoIdTimestamp` up to engine and make the methods final
if we do this, why did we need to change how createNewEngine behaved (i.e., update currentEngineReference etc.)
I looked at the implications of exposing an engine that isn't fully recovered yet and it's OK, with the exception of syncFlush(). Depending how this ends up being, we may need to make sure that runs under a permit.
it will be good to have some kind of progress logs here (like log ever 10k ops or something) under debug.
Nit: there is an extra space after the `&&` and before `inSyncLocalCheckpoints`
do we want to unify this code with the refresh method by making this get a manager to work on? (+ a string description for failures)
I think we should return active.get() == false and also - set it if we became idle...
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
ok fair enough
for readability I'd use this. as well
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
snpashot -> snapshot
while we are at it, can we move this log to debug? its very noisy and it can happen with join retry logic
the start cluster does this.
Nit: `accross` -> `across`
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
Probably should also be getAssignedNodeId.
I like this style. I think I'm going to steal it.
ok can we rename the getter then to `getFailedNodeExceptions()`
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
NIT: Noisy reformatting
I like `hasSize` better for this because it gives a nicer error message on failure.
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
NIT: noisy reformat :)
same as above, no need for try catch
But yeah, keep it now.
Typo: "Dynamics" -> "Dynamic"
Should we add a `default:` clause just in case here? It looks like the original code had one
can we call this primaryItemRequest? It's the one that's sent to the primary. Also, if we pass it as a `BulkItemRequest` parameter, we can avoid sending `requestIndex` and `BulkShardRequest` (from which need the concreteIndex, which I think we can from the shard). Last can we assert that the `BulkItemRequest` has as a request object the `updateRequest` we got? this is all super trappy but we can take one step at a time :)
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
> toArray() returns an Object[] depends on which toArray method you use. Just move to the one that accept an array as argument. Or iterator is fine too.
you can remove the validate call for now, we will fix all queries soon, I promise
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
I don't think reusing Lucene doc ids as slots will work in case of nested docs.
can you use `== false` instead of `!`
I think we should stick to the current validate api for now, although it does feel weird that we don't actually throw exception. What happens is that the listener gets notified of the exception in `TransportAction#execute`. We can't yet hook into the validate mechanism as the `SearchRequest` only contains a `source` bytes array in json format, but at the end of the refactoring we should have different elements that hold the different parts of a search request, among which the query which can be validated as part of `SearchRequest#validate`. This is to me the only way to make sure that validation happens whenever needed.
sorry for changing my mind, what do you think about having our own exception here e.g. `QueryValidationException` ? when we'll hook into the search request validation we can just wrap it in the ActionRequestValidationException or something along those lines. I wouldn't query builders to depend on transport action packages ideally.
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
alright that's what I thought too, sounds good
can we call it testNoInnerQueries? I would like to avoid confusion with our nested query (nested type) here
we can delete ForceMergeFailedEngineException now, right? It's not used.
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
same here - I think it's better to log the info message if the deletion was successful.
we need to add that we return false if no folder was found for this shard.
Right - RollupIT is the right place
you could use `scriptRequest.setJsonEntity`
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
And one more...they seem to be all over, I presume a mistake in regex find/replace.
++ thanks Nik
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Space missing between `}` and `is`.
`foo`-> `{@code foo}`
typo: `i` missing. Also, maybe rephrase to something like: `materialized and represent the result columns sent to the client`.
"sent to the clienT"
`clien` -> `client`
those are hard to debug I can tell u :dancers:
Thank you for cutting over to a better clock :)
Woops, never mind: maybe put params around `status.activeIndexing == false` ;)
my thoughts too :)
Not -> Note
Sorry, I overlooked the null check. This is good!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Ahh, sorry. You are 100% correct.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
More indentation that is hard for me to read.
then check for non null here...
is this needed here? I think it does something only when the current token is start array or start object.
I might use an empty array here or switch the IdsQueryBuilder work with lists.
I'd have added an integer to `TypeParser` and sorted them by the integer resolving same integers alphabetically or something. And set the FieldNamesFieldMapper to MAXINT. But I think what you did here is ultimately simpler.
I opened: #23338
update version to beta 1
+1 then we shouldn't forget about it :)
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
please ignore - misread the constructor - seems like a null is a valid value.
update version to beta 1
maybe add the type that is found in the error message with fieldType.typeName()
let's not log since it is an old index
I don't think we need this part? Even if you've created an index with 6.4, you still want to be warned that things are going away if you upgrade to 6.5
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
fine with me
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
ok, i see it. Its just a little non-obvious due to the way searchers are bubbled up. maybe we can add an assert in the future.
can you try to exercise this method to make sure we open a new searcher and close / release everything
I'm a bit concerned that this will be the case almost all the time except when we wrap. Can we avoid this if statement and just recreate an IndexSearcher all the time? (the else branch)
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
we should assert this is never called (same for the other places here where `UnsupportedOperationException` is thrown), as this indicates a bug.
What about : ``` json "retries": { "bulk": 0, "search": 0, } ``` Note: I tend to like JSON inner objects since clients and parsers can skip whole objects while parsing...
sorry I meant `org.elasticsearch.common.xcontent.ObjectParser` all the time my fault
+1 on using static strings - I didn't realize that the XContentStrings things are not usable when parsing.
As Boa mentioned before we would need both a default to print out, and a boolean that tells whether the current value is default or not, as the `currentValue != defaultValue` is not enough. Something like the following should help in most cases I think? ``` public static void maybeAdd(XContentBuilder builder, String key, Object value, Object defValue, boolean isDefault, boolean includeDefault) { if (value != null || !isDefault) { builder.field(key, value); } else if (includeDefault) { builder.field(key, defValue); } } ``` That said, maybe it doesn't cover 100% but 90% of the cases, and for the 10% left we can still have the custom if? In my opinion it doesn't need to be perfect but still better than copy pasting that `if` so many times.
I took another look at MovAvgModelStreams, and although I'm not completely sure it look a lot like what NamedWritable is doing, so I was wondering if Stream could be replaced by it.
I think this message might be misleading.
we can do try-with but we need to have 2 try blocks. since the write lock needs to be released last. but in a try / with blokc it's released before the finally block is executed
Typo, finalzlie -> finalize
I think we can remove this one because the lock is aquired higher up (and we should check there).
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
could be a instance variable, as used in all tests
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
Maybe it always should have been....
I'd prefer `param.substring("the 13 character string".length());` or something like that.
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
10 seconds is pretty fast for some of these CI machines to get the whole ES process up. Does this happen pretty early in the process? Either way, this change might be shortening the timeouts that the CI nodes need to get ES up in time.
If its early I think this is safe - but now maybe the read timeout on test side will be too low.
Can you shrink-wrap this try clause? (Pull the `map.put` out after it.)
It's expected that some files will sometimes be gone here, because `IndexWriter` is actively changing the index while this reader has a point-in-time snapshot open. Maybe we catch `FileNotFoundException` and `NoSuchFileException` and don't log (even trace) those ones? Any other `IOException` we should log.
Actually, I think IW should not remove files that are being used by NRT readers (we fixed this a while back in Lucene), so I think we should continue to log the exception, but can you increase log level to WARN? Also, can you shrink wrap the exception handling? Put one try/finally around the `listAll`, and another on the `directory.fileLength`? And include in the exception message which directory (`directory.toString()`) and which file caused an exception.
similarly here I would like it better with a regular for loop and by making fillSegmentInfo take a single segment at a time
yea, I would at least debug log it..., it shouldn't happen
I think this check should go into initializeSnapshot or repository.
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
I think we have this logic in the settings already maybe we can factor it out and reuse? seems scary and it would be good to be consistent.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
This might read better if it were renamed to `hasRun` initialized with false and then it could be ``` java if (hasRun.compareAndSet(false, true)) { prepareBulkRequest.run(); } ```
Ahh okay, that makes sense, I missed that
Could initialize this with the size of the hits list to prevent resizing
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
Can you reverse this, the negative makes it harder to read
I'd return an Immutable set... it enforce compilation failure when used inappropriately (if the user tries to mutate the set)
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
Do we really need to also duplicate the typed_keys logic here? Can't we just print out the name of the parsed aggregation (it can be initialized with type#name)
I understand. But this requires to grab back the type and delimiter where initializing the parsed aggregation directly with the name "type#name" would allow to parse back the result too. Also, in a client side point of view, the name is "type#name". But I'm nitpicking, we can change this later if we want.
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
maybe add an explicit `continue;` here to indicate that it's being skipped
I think that the `ResponseContainer` abstraction is completely unnecessary. You can just add an abstract protected method to `TransportNodesAction` that receives the collected responses and failures. Take a look at `TransportBroadcastByNodeAction` where a similar mechanism is employed (the grouping is handled in the base class, and then delegated to an abstract protected `newResponse` method to handle creating the correct response object).
should say shard active
ah - now I see what you did it :)
this can ne ThreadPool.Names.SAME, the handling is lightweight enough to not require forking to the unbounded generic TP
"if if" again
this is unneeded? we check before we call...
why did you decide not to do the approximation we talked about? i.e., `System.nanoTime() - (Math.min(0, System.currentTimeMillis() - this.timestap))* 1000000L;`
I think we might want to add this to the docs for delayed allocation (just so users are aware)
this should probably be an array
Ok great, thanks for the correction @rjernst
It was removed from ParseField in #17933. It also shouldn't be added here.
I'm pretty sure camelCase shouldn't be supported any more.
I don't like these being in ParseField because ParseField is broader than Aggregations and is used all over the codebase. I would rather this was moved to a constants interface called `CommonFields` as an inner interface to AggregationBuilder (much like we have `InternalAggregation.CommonFields` for the response side).
also reflect the deprecations on the java api to the corresponding parse fields too? (slop etc.)
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
we shouldn't need this here in parse phase
why is this? what's wrong with `1.f`
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
we can do this in a more optimize manner. We can create a builder, and then use `copyCurrentStructure` on the builder (passing it a parser), to just copy it over, compared with parsing into a map and then serializing the map. Also, since its internal, I would use smile builder, as its considerably more efficient than json.
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
Ok, then it's fine.
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
This whole loop reads fairly low-level. If config files can be considered small, we could just read them much more concisely with the Stream API (untested): ``` java String rules = Files.readAllLines(path) .stream() .filter((v) -> v.startsWith("#") == false) .collect(Collectors.joining("\n")); ``` All the low-level stuff is gone. But this relies on Java 8 features and will only work on master.
We can rely on auto-closeables here (i.e. we could use just the try-with-resource statement). Not necessary if you use my suggestion with the Stream API.
can you also add ``` @Override public Decision canForceAllocatePrimary(ShardRouting shardRouting, RoutingNode node, RoutingAllocation allocation) { assert shardRouting.primary() : "must not call canForceAllocatePrimary on a non-primary shard " + shardRouting; return canAllocate(shardRouting, node, allocation); } ``` as this is a hard constraint with no exceptions
I would use the following message: "ignored as shard is not being recovered from a snapshot" and not have an explicit check for `shardRouting.primary() == false`. That case is automatically handled by this case too as replica shards are never recovered from snapshot (their recovery source is always PEER).
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
I would write this check as ``` if (shardRestoreStatus.state().completed() == false) { ``` and then add an assertion that `shardRestoreStatus.state() != SUCCESS` (as the shard should have been moved to started and the recovery source cleaned up at that point).
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
I think that these log parameters are backwards.
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I am not sure if we should catch an exception here IMO the exception should bubble up
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
And i just did not have the time to yet yesterday remove the stupid asserts from SpanScorer. Please, lets not drag this stuff in again. If oyu want to push fine, but you will see a second push from me removing all this crap.
Why do we need the copy-paste at all? This whole thing seems like a code duplication of PayloadTermQuery.
would be great if this logic could be unit tested.
just my personal preference, I don't like instanceof checks that's it. you are free to leave them if you prefer them ;)
Sorry, I missed that you need to track scores as well. Then indeed, a LongHash would make sense.
Let's use `assertThat(..., equalTo(...))`.
Let's use `assertThat(..., equalTo(...))`.
Let's replace the `assertTrue` by more effective matchers, and replace the `assertEquals` by `assertThat(..., equalTo(...))`.
Can you rewrite these to use `assertThat(..., equalTo(...))`. I prefer this form because it's clearer which is the expectation and which is the value under test whereas with `assertEquals` it often gets confused.
This is another case where I would use a more effective matcher.
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I don't think it matters. We should not force making huge changes to the entire codebase in order to not add things which will just be deprecated and/or confusing to the user.
I would also be fine with removing all the camelCase options for all formats in this PR to make it consistent.
I just realized we aren't even talking about setting names, but the valid values for the `format` setting. This argument to use ParseValue does not make sense. We don't support camelCase in eg the `index` option. We should not do it here, it will just add more work for users if we allow them to _start_ using a new value that will just go away in the future (and will require them to change the value to what they would have found in the first place if they had tried using camelCase and seen an error).
oh oh I hadn't read your reply when I replied ;)
can we clean up the other try catch? it's not needed now (as we catch things here too)
I meant that one indeed. GitHub is playing tricks - it didn't show me that change in the same commit (but now it does). Sorry for the noise.
I'm afraid this won't work - you only want to decrement this when someone responds to the channel... it needs to be built into the RestChannel..
I'd probably just pass the map rather than close over it.
I would be more precise on the version, cause it's not clear if it is from 1.5.1 or 1.6.0.
you migth want to use //nocommit so maven notifies you when you forget about it ;)
version reminder here too, and s/splitted/split
this `id` gets sent over the wire in `ClusterBlock#readFrom` and `ClusterBlock#writeTo`. your change makes it backwards compatible only for reads, cause a 1.6 node that gets 1.2 detects and converts it. But what happens if a newer node sends 3 or 4 to an older node? We need to add some logic based on version of nodes. Also, I'd try and make this method package private, not sure why it's public it shouldn't IMO.
that looks good, thanks
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
nit: extra line
nit: `== false`
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
We discussed this on Slack and concluded that this is an unimportant special case in which it's painful to check the authorization correctly but, moreover, we can just ignore the auth checks on this API without losing anything significant. Arguably this could just use a `nonAuthPath`. I think get this special case out of the way first and then neaten up the rest and move it into `Bucket`.
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
should we maybe make ConfigurationUtils more flexible to enable its use here? I understand that the error message may want to be customized in this case.
since this is done once. should we be more restrictive here to actually have a proper path format? just a `.` is pretty flexible and would allow ``` hello. .hello ```
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
is this a leftover? I don't see where this is used outside of tests? and even there I think it's a huge overkill. Can we please remove this entirely. If you really need stuff like this for testing then look at `ThreadContext#setTransient` which you get from a threadpool
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
I don't think "Not implemented yet" adds anything other the exception type (and could be misleading if we never intend to implement).
This can (and should) be final.
This empty line can go.
I think this should be a hard illegal argument exception.
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
ð to this escape hatch
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Not related to this PR but I think that we should check if what we are trying to remove is not part of the BLACKLIST. Someone could potentially provide a plugin which contains his own `bin/elasticsearch` script, which looks scary to me.
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
minor note: we consider shards inactive until the first indexing operation has happen, so I think this part is OK regardless of the change.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
would be nice to allow to configure it to a percentage of the heap size
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
got it. Thanks.
It's better to use variable names with context so for example `check1` could be `keystoreCheck`, etc.
this should happen after we update `isSecurityEnabledByTrialVersion`
I was thinking something similar to how we use [addValidationError](https://github.com/elastic/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/common/ValidationException.java)
we should probably consolidate the error messages from the results so that we don't only present the first (from a seemingly arbitrary check order) error that was encountered to the user
Why do we need getters? These are all final and immutable
Ah, I see the dilemma. If you want to encapsulate for that reason, that seems fine. Then please use the naming convention proposed in #14266? ie `settings()`, `environment()`, etc since they are read only
I like dummy because it implies fake and the index is fake - not just empty.
save -> safe :tongue:
tokeinzer -> tokenizer
It should say greater than zero, 0 is not permitted.
I think the unlock calls should always be in a finally block
I don't think it changed the readability much - it made the checks simpler but then it left me wondering why two variables were needed. I was doing the "why does this have to be here, let me think hard about it" think.
Could you explain why this is needed instead of checking `expireAfterAccess <= 0`? I think it'd make the class more readable.
for some caches it would be nice to make sure to not compute twice the same value
maybe just `return blobMetaData.length() == fileInfo.length();`
err I guess you need to have failures added first so second...
I'd feel better if the `latch.countDown()` would be the first line in the catch block
you can just use IOUtils here too it accepts null etc. and ignores the IOException if you do closeWhileCatchi...
no file? maybe IOException
In fact, it should probably say something like `Remove the plugin specified by {@code pluginName}.`
The indentation is off here.
Let's drop the uppercase on `Terminal`.
I think we can state this more generally as it's thrown if any I/O exception occurs while performing a file operation (of which there are a few).
This should be `pluginName`.
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
once you rebase you can take out boost and queryName here, they are already taken care of in the base class
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
alright that's what I thought too, sounds good
I find the boolean condition quite hard to read, maybe negate the whole logic to get rid of all this weird `&&` and `== false`: ``` if (newPrimary.unassigned() || newPrimary.isSameAllocation(oldPrimary) || (oldPrimary.relocating() && newPrimary.isRelocationTargetOf(oldPrimary))) { // same primary term } else { // incrementing the primary term ... } `` ```
Can you add a textual description (makes it easier to understand)? I was wondering for example at first why we don't increase primary term upon full cluster restart (then I noticed we do, as isSameAllocation yields false if oldPrimary is unassigned primary).
I'm happy we have all these tests. It is also another data point to move in the direction we discussed - i.e., failures should mark things as stale.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
maybe, to be more precise, it would be good to check the partition that included the new primary.
can we rename this to shouldIgnoreNewClusterState? it's not only about being dated.
can we call this log: ``` received a cluster state from a different master then the current one, ignoring (received {}, current {}) ``` also note that disco nodes already have [] in their toString.
can we extract this logic and the logic above (where we prune/ dedup incoming cluster states), into a static method and unit test it? would make me sleep better :) This is super important.
+1 on warn. Can also do this check outside of the cluster state update task? it's a shame to go into an update task. We will still need this check in the cluster state as we may have two masters publishing while we are in the join process.
nice one. Good to add.
I think this check should go into initializeSnapshot or repository.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
is there a way to filter out the index metadata here? We just want the global metadata.
lets put this into a unit tests class
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
I was on the fence too cause it's internal code but it seems consistent with the other assert that we have on the static block
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
This does not necessarily need to be within a static initialization block.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
nit: extra new line
can we use `== false` instead of `!`
just for kicks can we have `reason = "works around https://bugs.openjdk.java.net/browse/JDK-8034057"` it's just more obvious which bug is meant
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
I think it's good have 0 as an option here too? I.e., index and search a freshly opened engine ..
Nit: `findHostName` -> `getHostName`
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
Hey I saw some updates on this PR and I just wanted to throw a reminder out that we are not going to do a singleton(404) here, because we want a delete that is not found to throw an exception. Also, last time we spoke you were going to change this to AcknowledgedResponse. <3
heh, duh... Sorry, ive been on vacation and full of turkey since last week.
It might also depend on which implementation of `AcknowledgedResponse` you are using, since we have two, yay duplication!!! You should have a look at `StartRollupJobResponse`, which is an example of changing the word from `acknowledged` to `started`. this should get you on the right track.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
just `for (IndexMetaData indexMetaData : state.metaData())`
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
i think `== true` can be skipped
I think this will result in a double info logging - we already logged at info level when discovering this.
It'd be cool to be able to list the phase and/or which shards you are waiting for. You could put all kinds of cool stuff in here one day! But for now this seems like the right thing to do.
one more thing (sorry!). For the language clients, I think it would be good to also have a small REST test that uses search_type count, just to verify that all of the clients (and our REST layer) still support it.
the logger here should either be static, or passed in the constructor (better, since it will have much more info)
two license headers? :)
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
+1 to throwing the exception.
same here - since we have on onFailure handler, calling is the equivalent of re-throwing the exception, imo.
Imho, the interruption is dealt with here. We don't need to bother the code higher up with it.
OK. I'm good with fixing this inconsistency by throwing an InterruptedException (and catching it up just like we do with LockObtainFailedException
we throw the exception and thus take care of the interrupt. We don't need to set it...
I think 0 is a good minimum value.
We call them "master nodes" everywhere else. :frowning:
right thanks for the explaining, I should have known, having worked on the search refactoring :)
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
also make this setting `Setting.Property.Final`
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
shouldn't we use here `!REST_EXCEPTION_SKIP_STACK_TRACE_DEFAULT` instead of `false`
I think you can just initialize to null
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
marks the shard store
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
This is logic that I think should go into ReplicatedOperation.
We should log the the failure here if the close fails
ð much better readable
instead of this check just override `public void onRejection(Throwable t)`
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
use `Objects.equals` for all once changed to potentially null references.
after is now minimum_age
No, you are right, I didn't realize the need for api users before going through the whole changes.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
you are perfectly right Christoph, let's merge the two and keep the existing class.
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
this curly bracket should be on the previous line
maybe also test a nested conditional setup? (So have conditional and then another conditional in the matched or unmatched list)
after rebase you will have to get rid of any wildcard import, or the build fails :)
I prefer `assertEquals` in cases like this. `assertThat` is great if you need to take a matcher or want to assert something complicated, but I like `assertEquals` for equality.
same as above, no need for try catch
I think we are still missing preference? Should be similar to the get API.
if you do not supply the the content-type, you can just hand over the builder and do not need to create a string object here. Also I would just return `JSON is disabled` instead of mentioning the config option here. The shorter the better IMO.
Minor nitpick 3: You could put the two if-statements into a long one making this diff really small
I can't come up with any more seriousness :)
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
oh oh I hadn't read your reply when I replied ;)
We can't safely say that all such exceptions will extend `ElasticsearchException` (e.g., a bad `NullPointerException`), but I like your idea of wrapping the ones that do not extend (as long as it's not wrapping it in an exception that sounds like the user can do something about it).
> Would using `ExceptionsHelper#convertToElastic(...)` helper method in `ConfigurationUtils#newConfigurationException(...)` or similar here be sufficient? +1
Please don't lose the original exception. It's already difficult enough to debug script exceptions without them being swallowed.
ok thanks for the explanation.
you can use MustacheScriptEngineService.NAME
Below is what I get when I try it out. As you can see that log message is drowned in many other log messages that don't mention the index name. A lot of this is guice and we're working on fixing it, but I think the easiest is to make sure that the index name is mentioned in the exception for now? people won't see it otherwise. ``` [2016-11-03T00:08:29,112][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... a terminal screen worth of stack trace here ... Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] .... [2016-11-03T00:08:29,144][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,146][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal screen worth of output [2016-11-03T00:08:29,161][ERROR][o.e.c.m.MetaDataIndexUpgradeService] [ePegTxb] [foo/TYJyxhVDRjGIMDrHomQciw] failed to process index settings: can't archive mandatory setting [index.number_of_shards] [2016-11-03T00:08:29,161][ERROR][o.e.g.GatewayMetaState ] [ePegTxb] failed to read local state, exiting... java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:528) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.archiveBrokenIndexSettings(MetaDataIndexUpgradeService.java:171) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.cluster.metadata.MetaDataIndexUpgradeService.upgradeIndexMetaData(MetaDataIndexUpgradeService.java:81) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] ... another terminal Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) ~[elasticsearch-6.0.0-alpha1-SNAPSHOT.jar:6.0.0-alpha1-SNAPSHOT] [2016-11-03T00:08:29,229][WARN ][o.e.b.ElasticsearchUncaughtExceptionHandler] [] uncaught exception in thread [main] org.elasticsearch.bootstrap.StartupException: org.elasticsearch.common.inject.CreationException: Guice creation errors: 1) Error injecting constructor, java.lang.IllegalStateException: can't archive mandatory setting [index.number_of_shards] <--- THESE IS REPEATED 4 times at org.elasticsearch.gateway.GatewayMetaState.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayMetaState for parameter 4 at org.elasticsearch.gateway.GatewayService.<init>(Unknown Source) while locating org.elasticsearch.gateway.GatewayService ... another terminal, this time full of guice information Caused by: java.lang.IllegalArgumentException: Failed to parse value [2000] for setting [index.number_of_shards] must be <= 1024 at org.elasticsearch.common.settings.Setting.parseInt(Setting.java:533) at org.elasticsearch.common.settings.Setting.lambda$intSetting$12(Setting.java:504) at org.elasticsearch.common.settings.Setting$$Lambda$183/2092885124.apply(Unknown Source) at org.elasticsearch.common.settings.Setting.get(Setting.java:312) at org.elasticsearch.common.settings.AbstractScopedSettings.archiveUnknownOrInvalidSettings(AbstractScopedSettings.java:525) ... 47 more And this ^^^ is the last message on the screen. ```
I think this should be at debug level
Fall back to _old_ behavior
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
`upgrade API` -> `the upgrade API`
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
remove this additional line break? :)
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
if the size was previously less than PAGE_SIZE_IN_BYTES (possible with the contructor that exposes a size), this will actually grow the array (potentially going from a simple heap-allocated byte[] wrapper to a recycling instance)
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
I think it would have been worth it but now that you mention it - other requests may have changed this in the mean time too, so let's leave this assertion.
save -> safe
OK. > On 20 Jul 2015, at 14:01, Shay Banon notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java: > > > ## > > - AsyncShardFetch<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> fetch = asyncFetchStarted.get(shard.shardId()); > > - if (fetch == null) { > > - fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction); > > - asyncFetchStarted.put(shard.shardId(), fetch); > > - } > > - AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId())); > > - if (shardState.hasData() == false) { > > - logger.trace("{}: ignoring allocation, still fetching shard started state", shard); > > - unassignedIterator.remove(); > > - routingNodes.ignoredUnassigned().add(shard); > > - continue; > > - } > > - shardState.processAllocation(allocation); > > - changed |= primaryShardAllocator.allocateUnassigned(allocation); > > - changed |= replicaShardAllocator.allocateUnassigned(allocation); > > I will do the assert when I remove the primaryAllocated flag in a different change > > â > Reply to this email directly or view it on GitHub.
can we add an assertion going out that going out of the primary shard allocator we don't have any primary shards in the unassigned list, unless we expect them to be there? (primaryAllocatedPostApi is false or restoreSource != null)
can we add some trace logging here? I can imagine it will save some WTF at some point.
Looking at this again, I think we can remove the node settings as updateDelay / getRemainingDelay only depends on index settings.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
last parameter can be set to from.
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
if we use millis then we really should make sure that time doesn't go backwards!
no need for this to be public
I would use System.currentTimeInMillis, nanoTime has different semantics
and also assert that `startOfThrottle != 0`
we can maybe use similar technique as we do in `QueryParsingException` and also report the location
`curWrnHeaderSize` -> `currentWarningHeaderSize`
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
The user already expects if they have set this setting that warning headers will be truncated. Therefore, I don't think we should do this, losing a warning header (or more) at the expense of a warning header saying that there are more warnings that can be found in the logs. Instead I think that we should log (in the main Elasticsearch log) when we truncate.
I think that we want to log *each* time that we drop a warning header, not only the first time for a given request. Also we can be more precise than the current implementation which says one or the other condition is met, but we always know exactly which condition it is so we can help the user more by letting them know.
I think it'd be useful to get one more warning when the limit is hit, saying that there were more warnings but we dropped them because `http.max_warning_header_count` is set to `<n>`, and similarly for the size limit.
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
It'd be "more normal" to declare this as `Writeable` and use `readOptionalWriteable` and `writeOptionalWriteable`. You've done plenty in this PR so it can wait though!
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
I think you can just blast the entire method in this case.
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
We tend to prefer `false ==` over `!` because it is harder to miss the `!`.
It's frustrating that we cannot share this code with SearchRequestBuiler.
Maybe this one too, I'm not sure.
Fine by me.
could be a instance variable, as used in all tests
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
does this need to be public and also does this class need to be subclassable
Is it right to just eat the exception thrown from the listener? At least log a warning or something.
> I have just moved code around, so this implementation is not new. Fair enough. I'd still log a warning just to help debug any mistakes in the listener. If all goes well and the listener catches any exceptions then we will never call it.
We typically do this light weight coordination on the same thread. I.e., Names.SAME . This does nothingother than spawn another bulk request. This will cause a new thread to be spawned as we don't do anything else with the bulk pool on the client. To be honest, I don't think the transport client should have so many thread pools. I'll open a different issue for that.
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
Could you make the reduction create a new aggregation instead of filling the first one? This proved to be error-prone in the past.
similar concern about in-place reduction
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
`fields = in.readList(StreamInput::readString);` I think
just saw it in the factory validation, nevermind :)
`seqno` -> `_seq_no`
Nit: `primary term` -> `_primary_term`
I think you want (soft)deleted
Nit: `seqNum` -> `seqNo`
I liked the assertion you had there that if already have a result, this one has a higher seq no
nevermind I see it was already there, then it should be ok
clarify the error message specifying what needs to be non null? the inner query...also remove empty, doesnt make sense here
alright that's what I thought too, sounds good
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
Please do not drop stack traces; `Throwable#getMessage` is an abomination.
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
I think we should return active.get() == false and also - set it if we became idle...
typo: dictionnary -> dictionary
we could pass a glob with regex:xxx to newDirectoryStream if we want
you can just use a glob here ie: ``` blobNamePrefix = blobNamePrefix == null ? "" : blobNamePrefix; try (DirectoryStream<Path> stream = Files.newDirectoryStream(path, blobNamePrefix + "*") { //.... } ```
I think it's good have 0 as an option here too? I.e., index and search a freshly opened engine ..
Yes, but replace `FileAlreadyExistsException` with `IOException` to maintain the same functionality. Sorry for saying it so confusingly before.
fair enough, leave it.
this class could be made `final`
Nit: this blank line is extraneous.
No need for an empty default ctor when the super is also a default ctor.
I know this is how it used to be, but can we make the if be more like the `masterNodeChangePredicate` name and check the the master node is not null and have changed? (we now test for a cluster state change)
You are already in `ESRestTestCase` so you don't need the to reference the class.
This seems a bit broad.
Here we lose the option to fail if an expected warning didn't materialise. Is that OK? Its conceivable some tests can be certain in their expectations of failure and we do need a way to fail when we fail to fail (so to speak).
Missing `assertAcked()` or call to .get()
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
maybe just inline this into the `planIndexingAsNonPrimary` method? I think that would be cleaner.
Nit: this does not need to be on a separate line
Typo: "temporary" -> "temporarily"
Nit: `added [{}] the` -> `added [{}] to the`
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Do we really need this randomization? seems like the wrong place to test the version created setting is working properly.
new is not possible with an older version...
Yeah, I think the problem with the test here is that we don't make sure that nothing is left in the stream after we read it. That's why we didn't catch it here.
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
yes lets do it later otherwise we have to remove setters and break things.
sure things changes now that we know for sure the target branch, that said making everything final would be better to do once we merged back to master to prevent merge conflicts here. Same with renaming XYZQueryBuilder to XYZQuery, and moving to proper getters and setters.
I think the type and queryBuilder instance members could be made final
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
I think it can be even less in tests. No one is worried about sending multiple requests there.
can we make this configurable? also 500 millis is way too small and will busy spin. I guess 10s ? (the real solutions will be to have long polling, but that will come later).
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
last parameter can be set to from.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
this curly bracket should be on the previous line
No, you are right, I didn't realize the need for api users before going through the whole changes.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
you are perfectly right Christoph, let's merge the two and keep the existing class.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
we can pass along a reason to persistence to be used as writeReason
It's currently remote controlled by the creation of oldShardStateMetadata in updateRoutingEntry. If we want to keep the optional persistence based on the previous state, we can do it directly on currentRouting have it all in one place (either in updateRoutingEntry, or replacing persistMetadata. Something like this: ``` if (persistState) { final String writeReason; if (newRouting.active() == false) { logger.trace("skipping state persistence as it's not active"); writeReason = null; } else if (currentRouting == null) { writeReason = "freshly started, version [" + newRouting.version() + "]"; } else if (currentRouting.version() < newRouting.version()) { writeReason = "version changed from [" + currentRouting.version() + "] to [" + newRouting.version() + "]"; } else if (currentRouting.equals(newRouting) == false) { writeReason = "routing changed from " + currentRouting + "] to " + newRouting; } else { logger.trace("skip writing shard state. previous version:[{}] current version: [{}]",currentRouting.version(), newRouting.version()); writeReason = null; } if (writeReason != null) { final ShardStateMetaData shardStateMetaData = new ShardStateMetaData(newRouting.version(), newRouting.primary(), getIndexUUID()); try { ShardStateMetaData.write(logger, writeReason, shardId, shardStateMetaData, currentRouting != null, nodeEnv.shardPaths(shardId)); } catch (IOException e) { // this is how we used to handle it.... :( logger.warn("failed to write shard state for shard " + shardId, e); // we failed to write the shard state, we will try and write // it next time... } } } ```
`s/shadow replicas/shadow shards/`
I usually do this: ``` assert xContentBuilder.generator().isClosed(); return true; ```
fyi - this gives you double [[]]
s/payload is/payloads are
s/payload is/payloads are
I see, so parser always sets both "order" and "mode", regardless of whether they are set by the user. But what if we only go through the java api, use a plain builder and set "reverse = false". Translated to json this should give us "mode = MIN", but only if not explicitely set by the user otherwise, no? Sorry, haven't got a good solution myself so far either.
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
Nit: `reject` -> `rejected`
ok let's leave it as is for now.
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
I think it will be cleaner to have ShardInfo have a constructor that takes all parameters and set that on the finalResponse. This will make sure we will not forget anything in the future.
We should try to take the rest status from the exception. See ShardSearchFailure
oh, the boxing horrors :)
here we could use sublists again - just scan to the place you need. No need to reverse then.
removed can just be a count. We always remove from the beginning of the queue.
If we use Collection<Tombstonre> we can return an unmodifiableCollection() which doesn't copy stuff..
can we add the serialization logic we need to the Index object it self? we're likely to use it in other places.
++ to talking this through but to put it out there, what I am thinking is that we re-build the user after the lookup. For this case we have PkiUser and LookedUpUser. The final user will be the combination of the PkiUser's metadata, the LookedUpUser's metadata, and the LookedUpUser's roles. The looked up user's metadata would trump the PkiUser's metadata in case of a conflict. This does get trickier when you do this in an AD/LDAP realm since some of the metadata comes from the group resolution. In that case, I would only include the metadata that does not involve group resolution from the authenticating realm.
Not a specific concern, but just more configuration options for the end user when it is not being that effective. The code is trivial and not of maintenance concern so I am fine with we being consistent in all cases.
Nit: Needs a blank line.
I believe `ScrollHelper.fetchAllByEntity` already wraps the listener in the client's `threadContext`.
Yes! you are right ð
ok can we rename the getter then to `getFailedNodeExceptions()`
Optional: darkon has this style that I like where you start a new block every time you startObject or startArray and it makes these much more readable!
extra space makes everything not line up!
can we use getters here like `getNode` `isCanceled`
same here these strings are only used in one place just use them directly and trash the Fields class
Can we not extend and override `StubbableTransport` like this? Ideally maybe the class should be final. It provides methods to attach lambdas for "stubbing" the behavior (although I think the method will need to be made public). The method is either `addConnectBehavior` or you can add a `setDefaultConnectbehavior`. Similar to `setDefaultSendBehavior`.
There's an extraneous blank line here.
I think that `node);` fits in the previous line
nit: extra newline
maybe we could randomize the names of the 2 settings we have in this test
I think a nicer approach (can be a follow-up done by me) would be not to call `updateGlobalCheckpointOnReplica` here, but instead call ``` globalCheckpointTracker.activatePrimaryMode(SequenceNumbers.NO_OPS_PERFORMED); ``` either here or in the IndexShard constructor (where we create the GlobalCheckpointTracker) when the recovery source is EMPTY_STORE.
I would prefer not to call `updateGlobalCheckpointOnReplica` on the `GlobalCheckpointTracker` if the shard is a blessed primary. A shard that's created from snapshot / local_store / local_shards is by definition blessed from the master. It should just activate the tracker. The activation logic for a replica can be different than for a primary.
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
Nit: `added [{}] the` -> `added [{}] to the`
I don't see NO_MORE_DOCS changing in the future. I don't dislike having NO_MORE_DOCS=MAX_VALUE, it makes the sequences of integers returned by DocIdSetIterator monotonic from -1 (not started) to MAX_VALUE (exhausted) :)
Hmm, this assertion can never fail? (NO_NORE_DOCS is Integer.MAX_VALUE). It looks like the other modes have the same issue, I think the intent was to put a "&&" instead of the "||"
can we use "script_factor" I think it's nicer than the came case
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
I'd rather have a different parameter there. However, that would add complexity. It might be better to not handle missing field or NaN and Inf at all and let the user sort it out with range filters.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
is this needed here? I think it does something only when the current token is start array or start object.
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
I might use an empty array here or switch the IdsQueryBuilder work with lists.
we should make this entire class package private and try to contain visibility here as well.
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
ok can you add alls these infos into this class
final and java docs
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
Makes sense to me. The random null pointer exception you'd get later on if this went wrong would be unpleasant to users. Probably best to use an explicit check rather than an `assert`.
can we add an assert to make sure that highlighterType != null here? it really should since we know that plain highlighter always returns true, but the assert would make it more explicit that it is expected
the == false is done on purpose to make these comparisons more explicit
thinking out loud, maybe I am getting confused, but in order for a field to get highlighted, doesn't it need to be stored too or we need to have the _source at least? but metadata fields, which match `*` are not part of the `_source` hence they need to be stored or excluded from highlighting by definition. I have the feeling we should do something more to address that...
I'd go for either check in the constructor or here.
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
Nit: there is an excess blank line here.
`if (serializedStates != null) {` is no longer needed
can we call this last seen clusterState? it doesn't need to be volatile as it is changed under a lock.
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
can we add a check for whether we sent a diff? I want to avoid a potential infinite loop.
I think this code will be simpler if we have two methods - sendFullClusterState and sendClusterStateDiff , each dealing with it's own serialization (and have the cache map passed to them). We can have sendClusterStateDiff fall back to sendFullClusterState if needed , which will mean no resend method..
`it's` -> `its`
`translogs` -> `translog's`
you can do some streaming java8 magic here.
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
nit: extra line
Same here, I think List is already initialized in L51.
I don't think we should do `__default__` we can pass the default separately...
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
lots of things here will need to be moved to the data node too once we refactor this query I think
we shouldn't need this here in parse phase
I think that makes sense. Otherwise we may throw an index not found exception if the index patterns the user is interested in does not yet exist.
I don't think this should have been changed
lets revert this. We do not need it here
Is this an oversight? `DEFAULT_KEEPALIVE_SETTING.get(settings)`
can we fold this into ClusterHealthResponse? that way we can test this as well as part of the unit testing.
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
Because a processor may also be wrapped by other processors with on failure definitions.
I like `hasSize` better for this because it gives a nicer error message on failure.
same as above, no need for try catch
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Autoboxing already happens and I wouldn't worry to much about it considering the depth is not that big. Same for `Linked` vs `Array` (in general arrays are faster except for inserting in the middle as that requires resizing/copying at which the linked structure excels). I think the `Tuple` makes the code a bit more compact and safe (the queues cannot get out of sync) and more readable/simple code always trumps optimization (especially micro ones as here).
Since the index and the Map are associated, how about using only one `Deque` which holds a `Tuple` instead of two `Deque`: ``` Deque<Tuple<Map<String, Object> index>>` queue = ... if (node instanceof Map) { queue.add(new Tuple<>(node, Integer.valueOf(i)); } ```
are we sure we want to silently go ahead this way when templateService is null? Maybe we should fail so that we find out when it happens, unless it's situation that is actually expected to happen.
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
I wonder if this should rather be made part of Request#multiSearch like we did for bulk. I see that it may be nice to have read and write methods close to each other, on the other hand the only place where we need to write this format is in our client.
can't we just call this feature `trim`? `trim` personally makes more sense to me.
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
maybe wrap all these maps in `Collections#unmodifiableMap(...)`? To enforce that no changes can be made.
+1 then we shouldn't forget about it :)
we should totally not have this method, one more reason to not implement the interface.
Set capacity to `2`
this deserves a sep issue I guess but good catch
Shouldn't this check instead be: `if (!(obj instanceof SuggestionBuilder))` Because sub-classes of this class will call its equals to test the equality of its specific private fields.
Should we initialize indexBoosts to new ArrayList<>() straight-away instead and remove this null invariant? This if would go away too.
Can you use StreamInput#readList ? You need to check for the version here since this code can receive requests from nodes in previous version. Something like ````if (in.getVersion.onOrAfter(Version.V_6....)````
This should be the version we are going back to, so 6.5. In this PR, disable bwc tests in the root build.gradle file. Then re-enable in the backport, and do a followup to master to re-enable there as well. This minimizes the changes necessary to followup to master (instead of needing to remember and change all the places that have this version constant).
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
I think it's odd to have a public constructor for a test only... remove the OriginalIndices parameter at least? it's always set to null I think.
I think we discussed this before, but it didn't change, thus I'm bringing it up again ;) can we add a constructor that accepts `shardInfo` as argument and change the subclasses constructors to accept it there, just to enforce that this info is needed so we don't forget it anywhere. Maybe then we could also remove the setter...
I see some places where null is not protected against...
I didn't check but unittests for this would be awesome!
could we implement Writeable rather than Streamable? (Writeable is supposed to be a replacement for Streamable if I'm not mistaken)
nit cat we explicitly call the other constructor with null? i.e., `this(null)`
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
same - please name it something like `explainOrThrowRejectedCommand`
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
see text from other suggestion for empty primary allocation
is it an option to make this method package private? Then it would become more of an internal thing. Thanks for addressing this!
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
Exception e = expectThrows(Exception.class, () -> doSomething()); assertEquals(e.getMessage(), containsString("bla"));
I tend to like expectThrows better for doing this.
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
I think it'd be nice to have this in :test:framework so others can use it.
Probably worth putting an explanation in here.
Maybe explain that it is used in places where you want to make sure that scripts are valid but don't care about the specific script and this is the easiest way to do that.
Looks like there isn't an ExecutebleScript equivalent for search scripts anyway - ignore this.
Talked with @cbuescher in a chat - since these are just copied from their old place they should probably just keep their implementation in this PR. Moving to test framework is still possible in this PR.
I guess it could be renamed to isFalse() / isTrue() now
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I don't believe this is only kept for BWC. You use this to parse `_source` above.
This can be replaced with ``` java boolean isTrue = isExplicitTrue(value); ``` similar to the previous example
I think it would be cleaner to set translated outside of the if statement. ``` boolean translated = incorrectOrientation && rng > DATELINE && rng != 360.0; if (translated || shellCorrected && component != 0) { ... ```
Needs a guard.
Ah yes, thanks!
I think this message should be a bit more clear. Can you include: - the path - the supportedAttributes - some explanation about what attributes we're looking for It can just be `"Don't know how to make file {} non-readable on a filesystem with attributes {}"`
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
Yes, I would ditch DOS (as you have done). I don't think we run any CI on non-ACL aware platforms. If it turns out we do, then we should just do an `assumeFalse` as the test is not possible on that platform.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
do we want to unify this with nodeIndexDeleted? I think it's better to have this called once the store is deleted in IndicesService#deleteShardStore .
can we sometime just rely on the wrong allocation id? (and have a valid node)
using ActionListenerResponseHandler will simplify this lightly.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
Throw the exception here
Just a formatting issue here. Add a space before the curly bracket: ``` java if (cannedACL == null || cannedACL.equals("")) { ```
Same formatting issue as below
Forbidden API: ``` Forbidden method invocation: java.lang.String#toUpperCase() [Uses default locale] in org.elasticsearch.cloud.aws.blobstore.S3BlobStore (S3BlobStore.java:204) ```
Ok, thanks for this precision.
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
do we want to check listener.isDone? (because it is supposed to return immediately). get() waits.
can we add that to ClusterStateCreationUtils? It might be useful for others as well
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
So, this could be simplified to `assertFalse` Or could be something like the following (which admittedly, is probably less simple) ``` import static org.hamcrest.CoreMatchers.everyItem; import static org.hamcrest.Matchers.greaterThanOrEqualTo; import static org.hamcrest.beans.HasPropertyWithValue.hasProperty; ... assertThat(response.records(), everyItem(hasProperty("recordScore", greaterThanOrEqualTo(50)))); ``` Man, that is frustrating that hamcrest does not support just passing a lambda as a type of matcher :(
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
If you want to test the multi-write behavior you could make a testing aggregation here that needs to be rewritten twice. I'm not sure how important that is to you, but it ought to be possible.
Can we fold all these assertions into a single one? I think this should cover enough. ``` assertThat(shardChangesRequests, contains(new long[][]{ {0L, 8L}, {9L, 8L}, {18L, 8L}, {27L, 8L}, {36L, 8L}, {45L, 8L}, {54L, 8L}, {63L, 8L} })); ``` Moreover, the leader should not return more than the requesting batch size. Here, we request 8 operations, but it returns 9 operations.
count > 0? just being paranoid :)
Looks like the max is still here for time stamps? maybe assert it's -1 (for both seq# and timestamp)
`s/Class<C>/Class<? extends C>/`
I don't think we either but I know some folks like them so I certainly don't object to them.
Nit: `if(` -> `if (` (whitespace)
maybe put this check before the primaryTerm check
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
can the aid matching be the implementation and the rest just assertions ? it should be enough
can we not wrap a translog but rather just keep this test translog next to the normal one? keep it simple and readable :)
`String.format(Locale.ROOT, "%s operation term [%d] is too old (current [%d])", shardId, term, primaryTerm)`
maybe call this "resolveSnapshotNames"? I would also prefer to use `List<String> snapshotNames` as parameter to bring it closer to the return type.
Maybe just rename the method to `snapshotShard` or something. I know it takes the IndexShard, that that really helps.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
It'd be more helpful to me if these notes were on the method if we're going to mix them together like this. Another option would be to have two interfaces implemented by one class. I'm not sure that helps at all.
Forget the two interfaces idea. Just renaming the methods'd be good enough for me.
`s/Class<C>/Class<? extends C>/`
`s/Class<C>/Class<? extends C>/`
It's not a big deal, but I liked that it allows to - make StreamInput not depend on NamedWriteableRegistry - stack registries: you could stack registers on top on each other, while the current approach requires that you provide a registry that knows about all namedwriteables at once. I don't have use-cases in mind, but thought this could be useful.
one too many whitespace between List<C> and the method name
++ thanks Nik
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
this code and the code in `SearchPhaseController#sortDocs` is almost identical. I think the only difference is the assignment of the shard ID. Maybe we can factor this out into a static method and use it in both places. It would be good to redcue the duplication on such a level and it would increase the test coverage. I would be in favor of that.
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
unrelated but maybe we can clean this further up and rename `matchedQueries` to `setMatchedQueries` and make it use a List instead of a String array.
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
thanks for checking, that is fine then
we may have a small problem here, when toXContent is called on an object deserialized from a previous version that didn't send the _id .
if it prints out null it may be ok, if it gives NPE we need a null check, that's what I meant.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
I think checking for newline is better than relying on pretty printing having space between key/object...
I would really just check for newlines.
Shouldn't this be equal to the `jsonBuilder().string()` above, without adding `.prettyPrint()`? And a nitpick: please add a space after the comma..
same here don't do the pretty printing please
What happens if `enabled` isn't set? I *think* we should continue to do nothing if `enabled` is actually true.
This one also uses a Java 9 method.
This one has the same problem with java 8.
do we need ordered things? does order help anywhere? If not I would just use HashMap
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
do we need this Reader interface? can't this just be `Funciton<StreamInput, T> reader`
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
if we only use all names to put things in the map we lose all the deprecation warnings that we might have etc. we should rather keep track of the original ParseField and call ParseFieldMatcher#match.
just my personal preference, I don't like instanceof checks that's it. you are free to leave them if you prefer them ;)
I think if we get in that other PR I just reviewd we can reuse here the new method that you introduced there? :)
as I mentioned a million times now, when we will say let's not use it and remove it everywhere I will stop whining about it. I don't want to see three methods with annotations and one without it, it hurts my eyes. Either with or without it, not in the middle, at least in the same test class.
can we call it testNoInnerQueries? I would like to avoid confusion with our nested query (nested type) here
we should `@Test` to forbidden API
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
make it final
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
`min` can be named `simple` or `aggregation`
This should be a `ConstructingObjectParser` so that the private empty ctr can be removed.
we should include `e` here, otherwise we lose the cause of the configuration error.
please log the exception here as well we really wanna see what was going wrong
Writeable#readFrom returns a new instance of the object, it allows to have final fields, but it requires to have a PROTO instance of the object to call readFrom against. I wish there was an interface to declare writeTo only though but we don't have it at the moment.
Doesn't PipelineConfiguration deserve its own class file under o.e.ingest ? It's returned by the java api too.
nit: wondering if we can avoid parsing the map and rewriting it directly in json format. not sure there's a better way to do this.
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
maybe have a helper method since the logic below does that though...
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
this made me worry we don't log these failures anymore.. In this specific case I think we are best to just let the exception bubble up, but it does raise a more general issue - if people put exceptions in the builder, it's their responsiblity to report it. we should probably add something to the internal cluster service to auto log it.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
I prefer my way but have asked @jasontedor to chime in.
// must use exception that is not **ignored by** replication logic. (also 2 more occurrences of this in IndexShard)
maybe put this check before the primaryTerm check
same here re enumSet.toString
we throw the exception and thus take care of the interrupt. We don't need to set it...
can we have two static helpers that allow to create the processor either providing the Client or the RestHighLevelClient ? I am thinking of users, there are many existing usages of BulkProcessor out there. I may be ok to change the way it gets created, but as a user I would be surprised to have to pass in a method reference. That should be more of an implementation detail.
I may have forgotten, but what has changed here compared to the startFlush method? We don't call daemonThreadFactory as we dropped the name and settings requirement for logging right? I wonder if we should still call that and just provide the standard "bulk_processor" prefix.
got it thank you.
probably `new ThreadPool(Settings.EMPTY)` :) I wonder if the helper could hide the creation of the thread pool even, maybe not, but we will see that later. As you pointed out it may be that the helper is not needed at all.
I think I would consider taking settings out. We try to extract node.name from it as far as I understand, which I don't think is ever going to be set on a transport client. Maybe we can just live without that part of the thread name and remove some complexity. This may very well come from the times where node client was widely used, hence node.name made sense in the past, but it doesn't anymore.
we could pass a glob with regex:xxx to newDirectoryStream if we want
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
I dont have a good answer for this yet. While we can totally test this, the value in the server -> client.fromXContent is greater than just testing the client.toXContent -> client.fromXContent. I think these kinds of tests are not really providing much value, and we also test the former in the IT tests.
Do you need this? I dont see it being used anywhere.
I think we can check the beforePart == null out of the if(!..equals) and it will make it cleaner.
I think we prefer not to use underscores as part of method names, camel case is better
Why not use the dedicated get aliases api? IndicesAdminClient#getAliases()
- do we need to `new`-up a distinct `SSEAwsKeyManagementParams` each time `S3BlobStore#getSSEAwsKey()` is sent? Can we instead `new`-up one in the constructor (e.g., is `SSEAwsKeyManagementParams` externally mutable?) - from what I can tell, this and `S3BlobStore#serverSideEncryptionKey()` can be _package-private_; exposing public accessors on encryption keys is unnecessarily risky.
Maybe we could call the remaining equals() implementation in the query builders slightly different? When I read this code and don't know about the abstract superclass, this might look a bit odd since it's doesn't really overwrite the canonic equals() but it sort of looks like it does.
I think we should do this even if we use docvlaues? I think we should have consistent slicing no matter how it's done!
please fail if vals.length > 3
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
Gotcha, thanks for the explanation!
ok cool then we need to fix this place? https://github.com/elasticsearch/elasticsearch/pull/3953/files#diff-79371c2235df5580ddc99db30932bea5R89
the utility should be a static class
this file needs formatting
sorry but we have to find other solutions for this than using these injection providers. We can't sustain this kind of software engineering here.
I'm fine with leaving it, yeah. I did want a prettier one but if this is what we can do, it'll do.
I talked with @costin earlier about this - he wants to keep the order the same and my proposal doesn't. What about this? ``` while (result.size() > 1) { ListIterator<Expression> itr = result.iterator(); while (itr.hasNext()) { itr.add(combiner.apply(itr.remove(), itr.remove())); } } ``` Your version works but `for (int i = 0; i < result.size() - 1; i++) {` make me think it'll be a normal loop and then you remove and add and I'm confused. Using the `ListIterator` forces the reader to think.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
Here you can do `if (function() == SUB && r.isDateBased() && DataTypes.isInterval(l))` (`r` and `l` are already defined above).
The type check should happen inside SUB not in its parent class...
Actually I just checked and removing name and description from the Plugin interface should be easy. The only thing to think about is what to give for those properties when plugins are loaded from the classpath (plugin.types). I think here the name should just be the classname, and description something like "plugin loaded from classpath"? I don't know what other info we really have.
Also, can you add an element to maven enforcer plugin for plugins/pom.xml so it fails build cleanly and early if this property is not set? We should also insert a check in pluginservice, if it differs from the directory name, someone manually meddled
We should also check the name matches that in jvm plugins. As a follow up, we should at least remove description from jvm Plugin interface, and possibly also name (possibly a little harder, just requires passing around PluginInfo instead of Plugin I think).
This file is new in 2.0, we can change it
Now the logging here is really "fun". Maybe pull the pluginName to the top and use it in the []s. I'm trying to think through what this will look like for the temporary directory versions. Maybe it makes sense to make the whole temporary directory thing a more first class citizen - like a field or a subclass of this rather than just passing in randomness.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
can you add a //norelease here too? context should really go away after all queries are refactored
Ok, then it's fine.
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
we should remove the iterator in this case. I would just do: ``` if (indexRoutingTable == null) { iterator.remove(); continue; } ```
Nit: spacing between `while` and `(`.
Nit: spacing between `!` and `value`.
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
I would add an `assert this.context != null` here just to make sure
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
+1 to have `fromXContent` and `parse` be static
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
I'm not a big fan of ActionListener<Void>? Maybe we can do this differently and replace it with two functions? Runnable for the onResponse() part and for onFailure use a Consumer.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
please log the exception here as well we really wanna see what was going wrong
But that means the pipeline can never be used again (it is now closed).
I think this is confusing if we support camelCase in some of the options in this parser and not others (even if they are new). We should either support camelCase for all options or for none to be consistent.
I am only talking about the date formats here, not across the whole codebase (i can see the above statement might have been a bit ambiguous on that). All the multi-word date format values above support both a camelCase and an underscored version. That should be consistent, whether that means supporting both for now or only supporting the underscored version I don't have a strong opinion but its hardly a huge change to update the date format values to be consistent and its not a huge overhead to maintain an extra 2 camelCase options given that any change to that policy would require a change to all the other date formats too
I don't think it matters. We should not force making huge changes to the entire codebase in order to not add things which will just be deprecated and/or confusing to the user.
I would also be fine with removing all the camelCase options for all formats in this PR to make it consistent.
I just realized we aren't even talking about setting names, but the valid values for the `format` setting. This argument to use ParseValue does not make sense. We don't support camelCase in eg the `index` option. We should not do it here, it will just add more work for users if we allow them to _start_ using a new value that will just go away in the future (and will require them to change the value to what they would have found in the first place if they had tried using camelCase and seen an error).
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
This is similar to the internal implementation, nice
Misspelled in the \@param tag also
excude_interim - missing 'l' -> exclude_interim
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
maybe add more docs like `between(2, max)` and use `indexRandom()` so you get holes in the segments ie. del docs. Then you can can randomly set the threshold `between(2, max-1)` etc.
can we configure the delayed allocation to not be the default (`1m`) but something high enough to trigger what we are trying to fix, like `200ms`? This will speed up the test.
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
can we add bogus non relevant settings? Would be good to know they don't mess up with things.
just FYI - you can do setSettings("index.number_of_replicas", 0)
nit: `an` -> `a`
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
I think it's confusing that the WriteReplicaResult flow is different than WritePrimaryResul. i.e., `finishWrite` is called in the constructor for one and in the respond method for the other. We should try to make them the same as far as possible.
Nit: `reject` -> `rejected`
Typo: "Dynamics" -> "Dynamic"
here too, toQuery might return null, not sure what happens
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
as I mentioned a million times now, when we will say let's not use it and remove it everywhere I will stop whining about it. I don't want to see three methods with annotations and one without it, it hurts my eyes. Either with or without it, not in the middle, at least in the same test class.
:) good catch
do you think that it would be possible to have two different test classes, one for the xcontent bits, that doesn't rely on equals/hashcode , and the other one like this on that we have that tests serialization and ordinary equals/hashcode ? Let me know if I am missing something.
s/to list of/to the list of/
Does this need to set `change = true` also? It's missing from this `if` block
As well as the default buffer size
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
Do we need this? the settings are already immutable
now I see why `QueryParseContext` here too. we should probably split the QueryParseContext in two data structures, one needed for parsing and one needed for toQuery (e.g. mapping etc.)
looking deeper, I see that we set a non null TermsLookup object only when we have it in query, which causes a validation error when values are set too. We should keep it that way then, this is as good as it gets.
I meant that other way around, not in the else, set termsLookup only if values == null
you can remove the validate call for now, we will fix all queries soon, I promise
This line is called multiple times as we keep adding indices. It could be called once at the end of the loop I guess.
this smells like it should be a setting validation thing. Testing for this so deep, on every request without throwing exceptions feels wrong.
nit: use assertThat(...) with isNull() as matcher instead? I think in general that is the preferred way of writing test assertions.
if the size was previously less than PAGE_SIZE_IN_BYTES (possible with the contructor that exposes a size), this will actually grow the array (potentially going from a simple heap-allocated byte[] wrapper to a recycling instance)
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
is this a leftover? I don't see where this is used outside of tests? and even there I think it's a huge overkill. Can we please remove this entirely. If you really need stuff like this for testing then look at `ThreadContext#setTransient` which you get from a threadpool
can we rename this to `boolean isCanceled()` and then instead of the exception just return a boolean? I think it would be more intuitive and we really don't need yet another exception
This is why I do not like `assertEquals`; this is backwards from expected and actual. Instead: `assertThat(t1.v1(), equalTo(2L))`.
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
can this see `unregister task for id: [{}]`
I think I miss something here because I think we need it for now but not in the future after we have a Lucene rollback. I will reach out to discuss this.
We have dedup in this PR already (line 161-163). The `lastSeenSeqNo` is used for dedup and range check. I am fine to remove the primary sort and dedup mechanism.
As discussed - this should be needed in the future. Maybe we should remove it and instead assert that we never have duplicate seq#
@bleskes I moved this to `next` but we also need to dudup for nested docs then I moved this to `readDocAsOp` again. I think we should optimize for nested docs. I am open to suggestions here.
I will make it in a follow-up.
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
ok let me have a look then ;)
It might be cleaner and create less new-Function objects if you extract this compute block as a new method, say "newIndexFieldDataCache(fieldName)", then just do `fieldDataCaches.computeIfAbsent(fieldName, this::newIndexFieldDataCache)` here.
alright - didn't see it immeditately
also, the setting should be using `componentSettings.get("page.limit", ...)`, so it will resolve to `cache.recycler.page.limit` (and I think the in_bytes usage here is not needed).
Indeed, I think two BytesReference instances should be considered equal if they have the same content (which is what the way other children of BytesReference are implemented suggests). My point was this path of the equals method ignores the offset of `other` (it starts comparing its bytes at `0` instead of `other.offset`.
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
is this correct? this will return a copied array if offset > 0, yet the `arrayOffset` method will return the offset into an array that has offset 0... .
I think we should return the BytesRef array we get from reading from byte array, and `arrayOffset` will use the same logic, and return the offset form the BytesRef
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
Maybe something like: The bucket can "overflow", in which case the excess capacity is just "spilled", rather than saved up. So it never holds more than a minute's capacity.
I'd mention the name of the setting that controls the limit in the error message. I can imagine needing this desperately. I'm honestly really hoping no one sees this for the first time in production, but I know some people will.
It might be a good idea (possibly in a different PR) to have a method on `ScriptEngineService` called something like `getSupportedScriptContexts()` which each implementation can use to define what script APIs they support. I imagine there are/will be other language that don't support some script APIs and this would not only allow them to use this too but would also remove language specific code form the ScriptService, which should probably remain language agnostic.
Ok fair enough, Hadn't considered the settings aspect of this.
Er - if you are going to log something then it doesn't matter which order you do it I guess.
same here - since we have on onFailure handler, calling is the equivalent of re-throwing the exception, imo.
+1 to throwing the exception.
This should be `== false` right? otherwise we will warn if the latch _found_ a state
What is the reason for not just using the timeout on the observer? ``` diff diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java index c8eb8a4..29a11d9 100644 --- a/core/src/main/java/org/elasticsearch/node/Node.java +++ b/core/src/main/java/org/elasticsearch/node/Node.java @@ -336,14 +336,12 @@ public class Node implements Closeable { @Override public void onTimeout(TimeValue timeout) { - assert false; + logger.warn("timed out while waiting for initial discovery state - timeout: {}", timeout); + latch.countDown(); } - // use null timeout as we use timeout on the latchwait - }, MasterNodeChangePredicate.INSTANCE, null); + }, MasterNodeChangePredicate.INSTANCE, DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings)); try { - if (latch.await(DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings).millis(), TimeUnit.MILLISECONDS) == false) { - logger.warn("timed out while waiting for initial discovery state - timeout: {}", DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings)); - } + latch.await(); } catch (InterruptedException e) { throw new ElasticsearchTimeoutException("Interrupted while waiting for initial discovery state"); } ```
The message doesn't really make sense because it's missing the "discovery state" part, right now it says it timed out waiting for initial timeout :)
can this also be `IndexingOperationListener... listeners` please
I don't think there is any need to keep `META_FIELDS`, and this is incorrect do both because `META_FIELDS` is static right now (so should not be initialized in the ctor) and because it leaves the incorrect values there now. `META_FIELDS` should be removed completely, and the methods that use it should instead pull the keyset from `mapperRegistry`.
these can go away if we cut over to a `IndexingRequestListener...`
can we pass a reason to this method and mention it here? I always to scroll to find out whether this is a "true" index or just one that was created when importing/creating one.
master is the future 7.0, so I would do the following: ```java if (INDEX_MAPPER_DYNAMIC_SETTING.exists(indexSettings.getSettings())) { if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0)) { // 7.x index throw new IllegalArgumentException("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " was removed after version 6.0.0"); } else { // 6.x index DEPRECATION_LOGGER.deprecated("Setting " + INDEX_MAPPER_DYNAMIC_SETTING.getKey() + " is deprecated since indices may not have more than one type anymore."); } } ``` Then when backporting I'll just remove the 7.x branch and make sure that we only emit a deprecation warning on 6.x indices (you don't need to worry about it).
I mean random number of replicas with random combination of non-active states
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I think we can check also randomly on a shard that relocates _to_ the local node
this can be removed now
do we want to check that the shards were actually failed? Ideally we would just check that the allocation service was asked to fail them. Mockito maybe helpful? I don't want to hold you back for this though...
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
Does this message go back to the end user? If so the fact that a map must be empty is more of an implementation detail than an meaningful error message for the end user. Something like "Mapping definition for field X has unsupported parameters: foo, bar" would be more appropriate.
Can you use `== false` here...the `!` is almost hidden in all the other text around it...
nit: missing a space after the first comma
I think we should not just ignore when something else than a map is provided? Maybe we could do something like: ``` java } else if (propName.equals("fields") { final Map<String, Object> multiFieldsPropNodes; if (propNode instance of List && ((List<?>) propNode.isEmpty()) { multiFieldsPropNodes = Collections.emptyMap(); } else if (propNode instanceof Map) { multiFieldsPropNodes = (Map<String, Object>) propNode; } else { throw new MapperParsingException("Expected map for property [fields] on field [" + multiFieldName + "] or [" + type + "] but got a " + propNode.getClass()); } } ```
I think we _do_ need to consider BWC for these lists. If you look at the implementation of `readList()` and `writeList()` they start by reading/writing the list length. So we need to write an empty list to versions before 6.5, and read a list of something. We can replace `PartitionScore::new` with a function in `Bucket` that reads the same stuff that `PartitionScore::new` read but just discards it.
That is true for when there is a transport client which I didn't think of at the first place. So, yes, we'll need to do the trick of reading the scores. There is another place where I'm doing this: https://github.com/elastic/elasticsearch/blob/6.x/x-pack/plugin/core/src/main/java/org/elasticsearch/xpack/core/ml/job/config/Detector.java#L253. You can take a look and follow a similar approach. Note we only need that code in the `6.x` branch.
this needs to be fixed before merging (as it should go to 5.2.1).
I think it would be easier to reason about it it was expressed as something like ``` if (clientVersion.before(Version.V_5_3_0)) { ... } else if (clientVersion.before(Version.V_5_3_3)) { ... } else { ... } ``` There is also no `else` after this statement, which means we write ord twice... And if tests don't catch this, we might need to figure out how to write a better test that would.
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
one too many whitespace between List<C> and the method name
It's not a big deal, but I liked that it allows to - make StreamInput not depend on NamedWriteableRegistry - stack registries: you could stack registers on top on each other, while the current approach requires that you provide a registry that knows about all namedwriteables at once. I don't have use-cases in mind, but thought this could be useful.
`s/Class<C>/Class<? extends C>/`
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
`s/Class<C>/Class<? extends C>/`
yes I would at this point. it's a remote connection to another cluster that may be at a different location etc.
should we call the field `socket_timeout` ? Will we want to add `connect_timeout` too in the future? I think timeout is very generic so we may want to be more specific.
maybe just `esVersion()`
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
we should assert this is never called (same for the other places here where `UnsupportedOperationException` is thrown), as this indicates a bug.
I think this should be an `assert false;` + throw new UnsupportedOperationException
something like this: ```Java public SearchOnlyEngine(EngineConfig config) { super(config); try { Store store = config.getStore(); store.incRef(); DirectoryReader reader = null; boolean success = false; try { this.lastCommittedSegmentInfos = Lucene.readSegmentInfos(store.directory()); this.translogStats = new TranslogStats(0, 0, 0, 0, 0); final SequenceNumbers.CommitInfo seqNoStats = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(lastCommittedSegmentInfos.userData.entrySet()); long maxSeqNo = seqNoStats.maxSeqNo; long localCheckpoint = seqNoStats.localCheckpoint; this.seqNoStats = new SeqNoStats(maxSeqNo, localCheckpoint, localCheckpoint); reader = SeqIdGeneratingDirectoryReader.wrap(ElasticsearchDirectoryReader.wrap(DirectoryReader .open(store.directory()), config.getShardId()), config.getPrimaryTermSupplier().getAsLong()); this.indexCommit = reader.getIndexCommit(); this.searcherManager = new SearcherManager(reader, new SearcherFactory()); success = true; } finally { if (success == false) { IOUtils.close(reader, store::decRef); } } } catch (IOException e) { throw new UncheckedIOException(e); // this is stupid } } ``` I did something similar a while back so I had it ready... I am not sure it safe to use ð¯
newline, also no need to write `throws EngineException`
newline also no need to write `throws EngineException`
Pls be sure this is not null. Other converters do a null check and return and give this `addCommaSeparatedPathParts` a empty array if need be. check `forceMerge` for an example
no need for extra space
we also support a parameter called `updateAllTypes` here.
`.addPathPartAsIs("_xpack", "rollup", "job")`
given that the request goes through validate first, I think we could remove this assertion, this is already checked in as part of validate which will throw an error otherwise.
the dollar sign option :)
should these be private? not sure who is using it...
again, this is the reasoning: if we check for existence of a field in the parser, it means that the only way it can be null in the builder is when it comes in through java api. In that case we might want to fail fast and throw error in the constructor/setter already rather than in validate. If non validated values might come in through the parser as well then validate is the way to go. In this case it makes to do as Christoph suggested. In term query builder I think it still makes sense what we do (again, you can test it to see the differences), same for common terms query.
which other queries do you mean? You mean check against this specific field in similar queries or just in general. I think the question is "when can this happen?". If stuff can happen in both java api and rest layer, validate is the way to go. If we already perform some kind of validation that makes sense in the parser, then having null here can happen only from the java api and we should maybe try and fail straight-away.
Why remove it? I was adding them because I thought it was nice to mark the constructors for anyone unfamiliar with Elasticsearch. It'd help them get their bearings.
In the other tests that are migrated to use Zen2 we set this to `true` (i.e. we are not testing the Zen1 case any more). I think that's what we want to do here too, but in any case we should be consistent about this.
seems like this is not needed anymore given that we don't go through InternalSettingsPreparer anymore? sysprops will always be ignored I think
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
but, it seems we look for an hexadecimal number? (which is OK because normal long are also parseable as hex, but you know, pedantic)
> but then if that's the case I wonder, how do we test that the setting is not really needed, cause it shouldn't be? :) @javanna imo this should be a pre-release smoke test.
People don't know what archiving setting means. They just upgrade and their end up in an illegal state. I think it will be cleared not to mention the "can't be archived" part. But as said - just a nit, not a big deal.
Also- I traced the code and as far as I can tell, in the case of `index.number_of_shards` we never say which index was problematic? I think it's important to add that info..
Nit: `get's` -> `gets`
Nit: `if(` -> `if (` (add space)
I think that will fail compilation? ð
You can do this directly on the member variable: ``` private final CharTermAttribute termAtt = addAttribute(CharTermAttribute.class) ```
This should only be done in close()
I just want to remark that this is working differently to the `query_string` parser. In the `query_string` the default locale is used which I think should be an option on the query for both of them You might want to open a new issue to fix that or add it here already and then open a new one for the `query_string`
I am not sure if we should keep this analyzer - I think we can just use the `PrefixTokenFilter` by itself and move it somewhere in the completion namespace. Yet I think we should have some dedicated tests for this that use `ElasticsearchTokenStreamTestCase` there are some awesome helper methods that can find a lot of stuff that is not correctly set in the `TokenStream`.
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
To be clear - I think we want to know how the oldest file is, regardless of the generations. It will always be the oldest generation and the first in the reader list, but I don't think we want to rely on it. Part of the role of the stats is to validate things are correct.
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
why did you change this to take a `TranslogGeneration` with the uuid instead of just the `long minGeneration`? It's not using that uuid anywhere here AFAICS.
Can we add a Math.max(0, currentTime - Math.min()) ? we rely on this being non negative, but time may go back and the FS may have other quirks.
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
this one ends up sending parameters that are getting ignored, see `IndicesOptions.fromMap`. we should remove the last three parameters. This should be cleaned up, the problem is that some indices options are settable at REST, while some other are internal properties that define each API (the default argument in `fromMap`) which cannot be changed, so they should never be printed out nor parsed back.
We should be writing out the settings in the "new format". There is no longer index_analyzer. So in the case of search_analyzer being set alone, when we serialize, we should write both analyzer and search_analyzer.
we are using a mocked service, we can retrieve the generated values through the mocked service I guess. Even pre-generate random values when the service is created. I think that would be already better than returning index, type etc.
It feels wrong that hashCode is using writtenBy while equals isn't
As Boa mentioned before we would need both a default to print out, and a boolean that tells whether the current value is default or not, as the `currentValue != defaultValue` is not enough. Something like the following should help in most cases I think? ``` public static void maybeAdd(XContentBuilder builder, String key, Object value, Object defValue, boolean isDefault, boolean includeDefault) { if (value != null || !isDefault) { builder.field(key, value); } else if (includeDefault) { builder.field(key, defValue); } } ``` That said, maybe it doesn't cover 100% but 90% of the cases, and for the 10% left we can still have the custom if? In my opinion it doesn't need to be perfect but still better than copy pasting that `if` so many times.
I'm okay with `foo.backup`. It would also not be hidden from non-Windows users by default.
@dadoonet I don't think it complicates things that much.. it's just traversing the file tree... and yes... sub-folders need to be supported as well. so if you see a folder with the same name/path in both places, recursively merge the two by adding the new files and skipping existing ones. I'd also argue that if in the es plugin config dir there's a file that doesn't exist in the new plugin dir structure, then rename it to "<original_file_name>.<original_extension>.old" (or something like that).
It'd be better, to only skip the config files that have the same name, not the whole directory. So for example, if currently es has a config dir that looks like this (for plugins `foo`): ``` /config/foo/bar.yml ``` and the new plugin that installs needs to copy two files there: ``` /config/foo/bar.yml /config/foo/baz.yml ``` we'll skip `bar.yml` but we'll still copy `baz.yml`. This will help us a lot when we guide the user on how to upgrade - instead of telling the user, to copy & modify a bunch of files, we'll only need to tell him to modify files under `config/foo`
Would it be easier to copy the old config to somewhere else, then replace it rather than trying to mix adding new files while keeping old files? I feel like this will be very confusing for users, especially if `file1.yml` had changes coming from both directions.
Feel like this should be more significant than `debug` because it really indicates a form of failure in some scenarios.
I _think_ that you can get away with just letting the exception bubble up and RestController will send it to the user. You won't get the error log but I'm not sure logging an error on 400 level parse errors is a good thing in the long run anyway. I try to usually run requests with `error_trace` on them so we don't eat the stack trace....
you need to generate two errors for this to test what you want :)
Actually, ignore this, the rest actions are actually just forwarding to the transport actions
I am surprised that we don't have a default impl for this :)
Change to Throwable.
nit: can you assign `event.state()` to a local var
we should also have messages here in this assert
future note - once refresh mapping is gone, we should inline this with index creation.
applyDeleteIndices -> deleteIndices
Sure. This one is more than good enough :)
Also, you dont necessarily have to change this but you can now replace `.execute.actionGet();` with just `.get();`
nit: missing space
Yeah - I'm sure that is what happened. Ok - cool with me!
Btw, you don't necessarily need to use a jsonBuilder here, you can just do `setSource("text","parent")`
if you use here `refresh();` from the base class we also make sure we get back no failures.
+1 on the closed indices use case. Good catch. I'm not sure it has effect now. Did some sniffing and we close the shards in too many places upon index close. First place in `IndicesClusterStateService.applyDeletedShards`, then we have another iteration in the beginning of `IndicesClusterStateService.applyCleanedIndices` : ``` for (IndexService indexService : indicesService) { String index = indexService.index().getName(); IndexMetaData indexMetaData = event.state().metaData().index(index); if (indexMetaData != null && indexMetaData.state() == IndexMetaData.State.CLOSE) { for (Integer shardId : indexService.shardIds()) { logger.debug("[{}][{}] removing shard (index is closed)", index, shardId); try { indexService.removeShard(shardId, "removing shard (index is closed)"); } catch (Throwable e) { logger.warn("[{}] failed to remove shard (index is closed)", e, index); } } } } ``` and only then we do `indicesService.removeIndex(index, reason);` which closes the index (but it has no shards any more..)
or "failed to close store on shard removal"
Closing the store doesn't necessarily mean the shard is being deleted, I tested this and this codepath can happen when the index is closed, so I think this should be "failed to close store on shard closing"
Out of curiosity, why create a class for this instead of an anonymous class in `IndexService` capturing the local `shardId`? There are no other instantiations of this class other than the single one
should we catch exceptions here to make sure we cancel everything we need
if the argument name is `failNoIndices` you should provide `! indicesOptions.allowNoIndices()` as argument
I see your point on changing the name, that makes sense cause allowNoIndices != indicesOptions.allowNoIndices
if the argument name is `failNoIndices` you should provide `! indicesOptions. ignoreUnavailable()` as argument
Java docs says ResourceNotFoundException
it's fine to remove it
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
I think that these log parameters are backwards.
I like this much better!
I _think_ you can do `XContentParser::mapStrings` above instead of having this method.
I think s/lang/defaultLang/
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
Could you move `writeTo` up here? It is easier to compare them if they are together.
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
I think this check does not add much (I would skip it)
maybe make this variable final? just better indicate it will never change
maybe, to be more precise, it would be good to check the partition that included the new primary.
maybe 7 indices with 50 docs is a bit too much (= slow test), let's reduce randomness to 3 indices, each max 2 shards, and 10 docs.
can we init this with `1`
well maybe you don't like the success pattern though... but I think it should be closed even on Throwable
can we hide `shared.refcount` behind a method ie. decRef() / incRef() to be consistent with other stuff
> I have just moved code around, so this implementation is not new. Fair enough. I'd still log a warning just to help debug any mistakes in the listener. If all goes well and the listener catches any exceptions then we will never call it.
Is it right to just eat the exception thrown from the listener? At least log a warning or something.
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
Do we need this? the settings are already immutable
I think this should be done via IndexShard#failShard (which can be exposed via indexShardReference ). Will be cleaner and faster (it's local fail first, then notify the master)
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
Nit: space between the cast operator and the target.
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
Looks like there isn't an ExecutebleScript equivalent for search scripts anyway - ignore this.
Talked with @cbuescher in a chat - since these are just copied from their old place they should probably just keep their implementation in this PR. Moving to test framework is still possible in this PR.
Maybe explain that it is used in places where you want to make sure that scripts are valid but don't care about the specific script and this is the easiest way to do that.
Probably worth putting an explanation in here.
I think it'd be nice to have this in :test:framework so others can use it.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
You don't need to create an explicit default ctor since the super class has a default ctor.
No need for an empty default ctor when the super is also a default ctor.
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
NIT: noisy reformat :)
I'm confused because I thought you were implying there are cluster level tasks always running in the background, that are simply part of the cluster operating normally. A leak is a leak, and we should catch and reject it.
I am not sure that it warrants "WARN" logging level. It's perfectly fine for some of the tasks to be running in a working cluster. This includes node and master fault detection pings for example. I feel that INFO level logging would be more appropriate here.
Somehow we need to distinguish "background" tasks for the cluster from those started by rest actions.
ok can we rename the getter then to `getFailedNodeExceptions()`
can we please unpack the tuple right away instead of using v1 v2? just easier to read
Again, putting the unit in the name would help here, unless someone reads the docs they can't tell whether it's millis or nanos
Again missing units :(
can we replace the Math.max with an assertion? it should never happen and we shouldn't protect for it.
Yes, that would be clearer
oh hahahah, I can't read, that's an L
we should soften the language here. We can return before these are active (with a time out flag))
Why is it not possible to specify 0? I might want to create an index without waiting for any shard of that index to be active.
But that is not equivalent? Arrays.toString is a static method, and different than result.buildConflicts().toString()
to make this simpler, I think we should add a method `addCustomFields` to the `AcknowledgedResponse` object instead and just call `response.addCustomFields(builder)` in `AcknowledgedRestListener`. As a follow-up we can then make AcknowledgedResponse implement `StatusToXContent`.
I would flip this logic to remove negations. ie `mergeWith.meta == null ? meta : mergeWith.meta`. Positive logic is easier to reason about. It might also be better to just move it out to a local instead of trying to inline it.
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
clarify the error message specifying what needs to be non null? the inner query...also remove empty, doesnt make sense here
nit: we can check the expected token and then create the searchProfileResults map
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
is this needed here? I think it does something only when the current token is start array or start object.
I might use an empty array here or switch the IdsQueryBuilder work with lists.
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
you are right, sorry
space between `if` and `(`
maybe expectThrows would be easier.
I tend to like expectThrows better for doing this.
Exception e = expectThrows(Exception.class, () -> doSomething()); assertEquals(e.getMessage(), containsString("bla"));
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
we should log the exception here.
this can very verbose (600 shards on a node). I'm doubting whether we should have this as debug and have an info level log saying "allocation of [X] unassigned shards delayed".
This is redundant. getDelayAllocationExpirationIn also calls getAllocationDelayTimeoutSetting()==0 and returns 0 in that case.
Just an idea how about making rerouting an AtomicReference<String> where a non null value signals the currently next reroute task name? this way we can log here logger.trace("already has pending reroute due to [{}]. ignoring [{}]")/
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
here too we do the same twice
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think filter and query can never be null here? not sure whether we should validate this here.
We can remove the `!` if we reverse this if statement, so ```java if (difference.isEmpty()) { status = RestStatus.OK; } else { ... the error stuff ... }
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Under what circumstances would the mappings for an index be null (as opposed to an empty map)? It seems the default for `GetIndexResponse` is to always have an empty map for mappings (and aliases and settings) and it would only get assigned to a non-null map.
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
nit: extra newline
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
same here - I think it's better to log the info message if the deletion was successful.
index's toString gives you '[index_name]' no need for '[{}]'
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
we need to add that we return false if no folder was found for this shard.
OMG `== false`! ð±
should we assert that reader.getCoreCacheKey() == engineSearcher.getDirectoryReader()? Forcing the core cache key handling to be delegated to the inner reader could be trappy otherwise
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
can you try to exercise this method to make sure we open a new searcher and close / release everything
this could possibly called I think
This can be final. This makes it easier to immediately see what is and is not immutable.
can you add more rolling while adding? Also *sometimes* increment the primary term
Note that you want to make sure that you test the difference between the terms in the ops and the terms in the files. These are not the same.
can you please inline this while [adding docs](https://github.com/elastic/elasticsearch/pull/30176/files#diff-ed6e20d0c4d03d97ae9b7a9a33190c4bR1532)? We need to have more roll overs randomly
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
it wouldn't be empty here at this point, it needs to validate the inner query and filter, see #11889
once you rebase you need to implement doHashCode instead, and can take out boost and queryName here, they are already taken care of in the base class,
I think filter and query can never be null here? not sure whether we should validate this here.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
Because of the structure of the grammar it's a way to get the `-` symbol from the immediate parent context in the hierarchy that could possibly contain it.
Let's improve the expression a bit: 1. add location (so the user can tell where the parsing stopped): `new ParsingException(source(ctx), "")` 2. rephrase the message to better convey the message: "SQL statement too large; halt parsing to prevent memory errors (stopped at depth {})" or something along those lines.
I talked with @costin earlier about this - he wants to keep the order the same and my proposal doesn't. What about this? ``` while (result.size() > 1) { ListIterator<Expression> itr = result.iterator(); while (itr.hasNext()) { itr.add(combiner.apply(itr.remove(), itr.remove())); } } ``` Your version works but `for (int i = 0; i < result.size() - 1; i++) {` make me think it'll be a normal loop and then you remove and add and I'm confused. Using the `ListIterator` forces the reader to think.
I'm fine with leaving it, yeah. I did want a prettier one but if this is what we can do, it'll do.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
Yeah, it's puzzling!
And yes, I misread the assertion at first but the puzzle why a change is needed only here remains! ð
You should also test `nextUp(-0f)` ?: ```` assertEquals( NumberFieldMapper.NumberType.DOUBLE.rangeQuery("field", -0f, null, false, false), NumberFieldMapper.NumberType.DOUBLE.rangeQuery("field", +0f, null, true, false)); ````
missed that. All good then. Sorry for the noise.
I think we need to add a check that other settings do not spring back to their defaults, which I believe was the original issue (update one setting and have all the rest go back to default).
ok fair enough
Yeah, I think we can collapse both deciders into one here - it will make things simpler. Call it RecoveriesAllocationDecider that is incharge of all recovering shards (replicas and relocating primaries). It's good to do it in a different PR imo..
This predicate can be simplified to `(count, limit) -> count > limit`.
too many shards already allocated to this node for index ...
and 2 more occurrences below
we only have index name (and not index uuid) in this one, wonder if we need snapshot uuid here...
you probably intended to write "alias:id,snapshot".
I think this needs to be "unidented" by 4 spaces. Also just for the "beauty" of things you can move the leading whitespace char to the prev line.
I'd rather call this `queueSize` as we do in nodes info api.
`thread_pools_patterns` does not match the name of the parameter registered in the RestController
This could be `Strings.hasLength(tokenizerName)`
I am not sure if we should catch an exception here IMO the exception should bubble up
would it be possible to eagerly initialize the clients and make them final? I don't see why not, but maybe I am missing something.
alright I can't see a reason why one would have the two clients using different protocols. Then reading from settings becomes overkill. I am sorry, I think I'd go back to the method that you had before then. It was a good one, I just needed to see it gone to realize that :)
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
I think I missed the discussion but why isn't all this (this method and the next two) part of BaseNodeResponse's toXContent implementation? It can declare an abstract method that the subclasses can override for their own xcontent? We use that pattern pretty frequently with things like the query builders.
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
+1 to capture `System.nanoTime()` at the beginning of the method
Yeah, I think we can collapse both deciders into one here - it will make things simpler. Call it RecoveriesAllocationDecider that is incharge of all recovering shards (replicas and relocating primaries). It's good to do it in a different PR imo..
typo I guess `s/chanHaveDuplicates/canHaveDuplicates/`
I think this is wrong? I this is an indexing request on a replica and we're here, that means that there is already a doc with this id. In this case we want to just ignore the request. +1 on what Simon said regarding not changing this code.
This might be more readable and succinct with `&&` chaining, what do you think? ``` java return timestamp == create.timestamp && ttl == create.ttl && version == create.version && id.equals(create.id) && type.equals(create.type) && ... etc ... ```
yeah nevermind I was confused about some internal classes
same here. ElasticsearchAssertions.assertThrows wil help
you can call `bytesAsInt()` then you safe the cast and it checks that it's lossless
nit: `== false`
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
This could be `Strings.hasLength(tokenizerName)`
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
nah this should just pass a string.
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
this new exception is going to trigger errors too if we try to serialize it to an older node
I think s/lang/defaultLang/
Fine by me.
I missed it, indeed it should be moved to setupSuiteScopeCluster
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
I am wondering if it makes sense to implement `getProperty()` for `Aggregations` as well and not just for `Aggregation`. For example in a test I would write something like ``` Aggregations agg = searchResponse.getAggregations(); Object o =agg.get("aggname").getProperty("path"); ``` but if Aggregations also implemented getProperty() I would save another line and it is needed anyway here internally.
Conversion to bytesref is done elsewhere with `indexedValueForSearch`. I'm unsure of the impact of rejecting anything but bytesrefs.
sure sounds good. I thought the enum contained all the possible codes :)
cool. this is sufficient for ILM for now, so that makes sense
That should probably go to TaskInfo, especially parser that should be definitely somewhere close to the corresponding toXContent method that generates this json.
Here we lose the option to fail if an expected warning didn't materialise. Is that OK? Its conceivable some tests can be certain in their expectations of failure and we do need a way to fail when we fail to fail (so to speak).
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
You can use the diamond operator here.
You can use the diamond operator here.
class could be `final`
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
missing t at the end of the method name
If we are going to load the class directly (i.e., via the class itself) there is no need to use `Class.forName`, you can just say `final Class<?> class = HttpAsyncResponseConsumerFactory.class;`.
Given the method's name I expected it to check the values too.
I'd use `randomAsciiOfLength(5)` rather than fixed strings for this.
I don't understand the need to use Occur.FILTER here (or in other parsers) versus Occur.MUST. To me these are just parsers for queries, and thats the correct logic, the fact it is wrapped as a Filter means these will all become non-scoring clauses.
I don't get it sorry :)
yeah it might be ok to do this since we are only parsing it on a search thread. I wonder if we can add an assertion for the threadpool that it is not a nework thread ever? but opening a diff issue is good
can we deprecate the method so it doesnt spread? If it spreads somewhere else, then it would need more logic to handle all the cases (e.g. DISI.iterator() == null etc)
I'd go for either check in the constructor or here.
Wouldn't the definition of "upgradable" for string to text/keyword mean the norms setting fits with what is allowed? As this is now, it would mean eg keyword fields could have all of the old settings right, but they would be deprecated...that is just really weird for a new mapper type.
And the same for TextFieldMapper, although that is a little different since it uses parseTextField...
Can you use `== false` here...the `!` is almost hidden in all the other text around it...
nit: missing a space after the first comma
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:918E10886BC43EC1]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.LineStringBuilder.<init>(LineStringBuilder.java:49) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiLineString(GeoWKTShapeParserTests.java:112) ... ```
nit: formatting, add some whitespaces
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
I think s/lang/defaultLang/
Fine by me.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
instead of the assertBusy, maybe use a future above with setWaitForCompletion(true).
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
is there a way to filter out the index metadata here? We just want the global metadata.
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
same thing with 'even make' here
s/payload is/payloads are
I think we should enable this by default and maybe say `5`
should we here or in the superclass fail if the cluster has not fully upgraded to 2.3? just as a safety guard I think that would be a good check in several places otherwise I can see us debugging weird issues `DiscoveryNodes#smallestNonClientNodeVersion()` has a neat method to check.
can we call this RecoveryNodeResponse? (it's no longer about a single shard)
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
last parameter can be set to from.
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
This duplicates the `hasWriteBudget` check and can never fail by virtue of being inside the `while` loop.
Oh nevermind, I see the problem now, the field name is not used to calculate equality so they can stomp on each other even if they have the same name :(
Can you use StreamInput#readList ? You need to check for the version here since this code can receive requests from nodes in previous version. Something like ````if (in.getVersion.onOrAfter(Version.V_6....)````
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
I don't think you need @Before here, the parent method already has it.
I think we should keep the `Collections.sort(keys)` part to keep the reproducibility between different jvms if we can.
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
Maybe we should sort the list of byte[] here? I'm thinking this might be useful if we decide to support sorting on binary values in the future.
I think it would be better to do something like `return "[" + new BytesRef(ranges, 0, BYTES) + " TO " + new BytesRef(ranges, BYTES, BYTES) + "]";`
see above - I think you should add it though
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
left over reference to a countdown latch
Oh, nevermind on the second point, I see `ShardLock` implements `Closable` already.
In our discussion about semaphores I understood a different model we keep a semaphore per index/shard directory (like the on the disk locks but in memory). That would be pruned when the folders are pruned. I see where you were heading. I'm fine with either way.
I think enforcing this as a List of `ShardLock`s would be better, type safety wise
minor typo - "indexes shards lock" -> "shard locks"
Nit: strictly speaking i think we need targetBuffer.remaining() , which is how many bytes we are reading.
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
Another `_` java 9 will be mad at
Here, I think you should adopt the pattern we use throughout the rest of the class, i.e., ``` try { closeWithTragicEvent(e); } catch (Exception inner) { ex.addSuppressed(inner); } throw e; ``` so that we get the original cause.
I wonder if we want a trace message here...
This method also does not need to exist, as you can use `this(indices, IndicesOptions.strictExpandOpen())`, and fix the validation in the other constructor.
yea Im all for not exetnding that class. And Im also all for putting things that are primitive and easily validatable into the constructors. Optionals, i think im ok with setters but i think this also deserves a wider audience to discuss.
This is a question, not a change request: What is our philosophy regarding having setters vs. immutable request objects going forward for the HLRC? I've been under the impression we preferred immutable objects, but it doesn't seem to be consistent.
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
make `Boolean` and only serialize when not null
FWIW I've used this in the past for production ES clusters to have a set of common settings (elasticsearch.yml) and node-specific settings (elasticsearch.json) to merge two files with settings. That said, I still think it's safer/better to remove this feature and fail if more than one config file is found. It reduces the complexity for reasoning where a setting came from.
we need to support whatever extensions Settings supports and that includes json & java properties formats. I wouldn't worry about restricting it to these three (yml, json, properties) with regards to bwc.
with the current code a `logging.whatever.yaml` file would be loaded. I wonder if this is our intention or a side-effect of the current behaviour. Honestly I would be in favour of simplifying this further and even have something like `if (file.getFileName().toString().equals("logging.yaml") || file.getFileName().toString().equals("logging.yml") )` unless we want to extend this to json and properties files, which I think would be off-topic in this PR.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
We had to choose a shared prefix in order for there to be a consistent way to detect types deprecation messages in REST tests (and ignore them). I think @jdconrad is just using this prefix here for consistency.
I don't think you need @Before here, the parent method already has it.
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
Ah yes, thanks!
I think s/lang/defaultLang/
Usually we also make a few API calls to the server, e.g. https://github.com/elastic/elasticsearch/blob/2aba52de8f9315b0e384e1c657d7b0401d26a1b0/qa/vagrant/src/main/java/org/elasticsearch/packaging/test/PackageTestCase.java#L121-L122 I'm not completely sold on the value of those though
Nit: can you put this and `runWithoutJava` next to each other
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
You could look at `GradleUnitTestCase` it does the same by pulling int the randomized runner only. What I was wondering about w.r.t order is that if it really makes sense to have it fixed. If all we are doing is going trough methods sequentially what advantage does it bring to have them in separate methods ? Maybe better error reporting ? Should we keep the randomized method order and make sure it actually works like that? I'm not saying we need to change it just looking to understand the implications.
Do we really need a before and after? These are run completely sequentially, so the "before" of one test is the "after" of the previous. I'm just thinking of what the old output used to look like (a single line per test in most cases with "OK") compared to what we are moving to here (many lines per test, if I understand correctly).
new is not possible with an older version...
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
argh. Hidden by github ui. all good.
The fqdn was used before though too. It is not introduced here. It makes it clear which exception it is (e.g. org.elasticsearch.script.ScriptException vs javax.script.ScriptException), and it makes it easier to remove exceptions from here in master (vs having an import statement too), which is really needed.
Can you rewrite this as an array of ctor references and iterate the list to build the map? It might be a bit easier to read.
I guess it would be better to have a random unicode string here instead of the English? We don't need hits here really
I think we can simplify this and make sure we have 1 shard, no replicas.
I think it's important to know that the transport system is replaced and that the settings have effect. This also has security implications, as plugins can add settings. I think this should stay an info log like it was. Adding something similar to the SelectedType is good but over there debug is the right call indeed - it may be used for many things.
`this()` is obsolete
please fail if vals.length > 3
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
My motivation is both making it so there is one obvious way to calculate distance (I was reminded recently of this beatiful mantra from the Zen of Python: `There should be oneâ and preferably only one âobvious way to do it.`). I also think not having instance methods will allow us to play more with the underlying field access so we dont need an intermediate object, GeoPoint).
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
I am good with both options.
fine with me as well. go ahead and push!
maybe it is a matter of style, but i think its easier to handle the exceptional case like a guard up front: check stats.docCount == -1 and set to -1, otherwise sum. this is not really important to me.
What if this.docCount was already -1? then it should stay -1 right? (in the else case here)
Weird markdown seemed to silently remove some of my text...I was trying to say `FieldStats<java.lang.Long>` (which is what I think you meant by your last statement).
`S3SignerType should not be available for China region`
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
`} catch(IllegalArgumentException e) {`
`} catch (IllegalArgumentException e) {`
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
This constructor doesn't seem to be necessary.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
I don't see how the cluster state is not _always_ the right place to store configuration. Putting it in an index is a hack. I don't see the issue with "large pipeline configuration", but I also don't see how it would differ from how cluster state for a specific index is passed where necessary, eg mappings are not loaded for all indexes on all nodes.
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
maybe make this variable final? just better indicate it will never change
The method name implies yellow though. I bet there are places where we don't _need_ green.
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
Is the version needed? I don't see it being read here.
this will annoy the forbidden API after rebase + squash. Heads up
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
you should replace the curly bracket with a square bracket here.... :D
do we need == true ? :)
If the intention is for this to be immutable then you should wrap the `new TreeMap` with `Collections.unmodifiableSortedMap()`, because otherwise a caller can modify it via the getter.
here you may be able to use copyCurrentStructure
It would be worth requiring that `jobId` and `jobType` are not `null`.
I think we can do this more simply by looking at `endsWith(".jar")` of the uri string. We don't really need to convert the uri to a path, since we don't need to load the file. Then, the original if statement can simply be wrapped with like: ``` URL location = clazz.getProtectionDomain().getCodeSource().getLocation(); if (location.toString().endsWith(".jar") == false) { // original if and exception here } ``` Basically, if the file is in a jar, we don't need to worry about it here, as those would have already been added to the codebases map by `Security.getCodebaseJarMap`. This method is about adding classes that are on the classpath, but not via a jar (ie built by the IDE).
This assumes a version format that while fairly standard is not guaranteed.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
maybe not appropriate here, but we can do this with one underlying read of metadata via Files.readAttributes (you then have isRegularFile() and size() available from BasicFileAttributes)
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
Isn't `js` the common extension? At least, that's what is in RFC 4329.
Since these tests are so fast + simple, maybe we could just test both methods every time. I don't think this will be much extra code, as you could re-use the same `FakeRestRequest.Builder`.
nit: shard routing already has [] in it's toString
I think I would make a breaking change here. Let's drop support for the string value in the builder and add it to the breaking changes. The parser still supports `none` and `all` but the builder only accepts a query. Then the method below needs to pretty much be moved to the parser.
The other configs should also implement ToXContentObject and change their `toXContent` but let's do that in a follow up.
Yeah, let's the keep the tests just focused on whether or not `MinMasterNodeCheck` does the right thing based on whether or not `discovery.zen.minimum_master_nodes` is set and we can think about broader tests for the default checks from `BootstrapCheck` itself in a separate pull request.
There's a `BootstrapCheck#check(boolean, List<BootstrapCheck.Check>)` override that is visible for testing exactly so that the test can be written without having to rely on passing in a setting the triggers enforcement.
nit: IllegalArgumentException ;-) You're checking the `settings` argument here, not the state of InternalTestCluster.
space missing between ) and {
+1 on that reformatting.
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
+1 to have `fromXContent` and `parse` be static
This shouldn't be needed anymore. By default we wait for the index to be created now.
`client().prepareIndex(...` is more normal now.
for master you don't need to specify the gateway.type we only have what used to be local!
+1 I like plugin examples!
you can simplify this a bit here: ``` Java NodeStats unluckyNode = randomFrom(Iterables.toArray(nodestats.getNodes())); ```
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
relativize can be tricky if paths have different roots. is siteFile really guaranteed to be absolute too? In lucene i coded this "minimal path" with the following idiom: ``` root = root.toAbsolutePath().normalize(); path = root.relativize(path.toAbsolutePath().normalize()); ```
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
It won't always be the case that there will be one index commit, sequence numbers will change this assumption.
> If there are multiple commits, what does IndexWriter.getCommitData() return? I am guessing it reads the "latest" commit's data? Yes, the latest.
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
we can do this in a more optimize manner. We can create a builder, and then use `copyCurrentStructure` on the builder (passing it a parser), to just copy it over, compared with parsing into a map and then serializing the map. Also, since its internal, I would use smile builder, as its considerably more efficient than json.
I think it's better to use the index version created to test whether the old or the new parent join should be used. This way you can make sure that the correct explanation is returned in the exception if the parent field is not filled.
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
Might be slightly better to return a StringBuilder here as well to not create an additional object? Maybe this could also be done in several other places in this PR where partial WKT strings are built (e.g. all the contentToWKT calls)
would you mind adding the same for allocation ids? :+1:
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
This is not good for backword compatibility. Instead it should do: ``` if (indexSettings.getIndexVersionCreated().before(Version.V_6_0_0)) { String tokenizerName = settings.get("tokenizer", "whitespace"); tokenizerFactory = ...; } else { tokenizerFactory = null; } ```
Move to the new randomized testing. Important for reproducibility
looks new. I like this update!
I think it would be cleaner to move the assert into the catch, and add a `fail("expected script exception")` after the call to `run()`.
If these privileges are only needed for loading static definitions, then this should be done in a static block when the plugin is loaded, instead of on every invocation of the script.
If this jolly library really only works with context classloader then I think we should find another example...we should not be promoting in any way setting the context class loader.
This name won't work as I can specify multiple scripts of a single type (e.g. `inline`) and the `ParseField` name for them all will be `"inline"` so they will overwrite each other. I think we need to go back to the parser here and parse a `Map<String, Script>` so each script can have a name. In the request this would look like: ``` { ... "script": { "my_script_1": { "inline": "script contents", "lang": "expressions" }, "my_script_2": "script contents", ... } ``` Note that scripts can either be a JSON object or a String. The `Script.parse()` method handles both cases.
and do that in all other classes we do this for serialization in this pull request.
Do we need to still read from the wire using something like this? ``` // TODO change CURRENT to specific version when feature branch is merged if (in.getVersion().onOrAfter(Version.V_6_3_0) && in.getVersion().before(Version.CURRENT)) { in.readBoolean(); // was waitForAck } ```
I don't get this part why do you change the way we read the `TranslogStats` here? can't this just be ``` Java translog = in.readOptionalStreamable(new TranslogStats()); suggest = new SuggestStats(); if (in.getVersion().onOrAfter(Version.V_1_2_0)) { suggest = in.readOptionalStreamable(suggest); } ```
I'm actually wondering if it would be better to commit with the `onOrAfter` line and just accept the errors for a build or two. The last good commit stuff should mean that only the intake build fails on this. You could also set up the backport for 6.x branch before pushing the change on master so you can push both at the same time and minimise the chances of builds failing.
I think consensus is to avoid build failures entirely whenever possible
I would use System.currentTimeInMillis, nanoTime has different semantics
and also assert that `startOfThrottle != 0`
nit: "so we assume"...
nit - I like the blockOperations naming... syncX is just one letter away from asyncX..
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
I think this would read much simpler if you would do `if (it != null)`
can this be `else if (res == null) {...`
I really don't think we should put methods that have side-effects into a short circuit logic. Can we use a traditional if statement here like ``` if ( docIdSetIterator.docID() == target) { return true; } else { return docIdSetIterator.advance(target) == target; } ```
can we also step out if `matchedDocId < DocIdSetIterator.NO_MORE_DOC`
Different leaves might use different codecs, and some of them might support `totalTermFreq` while other leaves might not. So this should return `-1` if any of the leaves returned `-1`.
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
the `grok` field can be final too
this should just throw IOEXception no need for a shadowing ConfigException
@talevy Can you extract this IOException change from the PR and commit this to the branch? I can then benefit from it in the geoip PR too.
I was thinking of something like: ``` java public static enum TestQueryType { MATCH_ALL { @Override public QueryBuilder buildQuery() { return QueryBuilders.matchAllQuery(); } }, MATCH { @Override public QueryBuilder buildQuery() { return QueryBuilders.matchQuery(TestIndexField.STRING_FIELD.toString(), randomAsciiOfLengthBetween(MIN_SMALL_INTERVAL, MAX_SMALL_INTERVAL)); } }, TERM { @Override public QueryBuilder buildQuery() { return QueryBuilders.termQuery(TestIndexField.STRING_FIELD.toString(), randomAsciiOfLengthBetween(MIN_SMALL_INTERVAL, MAX_SMALL_INTERVAL)); } }, QUERY_STRING { @Override public QueryBuilder buildQuery() { return QueryBuilders.wildcardQuery(TestIndexField.STRING_FIELD.toString(), randomBoolean() ? "*" : "?"); } }, WILDCARD { @Override public QueryBuilder buildQuery() { return QueryBuilders.wildcardQuery(TestIndexField.STRING_FIELD.toString(), randomBoolean() ? "*" : "?"); } }; public abstract QueryBuilder buildQuery(); } ``` Then to build a random query, you could do: ``` java randomFrom(TestQueryType.values()).buildQuery(); ```
I think our other enums need this ids for backward compatibility of the streams, so that even if we add/remove entries to the enum they still get serialized with the same byte.
The `activeBenchmarks` reference can change anytime, so I think there should be a ``` java final ImmutableOpenMap<String, BenchmarkState> activeBenchmarks = this.activeBenchmarks; ``` at the beginning of the method to make sure we are always talking to the same instance.
we try to not sync on this generally maybe you can just add a `private final Object lock = new Object()` and sync on that? it's better to hide the sync lock from the outside :)
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
I think it would be better to pass a boolean in to this method, since it's ambiguous from the name of the method whether it sets a var (could be named `setDeleteOnClose()` if it were setting something) or actually does the deleting.
It would also allow you to change the ``` java if (delete) { channel.deleteOnClose(); } channel.close(); ``` to ``` java channel.deleteOnClose(delete); channel.close(); ```
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
minor nit: "int he" -> "in the"
maybe not appropriate here, but we can do this with one underlying read of metadata via Files.readAttributes (you then have isRegularFile() and size() available from BasicFileAttributes)
there is an `hasUnassigned` method already, so yeah, I'm +1 on being explicit here...
This is logic that I think should go into ReplicatedOperation.
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
I don't see this change implemented here.
this needs to stay because the method can be called from any other class, it's a public static method....thus validate might not be called at all before calling this method.
we shouldn't need this here in parse phase
nevermind, I guess it depends on how you look at it. at the end of the day this parse method does parse + toQuery, having QueryShardContext is fine given that it will still happen on the shard. Also given that the QueryParseContext is much more lightweight, it makes more sense if done this way. Plus the parse method will go away, so leave it as-is.
I think conceptually this should be QueryParseContext instead, if it needs to do more (toQuery) then we need to figure out how to create the QueryShardContext too out of it, but the other way around seems confusing to me. Sorry I see we are going back and forth on this.
I think âdoes not have soft deletes enabledâ was great!
instead of one snapshot per index, I think it's more natural to have a fixed SnapshotID(latest, latest) and all the indices of the cluster then as indices that are part of the snapshot.
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
ð I will work on it.
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
I Am concerned that we will miss the actual message because its wrapped, my vote is the detailed message one
yea, in that case, let's not add the addition message, and solve it on the logging side m
This could just be `close()`
I don't think we need to get into this now. For now we can remove the test and just keep a test where we have some nodes with no shards assigned to them.
I think this check does not add much (I would skip it)
maybe make this variable final? just better indicate it will never change
maybe, to be more precise, it would be good to check the partition that included the new primary.
maybe 7 indices with 50 docs is a bit too much (= slow test), let's reduce randomness to 3 indices, each max 2 shards, and 10 docs.
@javanna I don't think it is? see org.elasticsearch.action.deletebyquery.DeleteByQueryResponse#iterator
internal class :) I think it's fine
oh nevermind, I just found the method that called it with null :)
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
with inflating `indexShardLimit` by 1 in `canRemain`, this message might be confusing.
Indeed, I think two BytesReference instances should be considered equal if they have the same content (which is what the way other children of BytesReference are implemented suggests). My point was this path of the equals method ignores the offset of `other` (it starts comparing its bytes at `0` instead of `other.offset`.
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
is this correct? this will return a copied array if offset > 0, yet the `arrayOffset` method will return the offset into an array that has offset 0... .
I think we should return the BytesRef array we get from reading from byte array, and `arrayOffset` will use the same logic, and return the offset form the BytesRef
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
I like this much better!
I _think_ you can do `XContentParser::mapStrings` above instead of having this method.
Fine by me.
I think s/lang/defaultLang/
Maybe this one too, I'm not sure.
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
The indentation is off here and the rest of the way through this test.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
can we check and stop if the background thread had any issues? o.w. will have to dig through more than needed.
Don't get me wrong - I like the loop above - I just don't think is sufficient to prove to ourselves that we recreated the problem.
in this re-write, we have a lot more things we probably want to report in our status.
I'nm still missing the buffer size, the max requested seq no, leader global checkpoint , follower global checkpoint etc. I'm fine with a follow up for those, but that's what I meant.
if it was always local it should all be taken care of by the put mapping api (retries etc). That said, this is also remote and I was mistaken. Sorry for the noise.
I think it would have been worth it but now that you mention it - other requests may have changed this in the mean time too, so let's leave this assertion.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
Nit: `s/soft-deletes enabled/soft deletes to be enabled`
I think 0 is a good minimum value.
right thanks for the explaining, I should have known, having worked on the search refactoring :)
We call them "master nodes" everywhere else. :frowning:
same here just use synchronized methods
I thought it was a typo as well until I read https://en.wikipedia.org/wiki/Luser :p
This method is not necessary. With the code as is, we would be extracting the entire zip, but only using the one directory from it. Instead, we should do checks when extracting, see the `unzip` method. There we can have a prefix check like: ``` if (entry.getName().startsWith("elasticsearch/") == false) { // only extract the elasticsearch directory continue; } Path targetFile = target.resolve(entry.getName().substring("elasticsearch/".size())); ``` This will unzip everything in the `elasticsearch` directory directly into the temp installation directory, and all the other plugin cli installation code can work as-is.
I don't think this is a usage error (it's not something the user did wrong, it is something wrong with the plugin). We also already get a FNFE when the descriptor is missing, is this really necessary? I don't think this message, vs FNFE, will give any better indication to the user that the plugin is broken.
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
I think it's good have 0 as an option here too? I.e., index and search a freshly opened engine ..
This will need updating once the setting is moved.
typo: if return -> is returned
typo: this this
thanks a lot! should we have a test that leverages this extension point for score functions? I thought we had one already but not sure anymore
The `<=` will need to be escaped.
Fair enough, good to know.
This should be `eventListener.indexShardStateChanged(indexShard, null, indexShard.state(), "shard created");
can we move this back into the try? I'm worried that exceptions wouldn't release the shard lock .
Believe it or not, it's fine to pass `null` to `IOUtils.closeWhileHandlingException` (it just skips them). We do that for cases where you might have N things that need closing from a large try block, and you don't know which are `null` and which are not (depends on where the exception was thrown). But for here I like the `null` check: less smelly.
or "failed to close store on shard removal"
maybe it's me but this change seems fishy... we do much more than before now here, also not using indices options coming from the request... but first of all are we sure we want to support writing into index names containing date math expressions? in my mind it was more about reading, search api etc.
I wonder if we should spawn this to a background thread as this is still being run on the cluster state processing thread. Just be on the safe side.
do we want to do something with is error? (not related to this change)
can we call the callback onStarted ? it is not called on error
When moving the validation to the `validateCompositeTemplate` method we should be able to reuse the mapping generated in that method
I think that we can check the second byte as well to make sure, same way we do in SMILE (by not only checking the first byte), check here: https://github.com/FasterXML/jackson-dataformat-cbor/blob/master/src/main/java/com/fasterxml/jackson/dataformat/cbor/CBORParserBootstrapper.java#L112 for the logic
for other reviewers wondering where this change comes from, the first char is already checked earlier in this method
I wonder if we should this api to the forbidden api pointing people at the utilities... (like we did in the write variants).
Change "param required" to "parameters are required"
you can make one of them public and call it from both tests, I don't mind
nit: space before brackets
typo: optain -> obtain
If the usage of forbidden APIs is in a few places, I would consider it better to suppress only at the lowest level (sometimes I like wrapping those in a private method I suppress). The reason is that if an unintentional forbidden call creeps in it will be caught.
Minor suggestion to make it clearer that we're not waiting for the write index not to exist: ```suggestion public static final String NAME = "check-not-write-index"; ```
If it's possible to directly forward to `LoggingDeprecationHandler.INSTANCE` I'd rather do that because it would avoid duplicating the knowledge that the logger for `ParseField.class` goes to the deprecation log.
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
Not sure this should be "Query" ð
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
why not round robin on this? I think the randomness still allows us to have collisions and will keep us wondering. +1 on the insight that suite and test scope don't co-exists! Also, this makes us one step closer to using it randomly in our global cluster scope.
1+ portCounter.incrementAndGet() % 9 ? (now we have a collision for 10 & 11 )
The max TCP port is 65535 , min 30K gives us ~30K or 30 JVMs.
I think we can still run into conflicts between tests here? `RandomizedTest.randomInt(1000)` can be the same between tests and then we have a port conflict.
yes, true. Maybe each unicast based test should just stick with its own port range? Not sure how to solve this otherwise. Just want to prevent test failures caused by two nodes taking the same port.
If the constructor is modified, this method won't be needed anymore.
Ah, I see why this is a function ref - so that the `toString` generates the right method to invoke. That feels a little brittle but I understand what is up.
It would be nice to return a simple, non-empty structure here so that we test that aspect of the response parsing.
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
oh boy :)
Sorry about these crazy incantations....
In which case I would say remove the BOOLEAN format here since its not actually a numeric format
hmm not sure, it does seem a bit weird to be there so I'm leaning towards "remove it". It doesn't feel like a great idea to be running numeric aggregations on a boolean field and I don't know if its something that works by design or just happens to work right now and might break in the future. /cc @jpountz who might have thoughts on that
I think it just happens to work today and might break in the future indeed.
I believe this can be provided by overwriting EsTestCase#xContentRegistry().
Can we make this 1 hour? If it times out it's nice to get thread dump
same as above for non exception case
I am good
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
`FutureUtils.cancel` has a check for a null future, no need to add this check
I know it was like that before, but we are here now. ð
I think it would be great to have different values for same fieldname and type. Working on the SpanQuery builders, I introduced BaseQueryTestCase#randomValueForField(String fieldName) which at least works for String, Boolean, Int and Double fieldname, otherwise returns String. Might be useful to use this here as well, potentially with minor modifications.
I understand the that the way the we test the created lucene query at the moment is not affected, however since we already have the test for `expected list of terms` hat checks the terms at least for string fields, I think it would be really good to have this tests. Changing this shouldn't be too hard, and also the random query we create here would feel more "natural". Please correct me if this change is hard to do, otherwise it would be really great to have random values here.
I thought it would, plus I don't get why we do the same thing in different ways depending on the query. Maybe it's me though.
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
Wherever makes the most sense really. In this case I would put the default constants in `DirectSpellcheckerSettings` I think
nit: IMO `suggestMode must not be null` sounds more explicit.
These should all have sensible defaults rather than being null, as we have done with all the other builders. This also means we can remove @Nullable from all of the methods and add checks in there that throw an exception if null is passed in to make it safer. The defaults we currently use can be found in DirectSpellcheckerSettings.
You could add an assert that it's not ES 7.x here so we know to remove it
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
I think `requiresIndexMappingRefresh` is very misleading - it should be called `updateMapping` as it does update the mapping (and returns a boolean for refreshes)
Sure. This one is more than good enough :)
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
minor nit: you could move this into the WatcherState enum and just have a method `isStopState()`
`state == State.STARTED`? Otherwise no need to define the local variable `state` above
do we want to do something with is error? (not related to this change)
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
should say shard active
do we really need so many tests? this is just about parsing? It can probably just have unit testing for this..
we end up supporting both `$stashedKey` and `foo${stashedKey}bar` ? we may want to move to the latter once all the clients runners implement this feature, to have a single way to get stashed values.
maybe ${stashedKey} alone should return an object then? Does that complicate things? Calling toString makes sense when the stashed thing is part of a string, otherwise returning the object sounds better.
It would be nice to return a simple, non-empty structure here so that we test that aspect of the response parsing.
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
nit: indenting should be only 4 extra spaces
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
Can you add a TODO here? Something like: ``` // TODO: specialize based on compiled.type: for ALL and prefixes (sinkState >= 0 ) we can avoid i/o and just set bits. ``` I can look into it later.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
Ok, I was missing that piece of reasoning. This global ord lookup logic looks good!
Why do we need both? Is it because there are so many things going on in this file? I don't understand why we wouldnt just need the CompiledAutomaton for the terms.intersect operation, why do we need a ByteRunAutomaton too? Having both seems silly anyway, but if we must do it, try to assign the ByteRunAutomaton from the CompiledAutomaton. The majority of the time it will be non-null: ``` /** * Matcher for quickly determining if a byte[] is accepted. * only valid for {@link AUTOMATON_TYPE#NORMAL}. */ public final ByteRunAutomaton runAutomaton; ```
Here it is more clean, but again I think using `synonym_query_style` would be better
I think this should throw IAE if you pass null - that's 100% of the time a bug
For easier debugging it would be good to print the (unknown) value of `this.synonymQueryStyle`
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
hopefully having a default for fuzziness makes it non optional and simplifies things slightly here too
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
I'm wondering if the parent really helps define equality here? Additionally, by adding this we will do more checks than necessary given that we compare both sub-aggs and parent aggs
ok can we rename the getter then to `getFailedNodeExceptions()`
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
Wow, that's a big difference! Do you know whether it is lossy compression or not? If not then indeed compression seems to make a lot of sense. :-)
we can use in.readVInt() here, no? it's always non-negative... (same goes for other counters and also note that you'd have to change the writeTo message of course)
Why not have the standard to string? A multiline return value is difficult to work with in a debugger...
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
This needs to handle the -1 case.
obscure error message... let's start by `"could not read alias fields filtering from xcontent. expected an object but found [" + parser.currentToken() + "] instead"`
this is unneeded - we just iterate of the list...
Oh oh! deleteUnderLock should be called when you hold the lock! instead we should use IndicesService.deleteIndexStore
I think this will result in a double info logging - we already logged at info level when discovering this.
Does it need to be Writeable? It looks like we only serialize it using JSON.
can we log the full index object, includeing the index uuid? also it would be good to have the current cluster uuid and the one in the index meta data state.
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
This constructor doesn't seem to be necessary.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
this method is not returning a boolean
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
Should this be 6 instead of 9? When I try `Instant instant = Instant.from(formatter.parse("0.0000001"));` in the tests I get an `java.lang.ArithmeticException: Rounding necessary`
Fine by me.
I'm fine with `IllegalArgumentException`, in all the places of course. :smile:
then check for non null here...
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
It is all good!
I think it'd be easier to read if this were `ObjectParser` stuff.
Check nextToken is Token.END_OBJECT and throw appropriate error if not. Without this additional check the parser errors are somewhat confused if the JSON contains a parameter.
+1 on removing it
maybe I am missing something, but `.getSourceAndMetadata()` returns a mutable Map? here is an example: https://github.com/elastic/elasticsearch/pull/18193/files#diff-4e27382bea1f95bce321ce30c5315e98R42
just call `parser.text()` instead of `parser.bytes().utf8ToString()` since it might be optimized under the hood
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
+1 that is what I would do too
This is what I meant, yeah. I'd have made it a `private static final ImmutableList<String>` instead of `Immutable<Highlighter>` but it doesn't make much difference.
can you remove this TODO? I'm not sure we are going to implement this after all, nobody needs it for now :)
Yeah - at least needs the ALL_UPPER_CASE naming. Probably should be moved to the top of the class too because that's where I usually look for static stuff.
I don't think it's important for now
the naming might be a bit confusing: `clusterSettings` and then `getClusterSettings()` as variable names
Ah nevermind, I see where we check it above :)
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
ok...but client depends on the transport service anyway no? I think I don't get it
I guess it could be renamed to isFalse() / isTrue() now
the node where the shard should move to
yeah, that was what I meant
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
Could you explain why this is needed instead of checking `expireAfterAccess <= 0`? I think it'd make the class more readable.
I don't think it changed the readability much - it made the checks simpler but then it left me wondering why two variables were needed. I was doing the "why does this have to be here, let me think hard about it" think.
I suggest that we take advantage of this change to remove support for time-based expiration, which we don't need
Or not. It looks like you are allowed to modify the segment's innards while you have this lock.
I was getting confused by invalidateAll - on second inspection you hold both locks when clearing the maps.
extra space makes everything not line up!
Missing a space here after `id`
Elasticsearch tradition is to make this an EMPTY constant :)
drop the actually? sounds so "uncertain" :)
ok can we rename the getter then to `getFailedNodeExceptions()`
this would allow to remove the two parse fields above I think
I think the following if is not valid anymore in fromXContent: ``` MatchQuery.Type type = MatchQuery.Type.BOOLEAN; if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_FIELD)) { type = MatchQuery.Type.PHRASE; } else if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_PREFIX_FIELD)) { type = MatchQuery.Type.PHRASE_PREFIX; } ```
sorry, my bad.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
fyi, I added serialization to the enum I moved to MatchQuery (#13402) maybe we can reuse this.
Nit: `primary term` -> `_primary_term`
`seqno` -> `_seq_no`
I think the message here should 1. be a static final constant and 2. say what this TermsEnum allows ie.: `"This TermsEnum only supports #seekExact(BytesRef) as well as #docFreq() and #totalTermFreq()"`
I liked the assertion you had there that if already have a result, this one has a higher seq no
I'd just do the same thing as mentioned above to keep this simple though
I think filter and query can never be null here? not sure whether we should validate this here.
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
+1 on introducing a constant somewhere and reuse it in the parser as well.
shall we use MatchAllQueryBuilder as a default value in general, outside of this constructor? If not set, it will be match all? When set, we check that it's not set to null in setter.
then let's use it now otherwise this change is half baked
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
I think the whole method could just be: ``` return randomBoolean ? MetaData.ALL : randomFrom(currentTypes); ```
Same here as above, since both methods are related and read similar.
either way please create a static array containing these fields on top close to where we create `mappedFieldnames` so this selection is not buried in this method and we see that we might have to change it if/when we add new fields.
In which case your original solution would have worked too. Sorry
I think if you do `nextParams.putAll(params)` here you don't need to clear the `nextParams` map or do the `params.putAll(nextParams)` call below as the `nextParams` map will be used if `node.retrieve()` returns something and if it returns `null`, `params` will be untouched for the next attempt at retrieving the node.
Instead of creating the formerParams and replacing them afterwards could we not create a `nextParams` map which is a copy of the params map and pass it into the node.retrieve method? This would save us having to put things back after the method returns
Ok sounds good....as long as all the REST tests pass, I'm always afraid of any change to `PathTrie` :) Thanks a lot for the detailed explanation! Maybe it would be better to treat it as a bugfix and get it in separately? I don't have a strong opinion though since it's something that came up with this new api and wouldn't make sense without. Just thinking it would better highlighted as a different change and leave some more history on it this was applied.
maybe just `esVersion()`
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
I would probably throw an exception instead of accepting null here.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
no need to set timeout, the default is good enough
Yes, but you can change this setting during restore and it would be nice to test changing settings during restore anyway.
you can put these into `assertAcked(client().admin().indices().prepareUpdateSettings("test").....` to make sure this doesn't happen again
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
good catch on delta > 0
thanks for adding this
let's not log since it is an old index
How about building a set of invalid keys and adding them all to the exception? This would be a little friendlier to a user with multiple secure settings
Incredibly minor: should match the value used by the `return` line so that if the method ever changes, we use the same value.
and use the constant here
btw - the test uncovered some issue with the dangling indices import. You might run into a node not connected issues - working on an independent fix.
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
Yeah, it seems it is. We treat non existing indices as red. Thx for educating me.
I think there is a race condition here - it may take some time for the dangling logic to kick in (it's async via network calls). I would assertBusy until the index is visible in the cluster state, then go into ensure green.
Maybe use `getSecure()` so that it's closer to the other methods in this class (`get()`).
can we just change this to System.getProperty("tests.seed") != null? Then that method can be removed.
ReflectiveOperationException can be used instead of both of these
It feels like this is the wrong place to do this. I think we should do this in `Bootstrap` and then just pass a `Path tmpDir` to `InternalSettingsPreparer#prepareEnvironment` and make sure it's mandatory for all instances of environment that are not the single arg ctor. Btw. it feels like there are some sleeping bugs if this ctor is used in prod code.
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
You're right @benwtrent, we've been dropping the `@throws` clause in some of the methods in the client. We'll need to revisit and add them. I'll make a note to do that.
The indenting is out here
64e5c25 added support for this.
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
Hey I saw some updates on this PR and I just wanted to throw a reminder out that we are not going to do a singleton(404) here, because we want a delete that is not found to throw an exception. Also, last time we spoke you were going to change this to AcknowledgedResponse. <3
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
wondering if we need recoveryState.isPeerRecovery() to simplify these lines.
> can be cancelled just because primary relocation completed before shard was activated by the master node yes. I'm aware of that - I'm thinking that with seq# fast recovery it wouldn't matter much as a ready shard will quickly re-recover. However, seeing how the new code looks like with the cancelRecoveriesForShard + shardRouting.isPeerRecovery changes, I think it became much simpler. I'm good. We can see how things develop later on and potentially move some logic to the master (which will simplify this class) or not.
we lose some concurrency control here where we only cancel the recovery if it's not done. I'm wondering if we should use `cancelRecoveriesForShard` and if it returns true, we then remove the shard. Also - In all cases where the the source of recovery changes due to a primary failure, the master cancels the allocation and changes the allocation id, meaning we don't get here. I wonder if we should also catch the case where a primary relocates on the master and not have to worry about all of this here. I think it will be simpler all in all
I ran it and it took ~2-4 seconds, I was checking to see whether the `@Slow` tag was needed :)
ok, fair enough. ++ for setting up compatibility with GeoPointv2
is it worth doing the conversion from and to geohash every time here? Could it be better to not do the conversion and store two doubles per bucket instead of one long? I guess its a trade-off between execution time and memory
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
hmm maybe name it `markCommitted(long translogId) throws IOException` I think it sholud be IOException here
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
nit: extra line
operation can be `final`
`engine failure` -> shard failure
missing t at the end of the method name
strictly speaking, this doesn't need to be volatile. We update it under a lock which guarantees the visibility of the changes.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
this is dangerous. I'm not sure we can rely on this. Also testing the exact amount tests generic Transport functionality. I don't think we should do it here. Just keep it simple.
good! as for when we merge the branch...well we will do it when it's ready, most likely not before 2.0 but we don't know yet. One other thing about backporting fixes is that the branch is already big enough with the changes that we are making. If we can isolate non related fixes we simplify things a lot and clarify what happened when for the future.
ok didn't know that. yet another bug fixed in master then it seems
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
Can you switch this around and use the preferred name as first constructor argument? This way it looks like there's something special with this field, which I guess its not.
This was called "path" before.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
why have the condition at all? Just always overwrite? Same for disterrpct above
I'm not sure myself why this hasn't been done this way. :-) It's fine, I was just curious if you had tested calling super and if it introduced issues.
or just: ``` java if (Objects.equals(similarity(), other.similarity() == false) { conflicts.add("mapper [" + names().fullName() + "] has different similarity"); } ```
is it really possible that we receive join requests if `ZenDiscover#doStart()` hasn't been completed yet? this feels odd to me
yes, we can't do too much about this, so it is better be defensive here.
if we use a negative value here we can also just do this: ``` if (output.getVersion().before(Version.V_1_1_0)) { b = Math.max(0, b); } ```
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
drop the actually? sounds so "uncertain" :)
I think it should be: `<C> C readNamedWriteable(@SuppressWarnings("unused") Class<? extends C> categoryClass) throws IOException {`
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
I think it would be clearer to rename `file` to `dir` or `directory` here
+1 to not swallow the original exception
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
`FileAlreadyExistsException` is an `IOException` and this `IOException` block does the same thing as doing nothing -- `return CONTINUE;`.
Yes, but replace `FileAlreadyExistsException` with `IOException` to maintain the same functionality. Sorry for saying it so confusingly before.
we should include `e` here, otherwise we lose the cause of the configuration error.
please log the exception here as well we really wanna see what was going wrong
Writeable#readFrom returns a new instance of the object, it allows to have final fields, but it requires to have a PROTO instance of the object to call readFrom against. I wish there was an interface to declare writeTo only though but we don't have it at the moment.
Doesn't PipelineConfiguration deserve its own class file under o.e.ingest ? It's returned by the java api too.
nit: wondering if we can avoid parsing the map and rewriting it directly in json format. not sure there's a better way to do this.
you can remove the QueryParsingException catch, it's unreachable
close is supposed to clear as well so this shouldn't be necessary to call clearReleasables
we can remove this catch
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
OMG `== false`! ð±
hmm why did you remove the mapping from here? I think that was a good change? you should add the settings from from `public Settings indexSettings()` are only used if you use `prepareCreate` so you should add the settings to the versionSettings below. other than that it looks awesome
I don't think it is a good idea to call randomInBetween from here? We should save the result to a variable outside of the loop.
maybe just start a unicast cluster for now
why this opening bracket here and the closing one in line 186? Apart from that LGTM
and use the constant here
This is logic that I think should go into ReplicatedOperation.
this logic belongs in transportWriteAction
I think we should use `debug` for the logging here
please remove that blank line
the suppress warnings could be right on the line of code doing the cast instead of the whole method
Please fix identation.
this last line is redundant I think, we already check the same above
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
ignore this, sorry for the noise :)
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
oh, the boxing horrors :)
here we could use sublists again - just scan to the place you need. No need to reverse then.
removed can just be a count. We always remove from the beginning of the queue.
If we use Collection<Tombstonre> we can return an unmodifiableCollection() which doesn't copy stuff..
can we add the serialization logic we need to the Index object it self? we're likely to use it in other places.
sorry, my bad.
Since `value` internally is a String now, we can change read/write here as well.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
we set the rewrite method twice it seems? probably a bug in the original parser
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
I think we can check the beforePart == null out of the if(!..equals) and it will make it cleaner.
I think using a `LongAdder` would probably be more efficient than `AtomicLong`, since the value is not going to be inspected as often as its incremented
We need to cast indeed, but I want to give the compiler opportunities to find errors, which is never possible when one starts definiting methods whose generic parameter is only used in the return value. By the way I'm thinking that we could make casts more safe by making category a class instead of a string, and this class would be the base class of the object that the namedwriteables can deserialize
Would it be beneficial here to return an empty string instead of null? If not, maybe just annotate this with `@Nullable`
This seems to only be used for tests. Maybe it should be a helper method in the test framework instead of part of the public api? I would be afraid of something accidentally using this in ES code.
Ok, my confusion stemmed from the fact the first result when searching down the diff was ScriptProcessorFactoryTests.java, which this PR changes from testing against `getMessage()`, to using `getDetailedMessage()`. I see now that is the only case. Can it be switched back? Changing the tests to use `ExceptionsHelper.detailedMessage` seems ok given they all already use it.
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
We should nuke all this logic after the `super` call, because now we init the exception with `ex` as root cause, so it will still keep all of its suppressed exceptions.
I'd rather merge TermsQueryBuilder and TermsLookupBuilder, this is going to be a problem anyway when registering builders for serialization if we want to keep registering the parser only and deduce the builder from it . I don't see any value in having two builders for the same query, it becomes confusing for java api users too. Also, the easy way of creating queries should be through querybuilders, we can keep the existing `QueryBuilders#termsLookupQuery` but it will return a TermsQueryBuilder instead. We can also add more methods to `QueryBuilders` to create a terms lookup query that holds all the needed params.
we shouldn't need this here in parse phase
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
maybe we should had a LoggingShardFailureListener instead of the the default noop. That would mean we can only log trace here and allow the listener to decide what to log, potentially adding information like what it is going to do due to this failure.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
the way we check the resulting query here reminds of the previous createExpectedQuery, as we still leverage lucene's equals and because of that we run into issues. Also, it makes little sense to test the result by calling the same method that we call in prod code (handleTermsQuery). I would keep these checks more lightweight then.
Ok, what is your proposal then? The current test is not ok I think.
Got it, sorry didn't fully realize how value is initialized in any case before. So scratch this remark.
this is same as what we do in term query. We randomly choose a value depending on the type. We might choose the mapped field for that value type, or just pick an unmapped field for it.
same question as above
fielddata format can still contain arbitrary values: ``` PUT testidx { "mappings": { "doc": { "properties": { "user": { "type": "string", "fielddata": { "format": "fst", "blah": "blub" } } } } } } ``` I am however not sure what is expected here because when I get the mapping the wrong entry will be returned...
Old indentation was better because it made it obvious that the conditions weren't part of the body.
I think we can remove this exception now.
nit: missing a space after the first comma
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
Fine by me! Can you make an issue explaining it so we don't forget totally? I'd do it but I don't know the problem well enough.
I think we've started to use `setShard` style here? I'm not totally sure.
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
see text from other suggestion for empty primary allocation
I like this style. I think I'm going to steal it.
This API call is forbidden and fails the build. `random().nextBytes(randomBytes);` is fine though. I'll fix it before I merge.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
I wonder if using fromSeq and toSeqNo (instead of size) will result in this being less confusing.
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
maybe in a followup we can think about removing these -1s... see what platforms fail, and better fine-grain the stuff (e.g. add assumption for WINDOWS, IBM jdk, whatever it might be). Then we know when and where stats are available.
For backporting to 6.3, I think this needs to be changed to 7.
nit: the map can be `PluginBundle::plugin`
did you plan to add here the list of nodes or something? looks like there is a missing argument.
3 more indentation issues above
I think this is a left over.
I see what you are talking about. Weird. I'm fine with it then. I mean, I don't like it, but I don't really have to like it. It makes sense to make it look like the test above even if the test above looks funny to me!
I mean, we still need to create the index, but i don't think we need to do it inside a new block.
I'd rather have ISO timestamps in the example as it's what I'd prefer users to use. Same for start and end.
Checkstyle is unhappy with this.
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
can we assert that if we need to generate a new history uuid we always use `*_CREATE_TRANSLOG` as an open mode? that's why we rely on the translog uuid only for trimming purposes (and avoid thinking about what it means to generate a new history uuid)
a transformer and performer. Quite a guy :)
since we open the translog before the writer now - can we use the open translog for all this information rather than static reading it? this will make sure that we use something that went through all the right validations.
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
maybe replace this with ensureOpen in the beginning? feels cleaner to me
I think that we can save the instanceof checks, builder.value(Object) does it already
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
remove this additional line break? :)
ops turns out I had seen it because I was working on it for the date processor, i will add the needed method for string arrays.
I thought I saw some `List<String>` already but I can't find it anywhere, seems like we will add that when we need it then.
s/to list of/to the list of/
Oh, that error handling!
let's keep as is, with the assertion message I think it's ok. I wonder if we should have an assertion at the end of this method to say something like "if we have an active primary shard that's not relocating, then the replication tracker is in primary mode".
fyi - this gives you double [[]]
ah - now I see what you did it :)
Just a style note, we prefer the more verbose negation (`foo != true` or `foo == false`) over the short form (`!foo`), because the short form is easy to misread or overlook. :)
Even though this one should work, exact double comparisons tend to scare me a bit: should we use `null` instead of `-1` for non-existing x-axis units? (and store it in a Double)
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
That assumes `list` can't contain null..if that is not the case ignore
spaces after '//'
this is good as we already have a unit test for the filter. Wondering if that current BulkProcessingState object needs its own unit tests outside its use within a filter.
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
it's only as a safe guard for the future, or a warning for someone using totally the wrong classes. I think it's OK in these cases to fail the entire request? (unlink non-programmatic errors)
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
same here: ``` parser.longValue(true); ```
I think BuildFactory should be allowed to throw a ParseException since subclasses should have the ability to throw it if there is a problem with creating the builder at this point
Oh I see, it's the ZTable stuff. Sorry for the noise :)
This can stay as a break - exactInclude is the highest form of checking, no need to check more
Same here. Can stay a break
Same here. No need to continue
+1. It looks like a small method and while it might be inlined the extra `Tuple/Integer` are boiler-plate. If the method gets unrolled, both the index and the found value will be available without wrapping/boxing.
Since the index and the Map are associated, how about using only one `Deque` which holds a `Tuple` instead of two `Deque`: ``` Deque<Tuple<Map<String, Object> index>>` queue = ... if (node instanceof Map) { queue.add(new Tuple<>(node, Integer.valueOf(i)); } ```
can you add a //norelease here too? context should really go away after all queries are refactored
I would add an `assert this.context != null` here just to make sure
I always wondered the same, I think we don't given that everything works without... that said we do have a lot of empty constructors with the `@Inject` annotation. Up to you... ;)
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
Same here... we don't really need `String[] addresses`
There's an extraneous blank line here.
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
Discussed via chat - we should not use the Version.CURRENT as a default to make sure the version is set. The part about a 1.2.0 master is not relevant as it will set the SETTING_VERSION_CREATED key as well.
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
I donât think this buys you anything in terms of concurrency. The list reference is already final.
This has issues as two calls could wind up finishing this listener. I think it would be better to use a AtomicBoolean and compareAndSet.
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
this class could be made `final`
We typically do this light weight coordination on the same thread. I.e., Names.SAME . This does nothingother than spawn another bulk request. This will cause a new thread to be spawned as we don't do anything else with the bulk pool on the client. To be honest, I don't think the transport client should have so many thread pools. I'll open a different issue for that.
I suggest trace logging here
these replacements seem to be wrong the if / else logic is obsolete now
otherwise you could index into an alias that target a specific shard and yet index in other shards by specifying a routing key, which I guess could be seen as a bug
can we use different ids for the different indices? I find this super confusing to reason about. Maybe also add the routing value you expect to be used to the id.
I would make this class extend `AbstractXContentTestCase`, then your randomPutIndexTemplateRequest would become `createTestInstance`, and ``` @Override protected PutIndexTemplateRequest doParseInstance(XContentParser parser) throws IOException { return new PutIndexTemplateRequest().source(parser.map()); } @Override protected boolean supportsUnknownFields() { return false; } @Override protected void assertEqualInstances(PutIndexTemplateRequest expected, PutIndexTemplateRequest parsed) { assertNotSame(expected, parsed); assertThat(parsed.version(), equalTo(expected.version())); assertThat(parsed.order(), equalTo(expected.order())); assertThat(parsed.patterns(), equalTo(expected.patterns())); assertThat(parsed.aliases(), equalTo(expected.aliases())); assertThat(parsed.mappings(), equalTo(expected.mappings())); assertThat(parsed.settings(), equalTo(expected.settings())); } ```
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
we throw the exception and thus take care of the interrupt. We don't need to set it...
Nit: I think it will be safer to have this boolean as a parameter and determine the action here. I'm weary of arbitrary string input.
this doesn't mean the index is not active, but rather that it doesn't exist or is closed. I don't think we need to retry in that case. [Old cold would throw `IndexNotFoundException` in this case](https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/OperationRouting.java#L203).
The logging brackets are off here: `[{} to [{}]]`.
Why is this `volatile`? It doesn't look necessary to me.
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
can we add to this: "we have to do this after succesfully indexing into the primary in order to honour recovery semantics. we have to make sure that every operation indexed into the primary after recovery start will also be replicated to the recovery target. If we use an old cluster state, we may miss a relocation that has started since then."
I find it confusing the we have the same field names for this in both ReplicationPhase and PrimaryPhase.
actually I just got a bit confused because both classes are in the same file...
I've dug some more. This is caused by us running the tests with the built in gradle test runner rather than the randomized runner. We configure the randomized runner to run with the system properties but we don't ever configure the standard runner.
When I pulled this locally and reverted the changes to this file I didn't have any trouble. We've traditionally been very weary of making changes to this file so I'd really like to make sure we need this before we do it, even if it is temporary.
And some more: this is not caused by the build compare plugin. Maybe by gradle 4.8 or maybe by one of our hacks to make 4.8 work.
This assumes a version format that while fairly standard is not guaranteed.
I think we can do this more simply by looking at `endsWith(".jar")` of the uri string. We don't really need to convert the uri to a path, since we don't need to load the file. Then, the original if statement can simply be wrapped with like: ``` URL location = clazz.getProtectionDomain().getCodeSource().getLocation(); if (location.toString().endsWith(".jar") == false) { // original if and exception here } ``` Basically, if the file is in a jar, we don't need to worry about it here, as those would have already been added to the codebases map by `Security.getCodebaseJarMap`. This method is about adding classes that are on the classpath, but not via a jar (ie built by the IDE).
given where it ended up being called, I think that removing properties from config is not that useful anymore here? maybe we should have two versions of the method, one to validate and one called here so we avoid the deep copy? in theory the pipeline should be correct at this point right? no need to validate it twice probably
ok let me have a look then ;)
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
Doesn't PipelineConfiguration deserve its own class file under o.e.ingest ? It's returned by the java api too.
Writeable#readFrom returns a new instance of the object, it allows to have final fields, but it requires to have a PROTO instance of the object to call readFrom against. I wish there was an interface to declare writeTo only though but we don't have it at the moment.
then do something like this `source[n/a max source size: ...`
I like including the original size here. Maybe instead if the source is chopped it should read like `first 2048 characters out of 10122123: _slice_of_the_source_`.
I don't think we need the exact number of bytes and if bytes is what we have we should use it. No reason to work hard to get characters.
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
I think all of these need to be trace and we should enable these in tests that are relevant.
IMO lets drop them all. IF you have to make them trace you can also just add them back if you need it.
same request - please have a method called `haveWriteBudget` and do `while(haveWriteBudget() && buffer.isEmpty() == false) { `
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
this retry counter is tricky as we need to have a budget that allows all current read/writers to fail on a network hiccup. There's also the question on how people know what happen when the task is failed (where we might need support from persistent tasks). I think we can leave this for now but have to deal with it in a follow up.
Can we fix callers to concatenate streams instead of iterators? (which is already supported in the JDK)
just a style question but this loop looks more like a `do/while` would be easier to read IMO
this assumes that the returned array will be of the same size as tops. This will be true in practice since they are both arrays of doubles, but I think the code would be more robust if it called `resize(bottoms, tops.size())` instead of `grow(bottoms, owningBucketOrdinal+1)`.
can we keep the same semantics of other metadata parts and no write the key here (but rather in metadata class)
can this be called `assertConsistent` makes it clearer that it is used for assertions
I know this is existing, but I think we can lift this up to a singleton so that we do not create a new instance on every publish to every node.
can we add a check for whether we sent a diff? I want to avoid a potential infinite loop.
cool. lets look at it on another issue.
small typo, 'saving'
can we call this last seen clusterState? it doesn't need to be volatile as it is changed under a lock.
I usually do this: ``` assert xContentBuilder.generator().isClosed(); return true; ```
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
we shouldn't need this here in parse phase
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
I have yet to get to that alternative, I am lagging behind :)
I think you can leave null here. this init empty value will never be used as we throw exception when queryFound is false. Otherwise there are two places that can cause empty and that may be confusing.
nevermind, I guess it depends on how you look at it. at the end of the day this parse method does parse + toQuery, having QueryShardContext is fine given that it will still happen on the shard. Also given that the QueryParseContext is much more lightweight, it makes more sense if done this way. Plus the parse method will go away, so leave it as-is.
Typo: "Dynamics" -> "Dynamic"
can we assigne `indexService.mapperService()` to a var? just to remove the chaining :)
yeah nevermind I was confused about some internal classes
operation can be `final`
nit: extra line
you can replace with //norelease so we don't forget but at least you can get this in while we fix this problem in master.
remove the set boost
remove the setBoost
all these random values need to be saved out of the loop...you know what happens otherwise? :)
how much work would be to "decode" the values and expand the test? I am wondering if it's worth doing or not.
There's an extraneous blank line here.
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
good that you added this assertion :)
This thread can leak and fail the test, I think that you need to clean it up (join on it in tear down).
nit: space before brackets
typo: optain -> obtain
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
don't drink and code ð» (same line twice)
I think this can be removed (here and from the interface) and then `this.shardId` can be used in the only caller, the `.get()` method
`this` is unnecessary
Actually I'd still prefer to go with Colin's idea to use empty sets. We can still optimize later by making sure to use a Collections.emptySet (which is a singleton) if the size is 0.
Ok fair enough, I'm happy leaving this as is then
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
OK. Just double checking :)
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
This should be fatal.
I think it gets weirder to retrieve a prototype builder from an actual builder. Going through the parser is more logical to be honest. We can change when we need it later on.
I had a quick look and opened #25519 with what I imagine the strategy is. It certainly looks big enough to be worth doing in its own PR.
Fair enough. I wouldn't change the capitalization though.
I wouldn't name it in capital case because it isn't a constant. Otherwise I'm fine with whatever rename you like.
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
This empty `if` followed by this line looks off.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
ok can we rename the getter then to `getFailedNodeExceptions()`
This needs to handle the -1 case.
Oh right, sorry for the noise.
can we add a note here why this is optional? the validate request suggests otherwise...
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
I see, it became a writable...
I don't mind as long as we use `writeString/readString` and `writeOptionalString/readOptionalString` consistently. So you can maybe just change the `readFrom` to explicitly use readBoolean.
If its early I think this is safe - but now maybe the read timeout on test side will be too low.
10 seconds is pretty fast for some of these CI machines to get the whole ES process up. Does this happen pretty early in the process? Either way, this change might be shortening the timeouts that the CI nodes need to get ES up in time.
I'd prefer `param.substring("the 13 character string".length());` or something like that.
I think this needs to be wrapped in try/catch so that this doesn't cause a missed invalid line like: ``` 2147483648-:-XX:+TurnOnCatLasers ```
Nit: can you put this and `runWithoutJava` next to each other
What uses this? And why is forbidden APIs not angry about passing in String,int here... i feel like i banned that method. I dont like it as its wired to 127.0.0.1 in non-test code.
would be nice to allow to configure it to a percentage of the heap size
can we make that -1 a constant and use it in all the relevant places? it would be easier to remove it once we go to 4.0
can't we do this here: ``` Java void ensureNumberConversion(boolean coerce, long result) { if (!coerce) { double fullVal = doDoubleValue(); if (result != fullVal) { handleNumberConversionError(fullVal, result); } } } ```
we shouldn't need this here in parse phase
It would be nice to find another way to do this other than replacing the thread context. I had a look but didn't find other ways though :) I guess you have tried as well.
I think that we are leaking a thread local here? We should close the current threadContext before overriding it.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
> write past EOF :dancers: +1!
Instead of having this public ctor should we have one that has this signature: ``` Java public CompressedXContent(ToXContent xcontent, XContentType type, Params params) { // do the serialization here with checked output stream etc } ``` that way we can hide the _CRC32_ impl detail entirely
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
maybe its simpler to do this: ``` Java try (FileChannel channel = factory.open(checkpointFile, options)) { IndexOutput indexOutput = new OutputStreamIndexOutput (resourceDesc, checkpointFile.toString(), java.nio.channels.Channels.newOutputStream(channel), BUFFER_SIZE); // ... } ```
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
no need to set timeout, the default is good enough
can we try turning those into constants? I think we should try doing this all the time though.
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
can we check and stop if the background thread had any issues? o.w. will have to dig through more than needed.
`createIndex("test")` ? then you can remove the following `assertAcked`
I think something like `randomSearchSourceBuilder` would be a more consistent with other random builders.
It drives me bonkers that this is called "scroll" everywhere instead of "scrollId", but it's a matter of taste, no impetus to change it if you like it :)
I think we could check that successful == total shards and that total shards is greater than zero
super minor, but indentation is off here
Maybe this was already covered somewhere, but is `GENERIC` the right threadpool for this? (I don't have a better suggestion, just asking)
I'm happy we made those exist queries fast. :)
looks like there are two levels of indentation instead of one
Maybe in the future we want to add a new topology library, e.g. spatial3d, so I think it is better to name the method with a reference to the underlaying library.
I think this can be extracted into something like `float[][] lineToFloatArray(Line line)` since it appears 3 times in this file.
please fail if required stuff is null
I don't like leniency. Can it be `"true"`, `"false"` or `null` with the former parsing to the right `boolean` and null giving the default? A typo of `"tru"` will parse to `false` and that makes me :cry:.
The worst is how `on` and `no` both parse to legitimate values, very dangerous for transposing typos.
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
> I think we're talking about two different sets of leniency :) ++ :smile:
This should only be done in close()
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
I find it confusing with the `toXContent` coming from the `ToXContent` interface. Arguments help but I think naming is better now.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
I think something like `randomSearchSourceBuilder` would be a more consistent with other random builders.
It drives me bonkers that this is called "scroll" everywhere instead of "scrollId", but it's a matter of taste, no impetus to change it if you like it :)
I think that what confuses me here is that we call performRequest and performRequestAsync here, why do we mock the rest client then? Wouldn't it be better to test that RestHighLevelClient subclasses can use performRequestAndParseEntity and performRequestAsyncAndParseEntity (which are private at the moment)
I think we could check that successful == total shards and that total shards is greater than zero
super minor, but indentation is off here
scratch that, I think this will be fine as-is in 6.x as well.
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
we also support a parameter called `updateAllTypes` here.
Can you update the `\rest-api-spec\src\main\resources\rest-api-spec\api\indices.clear_cache.json` as well? ( do we need to specify all supported params, or only the preferred ones. There is also a `recycler` flag in the rest specs which I do not see in the code )
`fielddata` is the preferred name as of my merging #28943 today.
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
I don't think so, I think these should be bytes or size-value only.
++ to keep byteSizeSetting here
We call them "master nodes" everywhere else. :frowning:
connec to to -> connect to
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
good catch! that means we are not properly testing this case either given that we didn't catch it.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
+1 to have `fromXContent` and `parse` be static
while I get that the preference for a for loop... but the inconsistency of how xcontent is parsed is annoying.. if we do it everywhere using a `while (...)` then we should stick to that... if we want to change to a for loop, then lets do it across the board
replace match here too
let's not make this hold this PR, but let's keep track of this potential issue and address the need for generifying in a separate issue
same question as above
well, we can call it `ZenTestDiscovery` :) - my point is more that then we can move the `getZenPing` to the test only variant and not have it public on `ZenDiscovery`. There were also times where we considered mocking elect master service where this test-only discovery would have been useful.
Nit: this blank line is extraneous.
can we add that to ClusterStateCreationUtils? It might be useful for others as well
I wonder whether we should use `unicastConnectExecutor` for this and keep it contained (and throttled).
Actually plugins can implement `Closeable` and they will be closed when the node shuts down.
++ . nit: add the state to the message please.
Oh, that error handling!
same here re enumSet.toString
I'm on the fence regarding this one - on one hand it's a public api and people can do whatever with it so you don't want them to slow down the release of the lock. On the other hand as an API it is really weird to have `POST_RECOVERY` come in after `STARTED` (which may happen if the shard is allocated on master - though the chance is still very small)... will think more.
+1. Good catch. I missed it. It would still be good to kill the node when testing - so we should have some assertions here too.
not sure either, I just thought we introduced `parserName()` to have our temporary `toQuery()` method working. ``` //norelease to be removed once all query builders override toQuery providing their own specific implementation. public Query toQuery(QueryParseContext parseContext) throws QueryParsingException, IOException { return parseContext.indexQueryParserService().queryParser(parserName()).parse(parseContext); } ```
you don't have to assert on anything if an exception is expected
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
then check for non null here...
Compared to our other parsing code this is a little weird because it doesn't know what field it is parsing up front. I get why you do this, but it is weird. Also it is weird because we don't serialize all that much information. You get almost nothing if there isn't an error.
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
I had a look at all these parse methods. We might need to clean them up, we have too many variants of it, most of them are used in tests. But in general they are used by any component that needs to parse queries: percolator, highlighting (supports a separate highlight_query that gets parsed as part of highlighting), query rescorer, translog (old delete_by_query)...... I think those parse methods should be converted to fromXContent and return a QueryBuilder instead.
I think we might want to add this to the docs for delayed allocation (just so users are aware)
why did you decide not to do the approximation we talked about? i.e., `System.nanoTime() - (Math.min(0, System.currentTimeMillis() - this.timestap))* 1000000L;`
yes lets do it later otherwise we have to remove setters and break things.
sure things changes now that we know for sure the target branch, that said making everything final would be better to do once we merged back to master to prevent merge conflicts here. Same with renaming XYZQueryBuilder to XYZQuery, and moving to proper getters and setters.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
is this needed here? I think it does something only when the current token is start array or start object.
You can use `XContentParserUtils.throwUnknownToken()` (that would throw a ParsingException instead but I think it's appropriate here)
It seems like there are unnecessarily many levels where `null` is allowed. You're allowing `aggregatorFactoryBuilder` to be `null` here, but also in `FeatureIndexBuilderJobConfig` `aggregationConfig` is allowed to be `null`. I think at most one of these possibilities should be allowed.
typo: randon -> random
Should `job` be changed to the plural `jobs`? In ML we were told to use the plurals of `anomaly_detectors` and `datafeeds`. Other APIs that return lists of configs are also plural - `nodes`, `indices`, `aliases`, etc.
It would be nice if this class was immutable, and this line shows why it isn't currently. This is how to make it immutable: ``` List<CompositeValuesSourceBuilder<?>> sources = new ArrayList<>(num); for (int i = 0; i < num; i++) { CompositeValuesSourceBuilder<?> builder = CompositeValuesSourceParserHelper.readFrom(in); sources.add(builder); } this.sources = Collections.unmodifableList(sources); ```
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
I believe we've been just using the string version of field instead of these lately.
Nit: `cs version` -> `cluster_state_version`, please.
Maybe we should try to use a vLong? 8 bytes per bucket can be significant if there are lots of buckets
let's save a few lambdas: `context::nowInMillis`
ie. when showTermDocCountError is true
maybe make sure it's positive
mayb just do `if (++count >=`
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
Maybe call the validate method on the TermVectorRequest? it will check for things we check here and more... It is also more future proof.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
You can use the diamond operator here.
You can use the diamond operator here.
This can all fit on one line.
I think we should add custom validators / parser to make sure that `min <= max` at the settings parsing level. I know they have a cyclic dep. So I think you need to create two instance of each for the validation and for the actual registration, I thinks worth it.
Nit: addresses -> address
oh... didnt see the `updateInvocation` counter... nvm
nit: extra newline
nit^2: `assertThat(putTemplateListeners, hasSize(additionsCount));`
nit: extra newline
Nit: `parallel` -> `concurrent`
ok thanks for the explanation. @s1monw any magic that we can do to fix this? :)
I think this constructor can go away
what is this provider doing here? We can't do this in our production code this will take hours for decouple again We either pass a client or not but not yet another indirection.
not sure if we need it here, it's a transport client, not node client...
ok...but client depends on the transport service anyway no? I think I don't get it
we do this kind of parsing in several places maybe a util can help at some point? not sure just an idea
would it be possible to eagerly initialize the clients and make them final? I don't see why not, but maybe I am missing something.
are there concurrency concerns here that closeClients is called while we are initializing? I see that both `hasXPack` and `nodeVersions` are explicitly assigned to non-null values. anyways, I guess assertions do not hurt!
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
alright I can't see a reason why one would have the two clients using different protocols. Then reading from settings becomes overkill. I am sorry, I think I'd go back to the method that you had before then. It was a good one, I just needed to see it gone to realize that :)
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
Fine with me.
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
yep. missed it. sorry for the noise
nice one. Good to add.
can we add some randomization here around the version - check that new has a higher version then old and vice versa
Typo: `afllowed` -> `allowed`
Nit: `parallel` -> `concurrent`
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
I suggest adding a volatile flag called `running`, add a method called `stop` that sets it to `false` and interrupts the thread.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
Nit: " . " -> ". "
instead of if statements maybe use switch statement? ``` java switch (toType) { case: "integer": // do stuff break; case: "float": // etc. } ```
maybe move all these if checks to execute method? (I personally find that easier to read, when we get in do\* method we know we're good to go) Like this: ``` java if (update != null) { doUpdate(data); } // next if ```
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
can't we just call this feature `trim`? `trim` personally makes more sense to me.
maybe wrap all these maps in `Collections#unmodifiableMap(...)`? To enforce that no changes can be made.
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
It could be useful for debugging too. In the future it's conceivable that the support diag tool might use the HLRC, and we wouldn't want to be dropping this value.
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
Can you make this non-pretty, it's always weird when you log things and then end up being multi-line
This is only used in the constructor, doesn't need to be a field.
No, that's fine.
I'm undecided about whether this is too much machinery, and a simple `Mode` variable would be enough.
can we implement `Closeable` and use an AtomicBoolean to signal it's closed I like the `if (closed.compareAndSet(false, true))` pattern
why is shit guice exposed at all? Can't we reduce the number of @Inject here please it's such a pain to unwire all of this. Can we simply remove the @Inject and all the wiring and to in `PipelineStoreBootstrapper` ``` Java ReloadPipelinesAction action = new ReloadPipelinesAction(settings, pipelineStore, clusterService, transportService); ``` we can go even further and also don't wire `PipelineStore` and just call new in the bootstrapper as well.
I had a look and the settings code has been dramatically improved with 5.0 already, hence this fix is not required any longer. Nothing to do then, but thanks again for pointing this out.
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
1. There is a minor typo/grammatical mishap here - text should read "[cluster.name] must not _contain_ ':' character" 2. Id consider putting this exception text into a final static variable somewhere it would make sense to put it. This text is currently used in two places in the code - once here, and once in a unit test - and the way things are now, if you want to change the contents of this text, you need to change two strings in two different places in the code. If you had this text in a final String variable, and you referenced that variable here and in the test, you would only ever need to change the string in one place.
master_election.filter_data [{}] is a leftover I think
`limitedTo(long bytes)`? Clone is kinda non-specific.
when is this needed? I wonder if this marks that something is wrong and we should throw and exception.
oh cool the read is in the ctor! nice!
can we name this `CompleteDiff` don't use simple please :)
If we use Collection<Tombstonre> we can return an unmodifiableCollection() which doesn't copy stuff..
This constructor doesn't seem to be necessary.
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
connec to to -> connect to
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
We call them "master nodes" everywhere else. :frowning:
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
no need for `else` here
I think s/lang/defaultLang/
Fine by me.
Maybe this one too, I'm not sure.
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
> At the same time though, acquiring the write lock would be good, because even though there is a warning that this should not be run when ES is running, trying the lock seems like it would be a good idea Definitely, +1
It won't always be the case that there will be one index commit, sequence numbers will change this assumption.
I'm not super comfortable making this. I think maybe instead we should add the match skipping at the `FieldParser` level. Maybe some kind of subclass that skips or something. Not sure.
this example is not that close to reality. we cannot really parse such an agg as we need its type in the name (type#total_number_of_ratings). That is what makes the field not unknown, which is why I am not convinced that the mechanism should be a match all.
I guess it is "these" marked consumers now.
I think you are missing a `\n` here.
Fine by me.
do we want to check the phase/action times since those are meant to change
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
oh, woops. thought I counted right. sry
Out of date doc.
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
I'm fine with leaving it, yeah. I did want a prettier one but if this is what we can do, it'll do.
I talked with @costin earlier about this - he wants to keep the order the same and my proposal doesn't. What about this? ``` while (result.size() > 1) { ListIterator<Expression> itr = result.iterator(); while (itr.hasNext()) { itr.add(combiner.apply(itr.remove(), itr.remove())); } } ``` Your version works but `for (int i = 0; i < result.size() - 1; i++) {` make me think it'll be a normal loop and then you remove and add and I'm confused. Using the `ListIterator` forces the reader to think.
Can you name `equ` and `eq` a little more differently? They sort of blur together to me when I read this.
If the constructor is modified, this method won't be needed anymore.
The type check should happen inside SUB not in its parent class...
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
As long as you're using Optional here, I think this could be ```java ExceptionsHelper.maybeError(maybeFatal, logger).ifPresent(e -> { try { logger.error(maybeMessage, e); } finally { throw e; }}); ``` Up to you if you want though
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
can we use getters here like `getNode` `isCanceled`
same here these strings are only used in one place just use them directly and trash the Fields class
I took another look at MovAvgModelStreams, and although I'm not completely sure it look a lot like what NamedWritable is doing, so I was wondering if Stream could be replaced by it.
Curious about where the stream name gets read on the receiving side. Maybe read/write could be changed to be more symetric, but I haven't completely checked the deserialization code.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
> I'm going to add the static method, but I do want to note that the method name is toInnerXContent rather than toXContent, so it's not overridden by any of the child implementations. Sure but it _can_ be overridden, if it is overridden it must be called, and it has to be called by the `toXContent` methods on the inheriting classes that do implement `ToXContent` The typical pattern to address this is to make `toXContent` final and have it delegate to an abstract `doToXContent` inner method that the inheriting classes must override. But the reason that I do not like that solution here is because not all of the inheriting classes will implement `toXContent` so I do not think this method should be on the super class at all.
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
Sure I was just wondering if there is a use case for this.
Why would a user set this setting to false ? It's not taken into account when the shard is closed due to relocations or when the index is removed so is it useful to have it as an updatable index setting ? IMO this could be a chance to remove the setting and force the value to true.
The `<=` will need to be escaped.
DEFAUTL -> DEFAULT again
Nit: " . " -> ". "
Lol - I spent some cycles trying to figure out how the hell we know this won't throw an index out of bounds exception, only to end up learning something about the BitSet api - it's funky ;)
This is fine as-is.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
It would be nice to find another way to do this other than replacing the thread context. I had a look but didn't find other ways though :) I guess you have tried as well.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
I think this should happen first to make this PR less complex
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
space between `if` and `(`
and use the constant here
Maybe call this "testEmptyBoolSubclausesMatchAll()"? Sorry if I misunderstood what the test is doing, I just think having a github issue number in the name is unhelpful to someone if they see a failure.
I see, I didn't notice that, cool no problem
nitpicking here...but we could use an array instead of a list and avoid the conversion list to array afterwards
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
nit: extra newline
nit: extra newline
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
btw - the test uncovered some issue with the dangling indices import. You might run into a node not connected issues - working on an independent fix.
Yeah, it seems it is. We treat non existing indices as red. Thx for educating me.
I think there is a race condition here - it may take some time for the dangling logic to kick in (it's async via network calls). I would assertBusy until the index is visible in the cluster state, then go into ensure green.
and use the constant here
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
I might do `assertThat(totalShards, greaterThan(1));`.
I see that we need it from another package, I think it's ok.
maybe reverse this check? (`expected.equals(map) == false`)
... and this doesn't need to know it either.
maybe you can just delegate to `read(byte[],int,int)`
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
can you use try with resource here since we are on java 7 now ie: ``` Java try (CBORParser parser = CborXContent.cborFactory.createParser(content)) { parser.nextToken(); generator.copyCurrentStructure(parser); } ```
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
@s1monw if you're proposing we use inheritance and you assume the base class will always be caching DF then we could just remove all the "if(this.docFreq)" checks in the existing code as a simple way to clean things up? That would leave us with just the "if(this.totalTermFreq)" checks.
I think we should have a baseclass that only handles DocFreq and then subclass it if we need TTF that should remove a lot of branches here though. I don't like the long methods that basically repeat code because of the TTF / DF swtiches. I mean it makes sense do split it since they have a higher cost if TTF is needed though.
+1 there is a good example in BlendedTermsQuery though
Different leaves might use different codecs, and some of them might support `totalTermFreq` while other leaves might not. So this should return `-1` if any of the leaves returned `-1`.
I still don't get why we have all these branches. For the `docFreq` we can just calculate is all the time. For the TTF we can just do what lucene does internally: ``` if (totalTermFreq == -1 || leafTotalTermFreq == -1) { totalTermFreq = -1; continue; } ``` then we don't need the `hasMissingTotalTermFreq` alltogether
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
we should move to have an inner terms lookup builder. BTW You don't necessarily need to have a flag in your class, you just have to serialize what the method returns and read based on that on the other side. If you read correctly the method will return the right result. The flag would anyway depend on other instance members as far as I can see.
I think we will need to serialize this boolean flag so we can fix the problem we right now have in the readFrom
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
Fine with me :) I'm already wiping the repository itself after each test, so this shouldn't have much effect (I don't think).
I don't think is necessary. `request` is passed as`params`. So, "verbose" is already in `params` if it was specified, you just need to be careful resolving defaults. You would also miss other parameters here such as human and pretty.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
To coerce, should be: ``` parser.longValue(true); ```
same here: ``` parser.longValue(true); ```
Error if old-style params passed alongside new-style script
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
Oh I see, it's the ZTable stuff. Sorry for the noise :)
We need to check here if `ttl` read from translog is lower than 0, if so, then we actually don't have a value...
Oops nevermind, I misread.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
yeah nevermind I was confused about some internal classes
Here you call super method while in toQuery/doToQuery, doEquals, doWrite etc... superclass calls abstract method. Any reason why this is different here? Might be more consistent to follow one pattern and have the superclass always call concrete implementation? Just an idea really.
Maybe this should use a Boolean instead (the object wrapper) and only write it if not null. I know the other integers are not doing it, but I think this one is different since `true` is a valid value while `-1` is an invalid value for the other fields.
can we fix this and use `more_like_this` rather than `moreLikeThis`
it's fine, when I did the refactoring SpanQueryBuilder became an abstract class without any problem, but now it needs to be a marker interface again cause java doesn't support multiple inheritance ;) We just need a cast, sorry for the noise I had missed this change to be honest but now I get it, thanks a lot for digging!
I am starting to see that the default boost doesn't get printed out but other default fields do. Makes sense to me but maybe we want to be consistent? I think we should have this a separate discussion, make some decision and do the same everywhere (I have the feeling we are not yet settled yet on one way or another)
Can change this to the new autoclose functionality in Java 7 now that the codebase is on it: ``` try (ZipFile zipFile = new ZipFile(pluginFile)) { // ... } catch (Exception e) { // ... } ``` Thereby dropping the entire `zipFile`-related code from within the `finally` block.
It'd be better, to only skip the config files that have the same name, not the whole directory. So for example, if currently es has a config dir that looks like this (for plugins `foo`): ``` /config/foo/bar.yml ``` and the new plugin that installs needs to copy two files there: ``` /config/foo/bar.yml /config/foo/baz.yml ``` we'll skip `bar.yml` but we'll still copy `baz.yml`. This will help us a lot when we guide the user on how to upgrade - instead of telling the user, to copy & modify a bunch of files, we'll only need to tell him to modify files under `config/foo`
Feel like this should be more significant than `debug` because it really indicates a form of failure in some scenarios.
Would it be easier to copy the old config to somewhere else, then replace it rather than trying to mix adding new files while keeping old files? I feel like this will be very confusing for users, especially if `file1.yml` had changes coming from both directions.
ah I mean't Throwable.... sorry
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
can you add a //norelease here too? context should really go away after all queries are refactored
Ok, then it's fine.
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
maybe we should just get rid of this local variable and write the next line: ``` nodesIds = filterNodeIds(clusterState.nodes(), resolveNodes(request, clusterState)); ```
"Simulate a task that attempts to execute only on filterNodes. We are testing that this works."
I think this file needs formatting `if(` -> `if (`
ok fair enough I didn't try it :)
this method seems to be wrong here the class is concerned with fetching data in an async fashion, I think what we do with it or what we call as a result should just be somewhere else. I wonder if we can just have an ActionListener that we pass to execute this onSuccess and onFailure since those seem to be the two mode we have.
oh man that class is a nighmare. really I just realized how fucked up this is grrr.
I also wonder if we can trash this method then altogether a make `GatewayAllocator implement ClusterStateListener` and add it to the `ClusterService` once constructed or maybe inside the ClusterService...
I dropped QueryRegistration in https://github.com/elastic/elasticsearch/pull/17458.
Sounds good. I was also wondering if we need the QueryRegistration object since I think we should be able to directly register the query with the named writeable registry and the parser registry in the register method
oh nevermind I see there is a storedField method too
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
we should move to have an inner terms lookup builder. BTW You don't necessarily need to have a flag in your class, you just have to serialize what the method returns and read based on that on the other side. If you read correctly the method will return the right result. The flag would anyway depend on other instance members as far as I can see.
I think we will need to serialize this boolean flag so we can fix the problem we right now have in the readFrom
extra space makes everything not line up!
Missing a space here after `id`
Elasticsearch tradition is to make this an EMPTY constant :)
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
no utils for this :( `out.writeLongArray()` maybe :)
same here re enumSet.toString
I prefer my way but have asked @jasontedor to chime in.
++ . nit: add the state to the message please.
we throw the exception and thus take care of the interrupt. We don't need to set it...
+1. Good catch. I missed it. It would still be good to kill the node when testing - so we should have some assertions here too.
can you use `InetAddresses.forString` intead, which guarantees it won't do a dns lookup
I also think we can add a method that checks for precision to simplify this! please
same as above, no need for try catch
Note to remember: while this is kept as a QueryBuilder internally, I think we need to make sure to call `toFiler()` on it once on the shard (e.g. in the new build() method, doesn't seem to be there yet)
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Same, copy-paste error here
This looks like a copy-paste error
this would make sense especially given that their setters accept primitive types
wonder if we should make these Integer and Boolean just int and boolean primite types.
Hope this doesn't bite us for really slow (read: Windows) CI servers...
This is going to be 512 Unicode code units, but I think we should do bytes.
nit: maybe use Strings.isEmpty.
This should be `aliasAction.aliases == null || aliasAction.aliases.length == 0`
Without this we get: ``` { "error": { "root_cause": [ { "type": "null_pointer_exception", "reason": null } ], "type": "null_pointer_exception", "reason": null }, "status": 500 } ``` ``` [2016-02-09 15:56:02,492][INFO ][rest.suppressed ] /_aliases Params: {} java.lang.NullPointerException at org.elasticsearch.action.admin.indices.alias.IndicesAliasesRequest.validate(IndicesAliasesRequest.java:289) at org.elasticsearch.action.support.TransportAction.execute(TransportAction.java:62) at org.elasticsearch.client.node. ```
nit: Excluding the first word the error message is duplicated and could be extracted.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Sorry, I overlooked the null check. This is good!
Ahh, sorry. You are 100% correct.
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
these unit tests are great! We are going to need more of them :)
after rebase you will have to get rid of any wildcard import, or the build fails :)
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
this should just throw IOEXception no need for a shadowing ConfigException
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
if we only use all names to put things in the map we lose all the deprecation warnings that we might have etc. we should rather keep track of the original ParseField and call ParseFieldMatcher#match.
I think you are missing a `\n` here.
but if you are in strict mode you get an exception so you don't get back false :)
this is same as what we do in term query. We randomly choose a value depending on the type. We might choose the mapped field for that value type, or just pick an unmapped field for it.
Got it, sorry didn't fully realize how value is initialized in any case before. So scratch this remark.
ah ok I see
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
I will take care of this.
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
No "unsupported HTTP method" message? :)
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
Again, need to figure out what to do if ATOMIC_MOVE is not supported
I like the idea of the predicate. It could for instance be something like `registry.supports(name, Aggregation.class)`. This way we could also support ignoreUnknownFields for forward compatibility
BiPredicate<String, NamedXContentRegistry> ? is that ugly? :)
I am trying to think if these can be a single field rather than two that are so tightly coupled. I couldn't come up with a good idea but maybe you will...
I find it confusing to have a fallback/unknown field parser and still be able to ignore unknown fields. I'd make these two mutually exclusive, ie not possible to define an unknown field parser if `ignoreUnknownFields` is set to true.
but we do have to do both right? the logic should be: check whether the agg is a registered one by type, where the type is part of the name (type#name). If not, ignore the field (for forward compatibility).
indentation is off after other changes
maybe: ``` Java for (int i = 0; i < params.length; i++) { paramsMap.put(params[i++], params[i}); } ```
this will not work, right? cause the default is `9300-9400`, which is good, since we want to try another port on the second instance we start on the same machine.
Impl. `Closeable` here as well then you can use `IOUtils` from lucene to supress exceptions etc.
maybe just use `IOUtils` here they handle null values as well
this loop is hard to follow. I think we can make this more elegant by using a sublist and make sure we process all of them. we can also peak at the first element and get it's generation to calculate the range directly.
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
Hmm why are we ignoring exceptions here? You can consolidate those two `deleteFilesIgnoringExceptions` into one call and it will do the right thing if either path hit an exc while being deleted...
can we please not use `forEach` I think we should stick to for loops it just makes the code more readable and consistent
Can we add a Math.max(0, currentTime - Math.min()) ? we rely on this being non negative, but time may go back and the FS may have other quirks.
gotcha, thanks for explaining.
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
I think we can remove this
Is this an oversight? `DEFAULT_KEEPALIVE_SETTING.get(settings)`
I don't think we need this branch anymore.
ok as a follow-up
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
This is too subtle - if someone reduces the number of iterations it is very easy to miss the point that it has implications for this. How about making a max attempt constant (set it to 5) and then here do something like fail.failRate(attempt == MAX_ATTEMPT ? 100 : 30)
we do this so often. I wonder if it's time for a utility method.
++ thanks for changing this :)
don't prettyprint please we don't test this here
I think checking for newline is better than relying on pretty printing having space between key/object...
Nit: it isn't a jsonBuilder - it is whatever kind of xcontent was passed in. Nit: maybe only set prettyPrint if the original had it set? I don't know if you can tell though. Neither are a big deal.
nit: some whitespaces around the operators etc... would be nice
I think we should keep it in the name even if it is verbose
I still don't like the verbosity of this... it can get really hairy... another option is to have a boolean overloaded version of the method instead: ``` public void writeOptionalStreamable(@Nullable Streamable streamable, boolean apply) throws IOException { ``` then have it used as: ``` public void writeTo(StreamOutput out) throws IOException { ... out. writeOptionalStreamable(streamable, out.getVersion().onOrAfter(Version.V_1_2_0)); } ```
there are... but I believe this is the most common one by far, hence my suggestion
Use IllegalArgumentException for checkVersion functionality as well. It fits better than IllegalStateException I think (the node does not need to look at current state to reject serializing the message but just at the arguments).
If you add `// nocommit` any time that you add a debug line like this, the build will help you remember to remove it (a pre-commit check will fail).
> If there are multiple commits, what does IndexWriter.getCommitData() return? I am guessing it reads the "latest" commit's data? Yes, the latest.
It won't always be the case that there will be one index commit, sequence numbers will change this assumption.
> At the same time though, acquiring the write lock would be good, because even though there is a warning that this should not be run when ES is running, trying the lock seems like it would be a good idea Definitely, +1
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
Again, need to figure out what to do if ATOMIC_MOVE is not supported
good catch! that means we are not properly testing this case either given that we didn't catch it.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
can we change this to Loggers.getLogger(getClass());? it is what it should have been to begin with, which is my fault ;)
Do you think we could have something like: ``` java bulkRetry = Retry.on(EsRejectedExecutionException.class).policy(BackoffPolicy.wrap(backoffPolicy, task::countBulkRetry)); ``` I find it easier to know what's going on on bulk retries.
For readability, could we have ``` java List<SortBuilder<?>> sorts = mainRequest.getSearchRequest().source().sorts(); if (sorts == null || sorts.isEmpty()) { mainRequest.getSearchRequest().source().sort(fieldSort("_doc")); } ```
Maybe merge all the groovy securing code into one place? It feels funky to have the default receiver whitelist here but method blacklist above.
`limitedTo(long bytes)`? Clone is kinda non-specific.
So I'm thinking of using this in the reindex API which'd make it used inside of Elasticsearch. Taking a ThreadPool is fairly normal for the internals of Elasticsearch. I suppose if you wanted to keep API backwards compatibility then you could make it optional and the whole thing to fail if one isn't provided but a backoff needs it.
Should we be spawning a new thread here? Other places ES is pretty careful to use some pool.
> I'd rather play safe here and use client-side locking on all list accesses in order to avoid that another change introduces a subtle visibility issue I always get a bit jumpy about just locking things because I don't have a great understanding of when Java is allowed to reorder instructions around locks vs volatile. Its worth looking into more.
> Backos off Typo
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
This doesn't feel right to me, adding a parameter to the bootstrap check infrastructure that is specific to a check. I think that we should try to find a different approach (I'm happy to help brainstorm about this, but I have not yet done so).
canceled -> cancelled
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
Nit: missing `@Override`
The message is a little weird. I don't think "next release" should be mentioned.
Can you use `== false` here...the `!` is almost hidden in all the other text around it...
nit: missing a space after the first comma
te -> the
And the same for TextFieldMapper, although that is a little different since it uses parseTextField...
would you mind adding `<>` after `new PriorityQueue` ? otherwise this is an unchecked assignment.
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
this only works if we have entries? shall we check? Also can we just do a for loop here instead
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
Or do it as a direct followup, I suppose.
you can have a look at SimpleQueryStringBuilder.VERSION_5_1_0_UNRELEASED to see how to do it
new is not possible with an older version...
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
Would you kindly add some line feeds here to make it look like json instead of a wall of text? It'd be so much easier to read.
This method can be package-private.
Here you can do something like this: ```diff diff --git a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java index 356b9a29dc..36794e880f 100644 --- a/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java +++ b/core/src/main/java/org/elasticsearch/discovery/zen/PublishClusterStateStats.java @@ -65,9 +65,11 @@ public class PublishClusterStateStats implements Writeable, ToXContentObject { @Override public XContentBuilder toXContent(XContentBuilder builder, Params params) throws IOException { builder.startObject("published_cluster_states"); - builder.field("full_states", fullClusterStateReceivedCount); - builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); - builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + { + builder.field("full_states", fullClusterStateReceivedCount); + builder.field("incompatible_diffs", incompatibleClusterStateDiffReceivedCount); + builder.field("compatible_diffs", compatibleClusterStateDiffReceivedCount); + } builder.endObject(); return builder; } ``` which makes the JSON-structure clearer in the code.
Nit - strictly speaking these are publishing stats, can we open the object with just published cluster stats (drop received). You can maybe received back in the keys, which can be shorted by dropping the cluster states from the key names - itâs implied from the object theyâre in.
We've been moving away from these inner fields classes, we don't need them to encapsulate some strings.
Capturing what we discussed f2f: I don't know how to best fix this - I'm ok with putting this in with NORELEASE for now, but this definitely needs either an equals implementation that doesn't rely on serialisation or it should be moved to the test code.
maybe omit lowercase from the method names here? (since these tests also run for uppercase and trim)
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
same as above, no need for try catch
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
Let's make this a `SetOnce<BlobContainer>`
Same here, make this a `SetOnce< BlobStore>`
better yet, how about the following? This way it's clear how a `delayOperations` call is matched by the undelay logic. ``` diff --git a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java index 7fc56a1..f1c8b0d 100644 --- a/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java +++ b/core/src/main/java/org/elasticsearch/index/shard/IndexShardOperationPermits.java @@ -27,6 +27,7 @@ import org.elasticsearch.action.support.ThreadedActionListener; import org.elasticsearch.common.CheckedRunnable; import org.elasticsearch.common.Nullable; import org.elasticsearch.common.lease.Releasable; +import org.elasticsearch.common.util.concurrent.AbstractRunnable; import org.elasticsearch.common.util.concurrent.ThreadContext.StoredContext; import org.elasticsearch.threadpool.ThreadPool; @@ -95,7 +96,11 @@ final class IndexShardOperationPermits implements Closeable { throw new IndexShardClosedException(shardId); } delayOperations(); - doBlockOperations(timeout, timeUnit, onBlocked); + try { + doBlockOperations(timeout, timeUnit, onBlocked); + } finally { + releasedDelayedOperations(); + } } /** @@ -110,12 +115,21 @@ final class IndexShardOperationPermits implements Closeable { */ <E extends Exception> void asyncBlockOperations(final long timeout, final TimeUnit timeUnit, final CheckedRunnable<E> onBlocked) { delayOperations(); - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - try { - doBlockOperations(timeout, timeUnit, onBlocked); - } catch (final Exception e) { + threadPool.executor(ThreadPool.Names.GENERIC).execute(new AbstractRunnable() { + @Override + public void onFailure(Exception e) { throw new RuntimeException(e); } + + @Override + protected void doRun() throws Exception { + doBlockOperations(timeout, timeUnit, onBlocked); + } + + @Override + public void onAfter() { + releasedDelayedOperations(); + } }); } @@ -150,25 +164,30 @@ final class IndexShardOperationPermits implements Closeable { throw new TimeoutException("timed out during blockOperations"); } } finally { - final List<ActionListener<Releasable>> queuedActions; - synchronized (this) { - queuedActions = delayedOperations; - delayedOperations = null; - delayed = false; - } - if (queuedActions != null) { - // Try acquiring permits on fresh thread (for two reasons): - // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. - // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by - // ThreadedActionListener if the queue of the thread pool on which it submits is full. - // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure - // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. - threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { - for (ActionListener<Releasable> queuedAction : queuedActions) { - acquire(queuedAction, null, false); - } - }); - } + releasedDelayedOperations(); + } + } + + private void releasedDelayedOperations() { + final List<ActionListener<Releasable>> queuedActions; + synchronized (this) { + assert delayed; + queuedActions = delayedOperations; + delayedOperations = null; + delayed = false; + } + if (queuedActions != null) { + // Try acquiring permits on fresh thread (for two reasons): + // - blockOperations can be called on recovery thread which can be expected to be interrupted when recovery is cancelled. + // Interruptions are bad here as permit acquisition will throw an InterruptedException which will be swallowed by + // ThreadedActionListener if the queue of the thread pool on which it submits is full. + // - if permit is acquired and queue of the thread pool which the ThreadedActionListener uses is full, the onFailure + // handler is executed on the calling thread. This should not be the recovery thread as it would delay the recovery. + threadPool.executor(ThreadPool.Names.GENERIC).execute(() -> { + for (ActionListener<Releasable> queuedAction : queuedActions) { + acquire(queuedAction, null, false); + } + }); } } ```
I think it's still nice to keep the debug logging as we had before.
Nit: missing `@Override`
This might be `WRITE` actually - we are creating an index or modifying an index after all.
This is tough one. During snapshot operation, we create a record about running snapshot in metadata. So, technically we write into metadata. It's not a persistent record though.... so it all depends on the definition of the metadata. Maybe it was a mistake to put snapshot into metadata though. Now I am thinking it should have been custom cluster state level element. So, we might want to move snapshot into cluster state custom and use READ here.
can you explain why? :)
.... because it remove a record created in create snapshot. So, if it's METADATA_WRITE there it should be METADATA_WRITE here.
Let's stick with `METADATA_WRITE`.
I usually do this: ``` assert xContentBuilder.generator().isClosed(); return true; ```
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
does this work? it works for percentiles, but with percentiles rank it's reversed
Maybe as a followup (at sometime, not that important) the callers of this could be made to use the one line impl here. Just seems like a silly method to maintain.
`readFrom` is going to be removed from the `Writeable` interface, maybe in a few hours. Right now it has a default implementation telling you not to use it. So I'd just skip this bit.
Okay, don't forget the versioning when this is backported to 2.x!
I've been moving these up, right under the other constructors and moving writeTo under it.
I see the symmetry of having these two methods. I still wonder if it'd be as readable if you removed them and used the ctors directly.
I don't like super methods that when they _are_ overridden, they _must_ be invoked. I also don't like that this method is on the base class and thus inherited by response objects that do not implement `ToXContent`, I think that is misleading. Lastly, I think that we should include total/successful/failed counts in the response. My specific suggestion is to add a method to `RestActions` similar to `RestActions#buildBroadcastShardsHeader`. I think it can look something like this: ``` java public static <TNodesResponse extends BaseNodeResponse> void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final BaseNodesResponse<TNodesResponse> response) throws IOException { final TNodesResponse[] responses = response.getNodes(); final FailedNodeException[] failures = response.failures(); final int successful = responses != null ? responses.length : 0; final int failed = failures != null ? responses.length : 0; buildNodesInfoHeader(builder, params, successful + failed, successful, failed, failures); } public static void buildNodesInfoHeader( final XContentBuilder builder, final ToXContent.Params params, final int total, final int successful, final int failed, final FailedNodeException[] failedNodeExceptions) throws IOException { // nocommit: add a constant to Fields builder.startObject("_nodes"); builder.field(Fields.TOTAL, total); builder.field(Fields.SUCCESSFUL, successful); builder.field(Fields.FAILED, failed); if (failedNodeExceptions != null && failedNodeExceptions.length > 0) { builder.startArray(Fields.FAILURES); for (FailedNodeException failedNodeException : failedNodeExceptions) { builder.startObject(); failedNodeException.toXContent(builder, params); builder.endObject(); } builder.endArray(); } builder.endObject(); } public static <TNodesResponse extends BaseNodesResponse & ToXContent> BytesRestResponse nodesInfoResponse( final XContentBuilder builder, final ToXContent.Params request, final TNodesResponse response) throws IOException { builder.startObject(); RestActions.buildNodesInfoHeader(builder, request, response); response.toXContent(builder, request); builder.endObject(); return new BytesRestResponse(RestStatus.OK, builder); } ``` And then `buildResponse` call sites can just look like `return RestActions.nodesInfoResponse(builder, request, response);`
wondering if this should call `this(stats.queryCount, etc.)`, since the addition is not required given that we are creating a new object
This should be the version we are going back to, so 6.5. In this PR, disable bwc tests in the root build.gradle file. Then re-enable in the backport, and do a followup to master to re-enable there as well. This minimizes the changes necessary to followup to master (instead of needing to remember and change all the places that have this version constant).
I am concerned this will cause a ton of calls to `nanoTime`. We can prevent this by using `ThreadPool#relativeTimeInMillis()` (if we need nanosec resolution we can add it here too). This means we need to pass a `LongSupplier` to the stats somehow but I think it's worth it.
if we use millis then we really should make sure that time doesn't go backwards!
no need for this to be public
And we could then just leave an assert here.
+1 then we shouldn't forget about it :)
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
update version to beta 1
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
To clarify, I meant the default indices options used if the user doesn't set them.
not 100% sure we wanna return e1 here as failure, maybe the original one would be better given that the fallback call failed? I guess it depends on how you look at it... since we don't check the version of the node we are talking to. Maybe it's good as is, not sure really
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
nit: extra newline
sorry, my bad.
Since `value` internally is a String now, we can change read/write here as well.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
`s/step/cluster state step/`
I think this should be at debug level
do we want to check the phase/action times since those are meant to change
This constructor doesn't seem to be necessary.
I think the assertions are fine because ILM is in full control of the phase, action and step settings (they are INTERNAL settings so can't be touched by a user and will soon be moved to a custom index metadata object further locking down access to them. Therefore, I don't think its necessary to check that if one is set all three are set in production code but its useful to have the check in testing to make sure we don't do something silly so assertions feel right to me.
This seems to test the case where the same path has a number of distinct mount points. Can this happen? I can't think how.
I'd just do `sum += Math.max(0, data[1])`
The existing code doesn't filter out paths whose `mount` property is `null`, so I don't think we should start doing so as per this test case.
no utils for this :( `out.writeLongArray()` maybe :)
+1 on making configurable as well (it may very well change from one use case to the other.. this is a good default set however)
future note - once refresh mapping is gone, we should inline this with index creation.
in the case of createIndices, this should send shard failed for the shard routing that triggered the index creation, but it doesn't because the indexService is empty. I think the interaction with shard failures is too brittle/tricky. My suggestion would be to just return an exception on failure and let the caller deal with it in the right way. PS - maybe this signals a testing gap as well..
everything in here just uses the state maybe we only pass the state to the method instead of the ClusterChangedEvent
please return a Map instead no google guava stuff in public interfaces
we should also have messages here in this assert
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
I'd go the other way around ``` for (int i = 0; i < usefulHeaders.length; i++) { request.putHeader(userfulHeaders[i], restRequest.header(usefulHeader[i])); } ```
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
maybe, to be more precise, it would be good to check the partition that included the new primary.
maybe, to be more precise, it would be good to check the partition that included the new primary.
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
Ah sorry missed that
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
I find that `equalTo` is almost always a bad choice. In this case I think `assertThat(cancelTaskResponse.getTask(), hasSize(1));` will do the same thing but have much better error reporting. That way you get to see all the tasks when there are too many. Same for the above assertion.
this makes me wonder: if a node has node.ingest set to false, for sure no processors should run, hence simulate should be off and IngestDisabledActionFilter should throw exception when a pipeline_id is used as it does now. But how about crud actions for pipelines? One has to go to specific nodes to store them, that have node.ingest set to true? this may not be needed, as those are just index, delete and get operations that any node supports...it's like making client nodes reject index requests, they can forward them to the proper nodes, no problem with that.
oh sorry I see that you don't register the transport action when ingest is off, sorry I had missed that.
Change to Throwable.
Actually, ignore this, the rest actions are actually just forwarding to the transport actions
maybe use `AbstractRestResponseActionListener` then you don't need the `onFailure`
do we really need to do this? I mean if we hit the exception our search layer will retry for us? I don't think we should do this at all.
`expectedType.cast(e)` should remove the need for the unchecked suppression.
hm, thx! I missed something there, sorry.
I don't get why do we need a special overload.
That makes me think that ShardInfo needs a public default constructor.
argh. Missed the grey method start line in the github diff.
I am good
This is especially important in the case of `TransportReplicationAction` where the request sizes can get big. So we definitely want to count those bytes, but still exclude these requests from the checks.
Without digging into it it sounds like `addWithoutBreaking` is what we want for those requests? They still take up space so why not count them? I get that this could push us past the limit but that seems, if not a good thing, at least appropriate.
Don't get me wrong - I like the loop above - I just don't think is sufficient to prove to ourselves that we recreated the problem.
Fall back to _old_ behavior
I think this is easier to understand as it makes a 1-1 copy of the current active shard allocations in the routing table: ``` for (IndexShardRoutingTable shardRoutings : indexRoutingTable) { Set<AllocationId> activeShards = shardRoutings.activeShards().stream() .map(shardRouting -> shardRouting.allocationId()) .filter(allocationId -> allocationId != null) .collect(Collectors.toSet()); if (activeShards.isEmpty() == false && activeShards.equals(indexMetaData.getActiveShards(shardRoutings.shardId().id())) == false) { // only update active allocation ids if there is an active shard if (indexMetaDataBuilder == null) { indexMetaDataBuilder = IndexMetaData.builder(indexMetaData); } indexMetaDataBuilder.setActiveAllocations(shardRoutings.shardId().id(), activeShards); } } ```
I'd just use the Id really
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
Sorry, `MetaDataCreateIndexService` was a bad example. Still, the method `MapperService.merge` which does mapping validation is (AFAICS) not called by the `createIndex` method. This means that `verifyIndexMetadata` does not run the mapping checks in `MapperService.merge`. We check these however when we run `MetaDataIndexUpgradeService.checkMappingsCompatibility` which is called by `MetaDataIndexUpgradeService.upgradeIndexMetaData` when we start a node.
We talked about this and it's going to be tricky. Nevermind...
I personally think those queries should be build using query builders but we can do that in a second step.
cool stuff I didn't see that one!
one more thing (sorry!). For the language clients, I think it would be good to also have a small REST test that uses search_type count, just to verify that all of the clients (and our REST layer) still support it.
you can use `assertAcked(prepareCreate(...))` here
points are allowed to reuse the byte[] to I would make a copy of it before adding it to encodedPointValues
thanks for unwrapping
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
I am not sure how this can work, is the flag ever set? anyways I think we should remove this flag and change this logic as stated above
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
I think we should inspect the `AssertionError` and make sure that it comes from Groovy (by inspecting the stack trace and looking for `assertFailed` and other relevant Groovy calls).
Ok that was fast :D
thanks for digging in. i only dug into the aws one and have not looked at the root case of the gce problems. If it involves weakhashmaps, maybe its something easy we can fix for them as well to avoid pain.
Strings.EMPTY_ARRAY could be used too (if you want)
this code and the code in `SearchPhaseController#sortDocs` is almost identical. I think the only difference is the assignment of the shard ID. Maybe we can factor this out into a static method and use it in both places. It would be good to redcue the duplication on such a level and it would increase the test coverage. I would be in favor of that.
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
I will make it in a follow-up.
Nit: space between the cast operator and the target.
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
Because I expect the ZIP file to be in my .m2 dir so I can run mvn clean install anytime (even offline)
If we publish all our plugins (including xpack) to maven central or any other maven compatible repository, then I'm fine with this change.
The previous format was super handy for maven users. GroupId/ArtifactId. I was able to download a plugin from maven then launch it within a ant script to make integration tests against a cluster (external node). I feel like it will be more difficult for maven users now.
please fail if vals.length > 3
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
Can you rather call Releasables.close(tops, bottoms, posLefts, posRights, negLefts, negRights)? This way, it will try to close eg. negLefts even if closing posRights threw an exception
I guess it could be renamed to isFalse() / isTrue() now
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
Here it still says `on a per index basis` -> should be corrected.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
can we implement `Closeable` and use an AtomicBoolean to signal it's closed I like the `if (closed.compareAndSet(false, true))` pattern
You can use `UncheckedIOException`
I always wonder if we should use the PROTOTYPE constant here instead, cause that is what we need I guess. If so we should change all other tests accordingly
then call here `register(SimpleProcessor.TYPE, SimpleProcessor.Builder.Factory.class);`
Awesome! This is what I was missing! :+1: :heart:
yea, there is no need, if you bind an actual instance, it is by definition a singleton (how would it not be, can't really create another instance of it..)
I chased this one up, wondering the same thing and there is no asEagerSingelton for instances. We seem to do a similar thing in many other places.
+1 lets make this consistent with how now things work in IndexModule.
An enum won't work since these are numbered (or it would require separate variable to keep track of the number). But I don't see why the leniency needs to exist here to add the dash if it doesn't exist. I think the qualifier should always have no dash internally, just like we don't have dot prefixes on the numeric parts of the version.
just please don't add one. There are too many classes already.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
Why do you have `get` and `is`? If we don't make these public final members, then at least there should only be one of these methods.
The indentation is off here and the rest of the way through this test.
I think we can check also randomly on a shard that relocates _to_ the local node
nit^2: `assertThat(putTemplateListeners, hasSize(additionsCount));`
oh... didnt see the `updateInvocation` counter... nvm
yep. missed it. sorry for the noise
I think 0 is a good minimum value.
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
We call them "master nodes" everywhere else. :frowning:
also make this setting `Setting.Property.Final`
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
I wonder if we should use a hash here instead if some corruption wipes all bytes to 0 or some other value? maybe `MurmurHash3`
I don't think this is going to happen - lucene opted out of Serializable for a long time now I don't think we should add it back. I'd rather drop our dependency on it to be honest!
Sorry, I wasn't explicit, but you're missing "term" everywhere except for the ones that you just fixed.
same here re enumSet.toString
can this be in try-with logic.... you are not closing this input stream at all
if you do not supply the the content-type, you can just hand over the builder and do not need to create a string object here. Also I would just return `JSON is disabled` instead of mentioning the config option here. The shorter the better IMO.
I think this should happen first to make this PR less complex
maybe use `AbstractRestResponseActionListener` then you don't need the `onFailure`
I _think_ that you can get away with just letting the exception bubble up and RestController will send it to the user. You won't get the error log but I'm not sure logging an error on 400 level parse errors is a good thing in the long run anyway. I try to usually run requests with `error_trace` on them so we don't eat the stack trace....
This constructor doesn't seem to be necessary.
Why remove it? I was adding them because I thought it was nice to mark the constructors for anyone unfamiliar with Elasticsearch. It'd help them get their bearings.
there are more similar problems below
`fields = in.readList(StreamInput::readString);` I think
Really the attributes for the super class should be read and written by the superclass to ensure they are consistent across all implementations
Wow, that's a big difference! Do you know whether it is lossy compression or not? If not then indeed compression seems to make a lot of sense. :-)
we shouldn't need this here in parse phase
why is this? what's wrong with `1.f`
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
then check for non null here...
some adjustment is needed here once you merged master in
yes I am working on that
This test should assert that the headers are correct.
For readability, could we have ``` java List<SortBuilder<?>> sorts = mainRequest.getSearchRequest().source().sorts(); if (sorts == null || sorts.isEmpty()) { mainRequest.getSearchRequest().source().sort(fieldSort("_doc")); } ```
Do you think we could have something like: ``` java bulkRetry = Retry.on(EsRejectedExecutionException.class).policy(BackoffPolicy.wrap(backoffPolicy, task::countBulkRetry)); ``` I find it easier to know what's going on on bulk retries.
And we could then just leave an assert here.
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
+1 then we shouldn't forget about it :)
yes, lets do this in a follow up change.
The existing `ESTestCase#randomSubsetOf(int, Object...)` should just delegate to this new method here.
I don't get why do we need a special overload.
hm, thx! I missed something there, sorry.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
`Collections#shuffle(list, random())`! :)
This exception will be treated as ignore replica exception. :wink:
maybe put this check before the primaryTerm check
we throw the exception and thus take care of the interrupt. We don't need to set it...
I'm not so comfortable with separating this code from the one in `updatePrimaryTermIfNeeded` - they are tightly connected. Instead of sharing code this way, how about creating a callback that will run: ``` indexShardOperationPermits.acquire(listener, executorOnDelay, true, debugInfo); ``` or ``` indexShardOperationPermits.asyncBlockOperations(listener, timeout.duration(), timeout.timeUnit()); ```
This is logic that I think should go into ReplicatedOperation.
make it final
Can you put the `ParseField` into a class private var and then use it in the parser (so we don't accidentally typo/change it in the future)
I think this should take an `OperationMode` to push the conversion into the caller, rather than doing it in the constructor (it seems cleaner to me that way). This is just my personal preference though, so up to you if you want to change it.
It's needed somewhere because a `model_snapshot` embeds a `model_size_stats`. If you prefer you could remove it here and put this in `ModelSnapshot` instead: ``` public static final ParseField MODEL_SIZE_STATS = new ParseField(ModelSizeStats.RESULT_TYPE_VALUE); ```
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
Does this message go back to the end user? If so the fact that a map must be empty is more of an implementation detail than an meaningful error message for the end user. Something like "Mapping definition for field X has unsupported parameters: foo, bar" would be more appropriate.
we usually take `floats` for doubles. Even though it is not necessary here, I'd parse the value as a float or double to be more consistent with other parts of our code base
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Maybe only invoke `processorIdGenerator.getAndIncrement()` when no id has been specified in a if statement? Otherwise there will be holes in the numbers generated if only some processors have a user specified id.
Please rework this word wrap too.
Right, I mean change it so that it isn't static. Or have a different, non-static getAnalyzer() method that calls out to the static version in the base class.
Can we merge wrap() into getAnalyzer()? It feels wrong to have both methods
How about moving the static method to `HighlightUtils`? That seems to me to be a better place for it anyway, if it's being called from multiple highlighters.
debug or info? I would be more for debug
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
Yes, I would ditch DOS (as you have done). I don't think we run any CI on non-ACL aware platforms. If it turns out we do, then we should just do an `assumeFalse` as the test is not possible on that platform.
I think this message should be a bit more clear. Can you include: - the path - the supportedAttributes - some explanation about what attributes we're looking for It can just be `"Don't know how to make file {} non-readable on a filesystem with attributes {}"`
Needs a guard.
Can we keep the line numbers in the test assertions? I think they are important to maintain.
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
why did you remove this? What if we have multiple pattern that match multiple snapshots? we now add these multiple times. For example: `foo*,*bar` will match the snapshot `foobar` twice.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
I don't think is necessary. `request` is passed as`params`. So, "verbose" is already in `params` if it was specified, you just need to be careful resolving defaults. You would also miss other parameters here such as human and pretty.
lets put this into a unit tests class
I see, that is hideous. ð¦
Extra space is extra.
you evil person :)
I presume this is still in progress? (which is fine)
I'm okay with this.
maybe add a method to `IndexScriptExecution` like this: ``` Java public boolean enabled(ScriptEngineService service) { // return true for IndexScriptExecution.ALL // return service.sandboxed() for SANDBOXED // return false for others / by default return false; } ```
this new exception is going to trigger errors too if we try to serialize it to an older node
Fine by me.
Maybe this one too, I'm not sure.
I like this much better!
did you run into this being a problem? how can we open an index that was created before 5.0.0 and never had insync replicas but does have allocationId? the only thing I can think of is a node network issue during shard initialization. I'm wondering if we need to optimize for this and no keep this code simple (i.e., demote shards with a lock exception)
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
ah - now I see what you did it :)
Typo: "`check point`" -> "`checkpoint`".
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
Compared to our other parsing code this is a little weird because it doesn't know what field it is parsing up front. I get why you do this, but it is weird. Also it is weird because we don't serialize all that much information. You get almost nothing if there isn't an error.
we can't change the format of the response at this time. We can at some point, but for now we just have to parse what we have, and figure out what we should do to make things better for the future, meaning potentially breaking changes etc.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
we are generally moving away from gazillion packages and classes I am not a fan of all these service and they make things more complicated than they need to be today. I have a hard time to understand what feels wrong here and where you draw the line
it's really taste I guess so fine with me
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
this seems like it could create a lot of garbage since we do this for every request. Can we maybe hold a version of this per clusterstate version and invaliate it once the clusterstate has changed...
use `terminate(threadPool);` (this method is in ESTestCase)
`seqno` -> `_seq_no`
Nit: `primary term` -> `_primary_term`
I liked the assertion you had there that if already have a result, this one has a higher seq no
I still don't get why we have all these branches. For the `docFreq` we can just calculate is all the time. For the TTF we can just do what lucene does internally: ``` if (totalTermFreq == -1 || leafTotalTermFreq == -1) { totalTermFreq = -1; continue; } ``` then we don't need the `hasMissingTotalTermFreq` alltogether
I think the message here should 1. be a static final constant and 2. say what this TermsEnum allows ie.: `"This TermsEnum only supports #seekExact(BytesRef) as well as #docFreq() and #totalTermFreq()"`
Or we can let poorly formatted values pass through and throw exceptions at the end if values are missing, similar to how we do for queries
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
it's annoying that we write this code over and over again!
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
Does it need to be Writeable? It looks like we only serialize it using JSON.
Nit: spacing between the `)` and `{`: `){` -> `) {`
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
master_election.filter_data [{}] is a leftover I think
`limitedTo(long bytes)`? Clone is kinda non-specific.
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
Although the code is clear, the level of indirection here makes it hard for the reader to figure out that this (and similar other) test does. As a suggestion, what about combining test_object/test_object_IgnoreMalformed, then the code from `sourceWithObject` can be inlined in the test case. Also I would make the assertion on field1 and field2 explicit, even if that means a few more lines of code. In this case I would trade repetition for readability.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
see above - I think you should add it though
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
`ClusterBlockLevel.values()` ? don't think we need the constant
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
Sorry you are right, we should be using ParsingException. That snippet was the pre-refactored version. The difference is that ParsingException does not need the SearchContext (not available on the coordinating node) and actually points to the location in the request for the error (the XContentLocation). Please use ParsingException in this PR since this is going to be parsed on the coordinating node
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
is this needed here? I think it does something only when the current token is start array or start object.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
Not a big deal, I'm fine without it
I wrote this logic, and I don't like it, maybe turn it upside down, and do "if logger.isTrace -> log.trace the failure, else log.info("....", ExceptionHelper.detailedMessage)
Lets leave off the third sentence
`}` and `else if` should be on the same line
I find it confusing the we have the same field names for this in both ReplicationPhase and PrimaryPhase.
I think these don't need to be volatile any more, now that we read under lock.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
alright that's what I thought too, sounds good
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
can this runnable be an `AbstractRunnable`
can we just us a `Map` here instead of the guava one
can we keep this simple and just assign a new map here and make it final removing all the weird checks if it's null
please return a Map instead no google guava stuff in public interfaces
i think `== true` can be skipped
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
I would just `throw e;` here
Could we either do the percentiles of percentiles here or have another test that calculates the max bucket of a terms agg which is calculating percentiles over a histogram? This way it would check that the agg can both reference an inner sibling pipeline agg and be referenced by an out sibling pipeline agg.
@bizybot can you open up a issue that describes this behavior of the object parser and label it with discuss? Then we can move this PR forward.
for readability I'd use this. as well
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
You already asserted this 2 lines ago, this is a duplicate.
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
space missing before `new Named...`
space missing before `new Named...`
here is a space missing before `new NamedAnalyzer`
here is a space missing before `coerce(context`
here is a space missing before `postingsProvider`
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
Can we add a LongGCDisruption variant that allows using the startDisruption and stopDisrupting to control the GC? These extra params feel clunky (and yeah, I probably did it before too :))
We can call it suspend if you want. To me LongGC is easier to remember as it is what we talk about all them time.
I meant `node` from the for loop.
I'm not sure this method name is right. Maybe I just don't know this code that well though.
or junit for that matter. try/catch is much more readable (and the way most other tests do this)
Can we just use a simple try/catch here? I don't see why we need to use hamcrest complicatedness...
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
I like `hasSize` better for this because it gives a nicer error message on failure.
copy paste :)
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
I think it'd be nice to have this in :test:framework so others can use it.
I think it might be easier to read the code without this method to be honest. It saves a line every time you call it makes me go "what is going on here?" every time I see it. Not sure.
I'd prefer iterating over the map entries here.
Usually we'd stick this on the end of the last line.
CCE is never a good idea to throw out - especially since it forces the caller to handle it. It should be handled inside convert directly.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
same as above for non exception case
I am good
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
use `terminate(threadPool);` (this method is in ESTestCase)
indeed, did not see that.
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
`public static void configureSigner(String signer, ClientConfiguration configuration) {`
`} catch(IllegalArgumentException e) {`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
`} catch (IllegalArgumentException e) {`
you are perfectly right Christoph, let's merge the two and keep the existing class.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
No, you are right, I didn't realize the need for api users before going through the whole changes.
this curly bracket should be on the previous line
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
the exception declaration is not necessary.
`.addPathPartAsIs("_xpack", "rollup", "job")`
no need for extra space
you can comma separate these instead... i know the likelihood of us not using `/` is low, but its best to not have them in this.
scratch that, I think this will be fine as-is in 6.x as well.
I don't think raising en exception to save a few lines of code here is a good idea, please change this back to how it was before.
nit: we almost never use `Locale.US` exept for some number formating. While I think it doesn't make a difference for the enum names in question here, I'd suggest going with `Locale.ROOT`
Also please `Locale.ROOT`
There's no need to specify `this` : `if (isString() && other.isString())`
nit: `maxInspections must be positive`
Wasn't me, it was the tests :)
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
yeah that is true. nevermind then
true. nevermind then
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
we shouldn't be lenient in case `upperTerm` doesnt't implement BytesRef
Conversion to bytesref is done elsewhere with `indexedValueForSearch`. I'm unsure of the impact of rejecting anything but bytesrefs.
I mean in the code but just noticed there was one already
I don't think that we should move this code into the InetAddresses.java source file. That code is from the Guava code base, and is licensed to the Guava authors (see the license header). By moving this code which is not from Guava here we will create a confusing situation with respect to the licensing of the code. Let's take this code to IpFieldMapper.java.
what about throwing an IllegalFormatException instead? I'm a bit concerned about catching IAE as this is a very generic exception.
ok, fair enough
just please don't add one. There are too many classes already.
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
"just created files" <- what do you mean exactly? if one waits 2h they will be able to read it? if not I would just go with "the permissions on the store don't allow reading"
this feels weird to have this here (concerning whether we should delete data of closed indices , on master nodes - I feel this should be made higher up). It is a different change though... (and has nothing to do with your change).
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
we need to add that we return false if no folder was found for this shard.
If your intuition is that these will be almost always needed, then obviously we should keep them.
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
for master you don't need to specify the gateway.type we only have what used to be local!
This'll fail the build.
ah I see what you mean I thought the set to null could happen only with the java api. I don't know either way I find this weird. Maybe Christoph can come up with some better idea.
my bad from previous review, as I said above, change to `List<Object>` ad `Iterable<Object>`
fine with me
I think we shouldn't have this special case for Iterable, as I mentioned above I think it would be good if that constructor delegated to the Objects... constructor and do the potential String->BytesRef conversion there.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
I think this declaration/initialization can be moved to inside the if
can resolve possibly return null? if so we should check for it
the important part is having multiple open readers on this as well.
we also need unittests for these queries!!!
I would leave it as-is, it needs to extend BaseQueryTestCase
Nothing to do here for this PR, but how can we keep this up to date? We already have this list in like 3 other places it seems...
nit: an -> and
last `%version` should be `%major_minor_version`
last `%version` should be `%major_minor_version`
can we rename this to make clear that this has nothing to do with git, but is only about s3? `--upload-to-s3` seems a bit long
I think this constructor can go away
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
I'd rather just `new ConcurrentLinkedQueue<>()`.
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
formatting - 1 line instead of 2
formatting, 1 line instead of 2
I see. The seqNo and the term do not necessarily always go together. the seqNo is the location of the operation and the term is the authority to put it there. I like the fact that the result object only contains the things that the internal engine creates / changes. Seq# are owned by the engine (on a primary). Terms are owned by the shard. I would prefer to remove the term. At least in the example you gave (`Translog.Index#Index(Index, IndexResult`) it's readily available from the index operation.
random drive by question - why is the primary term part of the index result? it's already part of index and index result is supposed to capture the dynamic things that the engine has assigned.
same here re enumSet.toString
oh, multi-bucket comparisons are ready already? :)
Any way we can unify this with `BucketHelpers.resolveBucketValue()`? Or perhaps move this into the helper class and rename both of them to be more specific (`resolveHistoBucketValue()` and `resolveMultiBucketValue()` or something?) Also, I foresee this needing to handle gap policies too...unfortunately. :( For example, an agg like Autocorrelation needs to ingest a histogram (which might need gap policy) but emits a set of sibling buckets that represent correlation lags.
I am wondering if it makes sense to implement `getProperty()` for `Aggregations` as well and not just for `Aggregation`. For example in a test I would write something like ``` Aggregations agg = searchResponse.getAggregations(); Object o =agg.get("aggname").getProperty("path"); ``` but if Aggregations also implemented getProperty() I would save another line and it is needed anyway here internally.
now I see what you meant yesterday saying that we have to parse meta here
mention here too that this is what we do also in the corresponding builder
I think I would make a breaking change here. Let's drop support for the string value in the builder and add it to the breaking changes. The parser still supports `none` and `all` but the builder only accepts a query. Then the method below needs to pretty much be moved to the parser.
I think the type and queryBuilder instance members could be made final
yes lets do it later otherwise we have to remove setters and break things.
what naming convention do we want to follow here? I saw around some innerQueryBuider(), here innerQuery(), maybe we even want to drop the inner prefix... let's decide for one of the options and go for it everywhere.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
Nit: "seq no" -> "seq_no" (inconsistencies will make searching more difficult)
make these variables protected please and access them directly in IndexShard. I don't like accessing fields on self through getters. Also, this makes the PR harder to review, as it adds much noise.
can we just inline this in the transport action file? I don't see the need for another file.
Warning! Possible bikeshedding ahead! I think it should be `index.seqno.*` so it matches the package name? And I think drop the `index_`? Similarly for the other [setting](https://github.com/elastic/elasticsearch/pull/15111/files#diff-7efaad9c1a20fcc9fde96322ebc02e0fR42).
I meant [this](https://github.com/elastic/elasticsearch/pull/31163/files#diff-2ec2c2b070f96bf66b888db94648ffe0R321) . The standard engine ends up returning a `SnapshotIndexCommit` which is why I used the term lucene snapshot. I hope this is clearer.
missing generics type same as above
missing generics type same as above
missing generics type same as above
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
+1 to that for the yaml configuration.
Maybe merge all the groovy securing code into one place? It feels funky to have the default receiver whitelist here but method blacklist above.
I think we can do this without adding an interface? Users should not need to do this? A script cannot realistically be used for both search and executable. I know this is more a problem with the existing scripting apis, but I think here we can just implement executable, and search should throw UOE.
I think it'd be nice to have this in :test:framework so others can use it.
Probably worth putting an explanation in here.
one more thing (sorry!). For the language clients, I think it would be good to also have a small REST test that uses search_type count, just to verify that all of the clients (and our REST layer) still support it.
I personally think those queries should be build using query builders but we can do that in a second step.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
Would it be better to use the Assert.fail(String) method or throw an AssertionError here? That way the test will fail correctly in the test framework
My motivation is both making it so there is one obvious way to calculate distance (I was reminded recently of this beatiful mantra from the Zen of Python: `There should be oneâ and preferably only one âobvious way to do it.`). I also think not having instance methods will allow us to play more with the underlying field access so we dont need an intermediate object, GeoPoint).
Oh I see, it's the ZTable stuff. Sorry for the noise :)
interesting, what is the reason for this funny upper bound? :)
Would it make sense to move this method to some SpatialUtils utility class? I feel like it's pretty generic and we might find some other ways to use it. I think I would also replace first three doubles with Circle. And we should figure out what to do with the radiusMeters parameter in Circle since it is not meters in case of `shape`, but this is a topic for another PR.
so what about the other settings you can set on the Item like source filtering? I think we should expose all of them here though.
can we call this RecoveryNodeResponse? (it's no longer about a single shard)
I think some of them could be private
sounds great thanks
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
can we do this `((Long)value).longValue())` no boxing needed here
I think you should just do `instanceof Number` and else call `.toString()`
@rjernst can you fix this ^^
can you use `InetAddresses.forString` intead, which guarantees it won't do a dns lookup
This needs to handle the -1 case.
Ah yeah I suppose that might be ok, in this case it's user-defined input so that's pretty awkward but it beats breaking.
I'm tempted to also do it in a follow-up pr as this code is really just moved around.
Also captured in #14862.
I don't think that this is right since it will match the string "256.512.256.512/33" but that is not a valid IPv4 address/mask. While there are regular expressions that can correctly capture an IPv4 address, I'd prefer that we just write a simple state machine that parses an IPv4 address because it will be vastly simpler.
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
these ElasticsaerchExceptions are bogus remove them
Typo, "Trasnlog" -> "Translog"
Should use `{}` logging style instead of string concatenation here
I know this was copied over from another place, but I wonder if we should give preference to the recovering file. If I read this correctly , if we have both recovering and non-recovering, it is now random which one we choose.
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
I'd rather have a different parameter there. However, that would add complexity. It might be better to not handle missing field or NaN and Inf at all and let the user sort it out with range filters.
instance variables should use camelcase
we should use actual exceptions instead of assertions since we are validating some user input
can we use "script_factor" I think it's nicer than the came case
Even better you can use `try (BulkProcessor processor = BulkProcessor.builder(client(), listener).setBulkActions(6).setConcurrentRequests(1).setName("foo").build()) {` since we are on Java 7 :)
you can replace these two lines with a call to `ThreadPool.terminate`
Maybe pull this guy into BackoffPolicy? I figure it'd be useful for anyone uses BulkProcessor in tests. You'd want to make the DELAY configurable, but that is pretty simple.
does this need to be public and also does this class need to be subclassable
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
space missing before `new Named...`
space missing before `new Named...`
here is a space missing before `new NamedAnalyzer`
here is a space missing before `postingsProvider`
here is a space missing before `coerce(context`
we set the rewrite method twice it seems? probably a bug in the original parser
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
sorry, my bad.
FWIW I've used this in the past for production ES clusters to have a set of common settings (elasticsearch.yml) and node-specific settings (elasticsearch.json) to merge two files with settings. That said, I still think it's safer/better to remove this feature and fail if more than one config file is found. It reduces the complexity for reasoning where a setting came from.
we need to support whatever extensions Settings supports and that includes json & java properties formats. I wouldn't worry about restricting it to these three (yml, json, properties) with regards to bwc.
with the current code a `logging.whatever.yaml` file would be loaded. I wonder if this is our intention or a side-effect of the current behaviour. Honestly I would be in favour of simplifying this further and even have something like `if (file.getFileName().toString().equals("logging.yaml") || file.getFileName().toString().equals("logging.yml") )` unless we want to extend this to json and properties files, which I think would be off-topic in this PR.
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
space after `,`
we have a test util method that we use to shuffle fields in the response so we make sure that our parsers don't rely on specific keys ordering.
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
I think you can just initialize to null
it should be permissive....but we are not testing forward comp properly because of the structure of these objects. This is quite a bummer, we should probably look into testing this, otherwise permissive or not doesn't make a difference as we don't test it.
I think this should be trace
I think this can be optimized further. Here we are updating status of shards that are participating in the restore process. There are only two possible outcome of this operation for a snapshot itâs ether done when all shards are done or it is not done. It doesnât matter if we are applying a single shard or multiple shards â there is still only one outcome per snapshot. If a snapshot is done we need to check if all shards in this snapshot has started and if they are not â create a listener. In other words instead of having an array with one element per shard it might make sense to have a map with one element per snapshot.
hmm this has an empty impl? Not sure if we need the `Injectors.close()` if we need it, it should deal with null values!
trash the @param and @return
can this runnable be an `AbstractRunnable`
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
I don't like it much when constructors have side-effects. Can we maybe move the API from ``` java new PidFile(path, true); ``` to something like ``` PidFile pidFile = PidFile.create(path, true); ``` to make it clear that there is something happening (since there is a verb)
Again, need to figure out what to do if ATOMIC_MOVE is not supported
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
We should use a try-with-resources syntax with this.
I think using `nextLine` might be easier to read, and since we need all the lines in memory to perform the de-duplication anyhow, I would consider doing it in one step. Using java streams and a set as the Groovy implementation did to take care of the de-duplication would make this concise and easy to understand: ``` files.getFiles().stream() .flatMap(Files.readLines(null, StandardCharsets.UTF_8).stream()) .collect(Collectors.toSet()) .forEach( line -> { // write each line to target }) ``` You will probably have to collect to a different set implementation to preserve order but this is the general idea. Writing a test will make that obvious.
no need for a constant here, you can use `StandardCharsets.UTF_8`.
```suggestion public void setFile(File file) { this.file = file; } public void setFile(String file) { this.file = getProject().file(file); } ``` Along the same lines as above to avoid the use of Object.
I would prefer we use something like `Files.write` where we can be specific about the encoding. `FileWriter` will rely on the default encoding, something we generally try to avoid.
I think it'd be useful to see the filenames in the exception message.
This `{` block `}` fits the pattern we use elsewhere, but feels unnecessary in this context.
I think it'd be useful to see the filenames in the exception message.
Doesn't actually throw `IOException`.
I think it'd be useful to see the filenames in the exception message.
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
Did you push the change that added it? I don't see it.
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
please make sure all files closed and no file is leaked.
@jtibshirani is correct
I think you can avoid that by overriding `AbstractXContentTestCase#assertToXContentEquivalence`? I think it's worth using `AbstractXContentTestCase` here, it's going to be much more thorough than hand-rolling parsing tests.
I need to sit down to make a approach, ill finally have time early next week. Id prefer the manual parsing in order to test the fromXContents, for now.
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
I think that inserting random fields here would reveal problems on the parsing side with the current code.
We do this check in RestoreService.isRepositoryInUse. I am not quite sure what's the reason to repeat it here.
this assertion is not correct I think. If a restore for a shard fails 5 times, it's marked as completed only in one of the next cluster state updates (see cleanupRestoreState)
just wondering if it's possible for `shardRestoreStatus` to be null. I think it can be if you restore from a snapshot, then the restore fails, and you retry another restore with a different subset of indices from that same snapshot.
I would write this check as ``` if (shardRestoreStatus.state().completed() == false) { ``` and then add an assertion that `shardRestoreStatus.state() != SUCCESS` (as the shard should have been moved to started and the recovery source cleaned up at that point).
I think this can be optimized further. Here we are updating status of shards that are participating in the restore process. There are only two possible outcome of this operation for a snapshot itâs ether done when all shards are done or it is not done. It doesnât matter if we are applying a single shard or multiple shards â there is still only one outcome per snapshot. If a snapshot is done we need to check if all shards in this snapshot has started and if they are not â create a listener. In other words instead of having an array with one element per shard it might make sense to have a map with one element per snapshot.
I'd just use the Id really
I think that jumbo frames are common enough that we should try to go the extra mile here. If it's not possible to do cleanly, I would at least like to see a system property that can be set to set the MTU to 9000.
> just let the default be 1 instead My rational with going with half as default is that I think that adding replicas should change the behavior - if someone runs with 6 copies , it's probably not a good default to let of them (but one) go away before signalling alarm. I chose the word "half" in order to avoid a loaded word like "quorum" which implies stuff that aren't part of our model (i.e., quorum reads). I don't mind if we round up (i.e., `(size() + 1) / 2`) or down (i.e. `size()/2` ) as long as it's not `size()/2 + 1` .
> 6 shard copies? That's rather useless in a system like ES We do have people using more then 3 shards so that lead to the idea of having the default scale with it. Thinking about it more I think the main usage for having so many copies is auto-expand-replicas-like usages, where you want to have shard copies available on all active nodes. In those case I think you mostly care about the data being on everything thatâs up and not be bound by durability guarantees. In that case I would be fine with waitForActiveShards default to 1 and allow people to set things differently on the index level if the want different default (when we do that change). > This setting is of limited use anyhow as it does not provide the guarantee that most users are after Correct - this setting is meant to be used to limit the scope of events that will be indexed into less than a given number of shards. It should be coupled with a check of the response of each write operation.
let's assume that if the method parameters are not marked as @Nullable that they are non-null. Otherwise we clutter the codebase everywhere with these checks.
Can you add the `translogId` to the log message here? It makes tracking stuff down on shared filesystems much easier.
Nevermind, I see it later on in the `commitIndexWriter` method :)
I think the OOM reference was a copy paste error from another clause. This clause doesn't do `translog.newTransientTranslog(translogId);` so no need to revert it - although it seems to do no harm if there is no current transient translog.
a transformer and performer. Quite a guy :)
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
I'm okay with this.
I see, that is hideous. ð¦
Extra space is extra.
strictly speaking I think we need to read this from disk after the flush - i.e., make sure that what's on disk is OK.
I see - we reuse the same engine variable. I think it's cleaner to have it contained.
If we don't cache the fields, we should remove the fields.clear() at the end.
(there are a couple of other places in the code that have the same issue)
You can use joinFieldType.name() right? Instead of `joinField`
I think we should do this even if we use docvlaues? I think we should have consistent slicing no matter how it's done!
I was only talking about the context _path_. But what you have is fine for now, the entire class really needs a rethink. :)
Test is called "testPrimaryOperationLocks" and then most of the code is there to check replicaOperationLock ;-)
yes, I thought about failing the recovery in case where the block suddenly appears during the recovery. This has some other adverse consequences though. Needs more thought
we need to improve this, can you add it as an item to the meta issue? I wonder if we can fix this by acquiring an operation permit for each batch of operations that we send as part of phase 2 during peer recovery, and then also check whether there's a read-only block under the permit.
Oh. You need to explicitly close the op.
I think we can check also randomly on a shard that relocates _to_ the local node
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
I think this could use the `rebalance` function in `CatAllocationTestBase`? It looks like it's performing the same function
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
[{}] for path.
Remove and create again is not needed I think
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
You can use `assertAcked()`
there is just 1 node
Forbidden API: ``` Forbidden method invocation: java.lang.String#toUpperCase() [Uses default locale] in org.elasticsearch.cloud.aws.blobstore.S3BlobStore (S3BlobStore.java:204) ```
Ok, thanks for this precision.
It's a pure revert of my previous commit, where I did fix the formatting here. I'm okay with undoing the formatting fix in favor of a pure revert.
I'd throw the exception in `initCannedACL()` method instead of checking for a `null` here.
Thanks for adding this warning. Since ` metadata.name() ` refers to the repository name, we could maybe change this to: "ignoring use of named client for repository ["
I'm good with latest. It's also probably a good idea to change testJoinElectedMaster_incompatibleMinVersion as well
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
and use the constant here
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
Is the error message correct? also, I don't it's needed containsInAnyOrder also test for size.
space missing before `new Named...`
space missing before `new Named...`
here is a space missing before `new NamedAnalyzer`
here is a space missing before `postingsProvider`
here is a space missing before `coerce(context`
The distinction of what "class" means (why it does not include def or arrays) should probably be explained before this list.
I _think_ (Collections.&lt;String, DiskUsage&gt;emptyMap(), Collection.&lt;AllocationId, Long&gt;emptyMap()) is more "java" here even (and maybe especially) if it is a horrible mouth full.
I think think `type` (not the naming scheme, but the concept) should be explained outside of this list? It applies to eg javaType above as well.
My understanding was sort of the opposite: use it in places where it doesn't not make sense. Whenever you don't care, use it. At least, that is what seemed right to me. This is fine though.
Any reason not to just call `indexRandom(true, youstuff)`? Are you sure you want `ensureGreen`? Now that creating an index waits for all primaries to be assigned stuff like this should be the exception rather than the rule.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
It seems like there are unnecessarily many levels where `null` is allowed. You're allowing `aggregatorFactoryBuilder` to be `null` here, but also in `FeatureIndexBuilderJobConfig` `aggregationConfig` is allowed to be `null`. I think at most one of these possibilities should be allowed.
Should `job` be changed to the plural `jobs`? In ML we were told to use the plurals of `anomaly_detectors` and `datafeeds`. Other APIs that return lists of configs are also plural - `nodes`, `indices`, `aliases`, etc.
typo: randon -> random
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
I meant that other way around, not in the else, set termsLookup only if values == null
looking deeper, I see that we set a non null TermsLookup object only when we have it in query, which causes a validation error when values are set too. We should keep it that way then, this is as good as it gets.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
I don't think this needs the string/boolean. They can be regular enum values. And the constants can be inside the enum, so that they can be used as if they were additional values.
Since we have this guard here, should `innerClose` be changed to have ``` java assert !closed; ``` instead of ``` java if (closed) { return; } ```
as said above, the double negation here feels weird to me, but again maybe it's just me
This was a bit hard for me to read due to the order in which comparators are checked. Could it be rewritten in a more idiomatic way, ie. ``` java if (o1.isPrimary() != o2.isPrimary()) { return o1.isPrimary() ? -1 : 1; } final int secondaryCmp = secondaryComparator.compare(o1, o2); if (secondaryCmp != 0) { return secondaryCmp; } final int indexCmp = o1.index().compareTo(o2.index())); if (indexCmp != 0) { return indexCmp; } final int idCmp = o1.getId() - o2.getId(); if (idCmp != 0) { return idCmp; } ``` It would be helpful at least for me to see more quickly in which order comparisons are performed.
You didn't introduce it, but seeing this line again reminds me that this is buggy if Long.compare returns Integer.MIN_VALUE, which is legal :) So it should rather be `Long.compare(o2.getDocCount(), o1.getDocCount())` (without the minus sign)
Doesn't actually throw `IOException`.
I think it'd be useful to see the filenames in the exception message.
I think it'd be useful to see the filenames in the exception message.
I think it'd be useful to see the filenames in the exception message.
Nit: this could be on the previous line.
I think we should separate the two and push this as is. Your code refactoring has more changes than this functional change and on the security end I think we should be careful. let get this in and cleanup the stuff afterwards
please wrap with `{}`
please wrap in {}
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
ok...but client depends on the transport service anyway no? I think I don't get it
can you try to exercise this method to make sure we open a new searcher and close / release everything
something like this: ```Java public SearchOnlyEngine(EngineConfig config) { super(config); try { Store store = config.getStore(); store.incRef(); DirectoryReader reader = null; boolean success = false; try { this.lastCommittedSegmentInfos = Lucene.readSegmentInfos(store.directory()); this.translogStats = new TranslogStats(0, 0, 0, 0, 0); final SequenceNumbers.CommitInfo seqNoStats = SequenceNumbers.loadSeqNoInfoFromLuceneCommit(lastCommittedSegmentInfos.userData.entrySet()); long maxSeqNo = seqNoStats.maxSeqNo; long localCheckpoint = seqNoStats.localCheckpoint; this.seqNoStats = new SeqNoStats(maxSeqNo, localCheckpoint, localCheckpoint); reader = SeqIdGeneratingDirectoryReader.wrap(ElasticsearchDirectoryReader.wrap(DirectoryReader .open(store.directory()), config.getShardId()), config.getPrimaryTermSupplier().getAsLong()); this.indexCommit = reader.getIndexCommit(); this.searcherManager = new SearcherManager(reader, new SearcherFactory()); success = true; } finally { if (success == false) { IOUtils.close(reader, store::decRef); } } } catch (IOException e) { throw new UncheckedIOException(e); // this is stupid } } ``` I did something similar a while back so I had it ready... I am not sure it safe to use ð¯
nit extra newline
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
this might be called by `scheduledRefresh`, which can happen at any time
well we use a dummy lock so I guess it's fine
try finally here please since if close fails we don't release lock etc which can be missleading
we have `TestThreadPool` that makes it simpler
use `ThreadPool#terminate` here otherwise you will get lingering threads etc.
This also might need an `ensureGreen`
As this setting should usually be only set once, it is probably simpler to leave it non-dynamic (as @jasontedor suggested and as it was before this PR). In case where this must absolutely be updated on a production cluster, rolling restart (of master nodes) with config update is always possible.
Space after the equals. Its a silly small change but it helps my eyes.
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
I wonder if we can somehow come up with something that better normalizes across failed cloud instances? If a machine is pulled, but its replacement can come up within the allotted time, then it would be ideal to not trigger the recovery because we're waiting on the dead machine (based on its InetAddress).
I think we should extend our cloud integration plugins to add some kind of a stable identifier as a node attribute (if not already doing so) and auto-configure this setting to it. /cc @dadoinet @tlrx
I think we can go with a higher bulk size, because we only do deletes. Something like 5000 or even 10000.
This default of 1 second is too low, it should be 60 seconds by default.
Just a question: would it be possible to extend from `LongFieldMapper`? Would be nice to have some code reuse.
Cool, I can see how this can complicate things, was just hoping that this code reuse would be a low hanging fruit.
My understanding was sort of the opposite: use it in places where it doesn't not make sense. Whenever you don't care, use it. At least, that is what seemed right to me. This is fine though.
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
If it can be null we should skip it here.
Maybe use a simple for loop here like: ``` Java if (!contextMapping.isEmpty()) { builder.startArray(Fields.CONTEXT); for (ContextMapping c : contextMapping) { builder.value(c); } builder.endArray(); } ```
depends (which is why I asked). If it's about API bwc I think we should break it and be clear about the impact of the version. Which is also makes me think we should not render the field if we don't have a version (because we removed it)
How do you feel about always emitting a `profiles` map, that map just be empty? I think it's a cleaner implementation than a key that sometimes can be missing depending on the profile map, it makes client diagnostics easier also (ie, you know where to look, even if there isn't anything there yet)
fyi, I added serialization to the enum I moved to MatchQuery (#13402) maybe we can reuse this.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
Since `value` internally is a String now, we can change read/write here as well.
sorry, my bad.
hopefully having a default for fuzziness makes it non optional and simplifies things slightly here too
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
I am not sure how this can work, is the flag ever set? anyways I think we should remove this flag and change this logic as stated above
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
can we maybe cache `(1 + bitArrayKey) * bitArraysSize - 1` to something like lastSeqNoInArray ? I think it will be easier to read.
Nit: " . " -> ". "
The `<=` will need to be escaped.
`them` -> `them;`
Typo: "temporary" -> "temporarily"
maybe just inline this into the `planIndexingAsNonPrimary` method? I think that would be cleaner.
I think you should inline this into `planIndexingAsNonPrimary` then we don't need all the asserts
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
doc level failure (normal failures are OK from an algorithmic perspective).
Nit: "doens't" -> "doesn't"
thanks for moving this to a unit test!
these don't need to be static
Good idea to add this safety net.
you can also use this method without needing to subclass `ESAllocationTestCase`.
There is now a base class `RestActionTestCase` that helps remove some of the test boilerplate.
indentation makes the `if` block a bit hard to read
Sure, I was just thinking out loud
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
(not as a float but due to the cast to int after `Math.ceil`)
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
s/listener/delegate/? I read this and immediately thought "infinite loop!" because this thing already **is** a listener. I know it is silly though.
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
perhaps a different name for this listener, as it doesn't only handle failures but also successful response publishing
We should make TaskInfo final then.
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
confuses the shit out of me everytime :)
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I think we should return active.get() == false and also - set it if we became idle...
even though this is just `debug`, logging an encryption key is worrisome
I think you can drop this interface and move ``` void execute(String action, ActionRequest actionRequest, ActionListener actionListener, ActionFilterChain actionFilterChain); ``` to the Operation (as abstract method)
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
partially replying to the original message - the idea is to test how this action behaves under different error conditions - a connection error (which is thrown here), a general exception / shard not available (which is typically given as a response , not thrown here (although it's equivalent at the moment).
do we want to check listener.isDone? (because it is supposed to return immediately). get() waits.
can we check here if the listener is done? (just checking if I got it right this time :))
I know this is how it used to be, but can we make the if be more like the `masterNodeChangePredicate` name and check the the master node is not null and have changed? (we now test for a cluster state change)
using ActionListenerResponseHandler will simplify this lightly.
Somewhat simpler: ("timed out while retrying [{}] after failure (timeout [{}])", action, failure) . I'm doubting between DEBUG and WARN for this log...
The logging brackets are off here: `[{} to [{}]]`.
add action name pls.
The language in this sentence isn't clear, perhaps change "that is replacing" to "and it is replacing"
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
I am not sure whether the log message is too specific, i.e. the subclass must not necessarily be a service.
> Though I do prefer that it fails fast instead of lazily later. ++
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
yeah, prefer top-level there as well.
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
I think we don't need to make the global SuggestBuilder implement NamedWritable, simply Writable should be enough. This is the only implementation (and will likely stay so) so we don't need to differentiate it from others on the stream.
Good point, but my personal opinion here is that if the value is optional we should allow null. It would be different if this can overwrite a default settings, but thats not the case here. I'm not a big fan of the annotation though.
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
I think s/lang/defaultLang/
Fine by me.
Maybe this one too, I'm not sure.
5.1+ I think, actually. Have a look at `VersionTests#testUnknownVersions` and the note right underneath `Version#CURRENT`.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
Nit picky: I wonder if we should make this ctor get all the parameters and construct the message locally. Will be easier to read the code and use, imho.
one line too much
I see some places where null is not protected against...
here too, toQuery might return null, not sure what happens
Can we switch between the string and the millis representation fo the modified date using the `human` flag like the explain API already does? That way we can just have one `modified_date` field in the output? Also the parser will not need to worry about the string version in this case since the client it will never set the human flag
It seems like there are unnecessarily many levels where `null` is allowed. You're allowing `aggregatorFactoryBuilder` to be `null` here, but also in `FeatureIndexBuilderJobConfig` `aggregationConfig` is allowed to be `null`. I think at most one of these possibilities should be allowed.
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
+1 to this, there is always the low-level rest client for this, and we can revisit adding it at a later time if we change our minds.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
Nit: spacing between `!` and `value`.
Nit: spacing between `while` and `(`.
this deserves a sep issue I guess but good catch
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
we have `ignoreMalformed` on numerics for historical reasons, I'd be in favour of not having it on range fields
+1 to support it and also +1 to not do it now
And we could then just leave an assert here.
If we plan on keeping the time zone, I think we should add it here.
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
too many shards [%d] allocated to this node, [%s=%d]
too many shards already allocated to this node for index ...
and 2 more occurrences below
can you undo all indentation changes, it adds noise to the diff
This predicate can be simplified to `(count, limit) -> count > limit`.
this might also be called I think
this could possibly called I think
this might be called by `scheduledRefresh`, which can happen at any time
afaics this might be called by `maybeFSyncTranslogs` because engine might be swapped between `isTranslogSyncNeeded` and this call
no need for `throws EngineException`
I called these methods test*ToAndFromXContent() as they effectively do one complete roundtrip: toXContent -> fromXContent -> toXContent
I am adding a util method for this in XContentHelper, maybe worth replacing this later (should not block this PR)
I really dislike this style of variable reuse in our tests. If I use my IDE to navigate to the definition of this variable I end up on a line assigning a value to this variable that is removed from its current value. This hinders readability, especially in longer tests. Letâs avoid introducing it here, we should be moving away from it.
I might do `assertThat(totalShards, greaterThan(1));`.
I'd name the shrunken index `index + "_shrunk"` or something. I like that the indices are all named after the test that uses them.
can me extract this into a method, it is used in 3 places
optimization nit, but maybe we can just have one list, and reorder to push active one to the start, we do something similar in primaryFirst. This will mean we don't have to create 3 lists, just one
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
The 2 `if-else` conditions can then also be simplified to just: ``` if (lowestVersionSeen == null ||Â replicaNodeVersion.before(lowestVersionSeen)) { lowestVersionSeen = replicaNodeVersion; candidate = shardRouting; } ```
I think that the activeReplica method could also be expressed very concisely using Java 8 streams :-)
if this is an attempt to catch more things... maybe add an example with type coercion as well? ``` bank.put("NAME", "!!!%{NAME:name:int}!!!"); ```
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
I might make something like ``` private void expectMissingBodyError(Matcher<String> responseMatcher, ThrowingRunnable exec) { ResponseException responseException = expectThrows(ResponseException.class, exec); assertEquals(400, responseException.getResponse().getStatusLine().getStatusCode()); assertThat(responseException.getMessage(), responseMatcher); }
This lambda does not need to be a statement block.
Right... but I'd be happy if we could unit test this, and if we do then we need to ensure the object start.
We don't need to use this local ref
Sorry, I just saw that you remove them already, thanks!
+1 on removing the `Void context` from all methods. The `declareInnerHitsParseFields` is already complex to read I think, that won't add much.
It would be nice to have some doc that indicates that it's going to be parsed and stored in a temporary map before being created using createFromMap() method, and the reasoning around why we do this. Also, maybe we could rename to MAP_PARSER? Just an idea.
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
we shouldn't be lenient in case `upperTerm` doesnt't implement BytesRef
Conversion to bytesref is done elsewhere with `indexedValueForSearch`. I'm unsure of the impact of rejecting anything but bytesrefs.
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
nit: now that we folded the close and performRecoveryRestart into `status.resetRecovery()` we don't need the success pattern anymore. This can be: ``` if (onGoingRecoveries.replace(id, status, resetRecovery) == false) { resetRecovery.cancel("replace failed"); throw new IllegalStateException("failed to replace recovery target"); } ```
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
I think this is tricky for gateway recovery because it will report all the recovered operations at once and not as it goes. I The `TranslogRecoveryPerformer` can easily have access to the RecvoeryState (it's on the IndexShard). I think it will be better if we increment it directly there.
we need to remove this from onGoingRecoveries and only call cancel if it was found, otherwise we may leave a lingering recovery id, pointing at a cancelled recovery.
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
`createIndex("test")` ? then you can remove the following `assertAcked`
I think we prefer not to use underscores as part of method names, camel case is better
are those number randomizable ie `randomIntBetween(1,100)`
can we check and stop if the background thread had any issues? o.w. will have to dig through more than needed.
I think we can omit catching this and failing when caught, that's default behaviour, what matters if the `finally` I guess
too many shards [%d] allocated to this node, [%s=%d]
and 2 more occurrences below
can you undo all indentation changes, it adds noise to the diff
too many shards already allocated to this node for index ...
This predicate can be simplified to `(count, limit) -> count > limit`.
I think that inserting random fields here would reveal problems on the parsing side with the current code.
you can make one of them public and call it from both tests, I don't mind
I called these methods test*ToAndFromXContent() as they effectively do one complete roundtrip: toXContent -> fromXContent -> toXContent
Is this is necessary given we loop over OpType.values()? If other values are added in the future we should fail because expectedBulkItemResponse/originalBytes is not set anyway.
If you want to test the multi-write behavior you could make a testing aggregation here that needs to be rewritten twice. I'm not sure how important that is to you, but it ought to be possible.
Nit: `who's the a better` -> `which is the better`
Nit: `candidate` -> `candidates`
It turns out it's hard(ish) to remove ElectMasterService from guice.. not doing.
We call them "master nodes" everywhere else. :frowning:
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
maybe we could randomize the names of the 2 settings we have in this test
nit: extra newline
same here just use synchronized methods
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
what naming convention do we want to follow here? I saw around some innerQueryBuider(), here innerQuery(), maybe we even want to drop the inner prefix... let's decide for one of the options and go for it everywhere.
I would probably throw an exception instead of accepting null here.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
I'm confused. Does this mean we restart the leader checker on every incoming publication? We call becomeFollower on every incoming publication
Nice. I think this is a strong enough link between `currentPublication` and `mode`.
I think this'd be better put into the `Mode.CANDIDATE` branch below. I think we can also assert in the `LEADER` branch that either we're the master or nobody is. Anything could happen to a `FOLLOWER`.
I know this is for concurrency reasons. Just wondering: Would it make sense to move the update of the term under the mutex? In that case, this condition would not need to be checked here.
The `Coordinator` becomes leader in `joinHandler.test()` not in `handleJoinRequest`, and that's outside this mutex, so it's technically possible that it could become a candidate again before this synchronised block.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Sorry, I overlooked the null check. This is good!
Ahh, sorry. You are 100% correct.
resetting the state here makes the test hard to read... can you again maybe create a helper method, that does this ``` assertPrinted(terminal, SILENT) assertNotPrinted(terminal, SILENT) ```
Cancelable -> Cancellable
I think this catch not needed. It will be caught higher up.
I'd do ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new FsChannelImmutableReader(id, channelReference, length, totalOperations); channelReference.incRef(); // reader private reference return reader; } finally { channelReference.decRef(); } } else { throw new ElasticsearchIllegalStateException("can't increment translog [" + id + "] channel ref count"); } ```
this check is obsolet - we can just remove it
I think it'd be cleaner to put the `finishHim(e);` into an `else` statement than to return early in this logic
It's super minor, but our log standardization is usually all lowercase
Same here with period and lowercase
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
Could initialize this with the size of the hits list to prevent resizing
Just a suggestion, I don't mind if we remove it here entirely. I used to like those tests because they show how a typical xContent output of those classes looks like. But with these large ones its kind of debatable whether it is useful.
maxDepth can be final
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
I'm afraid we need to rely on the order if we want to be able to distinguish between negations (applied when a wildcard expression appears before the negation) and referring to indices that start with `-`. We will be able to get rid of it in 6.0 only when we will be sure such indices are not around anymore. I opened #20962. Can we also have a test where the wildcard expression is not the first expression but still before the negation? e.g. `test1,test2,index*,-index1`
Also `-test1,*test2*,-test20` or something along those lines? :)
do you understand this if block? I suspect it made sense before your change, to make it possible to refer to existing indices or aliases that started with `-` rather than treating the name as a negation. That said, I can't quite follow why it makes sense in some cases for `result` to be `null`. This was already there, not your doing but I wonder if it's related and may be cleaned up.
I think this is expected to be a sorted list on the `job_id`.
we have `Strings#EMPTY_ARRAY` for this but IMO we should keep the `null` and validate it. The `null` is very likely a bug and we should fail fast in that case" - afaik britta already added that
nit: s/read blob's/read the blob's
on the reading side we use inputstream, i find it strange we add callback methods for writing (in various ways: inputstream, bytesReference, etc), versus say the ability to open an outputstream and write whatever yourself. maybe just a good TODO to investigate as a followup. If there are less "producers" of this api (e.g. snapshot) than there are "consumers" (e.g. various cloud storage plugins etc), it may make things simpler as then the different implementations have less to do (e.g. copy loops and so on).
what naming convention do we want to follow here? I saw around some innerQueryBuider(), here innerQuery(), maybe we even want to drop the inner prefix... let's decide for one of the options and go for it everywhere.
I fell like a functional interface here doesn't really buy us anything comparing to a simple if statement with two calls.
it makes it too easy to call delete when its not necessary.
`} catch (IllegalArgumentException e) {`
`public static void configureSigner(String signer, ClientConfiguration configuration) {`
`} catch(IllegalArgumentException e) {`
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
Fine by me.
Why do we need a good github search when we have @clintongormley :)
I think we should throw an exception if `mapper.nested() != Nested.NO`, as this would not make sense (and I'm pretty sure some users have dynamic templates to make all their objects nested by default).
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
+1 to have `fromXContent` and `parse` be static
Allowing this to be customizable is nice but it is going to break parsing pretty hard if this doesn't stay MILLISECONDS.
I think it might be worth dropping the `timeUnit` for now? I'm just scared of it.
This should probably be an IdentityHashSet.
it should rather save the XContentType detected from the bytes (XContentFactory.xContent(bytes)) above and re-use it.
I think you have to sort before shuffling, otherwise it will not be deterministic, cause the order in the list still depends on the order in the set, which depends on the jvm :)
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
> write past EOF :dancers: +1!
thanks for improving this, this part is easier to read now IMO.
> should we just do the naive thing and handle the last 8 bytes case via a naive loop of writeByte() for each byte, so that the footer logic is only in one place? +1
yea, I would at least debug log it..., it shouldn't happen
++ on debug message
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
I might use an empty array here or switch the IdsQueryBuilder work with lists.
I'm fairly sure I have the wrong generics incantation there....
We might should move these last two declarations to a common spot something like ``` static <T extends AbstractObjectParser<? extends QueryBuilder>> declareStandardFields(T parser) { parser.declareFloat((builder, value) -> builder.boost(value), AbstractQueryBuilder.BOOST_FIELD); parser.declareString((builder, value) -> builder.queryName(value), AbstractQueryBuilder.NAME_FIELD); return parser; } ``` and then we can declare them when we're initializing the object.
This seems not to be the right exception message here (looks like cp'ed from term query).
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
Left over Note
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
the printStackTrace should go away here
I think we are still missing preference? Should be similar to the get API.
we should support the preference and parent flags similar to the get API.
Change to Throwable.
Why not use the dedicated get aliases api? IndicesAdminClient#getAliases()
good point. I didn't think about that. The value to append can be an json object too, so yes the exception should be replaced with logic to deal with that.
remove this additional line break? :)
Oh, never mind, I misread. Sorry for that. ð
I think that will fail compilation? ð
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
ok cool then we need to fix this place? https://github.com/elasticsearch/elasticsearch/pull/3953/files#diff-79371c2235df5580ddc99db30932bea5R89
catched -> caught
Instead of having a reserved null value (-1 in this case), use an Object float for `minScore` in ShardTermsByQueryRequest and TermsByQueryRequest. Then we can just do a null check: ``` java if (request.minScore() != null) { ```
Maybe use Object float? We do the same thing on SearchContext
I am not sure RestoreService would be the right place for it since addBlock would need to be moved to the same place and it's currently used all over the place. I don't have an issue with renaming it to `addIndexMedataBlocks` but since IndexMetadata is the only parameter, repeating IndexMetadata in the name might be redundant.
should we check here that the totalShardWeight is not negative. I was just thinking if somebody uses the number of docs per shard and we overflow? I really wonder if we should put some upperbound into the setting to ensure folk don't go crazy? They should use some log scale rather than actual numbers? maybe we use `1<<16` as the upper limit for now? and move totalShardWeight to a long and use doubles elsewhere? I really just wanna protect us form going negative :)
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
Fall back to _old_ behavior
"new" -> "now"
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I think we should return active.get() == false and also - set it if we became idle...
confuses the shit out of me everytime :)
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
same here for the leading whitespace char.
Should use `{}` logging style instead of string concatenation here
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
same here: no need for the [].
No need for an empty default ctor when the super is also a default ctor.
This cast should not be necessary. You can use `in.readMap(StreamInput::readString, StreamInput::readString)`
Does this rest path potentially limit api additions/changes moving forward given that there is no description of what action is being taken as part of the path? Something like admin/scripts/lang/painless/action/execute may be significantly more flexible.
No need to override readFrom or writeTo
You don't need to create an explicit default ctor since the super class has a default ctor.
maybe add an explicit `continue;` here to indicate that it's being skipped
that's odd, the root cause is really useful only with SearchPhaseExecutionException. But I don't think we can do better than this ATM.
Actually plugins can implement `Closeable` and they will be closed when the node shuts down.
I wonder whether we should use `unicastConnectExecutor` for this and keep it contained (and throttled).
nit: can we add the timeout value here.
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
maybe add what we computed as the scope of the alias and the path to the error message
+1 then we shouldn't forget about it :)
yes, lets do this in a follow up change.
I think we should have a dedicated method for this in IndicesService. ``` public FieldStats<?> getFieldStats(Engine.Searcher searcher, String field) { // do the caching in here and also lookup the MappedFieldType again! } ``` this way we don't allow everybody to cache whatever on our request cache!
right thanks for the explaining, I should have known, having worked on the search refactoring :)
Please revert this change.
I don't think so, I think these should be bytes or size-value only.
++ to keep byteSizeSetting here
fancy pants :)
Can you move all that code to AwsEc2ServiceImpl.getEc2Attributes instead? Potentially we could unit test this method.
Why do we need getters? These are all final and immutable
Ah, I see the dilemma. If you want to encapsulate for that reason, that seems fine. Then please use the naming convention proposed in #14266? ie `settings()`, `environment()`, etc since they are read only
Hmm...I wonder if we should have this here at all. There are so many cases where this is not correct and I think that could be very frustrating for users: - node does not bind to localhost - node does not accept HTTP (only HTTPS) - node requires basic authentication - user does not have `curl` (Windows?) - node does not bind to port 9200
nit: ditto for `final` method args here
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
in the case of createIndices, this should send shard failed for the shard routing that triggered the index creation, but it doesn't because the indexService is empty. I think the interaction with shard failures is too brittle/tricky. My suggestion would be to just return an exception on failure and let the caller deal with it in the right way. PS - maybe this signals a testing gap as well..
everything in here just uses the state maybe we only pass the state to the method instead of the ClusterChangedEvent
`if (serializedStates != null) {` is no longer needed
I think `requiresIndexMappingRefresh` is very misleading - it should be called `updateMapping` as it does update the mapping (and returns a boolean for refreshes)
oh nevermind, I just found the method that called it with null :)
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
`String.format(Locale.ROOT, "%s operation term [%d] is too old (current [%d])", shardId, term, primaryTerm)`
can the aid matching be the implementation and the rest just assertions ? it should be enough
++ for ordinal and tests then
Rather than use `0` in the case of "unknown" in a mixed version cluster it would be nicer to have a specific "unknown" value, say `-1`, and then not include the count in the JSON output if it's unknown. For example: ``` if (in.getVersion().onOrAfter(Version.V_6_5_0)) { this.nodeCount = in.readInt(); } else { this.nodeCount = -1; } ```
oh cool the read is in the ctor! nice!
I'd say yes... if you want to be able to parse script as a string, you want to be able to serialize it as as string. I believe serialization should be symmetric - you write what you read. For this reason, I believe the script type should be nullable. if you read a script like a string, the read state should be preserved for the writing.
> Run TransformOnIndexMapperIntegrationTest.getTransformed() with seed -Dtests.seed=CCF6041A004DDD9D to see why maybe you can explain why here? without knowing much.. it smells like a bug in transform
Ok, sounds fine.
or just: "return ok;"? :)
Instead of having this custom finish method, should it implement Releasable? This would also allow for using the try-with syntax
I think the unlock calls should always be in a finally block
For things like fielddata I think it's an important requirement
Wouldn't the definition of "upgradable" for string to text/keyword mean the norms setting fits with what is allowed? As this is now, it would mean eg keyword fields could have all of the old settings right, but they would be deprecated...that is just really weird for a new mapper type.
And the same for TextFieldMapper, although that is a little different since it uses parseTextField...
I think we can remove this exception now.
The message is a little weird. I don't think "next release" should be mentioned.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
sounds great thanks
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
but if you are in strict mode you get an exception so you don't get back false :)
typo (of <-> if)
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
it will be good to have some kind of progress logs here (like log ever 10k ops or something) under debug.
`engine failure` -> shard failure
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
I looked at the implications of exposing an engine that isn't fully recovered yet and it's OK, with the exception of syncFlush(). Depending how this ends up being, we may need to make sure that runs under a permit.
I think everything inherited from BaseTasksRequest should be converted.
This is a Request and setters in requests don't typically have "set" prefix and return the request itself. I don't like this notation, but this is the notation that is used in most of the existing requests including this one. Check detailed setting above.
I think you can just blast the entire method in this case.
can we use getters here like `getNode` `isCanceled`
I am surprised that we don't have a default impl for this :)
ta -> to
good test, would be better to move it to a brand new class though, as this existing test class starts a single node cluster but you don't need to send any requests to it. This is a pure unit test, you can call it `StringFieldMapperXContentTests` and make it extend `ElasticsearchTestCase`.
sorry, scratch that, you need parser, which needs the indexService, which needs an index on the cluster. It's all good, leave the test where it is. ;)
Not important, but couldn't this just be an array? String[] possiblePathValues = {"some_path", "anotherPath", null};
I see, and you are right, camel case is preferred. I probably misread the "NoNestedDocs" part of the name as "no nested docs" and that confused me for a second, but either way is fine.
I would inline `superSettings` and now there's another `put(Settings.EMPTY)` to nuke.
Can we also defer to `super.nodeSettings(nodeOrdinal)` so we don't also need to set `DISCOVERY_HOSTS_PROVIDER_SETTING` and `MAX_LOCAL_STORAGE_NODES_SETTING` here? (This also picks up a correct value for `DISCOVERY_ZEN_PING_UNICAST_HOSTS_SETTING`).
can we use package private methods and have unit tests for this.. an integration seems like an overkill.
Don't get me wrong - I like the loop above - I just don't think is sufficient to prove to ourselves that we recreated the problem.
This `if` statement will always be run, so it could probably be removed
can we do this `((Long)value).longValue())` no boxing needed here
I think you should just do `instanceof Number` and else call `.toString()`
@rjernst can you fix this ^^
can you use `InetAddresses.forString` intead, which guarantees it won't do a dns lookup
This needs to handle the -1 case.
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
I think it's odd to have a public constructor for a test only... remove the OriginalIndices parameter at least? it's always set to null I think.
I think you can just blast the entire method in this case.
A more meaningful name would be nice here too, for example `TestRequestHandler` is okay.
Thanks for bringing that to my attention. I think that at a minimum the method should renamed. I've opened #14780 to do this and add a method for encoding any long.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
remove this additional line break? :)
Shouldn't this check instead be: `if (!(obj instanceof SuggestionBuilder))` Because sub-classes of this class will call its equals to test the equality of its specific private fields.
maybe update the docs to say this is a terms query rather than a bool
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
please wrap in {}
use `terminate(threadPool);` (this method is in ESTestCase)
Can the `Async` interface also be removed? I see it's an interface defined inside InternTestCluster.
So what does this _look_ like? I imagine it doesn't look any different unless you set the logging level to something lower-than-default.
shouldn't we throw an exception here? we got an explicit request for a GCE address and we failed to resolve it.
++. Maybe also add a sanity check that a get on the doc at the end gives us what we expect? (deleted or found)
I presume this is still in progress? (which is fine)
you evil person :)
Did you confirm we sometimes hit this and not just ACE? (The "indexed" CountDownLatch should make it likely...)
strictly speaking I think we need to read this from disk after the flush - i.e., make sure that what's on disk is OK.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
Nit: it would be great if the loop structure could be changed somehow so these "continue" statements wouldn't be necessary. Not sure if this complicates stuff though. Also I think explicitely consuming the status field value here would improve readability a little bit.
is this needed here? I think it does something only when the current token is start array or start object.
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
I might use an empty array here or switch the IdsQueryBuilder work with lists.
add action name pls.
catched -> caught
I think this file needs formatting `if(` -> `if (`
I think we should use `debug` for the logging here
Another simplification - if we push the code at https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/action/admin/cluster/health/ClusterIndexHealth.java#L81 into ClusterIndexShardHealth's constructor, we can use it here and just make it a simple lookup in the enum set..
This seems not to be the right exception message here (looks like cp'ed from term query).
Maybe throw error here it `nested_filter` is the only allowed option here.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
Yes, sorry for the confusion, I remember the discussion now. Maybe just rename then, although `elementName` is also fine.
As mentioned above, maybe we don't need this here.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
ok didn't know that. yet another bug fixed in master then it seems
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
s/payload is/payloads are
you are perfectly right Christoph, let's merge the two and keep the existing class.
Trying to catch up on your discussion here, to me it seems like the TermsLookupQueryBuilder just tries to add serialization and toXContent (which kind of makes it a builder I guess) to the existing TermsLookup class. The Later just seems to be used in the TermsQuery anyway, so merging (deleting one) the two should be no problem. Please correct me if I am missing something.
No, you are right, I didn't realize the need for api users before going through the whole changes.
this curly bracket should be on the previous line
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
I wonder if this is a good name for this reducer? I haven't got any good ideas for alternatives but to me a differencing reducer would subtract one series from another rather than subtracting offsets from a single series. It took me a while to be clear on what this reducer was actually doing. I will defer to someones better judgement though as I appreciate that this might be a standard statistical term
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
just saw it in the factory validation, nevermind :)
You need to use .equals on a Double
Any way we can unify this with `BucketHelpers.resolveBucketValue()`? Or perhaps move this into the helper class and rename both of them to be more specific (`resolveHistoBucketValue()` and `resolveMultiBucketValue()` or something?) Also, I foresee this needing to handle gap policies too...unfortunately. :( For example, an agg like Autocorrelation needs to ingest a histogram (which might need gap policy) but emits a set of sibling buckets that represent correlation lags.
I _think_ we have a deprecation logger. We should probably log something when we see `position_offset_gap`.
Do we really need to ignore the setting in post 2.0 indexes? Why not just support both for a while? You already check above that both aren't specified.
We should tell the use to use `position_increment_gap` in this error message.
We shouldn't need to log if we through an exception. I don't like the hard cutover but I can live with it. If I discount the hard cutover my only thing is the exception message.
Users that have indexes created before 2.0 should not be precluded from using the new setting name. This looks like it _only_ allows using the old name with indexes before 2.0.
I don't think we need this branch anymore.
I believe `ScrollHelper.fetchAllByEntity` already wraps the listener in the client's `threadContext`.
Yes! you are right ð
Is this an oversight? `DEFAULT_KEEPALIVE_SETTING.get(settings)`
I see that `ScrollHelper.fetchAllByEntity` already wraps the listener inside a `ContextPreservingActionListener`.
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
I think the whole method could just be: ``` return randomBoolean ? MetaData.ALL : randomFrom(currentTypes); ```
I wonder if we should start already sharing some common code between our BaseQueryTestCase and this class....wouldn't want to complicate things though. Also our base test class in not in master of course so that woul already complicate things...
I'm fairly sure I have the wrong generics incantation there....
We might should move these last two declarations to a common spot something like ``` static <T extends AbstractObjectParser<? extends QueryBuilder>> declareStandardFields(T parser) { parser.declareFloat((builder, value) -> builder.boost(value), AbstractQueryBuilder.BOOST_FIELD); parser.declareString((builder, value) -> builder.queryName(value), AbstractQueryBuilder.NAME_FIELD); return parser; } ``` and then we can declare them when we're initializing the object.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
This needs to be another method (`parseInnerFilterToQueryBuilder`) which replaces `parseInnerFilter` and also takes care of switching the interal `isFilter` flag.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
this is not guaranteed to be smile! We randomize this in our tests I thing this should break if you run it multiple times.
we can do this in a more optimize manner. We can create a builder, and then use `copyCurrentStructure` on the builder (passing it a parser), to just copy it over, compared with parsing into a map and then serializing the map. Also, since its internal, I would use smile builder, as its considerably more efficient than json.
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
I didn't check but unittests for this would be awesome!
MultiSearchResponseTests was written before the test base classes were made more flexible, we should probably migrate that too if it works well for your case
you can override assertEqualInstances
thanks for moving this to a unit test!
I'd probably write validate's results to a variable and reuse it.
then check for non null here...
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
I mean maybe instead of declaring the key and the default we should instead declare a `org.elasticsearch.common.settings.Setting` and use it. Like, for example, AutoCreateIndex#AUTO_CREATE_INDEX_SETTING. That might mean moving the setting out of this configuration class and into some other place to feel more natural, but that is the whole point of the jvm-example plugin - to have a working semi natural plugin.
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
`assertThat((List) filteredMap.get("array"), hasSize(1))` has better error messages.
But you are just fixing a typo so you can skip it.
one too many new line? :)
sorry, scratch that, you need parser, which needs the indexService, which needs an index on the cluster. It's all good, leave the test where it is. ;)
good test, would be better to move it to a brand new class though, as this existing test class starts a single node cluster but you don't need to send any requests to it. This is a pure unit test, you can call it `StringFieldMapperXContentTests` and make it extend `ElasticsearchTestCase`.
What is the reason you decided to not use this check anymore? I cannot find it in the refactored method.
nit: remove empty line. But I don't think its worth changing this if there are no other changes and CI is green, only if anything else needs changing anyway.
I think we should close the analyzer if tokenizerFactory is not null. Otherwise, it is never closed. ``` finally { if (tokenizerFactory != null) { analyzer.close(); } } ``` (this looks like a pre-existing bug, it was not introduced by your PR)
This whole loop reads fairly low-level. If config files can be considered small, we could just read them much more concisely with the Stream API (untested): ``` java String rules = Files.readAllLines(path) .stream() .filter((v) -> v.startsWith("#") == false) .collect(Collectors.joining("\n")); ``` All the low-level stuff is gone. But this relies on Java 8 features and will only work on master.
This is not good for backword compatibility. Instead it should do: ``` if (indexSettings.getIndexVersionCreated().before(Version.V_6_0_0)) { String tokenizerName = settings.get("tokenizer", "whitespace"); tokenizerFactory = ...; } else { tokenizerFactory = null; } ```
can we add some java docs? the name to functionality transition is not trivial anymore
I think this code will be simpler if we have two methods - sendFullClusterState and sendClusterStateDiff , each dealing with it's own serialization (and have the cache map passed to them). We can have sendClusterStateDiff fall back to sendFullClusterState if needed , which will mean no resend method..
it would help me a lot if we could assign state() and previousState() to a variable instead of chaining all the methods
`if (serializedStates != null) {` is no longer needed
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
maybe log it debug or trace? not sure how many times this can happen...
sure, maybe a separate discussion but I guess we will need to log something sooner or later. anyways we can discuss this later on. let's get this in first
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
same as above, no need for try catch
copy paste :)
solely based on names, hard to distinguish from `testRebalanceNotAllowed`
I like dummy because it implies fake and the index is fake - not just empty.
ok, i see it. Its just a little non-obvious due to the way searchers are bubbled up. maybe we can add an assert in the future.
I think we should not execute these writes directly here but extend ESIndexLevelReplicationTestCase#ReplicationAction then run them via the infra of the new action (see ESIndexLevelReplicationTestCase#IndexingAction).
I wonder if this should be `Exception`. see also #20659
You can remove the `hasResponseFromRequest` method - it is not needed anymore.
You're missing "create" requests here (not sure if you want to support them, just wanted to make sure you knew)
FYI we don't throw version conflicts on replicas any more... (not related to your change)
Why do we want to support both `_version` and `version`? Can't we just pick one? Btw, I think Luca recently fixed camel case conversion of strings that start with an underscore.
maybe call this `setHit`
You could make it the same with an `else if` instead of `else`: ``` } else if (theAnalyzer != null) { builder.searchAnalyzer(theAnalyzer); } ```
As far as I can (brief check only) they are always null, but it wasn't part of the API to change properties that are not part of the json being parsed. Not a big deal..
Its sad that we have that problem but the log statements make sense then.
the generic thread pull should never reject, unless it's shut down. that's it's semantics. I would also vote for a trace log in the raiseNodeDisconnected, but that's another change :) It's just confusing imo if you shut down a cluster and see these messages.
Ah ok, I missing that method below, sorry.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
We've gone back to 140 character limits now so you don't need the newline if you don't want it.
I think we can just do this: ``` Java if (value instanceof Number) { return Long.toString(((Number)value).longValue()); } ```
can we do this `((Long)value).longValue())` no boxing needed here
This function is used to resolve index constraint on field stats. I am not sure if we should implement index constraint on a geopoint field but if we don't then we should throw an exception here.
please fail if vals.length > 3
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
Sure, good plan.
On deeper thought, this seems unduly lenient: it should only return credentials for the role that `GET /latest/meta-data/iam/security-credentials/` returned, and should return 404 otherwise. Also I think `credentialResponseFunction` can be inlined, it's only used in one place. Also also we could prevent cheating slightly more by inventing random credentials when the service starts up, rather than synthesising them from the role name.
... so that this doesn't need the `{credentials}` parameter in the URL ...
... and this doesn't need to know it either.
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
I thought we said we would move this method to IndexQueryParseService so we can avoid exposing the Client.
I'd have added an integer to `TypeParser` and sorted them by the integer resolving same integers alphabetically or something. And set the FieldNamesFieldMapper to MAXINT. But I think what you did here is ultimately simpler.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
this entire thing looks much better now! cool stuff
so I think we need to somehow extend the `fuzzyPrefixLength` with the length of our context otherwise we will apply LD to the prefix as well? Also we need a test for this I guess
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
calling `ConcurrentHashMap#size()` can be quite expensive IMO. I think we should keep track of the open ctx in a counter instead of using the map. I don't think being a little off here makes a difference. I think we don't need to add any sychronization changes here.
Maybe `createContext` should take the `SearchTask` as an argument? That'd make it very difficult to forget to set it.
I wonder if we should only do this if the cache is enabled. for all other operations its unneeded and might be overhead? - I mean not the rewrite but the setting the field stats provider. We check this with `IndicesService #canCache(ShardSearchRequest request, SearchContext context)`
now that it doesn't return a value, maybe rename in to loadIntoContext , or add something to the java docs to indicate where the output is put.
Oooh! Yeah! That makes sense - scrolls contexts will outlast that task that spawns them and need to get a new task. I haven't read the whole PR yet, but I wonder if we should clear task from the context between requests? If we don't then we maintain a reference to it after the task manager and that seems a bit weird. Changes to it wouldn't be useful to anyone.
Same here, original exception is dropped.
Again, this doesn't seem to actually use the `entry.getValue()`.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
Let's make this an `UncheckedIOException` too.
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
I think this check does not add much (I would skip it)
instead of the assertBusy, maybe use a future above with setWaitForCompletion(true).
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
maybe, to be more precise, it would be good to check the partition that included the new primary.
This change should not be necessary. We already have the ability to plugin in a filesystem in tests. See `PathUtilsForTesting.installMock()`
> it will for example cause tests that are running on a filesystem that handles paths differently to fail But we shouldn't be testing every FS. We shoudl be testing the logic in plugin installation, which is either is or is not posix. So you can use posix for testing the stuff works, and "basic" for testing it skips the extra code gracefully for non-posix FS.
I mean if path.data is set eg. in the config/elasticsearch.yml to be another location
nit: remove empty line. But I don't think its worth changing this if there are no other changes and CI is green, only if anything else needs changing anyway.
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
Yes, I confused myself.
Rather than the `noinspection`, I'd prefer: ``` diff diff --git a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java index 7ec47ca..4db70ed 100644 --- a/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java +++ b/core/src/main/java/org/elasticsearch/cluster/service/ClusterService.java @@ -407,8 +407,7 @@ public class ClusterService extends AbstractLifecycleComponent<ClusterService> { synchronized (updateTasksPerExecutor) { List<UpdateTask> existingTasks = updateTasksPerExecutor.computeIfAbsent(executor, k -> new ArrayList<>()); - for (UpdateTask existing : existingTasks) { - //noinspection SuspiciousMethodCalls + for (@SuppressWarnings("unchecked") UpdateTask<T> existing : existingTasks) { if (tasksIdentity.containsKey(existing.task)) { throw new IllegalArgumentException("task [" + existing.task + "] is already queued"); } ``` because it's more obviously correct. :smile:
And so does my proposal, by typing `existing` more strongly than the compiler can do (because of erasure) but is clearly correct and eliminates the suspicious call inspection.
Nits: `set` -> `batch` and `task` -> `tasks`
same here - can we add a note about the batching? i.e., not batched
@uboness I mean that it is called by the transport client going through the transport service directly (as was the nodes info call before), it is not exposed through clients, so java api users can't call it explicitly (the `Client` doesn't expose such api).
settings seems unneeded.
I think this catch not needed. It will be caught higher up.
I would probably make this package private
No, that's fine.
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
nit: extra line
I think this can be simplified into ``` if (obj instanceof Map || obj instanceof String) { valueWrapper = Map.of("shape", obj); } else { ```
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
Fair enough. I just see the increment/visit/decrement pattern a lot and it feels like something you could make more automatic/harder to forget/explicitly named.
`blocksmd.copyContext(trysmd);`? I know you use "context" to mean something and this might not be the right use of that word though.
Or `adapter.createStatementMetadata(blockctx, trysmd);` or `trysmd.substatement(blockctx);`.
`ifsmd.count = Math.max(ifsmd.count, blocksmd1.count);` would be a bit more clear to me.
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
I see what your are saying but I donât think we can rely on this. The nanoTime() is not guaranteed to actually have nano precision (just resolution). it is only guaranteed to never go backâ¦ > On 29 Jun 2015, at 10:39, Masaru Hasegawa notifications@github.com wrote: > > In core/src/test/java/org/elasticsearch/indices/recovery/RecoveryStateTest.java: > > > @@ -154,7 +154,7 @@ public void run() { > > if (randomBoolean()) { > > timer.stop(); > > assertThat(timer.stopTime(), greaterThanOrEqualTo(timer.startTime())); > > - assertThat(timer.time(), equalTo(timer.stopTime() - timer.startTime())); > > - assertThat(timer.time(), lessThanOrEqualTo(timer.stopTime() - timer.startTime())); > > I think lessThanOrEqualTo is correct. (because it's rounded down to nearest decimal value) > > If we use nano seconds, when start time is 1ns and stop time is 1000000ns (1ms), time() would be 99999ns but it's 0ms because of TimeValue.nsecToMSec. > But if we use milliseconds, above becomes 1ms - 0ms = 1ms. In this case, time() < stop() - start(). > When start time is 1ns (0ms) and stop time is 1999999ns (1ms), it's 1999998ns but time() will be 1ms and stop() - start() = 1ms. > > That's said, I like time() > 0 since it makes it simpler. > > â > Reply to this email directly or view it on GitHub.
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
nit: `an` -> `a`
I would prefer to have the previous boolean `isAborted` method. Call sites currently catch this exception and then throw another exception.
we will have to be careful though. If a very short-running method with < 256 calls is timed using this approach, we will have significant overhead from `System.nanoTime()` calls.
Can we remove `tag` as parameter here and make it part of the `config` parameter? In the end it is an optional argument and it feels that the this should be part of config, this way the signature of this method remains clean.
This can be outside the try/catch right? If there is a failure to create the pipeline, there is no pipeline to close.
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
please log the exception here as well we really wanna see what was going wrong
This could just be `close()`
much cleaner. thx.
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
I think enforcing this as a List of `ShardLock`s would be better, type safety wise
can this see `unregister task for id: [{}]`
nit: can we rename this to `getTasks`
can we make this ret val unmodifiable please
I think using a `LongAdder` would probably be more efficient than `AtomicLong`, since the value is not going to be inspected as often as its incremented
same for here, not sure if the full Objects.equals needs to be called
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
`s/step/cluster state step/`
`ilm-move-to-error` -> `ilm-move-to-error-step`
the outer parentheses are useless. On the other hand useless parentheses would be better spent to make precedence explicit when bitwise operators are involved. so I would do `long mask = 1L << (32 - networkMask);`
I'm thinking it could be more user-friendly to suggest a correction, like `"did you mean " + ipToString(accumulator & (blockSize - 1)) + "/" + networkMask` in the error message
I'm good with one decimal point with the caveat that this endpoint really should not be being indexed.
No matter what precision you pick will have that problem, for example rounding `89.99` to one decimal point will round to `90`, and so on.
As mentioned above, maybe we don't need this here.
If `elementName` is always the (target) fieldName for the sort, can we call it that way? Also, this only serves to create the FieldSortBuilder, maybe there's a way of passing in the blank FieldSortBuilder instead, making it clearer what that argument actually represents? Not sure though if that would be possible for the other builders as well though, so just an idea.
Yes, sorry for the confusion, I remember the discussion now. Maybe just rename then, although `elementName` is also fine.
should say shard active
this can ne ThreadPool.Names.SAME, the handling is lightweight enough to not require forking to the unbounded generic TP
add action name pls.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
we need to check on the node version, and only call it on nodes that are version 1.3 and above, otherwise they won't have this API
maybe we can factor out a method `boolean hasHits(QuerySearchResult result)` it's used in two places an a complex condition
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
Please revert this change.
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
please assign suggest.filter(CompletionSuggestion.class) to a local var so we can reuse it below when we iterate it a second time.
When it gets long like this can you indent it like ``` assertResult(() -> builder() .startObject() .startObject("foo") .startObject("bar") .endObject() .endObject() .endObject(), ``` I know we `assertThat` has the matcher second, but maybe we should put the closure second for this? I think it is nice when the closure is second because it makes the code formatting prettier.
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
If these privileges are only needed for loading static definitions, then this should be done in a static block when the plugin is loaded, instead of on every invocation of the script.
i think `== true` can be skipped
> Or "no longer than 512 bytes" +1
I'd be more comfortable if this generated random unicode instead.
you can replace these two lines with a call to `ThreadPool.terminate`
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
I think @bizybot is correct - we probably need some of the failure cases in `ApiKeyService.authenticateWithApiKeyIfPresent` to have a `terminate` status instead of `continue`. If I'm passing an API Key over TLS, then it would be very strange (and hard to debug) if the authentication use the API Key right up until it expired and then suddenly switched to PKI auth.
I am concerned about this change. We are leaking communication abstraction into the service layer here. I wonder if it can be avoided by passing necessary structures of CreateIndexRequest as part of CreateIndexClusterStateUpdateRequest or referring to it as TransportMessage or passing necessary pieces of information from TransportMessage as part of CreateIndexClusterStateUpdateRequest.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
what are testing here? sounds like primaryPhaseExecutesRequest
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I would definitely prefer a pure function here that returns a `Set<ShardId>` instead of mutating the method parameter
Should be unnecessary since shardSafe is called? (as opposed to just `shard`)
My idea was to make the BulkRequestSource hold what it has to hold (the failed items), be able to retrieve them and act accordingly from processBulkIndexRequest, rather than have logic to deal with failures within the BulkRequestSource itself. Exposing different getters might help as well, that's another option. I tend to think that extracting the "processing" part would make things cleaner but I may be wrong.
`engine failure` -> shard failure
`String.format(Locale.ROOT, "%s operation term [%d] is too old (current [%d])", shardId, term, primaryTerm)`
minDocFreq must be positive
nit: `if minDocFreq is greater than 1, then it must not be a fraction`
nit: `accuracy` instead of `Accuracy`
I like the succinctness of this checks, wondering if java 8 offers anything to avoid having to introduce the utility class for this though.
Sorry, didn't see that, you're right.
I think this catch not needed. It will be caught higher up.
this seems like it could create a lot of garbage since we do this for every request. Can we maybe hold a version of this per clusterstate version and invaliate it once the clusterstate has changed...
state might be null here since the benchmark id might have been removed between the call to `containsKey` and get. I think it should rather be: ``` java BenchmarkState state = activeBenchmarks.get(benchmarkId); if (state == null) { throw new ElasticsearchException("Benchmark with id [" + benchmarkId + "] is missing"); } ```
`return ingestNodes[Math.floorMod(ingestNodeGenerator.incrementAndGet(),ingestNodes.length)];` ? I know it's just copied but while we are at it
the utility should be a static class
I am wondering if we should add `buffer` (size or operations) to the Status object? We can do it in a follow up if you are okay.
We can setup other scenarios to test the cancellation if we remove `updateLeaderGlobalCheckpoint`. For example, make the read limits reached, then cancel, then verify that we won't issue any read request.
Can we fold all these assertions into a single one? I think this should cover enough. ``` assertThat(shardChangesRequests, contains(new long[][]{ {0L, 8L}, {9L, 8L}, {18L, 8L}, {27L, 8L}, {36L, 8L}, {45L, 8L}, {54L, 8L}, {63L, 8L} })); ``` Moreover, the leader should not return more than the requesting batch size. Here, we request 8 operations, but it returns 9 operations.
at that point you want have a read budget, which I mentioned above.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
I'm not sure we need to send this over the wire though.
Let's use `SnapshotId` instead here.
Looks like a merge issue? (the '+'s)
nit: spacing is off here
can this be synchronized please
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
Unused import here (not really a big deal)
Shouldn't this be using `ElasticsearchTestCase.randomFrom` instead of `com.carrotsearch.ant.tasks.junit4.dependencies.com.carrotsearch.randomizedtesting.generators.RandomPicks.randomFrom`? I don't want it to end up not using the right seed
You could look at `GradleUnitTestCase` it does the same by pulling int the randomized runner only. What I was wondering about w.r.t order is that if it really makes sense to have it fixed. If all we are doing is going trough methods sequentially what advantage does it bring to have them in separate methods ? Maybe better error reporting ? Should we keep the randomized method order and make sure it actually works like that? I'm not saying we need to change it just looking to understand the implications.
Do we really need a before and after? These are run completely sequentially, so the "before" of one test is the "after" of the previous. I'm just thinking of what the old output used to look like (a single line per test in most cases with "OK") compared to what we are moving to here (many lines per test, if I understand correctly).
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
actually, if its a single page, then we can just reference the first page byte array, if not, then we should return false. same with `array` and `arrayOffset`.
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
this check is obsolet - we can just remove it
ah I mean't Throwable.... sorry
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding jvm plugin [{}]", plugin.v1()); } ```
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding site plugin [{}]", plugin.v1()); } ```
> should we just do the naive thing and handle the last 8 bytes case via a naive loop of writeByte() for each byte, so that the footer logic is only in one place? +1
thanks for improving this, this part is easier to read now IMO.
> write past EOF :dancers: +1!
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
this is unneeded see above
this should go away
lower case F please :) - "found shard on ..."
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
good these variants go away...
I wonder if this should just be the implementation provided in `TransportReplicationAction`? It appears there are only two classes that currently provide a non-trivial implementation of this method.
I wonder if this should be `Exception`. see also #20659
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
I'd rather just `new ConcurrentLinkedQueue<>()`.
final, not volatile...
Let's rename the setting `registeredNextDelayMillis` to make the unit explicit
On reflection I think this means we don't need `lastCommittedState` any more.
Can we make this 1 hour? If it times out it's nice to get thread dump
that awfully sounds like two voices for debug.... your turn, @jasontedor.
I don't know how often this is called, depending on this maybe it makes sense to store the formatter somewhere for later reuse unless `format` changes? Is only called a few times maybe not worth the trouble.
Does it make sense to have the Enum and method name the same? I have no preference as to whether we call it `Weighting` or `WeightingType`
This might make the code in MovAvgModel easier as each weighting type will have its own class which knows how to calculate the moving average and we can just call a single consistent method on that class
could we not specify it with the following? ``` "movavg": { "bucketsPath": "the_sum", "weighting" : { "single_exp" : { "alpha" : 0.5 } } } ```
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
Looks like there isn't an ExecutebleScript equivalent for search scripts anyway - ignore this.
Talked with @cbuescher in a chat - since these are just copied from their old place they should probably just keep their implementation in this PR. Moving to test framework is still possible in this PR.
Maybe explain that it is used in places where you want to make sure that scripts are valid but don't care about the specific script and this is the easiest way to do that.
Probably worth putting an explanation in here.
I think it'd be nice to have this in :test:framework so others can use it.
Can you add some randomization ? We run this method multiple times and then perform some checks on the generated query (serialization, correctness, ...).
I think this declaration/initialization can be moved to inside the if
I always wonder if we should use the PROTOTYPE constant here instead, cause that is what we need I guess. If so we should change all other tests accordingly
I thought it would, plus I don't get why we do the same thing in different ways depending on the query. Maybe it's me though.
I understand the that the way the we test the created lucene query at the moment is not affected, however since we already have the test for `expected list of terms` hat checks the terms at least for string fields, I think it would be really good to have this tests. Changing this shouldn't be too hard, and also the random query we create here would feel more "natural". Please correct me if this change is hard to do, otherwise it would be really great to have random values here.
thanks for adding this
let's not log since it is an old index
This could be `Strings.hasLength(tokenizerName)`
This is not good for backword compatibility. Instead it should do: ``` if (indexSettings.getIndexVersionCreated().before(Version.V_6_0_0)) { String tokenizerName = settings.get("tokenizer", "whitespace"); tokenizerFactory = ...; } else { tokenizerFactory = null; } ```
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
can this see `unregister task for id: [{}]`
Nit: addresses -> address
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
I wonder if we can somehow come up with something that better normalizes across failed cloud instances? If a machine is pulled, but its replacement can come up within the allotted time, then it would be ideal to not trigger the recovery because we're waiting on the dead machine (based on its InetAddress).
this whole block here looks pretty much the same in all invocations. Can we make this even simpler? Maybe create a method `createIndexAndWaitForActiveShards` in `MetaDataCreateIndexService`. I've implemented it here: https://github.com/ywelsch/elasticsearch/commit/6e67ecabbfa5cc2568c0c987401e3ea521c7a330
never mind, I saw them later on
using ActionListenerResponseHandler will simplify this lightly.
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
Ahh okay, that makes sense, I missed that
maybe call the concrete indices "index1" and "index2", otherwise one may think they are aliases :)
By the way: lucene expressions "know this"
The use of `#` might make queries confusing since it is also used for filter clauses.
can we use "script_factor" I think it's nicer than the came case
Nit: you could use `Collections.emptyList()` here.
given that we also filter responses by creating a new response filter chain and filtered action listener, this inner class is not just a request filter chain... can we maybe merge the two at this point? Seems like in the end we either filters nothing or both (request and response) anyway...
Correct me if I am wrong but these filters have to be executed in a serial fashion one after another, right? So you can make this async if you need to on top of the blocking loop? I would like to see an example where this is used to understand the rational please :)
I find these two empty `continueProcessing` methods confusing, if we manage to merge the two filter chains impl as said above, we would get rid of them I think
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
does this work? it works for percentiles, but with percentiles rank it's reversed
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
does this work? it works for percentiles, but with percentiles rank it's reversed
just saw it in the factory validation, nevermind :)
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
+1 on removing it
Can you remove the empty javdoc? We are going to fail the build on those at some point....
Is this any quicker if you use bulks? I tend to do that out of habit.
I find that `equalTo` is almost always a bad choice. In this case I think `assertThat(cancelTaskResponse.getTask(), hasSize(1));` will do the same thing but have much better error reporting. That way you get to see all the tasks when there are too many. Same for the above assertion.
I see that there is already a rest test, great!
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
points are allowed to reuse the byte[] to I would make a copy of it before adding it to encodedPointValues
thanks for unwrapping
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
I am not sure how this can work, is the flag ever set? anyways I think we should remove this flag and change this logic as stated above
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
I think you should make `.size(0)` on the search as we don't really care about any of the hits, just the total number of them.
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
I think this is expected to be a sorted list on the `job_id`.
ok now i can see that it is null when removing the task, sorry for the noise
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
maybe we should be more explicit and initialize indexBoost in an else branch here, rather than above when declaring it. I think de-serialization is the only scenario when it may not get assigned.
I'd probably add an `else` clause that sets `splitOnWhitespace` to the appropriate value just to be super clear.
this needs to be fixed before merging (as it should go to 5.2.1).
I don't mind as long as we use `writeString/readString` and `writeOptionalString/readOptionalString` consistently. So you can maybe just change the `readFrom` to explicitly use readBoolean.
you can maybe use `StreamInput#readList()`? like `in.readList(in::readString);`
For static varialbles, `final` should indeed be used whenever possible.
at some point we should make this a helper method in `Strings` and use it across the board I bet it can safe hundreds of lines
ok can we rename the getter then to `getFailedNodeExceptions()`
We suppress and not report all errors which are OK. I don't think we need a special protection here about it.
Wow, that's a big difference! Do you know whether it is lossy compression or not? If not then indeed compression seems to make a lot of sense. :-)
I think this should be: ``` ^(?:[-\\w]+[.])*[-\\w]+$ ``` - non-capturing groups (`(?:..)`) are more efficient - `\w` already includes `\d` and `_` - a `-` inside `[ ]` should appear first, otherwise it indicates a range (at least in pcre)
This seems to only be used for tests. Maybe it should be a helper method in the test framework instead of part of the public api? I would be afraid of something accidentally using this in ES code.
Can this be split into the two cases `request.normalizer() != null` and `(request.tokenFilters() != null && request.tokenFilters().size() > 0) || (request.charFilters() != null && request.charFilters().size() > 0)` in two separate `else if` blocks instead of separating these cases later? I'm not entirely sure if this works, but I think it would make this part easier to read.
This can maybe go inside the following `else` branch.
A question out of curiosity: the analyzer we get here doesn't have to be closed (via closeAnalyzer) because its not a new instance? I don't know enough about the lifecycle of these objects yet I'm afraid.
Why not? http://vimeo.com/105758303
Why did not remove this from being a `ParseField`? This seems to go against the prevailing pattern.
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
I see, so parser always sets both "order" and "mode", regardless of whether they are set by the user. But what if we only go through the java api, use a plain builder and set "reverse = false". Translated to json this should give us "mode = MIN", but only if not explicitely set by the user otherwise, no? Sorry, haven't got a good solution myself so far either.
I am good with both options.
I think that we are leaking a thread local here? We should close the current threadContext before overriding it.
ow I see this PR is WIP, so I'm guessing that you'll add it :) Anyways this change does LGTM so far.
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
Nit: spacing between the `)` and `{`: `){` -> `) {`
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
All our tests currently use `RandomizedTest#atLeast` method, you can do the same here.
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
Ok I see the problem... I still find this hackish (needing to throw an exception to test things), but there's no easy way around it if we want to test different requests and responses. I'd consider using a mock request (one per client type actually) instead and give up on testing those real requests and responses. It would be more unit test friendly cause you'd know the request and the response you need to return (unless it's a nodes info request), you don't need an exception and you can assert on the sendRequest directly. Using real requests it feels wrong to only test a few of them anyway and we know that it's the client that injects the headers (`execute` method), that's what we need to test.
I mean random number of replicas with random combination of non-active states
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
Nit: this blank line is extraneous.
I missed the fact we don't resolve closed indices by default. Fair enough. Sorry for the noise.
can we add that to ClusterStateCreationUtils? It might be useful for others as well
yeah that is true. nevermind then
I think we should use `debug` for the logging here
do you have indentation at 2 chars only for this method? We use 4 chars in our codebase. I'd appreciate if you could change that.
yeah that is true. nevermind then
true. nevermind then
check listener.isDone() as we don't expect a retry here I think
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
do we really need to walk these directories, can we just do what `getFSInfoIgnoringQuota` does? I really don't think we should walk the direcotries
I think we should only make the change for total until we see evidence that adjustments need to be made for the others.
This seems to test the case where the same path has a number of distinct mount points. Can this happen? I can't think how.
I think we could change the output a bit here to make it more coherent with the format of others stats. Maybe something like: ``` "ingest": { "total": { "count": 10, "current": 10, "failed": 10, "time": "10s" }, "pipelines": { "my_pipeline" : { "count": 10, "current": 10, "failed": 10, "time": "10s" } } } ```
Weird markdown seemed to silently remove some of my text...I was trying to say `FieldStats<java.lang.Long>` (which is what I think you meant by your last statement).
should be clause.getOccur() == SHOULD
oh sorry, I had missed that you used the filtered collection below
It works for strings by using illegal characters. However here, ranges use a binary encoding and all values are allowed. So we should probably use `null` as a sentinel value.
is there always at least one element in this list? (I haven't checked whether we assert it somewhere else)
Why do we need both? Is it because there are so many things going on in this file? I don't understand why we wouldnt just need the CompiledAutomaton for the terms.intersect operation, why do we need a ByteRunAutomaton too? Having both seems silly anyway, but if we must do it, try to assign the ByteRunAutomaton from the CompiledAutomaton. The majority of the time it will be non-null: ``` /** * Matcher for quickly determining if a byte[] is accepted. * only valid for {@link AUTOMATON_TYPE#NORMAL}. */ public final ByteRunAutomaton runAutomaton; ```
same question as above
thanks for doing that Colin ;)
I think if we get in that other PR I just reviewd we can reuse here the new method that you introduced there? :)
you can replace with //norelease so we don't forget but at least you can get this in while we fix this problem in master.
we should `@Test` to forbidden API
You're right @benwtrent, we've been dropping the `@throws` clause in some of the methods in the client. We'll need to revisit and add them. I'll make a note to do that.
The indenting is out here
64e5c25 added support for this.
so then the 404 does not actually happen, right? If so we should remove it. Im also all for using Optional instead of found=false, in general, but you dont have to go fix that all right now.
Hey I saw some updates on this PR and I just wanted to throw a reminder out that we are not going to do a singleton(404) here, because we want a delete that is not found to throw an exception. Also, last time we spoke you were going to change this to AcknowledgedResponse. <3
no need for a constant here, you can use `StandardCharsets.UTF_8`.
The method was not named as a setter in groovy so this could be DSL-like. ie, usage looks like (notice the lack of equals sign): ``` noticeTask { licensesDir 'foo' } ```
Note that this is different than setting a single property as it adds the inputs to the list.
```suggestion public void setFile(File file) { this.file = file; } public void setFile(String file) { this.file = getProject().file(file); } ``` Along the same lines as above to avoid the use of Object.
these unit tests are great! We are going to need more of them :)
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
I don't think it needs to be `synchronized` any more because we do all plugin building in one thread.
What about readList? I get that sometimes you have an array and not a list but this seems like overkill.
I see that we need it from another package, I think it's ok.
I wonder if it is worth compressing the hitCount into byteSequence? That way you only have to store an array of ints? You'd have to cap `hitCount` at 255 but maybe that is ok? Or you could use an array of long and have tons of precision on your `hitCount`.
you can do some streaming java8 magic here.
I think you want to say that no commit point was found which could be recovered from the translog.
since we open the translog before the writer now - can we use the open translog for all this information rather than static reading it? this will make sure that we use something that went through all the right validations.
strictly speaking I think we need to read this from disk after the flush - i.e., make sure that what's on disk is OK.
Higher up at the caller we log in trace. If we want debug info then I think we should have a nice summary of the recovery starting info. I would recommend just making this trace for now. Also nit- maybe say something like "calculated starting seq# based on..."
maybe I would split this in two ifs, the outer one about version, then the inner one around levels.
the version here might need to be adjusted depending on the version we get this PR in e.g. if it ends up being 1.6 should be `before(Version.V_1_6_0)`
that looks good, thanks
this `id` gets sent over the wire in `ClusterBlock#readFrom` and `ClusterBlock#writeTo`. your change makes it backwards compatible only for reads, cause a 1.6 node that gets 1.2 detects and converts it. But what happens if a newer node sends 3 or 4 to an older node? We need to add some logic based on version of nodes. Also, I'd try and make this method package private, not sure why it's public it shouldn't IMO.
version reminder here too, and s/splitted/split
spaces after '//'
spaces after '//'
Can you throw something else? It just makes me uncomfortable to throw AssertionError.
similar concern about in-place reduction
please do `Long.compare(second.docCount, first.docCount)` instead of multiplying by `-1`
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
this seems to bypass the IndexSearcherWrapper defined in IndexShard (and passed via the searchFactory)
can this be in try-with logic.... you are not closing this input stream at all
I wonder if we should enable this only for new indices that we know are created with es 1.4
can we not wrap a translog but rather just keep this test translog next to the normal one? keep it simple and readable :)
Can you keep the formatting? I tend to find it easier to read when formatted
Can you test something that is not byte-aligned, like /15 or /17? We used to have bugs in those cases.
What happens if `enabled` isn't set? I *think* we should continue to do nothing if `enabled` is actually true.
if we'll need this in other tests, we should probably try to shorten this setup part of test by re-using what we have in our java api, that allows to provide `Object... source` , but we also want to be able to randomize the xcontent type, which is why we need to adapt it a bit
I tend to try an indent these manually so they *look* a little more like json. Not that this is required, but it does help when they get big like this.
one too many new line? :)
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
right I see that
I like `hasSize(1)` for this kind of thing because it makes a nicer error message.
Not important, but couldn't this just be an array? String[] possiblePathValues = {"some_path", "anotherPath", null};
please return a Map instead no google guava stuff in public interfaces
can this runnable be an `AbstractRunnable`
can we just us a `Map` here instead of the guava one
can we keep this simple and just assign a new map here and make it final removing all the weird checks if it's null
I think we should use `debug` for the logging here
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
To coerce, should be: ``` parser.longValue(true); ```
same here: ``` parser.longValue(true); ```
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
ok fair enough
for readability I'd use this. as well
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
snpashot -> snapshot
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
it would be awesome to have some doc-strings on these settings
this should be `INDICES_CACHE_REQUEST_CLEAN_INTERVAL.get(settings)`
It might be cleaner and create less new-Function objects if you extract this compute block as a new method, say "newIndexFieldDataCache(fieldName)", then just do `fieldDataCaches.computeIfAbsent(fieldName, this::newIndexFieldDataCache)` here.
Ah! I get it now. LGTM
here you may be able to use copyCurrentStructure
we should totally not have this method, one more reason to not implement the interface.
maybe just `esVersion()`
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
ok...but client depends on the transport service anyway no? I think I don't get it
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
this always yields true
Thanks for the explanation. Makes sense now, yes. And I learned something too.
You are throwing away the stack trace here. Just have this method throw Exception, and the tests that call it as well.
I wasn't entirely sure either but good to know! :)
If the usage of forbidden APIs is in a few places, I would consider it better to suppress only at the lowest level (sometimes I like wrapping those in a private method I suppress). The reason is that if an unintentional forbidden call creeps in it will be caught.
Should `job` be changed to the plural `jobs`? In ML we were told to use the plurals of `anomaly_detectors` and `datafeeds`. Other APIs that return lists of configs are also plural - `nodes`, `indices`, `aliases`, etc.
This method is defined in `MlSingleNodeTestCase`
nit: space before brackets
It's better to use variable names with context so for example `check1` could be `keystoreCheck`, etc.
This predicate can be simplified to `(count, limit) -> count > limit`.
add space between `if` and `(` (in other places as well)
any chance we can shard this code with AllocationService
can we move this in a sep method and make this `private boolean balance()` only have a single return statement, all these returns are hard to read
> can be cancelled just because primary relocation completed before shard was activated by the master node yes. I'm aware of that - I'm thinking that with seq# fast recovery it wouldn't matter much as a ready shard will quickly re-recover. However, seeing how the new code looks like with the cancelRecoveriesForShard + shardRouting.isPeerRecovery changes, I think it became much simpler. I'm good. We can see how things develop later on and potentially move some logic to the master (which will simplify this class) or not.
Nit: please add spaces after the `if` and before the `{`.
Nit: please add a space before the `,` separating the function arguments.
Nit: please add spaces after the `for` and before the `{`.
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
`allocation.hasPendingAsyncFetch()` will always return false here. The field that is used to determine this value is set by Primary/ReplicaShardAllocator. Even if this field were correctly set here, it would still be the wrong value to determine whether the shard can be allocated or not. The primary/replica shard allocator is only interested in knowing whether there are still pending fetches for the targeted shard id.
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
confuses the shit out of me everytime :)
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
I think we should return active.get() == false and also - set it if we became idle...
Maybe we can remain streaming parsing if the type was parsed before the query? If the `XContentStructure` class has 2 set methods setTypes() and setQuery(), then the latter method can be smart, so that if the type is already know it would immediately create the Lucene query. If the type isn't know it would just keep the unparsed query around in a BytesReference field. I see that would change this class completely, but I really like to do streaming parsing if possible.
I would leave it as-is, it needs to extend BaseQueryTestCase
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
I think saying that it should not be allowed in the query DSL is a bit misleading, cause it is allowed and we parse it properly. I know what you mean though and why you wrote that, I need yet to come up with a better explanation for this...
here too, toQuery might return null, not sure what happens
Here's another place to maybe use a [field](https://github.com/elastic/elasticsearch/pull/14651/files#r45225330).
`this` is unnecessary
Would you mind moving maxReadRequestSize above maxOutstandingReadRequests so that we have the same order for both read and write.
ok thanks for the explanation.
you can use MustacheScriptEngineService.NAME
It doesn't have to be JSON, we support Yaml, Cbor and Smile, so better to say we expected the beginning of an object or something along those lines.
I'd rather like to have a check outside the parsing loop that asserts that the first token the parser emmits is XContentParser.Token.START_OBJECT. I think its save to assume we are expecting full json objects. I'd also just throw a ParsingException in that case.
> we'll still see this infinite loop for "{" for example. I'd expect the parser to throw an exception on this? > Is it really a good idea to have the behavior of org.elasticsearch.rest.action.RestActions#parseTopLevelQueryBuilder be to loop forever on part of a valid JSON request? :) Of course not, and this is not what @cbuescher said.
Thats a String token though...
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
I wonder if it should not also decrement the CountDownLatch if an exception is caught in the SimpleChannelUpstreamHandler ? Something like ``` new SimpleChannelUpstreamHandler() { @Override public void messageReceived(..) { ... latch.countDown(); } @Override public void exceptionCaught(...) { latch.countDown(); } ``` Just to be sure that the client does not hang indefintily.
same as above, function name says nothing about what it does.
I'm fine we keeping the test of canceling from the runnable task, but can we also have a test for external canceling where post cancel call the runnable is a runned at most once? Note that to do this you will again be in that situation where you wait for something that shouldn't happen, causing the test to be slow - I'm fine with a direct check that will sometime cause false positives.
the suppress warnings could be right on the line of code doing the cast instead of the whole method
Can we get back to this once we need this complexity and keep it as simple as possible for now please? Can we hardcode the OBJECT_FIELD_NAME exclusion and be done with it? queries also have access to individual field names if they need that.
it's a minor thing but why would you assign a variable multiple times when it's not needed? default is a better fit here, it improves readability as well.
maybe we could have a `default` here which could make this switch a bit more readable rather than assigning value before the switch in any case.
Same here as above, since both methods are related and read similar.
either way please create a static array containing these fields on top close to where we create `mappedFieldnames` so this selection is not buried in this method and we see that we might have to change it if/when we add new fields.
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
thanks for adding this
Are we really okay with all of this repeated parsing and boxing and unboxing in the calls to `numberOfShards` and `numberOfReplicas`? Am I missing an obvious reason why we are not parsing these settings (the other being `number_of_replicas`) exactly once and storing the parsed values in fields? Also, I think it's best if in general we not invoke instance methods in constructors (it's not in this case, but it can be bad).
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
oh nevermind, I just found the method that called it with null :)
Instead of making up our own exception, why not use just use Files.delete? This will give you a better exception message. https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#delete(java.nio.file.Path)
I don't think that a security exception should be re-thrown as an `IOException`.
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
maybe not appropriate here, but we can do this with one underlying read of metadata via Files.readAttributes (you then have isRegularFile() and size() available from BasicFileAttributes)
I wonder if we should use the cluster state for this check. I'm worried about people passing in a dated cluster state here. Maybe a cleaner model is to make this method synchronised (to avoid async collision with the create code) and check the existence of the index instance in the #indices map member of this class.
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
Left over Note
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
Maybe just rename the method to `snapshotShard` or something. I know it takes the IndexShard, that that really helps.
can we keep this simple and just assign a new map here and make it final removing all the weird checks if it's null
I think it'd be nice to remove this second ctor so we're explicit every time.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
good catch! that means we are not properly testing this case either given that we didn't catch it.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
Er - if you are going to log something then it doesn't matter which order you do it I guess.
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
any chance we can use `org.elasticsearch.common.xcontent.ObjectParser` here instead of the old style way of parsing stuff.
I think s/lang/defaultLang/
Maybe this one too, I'm not sure.
can you add the `@Override` back? (here and in all the other subclasses of `Discovery`)
While I understand why passing `Plugin` here is safe, after thinking about it a bit, I think I prefer replacing the `Plugin plugin` with `String source` to give the flexibility to choose whether this logic should be applied on the Plugin itself (using `onModule` or `processModules`) or on a different `PreProcessModule` (that latter feels more natural to me)
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
`if (serializedStates != null) {` is no longer needed
I think this catch not needed. It will be caught higher up.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
you can move this method (and the one below it) up to IndexShardTestCase (in test:framework). It could be useful for other people.
It's that, or we can replace replace FsRepository with this one, but we need to beef it up.
I think we can just use an FsRepository for this. All our other shard-level tests do the same, so no need to optimize this. If we want to change that in the future, I think it's easier to switch to jimfs and continue using FsRepository.
I would prefer for IndexShard to just override `changeState` for now, call super, and then do the listener thing. This means one less abstract thing in this class.
Same here - the same as base calss
I wanted this directory to be consistent with whatever was written through the delegates as well. If there was an existing lock file on the Filesystem then we "loaded" it on startup via `#listAll()`
Is it a problem if we just track a non-existing file? To me this looks like this is already broken for NativeFSLockFactory, because this one may reuse already created lock files (the existence of lock file does not mean its locked). So we can just record here "there may be a lock file to track".
can we add a one lliner java doc explaining why this is needed (rather then pass through the the primary lock factory)? it's non-trivial to figure it is done to track the location of the lock file, if it's using files..
It looks like this includes the change from #8383? (nothing that needs to change, just curious)
It would be worth requiring that `jobId` and `jobType` are not `null`.
excude_interim - missing 'l' -> exclude_interim
Misspelled in the \@param tag also
Yes, end users would only ever read this object, hence the lack of a friendly `Builder`. I think it's OK to leave as-is.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I think we should return active.get() == false and also - set it if we became idle...
same here - I think it's better to log the info message if the deletion was successful.
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
Helper method is no longer needed now that `Logger.debug` exists.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Also we should wrap the `-` in `{@code -}`
I think this needs to be wrapped in try/catch so that this doesn't cause a missed invalid line like: ``` 2147483648-:-XX:+TurnOnCatLasers ```
Why did you opt for the consumer route rather than having `parse` return a `List<String>` and still have an invalid line consumer? My personal preference would be for a purely (or closer to purely) functional interface rather than a callback-ish one (I'm not saying you have to change it, I'm just curious what the reasoning is)
drop the actually? sounds so "uncertain" :)
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
fantastic thanks a lot
I wonder if we should start already sharing some common code between our BaseQueryTestCase and this class....wouldn't want to complicate things though. Also our base test class in not in master of course so that woul already complicate things...
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
Oh nevermind, I see the problem now, the field name is not used to calculate equality so they can stomp on each other even if they have the same name :(
to me these should be sets and required to be non-null
Can this lead to user code change? ( as you changed the tests above )
`assertThat((List) filteredMap.get("array"), hasSize(1))` has better error messages.
But you are just fixing a typo so you can skip it.
Should we still log something here, in case `terminal.println` throws an IOException? Or the impossible becomes possible (hey, you never know with JDK9)
And by "log", I guess worst case scenario is `System.out.println("The impossible happened: " + ...);`
I think enforcing this as a List of `ShardLock`s would be better, type safety wise
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
good catch on delta > 0
`getMasterNode()` already returns null if `masterNodeId` is null. Maybe cleaner to make that explicit in the `getMasterNode()` method (and not rely on the map implementation to do that for us) and also use `@Nullable` on the return type. The effect is that we won't need these conditions here and can just write `return new Delta(other.getMasterNode(), getMasterNode(), ...`
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
`limitedTo(long bytes)`? Clone is kinda non-specific.
alright that's what I thought too, sounds good
use a try-with resources for the parser value
can this be `searchReqeust.source()::size`
Change "param required" to "parameters are required"
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
Can you reverse this, the negative makes it harder to read
Yes, I confused myself.
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
Ahh okay, that makes sense, I missed that
Could initialize this with the size of the hits list to prevent resizing
no need to remember all individual boosts, you can just multiply: ``` java float boost = 1f; while(query instanceof BoostQuery) { BoostQuery boostQuery = (BoostQuery) query; boost *= boostQuery.getBoost(); query = boostQuery.getQuery(); } ```
let's have an assert and drop the branch
I usually prefer the way without the else but I don't object to either one.
you need to be careful here you might have a filter that is wrapped but not a query than you get a NPE here
maybe update the docs to say this is a terms query rather than a bool
you should run `gradle precommit`
minDocFreq must be positive
yes. This is too low level - I think we will fix it at the higher levels. I dont' think deleteIndexDirectoryUnderLock should be lenient
nit: `if minDocFreq is greater than 1, then it must not be a fraction`
This is totally funky and the parsing code is crazy, but I verified it works with weirder timezones. ``` assertDateMathEquals("2014-11-18", "2014-11-18T00:00:00-09:30", 0, false, DateTimeZone.forID("Pacific/Marquesas")); assertDateMathEquals("2014-11-18", "2014-11-18T23:59:59.999-09:30", 0, true, DateTimeZone.forID("Pacific/Marquesas")); ```
I believe this can be provided by overwriting EsTestCase#xContentRegistry().
Sorry, my bad. What I meant was overwriting `xContentRegistry()` from ESTestCase, I mixed that up. That way you can e.g. provide the parser that you need in the test without the need of instanceParser(). I don't mind either way, feel free to use it or not.
Instead of providing the instance parser by overwriting this method in the subtests, can subtest simply provide their own xContentRegistry with the appropriate parser by overwriting `getNamedWriteableRegistry()` from AbstractWireSerializingTestCase? I might be missing something though.
count > 0? just being paranoid :)
you can make one of them public and call it from both tests, I don't mind
fyi - this gives you double [[]]
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
Oh, that error handling!
Instead of acquiring the shard lock for a second time, I would prefer if we would do it once, and move this call under that lock and just rename `tryOpenIndex` to `tryOpenIndexUnderLock`, removing the locking mechanism from it. Same thing for `TransportNodesListShardStoreMetaData`. You can then also remove the `ShardLocker` interface, which irked me for a while.
let's keep as is, with the assertion message I think it's ok. I wonder if we should have an assertion at the end of this method to say something like "if we have an active primary shard that's not relocating, then the replication tracker is in primary mode".
can we capture System.nanoTime() at the beginning of this method so all shards use the same? it's not broken now, but will make it easier to reason about.
+1 to capture `System.nanoTime()` at the beginning of the method
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
OK. > On 20 Jul 2015, at 14:01, Shay Banon notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java: > > > ## > > - AsyncShardFetch<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> fetch = asyncFetchStarted.get(shard.shardId()); > > - if (fetch == null) { > > - fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction); > > - asyncFetchStarted.put(shard.shardId(), fetch); > > - } > > - AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId())); > > - if (shardState.hasData() == false) { > > - logger.trace("{}: ignoring allocation, still fetching shard started state", shard); > > - unassignedIterator.remove(); > > - routingNodes.ignoredUnassigned().add(shard); > > - continue; > > - } > > - shardState.processAllocation(allocation); > > - changed |= primaryShardAllocator.allocateUnassigned(allocation); > > - changed |= replicaShardAllocator.allocateUnassigned(allocation); > > I will do the assert when I remove the primaryAllocated flag in a different change > > â > Reply to this email directly or view it on GitHub.
can we add an assertion going out that going out of the primary shard allocator we don't have any primary shards in the unassigned list, unless we expect them to be there? (primaryAllocatedPostApi is false or restoreSource != null)
yeah, that was what I meant
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
we do this so often. I wonder if it's time for a utility method.
Nit: extra blank line
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
Thank you @jasontedor, I'll have a closer look at how the tests are run. I assume it runs each test method several times, otherwise I would still suggest to restructure `#testInvalidEnum` so it always asserts the invalid enum case.
@StefanSchmidtOz We use a randomization framework that is reproducible (each test execution is associated with a seed).
> I assume it runs each test method several times @StefanSchmidtOz We rely on CI for that.
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
It looks like BASE_PATH can be removed as well.
I think we should support it for individual repositories. Not really sure what would be a use case of supporting it globally.
if just read metadata it will also be easier to implement a fetch all interfeces, sort interface name, fetch interface ip sequence
Thanks for the explanation. Makes sense now, yes. And I learned something too.
preferably put this into the `next()` method instead so it will also cover the other blocking calls in this class. Could you also write this as `assert Transports.assertNotTransportThread(...)`, this will save from extra CPU in non-debug mode.
I wonder if we need this at all. The blocking call to the client executes it anyway. The issue was that there was no testing. I think this entire transport action can use a ml threadpool instead
OK. > On 20 Jul 2015, at 14:01, Shay Banon notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java: > > > ## > > - AsyncShardFetch<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> fetch = asyncFetchStarted.get(shard.shardId()); > > - if (fetch == null) { > > - fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction); > > - asyncFetchStarted.put(shard.shardId(), fetch); > > - } > > - AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId())); > > - if (shardState.hasData() == false) { > > - logger.trace("{}: ignoring allocation, still fetching shard started state", shard); > > - unassignedIterator.remove(); > > - routingNodes.ignoredUnassigned().add(shard); > > - continue; > > - } > > - shardState.processAllocation(allocation); > > - changed |= primaryShardAllocator.allocateUnassigned(allocation); > > - changed |= replicaShardAllocator.allocateUnassigned(allocation); > > I will do the assert when I remove the primaryAllocated flag in a different change > > â > Reply to this email directly or view it on GitHub.
can we add an assertion going out that going out of the primary shard allocator we don't have any primary shards in the unassigned list, unless we expect them to be there? (primaryAllocatedPostApi is false or restoreSource != null)
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
Is this necessary? I think that the cluster should know it only has one master node and sets this accordingly.
doesn't this add another field name that wasn't there before? Is this method used? do we need to implement toXContent? I'm looking a the implementation of RecoveryResponse
also applies to other places in the code below, if we decide to do it.
ok sorry I am not too familiar with these methods :)
as we discussed - corruptions can't lead to mapping parsing failures. They fail way earlier when reading from the translogs
can we factor the lentient handling part out in a single mehtod? ``` private Query rethrowUlessLentient(RuntimeException e) { if (settings.lenient()) { return null; } throw e; } ``` man I with we had support for annonymous functions here or macros even :)
I think that we want to log *each* time that we drop a warning header, not only the first time for a given request. Also we can be more precise than the current implementation which says one or the other condition is met, but we always know exactly which condition it is so we can help the user more by letting them know.
`wrnHeaderSize` -> `warningHeaderSize`
Use `Collections.singletonMap` here and `Collections.singletonList`
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
I'd do ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new FsChannelImmutableReader(id, channelReference, length, totalOperations); channelReference.incRef(); // reader private reference return reader; } finally { channelReference.decRef(); } } else { throw new ElasticsearchIllegalStateException("can't increment translog [" + id + "] channel ref count"); } ```
+1 to clone()
please - I can help if you want
Missing a space here after `id`
I'd return a dedicated return type not a tuple.. tuples are ugly on these interfaces introduce a new class!
I think you can just blast the entire method in this case.
I'd just leave the ternary operation there.
I see it now - I think how you've got it now is the most right thing then.
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
Again, I wouldn't pull out the ternary.
these unit tests are great! We are going to need more of them :)
Maybe use `expectThrows(...)` instead? It is much cleaner and safer than try-catch blocks: ``` java ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage(), equalTo("[regex_file] regex file [does-not-exist.yaml] doesn't exist (has to exist at node startup)")); ```
ah right I am familiar with this, I had the same too... you could do System.out.println(client).... just kidding.
this should just throw IOEXception no need for a shadowing ConfigException
@talevy Can you extract this IOException change from the PR and commit this to the branch? I can then benefit from it in the geoip PR too.
just as a sanity check that declares we do not support arbitrary unicode. I don't think we have that around
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
You can remove the http enabled in settings in this class now? Thank you for this! I think it should make these tests a bit faster!
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
this always yields true
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
`} catch (IllegalArgumentException e) {`
I think we can now remove this condition as the client can not be null because we throw now `new ElasticsearchException("Unable to configure Azure compute service", e);` in the CTOR
Does it need to be Writeable? It looks like we only serialize it using JSON.
we should remove `IndexMetaData#FORMAT`and `IndexMetaData#FORMAT_PARAMS` because they are now unused because of this
this is a confusing message... what if it's a boolean?.... also, it's annoying to get parsing error without any constext... "expected where?"... Have the method accept a `String fieldName` and change the message to: ``` throw new ElasticsearchParseException("expected an array of strings for field [" + fieldName + "] but found a [" + parser.currentToken() + "] token instead"); ```
nit: wondering if we can avoid parsing the map and rewriting it directly in json format. not sure there's a better way to do this.
Doesn't PipelineConfiguration deserve its own class file under o.e.ingest ? It's returned by the java api too.
You could probably avoid this by making the linux check a method that you stub out in OsProbe.
maybe in a followup we can think about removing these -1s... see what platforms fail, and better fine-grain the stuff (e.g. add assumption for WINDOWS, IBM jdk, whatever it might be). Then we know when and where stats are available.
actually it shouldn't be 0 but the same value as the wrapped query since timings are supposed to include timings of children
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
This test won't be needed when `getId()` is removed
I don't think we either but I know some folks like them so I certainly don't object to them.
Recently we've been doing something more like this: ``` clearIndicesCacheRequest.queryCache(request.paramAsBoolean("query", clearIndicesCacheRequest.queryCache())); clearIndicesCacheRequest.requestCache(request.paramAsBoolean("request", clearIndicesCacheRequest.requestCache())); ... ``` Rather than the loop. The whole loop thing is more appropriate for by-hand xcontent parsing then url parsing.
(hint: ParseField makes it easy)
`fielddata` is the preferred name as of my merging #28943 today.
Can you update the `\rest-api-spec\src\main\resources\rest-api-spec\api\indices.clear_cache.json` as well? ( do we need to specify all supported params, or only the preferred ones. There is also a `recycler` flag in the rest specs which I do not see in the code )
nit: missing space
just name it `readSize`
can this be in try-with logic.... you are not closing this input stream at all
just name it `read`
I wonder if we should enable this only for new indices that we know are created with es 1.4
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
1. There is a minor typo/grammatical mishap here - text should read "[cluster.name] must not _contain_ ':' character" 2. Id consider putting this exception text into a final static variable somewhere it would make sense to put it. This text is currently used in two places in the code - once here, and once in a unit test - and the way things are now, if you want to change the contents of this text, you need to change two strings in two different places in the code. If you had this text in a final String variable, and you referenced that variable here and in the test, you would only ever need to change the string in one place.
I think we should be able to assert here that the `metaStateService` is in its "reset" state, with no pending writes (i.e. empty `cleanupActions` and `newIndices` and `globalGeneration` matching that in the `currentMetaState`.
Nevermind, I see, it was a remnant from the imports up top, just got shifted around
It'd be more helpful to me if these notes were on the method if we're going to mix them together like this. Another option would be to have two interfaces implemented by one class. I'm not sure that helps at all.
nevermind I was confused... all is good
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
You don't need `containsKey` here, you can put this line of code below the check for `if (value != null)`
Right, what I meant was, that `containsKey` value is only used if `value != null`, so why not get it only if `value != null`
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
Can we somehow factor out these bytes w/ e.g. `Checkpoint.java` so that if we change the header of the checkpoint / translog files, this tool is fixed too? Otherwise if we fail to do this, a user could run this tool and it makes a corrupt translog instead!
what about creating reusable assertion methods here, along the lines ``` private void assertExecuted(tool, executed, OK) ```
this keeps bugging me :) we should something on the executor as well....
This logging statement has a `[{}]` but no argument to fill it
we should log the exception here.
can we use `== false`
Why is this `volatile`? It doesn't look necessary to me.
we shouldn't need this here in parse phase
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
I guess we just prefer primitive types over objects :)
I don't mean to block this PR specifically, these are just things that are popping up the more I review similar PRs
Hmm good point, I had forgotten that this class could actually be returned to the user (masked behind an API interface).
that is a good idea, but maybe add the switch later on then? it really makes no sense right now :)
was this another problem? I wonder why this assertBusy is needed.
> Though I do prefer that it fails fast instead of lazily later. ++
Is this right? Shouldn't it be `validHeaderValue`? And I don't think this should be an assertion, but a hard failure (assertions are disabled in production and if we are sending bad headers something is seriously wrong and we need to die hard).
No, I still think that it should not be a method on the `Strings` class.
Actually I just checked and removing name and description from the Plugin interface should be easy. The only thing to think about is what to give for those properties when plugins are loaded from the classpath (plugin.types). I think here the name should just be the classname, and description something like "plugin loaded from classpath"? I don't know what other info we really have.
Also, can you add an element to maven enforcer plugin for plugins/pom.xml so it fails build cleanly and early if this property is not set? We should also insert a check in pluginservice, if it differs from the directory name, someone manually meddled
This file is new in 2.0, we can change it
We should also check the name matches that in jvm plugins. As a follow up, we should at least remove description from jvm Plugin interface, and possibly also name (possibly a little harder, just requires passing around PluginInfo instead of Plugin I think).
Hrm, can we just call this "name"? None of the other settings are prefixed with plugin.
`retry < this.numberOfRetries` is implied here due to the outer check.
I also wonder if we should log `TRACE`/`DEBUG` issues for this.
nit: s/read blob's/read the blob's
Rather than `True` maybe this method could be called `checkCurrentBucketEventCount`? There's nothing to say it couldn't change again after this method does its work.
Er, well, it doesn't work like that. Ignore.
same here regarding the logging as above if applicable
I think this message is misleading - we don't actually schedule the delete of this index but rather ignore it. Maybe change to "failed to lock a dangling index [{}], probably in the process in being deleted, ignoring." . I also think we should include the exception as it may not be a LockObtainFailedException but something else.
Left over Note
same here - I think it's better to log the info message if the deletion was successful.
Do we need this? the settings are already immutable
let's keep as is, with the assertion message I think it's ok. I wonder if we should have an assertion at the end of this method to say something like "if we have an active primary shard that's not relocating, then the replication tracker is in primary mode".
Oh, that error handling!
With the change I suggested above we can leave out the == PEER condition and instead add ` && currentRouting.isRelocationTarget == false` to `currentState == IndexShardState.POST_RECOVERY && state == IndexShardState.STARTED`
I prefer my way but have asked @jasontedor to chime in.
fyi - this gives you double [[]]
Did you push the change that added it? I don't see it.
You can also assert that there are no bytes left to read I believe. Some of the other tests in this file do it and it is a good idea I think.
We have a check on the test setup for all tests that makes sure assertions are turned on and fails the test if it's not (not sure exactly where it is but if you try running a test without assertions turned on you'll see it)
ok I remembered some CI randomization around `-ea` in the past, maybe that has changed in the meantime.
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
I'd rather have a different parameter there. However, that would add complexity. It might be better to not handle missing field or NaN and Inf at all and let the user sort it out with range filters.
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
can we use "script_factor" I think it's nicer than the came case
Fine with me.
what happens if there is no mapper? I would tend to simply ignore (to match the logic we have for stored fields now)
Extra space is extra.
I see, that is hideous. ð¦
you evil person :)
I'm okay with this.
Did you confirm we sometimes hit this and not just ACE? (The "indexed" CountDownLatch should make it likely...)
Can you have a quick look again if this should be MATCH_PHRASE_PREFIX_FIELD instead? In which case it would also be good to catch this in tests if it is wrong.
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
nit: reading all this makes me think if we could get parseContext.parseFieldMatcher() once with a shorter local name at the beginning and then shorten the lines here a bit. Just for readability. I know at this points it's probably some tedious search/replace action, just throwing this in as a thought.
Good to read, but this more or less repeats what ParseFieldMatcher.match() already does. I think it just adds another stop on the road to the actual match-implementation, which is not even in ParseFieldMatcher but in the ParseField itself. I was thinking about simple shortening like `matcher.match(currentFieldName, PARSE_FIELD)`, but I think its fine the way it is right now in the PR, not worth going trough all the files again IMHO.
I think we should leave these two above for bw comp
Same feedback as the last `toString` - I think you can remove `created` and might want to look at `Operation`'s `toString`.
Same deal as the last `toString`.
I'd move this to line above, but I like the thought behind the change.
I think it is fine: we only build one search context per request per shard.
There's no need for reflection here - writing out all the fields, in a sensible order, is much preferred.
> we'll still see this infinite loop for "{" for example. I'd expect the parser to throw an exception on this? > Is it really a good idea to have the behavior of org.elasticsearch.rest.action.RestActions#parseTopLevelQueryBuilder be to loop forever on part of a valid JSON request? :) Of course not, and this is not what @cbuescher said.
I'd rather like to have a check outside the parsing loop that asserts that the first token the parser emmits is XContentParser.Token.START_OBJECT. I think its save to assume we are expecting full json objects. I'd also just throw a ParsingException in that case.
Thats a String token though...
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
+1 to: ``` List<DiscoveryNode> nodes = this.nodes; if (closed) { throw new IllegalStateException("transport client is closed"); } ensureNodesAreAvailable(nodes); ```
Yeah, I'm not advocating for removing the mutex. That isn't going to work. My thought came from vague notions of "can we just set the list to null when we've closed the client?" kinds of questions.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
This could technically add a listener after done is set to true and at the same time something else is reading the list which is not safe.
This is why I said moving to compute instead of computeIfPresent so that we could assert that we do have a mapping for nodeId in that map at that point. To be clear I think that what you did is correct, I'd just like to add assertions to it to make sure the invariant is respected.
why did you add it? I mean, it is very internal...., it will mean cluster state API will become so much more noisy
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
This can be replaced by ` ensureExpectedToken(XContentParser.Token.START_OBJECT, token, parser::getTokenLocation);` from `XContentParserUtils`
Looks like the toXContent() and fromXContent() are not completely mirrored; the former does not render any root object while the latter expects it.
Those two code snippets are very similar.. I think we should go more generic here, maybe you can add a static `XContentHelper.toString(ToXContent foo)` which acts like in the `SearchSourceBuilder` and does not throw an exception, but returns an error JSON ``` java @Override public String toString() { try { XContentBuilder builder = XContentFactory.contentBuilder(XContentType.JSON).prettyPrint(); toXContent(builder, ToXContent.EMPTY_PARAMS); return builder.string(); } catch (Exception e) { return "{ \"error\" : \"" + e.getMessage() + "\"}"; } } ``` There should be another `XContentHelper.toString(ToXContent foo, boolean wrapInObject)` method which adds the needed `builder.startObject()` and `builder.endObject` calls, if specified. With this change, both of this calls, would basically be one-liners. Hope it makes sense...
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
> talking below about using only the index, source, and id probably a typo, but just in case - index, type and id (not source)
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
we should be careful here and check for sources that are binary (SMILE etc..)
I don't think we need the exact number of bytes and if bytes is what we have we should use it. No reason to work hard to get characters.
Please fix identation.
this last line is redundant I think, we already check the same above
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
ignore this, sorry for the noise :)
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
Given the method's name I expected it to check the values too.
I'd use `randomAsciiOfLength(5)` rather than fixed strings for this.
Sorry about these crazy incantations....
Not one of my creative days today. Maybe in the org.elasticsearch.test package, no idea what the classname could be :)
I wonder if we should start already sharing some common code between our BaseQueryTestCase and this class....wouldn't want to complicate things though. Also our base test class in not in master of course so that woul already complicate things...
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
yeah, that was what I meant
and the `ExceptionsHelper.` qualifier is unnecessary
can this be a constant
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
this will annoy the forbidden API after rebase + squash. Heads up
use ArrayList? one less usage for non standard code...
While you are here why not remove the whole `Fields` class and just use strings? That is the "new style". For things that are used in more than one place we'll typically use constants - and if those things are using in parsing the constant will typically be a ParseField, but otherwise we've started to not make these `Fields` classes.
catched -> caught
left over reference to a countdown latch
In our discussion about semaphores I understood a different model we keep a semaphore per index/shard directory (like the on the disk locks but in memory). That would be pruned when the folders are pruned. I see where you were heading. I'm fine with either way.
Oh, nevermind on the second point, I see `ShardLock` implements `Closable` already.
This is the way the check should work, but I'm afraid its not totally complete. Imagine a 4.x commit point with some 3.x segments. I actually think lucene 5 does the wrong thing here right now and will throw some IllegalArgumentException or SPI error. I will look into it. In the future, this would be a cool test index for us to have cc @rjernst
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I think the OOM reference was a copy paste error from another clause. This clause doesn't do `translog.newTransientTranslog(translogId);` so no need to revert it - although it seems to do no harm if there is no current transient translog.
I think this missed a misses a maybeFailEngine
also applies to other places in the code below, if we decide to do it.
Hmm... I'm not actually sure how this would play with Snapshots, so it may be a no-go.
Please fix identation.
Since this is only going to be used in tests, I think we can get away with: ```suggestion return Objects.hash(maxSeqNo, localCheckpoint, globalCheckpoint); ```
Note that you can use Objects.hashCode(function) directly which will make sure to return 0 if the value is null.
Maybe let's just call Objects.equal(script, other.script) for simplicity? I know you did not introduce it though...
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
It might be a good idea (possibly in a different PR) to have a method on `ScriptEngineService` called something like `getSupportedScriptContexts()` which each implementation can use to define what script APIs they support. I imagine there are/will be other language that don't support some script APIs and this would not only allow them to use this too but would also remove language specific code form the ScriptService, which should probably remain language agnostic.
Ok fair enough, Hadn't considered the settings aspect of this.
same as above, this breaks bw comp for the java api
Er - if you are going to log something then it doesn't matter which order you do it I guess.
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
```suggestion public void setFile(File file) { this.file = file; } public void setFile(String file) { this.file = getProject().file(file); } ``` Along the same lines as above to avoid the use of Object.
I would prefer we use something like `Files.write` where we can be specific about the encoding. `FileWriter` will rely on the default encoding, something we generally try to avoid.
no need for a constant here, you can use `StandardCharsets.UTF_8`.
oh nevermind I know why it's Streamable since it's send as a request...
cool stuff I didn't see that one!
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
I think we should complain if we don't find the header name.
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
I think this needs to be "unidented" by 4 spaces. Also just for the "beauty" of things you can move the leading whitespace char to the prev line.
Probably don't need to compute `headers.size() - 1` for every header, could move it out of the loop
Instead of adding these plugins as we go, we can get the `values()` from `loaded` at the end of this method.
wrap the plugin names in `[` and `]` for consistency
can this be ``` if (pluginClass.getName().equals(plugin)) { luceneVersion = pluginProps.getProperty("lucene"); break; } logger.debug("skipping [{}]", pluginUrl); ``` I think taht is more clear
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding jvm plugin [{}]", plugin.v1()); } ```
nit: the map can be `PluginBundle::plugin`
That plan concerns me, as it means there is the (however distant) possibility these settings get released before being converted to secure settings.
Nit: you could use `Collections.emptyList()` instead of `new ArrayList<>()`
I hope I'm not splitting hairs, but there's also a typo in the field (deault is missing and 'f'). (This PR resulted from a question I asked here; thanks for all the awesome work you invest there!)
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Not needed anymore.
`s/shadow replicas/shadow shards/`
I think it is important to keep different classes on the client-side so that we can have more type safety and potentially add some methods to only eg. avg in the future
can we make the list immutable for safety? using Collections.unmodifiableList
I think BuildFactory should be allowed to throw a ParseException since subclasses should have the ability to throw it if there is a problem with creating the builder at this point
please log the exception here as well we really wanna see what was going wrong
`them` -> `them;`
I think this needs to be `Version.V_6_0_0_alpha3` now.
Just discussed it with Robert and indeed this fsync is not necessary.
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
+1 to not swallow the original exception
This change would only break `wildcard` query on these fields, right ? +1 to make them string fields, `prefix` and `regex` query do not work currently because of this so it would be a bug fix. I am also ok to do that in a follow up, the changes in this pr have a different scope.
The `keyword` field applies the normalizer on `termQuery`. Depending on the normalizer the wildcard and escaped characters could be removed/replaced so I wonder if we should apply the same logic than `QueryParserBase#analyzeWildcard` for `keyword` fields. This is out of scope for this pr but it made me realize that we might have a bug here.
maybe one day we will a base class for runtime mapper field types that does this in one place.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
I think the following if is not valid anymore in fromXContent: ``` MatchQuery.Type type = MatchQuery.Type.BOOLEAN; if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_FIELD)) { type = MatchQuery.Type.PHRASE; } else if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_PREFIX_FIELD)) { type = MatchQuery.Type.PHRASE_PREFIX; } ```
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I think that these log parameters are backwards.
sorry I didn't see that you created a copy (I missed the "new HashMap" part)
I think it is fine: we only build one search context per request per shard.
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
@spinscale I think it is needed if it is expected that another thread might be updating the context at the same time (ie. synchronization is protecting the hash map copy rather than the null check)
thinking if those `synchronized` code blocks are needed, if you always check for `null` first, as context is never set to `null` again...
oh I was hoping that was gone already. seems like parsing booleans is very complicated for us....
> I think we're talking about two different sets of leniency :) ++ :smile:
The worst is how `on` and `no` both parse to legitimate values, very dangerous for transposing typos.
I don't like leniency. Can it be `"true"`, `"false"` or `null` with the former parsing to the right `boolean` and null giving the default? A typo of `"tru"` will parse to `false` and that makes me :cry:.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
replace match here too
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
I think we can simplify here and print everything out, default values included, that's what we went for in all of the other queries too.
Another to remove
Can you remove this class entirely in favor of just returning AcknowledgedResponse? (similar to #32722)
We should be testing serialization here by extending `AbstractXContentTestCase`. Unfortunately, that means we need to also write a parser for the request but it's worth it.
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
nit: updates -> update
Again, I wouldn't pull out the ternary.
isCreated instead of getCreated
why do you pass the response to this method? `this` already has all information.
I see it now - I think how you've got it now is the most right thing then.
Ooooh - maybe we should just delete to `getOperation().status()`? We could probably move this whole method up to the superclass then.
Out of date doc.
Discussed via chat - we should not use the Version.CURRENT as a default to make sure the version is set. The part about a 1.2.0 master is not relevant as it will set the SETTING_VERSION_CREATED key as well.
3 more indentation issues above
Can you rename these indices? I know I'll get `test` and `test1` mixed up. Even `test1` and `test2` would be better.
I'm a fan of `assertThat(e.getCause(), instanceOf(IllegalArgumentException.class));` because the error reporting is better.
you can remove the validate call for now, we will fix all queries soon, I promise
here is a space missing before `EMPTY_FLAGS`
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
this should be `isExists`
this way you always a single flag. I think I would do something similar to what we do here: https://github.com/elastic/elasticsearch/blob/feature/query-refactoring/core/src/test/java/org/elasticsearch/index/query/SimpleQueryStringBuilderTest.java#L65
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I mean random number of replicas with random combination of non-active states
BTW, instead of the above to wait for the nodes to come up, could something like this be done? ``` client().admin().cluster().health(Requests.clusterHealthRequest().waitForNodes(Integer.toString(3))).actionGet(); ```
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
you can do : `internalCluster().getInstance(ClusterService.class, nodeA).localNode().id();`
This cast should not be necessary. You can use `in.readMap(StreamInput::readString, StreamInput::readString)`
No need for an empty default ctor when the super is also a default ctor.
No need to override readFrom or writeTo
Does this rest path potentially limit api additions/changes moving forward given that there is no description of what action is being taken as part of the path? Something like admin/scripts/lang/painless/action/execute may be significantly more flexible.
You don't need to create an explicit default ctor since the super class has a default ctor.
Is this any quicker if you use bulks? I tend to do that out of habit.
Can you remove the empty javdoc? We are going to fail the build on those at some point....
I find that `equalTo` is almost always a bad choice. In this case I think `assertThat(cancelTaskResponse.getTask(), hasSize(1));` will do the same thing but have much better error reporting. That way you get to see all the tasks when there are too many. Same for the above assertion.
Does this happen because the scroll doesn't hit docs in that segment so it can't be blocked? Should canceling a scroll request nuke the scroll id? If you tried to pump it again would it be busted? Maybe something for a followup though.
for master you don't need to specify the gateway.type we only have what used to be local!
Is there a reason these three fields need to be test instance members be randomized in the init() method? Otherwise I would prfer making them local in createTestIntstance().
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
I'd also merge it with the testPercentilesIterators() method if this is the only place where it is used.
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
But that is not equivalent? Arrays.toString is a static method, and different than result.buildConflicts().toString()
maybe put this in an `if else` clause? For me this makes it clearer what is pre 2.0 and what is 2.0 behaviour.
why do we need to merge this again since we are still holding on to the lock? I don't necessarily understand why this is helping us as well but that might just be because I don't know this code very well.
Notice the difference in the first parameter to MergeResult. This is the "simulate" argument. The first time we don't change anything in the merge, only check for any problems. Ideally we could move this simulation to something like we have here with check compatibility. I had a branch for a this long ago, but it was a complex change.
I think we should collapse the two above methods, they are always called in sequence.
In my dreams, merging would either throw an exception or return a new independent mapping so that we wouldn't need this validation phase :)
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
I think you can just do the `== null` part of this and the next `if` condition, since if the other were equal to null, we would have already returned in the first `if`? ``` if (x == null && y == null) return if (x == null) ... else if (y == null) ... else // x and y are not null ```
I'm not sure myself why this hasn't been done this way. :-) It's fine, I was just curious if you had tested calling super and if it introduced issues.
I'm worried that by copying over the field type completely we get more stuff then what we tested for collisions. For example, indexOptions is not tested. Maybe there are other stuff.
I think these don't need to be volatile any more, now that we read under lock.
I think we want to assert here that lastRequestedSeqno is the global checkpoint
at that point you want have a read budget, which I mentioned above.
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
I think 0 is a good minimum value.
I don't think so, I think these should be bytes or size-value only.
++ to keep byteSizeSetting here
We call them "master nodes" everywhere else. :frowning:
if this is for tests only then don't register it by default. Rather register it in `InternalSettingsPlugin.java` and install that plugin in the relevant tests
minor: I think it would be a bit more obvious to explicitly call `DateTimeZone.getDefault()` instead of `null`. Since that is what Joda does with the `null` value. http://joda-time.sourceforge.net/apidocs/src-html/org/joda/time/DateTimeZone.html#line.301
Just as a note, LuceneTestCase (which we inherit from) offers a nice helper to shorten these try/catch constructs, it goes something like this: ``` IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> ...do Something...); assertThat(... some assertions about e...); ``` I see that the rest of this test also still uses try/catch for most exception tests. This is okay as it is, I just wanted to mention it.
can you try and run the test with the seed mentioned in the bugurl and see what happens (also possibly run it with a `-Dtests.iters=2000` and see if that passes) - maybe we drive by fixed this.
we may want to rename match_formats as well here, can do in another PR though.
This is totally funky and the parsing code is crazy, but I verified it works with weirder timezones. ``` assertDateMathEquals("2014-11-18", "2014-11-18T00:00:00-09:30", 0, false, DateTimeZone.forID("Pacific/Marquesas")); assertDateMathEquals("2014-11-18", "2014-11-18T23:59:59.999-09:30", 0, true, DateTimeZone.forID("Pacific/Marquesas")); ```
timestampMillis -> unassignedTimeMillis delayCalculationTimestampNanos -> unassignedTimeNanos
lastComputedDelayNanos -> lastComputedLeftDelayNanos
Let's call this `timestampMillis`
getDelayCalculationTimestampInNanos -> getLastComputedLeftDelayNanos
Oh, got confused , which is the point :) getDelayCalculationTimestampInNanos -> getUnassignedTimeInNanos
maybe make if final
maybe s/INDEX/COPY and s/NONE/NOT_STARTED to be consistent you should also s/FAILURE/FAILED
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
maybe also test a nested conditional setup? (So have conditional and then another conditional in the matched or unmatched list)
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
Do these really have to be test instance fields? Can they be passed around? They are easy enough to construct.
as an alternative you can mark it as final abstract then you don't need the private ctor
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
remove the iterations please
If your intuition is that these will be almost always needed, then obviously we should keep them.
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
I think an absurdly high limit could still be helpful? (in a follow-up PR)
Here again I think we should use `builder.timeField` to handle this
For human readable-ness, an additional field should be added, we shouldn't replace the field with a human readable version. You should be able to do ```java builder.timeField("modified_millis", "modified", modifiedDate); ``` (replacing the field names with the fields we want to use) and then you don't have to check the human readable flag yourself
+1 to this, there is always the low-level rest client for this, and we can revisit adding it at a later time if we change our minds.
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
I think we should make all of the mutating methods in here package private to be consistent like `moveToPrimary` etc.
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
nit: maybe call this `awaitSearchActive` (or `markSearchActive` if my other suggestion is accepted to move setting the timer here) ? pending refresh is an internal implementation detail..
can we move this part to the setRefreshPending method? this will come at the expense of a dedicated listener but all the code that changes pendingRefreshLocation will be in one place making it easier figure out.
I think we use the empty string somewhere yes, not sure if that was a wise choice. I don't mind leaving null, no biggie
The reason used to be not to make writeNamedWriteable public. I think it is still the same. Design decision we made with Simon when we added the NamedWriteable abstraction. We didn't want e.g. plugins being able to serialize just anything by using this generic write method.
I don't like that we're making `StreamInput` a God class.
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
the node where the shard should move to
Question, do you think it would be helpful to copy the pattern we have elsewhere having a `*Safe` version of the functions? So something like: ``` java public Decision getDecisionSafe() { if (isDecisionTaken() == false) { throw new IllegalArgumentException("decision must have been taken in order to return decision"); } return decision; } ```
Instead of making up our own exception, why not use just use Files.delete? This will give you a better exception message. https://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#delete(java.nio.file.Path)
I don't think that a security exception should be re-thrown as an `IOException`.
> We should not catch the `SecurityException` at all. Let it propagate. Precisely.
We should not catch the `SecurityException` at all. Let it propagate. We should not have even gotten to this point if the security manager did not give us access here, but in any case, its not an exception we should handle at this level. It should just be propagated.
maybe not appropriate here, but we can do this with one underlying read of metadata via Files.readAttributes (you then have isRegularFile() and size() available from BasicFileAttributes)
not really wrong since we do not require things to be reproducible in that case, but I'd rather like to use context.reader().maxDoc() instead of context.docBase so that matches only depend on the current segment
I'm wondering why you decided to override this optional API. Is this impl expected to be faster than pulling the iterator and calling next in a loop? (this is what the default impl does)
we should use actual exceptions instead of assertions since we are validating some user input
instance variables should use camelcase
This worries me a bit as this is inconsistent with the filters and ranges aggregations.
I am fine with doing it in a follow-up PR if that works better for you
don't try to fix it, you just moved code around, but this catch block worries me :(
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
I am not sure how this can work, is the flag ever set? anyways I think we should remove this flag and change this logic as stated above
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
While you are here why not remove the whole `Fields` class and just use strings? That is the "new style". For things that are used in more than one place we'll typically use constants - and if those things are using in parsing the constant will typically be a ParseField, but otherwise we've started to not make these `Fields` classes.
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
this will annoy the forbidden API after rebase + squash. Heads up
Instead of having a reserved null value (-1 in this case), use an Object float for `minScore` in ShardTermsByQueryRequest and TermsByQueryRequest. Then we can just do a null check: ``` java if (request.minScore() != null) { ```
Maybe use Object float? We do the same thing on SearchContext
w00t thanks !!
`this()` is obsolete
so this means we don't support `topLeft` anymore? I think we have to to be honest. Also we have to support `northWest`
ok, fair enough. ++ for setting up compatibility with GeoPointv2
is it worth doing the conversion from and to geohash every time here? Could it be better to not do the conversion and store two doubles per bucket instead of one long? I guess its a trade-off between execution time and memory
The score of this query depends on the number of shards, the default similarity, ... To make sure that we have consistent scoring you can use a `function_score` query like the following: ```` QueryBuilder query = functionScoreQuery( termQuery("name", "one"), ScoreFunctionBuilders.fieldValueFactorFunction("my_static_doc_score") ).boostMode(CombineFunction.REPLACE); ```` ... and add the `my_static_doc_score` at indexing time.
one too many new line? :)
What happens if `enabled` isn't set? I *think* we should continue to do nothing if `enabled` is actually true.
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
right I see that
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
Nit: `}` is in a funny place.
Also, we will need the oposite conversion from the ES enums (e.g. TermSuggestionBuilder.SuggestMode) to the Lucene enums (org.apache.lucene.search.spell.SuggestMode) used in the DirectSpellcheckerSettings later anyway, so rather than having `fromUnderlying` better turn the direction around to each enum knows how to produce the corresponding low-level enum.
nit: can you break this into multiple lines so its easier to track w/ `writeTo`
`this` is unnecessary
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
Incides -> Indices ? ;)
typo in the method name here too
same as above, this seems the same method as before
I think we can omit catching this and failing when caught, that's default behaviour, what matters if the `finally` I guess
please replace `assert false` with `fail()` if we run without assertions this test fails :)
confuses the shit out of me everytime :)
"new" -> "now"
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
I think we should throw an exception when `id < 0`, which should never happen? (unless Bad Stuffâ¢)
I think this needs to be `Version.V_6_0_0_alpha3` now.
nit: this change is not needed
given this I think we should add some checks to the place where this is created in `SearchService` ie. this: ``` Java SearchContext createAndPutContext(ShardSearchRequest request) throws ElasticsearchException { SearchContext context = createContext(request); activeContexts.put(context.id(), context); context.indexShard().searchService().onNewContext(context); return context; } ``` should look like: ``` Java SearchContext createAndPutContext(ShardSearchRequest request) throws ElasticsearchException { SearchContext context = createContext(request); boolean success = false; try { activeContexts.put(context.id(), context); context.indexShard().searchService().onNewContext(context); success = true; return context; } finally { if (!success) { freeContext(context); } } } ```
I'm not a big fan of this field. It feels like it could just get pushed down to be an `AtomicBoolean` inside `upgradeTemplates`, or if we need it to be a field, I think it works better if its meaning is reversed e.g. `detectedUpgradeErrors` As it stands we reset it to `true` even if we know something failed, which just feels wrong.
why change this to an AtomicReference? Just because of stylistic reasons or is there more to it? Looking through the PR, I could not find a reason for this change. Every write access to it is guarded by a mutex, and read access is ok with volatile. Let's keep it a volatile variable.
I think these don't need to be volatile any more, now that we read under lock.
Er, probably not. But a bit confusing name because it looks like a typo.
I think this file needs formatting `if(` -> `if (`
also, why not use indexShards() now that we see this as a write op - then we don't need to change the visibility of the shards methond on Operation Routing
clusterName is not needed here.
should we here or in the superclass fail if the cluster has not fully upgraded to 2.3? just as a safety guard I think that would be a good check in several places otherwise I can see us debugging weird issues `DiscoveryNodes#smallestNonClientNodeVersion()` has a neat method to check.
I think that this should be an `IllegalStateException`.
Nit: `getNumConnection` -> `getNumConnections`.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
yea, I would at least debug log it..., it shouldn't happen
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
Can you shrink-wrap this try clause? (Pull the `map.put` out after it.)
the important part is having multiple open readers on this as well.
as an alternative you can mark it as final abstract then you don't need the private ctor
we also need unittests for these queries!!!
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
I think this declaration/initialization can be moved to inside the if
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
Hurray no more weird `while (true)` loop
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
Another `_` java 9 will be mad at
this is really the job of TRA to test this? it's an index meta data thing. Whis is it here? I think testing here should be very minimal and just check that the TRA funnel index level setting to a request object _IF_ the request has it's method set to default. All the rest of the logic is a `ReplicationOperation` thing.
I think we want to test index level blocks too here
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
nit: `an` -> `a`
let's assume that if the method parameters are not marked as @Nullable that they are non-null. Otherwise we clutter the codebase everywhere with these checks.
I think we should separate the two and push this as is. Your code refactoring has more changes than this functional change and on the security end I think we should be careful. let get this in and cleanup the stuff afterwards
yeah again, its definitely bad the way it is now, easy to break. if we initialize netty classes too early before security kicks in, we might not notice anything, then suddenly users jvms are crashing (e.g. because of some bug in unsafe/native usage, or whatever). with a netty module things would get way better: one advantage is, netty isnt on the classpath anymore, instead we load it explicitly with `URLClassLoader.newInstance` in PluginService, followed by `Class.forName` and so on with the registered plugin class from the plugins configuration file. So it would be well-defined exactly when these classes will get loaded, and its all after security and everything else is fully initialized.
> Last - if there is any way to determine the list of classes loaded at the point security kicks in, Yeah, you can do something like this: `JAVA_OPTS=-verbose:class bin/elasticsearch`
> Also, for my understanding - what is the difference in terms of class loading between running that static `NettyTrasnport.DEFAULT_RANGE` that was before? Accessing static compile-time constant variables will not trigger class initialization, but any other access to a class member will trigger class initialization immediately before the first such use (the JLS provides very strong guarantees about [when](https://docs.oracle.com/javase/specs/jls/se7/html/jls-12.html#jls-12.4.1) and [how](https://docs.oracle.com/javase/specs/jls/se7/html/jls-12.html#jls-12.4.2) this occurs). > This is so easy to slip without anyone noticing. Yes. The [suggestion](https://github.com/elastic/elasticsearch/pull/14549/files#r44182190) for a test for this has come up before.
typo: "always called" twice
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Ahh, sorry. You are 100% correct.
Sorry, I overlooked the null check. This is good!
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
Is the version needed? I don't see it being read here.
this will annoy the forbidden API after rebase + squash. Heads up
kk. was referring to both the maps and the lists later onâ¦ > On 28 Aug 2015, at 20:40, Jason Tedor notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/action/admin/indices/recovery/TransportRecoveryAction.java: > > > - for (int i = 0; i < shardsResponses.length(); i++) { > > - Object shardResponse = shardsResponses.get(i); > > - if (shardResponse == null) { > > - // simply ignore non active shards > > - } else if (shardResponse instanceof BroadcastShardOperationFailedException) { > > - failedShards++; > > - if (shardFailures == null) { > > - shardFailures = new ArrayList<>(); > > - @Override > > - protected RecoveryResponse newResponse(RecoveryRequest request, int totalShards, int successfulShards, int failedShards, List<RecoveryState> responses, List<ShardOperationFailedException> shardFailures) { > > - Map<String, List<RecoveryState>> shardResponses = Maps.newHashMap(); > > @bleskes Are you referring to Maps? That hasn't been forbidden yet (but it will be soon). > > â > Reply to this email directly or view it on GitHub.
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
I don't believe its necessary, ++ for taking it out
Not necessary with `ConstructingObjectParser`
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
excude_interim - missing 'l' -> exclude_interim
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([9959A23819CF838B:6FE2182D9705AE]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.MultiPointBuilder.<init>(MultiPointBuilder.java:46) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiPoint(GeoWKTShapeParserTests.java:82) ... ```
nit: formatting, add some whitespaces
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: Invalid number of points in LineString (found 1 - must be 0 or >= 2) at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:3A8577712E4A2AD2]:0) at com.vividsolutions.jts.geom.LineString.init(LineString.java:102) at com.vividsolutions.jts.geom.LineString.<init>(LineString.java:93) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:539) at com.vividsolutions.jts.geom.GeometryFactory.createLineString(GeometryFactory.java:531) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseLineString(GeoWKTShapeParserTests.java:99) ... ```
I get occasional failures here if run frequently (100 iters), e.g for this seed: ``` java.lang.IllegalArgumentException: cannot create point collection with empty set of points at __randomizedtesting.SeedInfo.seed([3BC798163FFF812D:918E10886BC43EC1]:0) at org.elasticsearch.common.geo.builders.ShapeBuilder.<init>(ShapeBuilder.java:97) at org.elasticsearch.common.geo.builders.LineStringBuilder.<init>(LineStringBuilder.java:49) at org.elasticsearch.common.geo.GeoWKTShapeParserTests.testParseMultiLineString(GeoWKTShapeParserTests.java:112) ... ```
nit: formatting, add some whitespaces
+1 to not swallow the original exception
Just discussed it with Robert and indeed this fsync is not necessary.
Can we soften this message? maybe "deleted previously created, but not yet committed, next generation [{}]. This can happen due to a tragic exception when creating a new generation"
I think this needs to be `Version.V_6_0_0_alpha3` now.
`them` -> `them;`
sorry, my bad.
Since `value` internally is a String now, we can change read/write here as well.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
we set the rewrite method twice it seems? probably a bug in the original parser
I think you should use QueryShardContext#isFilter but that is something that @cbuescher is working on, he should be able to give you some more details on that
good test, would be better to move it to a brand new class though, as this existing test class starts a single node cluster but you don't need to send any requests to it. This is a pure unit test, you can call it `StringFieldMapperXContentTests` and make it extend `ElasticsearchTestCase`.
sorry, scratch that, you need parser, which needs the indexService, which needs an index on the cluster. It's all good, leave the test where it is. ;)
one too many new line? :)
Thanks, I probably read the test to quickly and missed the startArray() part. You are absolutely right, this is how I expected the test. Sorry for the noise.
nit: some whitespaces around the operators etc... would be nice
It'd be nice to know that some more things we expect to work do - stuff like the current time, all the listed methods. Most of the the stuff you need to fake out scoring is in the IndexLookupTests so that is cool.
`indexMetaData.getIndex()` -> NullpointerException!
Can you open a lucene issue for this? Meanwhile, I think it's a good idea to copy the implementation of checkResetException() into the test code here, as it checks the contract pretty strictly.
There is a problem with this test setup that I just found: the xContentType that is used for parsing here is not necessarily the same as the one that is used int randomUpdateResponse(). So the expected values might be off, e.g. if in randomUpdateResponse() SMILE is used and here xContentType is Yaml.
you are right thanks a lot for catching this
Nit: Can we give this a more meaningful name instead of an abbreviation? I'm fine with `TestResponseHandler` for example.
Nice, I like the randomization on the thread pool.
A more meaningful name would be nice here too, for example `TestRequestHandler` is okay.
use ``` if (!latch.await(10, TimeUnit.SECONDS)) { fail("error message...") } ``` to avoid potentially hanging the test
this applies specifically to generic() threadpool. As this is a more general test case now, we can increase the bounds to (expectedmin, MAX_INT).
I wish that we did not have to go from MapperScript to IndexTimeScript, and rather reuse the same concept. I still wonder if this could be `void executeScript(SearchLookup, LeafReaderContext, ParseContext)`? We could make the notion of scripted field known to FieldMapper, let MappingLookup collect all mappers that have a script declared, then each one of those has the execute method called. That way you can also ensure the same behaviour once you add this functionality to other mappers? This suggestion goes against another one I made on making OneTimeFieldExecutor implement IndexTimeScript. MAybe with this suggestion IndexTimeScript could go away and we would have to see what to do with the one time executor.
I can see how having two methods is not fantastic, and why you had done it differently before. I had envisioned script as a member of FieldMapper directly, but we are going to see if that is possible once we add support for script to other mappers. The type of the consumer will make it possibly harder to share the impl but we'll see. I am happy though with the execute method, I find it much clearer than returning an executor like we had before, because it is evident what it does and easier to trace.
Are there any calls to this version of findTemplateBuilder with matchType `string`? Or `findTemplate` below? very confusing how we have so many public variants of this method...
Have a look at `ConstructingObjectParser` which is designed for those cases where you have required parameters for the constructor. Alternatively you may end up making an object that has writeable parameter and then building the script from that. Whatever you think is more readable.
Maybe this one too, I'm not sure.
I just realized that this would make the upgrade experience really difficult for indices that break this limit already. They would have to close their index before the upgrade, change the limit in the new version and open the index again. That's a bit too much I believe so to be safe we should check this setting only for indices created before it existed: ``` if (indexSettings.getIndexVersionCreated().onOrAfter(Version.V_7_0_0_alpha1)) ``` ... and only log a deprecation warning if the filter breaks the limit on an index that was created an a previous version (see DeprecationLogger and its usage to see how to do that). This way we could also backport this new setting in 6.x and makes the upgrade easier.
thanks for adding this
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
Ok, then it's fine.
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
Can we add an assertion that this is never negative? I don't think it ever will be, but just to be sure...
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
`limitedTo(long bytes)`? Clone is kinda non-specific.
good catch on delta > 0
Can you add the `oldMemSize` and new estimate to the assertion message? (In case it fails)
tests should avoid using `now` as it can hurt reproducibility
When you run tests, a seed is automatically chosen and returned in case of errors. This way, you can re-run the test with this particular seed so that these random vars get exactly the same values. This would not be the case if `now` is used.
Same here with line breaks. Usually I see this as `} else {` in our code.
Can we check that the hits information is correct in the response too? i.e. the hits are empty, the totalHits is correct and the maxScore is zero
`assertNoFailures` is more common in newer tests and much shorter.
yea I see that also bulk depends on BytesRef which is not great. If it's too much work we can do it as a follow-up.
I wonder if this should rather be made part of Request#multiSearch like we did for bulk. I see that it may be nice to have read and write methods close to each other, on the other hand the only place where we need to write this format is in our client.
what can be done here is that the regex can be compiled in the constructor: ``` java Pattern pattern = Pattern.compile("my_regex"); ``` Then in the `doGsub` method, you can do this: ``` java Matcher matcher = pattern.matcher("my_string"); matcher.replaceAll("replacement"); ```
can't we just call this feature `trim`? `trim` personally makes more sense to me.
can we move this to the new `writeDoubleArray` methods
Can't recovery -> Can't recover
Right, but the point is that the `InvokeHelper` is right at the top of the stack trace. I do not think we should be descending in case the top of the stack trace is from an assert failing elsewhere outside of Groovy.
Typo, finalzlie -> finalize
Someday we're really going to have to standardize on American "canceled" or British/Australian "cancelled"... :)
should we catch exceptions here to make sure we cancel everything we need
why did you change this to take a `TranslogGeneration` with the uuid instead of just the `long minGeneration`? It's not using that uuid anywhere here AFAICS.
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
> Sure but we can't use BaseTranslogReader:: getLastModifiedTime as the method throws a checked exception. Fair enough. No streams for us - we need to do it the old fashion way :D > Does Stream.concat(readers.stream(), Stream.of(current)) not include the writer? Yes. Current is a TranslogWriter.
To be clear - I think we want to know how the oldest file is, regardless of the generations. It will always be the oldest generation and the first in the reader list, but I don't think we want to rely on it. Part of the role of the stats is to validate things are correct.
there is no exception possibility here? I think this is overparanoia
I know it's not part of this change, but it bugs me (for a while now) that the indexing memory controller owns the buffer size for active indices but inactivity is controlled by the engine/shard. I wonder if we should move these settings to the memory controller.
I think we should return active.get() == false and also - set it if we became idle...
Can you move the getAndSet to its own if statement? It has a side effect and its mixed with stuff that doesn't and when I first read the code I didn't notice it.
I'm used to wrapping debug logging stuff in `if (logger.isDebugEnabled())` tests to prevent the message construction in the (very common) case that debug is disabled. Here it probably doesn't matter because message construction is dwarfed by the refresh call.
can we make this log include the decision about whether to refresh (and also the current IW memory consumption, while at it)
This can be `assertTrue(called.compareAndSet(false, true))` to avoid the race condition between the assert and the set.
We should log the the failure here if the close fails
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
OMG `== false`! ð±
This condition will never evaluate to `true` as we'll get an NPE when dereferencing a `null` instance of type `ExecutorHolder` in the line above.
you are right thanks a lot for catching this
There is a problem with this test setup that I just found: the xContentType that is used for parsing here is not necessarily the same as the one that is used int randomUpdateResponse(). So the expected values might be off, e.g. if in randomUpdateResponse() SMILE is used and here xContentType is Yaml.
++ I like that solution here
While I think a common methods would be great, I'm not sure this distinction (small vs. large longs) is needed very often. In the parsing tests its good to have some more "smaller" values to catch cases where they might be parsed back as int. I wonder how a common method would be called (randomNonNegativeLongButOftenSmall?), which range to sample the small values from (that might vary between tests) and where to put it. But maybe @tlrx has some suggestion.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
> And only print the message like "Source is too big - 5kb" +1 to that. Keep it simple
> talking below about using only the index, source, and id probably a typo, but just in case - index, type and id (not source)
I feel like we might get a working solution by adding something like `XContentHelper.convertToJsonFragment(source, maxFragmentSize);` that would construct a XContentBuilder by passing it a modified `BytesStreamOutput` that would through an exception when it reaches a certain size, then we can intercept this exception add "..." at the end and return it as a string.
we should be careful here and check for sources that are binary (SMILE etc..)
I don't think we need the exact number of bytes and if bytes is what we have we should use it. No reason to work hard to get characters.
I don't know what it looks like in query registration, but in all the other register methods we have, we put the "key" first. ie here the agg name should be first? I really don't understand why we are taking ParseField instead of String too...seems we will never get rid of camelCase alternative fields if we keep extending support for it.
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
this is usually a bad sign. We should use sleep anywhere. Sometimes it's needed but we try give all the utilities to make sure no one used it explicitly. In this case we have assert busy: ``` assertBusy(() -> { final ClusterState currState = internalCluster().clusterService(masterNode1).state(); assertTrue("index not deleted", currState.metaData().hasIndex("test") == false && currState.status() == ClusterState.ClusterStateStatus.APPLIED); }); ```
I would reduce this timeout to 0 - we don't care - we check with assertBusy later for execution. Make it fast. Also reduce the publishing timeout by setting PUBLISH_TIMEOUT_SETTING to 0.
I wonder if it's easier just to isolate some of the replicas among each other, i.e., take a subset of replicas and isolate them from the remaining replicas. This means that all replicas stay connected to the master.
maybe, to be more precise, it would be good to check the partition that included the new primary.
we have a new awaitNoMaster util method
I don't understand here what you mean by synthetic variable. If you mean the two ENulls, the analysis and writing would be contained to only compile-time.
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
I think here we can go with an ordinary `BytesReference` and use it's efficient iterator `BytesRefIterator iterator()` the returned `BytesRef` is just a pointer into the underlying `byte[]` that you can wrap in with `ByteBuffer#wrap` and do your accounting what is left for writing in this method. so there is no need to use a `NetworkBytesReference`
Elasticsearch tradition is to make this an EMPTY constant :)
This has issues as two calls could wind up finishing this listener. I think it would be better to use a AtomicBoolean and compareAndSet.
I'm not a big fan of ActionListener<Void>? Maybe we can do this differently and replace it with two functions? Runnable for the onResponse() part and for onFailure use a Consumer.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
Hm. Not sure about the custom similarity part. For you maybe :) The whole purpose of IndexLookup was to have an easy to use api for access to term stats. I found it very convenient. Whether or not we should have IndexLookup is a different discussion because it can be used in other contexts too.
I don't think we should even have IndexLookup. It is no more work to write and use a custom similarity than to write and use a native script, and the point of similarity is for customizing exactly this.
I opened an issue for better visibility of this discussion: https://github.com/elastic/elasticsearch/issues/19359
I don't think we should be promoting using this feature of scripting. If someone wants this level of control over scores, they should implement their own Similarity; that is its purpose.
Might be nice to add a check for existence of these parameters for completeness.
please wrap in {}
please wrap with `{}`
you have 140 chars use them :)
maybe move the loop in a method then we can return early and don't need a label / boolean var in the outer loop
missing { } :)
It is probably better to use nanoTime here so you don't get clock skew giving you weird numbers. Not like it matters a whole lot here though.
I hope we never have to implement this for minor or patch versions of the JVM :X
These should all be wrapped in `<pre>` or `{@code ...}`
Also we should wrap the `-` in `{@code -}`
I think this should have a `continue;` after it for the sake of completeness, otherwise it's possible that it will be added to both the valid and invalid lists (it'll still fail the parsing, but to prevent future bugs)
Knowing the supported time formats would be helpful for the user. (this goes for all the time fields in this object)
Same here about parsing end ranges that are out of the integer range
I think this can be done easier with an Iterator ```java final StringBuilder spaceDelimitedJvmOptionsBuilder = new StringBuilder(); Iterator<String> it = jvmOptions.iterator(); while (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(it.next()); if (it.hasNext()) { spaceDelimitedJvmOptionsBuilder.append(" "); } } return spaceDelimitedJvmOptionsBuilder.toString(); ```
ok, i see it. Its just a little non-obvious due to the way searchers are bubbled up. maybe we can add an assert in the future.
pageParams is missing from the equality check
My preference would go to adding a serialization context to readFrom.
I understand this, but this sound confusing to me. You would have some member in each builder that is only set for the prototypes, need special constructors for the injection. I understand your proposed solution with the static method access much better.
well then you have to have a dedicated parser interface - I wonder if this is a general thing we should have on stream input though
I think saying that it should not be allowed in the query DSL is a bit misleading, cause it is allowed and we parse it properly. I know what you mean though and why you wrote that, I need yet to come up with a better explanation for this...
maybe call this readDiffAndApply? this doesn't really read a diff and return it.
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
Can this be "metadata"? We don't hyphenate anywhere else in the code.
Same here, maybe "index-metadata"
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
This does not necessarily need to be within a static initialization block.
This includes both of the fixes but to make the change uncontorversial it should just include the `finally` part, not the checking if the file exists part. Personally I think removing the file up front is the right thing to do but I'd like to separate that out into a separate PR because I expect other folks to object to that way of doing it (see the linked issue) and I'd like to get the `finally` block portion of this fix in.
Let's move this to a `finally` block.
And anyway, moving it to a `finally` block does help because if the create fails because the file already exists, the delete in the `finally` block will clean it up so we only fail in this way once.
I'd prefer to delete the temp file first as well but it looks like to be consistent with #19036 we should do the delete in a finally block. That way if the file exists we'll nuke it in the finally block as we abort startup. I guess this has the advantage of failing once for the user so they know it is a problem.... I'm not sold on it. The bottom line is that what we have now is wrong and if you move the delete to a `finally` block I can merge this without further debate. We can then open an issue or another PR to discuss deleting the file first. That way we have _a_ fix in and we can more leisurely decide what the right solution is.
I don't think that a security exception should be re-thrown as an `IOException`.
this always yields true
I know that this code did not change in this PR but couldn't we just expose an endpoint setting and have the user set it instead of deriving it ourselves? This would also save us some maintenance effort.
I think we should only log.warn here. I can imagine that at some point AWS may support this in China and I would not block users for this. May be we should not control that at all and let the user specify whatever he wants. I mean that if this plugin is used with other S3 compatible platform, we can't do those checks.
`} catch (IllegalArgumentException e) {`
I think we can now remove this condition as the client can not be null because we throw now `new ElasticsearchException("Unable to configure Azure compute service", e);` in the CTOR
Sure. This one is more than good enough :)
I think `requiresIndexMappingRefresh` is very misleading - it should be called `updateMapping` as it does update the mapping (and returns a boolean for refreshes)
applyDeleteIndices -> deleteIndices
future note - once refresh mapping is gone, we should inline this with index creation.
in the case of createIndices, this should send shard failed for the shard routing that triggered the index creation, but it doesn't because the indexService is empty. I think the interaction with shard failures is too brittle/tricky. My suggestion would be to just return an exception on failure and let the caller deal with it in the right way. PS - maybe this signals a testing gap as well..
@javanna is that something we decided? new APIs have real getters/setters? I thin it'll create such inconsistency across the codebase. Right now it's kinda clear - user facing API use real getters/setters, internal don't.... but maybe a decision was made around it and I didn't notice
+1 on removing it
Might be nice to add a check for existence of these parameters for completeness.
can we use "script_factor" I think it's nicer than the came case
I'm wondering why you decided to override this optional API. Is this impl expected to be faster than pulling the iterator and calling next in a loop? (this is what the default impl does)
ok I remember now. The point of IndicesRequest and CompositeIndicesRequest is to return the indices that a request works against. when a request is composed of multiple operations, it should implement CompositeIndicesRequest. In this case delete by query reads from some indices as part of search, and writes as part of deletes. But what indices would it delete from? It is not possible to create a DeleteRequest that points to multiple indices, yet it is hard to predict all the deletions that will be performed as part of the request execution. I doubt that this request should implement CompositeIndicesRequest then.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
do we need == true ? :)
And it looks like you cover the response below. So you can ignore this.
I wonder if it'd be nice to have the assertion in the docs with a note about how this is the response. And maybe a note that you don't have to assert anything if you don't care whether or not it was created up updated because non-200s throw exceptions.
I believe this text is out of date now that we have a macro.
yes please I haven't seen them used before in our codebase. At some point we will automate formatting and these classes will have to somehow be ignored I think.
Change this to `// tag:example[]`
yea sorry....... should have been "seems harmless". Yet we may want to change what we do here and whether we need logging or not. And not sneak it in among all these other changes.
Those two code snippets are very similar.. I think we should go more generic here, maybe you can add a static `XContentHelper.toString(ToXContent foo)` which acts like in the `SearchSourceBuilder` and does not throw an exception, but returns an error JSON ``` java @Override public String toString() { try { XContentBuilder builder = XContentFactory.contentBuilder(XContentType.JSON).prettyPrint(); toXContent(builder, ToXContent.EMPTY_PARAMS); return builder.string(); } catch (Exception e) { return "{ \"error\" : \"" + e.getMessage() + "\"}"; } } ``` There should be another `XContentHelper.toString(ToXContent foo, boolean wrapInObject)` method which adds the needed `builder.startObject()` and `builder.endObject` calls, if specified. With this change, both of this calls, would basically be one-liners. Hope it makes sense...
The precision stuff here looks messy to me. I think an alternative would be to pass the type into the constructor of the builder and make the type `final`. Then change the PARSER to be a `ConstructingObjectParser` so we can still parse the type but have the constructor use the result. Lastly we can then have the parsing of the precision work directly because it will always know the type by the time its called.
remove this additional line break? :)
I think it'd be useful to see the filenames in the exception message.
doc level failure (normal failures are OK from an algorithmic perspective).
yeah nevermind I was confused about some internal classes
fillResponse can throw an already closed exception. We should make sure we deal with exceptions here correctly
Maybe warp the listener using ActionListener#wrap which does the write things and will simplify the code here too.
operation can be `final`
so this means we don't support `topLeft` anymore? I think we have to to be honest. Also we have to support `northWest`
I think we should change this so we output a `validation_method` field which can have the values `ignore_malformed`, `coerce` and `strict`. Then the parser should parse this as well as parsing the deprecated `coerce` and `ignore_malformed` boolean fields
can we make those two constructors call the 3rd one so that we can centralize validation (if we ever add some)
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
Hmm, doc says `The order defaults to desc when sorting on the _score, and defaults to asc when sorting on anything else.`, so maybe having the default in the enum is missleading.
Same here, you'll need to deserialize differently depending on StreamOutput#getVersion
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
Same here about multi-line toString methods
This is confusing is what this is.
sorry, my bad.
Maybe let's just call Objects.equal(script, other.script) for simplicity? I know you did not introduce it though...
Please fix identation.
Since this is only going to be used in tests, I think we can get away with: ```suggestion return Objects.hash(maxSeqNo, localCheckpoint, globalCheckpoint); ```
I still wonder if for this simple case we should just to return boost != other.boost , doesn't make sense to call `Objects.equals` to me.
One option might be for this class to hold the already serialised form of the exception, but I'm not sure if that is better or worse than the current solution
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I mean random number of replicas with random combination of non-active states
I think we can check also randomly on a shard that relocates _to_ the local node
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
this can be removed now
Earlier in the SecurityLifeCycleService the cluster changed event was handled in order - first, to handle the event in SecurityIndexManager later it would start the index audit trail. Is there any order defined which does not change the behavior of handling cluster event? Not sure if this would be of any concern.
The migration process will only move datafeeds from cluster state to index when the entire cluster has been upgraded to whatever version this goes into (6.6 or 6.7). So if we can find the minimum node version in the cluster in `toXContent()` then we can write the extra fields into the X-Content representation only after the entire cluster has been upgraded. That will make full cluster restarts work in the case where the entire cluster is on 6.6/6.7 (and it is essential this works because some people will run 6.7 for a year after 7.0 is released). So if `job_id` is `null` after a full cluster restart then that implies the cluster was not completely upgraded to 6.6/6.7, and hence the migration will not have started, and hence the information can be obtained from the `MlMetadata` in cluster state.
Please revert this change.
yes. This is too low level - I think we will fix it at the higher levels. I dont' think deleteIndexDirectoryUnderLock should be lenient
Yeah, let's the keep the tests just focused on whether or not `MinMasterNodeCheck` does the right thing based on whether or not `discovery.zen.minimum_master_nodes` is set and we can think about broader tests for the default checks from `BootstrapCheck` itself in a separate pull request.
I'm not sure if the cast is worth it here. It is usually simpler to just work in integers even if we know if can't be more than 255.
It looks like you have proper ram usage stuff. Maybe it'd be simpler to refuse to expand the tree if it'd put the `bytesAllocated` above a certain size.
I think this might be important to have up front but I'm paranoid about filling up memory because I've been paged too many times for things like this. Some kind of numeric limit is good enough for me though. Like "only 10,000 `ByteSequenceLeafNode`s are allowed in the entire tree". Or something.
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
I'm fine with the answer being "no, you are crazy Nik" or "not right now".
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
You can use `assertAcked()`
Can you use more explicit name? (Also for getRepositoriesResponse1/2).
I don't think we need to check the implementation class, instance should be enough.
I wonder if this will cause problems down the road, the fact that toXContent doesn't output a valid json object per se.
if you save the xContentType randomly chosen above you don't need to guess what it is from the bytes here. we use auto-detection in so many places without knowing, we should not do that.
Supporting multiple versions is hard, in order to support that we should have versioning support in our fromXContent methods, knowing which version we got the message from, like we do for serialization. I would note down this problem and not address it now.
I think that inserting random fields here would reveal problems on the parsing side with the current code.
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
`this` is unnecessary
Nit: `}` is in a funny place.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
oh damned it's BWC I guess...
I personally think those queries should be build using query builders but we can do that in a second step.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
why a single data node? If you need that, you can use `numDataNodes=1` instead
is index name and type something we really need to randomize in this test? i think we shoudl just test date backcompat here and leave problems with index and type names to other tests...
This change would only break `wildcard` query on these fields, right ? +1 to make them string fields, `prefix` and `regex` query do not work currently because of this so it would be a bug fix. I am also ok to do that in a follow up, the changes in this pr have a different scope.
The `keyword` field applies the normalizer on `termQuery`. Depending on the normalizer the wildcard and escaped characters could be removed/replaced so I wonder if we should apply the same logic than `QueryParserBase#analyzeWildcard` for `keyword` fields. This is out of scope for this pr but it made me realize that we might have a bug here.
maybe one day we will a base class for runtime mapper field types that does this in one place.
Should this be `rewrite` field instead of `fieldName` (mentioned twice)
I think the following if is not valid anymore in fromXContent: ``` MatchQuery.Type type = MatchQuery.Type.BOOLEAN; if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_FIELD)) { type = MatchQuery.Type.PHRASE; } else if (parseContext.parseFieldMatcher().match(parser.currentName(), MATCH_PHRASE_PREFIX_FIELD)) { type = MatchQuery.Type.PHRASE_PREFIX; } ```
confuses the shit out of me everytime :)
"new" -> "now"
can you just use `Iterables#concat(uncommittedTranslogs, Collections.singletonList(current))`
Needs to be protected by `logger.isTraceEnabled()` now that `translogId()` locks the readlock, either that, or grab it into a temporary variable before the logging and return statements.
Typo, "Trasnlog" -> "Translog"
Again, this doesn't seem to actually use the `entry.getValue()`.
this deserves a sep issue I guess but good catch
Nit: spacing between `!` and `value`.
I suggested renaming `files` to `newFiles` above so that this fails if someone changes the name of the local var (right now it would just be silently bad)
can't we just call this feature `trim`? `trim` personally makes more sense to me.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
Given the method's name I expected it to check the values too.
I think we don't need to make the global SuggestBuilder implement NamedWritable, simply Writable should be enough. This is the only implementation (and will likely stay so) so we don't need to differentiate it from others on the stream.
My understanding was sort of the opposite: use it in places where it doesn't not make sense. Whenever you don't care, use it. At least, that is what seemed right to me. This is fine though.
The 2 `if-else` conditions can then also be simplified to just: ``` if (lowestVersionSeen == null ||Â replicaNodeVersion.before(lowestVersionSeen)) { lowestVersionSeen = replicaNodeVersion; candidate = shardRouting; } ```
I think that the activeReplica method could also be expressed very concisely using Java 8 streams :-)
make sure you fix the codestyle here
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
I think the regexp should be an object here. We should be consistent with what we did in term query and similar. The value is an object and can either be a number, string or BytesRef. We use internally bytesref for string when parsing through the parser, but java api users can set string and we take care of the conversion.
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
I think we have at least one similar test that does the same, we can maybe share the dummy client to minimize the code repetition. It's not that we cannot use mockito, we could, we would need to have a bigger discussion around it, some people are in favour of that and some others are totally against it. I personally don't think mockito would solve all our problems, we should strive to make elasticsearch more unit testable, easier to say that to do though :)
Writeable does that too but allows to have final fields and drop empty constructors
can you throw an exception in the else clause, eg. "All queries must extend AbstractQueryBuilder but ..."
It looks like this could fit in 140 columns.
if so, I think we should have a signature like: `public ScoreDoc[] getLastEmittedDocPerShard(ScoreDocs[] sortedShardList, int numShards, int offset, int length) {` it's more flexible I think
I think it would be better to use a [`vInt`](http://lucene.apache.org/core/4_7_0/core/org/apache/lucene/store/DataOutput.html#writeVInt%28int%29) to save space. Up to a length of 127, a vInt would require one single byte while an int always requires 4 of them. You can use a ByteArrayDataOutput in order to make it easier to fill the byte[]. In order to compute the size of the array to write into, you can just assume worst-case, which is 5 bytes for a vInt.
I was wondering wherer the bucketsPaths passed get used here, but they might only be necessary in other impls of PipelineAggregatorFactory I guess. I also found the order in which the super class reads something from the stream, then calls this method to create the actual implementation and then reads some more a bit hard to follow and a bit tricky. Maybe there are ways of simplifying this, but unfortunaltely I don't have a good suggestion at this point. Maybe the whole readFrom/doReadFrom separation in the abstract class and the implementations could be merged, which would mean some duplication in code but would be easier to understand and maintain? Just a suggestion though.
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
Yeah, I think the problem with the test here is that we don't make sure that nothing is left in the stream after we read it. That's why we didn't catch it here.
We will need stronger assertions here too.
Do we really need this randomization? seems like the wrong place to test the version created setting is working properly.
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
would be nice to allow to configure it to a percentage of the heap size
You can use expectThrows()
You are throwing away the stack trace here. Just have this method throw Exception, and the tests that call it as well.
I think we can simplify here and print everything out, default values included, that's what we went for in all of the other queries too.
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
Is there a reason these three fields need to be test instance members be randomized in the init() method? Otherwise I would prfer making them local in createTestIntstance().
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
Won't the `indexName` be wrong below, since it is just `_parent`? Maybe we should just have a special case here for `_parent` for now? Something like: ``` String indexName = fieldMapper.fieldType.names().indexName(); FieldDataType fieldDataType = fieldMapper.fieldType().fieldDataType(); if (fieldMapper instanceOf ParentFieldMapper) { ParentFieldMapper parentMapper = (ParentFieldMapper)fieldMapper; indexName = parentMapper.getJoinFieldType().names().indexName(); fieldDataType = parentMapper.getJoinFieldType().fieldDataType(); } ```
I dont' think this is possible? `getFields()` never returns null
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
Not related to this change but we could write this: ``` java log("Installed plugins in " + environment.pluginsFile().toAbsolutePath() + ":"); if (plugins == null || plugins.length == 0) { log(" - No plugin detected"); } else { ``` It could help people to have a better understanding on plugins location. (IIRC I saw this request on the mailing list).
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
ok I would always pass down true then otherwise it feels like we should do something with it. Consumer<Void> would be better in that sense but then you need to provide null which is even worse to see...
Correct me if I am wrong but these filters have to be executed in a serial fashion one after another, right? So you can make this async if you need to on top of the blocking loop? I would like to see an example where this is used to understand the rational please :)
given that we also filter responses by creating a new response filter chain and filtered action listener, this inner class is not just a request filter chain... can we maybe merge the two at this point? Seems like in the end we either filters nothing or both (request and response) anyway...
Why do we need a good github search when we have @clintongormley :)
I think we should throw an exception if `mapper.nested() != Nested.NO`, as this would not make sense (and I'm pretty sure some users have dynamic templates to make all their objects nested by default).
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
+1 to have `fromXContent` and `parse` be static
hey guys I did some work a while ago on the delete index api acknowledgement in #4218 which is the only api left that doesn't use the "standard" acknowledgement code. That said we decided at that time not to migrate it to keep two different actions: one for deletion from cluster state, one for deletion from store. Not sure I follow these PR's changes when it comes to how they affect acknowledgements, but If we want to make the two a single action, can't we just use the standard acknowledgement code and drop the custom actions? I think it would simplify the code quite a bit.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
here we would validate that each node made two switches - one to remove the old master and one to accept the new.
This constructor doesn't seem to be necessary.
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
Should be `this.detectors = Collections.unmodifiableList(detectors)`. (This is probably a bug in X-Pack core too.)
It would be worth requiring that `jobId` and `jobType` are not `null`.
We probably shouldn't allow `detectors` to be `null` as other code makes the assumption it's not set. Probably on the server side the `build()` method will check this, but on the client side we might as well `requireNonNull()` here.
I think an exception other than an `AssertionError` will stop the busy loop. So if an `IOException` can be thrown that _shouldn't_ terminate the busy loop then it needs to be caught here. But maybe there isn't.
create does an inline reroute, so you can check directly here that no shard is assigned. No need for timeouts
Nit: `reject` -> `rejected`
nit: `an` -> `a`
this should be part of the tests for the replication phase - with random cluster state and all..
what are testing here? sounds like primaryPhaseExecutesRequest
I think we want to test index level blocks too here
well if you put in into an `assert` it's not called in production that is the purpose of `assertions`? I think we should call it at the bottom of the constructor and maybe in `iterator()` as well as `shards()`
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
a general remark. I'd like to have a method like: `private boolean assertShardStats()` that calculates all the statistics from the shards we have to make sure they are identical. We can then just use this method in statements like `assert assertShardStats()` to make sure the tests fail if we miss something!
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
same here. ElasticsearchAssertions.assertThrows wil help
Did you confirm we sometimes hit this and not just ACE? (The "indexed" CountDownLatch should make it likely...)
++. Maybe also add a sanity check that a get on the doc at the end gives us what we expect? (deleted or found)
Missing `assertAcked()` or call to .get()
I was confused because `request.index()` does not exist here. There is `getCurrentItem().index()` though.
I wonder if we can add this (and similar ones) as invariant to the class (similar as was done for ReplicationTracker) we then call `assert invariant()` on each of these methods. For example, one invariant might state that if we are in TRANSLATED state, the executionResult is null.
instead of ruling out the states which don't allow this to be called, I think it's easier to understand if we put the states where we allow this to be called.
I think this should just be `assert currentItemState == INITIAL`
this whole method can be abbreviated to ``` return new BulkShardResponse(request.shardId(), Arrays.stream(request.items()).map(BulkItemRequest::getPrimaryResponse).toArray(BulkItemResponse[]::new)); ```
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
I still wonder if for this simple case we should just to return boost != other.boost , doesn't make sense to call `Objects.equals` to me.
It feels wrong that hashCode is using writtenBy while equals isn't
use `Objects.equals` for all once changed to potentially null references.
I guess we just prefer primitive types over objects :)
What about just converting to bytes and comparing? The way you have it now this isn't consistent with `equals`.... Also the _cat API we call `toString` which doesn't really use the unit anyway.
Yeah, looking at it again, that makes sense!
similarly, equals uses the hash while hashCode doesn't
It feels wrong that hashCode is using writtenBy while equals isn't
Correct [equals](http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#equals%28java.lang.Object%29) implementation supposed to be reflexive. In other words the following test should pass: ``` StoreFileMetaData test = new StoreFileMetaData("test", 0, null, null); assertEquals(test, test); ``` Maybe `equals` is not a good substitution for `isSame` here.
this can be out of if now.
nit: can we have this ugliness in a getClusterService(Node node) method? we use it in `doStart` as well.
I'm thinking of the case that the previous cluster is the same as current (and thus has a master) and I basically the same question here - do we have a case where the cluster state has a master but also the no master block? if not, maybe we should an assertion to that matter as an else clause of `if (newClusterState.nodes().isLocalNodeElectedMaster() && previousClusterState != newClusterState)`
I don't think you need an if else structure here? you can set the first and iterate over the rest? This can be simplified
that awfully sounds like two voices for debug.... your turn, @jasontedor.
minor nit: "int he" -> "in the"
occurred with 2 Rs :)
++ on debug message
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
same here - I think it's better to log the info message if the deletion was successful.
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
Left over Note
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
You can use `assertAcked()`
Can you use more explicit name? (Also for getRepositoriesResponse1/2).
I don't think we need to check the implementation class, instance should be enough.
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
after rebase you will have to get rid of any wildcard import, or the build fails :)
There is now a base class `RestActionTestCase` that helps remove some of the test boilerplate.
argh, I forgot UnicastZenPing doesn't support local addresses by default. Sorry for the noise.. (we should fix this at one point)
When it gets long like this can you indent it like ``` assertResult(() -> builder() .startObject() .startObject("foo") .startObject("bar") .endObject() .endObject() .endObject(), ``` I know we `assertThat` has the matcher second, but maybe we should put the closure second for this? I think it is nice when the closure is second because it makes the code formatting prettier.
Nit: could this move back down to where it was before, since it's not being changed? Would make the diff smaller.
Right - RollupIT is the right place
you could use `scriptRequest.setJsonEntity`
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
maybe put the actual and expected length in the message
can we introduce a method similar to mayHaveBeenIndexedBefore that does the check and also updates the `maxSeqNoOfNonAppendOnlyOperations`? I think it's good to have both marker handling consistent.
random drive by question - why is the primary term part of the index result? it's already part of index and index result is supposed to capture the dynamic things that the engine has assigned.
I see. The seqNo and the term do not necessarily always go together. the seqNo is the location of the operation and the term is the authority to put it there. I like the fact that the result object only contains the things that the internal engine creates / changes. Seq# are owned by the engine (on a primary). Terms are owned by the shard. I would prefer to remove the term. At least in the example you gave (`Translog.Index#Index(Index, IndexResult`) it's readily available from the index operation.
those are hard to debug I can tell u :dancers:
braces please. for the rest of the method too. (I realize you just tweaked this to be a lambda but it would be good to fix this as two line single statement `if`s are dangerous and evil).
nit: space after IOException
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
we need to add that we return false if no folder was found for this shard.
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
Do we need this? the settings are already immutable
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
I prefer to encapsulate this in a class instead of floating magic values around (-1 and -2) making it hard to ensure they are properly used everywhere.
@clintongormley mentioned that NONE doesn't have many external usages (we only use it for index auto creation) so we might want to drop the special naming and use `0`. I will keep the object reuse in parsing.
and.. looking at the parsing logic this is indeed internal and we don't accept none from strings. Sorry for the noise.
we "special case" NONE here but not ONE, maybe it's simpler just to remove this method as well as the `validateValue` one and use `new ActiveShardCount(...)` in the two places it's currently used (and also ad ``` if (value < -2) { throw new IllegalArgumentException(...) } ``` to the constructor.
I you decide to go this route you should also remember to replace the reference equality checks (`this == ActiveShardCount.NONE`) by equals checks or by looking at value (`this.value == 0`).
Just a note when back porting this piece of code needs to be changed. I think we should use java8 where possible and in this case back porting is trivial and the isolated. Only in cases where the back port change wouldn't isolated and difficult we should hold back on java8 usage.
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
why do we have this API bloat with all the Builders? Can't we simply use a constructor? All the factories etc are not really needed IMO
I prefer `assertEquals` in cases like this. `assertThat` is great if you need to take a matcher or want to assert something complicated, but I like `assertEquals` for equality.
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
didn't we say that we are going to use constants from QueryParsers? maybe I am missing something though
ah ok I see
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
it makes sense to make them public then I think
I think we have constants for this now: https://github.com/elastic/elasticsearch/blob/8238f497d85d785a61ebc017b8ac96fc5fcd28ae/core/src/main/java/org/elasticsearch/index/query/support/QueryParsers.java#L32
one too many new line? :)
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
I see, and you are right, camel case is preferred. I probably misread the "NoNestedDocs" part of the name as "no nested docs" and that confused me for a second, but either way is fine.
just as feedback, nothing to change really, but I liked the previous variable name better ;-)
Not important, but couldn't this just be an array? String[] possiblePathValues = {"some_path", "anotherPath", null};
make `Boolean` and only serialize when not null. Also remove setting the default. The idea here is that by doing so we inherit the defaults of the backend without having to duplicate them in the client.
make `Boolean` and only serialize when not null
nit: "an started" -> "a started"
extra space makes everything not line up!
use `Objects.equals` for all once changed to potentially null references.
maybe add propNode to the error message so that it is easier to understand what the issue is if a user ever complains of getting this message
Recently we've been doing something more like this: ``` clearIndicesCacheRequest.queryCache(request.paramAsBoolean("query", clearIndicesCacheRequest.queryCache())); clearIndicesCacheRequest.requestCache(request.paramAsBoolean("request", clearIndicesCacheRequest.requestCache())); ... ``` Rather than the loop. The whole loop thing is more appropriate for by-hand xcontent parsing then url parsing.
I feel like `pattern bank` is an internal naming convention, and externally we just call it `patterns`. not sure it matters here though, since one can only assume we are talking about the same thing.
I'm a bit torn on this. I like the similarity to the other Aggregations and this does also leave it open for pipeline aggregators to have multiple result readers if they need to, but on the other hand at the moment it's not currently needed. I'd say I'm slightly leaning towards keeping it like this but I am happy with either way so coders choice. ð
I don't think we either but I know some folks like them so I certainly don't object to them.
Note that ParseField does the camel casing for you and the 2nd/3rd... args to its constructor are actually deprecated names so that in future we can run in "strict" mode and flag any client uses of deprecated APIs
this class is also missing a hashCode impl.
you must drop this equals method unless you have a corresponding hashCode impl Yet since this is a singleton you can just drop it.
Ah ok, I missing that method below, sorry.
This should be a `ConstructingObjectParser` so that the private empty ctr can be removed.
I had a look and the settings code has been dramatically improved with 5.0 already, hence this fix is not required any longer. Nothing to do then, but thanks again for pointing this out.
Duplicating the string is fine, the maintenance here is low as this string is not going to be changing, and the lack of indirection keeps it simple.
1. There is a minor typo/grammatical mishap here - text should read "[cluster.name] must not _contain_ ':' character" 2. Id consider putting this exception text into a final static variable somewhere it would make sense to put it. This text is currently used in two places in the code - once here, and once in a unit test - and the way things are now, if you want to change the contents of this text, you need to change two strings in two different places in the code. If you had this text in a final String variable, and you referenced that variable here and in the test, you would only ever need to change the string in one place.
master_election.filter_data [{}] is a leftover I think
`limitedTo(long bytes)`? Clone is kinda non-specific.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
something is wrong in this sentence :)
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
This seems very error prone, since it relies on CPU scheduling, network latency, or even whether the test is using mocked networking...
This should be `== false` right? otherwise we will warn if the latch _found_ a state
What is the reason for not just using the timeout on the observer? ``` diff diff --git a/core/src/main/java/org/elasticsearch/node/Node.java b/core/src/main/java/org/elasticsearch/node/Node.java index c8eb8a4..29a11d9 100644 --- a/core/src/main/java/org/elasticsearch/node/Node.java +++ b/core/src/main/java/org/elasticsearch/node/Node.java @@ -336,14 +336,12 @@ public class Node implements Closeable { @Override public void onTimeout(TimeValue timeout) { - assert false; + logger.warn("timed out while waiting for initial discovery state - timeout: {}", timeout); + latch.countDown(); } - // use null timeout as we use timeout on the latchwait - }, MasterNodeChangePredicate.INSTANCE, null); + }, MasterNodeChangePredicate.INSTANCE, DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings)); try { - if (latch.await(DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings).millis(), TimeUnit.MILLISECONDS) == false) { - logger.warn("timed out while waiting for initial discovery state - timeout: {}", DiscoverySettings.INITIAL_STATE_TIMEOUT_SETTING.get(settings)); - } + latch.await(); } catch (InterruptedException e) { throw new ElasticsearchTimeoutException("Interrupted while waiting for initial discovery state"); } ```
The message doesn't really make sense because it's missing the "discovery state" part, right now it says it timed out waiting for initial timeout :)
@s1monw if you're proposing we use inheritance and you assume the base class will always be caching DF then we could just remove all the "if(this.docFreq)" checks in the existing code as a simple way to clean things up? That would leave us with just the "if(this.totalTermFreq)" checks.
I think we should have a baseclass that only handles DocFreq and then subclass it if we need TTF that should remove a lot of branches here though. I don't like the long methods that basically repeat code because of the TTF / DF swtiches. I mean it makes sense do split it since they have a higher cost if TTF is needed though.
I guess that's ok...
+1 there is a good example in BlendedTermsQuery though
Different leaves might use different codecs, and some of them might support `totalTermFreq` while other leaves might not. So this should return `-1` if any of the leaves returned `-1`.
I'd probably add an `else` clause that sets `splitOnWhitespace` to the appropriate value just to be super clear.
We handle this by temporarily disabling bwc tests. I just pushed the disabling to your branch. Tomorrow I will test the bwc behavior locally before pushing.
Yes, 7.2 was branched, but the 7.3 constant hasn't been pushed yet. I will update this branch today once the constant exists.
Sorry I mispoke. 7.2.0 is good.
This should be fatal.
as far as I can see there are now two reasons why we need more rounds: 1) concurrent modifications to the blacklist (like before this change) 2) the selector rejects all hosts (introduced with this change) . Instead of trying max 10 times, can we figure out whether the reason for having no hosts is either the former or the latter and act based on that? In the first case we can just retry (indefinitely) while in the second case I am not sure. Do we fail the request or do we try a node that the selector doesn't want us to go to? Probably the former but just double checking.
maybe it would be nice to also print out how many nodes were provided as well (I know such info is not part of this class but it could help figuring out why we can't send the request)
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
something is wrong in this sentence :)
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
s/can't used/can't be used/;s/their/they/;s/subtile/subtle/
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
Do we need this? the settings are already immutable
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
please don't load stuff lazily. go and load it all in the ctor. they are in memory anyways.
maybe use `shouldCompress` here to make it a little clearer? ```java if (shouldCompress) { IOUtils.closeWhileHandlingException(stream, bytesStreamOutput); } else { assert stream == bytesStreamOutput : "the stream variable is not the same instance as bytesStreamOutput"; IOUtils.closeWhileHandlingException(stream); } ```
maybe just call this `public BytesReference materializeAndClose() throws IOException` and don't even return the stream.
I wonder if it'd actually be clearer *not* to have `shouldCompress` and instead check for reference equality here.
cool thanks for the explanation!
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
You can use `prepareCreate("my-index")` instead of `client().admin().indices().prepareCreate("my-index")`
if you use here `refresh();` from the base class we also make sure we get back no failures.
one too many new line? :)
This line is too long, it is causing checkstyle to fail. We have a line limit of 140 characters that we started enforcing a few months ago but only on files that didn't have any violations. We're super super slowly fixing the violations as we go. I'll fix this before I merge.
Can you call `assertSearchResponse` on the DSL and API responses? If there are different hits, this will help make sure this is not because of failed shards.
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
we decrease the ref count multiple times if we call close more than once - I think we must protect from this though
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
Hurray no more weird `while (true)` loop
`assertNoFailures` is more common in newer tests and much shorter.
I like `hasSize` better for this because it gives a nicer error message on failure.
I like `hasSize(1)` for this kind of thing because it makes a nicer error message.
could we make this test somehow operations based rather than time based. The Problem with time-based tests is that you have a very very hard time to get anywhere near reproducability. I know this is multithreaded anyways so it won't really reproduces but we can nicely randomize the num ops per thread which make it a bit nicer :)
10000000L seems arbitrary, maybe `Long.MAX_VALUE` would better reflect what you are trying to achieve here? Or maybe we can make `-1` to work as `unlimited` or check for `unlimited` string constant.
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
Ahh okay, that makes sense, I missed that
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
if we use double futures (one that you have already and another to pass back the results) we won't have to busy wait here.
I think that these log parameters are backwards.
This is not the right condition, a plugin bin directory is not required to exist.
We can remove the period here, this is a sentence fragment (as these usually are).
We can drop everything after and including the comma.
Let's remove the period from the end of these, they are typically not sentences.
This should be `pluginName`.
I don't see this change implemented here.
this needs to stay because the method can be called from any other class, it's a public static method....thus validate might not be called at all before calling this method.
we shouldn't need this here in parse phase
nevermind, I guess it depends on how you look at it. at the end of the day this parse method does parse + toQuery, having QueryShardContext is fine given that it will still happen on the shard. Also given that the QueryParseContext is much more lightweight, it makes more sense if done this way. Plus the parse method will go away, so leave it as-is.
I think conceptually this should be QueryParseContext instead, if it needs to do more (toQuery) then we need to figure out how to create the QueryShardContext too out of it, but the other way around seems confusing to me. Sorry I see we are going back and forth on this.
you can reduce this code by using only the `nio` classes instead of moving forth and back between NIO and `File`, see `java.nio.files.Files` for things like moving `Path`
Yes, but replace `FileAlreadyExistsException` with `IOException` to maintain the same functionality. Sorry for saying it so confusingly before.
`FileAlreadyExistsException` is an `IOException` and this `IOException` block does the same thing as doing nothing -- `return CONTINUE;`.
I think the name of the method is misleading. Maybe call it purgeIndexDirectory? as it doesn't really delete it but rather removes all unlocked shards and if all succeeds removes the index folder as well
It looks like if `index` is null here, we will end up locking all shards for all indices, then hit an NPE, then release all the locks. Would it be better to bail early if `index` is null without trying to acquire locks? It seems a little strange here since a null `Index` is used in some of the other methods to indicate "all indices".
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
I mean random number of replicas with random combination of non-active states
I think we can check also randomly on a shard that relocates _to_ the local node
Dude! Linebreaks! Strive for 80 columns! (or at least 100 or 120) :D
could use 1. `UnassignedInfo.INDEX_DELAYED_NODE_LEFT_TIMEOUT_SETTING.getKey()` 2. `IndexMetaData.INDEX_NUMBER_OF_SHARDS.getKey()` 3. `IndexMetaData.INDEX_NUMBER_OF_REPLICAS.getKey()`
again, this is the reasoning: if we check for existence of a field in the parser, it means that the only way it can be null in the builder is when it comes in through java api. In that case we might want to fail fast and throw error in the constructor/setter already rather than in validate. If non validated values might come in through the parser as well then validate is the way to go. In this case it makes to do as Christoph suggested. In term query builder I think it still makes sense what we do (again, you can test it to see the differences), same for common terms query.
which other queries do you mean? You mean check against this specific field in similar queries or just in general. I think the question is "when can this happen?". If stuff can happen in both java api and rest layer, validate is the way to go. If we already perform some kind of validation that makes sense in the parser, then having null here can happen only from the java api and we should maybe try and fail straight-away.
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
Maybe you could put the validation removed from toCContent here. (point.size > 0)
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
I mean in the code but just noticed there was one already
we should have the same logic as DoubleFieldMapper#parseValue. Maybe have a NumberFieldMapper#parseDoubleValue, that the double field mapper can call as well.
I would call `indexedValueForSearch`.
BytesRef implements `Comparable`, so you should be able to do something like: ``` int comp = lowerTerm.compareTo(new BytesRef(type)); ```
Conversion to bytesref is done elsewhere with `indexedValueForSearch`. I'm unsure of the impact of rejecting anything but bytesrefs.
Just wondering if in the future we could use IndexShard as a point to synchronize recovery and replication. An IndexShard representing a primary could also precalculate the shards to replicate to. The code here would then just have to ask IndexShard where to replicate to.
Nit: there is an excess blank line here.
I think that all of these members variables except for `finalResponseListener` can be `private`.
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
Hurray no more weird `while (true)` loop
I think we should have a proper (top-level) class for this, supporting both min and max. min would be useful for `newSnapshotFromMinSeqNo` (see e.g. PrimaryReplicaResyncer, which still has to filter based on min = startingSeqNo, all of which could be accomplished through the Snapshot), and max would be useful for this one here (where it might also have a `min`). We might even make the interface of this `newSnapshot` method purely sequence-number-based, where you can specify the range of operations to recover instead of the translog generation. That last part is not something I would change right away, but maybe something to look into later.
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
Can you give each of them a numeric id instead? This will allow to rename the enum constants without breaking the bw compat of the stream
Nit: `}` is in a funny place.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
Also, we will need the oposite conversion from the ES enums (e.g. TermSuggestionBuilder.SuggestMode) to the Lucene enums (org.apache.lucene.search.spell.SuggestMode) used in the DirectSpellcheckerSettings later anyway, so rather than having `fromUnderlying` better turn the direction around to each enum knows how to produce the corresponding low-level enum.
nit: mergeSourceIndex -> resizeSourceIndex
Sorry, `MetaDataCreateIndexService` was a bad example. Still, the method `MapperService.merge` which does mapping validation is (AFAICS) not called by the `createIndex` method. This means that `verifyIndexMetadata` does not run the mapping checks in `MapperService.merge`. We check these however when we run `MetaDataIndexUpgradeService.checkMappingsCompatibility` which is called by `MetaDataIndexUpgradeService.upgradeIndexMetaData` when we start a node.
I could be wrong (not that familiar with the code in that area) but I think that in-memory data structures for mappings are not created by the `createIndex` method. These are merged later (see e.g. MetaDataCreateIndexService:325). We could check here as well that all is good on the mapping level.
should have been **cleaned up** by
`String.format(Locale.ROOT, "%s operation term [%d] is too old (current [%d])", shardId, term, primaryTerm)`
class could be `final`
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
although under the hood this ends up being efficient (the ArrayQueue copies it's array to another array which is used by the ArrayList<>) I think all these conversions between collection types making things unneededly complicated. I think we can use ArrayList<> explicitly in the builder and here. The only place where dequeue is potentially useful is in the purge method, but there we can use ArrayList.subList(), which is even more efficient (and it all becomes simpler, which is the important part)
you should pass fieldNames as an argument
snpashot -> snapshot
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
just a style question but this loop looks more like a `do/while` would be easier to read IMO
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
actually, if its a single page, then we can just reference the first page byte array, if not, then we should return false. same with `array` and `arrayOffset`.
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
we should get rid of the retry logic here entirely, there is no need for the while loop when we aren't retrying.
we need to support whatever extensions Settings supports and that includes json & java properties formats. I wouldn't worry about restricting it to these three (yml, json, properties) with regards to bwc.
with the current code a `logging.whatever.yaml` file would be loaded. I wonder if this is our intention or a side-effect of the current behaviour. Honestly I would be in favour of simplifying this further and even have something like `if (file.getFileName().toString().equals("logging.yaml") || file.getFileName().toString().equals("logging.yml") )` unless we want to extend this to json and properties files, which I think would be off-topic in this PR.
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
Nit: spacing between the `)` and `{`: `){` -> `) {`
maybe `== false` just so we don't typo it in the future
small typo, 'saving'
we have `TestThreadPool` that makes it simpler
use `ThreadPool#terminate` here otherwise you will get lingering threads etc.
Also, since "recover" and "restore" are very similar and easy to confuse, I think it'd be nice if this were named "`recoverState`"
Error if old-style params passed alongside new-style script
Ah yes, thanks!
I think s/lang/defaultLang/
Fine by me.
Maybe this one too, I'm not sure.
Hmm, we make a `private static final Logger logger` in `RemoveCorruptedShardDataCommand`, does that not work? Also, does this logger have the same configuration as loggers in Elasticsearch proper, i.e., it writes to the Elasticsearch log by default? If so, I think we should log more information about this tool having been run in that log.
We discussed and concluded there is no good way to do this, but also no real need to support higher node ordinals.
s/support multiple command/supports multiple commands
Please add a string message about the context registry being null
Shouldn't this be using `ElasticsearchTestCase.randomFrom` instead of `com.carrotsearch.ant.tasks.junit4.dependencies.com.carrotsearch.randomizedtesting.generators.RandomPicks.randomFrom`? I don't want it to end up not using the right seed
I don't think that this is the right place for this. Since #13086, we already do duplicate settings validation in the `XContentSettingsLoader` and the `PropertiesSettingsLoader`, and this kind of check should sit right along side those checks (rather than having these checks spread out). If we do add this check to `XContentSettingsLoader`, this pushes the check as far down as it can go, and enables us to fail as early as possible. As a bonanza, we can give an error message that includes the line number that the failure occurred on. This is as user-friendly as we can get here. I didn't realize that you had opened this pull request, but I already opened #17310 that does exactly this.
Instead of creating the setting here, it should be a static setting defined in the class, similar to the way settings are defined in https://github.com/elastic/elasticsearch/blob/master/core/src/main/java/org/elasticsearch/cluster/routing/allocation/DiskThresholdSettings.java#L37
This isn't needed, since `Files.createDirectories` will throw a `FileAlreadyExistsException` if a file already exists at that location and is not a directory.
We don't really use the `Settings.get` method now, it should instead be `TEST_SETTING.get(settings)`
Yes, but replace `FileAlreadyExistsException` with `IOException` to maintain the same functionality. Sorry for saying it so confusingly before.
I think this needs to call PathUtils.get (not Paths.get) so that it does not use the JVM default filesystem, in the case one is set differently in tests.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
Yes, but replace `FileAlreadyExistsException` with `IOException` to maintain the same functionality. Sorry for saying it so confusingly before.
`FileAlreadyExistsException` is an `IOException` and this `IOException` block does the same thing as doing nothing -- `return CONTINUE;`.
just use `IOUtils.closeWhileHandlingException(is)` instead of the 6 lines in the finally block
ah I mean't Throwable.... sorry
please reformat to: ``` java if (logger.isTraceEnabled()) { logger.trace("adding jvm plugin [{}]", plugin.v1()); } ```
I would debug log it, not warn, this is not always caused by user permission (getting null when listing files)
code style can you put the else on the same line as the `}`
it's fine to remove it
if the argument name is `failNoIndices` you should provide `! indicesOptions.allowNoIndices()` as argument
if the argument name is `failNoIndices` you should provide `! indicesOptions. ignoreUnavailable()` as argument
I see your point on changing the name, that makes sense cause allowNoIndices != indicesOptions.allowNoIndices
seems redundant indeed
FYI we don't throw version conflicts on replicas any more... (not related to your change)
You're missing "create" requests here (not sure if you want to support them, just wanted to make sure you knew)
instead of ruling out the states which don't allow this to be called, I think it's easier to understand if we put the states where we allow this to be called.
I think this should just be `assert currentItemState == INITIAL`
I was confused because `request.index()` does not exist here. There is `getCurrentItem().index()` though.
we should log the exception here.
we should probably bail here. One nit pick - I would prefer having this rejection logic closer to where it holds. I think there is only one method that can cause this.
Could initialize this with the size of the hits list to prevent resizing
Ahh okay, that makes sense, I missed that
do we need this trace log here and if so can we fix it to say `temporarily` or something like this
[{}] for path.
Why not wipe the entire source directories? I think it's good not to leave empty folders behind? we also leave lock files behind...
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
`Arrays.toString(paths)` already adds [] , no need to add them
missing { } :)
Can we just explicitly test these? Let's have a test that the field is removed, no error, in the old ones, and another test that tan exception is thrown for newer indices. Randomizing the version is fine, but let's keep it to randomize within the versions we expect to have a particular behavior, so that we keep full coverage of what we are testing on every test run.
did you mean `MapperParsingException`? ;-)
Instead, can we build what we expect given the exception? Isn't it just wrapping what we have into an ElasticsearchException with the same message? Or does it get too complicated? I think Tanguy did something similar in some other test.
It can be complicated to rebuild the object, how about doing something like: ``` assertEquals(parsed.getCause().getMessage(), "Elasticsearch exception [type=parse_exception, reason=" + originalMsg +"]"); ```
Can you test something that is not byte-aligned, like /15 or /17? We used to have bugs in those cases.
minor nit: "int he" -> "in the"
yea, I would at least debug log it..., it shouldn't happen
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
you can move this method (and the one below it) up to IndexShardTestCase (in test:framework). It could be useful for other people.
It's that, or we can replace replace FsRepository with this one, but we need to beef it up.
this is a personal preference, I like to avoid overriding the setup and teardown methods of estestcase and use separate one
Can you give an example of what you mean by 2? i.e. expected behavior vs actual behavior.
yeah that is true. nevermind then
can we add that to ClusterStateCreationUtils? It might be useful for others as well
can we set the timeout to 0 here? otherwise tests half the time takes 1s
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
As mentioned above, I'd opt for setting the fully constructed lookUp oject here in case it is valid.
the idea would be to validate that this doesn't happen to prevent mistakes, and always serialize everything we have.
can't help but wonder if these two impls could share more of their code. I guess that it all starts with the factories not sharing a base class, and I vaguely remember talking with @nik9000 about this not being straight-forward...
Did you push the change that added it? I don't see it.
Let's maybe call it `preCollect`? (symetric with `postCollect`)
I usually prefer avoiding lambdas when it is possible, in that case that would give something like this: `Collections.sort(this.filters, Comparator.comparing(KeyedFilter::key));`
does this work? it works for percentiles, but with percentiles rank it's reversed
This worries me a bit as this is inconsistent with the filters and ranges aggregations.
would be great if this logic could be unit tested.
would you mind reverting the variable name change, at least temporarily? it confuses the review
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
I would try and rename this one as well, I find it annoying that is has the same name as the ordinary toXContent.
yeah, that was what I meant
I'm not too happy with the implicit unchecked cast that is happening here. IMO it should either return an Object or require the key to be parameterized (`V getFromContext(Key<V>)`).
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
++ to just `get*`
Probably worth putting an explanation in here.
Might be nice to add a check for existence of these parameters for completeness.
Why do we need a concrete and an abstract method for each test where the caller only calls these methods anyway? I think we should just make `testReadFrom` and `testWriteTo` abstract.
I meant [this](https://github.com/elastic/elasticsearch/pull/31163/files#diff-2ec2c2b070f96bf66b888db94648ffe0R321) . The standard engine ends up returning a `SnapshotIndexCommit` which is why I used the term lucene snapshot. I hope this is clearer.
+1 on pulling this out, I'm sure this can be used in other places, although in many of the tests I'm thinking about right now we have NamedWriteable things under test, but only the copy method would need to be slightly different.
I think it'd be more accurate to call it `testSuccessfulBuilderContext` or something like that because it isn't just testing with the settings - it has the `ContentPath` too.
the nice thing of it is that you wouldn't need to write the usual code to test parsing etc. indeed in this case you would have to rewrite assertEqualInstances to not rely on equals/hashcode so that we only check stuff that is serialized over xcontent. I would give this a try if you don't mind, unless there are complications that I don't see :)
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
You can use expectThrows()
You are throwing away the stack trace here. Just have this method throw Exception, and the tests that call it as well.
Thanks for the explanation. Makes sense now, yes. And I learned something too.
> Makes sense? It does not make sense. Having try/catch like this means the test doesn't really know what it is testing.
For backporting to 6.3, I think this needs to be changed to 7.
right I think tests are made for that. I wouldn't want to have checks for something that we handle earlier and that should never happen here, that is my personal opinion though :)
I think filter and query can never be null here? not sure whether we should validate this here.
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
cool thanks for the explanation!
Did this change in the builder or does the case check stay? Can't find it, maybe missed it.
ok lets keep it but please let's not create a list for this, we can just do if INT.equals(field) || DOUBLE.equals(field)
this could be static
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
sorry, my bad.
should this be "not mounting...consistently" or "mounting...inconsistently"? But I would think not the current double negative.
open reader doesn't need to check for <0 and throw an exception any more.
we could pass a glob with regex:xxx to newDirectoryStream if we want
the reason why I suggested to make it configurable is that we could pass in our own values in tests that's all... not a big deal
I think this needs to be wrapped in try/catch so that this doesn't cause a missed invalid line like: ``` 2147483648-:-XX:+TurnOnCatLasers ```
you can have a look at SimpleQueryStringBuilder.VERSION_5_1_0_UNRELEASED to see how to do it
I think consensus is to avoid build failures entirely whenever possible
I'm actually wondering if it would be better to commit with the `onOrAfter` line and just accept the errors for a build or two. The last good commit stuff should mean that only the intake build fails on this. You could also set up the backport for 6.x branch before pushing the change on master so you can push both at the same time and minimise the chances of builds failing.
Actually I'd still prefer to go with Colin's idea to use empty sets. We can still optimize later by making sure to use a Collections.emptySet (which is a singleton) if the size is 0.
Ok fair enough, I'm happy leaving this as is then
I tend to try an indent these manually so they *look* a little more like json. Not that this is required, but it does help when they get big like this.
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
What happens if `enabled` isn't set? I *think* we should continue to do nothing if `enabled` is actually true.
Can you test something that is not byte-aligned, like /15 or /17? We used to have bugs in those cases.
Although the code is clear, the level of indirection here makes it hard for the reader to figure out that this (and similar other) test does. As a suggestion, what about combining test_object/test_object_IgnoreMalformed, then the code from `sourceWithObject` can be inlined in the test case. Also I would make the assertion on field1 and field2 explicit, even if that means a few more lines of code. In this case I would trade repetition for readability.
Let me re-iterated what my concerns are regarding my current approach - It overrides default path handling of the InternalTestCluster without needing to. - It overrides path logic in NodeEnvironment w.r.t where to put the data. NodeEnvironment expose the API to get it. - It starts another node where we can make it simpler and use the async standard node start logic of InternalTestCluster (minor) My point here was not w.r.t randomness but rather making the code simpler and straight forward.
btw - the test uncovered some issue with the dangling indices import. You might run into a node not connected issues - working on an independent fix.
Yeah, it seems it is. We treat non existing indices as red. Thx for educating me.
I think there is a race condition here - it may take some time for the dangling logic to kick in (it's async via network calls). I would assertBusy until the index is visible in the cluster state, then go into ensure green.
and use the constant here
I think this check should go into initializeSnapshot or repository.
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
really this would look nicer if we counld just do: ``` indexShardRepository.lock() try { .... } finally { indexShardRepository.unlock() } ```
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
Got confused by this and had to go to the code :) - I think this will be clearer "returns the time in millisecond until this unassigned shard can be reassigned."
I think we no longer want this to be an `assertBusy()` - we expect that the previous reroute didn't do anything, so it should still be in this state from beforehand.
I think I see what you are doing here (protect against system clock going way back in time), but I wonder if we should be so strict. 0 is a dangerous value - I'm worried that a very fast machine will render this check ineffective, so I would go with `delta<0`. I also wonder if a short ntp correction will release pending shards. Maybe use `delta<-delayTimeout`? .
++. Thx On Wed, Jun 17, 2015 at 9:09 PM, Shay Banon notifications@github.com wrote: > > - return 0; > > - } > > - TimeValue delayTimeout = indexSettings.getAsTime(DELAYED_NODE_LEFT_TIMEOUT, settings.getAsTime(DELAYED_NODE_LEFT_TIMEOUT, DEFAULT_DELAYED_NODE_LEFT_TIMEOUT)); > > - return Math.max(0l, delayTimeout.millis()); > > - } > > + > > - /** > > - \* The delay in millis when delaying assigning the shard need to expire in. > > - */ > > - public long getDelayAllocationExpirationIn(Settings settings, Settings indexSettings) { > > - long delayTimeout = getAllocationDelayTimeoutSetting(settings, indexSettings); > > - if (delayTimeout == 0) { > > - return 0; > > - } > > - long delta = Math.max(0l, System.currentTimeMillis() - timestamp); > > - if (delta == 0) { > > I think I got what you mean, I will improve it to check on negative value and return 0, to accomdate cases where its fast enough where currentTime is the same as timestamp > > --- > > Reply to this email directly or view it on GitHub: > > https://github.com/elastic/elasticsearch/pull/11712/files#r32663140
can we call these indices "short_delay" and "long_delay" ? I think it will be easier to read.
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
Can we switch between the string and the millis representation fo the modified date using the `human` flag like the explain API already does? That way we can just have one `modified_date` field in the output? Also the parser will not need to worry about the string version in this case since the client it will never set the human flag
It would be nice if this class was immutable, and this line shows why it isn't currently. This is how to make it immutable: ``` List<CompositeValuesSourceBuilder<?>> sources = new ArrayList<>(num); for (int i = 0; i < num; i++) { CompositeValuesSourceBuilder<?> builder = CompositeValuesSourceParserHelper.readFrom(in); sources.add(builder); } this.sources = Collections.unmodifableList(sources); ```
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
+1 to this, there is always the low-level rest client for this, and we can revisit adding it at a later time if we change our minds.
ok let's leave it as is for now.
We can simply add responseSupplier to the constructor of TransportChannelResponseHandler (same I did in #17752). We can then remove the static methods in that class (one of which should be obsolete anyhow by the change here w.r.t. master).
I wonder if this case distinction should be part of ReplicatedOperation.
can add a sentence or two about what is currently known to be potentially missing? (in sync markers for shards on new nodes that should be accounted for GP calculations). I think it will help (at least it would me) to understand what this is about.
I think this is the right thing but can we log a debug level log here? this is extremely exceptional for people to index into and delete their index concurrently. We should have some visibility into it. As it is strictly speaking OK from an API perspective (people can do that), I wouldn't go with WARN/INFO, but with DEBUG
This directory is optional now, so the logic should be changed? ``` java if (Files.exists(userAgentConfigDirectory)) { if (Files.isDirectory(userAgentConfigDirectory) == false) { throw new IllegalStateException( "the user agent config path [" + userAgentConfigDirectory + "] isn't a directory"); } PathMatcher pathMatcher = userAgentConfigDirectory.getFileSystem().getPathMatcher("glob:**.yaml"); try (Stream<Path> regexFiles = Files.find(userAgentConfigDirectory, 1, (path, attr) -> attr.isRegularFile() && pathMatcher.matches(path))) { Iterable<Path> iterable = regexFiles::iterator; for (Path path : iterable) { String parserName = path.getFileName().toString(); try (InputStream regexStream = Files.newInputStream(path, StandardOpenOption.READ)) { userAgentParsers.put(parserName, new UserAgentParser(parserName, regexStream, cache)); } } } } ```
This has to use the new settings API.
I don't think we should make the patterns dir configurable? Outside the ES_HOME directory ES has insufficient permissions to read files. I think the patterns dir should always be `$ES_HOME/config/ingest/grok/patterns`.
I wonder if we should log a warn level log if we have multiple shard states at this stage. It means something went wrong.
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
we also need unittests for these queries!!!
I wish the API was more in-line with things like collectors and comparators, ie. `LeafCollapsingDocValuesSource CollapsingDocValuesSource.getLeafSource(LeafReaderContext context)`
the important part is having multiple open readers on this as well.
I think this declaration/initialization can be moved to inside the if
I think this will be clearer if we say - "// precreate incoming indices and popluate them with the relevant types"
make this Error? we alway want to use this.
can we add some trace logging here? I can imagine it will save some WTF at some point.
this can be out of if now.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
Maybe use indexSafe() here? Just in case of the resolved index got deleted before the cluster state update task is executed.
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
I think as it currently is, we'll have to rewrite the parsing, because we won't know what the source index name is until much later, and we won't know the destination index name until actual execution also. I think we may want to not use `RollupV2Config`, but instead keep our own configuration option with the options we need. (At least if we want to keep `RollupV2Config` requiring the source and destination names up front
I think this should be removed based on the value of `index.blocks.write` (i.e., if true add, if false remove). See `MetaDataUpdateSettingsService#updateSettings`.
I think saying that we can not convert the follower index to a non-follower would be clearer. My concern here is that if `bar` is following `foo` and this message says `cannot unfollow index [bar]` it would be confusing since it is `foo` that will no longer be being followed by `bar`.
maybe it would be better if each test had its own instance of TestTemplateService (better test isolation)? I think we shouldn't worry about performance or too many objects created here.
this class is not needed anymore as Aggregations is no longer abstract and also implements ToXContent
just being over paranoid I think this class should be final
add a private constructor so it is not possible to instantiate it. Maybe even make it final, although it is redundant with the private constructor.
That's just a minor thing but I think the recommended order in the Java styleguide is `private static final`.
> I thought I was getting at that without making it too wordy. The key is that you're not registering a `DeprecationRestHandler` as the name `registerDeprecatedHandler` implies. Instead, you're registering a handler that gets wrapped as a `DeprecationRestHandler` before registration. I guess `registerAsDeprecationHandler` would be slightly less wordy than `registerHandlerAsDeprecationHandler` but the point still remains.
this is just personal preference so feel free to ignore it, but I like the name `registerDeprecatedHandler`
The language in this sentence isn't clear, perhaps change "that is replacing" to "and it is replacing"
Change to Throwable.
No, I still think that it should not be a method on the `Strings` class.
similar concerns as DeleteRequest
can you remove this empty line? :P
Maybe replace these with writeOptionalString as well while you are at it
`tokenFilters` is not nullable anymore, as `charFilters`. I think we can use `writeStringArray` here, I checked and this doesn't seem to break backwards compatibility on the wire level.
can we add a note here why this is optional? the validate request suggests otherwise...
+1 to setTopReader instead of next (it makes more sense imo since there is a single top reader)
Is there any way to do this check earlier? maybe in the preCollection method? Only wondering as we will have already done the main collect phase by this point so it would be nice to fail faster if we can
ok, fair enough then
this part of the change looks a bit scary to me. I'm wondering how hard it would be to do this 'state' management and wrapping of collectors outside of IndexSearcher so that we don't have to check what the query is.
The default case can be removed here.
Where are these mapper helpers used? I've only found them used by tests. Maybe we don't need them? I removed a number of them before for metadata fields.
Well, I think this needs to be fixed here. There is no index created version in field data settings, this is an artificial thing that it sounds like you have added to workaround some other issue.
Or actually just "ignore for old indexes" would probably be sufficient, since the version is clear from the condition.
update version to beta 1
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
same here re enumSet.toString
I prefer my way but have asked @jasontedor to chime in.
I am not a super fan of this. I wonder if we can afterwards rethink this.
same here. I would prefer to have a separate `runTranslogRecovery` method that we use for the local replay after reset. This method could then use a different stats object as well as a different origin.
++ . nit: add the state to the message please.
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
nit: can you assign `event.state()` to a local var
we should also have messages here in this assert
future note - once refresh mapping is gone, we should inline this with index creation.
Itâs fine @javanna, pull it in in this one. I would prefer we keep changes like this out of PRs, they can go in separately, I want less to think about when I review.
This condition will never evaluate to `true` as we'll get an NPE when dereferencing a `null` instance of type `ExecutorHolder` in the line above.
should we release the releasable just in case the exception comes from the listener? this would allow us to only implement on failure.
do we want to do something with is error? (not related to this change)
typo: direct**or** -> direct
Hope this doesn't bite us for really slow (read: Windows) CI servers...
schedule first run should be called twice, regardless of cancellation right? can we check for that using an assertion? we don't really have to test it as there is no way for the user to achieve this when the class is not exposed.
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
Ahh okay, that makes sense, I missed that
maybe rename those methods to assert\* as this is what they do... same with the next one
oh damned it's BWC I guess...
we can use in.readVInt() here, no? it's always non-negative... (same goes for other counters and also note that you'd have to change the writeTo message of course)
drop the actually? sounds so "uncertain" :)
can we invert this and say `if (suggestStats != null)`
This method could take an IndexMetaData object as parameter instead. This would let us get rid of exceeds method as well.
Can you add a check for reparsing (ie taking a settings that have been run through archiver and using them in another settings builder) the settings works? ie the setting stays archived and doesn't disappear.
Typo: `afllowed` -> `allowed`
This has to use the new settings API.
If these privileges are only needed for loading static definitions, then this should be done in a static block when the plugin is loaded, instead of on every invocation of the script.
Maybe add minimumLuceneVersion() to index metadata as a placeholder for #11095? Then the impl can just be createdVersion().luceneVersion in this PR? It would just make it more clear here that the lucene version is the driving factor.
I think this catch not needed. It will be caught higher up.
I think we should use the `ElasticsearchSingleNodeTest.class.getName()` as the cluster name then we know exactly what is going on.
we should set a node name too...
can this see `unregister task for id: [{}]`
I think it could be null instead of `"*"`
Unless your node is named "1", this is not a valid configuration. Please have a look at the [docs](https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-discovery.html) or reach out to @DaveCTurner or me on how to configure this. Note that if your tests are running a single node in development mode, then no configuration should be necessary.
I think this assertion should be in `getAnyNodeExcept()` - it's ok to return an empty list here.
`S3SignerType should not be available for China region`
nit: `an` -> `a`
can we move this to our `test` infra? I think we do this in another place in our code (or one of our branches)
Can you indent this one extra time? When the body of the block below it and a part of the `if` statement line up I have trouble separating them properly when reading quickly.
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
can we be slightly more verbose on why this is use full? (different deserialization logic based on key in parent map)
can we also add a line saying this variant allows for custom value deserialization based on the map using a KeyedReader? I got confused by why this is useful (until I saw how it is used).
nit: naming issue...
I think we should mention the index, cause that is the useful bit (e.g. which index is closed), also because we never really hide the fact that users are using aliases (e.g. when indexing into an alias, the response will contain the concrete index as `_index`, not the alias).
hey @martijnvg I double checked with @clintongormley and we both think it's better to add the actual index that was closed, not the alias. Knowing that an alias is closed has little sense, better to report back which concrete index was closed.
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
`com.sun.glass.ui.Size` appears to be unused.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
Depends where you want to through the exception I guess. I think throwing it right in the listener is going to make the failures more clear but both should be fine.
I'd likely do an `AtomicBoolean` and `boolean alreadyFired = hookWasFired.getAndSet(true); assertFalse(alreadyFired);` just for extra paranoia.
s/un a thread/in a thread/
maybe, to be more precise, it would be good to check the partition that included the new primary.
Test is called "testPrimaryOperationLocks" and then most of the code is there to check replicaOperationLock ;-)
I think this can move to before the threads start - will be nastier
we can throw exceptions on the background thread and the test should fail with uncaught exceptions on a thread.
Oh. You need to explicitly close the op.
> However, I am not sure if we should do it. why is that? We're building all this machinery to have search availability during the transition, except for this very short moment? I had the same idea about retrying. An alternative would be to do refcounting for closing the engine, to ensure that we only actually close once all in-flight `acquireSearcher` calls have been completed.
How do we ensure that searches are not accessing acquireSearcher on the closed engine and switching to the new engine? Also, is there a test that checks that searches (with preference set to this node) continue to work during this transition.
please assign the `System.nanoTime()` to a local var that way you only need to read it once and you have consistent values.
make this synchronized too. it's safer since you modify both references
it feels weird to do these things here - this method now only creates an engine but doesn't change the IndexShard fields - imo it shouldn't touch the store (because it doesn't know anything about any current engine running it)
I am afraid for consistency reasons we should for now go for path(..) and drop the set prefix on these new setters. We will fix them altogether at a later stage.
don't you want to reset first and then set the parseFieldMatcher? :)
we should probably consolidate the error messages from the results so that we don't only present the first (from a seemingly arbitrary check order) error that was encountered to the user
I was thinking something similar to how we use [addValidationError](https://github.com/elastic/elasticsearch/blob/master/server/src/main/java/org/elasticsearch/common/ValidationException.java)
nit: I wonder if we should rename this to "fromXContent" like we do in most of the queries, suggesters etc... No strong opinion here though.
I was wondering if `getSuperset/SubsetSize` is part of the Bucket interface but not rendered via the Rest response, should we either add rendering of these values to the bucket response or remove it from the interface to get equivalent behaviour of functionality of the transport client with the high level rest client here? I think this can be done in a separate issue though, maybe its not needed at all.
I'm okay with the UnsupportedOperationException for now if we can track this question (whether we can reach consistency between the functionality the transport client provides via the SignificantTerms.Bucket interface with the rest response) in a separate issue
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
Aggregations is not abstract anymore, you can remove the curly brackets. also if we had Aggregations as a member we wouldn't have to create it on the fly here
shall this extend ParsedAggregation? then it implements ToXContent and we can drop a cast below I think.
It's super minor, but our log standardization is usually all lowercase
Same here with period and lowercase
I think it'd be cleaner to put the `finishHim(e);` into an `else` statement than to return early in this logic
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
Ahh okay, that makes sense, I missed that
oh I see. I missed it.
I'd prefer using `IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> prez.setRelevalntRatingThreshold(-1))` here like we do in many other tests and get rid of the @Rule
Ah yeah I suppose that might be ok, in this case it's user-defined input so that's pretty awkward but it beats breaking.
One way to implement this: Ignore the LockFactory of the inner directories and require the LockFactory to be set on DistributorDirectory itsself (by extending BaseDirectory and taking a external LockFactory on ctor). In that case the Distributor would know the exact type of lock, because it is responsible for locking. The underlying directories would just need no locking at all (NoLockFactory). But this would be a change out of the scope of this issue. But I like the current impl better. Locking should be the responsibility of the directory that actually holds the lock. This implementation is now implemented the same way like FileSwitchDirectory. FileSwitchDirectory just has the additional "feature" that it delegates the makeLock() call by its file extension, too (and no longer places it in primary dir), see MIGRATE.txt in Lucene. Please also keep in mind, that the lock file itsself is an implementation detail, so maybe we get another lockFactory in the future that does not create any files at all (e.g., by locking the directory itsself or writing some information to its metadata). So to me it looks wrong to see the lock file as required to be listed in listAll(). Lucene itsself does not depend on that (because lock files are unknown to lucene), Lucene just uses the makeLock() method, nothing more.
Ah! I get it now. LGTM
I think it could be null instead of `"*"`
Why not use the dedicated get aliases api? IndicesAdminClient#getAliases()
try to use `AbstractRestResponseActionListener` instead of `ActionListener` the `onFailure` method is already implemented there
Not sure if we want this optimization, but we could always run these three requests in parallel, putting the responses in three `AtomicReference`s and using three `CountDownLatch`s to wait until all three complete.
I implemented the early cat APIs that way and @kimchy wanted to nest instead. If the cluster's busy then you only have one dangling request.
I took a quick stab at sth. that avoids the Tuple and replacing the test builder [here](https://gist.github.com/cbuescher/88531fe7c2abd38936ef), but it still looks a little bit strange to me. EDIT: Doesn't work, equals-tests break with this little hack. Sorry, nevermind.
+1. Maybe this helper so far is limited to the query / suggester tests only, but then again it might be general enough for ESTestCase.
I believe this can be provided by overwriting EsTestCase#xContentRegistry().
I think we should collapse the two above methods, they are always called in sequence.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
do we want to check the phase/action times since those are meant to change
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
oh, woops. thought I counted right. sry
Can you add a check for reparsing (ie taking a settings that have been run through archiver and using them in another settings builder) the settings works? ie the setting stays archived and doesn't disappear.
Out of date doc.
fileswitch -> default here
this is not needed. createIndex automatically reroutes.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
This could just be `close()`
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
is this needed here? I think it does something only when the current token is start array or start object.
we can't change the format of the response at this time. We can at some point, but for now we just have to parse what we have, and figure out what we should do to make things better for the future, meaning potentially breaking changes etc.
calling `ConcurrentHashMap#size()` can be quite expensive IMO. I think we should keep track of the open ctx in a counter instead of using the map. I don't think being a little off here makes a difference. I think we don't need to add any sychronization changes here.
Maybe `createContext` should take the `SearchTask` as an argument? That'd make it very difficult to forget to set it.
this can only be a runtime exception you can just bubble it up no need to use `convertToRuntime`
You can remove the `hasResponseFromRequest` method - it is not needed anymore.
Oooh! Yeah! That makes sense - scrolls contexts will outlast that task that spawns them and need to get a new task. I haven't read the whole PR yet, but I wonder if we should clear task from the context between requests? If we don't then we maintain a reference to it after the task manager and that seems a bit weird. Changes to it wouldn't be useful to anyone.
Why not have the standard to string? A multiline return value is difficult to work with in a debugger...
I believe we've been just using the string version of field instead of these lately.
Or we can let poorly formatted values pass through and throw exceptions at the end if values are missing, similar to how we do for queries
obscure error message... let's start by `"could not read alias fields filtering from xcontent. expected an object but found [" + parser.currentToken() + "] instead"`
same here these strings are only used in one place just use them directly and trash the Fields class
You mentioned the overflow that could happen here. Can you please add a safeguard? Otherwise I might not be able to sleep anymore ð¨
This should probably be `synchronized` too since you're protecting access to `delayedAllocations`.
connec to to -> connect to
This can all fit on one line.
ok however, I think we need to come up with a better model here after all maybe register all stuff up-front and make the registered listeners mutable and more tailored to their usecases and remove and add patterns
which asserts failed? the idea of hasArray is that if its cheap to get the array for it, so any code block that fails is potentially a bug for implementations that don't have support for it.
actually, if its a single page, then we can just reference the first page byte array, if not, then we should return false. same with `array` and `arrayOffset`.
@hhoffstaette I fixed the places where we didn't respect the `hasArray` contract in #5455, so now we can go ahead and return `true` when we have a single page, and false otherwise. Also, `array` and `arrayOffset` should throw an exception if its not a single page (i.e. hasArray is not true)
totally +1 on having bulk operations, we already started discussing it with @hhoffstaette
this check is obsolet - we can just remove it
Same concern about reproducibility as in the other PR.
import not needed.
> Makes sense? It does not make sense. Having try/catch like this means the test doesn't really know what it is testing.
Not needed anymore.
Not needed anymore.
use `ThreadPool#terminate` here otherwise you will get lingering threads etc.
we have `TestThreadPool` that makes it simpler
well we use a dummy lock so I guess it's fine
try finally here please since if close fails we don't release lock etc which can be missleading
yeah that is true. nevermind then
Do we need this on this one? It seems like these test suites are very small and any of them taking 40 minutes is grounds for making someone look at the VM at a minimum.
Thanks a lot for this! Definitely better to generate that in a temp dir on the fly instead of having those files as part of the git repo!
You could look at `GradleUnitTestCase` it does the same by pulling int the randomized runner only. What I was wondering about w.r.t order is that if it really makes sense to have it fixed. If all we are doing is going trough methods sequentially what advantage does it bring to have them in separate methods ? Maybe better error reporting ? Should we keep the randomized method order and make sure it actually works like that? I'm not saying we need to change it just looking to understand the implications.
Do we really need a before and after? These are run completely sequentially, so the "before" of one test is the "after" of the previous. I'm just thinking of what the old output used to look like (a single line per test in most cases with "OK") compared to what we are moving to here (many lines per test, if I understand correctly).
Is this really necessary? Seems like it will produce a lot of noise.
I'm not so comfortable with separating this code from the one in `updatePrimaryTermIfNeeded` - they are tightly connected. Instead of sharing code this way, how about creating a callback that will run: ``` indexShardOperationPermits.acquire(listener, executorOnDelay, true, debugInfo); ``` or ``` indexShardOperationPermits.asyncBlockOperations(listener, timeout.duration(), timeout.timeUnit()); ```
i like the final approach better this gives a uniform return value (easier to understand) and it makes sure these things are set.
should this be synchronized so we get a consistent snapshot of the two engines? Also, again, please do the closing outside the lock.
Typo: "`check point`" -> "`checkpoint`".
VersionUtils has a method for this
typo: tracker -> tracked
Ahh okay, makes sense, good point.
No need for this `else` statement since `lALogger` is already initialized to null
Rather than filtering ourself, we could alternatively pass prefix as glob to newDirectoryStream, and it would follow filesystem rules.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I think this should throw IAE if you pass null - that's 100% of the time a bug
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
I would probably throw an exception instead of accepting null here.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
you can just replace with `IOUtils#closeWhileHandlingExceptions`
Are we sure this is the correct logic? this logic means, if the file "definitely does not exist". But i think we want !Files.exists()? Unless the file "definitely exists"
I think this can be set to final and not intialized (`final Set<String> typesToUpdate;`) . It's only set once and it has to be set now.
This can be `Files.notExist(...)`
should we make this stream private here? I mean we might wanna have a dedicated exception for this
if randomInt() returns -2^31 then docCount will be negative (since the absolute value cannot be represented as an int in that case)
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
I wonder if this is a good name for this reducer? I haven't got any good ideas for alternatives but to me a differencing reducer would subtract one series from another rather than subtracting offsets from a single series. It took me a while to be clear on what this reducer was actually doing. I will defer to someones better judgement though as I appreciate that this might be a standard statistical term
I am wondering if it makes sense to implement `getProperty()` for `Aggregations` as well and not just for `Aggregation`. For example in a test I would write something like ``` Aggregations agg = searchResponse.getAggregations(); Object o =agg.get("aggname").getProperty("path"); ``` but if Aggregations also implemented getProperty() I would save another line and it is needed anyway here internally.
does this constant make sense to be here or in the fallback code should we just pass `new LoadAverage(-1, -1, -1)`. Maybe we should remove the ctor taking a single `double` as well, and pass `new LoadAverage(x, -1, -1)`. I had trouble following the logic but then it would be all clear what values are being returned in those cases.
oh boy, I see that we were using VInt for writing and Byte for reading.... thanks for fixing...
I prefer that we make this explicit by passing `UUIDs.randomBase64UUID()` here and removing the overloaded constructor.
Since `getSnapshotInfoInternal` (just below) is only used by `getSnapshotInfo`, we can move the code in `getSnapshotInfoInternal` directly into `getSnapshotInfo` and get rid of `getSnaphotInfoInternal`
As this is just a public wrapper for new Snapshot(...), I prefer that we make the constructor public and get rid of this method.
this logic belongs in transportWriteAction
Using 0 as a non-value (because we serialize using `out.writeVLong` ) seems brittle to me. I rather use -1 and serialize using normal `out.writeLong`. With 0 we will always be asking ourselves if it's a valid value. We can also potentially have two methods here - failReplica and failShard, where failReplica requires a valid primary term and failShard doesn't take one (but uses -1 internally) so users won't need to know about this implementation detail.
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
Nit: `"call back"` -> `"callback"`
I'm not sure regarding why wildcard is different. I suspect its just because we haven't before needed for change the behaviour of wildcard queries based on the field type. I can't see any reason not to change it so we can control the behaviour here though. If we do make the change it might be best to make it directly on master and then pull the change into this branch to disallow it as the change may become difficult to maintain in the feature branch
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
And we could then just leave an assert here.
I think an absurdly high limit could still be helpful? (in a follow-up PR)
Same here, I think the ctor should contain the mandatory arguments and those should be immutable later. Again, this means for parsing we need ConstructingObjectParser.
you know what? I thin that I was just being paranoid about the test succeeding despite the path prefix not being used. we check that it's used in the returned request line! Maybe we can just remove this method then and keep the following one, which makes much more sense.
I might make something like ``` private void expectMissingBodyError(Matcher<String> responseMatcher, ThrowingRunnable exec) { ResponseException responseException = expectThrows(ResponseException.class, exec); assertEquals(400, responseException.getResponse().getStatusLine().getStatusCode()); assertThat(responseException.getMessage(), responseMatcher); }
and randomly append '/' at the end
should this be `BAD_REQUEST` instead? If we cannot handle the request, it's not that there's an internal server error, but that the request is unexpected.
maybe just `esVersion()`
Could we also have a demonstration of the happy path on a three-node configuration, with the assertions adjusted accordingly? In the three-node case it's possible that publication responses interleave with commits, and this should be covered.
Could this be: assertThat(ackListener.await(0L, TimeUnit.SECONDS), containsInAnyOrder(n1, n2, n3));
We should assert that this is called (and I guess that we can say something about the response that is passed in).
We could get rid of this `== false` by inverting this statement.
We could get rid of this `== false` by inverting this statement.
`originalLocation` param is redundant
I think we can share this line and the return new BulkItemRequest line? these two clauses will need to set a final `updateResponse` field.
can we call this primaryItemRequest? It's the one that's sent to the primary. Also, if we pass it as a `BulkItemRequest` parameter, we can avoid sending `requestIndex` and `BulkShardRequest` (from which need the concreteIndex, which I think we can from the shard). Last can we assert that the `BulkItemRequest` has as a request object the `updateRequest` we got? this is all super trappy but we can take one step at a time :)
this whole method can be abbreviated to ``` return new BulkShardResponse(request.shardId(), Arrays.stream(request.items()).map(BulkItemRequest::getPrimaryResponse).toArray(BulkItemResponse[]::new)); ```
please move this method up next to `findNextNonAborted`
+1 this makes sense. Then we can drop the `PIPELINE_ALREADY_PROCESSED` transport header.
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
These two methods feel kind of copy and paste-ish. They aren't really, but when you scan them they look similar.....
> I think in that case the `ingest` thread pool should be the default, in case no thread pool has been configured on a pipeline. yes.. that was my intention with the "default TP"
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
I meant the listener we pass to the transport
also, using a non-inner class means we can free the memory (i.e. cluster state copy) rather then have them accumulate with every retry
We can pass a name in the constructor if need be? On 11 dec. 2015 9:53 AM +0100, Martijn van Groningennotifications@github.com, wrote: > Incore/src/main/java/org/elasticsearch/action/support/replication/TransportReplicationAction.java(https://github.com/elastic/elasticsearch/pull/15363#discussion_r47332645): > > > @@ -304,7 +304,27 @@ public void onFailure(Throwable t) {>observer.waitForNextChange(new ClusterStateObserver.Listener() {>@Override>public void onNewClusterState(ClusterState state) {>- threadPool.executor(executor).execute(AsyncReplicaAction.this);>+ transportService.sendRequest(clusterService.localNode(), transportReplicaAction, request, new EmptyTransportResponseHandler(ThreadPool.Names.SAME) {>+>+ @Override>+ public void handleResponse(TransportResponse.Empty response) {>+ try {>+ channel.sendResponse(response);>+ } catch (IOException e) {>+ logger.debug("failed to send retry on replica response, action [{}], request [{}]", e, actionName, request); > > got it. btw about the generic helper, we always have a custom log message or want to deal a failure differently in many scenarios, so I think a generic helper isn't going to help much. > > â > Reply to this email directly orview it on GitHub(https://github.com/elastic/elasticsearch/pull/15363/files#r47332645).
can we add something to indicate where this comes from? something like unexpected error while processing cluster state version [{}]
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
I think writer can be null if optimizeMutex is true when the method begins. It seems we have this recurrent pattern of calling ensureOpen and than getting the indexWriter to do something. Perhaps we can change ensureOpen to either throw an exception or to return a non-null writer (guaranteed) . This this can become `ensureOpen().waitForMerges()`
I wonder if we want a trace message here...
I think we should do this as one of the first steps in the if block. The reasoning is that if an exception occurs before this, we will never get the chance to continue operating as nothing will trigger this method again
s/The upgrade/The template upgrade
maybe move the conditional logic back out to the caller? the null check isn't needed, and the function name implies it always adds this trace, when in fact it depends on the request.
shouldn't we use here `!REST_EXCEPTION_SKIP_STACK_TRACE_DEFAULT` instead of `false`
I think you can just initialize to null
i don't think you need to save the currentName to a variable here, this can be a single `if (token == FIELD_NAME && STATUS.equals(parser.currentName()) == false)`
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
@s1monw I tried but realized that `NumericDocValues#advanceExact` method requires increasing docID values but it's not the case here. Do you have any suggestion for this? ``` /** Advance the iterator to exactly {@code target} and return whether * {@code target} has a value. * {@code target} must be greater than or equal to the current * {@link #docID() doc ID} and must be a valid doc ID, ie. &ge; 0 and * &lt; {@code maxDoc}. * After this method returns, {@link #docID()} retuns {@code target}. */ public abstract boolean advanceExact(int target) throws IOException; ```
I wonder if we can pull all these in the constructor into an array that we can access by index of the leaf reader. this is how we do things in lucene for stuff we access frequently.
please don't load stuff lazily. go and load it all in the ctor. they are in memory anyways.
I also wonder if we want to pull the `tombstoneDV` in the ctor next to `List<LeafReaderContext> leaves` and a `List<NumericDocValues>` for seqIds... I think this would be nice and prevent getting stuff from the reader over and over again.
this is unnecessary.
Fine with me.
acceptDocs will be checked _before_ these bits are checked anyway
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
can this be done in the base class with ``` Java return getClass().getSimpleName() + "[field=" + field + ", id=" + id + ", max=" + max + "]"; ```
I'd expect this to be in a synchronized block
ok, then assert that it's either snapshot or generic threadpool
If you need this in test, you can still call it getBlobStore()
let's check this on every access, not only creation.
Out of curiosity, why create a class for this instead of an anonymous class in `IndexService` capturing the local `shardId`? There are no other instantiations of this class other than the single one
I think this declaration/initialization can be moved to inside the if
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
I would leave it as-is, it needs to extend BaseQueryTestCase
I thought it would, plus I don't get why we do the same thing in different ways depending on the query. Maybe it's me though.
I think it would be great to have different values for same fieldname and type. Working on the SpanQuery builders, I introduced BaseQueryTestCase#randomValueForField(String fieldName) which at least works for String, Boolean, Int and Double fieldname, otherwise returns String. Might be useful to use this here as well, potentially with minor modifications.
we usually do check the lucene version in a static block ``` Java static { assert Version.CURRENT.luceneVersion == org.apache.lucene.utli.Version.LUCENE_48 : "Remove this class in Lucene 4.9"; } ```
Check nextToken is Token.END_OBJECT and throw appropriate error if not. Without this additional check the parser errors are somewhat confused if the JSON contains a parameter.
Sure, I was just thinking out loud
should we use a native trove collection here from String to long
> Ok this doesn't work because the standard synonym token filter also sets the position length attribute Arrrrgh, you are right. Here's maybe another idea: why not always treat things as if they were a graph,since a single linear chain of tokens really is just a graph. And then, when the graph enumerates to just one path, it should naturally "become" what already happens today? I.e. don't break out any special treatment for "graph" vs "not graph".
@s1monw I'm sorry that I didn't take any time to reply last night. The situation with the response parameters is quite complicated. Look for example at `Settings#toXContent`. The situation here is that the `flat_settings` parameter is consumed there, but the signature `ToXContent#toXContent(XContentBuilder, Params)` is a general signature, we can't just go and add a boolean parameter for flat settings to the interface because it doesn't make sense in all situations. It is for this and similar reasons that I ultimately handled response parameters the way that I did. Barring a redesign, I would prefer that we remain consistent for now. > It's just yet another place we need to maintain and look for params. Right now it is how we handle output parameters.
This is one way to do it, but I'm wondering why you opted to do it this way instead of using the infrastructure that exists for handling response parameters? Namely, override `AbstractCatAction#responseParams` (being sure to include the response params from super).
This isn't where I would expect it to be consumed since it affects the output only, not the request handling.
Now that I'm seeing these, I wonder if the default names should be `attr` and `value`. We could add aliases if we need longer. Since it's such a small API it's probably fine with the short versions.
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
Can you make this final? Also, I think you should use `getDataOrMasterNodeInstances` as the repository is only registered on master eligible and data nodes. The method `getInstance()` retrieves the instance from a random node and if it's not a data or master one it will not find the repository.
You can use `assertAcked()`
Can you use more explicit name? (Also for getRepositoriesResponse1/2).
I don't think we need to check the implementation class, instance should be enough.
You don't need to pass the default cluster `settings` here but `location` is enough for a FS repository
Minor: can we call this findSmallestDelayedAllocationSettings? Next confused me implying it somehow depends on now.
Yes, that would be clearer
oh hahahah, I can't read, that's an L
This is redundant. getDelayAllocationExpirationIn also calls getAllocationDelayTimeoutSetting()==0 and returns 0 in that case.
that's OK because of the fact that this run by a single thread, but it will be easier on the eye to use: ``` existingTask.cancel() ``` instead of removeTaskAndCancel()
This field is `static`, but it's set via a constructor. That seems odd.
Helper method is no longer needed now that `Logger.debug` exists.
I don't know, I believe METADATA_READ is probably enough but can't really judge, let's hear from @imotov ? ;)
Verification is called in two cases - when we create repo and when we explicitly call verification. We already check for `METADATA_WRITE` in the put repository operation, so I think we can use `METADATA_READ` here.
I think it might be worth dropping the `timeUnit` for now? I'm just scared of it.
Hurray no more weird `while (true)` loop
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
I usually do this a little different like this: ``` Java if (channelReference.tryIncRef()) { try { FsChannelImmutableReader reader = new ... channelRefernece.incRef(); return reader; } finally { channelReference.decRef(); } } throw new TranslogException... ``` just an idea...
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
Typo, "Trasnlog" -> "Translog"
I assumed that there is no problem setting values and checking that the output of the conversion from high-level request to low-level request is the expected one. We don't validate etc. I would do only what is straight-forward.
Its cuz when i did it, i had no idea that other thing existed. Would be a nice fixup PR after all these Snapshots related PRs got finished.
nit: it is slightly better to set a value only randomly, that way you also test that we do the right when the value is not set (this can be applied also to ignoreUnavailable above: ``` if (randomBoolean()) { boolean verbose = randomBoolean(); getSnapshotsRequest.verbose(verbose); expectedParams.put("verbose", Boolean.toString(verbose)); } ```
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
thanks @nik9000 ! @elastic/es-clients is this ok? I guess all the client runners will have to be changed accordingly.
I think this should be: ``` java Throwable newT = new OptimizeFailedEngineException(shardId, t); maybeFailEngine("optimize", newT); throw newT; ``` So that the OptimizeFailedEngineException is captured as part of the maybeFailEngine
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
This constructor doesn't seem to be necessary.
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
nit: we usually add a space here. We don't have anything that enforces this style but we usually do.
I'd do something like ``` boolean reverse = false; if (columnOrdering[i].endsWith(":desc")) { columnOrder[i] = columnOrder[i].substring(...); } else if (columnOrdering[i].endsWith(":asc")) { columnOrder[i] = columnOrder[i].substring(...); } ``` or something like that. I think we should complain if it ends in something other than `:desc` and `:asc`.
I think we should complain if we don't find the header name.
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
Consider checking for `null` somewhere for `primarySize` before the division below.
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
I am not sure if we should keep this analyzer - I think we can just use the `PrefixTokenFilter` by itself and move it somewhere in the completion namespace. Yet I think we should have some dedicated tests for this that use `ElasticsearchTokenStreamTestCase` there are some awesome helper methods that can find a lot of stuff that is not correctly set in the `TokenStream`.
maybe make if final
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
This should be `public static <T> PreBuiltCache<T> getCache(CachingStrategy cachingStrategy)`. As a result a few warnings on the caller methods are gone.
These names would be a lot easier to read without the redundant info. Eg `testDifferentMapData()`
these unit tests are great! We are going to need more of them :)
Maybe change the fields type to `Map` instead? The fact that it is a hash map is an implementation detail.
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
+1 to hardcode UTF8
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
remove the set boost
remove the setBoost
let's not make this hold this PR, but let's keep track of this potential issue and address the need for generifying in a separate issue
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
good point I am curious too now :) I hadn't noticed this at first
same as in the other PR, I would rather throw UnsupportedOperationException in the default case
Right but the only reason I suggested to test it here is that if/when it gets implemented this test will fail and will serve as a reminder to whoever implemented it that the test needs updating. I don't feel particularly strongly about this so its up to you but I think it might be useful.
Even though this one should work, exact double comparisons tend to scare me a bit: should we use `null` instead of `-1` for non-existing x-axis units? (and store it in a Double)
`min` can be named `simple` or `aggregation`
I was just opening the issue but I'll wait to see the conclusion here first in case we decide copying the first directory manually is still a better trade-off.
Yannick and I discussed this option first, but this needs extra care, for instance to not copy the write lock. It's also a bit more involved if we want to track statistics as well for the first source. In the end it's not clear to me which option is better.
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
I think we don't need this line or the following two, since they duplicate docs found elsewhere.
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
Sorry for the noise, realized all constructors are delegated to the `TermsQueryBuilder(String fieldName, Iterable values)` constructor, so all good.
good catch! that means we are not properly testing this case either given that we didn't catch it.
It might get written out correctly via toXContent, but I doubt it works when only going through the java api.
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
+1 to have `fromXContent` and `parse` be static
same here and in the rest of this method
There's a nice helper for this kind of random value creation in `ESTestCase#randomValueOtherThan(T input, Supplier<T> randomSupplier`). The second argument is a function that generates a random value, the first argument is a value that is supposed to be excluded from the range of possible random values. This might simplify this mutate code (and others in this PR) quiet a bit.
again: ESTestCase#randomValueOtherThan might shorten this quiet a bit
Great to see mutations added here as well.
Not one of my creative days today. Maybe in the org.elasticsearch.test package, no idea what the classname could be :)
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
the node where the shard should move to
shard can remain
These asserts are totally fine (and helpful!), but I think as a future direction, it would be nice if we encoded the invariants about a decision into the data structures themselves, so we make it harder to create an illegal state. It's totally not work for this PR, only an idea for future direction :)
Probably should also be getAssignedNodeId.
I see you have backcompat below for when this setting is passed in through a string field. However, i think we also need to have it for custom analyzers here.
I don't think that matters. This is a new setting we are adding, as far as the API is concerned. I don't think it is a problem to validate the user didn't try to configure the same thing in two different ways.
Users that have indexes created before 2.0 should not be precluded from using the new setting name. This looks like it _only_ allows using the old name with indexes before 2.0.
I would throw an exception if both are specified.
We should tell the use to use `position_increment_gap` in this error message.
I think we should fail the local shard on any unexpected error. Seems like the "safe" thing to do..
I think this should be done via IndexShard#failShard (which can be exposed via indexShardReference ). Will be cleaner and faster (it's local fail first, then notify the master)
I think we can do simpler by just returned a retryable exception to the reroute phase that started all of this. It will do the same thing. Also - I miss the annoying "request" reset (we should open an issue to remove it). I guess it's still coming..
this keeps bugging me :) we should something on the executor as well....
I think we need an extra check here to see if this was a local or remote execution. If local, we'll have double logging and double shard failed messages.
I would probably throw an exception instead of accepting null here.
ok, but we don't need to call this constructor in that case though and pass in `null`. That way we just open the door for null values. I would try and be more strict here.
this cast causes a warning. We can instead change the return type and argument of `convertToStringListIfBytesRefList` to `List<Object>` and `Iterable<Object>`
sorry I think I am mistaken here, looking deeper, I think we might need to remove execution from the builder in master instead given that we do nothing with it. Will do that.
Thanks for pointing this out, missed that all other constructors delegate here, my mistake.
In most other parsers (e.g. GeoBoundsParser) we do this by adding the following `else` block to the relevant places in the parser: ``` java } else if (!token(aggregationName, currentFieldName, token, parser, context.parseFieldMatcher(), otherOptions)) { throw new SearchParseException(context, "Unexpected token " + token + " [" + currentFieldName + "] in [" + aggregationName + "].", parser.getTokenLocation()); } ```
Sorry you are right, we should be using ParsingException. That snippet was the pre-refactored version. The difference is that ParsingException does not need the SearchContext (not available on the coordinating node) and actually points to the location in the request for the error (the XContentLocation). Please use ParsingException in this PR since this is going to be parsed on the coordinating node
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
We should add an else block here too so we throw an error if we get a token of a type we are not expecting
After reading this distinction for the third time - maybe generating a new FieldSortBuilder or ScoreSortBuilder could be factored into a private helper method like so: private SortBuilder generate(String fieldName) { ... }
I swear I'm missing something. I thought that top-level variables wouldn't be working with this based on the grammar changes I see...
also static method `matches` in Pattern is no good. otherwise it all seems fine.
Alternatively I think we should whitelist entire `java.util.regex` api properly with all exceptions, interfaces, etc. Just exclude Pattern.compile! Then tests can simply do stuff like: ``` assertEquals(Pattern.MULTILINE, exec("/foo/m.flags()")); ``` The constants in that file and helper methods like `split` seem useful. Also `pattern()` seems really useful for tests, especially if we want to test nuances of escaping. I can do it if you want, i know the whitelisting stuff is not the most fun...
I think the most direct tests are preferable for unit tests. If we want them in the docs as examples lets put them there and have them tested there instead. As far as Pattern, it would be really beneficial. whitelisting it should improve things as it would allow stuff like: ``` for (def foo : /foo/.split(xxx)) { ... ``` as well as hooks into function stuff like Predicate/Streams.
Definitely nice to add this at a later time since even with the docs I bet people will run into this and be confused. But, yes, for another PR :)
thanks for adding this
let's not log since it is an old index
This could be `Strings.hasLength(tokenizerName)`
This is not good for backword compatibility. Instead it should do: ``` if (indexSettings.getIndexVersionCreated().before(Version.V_6_0_0)) { String tokenizerName = settings.get("tokenizer", "whitespace"); tokenizerFactory = ...; } else { tokenizerFactory = null; } ```
Can you move these class variable definitions up to the top of the class? It's weird to see them after function definitions
Something like "This class assumes that the supplier is fast, with performance on the order of a volatile read." would give a lot of context to the decisions around how to use the Supplier.
Maybe mention that this amounts to a volatile read.
It is worth benchmarking this because it adds a volatile read. If it is too heavy we can make the check less frequent I imagine.
It might be possible, but I would try to avoid it in this case. I would go for either using both BaseTerm classes or none.
I would leave it as-is, it needs to extend BaseQueryTestCase
I wonder if it'd be easier to read if there were two methods? I'd kind of feel more comfortable having two just so you don't need auto-boxing. It might not make a huge difference, but in general `Rounding` doesn't its best not to allocate stuff. I think this method doesn't have to be so efficient, but still.
You use dateTimeFormatter.format() for equals but dateTimeFormatter for hashCode
Same deal, I'd just convert it to nanos.
This, plus the final return, can be simplified to just return the value of an `==` comparison between the two values.
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
I get that, I was just wondering why those default templates bother here
Why not public? Will make reflection faster for guice.
is index name and type something we really need to randomize in this test? i think we shoudl just test date backcompat here and leave problems with index and type names to other tests...
We need to think about optimizing here for the most common case. Which is a single alias. In this case, we don't really need to allocate a list. Might be an overkill, but stil.. :)
This default of 1 second is too low, it should be 60 seconds by default.
the XContent here does not match what you removed in the REST API. There was a bit about early termination, as well as count that you need to include. You likely need to also include the begin/end calls, or else this will fail tests. You can check the tests with `./gradlew :server:check` from the base of the checkout. If tests dont fail then we need some better tests around the response hehe
Wow, you are totally right, I see that now :)
spaces between commas
is this needed here? I think it does something only when the current token is start array or start object.
+1 on removing the `Void context` from all methods. The `declareInnerHitsParseFields` is already complex to read I think, that won't add much.
They are just hedging their bets.
I prefer it without the blank lines. No wonder we aren't consistent.
As far as inconsistencies, some classes even have a blank line between the opening and the body, but not the body of the class and the closing.
StreamInputReader already does this.
see above - I think you should add it though
Should this else clause be returned to what it was before the original refactoring PR? https://github.com/elastic/elasticsearch/pull/32068/files#diff-c94184ea4ef180f10817aa2bbd41a8edL119
Just a style note, we prefer the more verbose negation (`foo != true` or `foo == false`) over the short form (`!foo`), because the short form is easy to misread or overlook. :)
@jpountz could you have a look at this one? It made me nervous (not sure the stronger typing is safe).
Wow, that's a big difference! Do you know whether it is lossy compression or not? If not then indeed compression seems to make a lot of sense. :-)
no need for `else` here: ``` java if (numPredictions < 1) { throw new IllegalArgumentException("numPredictions may not be less than 1."); } if (numPredictions == 1) { predictions[0] = next(values); return predictions; } ```
why is this? what's wrong with `1.f`
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
Can we make a NoopGatewayAllocator (alla NoopClusterService) and put it in org.elasticsearch.test.gateway? then we can reuse it bellow
please fail if required stuff is null
oh cool the read is in the ctor! nice!
ok can we rename the getter then to `getFailedNodeExceptions()`
after is now minimum_age
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
Maybe this one too, I'm not sure.
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
why is this? what's wrong with `1.f`
please fail if required stuff is null
can we use a switch statement here maybe to read and write? like ``` JAVA switch(id) { case 0: return TERM; case 1: return RECURSIVE; } ``` and on writing we can do: ``` JAVA switch(this) { case TERM: out.writeVint(0); break; case RECURSIVE: out.writeVint(1); break; } ```
can we wrap this long line
Its a bit silly that an instance of this will return true for instanceof ImmutableTestCluster - its certainly not immutable. Not a big deal, probably.
ok can you add alls these infos into this class
if just read metadata it will also be easier to implement a fetch all interfeces, sort interface name, fetch interface ip sequence
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
when do not want to do it (and throw an exception as said above)
these unit tests are great! We are going to need more of them :)
Maybe change the fields type to `Map` instead? The fact that it is a hash map is an implementation detail.
the `grok` field can be final too
after rebase you will have to get rid of any wildcard import, or the build fails :)
What if we just load the grok expression only from the config dir. (`ES_HOME/config/ingest/grok`) We just make sure that when we create the distribution we also package the the ingest config into the zip file. Instead of loading stuff from the class path we can get it via the `Environment` class. (check the geoip PR how it is injected there) This has as a nice side effect that users can also define their own named grok expressions without us adding extra code.
do we need ordered things? does order help anywhere? If not I would just use HashMap
after all, what would the parsed output of `SearchPhaseExecutionException` look like? I'm asking because that subclass prints out an array and potentially additional objects, I wonder how users would retrieve that additional info from the parsed ElasticsearchException.
I think we should collapse the two above methods, they are always called in sequence.
here you may be able to use copyCurrentStructure
+1 on removing the `Void context` from all methods. The `declareInnerHitsParseFields` is already complex to read I think, that won't add much.
I don't think we should swallow the exceptions here, instead, this could be a try-with-resources block like: ``` java try (BufferedReader br = new BufferedReader(rulesReader)) { .. read the string .. } ```
This definitely feels like overkill now the `JoinHelper` is mode-aware and its mode is in sync with the coordinator.
maybe just `esVersion()`
This could be `Strings.hasLength(tokenizerName)`
Maybe this was already covered somewhere, but is `GENERIC` the right threadpool for this? (I don't have a better suggestion, just asking)
the utility should be a static class
this file needs formatting
No, that's fine.
This is only used in the constructor, doesn't need to be a field.
can we implement `Closeable` and use an AtomicBoolean to signal it's closed I like the `if (closed.compareAndSet(false, true))` pattern
Actually, now that you refactored LongHash, I think this can be made much simpler: we can just iterate with `i` from `0` to `bucketOrds.size()` (which is the number of entries in the hash table, instead of `bucketOrds.capacity()` which is the number of slots) and directly use `i` as a bucket ordinal. ``` patch --- a/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/LongTermsAggregator.java +++ b/src/main/java/org/elasticsearch/search/aggregations/bucket/terms/LongTermsAggregator.java @@ -108,13 +108,7 @@ public class LongTermsAggregator extends BucketsAggregator { BucketPriorityQueue ordered = new BucketPriorityQueue(size, order.comparator(this)); LongTerms.Bucket spare = null; - for (long i = 0; i < bucketOrds.capacity(); ++i) { - final long ord = bucketOrds.id(i); - if (ord < 0) { - // slot is not allocated - continue; - } - + for (long ord = 0; ord < bucketOrds.size(); ++ord) { if (spare == null) { spare = new LongTerms.Bucket(0, 0, null); } ``` (The same change should apply to other aggs.)
closing bracket should be inlined
It's a common theme across the codebase, we don't create iterators (explicitly/implicitly) if we don't need to
oh I thought that is an array from line 66 hmmm
spaces after '//'
seems redundant indeed
I'll leave this one
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
yes, that's what I was thinking, I'd maybe check state != CLOSE rather than checking for OPEN, but that's a super minor concern that doesn't change the result at this time
Nit: `cs version` -> `cluster_state_version`, please.
+1 this really cleans up code in several places
use ArrayList? one less usage for non standard code...
Maybe use ConcurrentHashMap? if we can then we don't the synchronized methods.
ah ok that make sense
The use of `#` might make queries confusing since it is also used for filter clauses.
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
Fine with me.
acceptDocs will be checked _before_ these bits are checked anyway
Whoops yeah, I only looked at the version for `Files` rather than `Files.newBufferedReader`, sorry
This could be: ```java try (BufferedReader br = Files.newBufferedReader(Paths.get(args[0]))) { ... } ```
Perhaps mention that the argument that is being expected is a filename of the jvm.options file
Also we should wrap the `-` in `{@code -}`
These should all be wrapped in `<pre>` or `{@code ...}`
and 2 more occurrences below
too many shards already allocated to this node for index ...
too many shards [%d] allocated to this node, [%s=%d]
can you undo all indentation changes, it adds noise to the diff
This predicate can be simplified to `(count, limit) -> count > limit`.
This check is unnecessary as if a job is being opened we are certain there is ML Metadata already installed.
Missing return statement.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
that awfully sounds like two voices for debug.... your turn, @jasontedor.
nit: extra line
This line will break our `precommit` checks because it violates the 140-character line-length limit.
I think it would be cleaner to set translated outside of the if statement. ``` boolean translated = incorrectOrientation && rng > DATELINE && rng != 360.0; if (translated || shellCorrected && component != 0) { ... ```
It would be nice to have this take the args in the same order as computePolyTop (array, offset, length)
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
please fail if vals.length > 3
I think this should be kept as is exactly for the reason that @bleskes mentions regarding the consequences in production code of changing this to a hard failure and the possible loss of visibility when tests are running. This really should never happen.
I think this check is wrong. When we have relocation going on and relocation source is marked as relocated (i.e. we call executeRemotely in TransportReplicationAction), then we have primary relocation target replicating back to primary relocation source (see also ReplicationPhase).
This exception will be treated as ignore replica exception. :wink:
simpler to write `(origin == Origin.PRIMARY) == (versionType != null)`
ok as a follow-up
I think this class as well as the constructor should be make public so a user (or us!) could micro-benchmark script execution themselves.
we might want to rehash the value before calling contains. For instance if the numeric field is a double and all values represent integer values, the lower bits will always be zeroes.
s/Long.hashCode/BitMixer.mix64/ ? otherwise we might still have the issue with doubles given that Long.hashCode is a bit naive
Might be nice to add a check for existence of these parameters for completeness.
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
good point, I think it's ok if it is configurable. and then it should do by default the same as the rest of the same search request does.
I find it odd that we modify the original source builder with the resolved indices names and replace what we originally had. Would it be possible to transport the resolved indices differently? I think we should serialize this new info separately and carefully handle bw compatibility around that.
can we move the resolution method out of `SearchSourceBuilder` too and also transport the info out of it as well? Like we do with aliasFilters map for instance? Does it make sense? Trying to keep `SearchSourceBuilder` as POJO as possible and have logic outside of it.
We also need a simple rest test, testing integration like we have for the other processors
I think @bizybot is correct - we probably need some of the failure cases in `ApiKeyService.authenticateWithApiKeyIfPresent` to have a `terminate` status instead of `continue`. If I'm passing an API Key over TLS, then it would be very strange (and hard to debug) if the authentication use the API Key right up until it expired and then suddenly switched to PKI auth.
I this this can simplified even further : https://gist.github.com/bleskes/0bf520c969eaa9542b1deefb4a8e1d5a (also note the test fixes, which are unrelated)
forcing execution should be a parameter for now imo - I know we want/maybe/potentially change how we deal with replicas and queues, but for now I rather not change semantics and have primary ops non-forced and replicas ops forced.
This seems weird since `retries` is an iterator for TimeValue, what is this going to print? the log message makes it seem like it's expecting a plain number for the number of retries
I think this can move to before the threads start - will be nastier
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
finally! its gone!
alright let's maybe make it a TODO then, just so we know the plan is to make it go away
Not sure this should be "Query" ð
I'd prefer to replace implementations of Streamable with Writeable or some other hack like having Streamable extend Writeable. I'm not sure what the right hack is though.
Forget the two interfaces idea. Just renaming the methods'd be good enough for me.
nit: `accuracy` instead of `Accuracy`
nit:`maxEdits` instead of `max_edits`
nit: `maxInspections must be positive`
These should all have sensible defaults rather than being null, as we have done with all the other builders. This also means we can remove @Nullable from all of the methods and add checks in there that throw an exception if null is passed in to make it safer. The defaults we currently use can be found in DirectSpellcheckerSettings.
I like the succinctness of this checks, wondering if java 8 offers anything to avoid having to introduce the utility class for this though.
hmm general question, why do we not use `"script_values_unique".equalsIgnoreCase(currentFieldName)`
To coerce, should be: ``` parser.longValue(true); ```
Please don't undo the migration to the diamond operator. :-)
we indeed need to fix this **and** `TermsParser`, `scriptValuesUnique` needs to be supported
don't you want to reset first and then set the parseFieldMatcher? :)
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
yeah, that was what I meant
I think this method is not quite right yet. A few observations: - if (unassigned) primary, then finalExplanation / finalDecision should be influenced by staleness of copy. In case of a replica, however, staleness does not influence allocation decision. - if replica, then we can still show that store copy is corrupt / has an io / error without influencing final decision / explanation - for the primary / replica shard allocator, corrupt / io_error is treated as no data. I think we can first calculate store copy (which just represents the status on disk) and then influence finalExpl / finalDecision based on that. Here is my go at it: ``` public static NodeExplanation calculateNodeExplanation(ShardRouting shard, DiscoveryNode node, Decision nodeDecision, Float nodeWeight, IndicesShardStoresResponse.StoreStatus storeStatus, String assignedNodeId, Set<String> activeAllocationIds) { final StoreCopy storeCopy; if (storeStatus == null) { // No copies of the data storeCopy = StoreCopy.NONE; } else { final Throwable storeErr = storeStatus.getStoreException(); if (storeErr != null) { if (ExceptionsHelper.unwrapCause(storeErr) instanceof CorruptIndexException) { storeCopy = StoreCopy.CORRUPT; } else { storeCopy = StoreCopy.IO_ERROR; } } else if (activeAllocationIds.isEmpty()) { // The ids are only empty if dealing with a legacy index // TODO: fetch the shard state versions and display here? storeCopy = StoreCopy.UNKNOWN; } else if (activeAllocationIds.contains(storeStatus.getAllocationId())) { storeCopy = StoreCopy.AVAILABLE; } else { // Otherwise, this is a stale copy of the data (allocation ids don't match) storeCopy = StoreCopy.STALE; } } final FinalDecision finalDecision; final String finalExplanation; if (node.getId().equals(assignedNodeId)) { finalDecision = FinalDecision.ALREADY_ASSIGNED; finalExplanation = "the shard is already assigned to this node"; } else if (shard.primary() && shard.unassigned() && storeCopy == StoreCopy.STALE) { finalExplanation = "the copy of the shard is stale, allocation ids do not match"; finalDecision = FinalDecision.NO; } else { if (nodeDecision.type() == Decision.Type.NO) { finalDecision = FinalDecision.NO; finalExplanation = "the shard cannot be assigned because one or more allocation decider returns a 'NO' decision"; } else { finalDecision = FinalDecision.YES; if (storeCopy == StoreCopy.AVAILABLE) { finalExplanation = "the shard can be assigned and the node contains a valid copy of the shard data"; } else { finalExplanation = "the shard can be assigned"; } } } return new NodeExplanation(node, nodeDecision, nodeWeight, storeStatus, finalDecision, finalExplanation, storeCopy); } ```
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
These asserts are totally fine (and helpful!), but I think as a future direction, it would be nice if we encoded the invariants about a decision into the data structures themselves, so we make it harder to create an illegal state. It's totally not work for this PR, only an idea for future direction :)
ok I remember now. The point of IndicesRequest and CompositeIndicesRequest is to return the indices that a request works against. when a request is composed of multiple operations, it should implement CompositeIndicesRequest. In this case delete by query reads from some indices as part of search, and writes as part of deletes. But what indices would it delete from? It is not possible to create a DeleteRequest that points to multiple indices, yet it is hard to predict all the deletions that will be performed as part of the request execution. I doubt that this request should implement CompositeIndicesRequest then.
I think I would still like it better as it avoids reverse-engineering a toString() impl.
Should we call remove before put? (Was just trying to think about what would happen if source == dest)
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
do we need == true ? :)
should probably be `Math.abs(value) >= 65520` rather than 65504. 65504 is indeed the maximum value but values up to 65520 excluded would be rounded to 65504
No. Floats that are between 65504 and 65520 will be rounded to 65504 however floats that are equal or greater than 65520 will be converted to +Infinity.
let's make it take a `float` so that we do not have to worry about null values
I mean in the code but just noticed there was one already
I see but I wonder if we should remove this method and simply accept Object and add a Fuzziness constructor that accepts Object instead
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Typo: "`local checkpoint`" -> "`local checkpoints`".
Typo: "`can not be update`" -> "`can not be updated`".
Nit: there is an extra space after the `&&` and before `inSyncLocalCheckpoints`
Typo: "`check point`" -> "`checkpoint`".
I'd recommend using the same syntax Lucene does: ``` bq.clauses().iterator().next().getQuery() ``` Just to follow their conventions
you can remove the validate call for now, we will fix all queries soon, I promise
if it doesn't have clauses we don't set the boost and ignore the queryName. I think it would be a bit more readable if we had two if branches, and the set boost and named query handling after the if which kicks in in both cases.
of course how could I forget about this, I pushed it 30 mins ago :)
I just realize that there might be a bug in the existing code already. We only seem to add the query to the named queries if it's a BooleanQuery, the other cases return early. Not sure, but we might want to change that.
cool stuff I didn't see that one!
could be a instance variable, as used in all tests
can we sometime check _gce_ ? also check illegal values and make sure it blows up correctly.
Note that this is different than setting a single property as it adds the inputs to the list.
The method was not named as a setter in groovy so this could be DSL-like. ie, usage looks like (notice the lack of equals sign): ``` noticeTask { licensesDir 'foo' } ```
oh sorry, I had missed that you used the filtered collection below
should we really return 1 if nothing was extracted? Let's return Integer.MIN_VALUE (or NEGATIVE_INFINITY once we are on floats or doubles) to make sure it won't be selected if another query could be extracted
It works for strings by using illegal characters. However here, ranges use a binary encoding and all values are allowed. So we should probably use `null` as a sentinel value.
is there always at least one element in this list? (I haven't checked whether we assert it somewhere else)
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
no need to break here
Change to Throwable.
maybe use `AbstractRestResponseActionListener` then you don't need the `onFailure`
Actually, ignore this, the rest actions are actually just forwarding to the transport actions
the printStackTrace should go away here
It is based around the class `Setting` and validates lots of stuff (among other goodness). Here's a short summary for your PR (untested): 1 Define a (list) setting as a constant in `IcuTokenizerFactory`: ``` java public static final Setting<List<String>> SETTING_RULE_FILES = listSetting("rule_files", emptyList(), Function.identity(), Property.IndexScope); ``` 2 You need to register the setting in `AnalysisICUPlugin`: ``` java public void onModule(SettingsModule settingsModule) { settingsModule.registerSetting(IcuTokenizerFactory.SETTING_RULE_FILES); } ``` 3 Retrieve values: ``` java List<String> ruleFiles = SETTING_RULE_FILES.get(settings); ```
I did not check this in detail but if `UCharacter.getPropertyValueEnum()` returns values > `UScript.CODE_LIMIT`, then it would break your code that populates the `breakers` array below. In that case I would add an explicit check and throw an exception.
Ok, then it's fine.
This whole loop reads fairly low-level. If config files can be considered small, we could just read them much more concisely with the Stream API (untested): ``` java String rules = Files.readAllLines(path) .stream() .filter((v) -> v.startsWith("#") == false) .collect(Collectors.joining("\n")); ``` All the low-level stuff is gone. But this relies on Java 8 features and will only work on master.
We can rely on auto-closeables here (i.e. we could use just the try-with-resource statement). Not necessary if you use my suggestion with the Stream API.
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
Heads up when you merge with master, I just merged another test where the original test query is modified assuming it is json, so that will need the same treatment as you do here I thinkg: https://github.com/elastic/elasticsearch/pull/14255/files#diff-9dc314365d49d84bff0645c2f9dfd7adR356 (and Overwrites in HasChild/HasParentQueryBuilderTests)
right I had missed that previous check, sounds good then
I think this should be strict too. The problem is that the not query has some alternate version that uses deprecated syntax. I think that should be moved to a separate test like you did with recent PRs.
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
I think filter and query can never be null here? not sure whether we should validate this here.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
I think we can simplify here and print everything out, default values included, that's what we went for in all of the other queries too.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
Is this extra method needed? I would combine it with the previous one that seems to be its only caller atm.
I get a warning for a missing GEOMETRYCOLLECTION case label here. Even if that shouldn't be possible, maybe add this to the switch (and/or a default case) that throws.
I think this can be extracted into something like `float[][] lineToFloatArray(Line line)` since it appears 3 times in this file.
same problem as above I think, only that unmatched closing brackets will create holes here.
Would it make sense to move this method to some SpatialUtils utility class? I feel like it's pretty generic and we might find some other ways to use it. I think I would also replace first three doubles with Circle. And we should figure out what to do with the radiusMeters parameter in Circle since it is not meters in case of `shape`, but this is a topic for another PR.
I wonder if we should start already sharing some common code between our BaseQueryTestCase and this class....wouldn't want to complicate things though. Also our base test class in not in master of course so that woul already complicate things...
Minor problem when I run this: test complains that it has to call super.tearDown().
I would probably take out the string comparison, once we know that the queries are equal, I think that's enough, we shouldn't test other methods on them, it's out of the scope of this test.
I'm about to change this in #22586 so that DeleteResponse/IndexResponse/UpdateResponse don't have to repeat all these checks. There will be a assertDocWriteResponse() method, and here we only have to check for UpdateResponse specific fields.
now I see what you meant yesterday saying that we have to parse meta here
This logging statement has a `[{}]` but no argument to fill it
Out of curiosity, could we do all the types in parallel instead of blocking and waiting for each type to complete before moving to the next type? (It's probably out of scope for this PR, but I'm wondering for a future enhancement)
we used to protect agains null here -> I think we should still do this? I'm thinking about failures that happen during index deletion..
`engine failure` -> shard failure
unkown -> uknown
was the answer yes? :)
Pre-size the buffer? ``` java final String index = getIndex(); final String type = getType(); final String id = getId(); final StringBuilder location = new StringBuilder(3 + index.length() + type.length() + id.length() + (routing == null) ? 0 : (9 + routing.length())); ```
not sure, but should we make the location available to java api users too? Transport client is still a thing in 5.x and this way one has to build the location by passing in the routing value. Should the location rather be a field in the response object? Not sure though as it becomes a header in the final rest response. maybe it's ok this way.
I guess you would have to carry the routing around in the response, serialize it etc. maybe it is not worth the trouble.
This is _much_ better.
What if this.docCount was already -1? then it should stay -1 right? (in the else case here)
maybe it is a matter of style, but i think its easier to handle the exceptional case like a guard up front: check stats.docCount == -1 and set to -1, otherwise sum. this is not really important to me.
Weird markdown seemed to silently remove some of my text...I was trying to say `FieldStats<java.lang.Long>` (which is what I think you meant by your last statement).
can we use getters here like `getNode` `isCanceled`
This needs to handle the -1 case.
I think I would parse headers more precisely into a `Map<String, List<String>>`, it shouldn't be a lot of code.
you are still casting here and eventually calling toString on Objects. What I meant is manually parse these headers instead and make the parsing code a little more accurate. That also won't require to go through the map once again once parsed.
Maybe we should at least parse List<String> given that we have that in some subclass? I wouldn't extend support for objects etc. here, but just for arrays of strings. that is what the addMetadata supports at the moment. I am not talking about supporting anything that may get printed when overriding metadataToXContent.
is this needed here? I think it does something only when the current token is start array or start object.
You can use `XContentParserUtils.throwUnknownToken()` (that would throw a ParsingException instead but I think it's appropriate here)
We can remove the `!` if we reverse this if statement, so ```java if (difference.isEmpty()) { status = RestStatus.OK; } else { ... the error stuff ... }
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Under what circumstances would the mappings for an index be null (as opposed to an empty map)? It seems the default for `GetIndexResponse` is to always have an empty map for mappings (and aliases and settings) and it would only get assigned to a non-null map.
is this check mutually exclusive with the above? If yes I would prefer an `else if` to denote that, otherwise the `errorMessage` should be checked and a `, ` should be appended first.
nice! I like this. super helpful for keeping track
oh, woops. thought I counted right. sry
do we want to check the phase/action times since those are meant to change
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
super nit: I tend to like validation to be first
not was indeed my point - we don't need to task what shard allocation does with the shard failures, we just need to test we told it to fail the right shards. But this is nit picking :)
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
Hmm, not sure how I feel about that.
same here these strings are only used in one place just use them directly and trash the Fields class
Or we can let poorly formatted values pass through and throw exceptions at the end if values are missing, similar to how we do for queries
obscure error message... let's start by `"could not read alias fields filtering from xcontent. expected an object but found [" + parser.currentToken() + "] instead"`
use `assertNoShardFailures` here please
I think it'd be nice to have an assertion on the text of one description just so we can look at it.
It'd be nice to be sure it contained that `not_found` wasn't found.
Now I get it! I had to dig around a bit in `ScriptService` to understand what was up. Now it makes sense.
I really dislike this style of variable reuse in our tests. If I use my IDE to navigate to the definition of this variable I end up on a line assigning a value to this variable that is removed from its current value. This hinders readability, especially in longer tests. Letâs avoid introducing it here, we should be moving away from it.
``` if (Double.isNaN(v1)) { return Double.isNaN(v2) ? 0 : 1; } ```
You didn't introduce it, but seeing this line again reminds me that this is buggy if Long.compare returns Integer.MIN_VALUE, which is legal :) So it should rather be `Long.compare(o2.getDocCount(), o1.getDocCount())` (without the minus sign)
just beware that Long.compare is Java 1.7 only, you might want to use Longs.compare from Guava instead when merging to 1.x
Can you throw something else? It just makes me uncomfortable to throw AssertionError.
spaces after '//'
same here, I think it will be easier to read with "shard state persisted despite of persist=false"
missing { } :)
I think we only have general IT tests ci runs. This class is not wel tested :(
can we name this selectNewPathForShard? , to contrast it from `loadShardPath` (findShardPath sounds to me like go and find an existing shard path).
Instead of acquiring the shard lock for a second time, I would prefer if we would do it once, and move this call under that lock and just rename `tryOpenIndex` to `tryOpenIndexUnderLock`, removing the locking mechanism from it. Same thing for `TransportNodesListShardStoreMetaData`. You can then also remove the `ShardLocker` interface, which irked me for a while.
this keeps bugging me :) we should something on the executor as well....
can we add something to indicate where this comes from? something like unexpected error while processing cluster state version [{}]
hmm at some point we need to apply backpressure... not sure if we need to do it in this change though
long live java 8
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
Simon added a fancy resolveIndex method
can we configure the delayed allocation to not be the default (`1m`) but something high enough to trigger what we are trying to fix, like `200ms`? This will speed up the test.
ver -> version
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
this can be removed now
we should also catch `NoSuchFileException`
hehe. There is already ensureOpen. so this can go away... (simpler state management --> easier to understand). but I'm good if you want to keep it.
I wanted to remove the `allowCommit.set(false)` here with an ensureOpen at the beginning of the method. Only saw later it's already there. No doubles.
maybe replace this with ensureOpen in the beginning? feels cleaner to me
since we open the translog before the writer now - can we use the open translog for all this information rather than static reading it? this will make sure that we use something that went through all the right validations.
I think we can reduce the scope of this change by exposing a resolveShardId method that resolves index,type,id and routing to a shardId. And then we don't need to touch these. Also, I know that type is not used now, but why not pass it? is there a place we don't have it? I hope we can back port this change to 2.x, so having type here will reduce the change.
OK. just saw the shardId() method. Good. the rest still holds ;)
it's used in 2.x and asked Areek to keep it to limit the scope of the change as I hope we can back port it.
> it's used in 2.x and asked Areek to keep it to limit the scope of the change as I hope we can back port it. ACK.
I'd just use the Id really
I wonder if we should make this a hard exception, potentially in the AllocationId constructor. When we start using this ID, a null value will create havoc in other places and will be hard to debug..
Nit: Change the casing of `CheckPoint` to `Checkpoint` in the method name.
Assert that the current thread holds the lock on `this`? The results from `ObjectLongMap#indexOf` remain valid only if no one else is mutating.
Typo: "`check point`" -> "`checkpoint`".
Perhaps annotate this one with `@Nullable` since it's the only one that can be null here
we can make this a function to `List<MergableCustomMetaData>` - we alreay check with instance of in the implementation of it.
I don't think you need an if else structure here? you can set the first and iterate over the rest? This can be simplified
nit: can we have this ugliness in a getClusterService(Node node) method? we use it in `doStart` as well.
this can be out of if now.
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
sweet! and we should have REST tests for them which you haven't removed, so everything should be fine indeed
can `aliases` be final as well
oh sorry I see that you don't register the transport action when ingest is off, sorry I had missed that.
this makes me wonder: if a node has node.ingest set to false, for sure no processors should run, hence simulate should be off and IngestDisabledActionFilter should throw exception when a pipeline_id is used as it does now. But how about crud actions for pipelines? One has to go to specific nodes to store them, that have node.ingest set to true? this may not be needed, as those are just index, delete and get operations that any node supports...it's like making client nodes reject index requests, they can forward them to the proper nodes, no problem with that.
Technically speaking the doc `type` in urls is being deprecated in 7.0. The general pattern we're adopting is it's not flagged as deprecated if you also pass an `include_type_name=false` along with the request. I can pick this up as part of types removal work if you want to leave that out for now.
I'm fine with logging "allocation id [null] of shard" . Will save on the if :)
you are right. Brain circuit breaked - interpreted the || as && . All good.
highestVersion = Math.max(highestVersion, nodeShardState.version()); is faster and cleaner
did you run into this being a problem? how can we open an index that was created before 5.0.0 and never had insync replicas but does have allocationId? the only thing I can think of is a node network issue during shard initialization. I'm wondering if we need to optimize for this and no keep this code simple (i.e., demote shards with a lock exception)
can the aid matching be the implementation and the rest just assertions ? it should be enough
Ok fair enough, Hadn't considered the settings aspect of this.
It might be a good idea (possibly in a different PR) to have a method on `ScriptEngineService` called something like `getSupportedScriptContexts()` which each implementation can use to define what script APIs they support. I imagine there are/will be other language that don't support some script APIs and this would not only allow them to use this too but would also remove language specific code form the ScriptService, which should probably remain language agnostic.
Maybe something like: The bucket can "overflow", in which case the excess capacity is just "spilled", rather than saved up. So it never holds more than a minute's capacity.
ok thanks for the explanation.
you can use MustacheScriptEngineService.NAME
nit: extra line
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Do we want to default to random salts here ? If I understand the primary use case correctly it is to anonymize fields for analysis which would prefer the same input values to result to the same hash. (e.g. hash(jakelandis) always results in "adslkjv983d")
I think this can be simplified into ``` if (obj instanceof Map || obj instanceof String) { valueWrapper = Map.of("shape", obj); } else { ```
Would it make sense to move this method to some SpatialUtils utility class? I feel like it's pretty generic and we might find some other ways to use it. I think I would also replace first three doubles with Circle. And we should figure out what to do with the radiusMeters parameter in Circle since it is not meters in case of `shape`, but this is a topic for another PR.
I prefer my way but have asked @jasontedor to chime in.
// must use exception that is not **ignored by** replication logic. (also 2 more occurrences of this in IndexShard)
maybe put this check before the primaryTerm check
same here re enumSet.toString
we throw the exception and thus take care of the interrupt. We don't need to set it...
something is wrong in this sentence :)
Maybe at this point the revival process should also make up a sorted list with all of the dead nodes and pass that one to the selector, although we will try to revive only the first one in the list? Not too sure though, just a wild idea.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
nit: shall we rather initialize to empty and replace this with an empty check? I see that empty is currently not an option anyways.
right, other encodings have no use here. Sorry for the holdup...
+1 to hardcode UTF8
is empty the same as {} ? I never know if start object and end object should be here or handled in the caller method.
cool thanks for the explanation!
maybe add the set of wrappers to the message so taht it would be easier to debug
I don't think we need the constant.
Also `zen2` is only available in â¥7.0 so `onOrAfter(6.5.0)` looks wrong.
zen2 is the default. Why is this change necessary? These tests are probably already running with Zen2 unless explicitly disabled in some place
Unless your node is named "1", this is not a valid configuration. Please have a look at the [docs](https://www.elastic.co/guide/en/elasticsearch/reference/master/modules-discovery.html) or reach out to @DaveCTurner or me on how to configure this. Note that if your tests are running a single node in development mode, then no configuration should be necessary.
For backporting to 6.3, I think this needs to be changed to 7.
I see, that is hideous. ð¦
Extra space is extra.
I'm okay with this.
you evil person :)
Did you confirm we sometimes hit this and not just ACE? (The "indexed" CountDownLatch should make it likely...)
today we ignore the mentioned exception in the engine, where its actually a real problem. We managed to find the entry in the transaction log, yet failed to read it, this can return potentially the wrong "latest value" for get. The code in the method to retrieve the source should not fail with IOEXception unless there is a real problem here, and this should propagate I think to the client.
Hurray no more weird `while (true)` loop
I think this should be named `newView`, otherwise it's ambiguous whether it returns a new or a current view
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
Another `_` java 9 will be mad at
Correct [equals](http://docs.oracle.com/javase/7/docs/api/java/lang/Object.html#equals%28java.lang.Object%29) implementation supposed to be reflexive. In other words the following test should pass: ``` StoreFileMetaData test = new StoreFileMetaData("test", 0, null, null); assertEquals(test, test); ``` Maybe `equals` is not a good substitution for `isSame` here.
missed that. Nanos is strictly speaking better, but not a biggy.
Since this is only going to be used in tests, I think we can get away with: ```suggestion return Objects.hash(maxSeqNo, localCheckpoint, globalCheckpoint); ```
I'm good with one decimal point with the caveat that this endpoint really should not be being indexed.
No matter what precision you pick will have that problem, for example rounding `89.99` to one decimal point will round to `90`, and so on.
I think we should not execute these writes directly here but extend ESIndexLevelReplicationTestCase#ReplicationAction then run them via the infra of the new action (see ESIndexLevelReplicationTestCase#IndexingAction).
you can use `ActionListener.wrap(r -> handler.accept(r.getLocalCheckpoint()), errorHandler::accept)` instead
you can use `ActionListener.wrap(handler::accept, errorHandler::accept)` instead
I am wondering if we should add `buffer` (size or operations) to the Status object? We can do it in a follow up if you are okay.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
The `routingAllocationWithOnePrimaryNoReplicas` method no longer needs to take a `Version` parameter, would be nice to get rid of it.
we can have three methods here, but all of them could just share their code by calling a common method `getNoDeciderWithForceAllocate(Decision)`
Ah nevermind, I see where we check it above :)
solely based on names, hard to distinguish from `testRebalanceNotAllowed`
I don't think you need the `Integer.toString` bit.
We can allow flush here, I think.
I might do `assertThat(totalShards, greaterThan(1));`.
I'd name the shrunken index `index + "_shrunk"` or something. I like that the indices are all named after the test that uses them.
I really dislike this style of variable reuse in our tests. If I use my IDE to navigate to the definition of this variable I end up on a line assigning a value to this variable that is removed from its current value. This hinders readability, especially in longer tests. Letâs avoid introducing it here, we should be moving away from it.
we should include `e` here, otherwise we lose the cause of the configuration error.
please log the exception here as well we really wanna see what was going wrong
I don't think it's important for now
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
ok...but client depends on the transport service anyway no? I think I don't get it
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
I understand this is the oversight you've mentioned
should be 6.3
can you remove this empty line? :P
We typically do this light weight coordination on the same thread. I.e., Names.SAME . This does nothingother than spawn another bulk request. This will cause a new thread to be spawned as we don't do anything else with the bulk pool on the client. To be honest, I don't think the transport client should have so many thread pools. I'll open a different issue for that.
I guess `BULK` is the right thing here. Usually BULK is used on the receiving side but these are the same in spirit as its just coordinating things.
I'm not sure why, but the usual convention for freeing resources when the request is done is to have a method called `finishHim`. Mortal combat reference? Anyway, the nice thing about this convention is that it gives us a place to look for resources to be freed. But above I mention reusing a thread pool of some sort anyway.
> This method is private and only ever called from a single thread so there is no need to recheck. I'm just weary of having the failure handling case so far from the success case. I figure its harder for someone to break it if its closer together.
Ok - I see where it is called. These checks are a bit too distant for my taste.
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
For immutability: ``` this.sources = Collections.unmodifiableList(new ArrayList<>(sources)); ```
If the constructor is modified, this method won't be needed anymore.
oh boy :)
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
We should have access to the services on the coordinating node, and they should be usable there, so I think this will come out in further refactoring.
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
no both Request and RequestBuilders are java api. one can choose which one to use. you can always do client.search(SearchRequest) without going through the builder.
ok thanks for the explanation.
you can use MustacheScriptEngineService.NAME
the start cluster does this.
we have a new awaitNoMaster util method
maybe just start a unicast cluster for now
We can call it suspend if you want. To me LongGC is easier to remember as it is what we talk about all them time.
Can we add a LongGCDisruption variant that allows using the startDisruption and stopDisrupting to control the GC? These extra params feel clunky (and yeah, I probably did it before too :))
I'm on the fence as to whether we should only do this on non-realtime get. Real time gets don't really relate to refresh cycles (they force a refresh if needed). They are already "efficient" in the sense that they only refresh if they need to (i.e., there's a pending doc change in the version map).
should remove the "force:[{}]" in trace logger. @s1monw
I wonder if this case distinction should be part of ReplicatedOperation.
long live java 8
my thoughts too :)
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
Might be nice to add a check for existence of these parameters for completeness.
It doesn't look like you are using any of the regular `getThenSet` features of the AtomicReference, can this just be a mutable variable? (Not really a big deal either way)
that is unnecessary - print that automcatically taht we start a new test
I find that `equalTo` is almost always a bad choice. In this case I think `assertThat(cancelTaskResponse.getTask(), hasSize(1));` will do the same thing but have much better error reporting. That way you get to see all the tasks when there are too many. Same for the above assertion.
s/payload is/payloads are
s/payload is/payloads are
Can we remove the lat() and lon() methods? We don't want people setting lat but not lon so it don't makes sense (IMO) to allow them to be set separately
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
I think if we get in that other PR I just reviewd we can reuse here the new method that you introduced there? :)
We can avoid arraylist resizing by creating it with `diff.different.size() + diff.missing.size()` and then doing `addAll` for the diff parts
Maybe it could be something like: ``` if (bytes.size() > BigArrays.PAGE_SIZE_IN_BYTES) { bytes = bigarrays.resize(bytes, BigArrays.PAGE_SIZE_IN_BYTES); } ```
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
if the size was previously less than PAGE_SIZE_IN_BYTES (possible with the contructor that exposes a size), this will actually grow the array (potentially going from a simple heap-allocated byte[] wrapper to a recycling instance)
minor nit: "int he" -> "in the"
This situation feels very fragile to me. It means in the future if we do want a settings instance here because we want to control fine-grained logging settings for a CLI tool, we can not without accidentally reintroducing the problem.
This thread can leak and fail the test, I think that you need to clean it up (join on it in tear down).
and use the constant here
this class could be made `final`
While I understand why passing `Plugin` here is safe, after thinking about it a bit, I think I prefer replacing the `Plugin plugin` with `String source` to give the flexibility to choose whether this logic should be applied on the Plugin itself (using `onModule` or `processModules`) or on a different `PreProcessModule` (that latter feels more natural to me)
My concern here is if a user sets the budget to `H` headers and `B` bytes because they can not handle more than that (e.g., the common case being a proxy) then we have to subtract a header (or possibly many) to stay under the `(H, B)` budget after we include the missed warnings warning.
I think it's more useful if we spend the last of the budget saying the list is truncated, in anticipation of a time when someone forgets that the list they're looking at might be truncated and makes a poor decision on the assumption that it's complete. These excessive warnings are often repetitive, so the specifics of the 62nd warning seem less valuable to me. (Not that it shouldn't be in the server logs too.)
I think it'd be useful to get one more warning when the limit is hit, saying that there were more warnings but we dropped them because `http.max_warning_header_count` is set to `<n>`, and similarly for the size limit.
I think that we want to log *each* time that we drop a warning header, not only the first time for a given request. Also we can be more precise than the current implementation which says one or the other condition is met, but we always know exactly which condition it is so we can help the user more by letting them know.
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
Is the version needed? I don't see it being read here.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
`if (serializedStates != null) {` is no longer needed
use `terminate(threadPool);` (this method is in ESTestCase)
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
same here, just `this.charFilters.add(new NameOrDefinition(charFilter));`
here too I think we should just do `this.tokenFilters.add(new NameOrDefinition(tokenFilter));`
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
We should log the the failure here if the close fails
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
`engine failure` -> shard failure
This is logic that I think should go into ReplicatedOperation.
nit - the old logging had the structure "componet][node][shardId] message " which we try to use for all shard related messages. I think we should keep it.
By keeping track of contexts in 2 different data-structures, I think you are potentially introducing race conditions, eg. if a clear scroll action is issued concurrently with an automatic release of the context due to the fact there are no more hits to process.
I think this should be a concurrentSet to be honest we remove stuff from this under locks and I don't like the runtime otherwise.
can this see `unregister task for id: [{}]`
nit: can we rename this to `getTasks`
can we make this ret val unmodifiable please
this can go back to boolean if we move back Settings to boolean too
this can go back to boolean if we move back Settings to boolean too
we don't need `== true`, I think we use this explicit version only for negations, instead of the `!`
given that we have almost proper setters here that return void, do we really want to make them return this? no strong opinion, just thinking out loud
you can remove the validate call for now, we will fix all queries soon, I promise
can we fold this into ClusterHealthResponse? that way we can test this as well as part of the unit testing.
can we do: ``` Java if (addFailureIfIndexIsClosed(updateRequest.index(), updateRequest.type(), updateRequest.id(), bulkRequest, responses, i)) { continue; } ```
I think it is not clear here exactly when IndexMissingException is expected to be thrown or not. I would rather move the if on top and have different asserts path based on that. FOr the expected exception one you can then do: ``` try { //do something fail("shouldn't get here"); } catch (IndexMissingException e) { //assert on exception } ```
I think we can remove this `if` completely, cause we call the same method given the same input at the beginning of the method, this condition will never be true here.
Actually, I did some digging, this if was introduced with #6475, and I think its purpose was to check that state of indices after aliases resolution. This is a bug that we should address on a separate issue, that should be about index state checks when resolving aliases, since it seems we don't check that at all at this time.
I don't think this test is needed. `testSpanMultiTermQuery` does the same thing.
nit: missing space
all these random values need to be saved out of the loop...you know what happens otherwise? :)
shall we move this method to a new QueryTestUtils class or something? I see it being used in other tests in the future and I am not sure it belongs to the test base class
From first glance to me its not clear why all these assertions are the same. When is this not the case and might it be easier to just test those cases? Not sure because I don't know how the resolution works though.
I might make something like ``` private void expectMissingBodyError(Matcher<String> responseMatcher, ThrowingRunnable exec) { ResponseException responseException = expectThrows(ResponseException.class, exec); assertEquals(400, responseException.getResponse().getStatusLine().getStatusCode()); assertThat(responseException.getMessage(), responseMatcher); }
Can we keep the line numbers in the test assertions? I think they are important to maintain.
++ thanks for doing it this way, I had thought it was new stuff in the beginning. looks good as is.
`expectedType.cast(e)` should remove the need for the unchecked suppression.
Is there any advantage in randomizing these? I assumed that since unit tests are fast to execute, we should go ahead and test the obvious paths all the time so that failures aren't flaky.
maybe make if final
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
ok fair enough
maybe also test a nested conditional setup? (So have conditional and then another conditional in the matched or unmatched list)
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
if the size was previously less than PAGE_SIZE_IN_BYTES (possible with the contructor that exposes a size), this will actually grow the array (potentially going from a simple heap-allocated byte[] wrapper to a recycling instance)
Then I'd rather remove this method, because if they start using it, it will have surprising behavior (I would never expect memory to be allocated in a method called `reset`)
I think I would remove this constructor, seems like it's only used in tests and we can replace it with empty constructors + setters
sounds great thanks
we can use Writeable here instead of Streamable so fields can become final and default constructor can go away
This does not necessarily need to be within a static initialization block.
Usually, the static variable initialization is done outside of the static block. Though this is not a strict pattern, I just don't see why you chose to initialize the value here instead of at the declaration.
ok so I try to think about situations where this doesn't work.... the missing / hasvalue filter can be expensive though but I guess we should just make it fast for that case and expose the filter on the field data... I like the idea... ok fair enough.
We can save object creations here by making the ByteArrayDataInput final and using `ByteArrayDataInput.reset`.
`ParentFieldMapper` sets this to `IndexOptions.NONE`. I wonder if we should that too here? Upside of adding an indexed field is that somone doesn't need to use the `parent_id` query, but on the other hand it does increase the index size and I'm not sure how often one would search by this field. With `_parent` field the field was made a non indexed field with the idea in mind that only a few would ever use _parent field for plain querying.
can we add the index name, shard id and the paths looked at as the exception? it's especially interesting because needsUpgrading checks for the state folder. Also, do we care about nodes that have the state folders but no data in them? should we fail the node in that case? if so, may change the message to say "no shard state found in any of [FOLDERS], please check and remove them if possible".
I think an absurdly high limit could still be helpful? (in a follow-up PR)
I wish that we did not have to go from MapperScript to IndexTimeScript, and rather reuse the same concept. I still wonder if this could be `void executeScript(SearchLookup, LeafReaderContext, ParseContext)`? We could make the notion of scripted field known to FieldMapper, let MappingLookup collect all mappers that have a script declared, then each one of those has the execute method called. That way you can also ensure the same behaviour once you add this functionality to other mappers? This suggestion goes against another one I made on making OneTimeFieldExecutor implement IndexTimeScript. MAybe with this suggestion IndexTimeScript could go away and we would have to see what to do with the one time executor.
I can see how having two methods is not fantastic, and why you had done it differently before. I had envisioned script as a member of FieldMapper directly, but we are going to see if that is possible once we add support for script to other mappers. The type of the consumer will make it possibly harder to share the impl but we'll see. I am happy though with the execute method, I find it much clearer than returning an executor like we had before, because it is evident what it does and easier to trace.
I think you are missing a `\n` here.
Are there any calls to this version of findTemplateBuilder with matchType `string`? Or `findTemplate` below? very confusing how we have so many public variants of this method...
could these three methods somehow be in the base test class, at least partially? what I am looking for is avoiding copy pasting when writing new tests, and possibly not forgetting to cover important scenarios.
I think that we need to guard against overflow here!
This is not quite what I think of as exponential backoff. The problem that I see with an implementation like this is that we can have a thundering herd problem. If there is some failure that causes a bunch of tasks to simultaneously fail (e.g., say that we have a bunch of outstanding fetch tasks waiting for a response, and the network connection breaks, failing all of them), all of the retries will keep waking up at the same time, itself potentially causing issues due to a herd. Typically it would be that there is a random component in exponential backoff, to avoid this herding. As a first approach, what I suggest here is: choose a random value k between 0 and 2^number of retries - 1. Then retry after k * delay seconds. We can cap this at max retry delay.
+1 to the statement and other problems previously mentioned (a network hick up will cause a failure for each outstanding request incrementing the counter by more than it can take). I asked Martijn to think about the retry counter as a follow up in order to reduce the scope of this PR.
I think you can write this more simply as: ```java LOGGER.debug( () -> new ParameterizedMessage("{} error during follow shard task, retrying...", params.getFollowShardId()), e); ```
these are covered by isShardNotAvailableException
Not sure why we get this `if`, I might be missing something but I thought we never update the listed nodes, thus they are always going to be the original discovery nodes with minimum comp version.
Nit picky: if we capture the node name from the start async we can do `internalCluster().getInstance(DiscoveryNode.class, blueNodeName).id()`
can we remove this try catch? let the original exception just bubble up...
can we configure the delayed allocation to not be the default (`1m`) but something high enough to trigger what we are trying to fix, like `200ms`? This will speed up the test.
I guess it's because the async shard fetch logic - the shards are not assigned when the call returns.
I don't think that we need such big docs, 100kb seems a lot still even if it's the upper bound.
maybe we should also decrease the chance that we add another child object compared to leaf fields.
Would it make sense to create a new method in `Randomness` with the following signature: `public static Random get(Settings settings, Setting<Long> setting)`? Now we "unpack" the key, just to get the settings in `Randomness` the old way again.
strictly speaking, this doesn't need to be volatile. We update it under a lock which guarantees the visibility of the changes.
can't you just use `settings.getAsVersion` here? and on the other end you just use `builder.put(ASSERTING_TRANSPORT_MIN_VERSION_KEY, version)`
should this be "not mounting...consistently" or "mounting...inconsistently"? But I would think not the current double negative.
These should all be wrapped in `<pre>` or `{@code ...}`
Also we should wrap the `-` in `{@code -}`
> we still want to use an beta over an alpha There shouldn't be anything needing to choose a beta over an alpha? There should be nothing using any qualified build to check bwc.
> The version class is now used more broadly, including in figuring out dependencies ( as it's string value is set as project.version which is then used when considering dependencies ). There shouldn't be any dependencies on a qualified version, so there should be no need to serialize it into a string value. > I don't think we should remove the qualifier from the version right now, we should eventually better express requirements for a version used in bwc Why would we keep something around that is unused? I think it only adds to confusion in a class that is already difficult to under (our gradle's Version class).
writeString would fail if the default timestamp is null. So I think we would also need to write a boolean to tell whether it is not null? (and an integration test that would exercise serialization)
can we maybe just pass null to `out.writeOptionalStreamable` and leave the impl details to that method
I understand this is the oversight you've mentioned
should be 6.3
can you remove this empty line? :P
it is to me, buy hey, taste :) up to you.
`}` and `else if` should be on the same line
++ on removing this catch. Not true any more
I find it confusing the we have the same field names for this in both ReplicationPhase and PrimaryPhase.
actually I just got a bit confused because both classes are in the same file...
I'd prefer to have translogId.v2() set to null, as opposed to be indentical to next. To me it would be clearer, but if you feel differently I'm OK with leaving as is.
hmm maybe name it `markCommitted(long translogId) throws IOException` I think it sholud be IOException here
I think we can just read the uuid of the generation associated with the checkpoint? I think this is overly fanatic, no? (I want to make a more complete validation at one place in a different PR - complete in the sense, check multiple lucene commits and multiple generations.
nit: extra line
operation can be `final`
Man this feels like a mess compared to ObjectParser. We can't do anything about it in the middle of this PR though. Just makes me sad.
replace match here too
maybe add assertion here for `(min == null) != (minAsStr == null);` and same for`max`.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
+1 on removing the `Void context` from all methods. The `declareInnerHitsParseFields` is already complex to read I think, that won't add much.
you can remove the validate call for now, we will fix all queries soon, I promise
super minor nitpick: lowercase the message? s/Supplied/supplied seems to be a convention in our codebase :)
Does this need to be public, or can we make it private to this class and force everyone to go through the String version of the `parseBooleanLenient`? (I did a cursory glance and didn't see usages, but it's possible I missed some)
I think `"*".equals(defaultField)` should use `Regex.isMatchAllPattern`
I don't believe this is only kept for BWC. You use this to parse `_source` above.
I don't understand here what you mean by synthetic variable. If you mean the two ENulls, the analysis and writing would be contained to only compile-time.
I don't think you can use this method because it won't necessarily store the type correctly since we do the slots ourself to avoid trash being on the stack with variables scopes and such. Instead you'll have to use writer.visitVarInsn(asmtype.getOpcode(Opcodes.ILOAD), slot);
@nik9000 Robert and I had a long conversation about boxing early during development. We decided to eliminate it as much as possible because of serious complications involving promotion and casting (which as you know is already very complicated). There's only a couple of places auto-boxing happens -- arguments to methods because it would be hard to force a user to cast something to an object to add to a list and with anything related to def type. Otherwise, there is no auto-boxing in painless. Perhaps, this should be the same for consistency? Sorry, I sort of missed this yesterday thinking about the cases, but def should work anyway already, otherwise primitives don't make sense here since we don't allow Integer to become an int anywhere else. With the def type we deemed auto-boxing to not be necessary anymore, and ideally something Java would've hidden from the user to begin with. It also happens that users can call boxed methods on unboxed types to further eliminate the need to ever have a boxed type.
@nik9000 What do you think about this proposal for now? What if for the null safe operator (?.), if the guarded type is a primitive we disallow it, and then for the elvis operator (?:) if the lhs is a primitive we disallow that too. I honestly don't think anyone will notice because currently there is no way to get a primitive out of a field from a non-static type (nothing exists in the whitelist afaik), and I would argue in the case where you want a primitive out of a call, it doesn't make sense to have the receiver be a boxed type. You would still have to check to see if the receiver was null afterwards anyway. For most cases the type will be def and the auto-boxing will just happen anyway. Both of these operators can be very useful for def types without needing to have them do magic for primitives. I would hate to not have them because of boxing issues when it's improbable that users would run into them. I would think the average use case would be something along the lines of list?.list?.map?.get(value)) in which case this operator is awesome.
Two test requests: What happens when you have something like `Integer a = Integer.valueOf(0); int b = a ?: 1;` `Integer a = Integer.valueOf(0); int b = a ?: Integer.valueOf(1);` I believe these are expected to be ClassCastExceptions where Integer cannot be cast to int, but I'd like to be sure.
might also want to add a toString implementation on ShardRecoveryHandler or add the shard in question to the assert.
same here - In think we should add the shard info either to handler or to the message.
We should catch any exceptions during the cancel and log them so we can continue to cancel any other handlers? Otherwise the first exception will cause us to bail
maybe just : ``` final ShardRecoveryContext shardContext = ongoingRecoveries.computeIfAbsent(shard, s -> new ShardRecoveryContext()); return shardContext.addNewRecovery(() -> createRecoverySourceHandler(request, shard, shardContext)); ```
can we move this to ShardRecoveryContext and pass request and shard to addNewRecovery ? this way won't need all the supplier fun. Might as well rename the add method here to addNewRecovery too? or maybe `registerRecovery`? (I don't mind much about the names, just a suggestion)
I always wonder if we should use the PROTOTYPE constant here instead, cause that is what we need I guess. If so we should change all other tests accordingly
same question as above
you can replace with //norelease so we don't forget but at least you can get this in while we fix this problem in master.
here too, toQuery might return null, not sure what happens
how much work would be to "decode" the values and expand the test? I am wondering if it's worth doing or not.
I think the naming is fine. This feature as described in the issue is about not counting tokens filtered from the token stream. This is what `enable_position_increments=false` does and I think it's all we need to do here. If your analyzer adds alternative tokens to each position they should not alter the final count since we're looking for the number of tokens in the original text.
If we don't count token with 0-increment this should be equal to 2
I don't think it should be static
I think we should close the analyzer if tokenizerFactory is not null. Otherwise, it is never closed. ``` finally { if (tokenizerFactory != null) { analyzer.close(); } } ``` (this looks like a pre-existing bug, it was not introduced by your PR)
This could be `Strings.hasLength(tokenizerName)`
Nit: add a space between `if` and `(`
Too bad we don't know if this task should be persisted in the first place. That would have simplified the whole thing to start with.
I think this is a left over.
I would prefer not to use `ExtraPropertiesExtension`. Let's add our own extension instead. We would need to go trough build scripts now, but having that extra namespace would make it clear when reading the build script where these are coming from, and there are fewer chances to clash with something in the build script ( thinking about users of build-tools here).
maybe it is a matter of style, but i think its easier to handle the exceptional case like a guard up front: check stats.docCount == -1 and set to -1, otherwise sum. this is not really important to me.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
Okay, doesn't matter if the builder only outputs verbose version as long as we support the other one still.
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
can we remove an "elasticsearch_" prefix if it exists, I think it will be cleaner? down the road, we can also remove the specific ElasticsearchIllegalArgumentException and such, it was added historically to get the correct status code, but now we also identify IlleglaArgumentException and return the correct status code, so the need for those became irrelevant.
I think `writeGenericValue` handles null values, so you could omitt the surrounding check.
maybe we should have a constant for it
This isn't quite right. Wrap the ends with checks in parentheses.
Oh, I misread it (mobile phone, sorry). The only thing that needs to change then is file:// -> file:/.
Also I think it is one slash only, annoyingly.
So it's starts with and (ends with or ends with).
ð much better readable
This one is upper case and the one below is lower case.
OMG `== false`! ð±
Wouldn't it be better to not call setScorer at all? I suspect most collector impls do not expect a null Scorer.
oh no I see, there is also a return. I think it's confusing that we can reach here because of either an assertion or a return statement
if it's not important, maybe a safer default is nicer :) I'm fine leaving as is for now. We can revisit after the bootstrapping.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
Nit: `candidate` -> `candidates`
Nit: `who's the a better` -> `which is the better`
I _think_ you can use `Setting.groupSetting(DISCOVERY_EC2.TAG_PREFIX, false, Setting.Scope.CLUSTER)` here instead of just a string.
Right - RollupIT is the right place
you could use `scriptRequest.setJsonEntity`
can you split this line in two? otherwise the <1> ends up in a new line in the rendered docs
For a better readability, could we have something like: ``` String[] includes = ... String[] excludes = ... FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes) ... ```
I think the parallelization should be on per doc level (not per bulk)... this approach will apply to all scenarios (regardless of the number of concurrent bulk requests you have). naturally, doing so means we'll need to block the bulk until all its docs were processes, but that's doable.
I think we should rather pass the logger to it or don't log here at all. we only use it for this: ``` Java logger.warn("ignoring [disable_dynamic] setting value as conflicting scripting settings have been specified"); ``` IMO we should rather collect the conflicting settings and provide it as a list and then log in the `ScriptService` with all the settings that are conflicting...
Do yo need the parameter `filters`? The only call of `evaluate`just uses the field `filters`.
can we not short cut return, but rather set the hostList to empty and continue the same execution path (with the same logging)
Please add a string message about the context registry being null
I really don't think we need this leniency, I'd like to understand why we're introducing it. I think we should just blow up the pings.
yeah I can see why I was just asking to put this info on the class so folks see immediately why we duplicate code
ok can you add alls these infos into this class
we should make this entire class package private and try to contain visibility here as well.
final and java docs
I think @albertzaharovits's line of thinking makes sense and let's not implement closeable. In the PutUserRequest I did not claim ownership but the array is cleared by the close method. I'll open a PR to resolve the issue there.
maybe call this `getMetaDataOrDefault()`
This is not the way to get the custom upgraders passed around (we should not be passing around PluginService). See other examples in Node: you should collect all the upgraders, and put them into a container that will then be injected (and eventually when GatewayMetaState is deguiced, we will just have it there as an arg, instead of via injection).
Please no `null` for no change needed, returning `Function.identity` is clear, and there is no need to make an optimization check.
I notice this pattern in every implementation. Perhaps this should be a Map instead of Collection (keyed by the custom type name)? Then the map can be copied, and keys replaced, removed, or added easily, without needing to have logic for the other custom metadata that the plugin does not care about.
Looking at this again, I think we can remove the node settings as updateDelay / getRemainingDelay only depends on index settings.
if we didn't get any op (i.e., lastOp.isPresent == false) we should look at the maxRequiredSeqNo - if it's not equal to from somethings have gone terribly wrong and we need to break with a hard error (please double think if the retry logic catch all errors that may case 0 ops to be returned so we catch these before we get here)
I think it would have been worth it but now that you mention it - other requests may have changed this in the mean time too, so let's leave this assertion.
nit: indenting should be only 4 extra spaces
can we make this configurable? also 500 millis is way too small and will busy spin. I guess 10s ? (the real solutions will be to have long polling, but that will come later).
I think it can be even less in tests. No one is worried about sending multiple requests there.
why is this? what's wrong with `1.f`
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
++ thanks for changing this :)
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
please fail if required stuff is null
I you decide to go this route you should also remember to replace the reference equality checks (`this == ActiveShardCount.NONE`) by equals checks or by looking at value (`this.value == 0`).
we "special case" NONE here but not ONE, maybe it's simpler just to remove this method as well as the `validateValue` one and use `new ActiveShardCount(...)` in the two places it's currently used (and also ad ``` if (value < -2) { throw new IllegalArgumentException(...) } ``` to the constructor.
This method could take an IndexMetaData object as parameter instead. This would let us get rid of exceeds method as well.
@clintongormley mentioned that NONE doesn't have many external usages (we only use it for index auto creation) so we might want to drop the special naming and use `0`. I will keep the object reuse in parsing.
and.. looking at the parsing logic this is indeed internal and we don't accept none from strings. Sorry for the noise.
We don't want to actually check what version of `openssl` they have installed. They might be generating certificates to be used on a different machine that has a different version of openssl. It's OK to always print a warning about the password exceeding the old openssl limit.
This one should be `true`. We want to check the password length any time we're generating a _new_ private key.
IMO we can name this calss just `Result` since it's already an inner class in `XLookup` no? so it has the namespace twice?! :)
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
I think an explanation why it's ok to throw an exception here might be helpful for future us.
Maybe it doesn't have to come at all.... I think only `copyCurrentStructure` is part of the xcontent implementation. The rest is just "stuff that ES uses". I think.
nit: remove space before `parser`
I am not sure that this test is that useful. I think that these two bytes reference objects are even equal when compared directly so they don't need to be compared using assertToXContentEquivalent. We should rather test that order doesn't matter by shuffling keys and/or verify the behaviour of assertObjectEquals .
Incredibly minor: should match the value used by the `return` line so that if the method ever changes, we use the same value.
wondering whether `CompiledScript` should hold the `Script` and `ExecutableScript` should hold the `CompiledScript`
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
looks new. I like this update!
Might be nice to add a check for existence of these parameters for completeness.
Maybe a name like "PlusOneMonth"
see text from other suggestion for empty primary allocation
maybe "all copies of " + shardId +" are already assigned. use the move allocation command instead".
can we call this `explainOrThrowMissingRoutingNode` ? the docs can read something like "a utility method to handle the case where a disco node can not be found in the routing table. Typically this would mean it's not a data node"
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
same - please name it something like `explainOrThrowRejectedCommand`
I'd probably write validate's results to a variable and reuse it.
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
I might use an empty array here or switch the IdsQueryBuilder work with lists.
I'm fairly sure I have the wrong generics incantation there....
Any way we can unify this with `BucketHelpers.resolveBucketValue()`? Or perhaps move this into the helper class and rename both of them to be more specific (`resolveHistoBucketValue()` and `resolveMultiBucketValue()` or something?) Also, I foresee this needing to handle gap policies too...unfortunately. :( For example, an agg like Autocorrelation needs to ingest a histogram (which might need gap policy) but emits a set of sibling buckets that represent correlation lags.
You need to use .equals on a Double
just saw it in the factory validation, nevermind :)
I think in this case we should add `null` to the lagWindow and not calculate the diff value for the bucket that is `lag` buckets from this one too. otherwise we will get out of step when we encounter missing data. This would match the behaviour in the derivative agg.
Could you make the reduction create a new aggregation instead of filling the first one? This proved to be error-prone in the past.
Nit: please add a space before the `,` separating the function arguments.
Nit: please add spaces after the `if` and before the `{`.
Nit: please add spaces after the `for` and before the `{`.
is this really testing the right thing? This test does not seem to call `canForceAllocatePrimary` as `TestAllocateDecision` returns THROTTLE and not NO for `canAllocate`.
ok fair enough
once #12937 is in we can do the following here: ``` QueryBuilder<?> finalQuery; if (queryBuilder.indices().length == 1 && getIndex().getName().equals(queryBuilder.indices()[0])) { finalQuery = queryBuilder.innerQuery(); } else { finalQuery = queryBuilder.noMatchQuery(); } Query finalLuceneQuery = finalQuery.toQuery(context); if (finalLuceneQuery != null) { finalLuceneQuery.setBoost(queryBuilder.boost()); } assertEquals(query, finalLuceneQuery); ```
I say goodbye you say hello ;-)
once #12937 is in we can do the following here: ``` String[] indices; if (randomBoolean()) { indices = new String[]{getIndex().getName()}; } else { indices = generateRandomStringArray(5, 10, false, false); } IndicesQueryBuilder query = new IndicesQueryBuilder(RandomQueryBuilder.createQuery(random()), indices); ```
you can remove randomization of boost and queryName
:) good catch
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Maybe we can add a check that only either termsLookup or values are used. Otherwise we won't be even able to serialize this object correctly since the serialization is either/or.
do we decide what to do based on fields that we haven't read yet? I think this conditional will always be false. Which also means that we are not testing this, which we should.
@colings86 suggested to use a different method name over in #11969 which I think makes sense.
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
why is this? what's wrong with `1.f`
Or do like we did in other Parsers: Have constant in the builder that holds the default value and re-use that in the parser. Removes the "magic number" in the parser and skips the condition.
we shouldn't need this here in parse phase
I think this one should be `null` as well to keep defautls in one place
then check for non null here...
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
I really think this should a hard-coded value and not passed in from the environment. I don't think we gain much by accepting it from outside, and I envisage it being the sort of thing I have to look up each time I come across it. The `BUCKET_NAME`/`KEY`/`TOKEN` inputs are clearer (despite that the `KEY` and `TOKEN` used here could be generated internally if we could do so deterministically).
... so that this doesn't need the `{credentials}` parameter in the URL ...
Sure, good plan.
On deeper thought, this seems unduly lenient: it should only return credentials for the role that `GET /latest/meta-data/iam/security-credentials/` returned, and should return 404 otherwise. Also I think `credentialResponseFunction` can be inlined, it's only used in one place. Also also we could prevent cheating slightly more by inventing random credentials when the service starts up, rather than synthesising them from the role name.
I think it is good enough to call `output.bytes().steamInput()`.
I would make this class extend `AbstractXContentTestCase`, then your randomPutIndexTemplateRequest would become `createTestInstance`, and ``` @Override protected PutIndexTemplateRequest doParseInstance(XContentParser parser) throws IOException { return new PutIndexTemplateRequest().source(parser.map()); } @Override protected boolean supportsUnknownFields() { return false; } @Override protected void assertEqualInstances(PutIndexTemplateRequest expected, PutIndexTemplateRequest parsed) { assertNotSame(expected, parsed); assertThat(parsed.version(), equalTo(expected.version())); assertThat(parsed.order(), equalTo(expected.order())); assertThat(parsed.patterns(), equalTo(expected.patterns())); assertThat(parsed.aliases(), equalTo(expected.aliases())); assertThat(parsed.mappings(), equalTo(expected.mappings())); assertThat(parsed.settings(), equalTo(expected.settings())); } ```
we don't need a context in this test, these two lines can go away
can this one use content() too just for consistency with all the other tests in this file? not a big deal, im sure there is more work to do in tests eitehr way.
let's not make this hold this PR, but let's keep track of this potential issue and address the need for generifying in a separate issue
we have `ToXContent.EMPTY_PARAMS`
Generally multi-line output from `toString()` is a bit of a pain to work with. +1 for using the system's line separator, and I think `System.lineSeparator()` works too as we're in Java 8 here, but a one-line output would be better.
There's no need for reflection here - writing out all the fields, in a sensible order, is much preferred.
+1 on using static strings - I didn't realize that the XContentStrings things are not usable when parsing.
sorry I meant `org.elasticsearch.common.xcontent.ObjectParser` all the time my fault
I would simplify this to just "importedClassName". Any name used in code always has to be canonical (like in java).
Same here, original exception is dropped.
I like this much better!
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
I _think_ you can do `XContentParser::mapStrings` above instead of having this method.
I think this can become an assertion now? we never expect it to happen...
can we pass a reason to this method and mention it here? I always to scroll to find out whether this is a "true" index or just one that was created when importing/creating one.
I could be wrong (not that familiar with the code in that area) but I think that in-memory data structures for mappings are not created by the `createIndex` method. These are merged later (see e.g. MetaDataCreateIndexService:325). We could check here as well that all is good on the mapping level.
Sorry, `MetaDataCreateIndexService` was a bad example. Still, the method `MapperService.merge` which does mapping validation is (AFAICS) not called by the `createIndex` method. This means that `verifyIndexMetadata` does not run the mapping checks in `MapperService.merge`. We check these however when we run `MetaDataIndexUpgradeService.checkMappingsCompatibility` which is called by `MetaDataIndexUpgradeService.upgradeIndexMetaData` when we start a node.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
so `round` should be called once per factory instead of once per aggregator
This needs to be protected by a `if (in.getVersion().onOrAfter(Version.V_1_3_0)) {`
Man this feels like a mess compared to ObjectParser. We can't do anything about it in the middle of this PR though. Just makes me sad.
That assumes `list` can't contain null..if that is not the case ignore
Er, well, it doesn't work like that. Ignore.
Should this be abstract? It feels weird to use it without actually configuring any scripts. I think maybe in `StoredScriptsIT` just extend it and return `emptyMap` there. That seems like a special case of using this.
All of the `*Plugin` interfaces we have added so far have used `get*`. I think we should be consistent.
++ to just `get*`
I think we should stick with calling these getters like `getCharFilters` because it is the char filters that the plugin has, they aren't "extra" in the context of this one plugin.
`Map<String, TransportFactory<Transport>>`? Then `TransportFactory<Transport>` can be an interface. It has too many parameters for a sane person to use it like a `@FunctionalInterface` but it'd be nice not to have to override the ctor and stuff.
I think I saw this in Christoph's PR too. Hopefully you don't need it.
maybe add an explicit `continue;` here to indicate that it's being skipped
same - please name it something like `explainOrThrowRejectedCommand`
What do you think of the name `finish(...)`? `doneFetching` is a little boolean sounding to me
Callers of this method can just do `allocation.routingTable().shardRoutingTable(shardId).primaryShard()` these days (if we add an overload for shardRoutingTable which takes a shardId). I don't think it's worth having this utility method. (I know it existed before - we have progressed since it was written :))
no need to reason an "ex.getMessage", we already log the exception...
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
++ on debug message
Also, `.length()` should be compared before `hash()` in my opinion so it can short circuit without comparing the entire `BytesRef` if it can be avoided.
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
I think we should turn this code in a util method on ScriptService in core module. There are now several places where we have code similar to this. This would fix the code duplication. Something like: ``` java public SearchSourceBuilder templateSearchRequest(Script script, QueryParseContext context) { .... } ```
I think this is fine.
Yikes! I'd really prefer not to do this. This kind of thing is hacky when you like guice and it is super bad when you are trying to leave guice. I'm not really sure the right thing here though.
this may get confusing since the feature will be allowed `today`, where `today` is some time in the future that someone will read this. maybe we can reference the PR here, and use more past-tense terms like `previously`.
I think see the point of not setting the source if it was not modified, but when it comes to metadata, should we just set them back all the time? anyway we end up with a single flag for all of them...
I like `hasSize` better for this because it gives a nicer error message on failure.
> Is this enough info from the error? I was expecting something more detailed like we do in ElasticsearchException#toXContent. Is that not needed? That makes sense to do, right now we may lose a lot of details. > One more thing, can it happen that we have multiple errors but we keep track of only one of them due to key collisions in the map? The exception is only available in the context of the current on failure processors. They need to act upon it.
Because a processor may also be wrapped by other processors with on failure definitions.
I see, yea we can't avoid this then. Maybe share the default value through a constant so at least we don't duplicate it. Odd! :)
this is odd especially because it seems that once you set a value for this field, you can never reset it to its original default value.
given that the request goes through validate first, I think we could remove this assertion, this is already checked in as part of validate which will throw an error otherwise.
minor - spaces between `if` and `(Strings`, and space between `){` at the end of line
no need for extra space
Similar to above, I would suggest to refactor so if a test failure occurs it is reproducible.
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
> I assume it runs each test method several times @StefanSchmidtOz We rely on CI for that.
Thank you @jasontedor, I'll have a closer look at how the tests are run. I assume it runs each test method several times, otherwise I would still suggest to restructure `#testInvalidEnum` so it always asserts the invalid enum case.
Given the method's name I expected it to check the values too.
there is an `hasUnassigned` method already, so yeah, I'm +1 on being explicit here...
it doesn't reset the ignored list..
Yea, the idea was to create a somehow fair movement. That was before we had things like throttled allocation and even the balanced algo, so it might not be relevant anymore.
Also here I wonder if we should be safe and synchronize this. Do we really need the metaData? we can get the setting from the injector (which we check anyway). Also I think a better name is hasShardUsedContent (we return false if there is nothing to delete.
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
Asserts are better for this. ð
The sequence number backwards layer won't be needed after 7.0.0.
Another `_` java 9 will be mad at
I'd use `expectThrows` here. I also like assertion *something* about the exception's massage just to make sure I caught the one I expected.
I think java 9 is going to choke on `_` here, if I recall correctly
I'm experiencing the same @s1monw . I had missed this change and I would like to better understand the rationale behind it. Why do we have to restart the global cluster if a test fails within the suite? Also, this seems wrong as if there's one failure in the suite we restart the global cluster for all the subsequent tests...this slows down all the subsequent tests quite a lot (e.g. think of REST tests in network mode).
Believe it or not, it's fine to pass `null` to `IOUtils.closeWhileHandlingException` (it just skips them). We do that for cases where you might have N things that need closing from a large try block, and you don't know which are `null` and which are not (depends on where the exception was thrown). But for here I like the `null` check: less smelly.
Hmm... I'm not actually sure how this would play with Snapshots, so it may be a no-go.
I wonder if we should extend `ChannelReference` to implement `Closeable` and have the `.close()` method decrement the ref and throw an error if it's not now at 0 (which it should be since it's being closed in this case). That way we error immediately if the translog is closed but something incremented the channel ref. What do you think of this? Dunno if you think it might make ChannelReference too complex.
I think a better way to do it would be: ``` if (success) { IOUtils.close(is, os); } else { IOUtils.closeWhileHandlingException(is, os); if (dest != null && dest.exists()) { dest.delete(); } } ```
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
right I had missed that previous check, sounds good then
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
Maybe point out that this is actually the place where we modify the valid input query by adding a new object level to it.
Can change this to the new autoclose functionality in Java 7 now that the codebase is on it: ``` try (ZipFile zipFile = new ZipFile(pluginFile)) { // ... } catch (Exception e) { // ... } ``` Thereby dropping the entire `zipFile`-related code from within the `finally` block.
Not related to this PR but I think that we should check if what we are trying to remove is not part of the BLACKLIST. Someone could potentially provide a plugin which contains his own `bin/elasticsearch` script, which looks scary to me.
ok thanks for the explanation.
you can use MustacheScriptEngineService.NAME
Also, we were testing in the past that `sourceConfigDirectory` is actually a dir and not only an existing file. Did you change that on purpose? Or should it be `if (Files.isDirectory(sourceConfigDirectory)) {`
Feels a bit weird that one method is returning a list and the other one an array
(similar naming consistency issues below)
can we make the list immutable for safety? using Collections.unmodifiableList
(or maybe `ObjectArrays.concat` to make this more concise)
Even if the number of sub aggregation is expected to be small, I'm not too happy with the use of `ListIterator.add` which is linear on array lists.
instead of "simulated change 1" can you provide a text that describes the actual change? e.g. "index created" or "cluster uuid changed".
just `for (IndexMetaData indexMetaData : state.metaData())`
this is not needed. createIndex automatically reroutes.
we don't need to determine `replicaToBePromoted`. Candidates also does not need to be filtered with ` !s.equals(replicaToBePromoted)`. It's ok to just check candidates.size() > 0 here to see whether there is going to be a new primary. In that case, we fail the primary + `random(0, candidates.size() - 1)` replicas and check afterwards that the new primary is on a node that is at least as high as all replicas.
no need for iteration here, you can get the node directly by calling `state.getNodes().get(shardRouting.currentNodeId())` (which will return `null` if no node found)
maybe make if final
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
I added this here https://github.com/elasticsearch/elasticsearch/commit/602c63d2aa3936a766e4e3432721812096ed54f5
ok fair enough
maybe also test a nested conditional setup? (So have conditional and then another conditional in the matched or unmatched list)
similar concerns as IndexRequest
otherwise you could index into an alias that target a specific shard and yet index in other shards by specifying a routing key, which I guess could be seen as a bug
@jimferenczi How do you know the the user didn't make a mistake in his code and set routing when he did not mean to, but meant to only set parent? Being lenient is bad, but being silently lenient is even worse.
Can we not ignore but throw an error back to the user? We shouldn't silently ignore something the user has passed in, it may be they are confused about the api and don't realize that part of their request is being ignored.
yeah nevermind I was confused about some internal classes
I saw this problem being dealt with in other place by setting currentFieldName to empty String. Worst that can happen then is that it is treated as fieldName in the query, which we should validate later and throw IAE then.
let's make sure we deprecate it as well in 2.x
While using ParseField also for values is useful, I'm wondering if it might be confusing on the long run. I would at least rename BOOLEAN_FIELD and the following to something else, since technically they are not fields. No strong opinion though.
so this means we don't support `topLeft` anymore? I think we have to to be honest. Also we have to support `northWest`
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
remove the set boost
remove the setBoost
count the expected errors too like we do in other tests? also we never do (invalid, invalid). I think randomizing things may improve this test and coverage too, like we do in other tests.
:) good catch
we don't need a context in this test, these two lines can go away
This shouldn't be necessary since the object that was serialized should already have had this logic applied. (Also, using `writeString` in the `writeTo` method means it's impossible for the string that's read to be `null`.)
No need for an empty default ctor when the super is also a default ctor.
Maybe we could name the context (and the class) something more descriptive for it's purpose? While the rest api is for executing a script, I think this context is a generic test context? Perhaps it could be "painless_test" (and PainlessTestScript) or something like that? I like having "test" in there because it is clear this is not for production uses, but to test painless code. It would also be more clear for when we do support other contexts in the execute api.
The factory is what holds onto the params, so that they can be passed to the constructor. Think of the factory as the signature for the constructor. It's not boilerplate; it is actually needed based on current uses of scripts throughout the system. Also note that the factory signature is what allows the script instance to have arbitrary objects passed in. If `ScriptService.compile` were to return an instance directly, instead of a factory, we would need some way to pass in this information in a generic way, which would probably mean duck typing through a String->Object map and then require casts. With the factory, we get static type checking of the arguments a script needs to be constructed.
this class could be made `final`
index's toString gives you '[index_name]' no need for '[{}]'
same here: no need for the [].
same here - I think it's better to log the info message if the deletion was successful.
Totally missed the extra `builder.put(settings);` line added in one of the commits. All good. Sorry for the noise.
what I mean is that we don't need have a method that builds new settings, we can just call `metaData.getSettings()` where we need them.
this makes me wonder: if a node has node.ingest set to false, for sure no processors should run, hence simulate should be off and IngestDisabledActionFilter should throw exception when a pipeline_id is used as it does now. But how about crud actions for pipelines? One has to go to specific nodes to store them, that have node.ingest set to true? this may not be needed, as those are just index, delete and get operations that any node supports...it's like making client nodes reject index requests, they can forward them to the proper nodes, no problem with that.
oh sorry I see that you don't register the transport action when ingest is off, sorry I had missed that.
can `aliases` be final as well
Change to Throwable.
I think we are still missing preference? Should be similar to the get API.
Nit: addresses -> address
just a style question but this loop looks more like a `do/while` would be easier to read IMO
would be nice to force the ctor to accept to arguments, one for the plugin name and another one for the context within the plugin... this way we can semi-enforce consistency of context keys and avoid conflicts between plugins... a la: ``` java public Plugin(String pluginName, String pluginContextKey) { this.key = pluginName + "_" + pluginContextKey; } ```
I'd just use the Id really
I suspect that some aggregations could be grouped under the same parsed aggregation implementation, so we won't really have a 1-1 relationship between the internal agg and the parsed agg. Like an aggregation of type "sum" (ie InternalSum) and "min" (ie InternalMin) can be parsed back using a same `LongSingleValueParsedAggregation`. In definitive I'm not sure we should add the getType() here or also in the Aggregation interface.
Same here for `compareAndSet`
We should remove the Store part. Perhaps make a constructor with a name? these errors are difficult tot trace so we should make it as clear as possible where the error came from (even if the stack trace is lost)
I only mentioned it because if we really have to keep this, then StandardOpenOption.DELETE_ON_CLOSE could be an implementation. But this one has race conditions too, this delete-on-close stuff is why Lucene's lockfactories were buggy for years. Lets defer it to a new issue, ideally we just nuke it completely.
I think it will be cleaner to have ShardInfo have a constructor that takes all parameters and set that on the finalResponse. This will make sure we will not forget anything in the future.
we throw the exception and thus take care of the interrupt. We don't need to set it...
regardless of where boost is, isn't it ok if we replace only when there's only one occurrence of it in the string query? Otherwise we skip the test? I think it's a best effort that should be ok 99% of the cases... unless I am missing something
Ah! Well if its a huge pain then its probably not worth it. Its just that if you do something drastic one of the simplest metrics to make sure you didn't break anything is to count the number of tests. And if some tests skip sometimes and not other times you have to manually validate those tests. Its not worth optimizing for this case though if its difficult.
right I had missed that previous check, sounds good then
nit: if you use assertThat(e.getMessage(), containsString("bogusField")), when this fails the error will be much more digestible than just "expected true found false"
Heads up when you merge with master, I just merged another test where the original test query is modified assuming it is json, so that will need the same treatment as you do here I thinkg: https://github.com/elastic/elasticsearch/pull/14255/files#diff-9dc314365d49d84bff0645c2f9dfd7adR356 (and Overwrites in HasChild/HasParentQueryBuilderTests)
I think this should be an `assert false;` + throw new UnsupportedOperationException
we should assert this is never called (same for the other places here where `UnsupportedOperationException` is thrown), as this indicates a bug.
well we use a dummy lock so I guess it's fine
try finally here please since if close fails we don't release lock etc which can be missleading
or when some docs match the query but do not have a value
Nit: please add spaces around the `=` sign.
The existing code doesn't filter out paths whose `mount` property is `null`, so I don't think we should start doing so as per this test case.
This seems to test the case where the same path has a number of distinct mount points. Can this happen? I can't think how.
Nit: extract 1533081600000L to a constant FIRST_BUCKET_TIME as the literal is used several times
[{}] for path.
The message is a little weird. I don't think "next release" should be mentioned.
I think we can remove this exception now.
Old indentation was better because it made it obvious that the conditions weren't part of the body.
I think `writeGenericValue` handles null values, so you could omitt the surrounding check.
Do we not also need a NAME constant here which is the name of this function in the NamedWriteableRegistry? Same with the other Functions
I think it'd be nice to throw an UnsupportedOperationException here just to catch any weird usage quickly.
Nit: space between the cast operator and the target.
Ah, okay. Then I'm good with it as-is; we can consider redirects separately (if ever).
maybe catch exceptions here and put them into an arraylist, you can then just use ExceptionHelper to rerthrow and surpress....it has a utility for this
can you use `IOUtils.close()` here please it will close all even if there are exceptions
Checkstyle is unhappy with this.
Now I get it! I had to dig around a bit in `ScriptService` to understand what was up. Now it makes sense.
I think it'd be nice to have an assertion on the text of one description just so we can look at it.
you don't have to assert on anything if an exception is expected
Nit: maybe fix the indentation to allign everything. Then again, code formatting will probably destroy this again soon, so no big deal...
I think having friend Input/Output classes to ByteArray, as you suggested, would help make this easier.
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
This worries me a bit as this is inconsistent with the filters and ranges aggregations.
could these three methods somehow be in the base test class, at least partially? what I am looking for is avoiding copy pasting when writing new tests, and possibly not forgetting to cover important scenarios.
could be `final`
same for here, not sure if the full Objects.equals needs to be called
I think you want to use `notVisitedTasks` here instead of `runningTasks`
perhaps a different name for this listener, as it doesn't only handle failures but also successful response publishing
Thinking about this more, I wonder if we should have this run-even-if-there-is-nothing-to-do complexity. I'll reach out to discuss.
that awfully sounds like two voices for debug.... your turn, @jasontedor.
If I see this correctly, the source still appears in pending cluster state tasks, which is why it should still contain the node name, i.e. `"zen-disco-node-left(" + node + ")"`
maybe call this pendingTasks or resolvedTasks? I got a bit confused by the valid notion - some of the tasks are marked as successful but are not valid :)
can we do the assignment in another line, very sneaky :)
this made me worry we don't log these failures anymore.. In this specific case I think we are best to just let the exception bubble up, but it does raise a more general issue - if people put exceptions in the builder, it's their responsiblity to report it. we should probably add something to the internal cluster service to auto log it.
I think it would be nice then to test equals/hashcode separately. We can probably use EqualsHashcodeTestUtils
just for ref, im not sure this is really valid.
this one ends up sending parameters that are getting ignored, see `IndicesOptions.fromMap`. we should remove the last three parameters. This should be cleaned up, the problem is that some indices options are settable at REST, while some other are internal properties that define each API (the default argument in `fromMap`) which cannot be changed, so they should never be printed out nor parsed back.
I wonder if this specific default should only be used in the REST layer, or if we should move this logic to the transport action so that it's applied to the java client as well. That way we would have consistency between REST and transport layer...
Incides -> Indices ? ;)
`blocksmd.copyContext(trysmd);`? I know you use "context" to mean something and this might not be the right use of that word though.
Or `adapter.createStatementMetadata(blockctx, trysmd);` or `trysmd.substatement(blockctx);`.
Fair enough. I just see the increment/visit/decrement pattern a lot and it feels like something you could make more automatic/harder to forget/explicitly named.
`ifsmd.count = Math.max(ifsmd.count, blocksmd1.count);` would be a bit more clear to me.
I don't think this is correct? Do tests pass? This should fail on unmapped fields.
Maybe `SystemUser.NAME`? I worry that in the future when we do object level security using a username that doesnât correspond to a real user may be a security hole.
I think you are right, I will try to find out what other language clients do in this situation just to make sure.
if you throw above, maybe throw inside, only in case the selector returns empty here too, that might make the code a bit more readable.
nit: indenting should be only 4 extra spaces
The existing code doesn't filter out paths whose `mount` property is `null`, so I don't think we should start doing so as per this test case.
Here it still says `on a per index basis` -> should be corrected.
what do you mean here? The important bit here is that we need index version compatibility for recovery. The data nodes on the follower cluster need to be able to read the Lucene index versions of the source clusters, otherwise we can't open the Lucene index.
can we implement `Closeable` and use an AtomicBoolean to signal it's closed I like the `if (closed.compareAndSet(false, true))` pattern
You can use `UncheckedIOException`
I always wonder if we should use the PROTOTYPE constant here instead, cause that is what we need I guess. If so we should change all other tests accordingly
and actually a boost on a match_no_docs query can matter when used as a sub query as it will contribute to the outer query weight
I might use an empty array here or switch the IdsQueryBuilder work with lists.
Empty array is a thing that the jvm is very good at optimizing here. It is a very common case and they've worked hard to make sure it is quick.
I'm fairly sure I have the wrong generics incantation there....
We might should move these last two declarations to a common spot something like ``` static <T extends AbstractObjectParser<? extends QueryBuilder>> declareStandardFields(T parser) { parser.declareFloat((builder, value) -> builder.boost(value), AbstractQueryBuilder.BOOST_FIELD); parser.declareString((builder, value) -> builder.queryName(value), AbstractQueryBuilder.NAME_FIELD); return parser; } ``` and then we can declare them when we're initializing the object.
no need for if/else, just write ``` return getNodeDecisions() != null && getNodeDecisions().stream().anyMatch(...) ```
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
yeah, that was what I meant
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
I think filter and query can never be null here? not sure whether we should validate this here.
no matter what I really want to have the manger go away here. I think it bloats the code we can just fold it in.
make sure you fix the codestyle here
please add `{}` around this
I think this will succeed even without the change in this PR? I'm not sure what is exactly tested here.
can we maybe make this an empty list instead. Unless this has a special meaning I'd like to prevent `null` invariants
ok. I'm with you.
can we rename this to shouldIgnoreNewClusterState? it's not only about being dated.
can we call this log: ``` received a cluster state from a different master then the current one, ignoring (received {}, current {}) ``` also note that disco nodes already have [] in their toString.
s/can't used/can't be used/;s/their/they/;s/subtile/subtle/
yes, we can't do too much about this, so it is better be defensive here.
also, throw an IllegalArgumentException and you will get a 400 response code instead of 500
side note (can be addressed later): all users of getFoundPeers always add the local node. Maybe we should have that node included by default.
meh. I think we should change the behavior of ListenableFuture to allow this. As this requires careful consideration of the existing callers, we should not do that change here. Let's keep the `listenerNotified` and add a TODO.
The listenerNotified mechanism is not needed, that's taken care of by the future (you can only complete it once)
I would move this before the call to schedule. This allows you to use a timeout of 0, which will then still reliably give you a response if the node has discovered enough nodes and not race against the scheduled task.
Is the version needed? I don't see it being read here.
Also, thinking about liveness, maybe `HANDSHAKE_ACTION_NAME` should be included in the defaults for `transport.tracer.exclude`
I think this should never happen; maybe: ``` final TransportReponseHandler handler = pendingHandshakes.remove(requestId); assert handler == null : handler; ```
can we add a check for whether we sent a diff? I want to avoid a potential infinite loop.
Nit: too many newlines here
hmm can't this just be replaced by ``` Java return new ShardRouting(shardId, in); ```
As written this isn't symmetrical with the write method. I would prefer that it be written in a symmetrical way for ease of comparison.
It'd be "more normal" to declare this as `Writeable` and use `readOptionalWriteable` and `writeOptionalWriteable`. You've done plenty in this PR so it can wait though!
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
Is this generating a random number between approximately -2 billion and +2 billion (i.e. the full range of `int`)? If so, the proportion of tests of valid enum values (in the range 0-2) is going to be so vanishingly small that the CI might not do a test of the valid path for thousands of years.
> write past EOF :dancers: +1!
thanks for improving this, this part is easier to read now IMO.
> should we just do the naive thing and handle the last 8 bytes case via a naive loop of writeByte() for each byte, so that the footer logic is only in one place? +1
yea, I would at least debug log it..., it shouldn't happen
Should this be `debug` instead of `info`? It generates a lot of message like this during replication: ``` [2014-07-01 22:30:36,127][INFO ][index.store ] [Mimic] [test][1] create legacy output for segments_1 ```
but why? :)
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
s/payload is/payloads are
these don't need to be static
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
You could probably avoid this by making the linux check a method that you stub out in OsProbe.
method refs ftw
Can you add some randomization ? We run this method multiple times and then perform some checks on the generated query (serialization, correctness, ...).
I don't understand why this can be true when in L263 we use `assumeTrue("test runs only when at least a type is registered", getCurrentTypes().length > 0)` I investigated this error yesterday with Jim and he pushed the "assumeTrue" part, so this test shouldn't run into those cases anymore. Did you run the mentioned reproduction line on current master, because I could get it to fail using it on 77617c8e62f7fa1407c62bdf33e4892206d62952
maybe expectThrows would be easier.
unkown -> uknown
Listener can be null here.
I just realized, for this log message and all of the ones below it here, we only log `index` and totally omit `reason` because there is only one `{}` in the log message...
or "failed to close store on shard removal"
Closing the store doesn't necessarily mean the shard is being deleted, I tested this and this codepath can happen when the index is closed, so I think this should be "failed to close store on shard closing"
I think this can leak a reader if `reset(DirectoryReader delegate)` fails (especially when the `this.delegate != null` is true)
s/it's leave/its leaf/
Maybe call this 'totalOpenedReaders'? I was a bit confused reading the tests as it looked as though it was reporting the current open count
can you java doc the semantics of this one? it's kinda funky: "give me something if you have it cached but if you don't give me null".
Thinking about this more and seeing how it's used, maybe we should split this into two methods: `getReader` which will return a reader if one was previously opened and `getOrOpenReader` that calls `getReader` and if it returns null, opens a new one.
@javanna thank you that helps a lot.
Since scripting is disabled by default, we re-enable it back when we start each node in our test infrastructure, just because we have quite some tests that need it on. We are thinking about re-enabling it only for the tests that rely on it though...
can we also randomize if we even set this setting at all? i.e. wrap setting it using `randomBoolean`.
I think it might make sense to do the same in `ExternalTestCluster`, so that we state that network mode is required there as well.
you can simplify this a bit here: ``` Java NodeStats unluckyNode = randomFrom(Iterables.toArray(nodestats.getNodes())); ```
I think I forgot a .value possibly? From your message I did not get if you managed to make it work after all, if not ping me and let's make sure that it works on doc_values
I really think this should a hard-coded value and not passed in from the environment. I don't think we gain much by accepting it from outside, and I envisage it being the sort of thing I have to look up each time I come across it. The `BUCKET_NAME`/`KEY`/`TOKEN` inputs are clearer (despite that the `KEY` and `TOKEN` used here could be generated internally if we could do so deterministically).
Why `ec2Key` here? This should be the instance profile name, and can reasonably be a fixed value...
... so that this doesn't need the `{credentials}` parameter in the URL ...
Sure, good plan.
++ on removing this catch. Not true any more
I think we should make newRecoveriesHanlder be: ``` private final Function<String, Releasable> delayNewRecoveries; ``` and then all of this becomes: ``` try (Releasable ignored = delayNewRecoveries.apply("primary relocation hand-off in progress or completed for " + shardId)) { final long currentClusterStateVersion = currentClusterStateVersionSupplier.get(); logger.trace("[{}][{}] waiting on {} to have cluster state with version [{}]", indexName, shardId, request.targetNode(), currentClusterStateVersion); cancellableThreads.execute(() -> recoveryTarget.waitForClusterState(currentClusterStateVersion)); logger.trace("[{}][{}] performing relocation hand-off to {}", indexName, shardId, request.targetNode()); cancellableThreads.execute(() -> shard.relocated("to " + request.targetNode())); } ```
Whoops, you already did, ignore this!
This logging statement has a `[{}]` but no argument to fill it
Someday we're really going to have to standardize on American "canceled" or British/Australian "cancelled"... :)
oh, woops. thought I counted right. sry
do we want to check the phase/action times since those are meant to change
is it the intention to have `getCurrentStepKey` return the "NEXT_*_SETTING", while there exists a "CURRENT_*_SETTING" that can be misunderstood to be just that, the current setting? seems like it is more a "previous" setting
This assert message says 2 shards, but the check is for `equalTo(6)`
Let's use `assertThat(..., equalTo(...))`.
fine with me as well. go ahead and push!
I am good with both options.
Oh I see, it's the ZTable stuff. Sorry for the noise :)
interesting, what is the reason for this funny upper bound? :)
no need for the alt variable? (but +1 to make vals[2] go through Double.parseDouble to make sure it is a valid double)
Nit: I think you can leave out ESTestCase here.
Like above, I'd simply use randomFrom(SortMode.values()).
Nit: I think you can leave out ESTestCase here.
Nit: I think you can leave out ESTestCase here.
I wonder if `PARSER.declareString((b, v) -> b.sortMode(SortMode.fromString(b), SORTMODE_FIELD);` is better? I kind of prefer it because then you don't need to think about `ValueType`.
This question reminds me of an interesting larger topic that I believe could be related: At least for precision IIRC one can compute a micro-averaged or macro-averaged version. Maybe it makes sense to let users decide which of the two (or both) they want? No idea how this plays out with the other quality metrics you looked at.
his -> This
Not sure if that makes any sense at all, but somehow my inclination would be to write counter < 1 instead of counter == 0 here.
... as discussed f2f: Add to the TODO to collect errors and return only when all requests are done, I'd do the actual implementation in a separate PR though
yep. sorry I missed it.
you can comma separate these instead... i know the likelihood of us not using `/` is low, but its best to not have them in this.
In 7.0 this should use `_migration/deprecations` as of https://github.com/elastic/elasticsearch/pull/35976, although in 6.x it will have to use `_xpack`.
Pls be sure this is not null. Other converters do a null check and return and give this `addCommaSeparatedPathParts` a empty array if need be. check `forceMerge` for an example
`.addPathPartAsIs("_xpack", "rollup", "job")`
no need for extra space
I wonder if we should enable this only for new indices that we know are created with es 1.4
really shouldn't we just skip this in the `LegacyTranslogStream`
can this be in try-with logic.... you are not closing this input stream at all
in this case is it worth peaking at the file again and check if the first byte is valid even for version 0? maybe we should do that check first and then move to V1 and fail hard if we see a CorruptIndexExp
Another for `Files.notExists(...)`
Can we make getHighlightFields always return a non-null value? (using Collections.emytyXXX if necessary)
why did you add it? I mean, it is very internal...., it will mean cluster state API will become so much more noisy
As Boa mentioned before we would need both a default to print out, and a boolean that tells whether the current value is default or not, as the `currentValue != defaultValue` is not enough. Something like the following should help in most cases I think? ``` public static void maybeAdd(XContentBuilder builder, String key, Object value, Object defValue, boolean isDefault, boolean includeDefault) { if (value != null || !isDefault) { builder.field(key, value); } else if (includeDefault) { builder.field(key, defValue); } } ``` That said, maybe it doesn't cover 100% but 90% of the cases, and for the 10% left we can still have the custom if? In my opinion it doesn't need to be perfect but still better than copy pasting that `if` so many times.
> this is only used for internal serialization and is not exposed in the api. so I think we are good? You are right, metadata is only exposed through cluster state that uses custom serialization which omits this.
Nit: I might get something wrong, but seems trappy to me since it goes to Object equals now (and does the right thing), but if any other superclass (like SortBuilder) would implements it's own equals() this would short-circuit everything. Of course there are tests for it now, but I'd do an explicit check for reference equality here.
All of this is equivalent to the simpler ``` return Objects.equals(newMasterNode, previousMasterNode) == false; ``` (see equals implementation of DiscoveryNode)
can we change to use isRelocationTarget() instead? i.e., `isRelocationTarget() || primary == false`
`getMasterNode()` already returns null if `masterNodeId` is null. Maybe cleaner to make that explicit in the `getMasterNode()` method (and not rely on the map implementation to do that for us) and also use `@Nullable` on the return type. The effect is that we won't need these conditions here and can just write `return new Delta(other.getMasterNode(), getMasterNode(), ...`
Maybe we could call the remaining equals() implementation in the query builders slightly different? When I read this code and don't know about the abstract superclass, this might look a bit odd since it's doesn't really overwrite the canonic equals() but it sort of looks like it does.
This is a hard override (via index.mapping.date.round_ceil setting, which default to true) to disallow rounding up. Not sure if this actuall set to false, seems undesired to me.
Nit, and I know it was there, but there's an extra space between `URLClassLoader` and `)`.
Let's make this an `UncheckedIOException` too.
The reason should be more explicit about why this needed.
Nit: `findHostName` -> `getHostName`
ah I mean't Throwable.... sorry
connec to to -> connect to
> Makes sense? It does not make sense. Having try/catch like this means the test doesn't really know what it is testing.
Can we pull this initialisation code into a method. I imagine most derived classes will implement `updateRemoteCluster` by storing the cluster names/addresses into some form of collection. But if that collection is a field, then it won't have been initialised at this point (in the parent constructor). The typical constructor is going to need to look like: ``` { super(settings, false); clusterNames = new ArrayList<>(); initialize(); } ```
You can use the diamond operator here.
This can all fit on one line.
nit: could be one line
`min` can be named `simple` or `aggregation`
Should we lazily compute a bucketMap like in InternalMappedSignificantTerms and then be able reuse it when this method gets called many times? I have no strong opinions on this though.
I just wanted to understand why its there. At the moment it doesn't complicate things a lot, and if if helps avoiding casts thats fine.
I would use the same type name as the StatsPipelineAggregator here so it's easy to see they relate. That's what we do on other aggregations. The contexts in which these are used and deserialised are different so the names would never clash
nit: maybe the null check isn't necessary
nit: looks like searchType cannot be null
Oh, I wasn't suggesting removing it in the copy constructor. I was missing the part that `sourceBuilder` here seems not be part of `searchRequest` yet when calling the copy constructor. All good now, thanks for the clarification.
I think it should be `VersionUtils.randomIndexCompatibleVersion(random())`
I wonder if this should rather be made part of Request#multiSearch like we did for bulk. I see that it may be nice to have read and write methods close to each other, on the other hand the only place where we need to write this format is in our client.
Needs a guard.
Ah yes, thanks!
I think this message should be a bit more clear. Can you include: - the path - the supportedAttributes - some explanation about what attributes we're looking for It can just be `"Don't know how to make file {} non-readable on a filesystem with attributes {}"`
I think there is a problem here. Imagine that `maxWarningHeaderCount` is set (not equal to `-1`) and then a user dynamically sets it to unbounded before the `if` statement on the following line (i.e., after we have passed the set condition). Then we will see the updated value and `warningHeaderCount` will always be greater than `maxWarningHeaderCount`. We want to avoid these sorts of race conditions.
Yes, I would ditch DOS (as you have done). I don't think we run any CI on non-ACL aware platforms. If it turns out we do, then we should just do an `assumeFalse` as the test is not possible on that platform.
I have no idea how we get these weirdly aligned lines....
Thanks for fixing that...
Yeah - I'm sure that is what happened. Ok - cool with me!
Same deal with `.get()`. I try to only do this when I edit the line so it doesn't blow up the diffs, but this is a good opportunity to do it here I think.
Can we check that the hits information is correct in the response too? i.e. the hits are empty, the totalHits is correct and the maxScore is zero
I think we should have these checks in validate. and if we don't want to rely on validate in doXContent have if conditionals there and ignore what's null just to prevent NPEs, but I wouldn't want to do validation and throw IAE in doXContent, where we just print stuff out.
this could lead to NPE if from the java api no set call is performed
ah ok I think I get it, we wouldn't get here before cause what is now the empty_query was null and you could never call toQuery against it. Now we have the empty query that returns null and we have to move some null checks to the different toQuery methods.
here too, not sure why we have to return null now, also we can use query.clauses() to count the added filters
I have yet to get to that alternative, I am lagging behind :)
why do you pass the response to this method? `this` already has all information.
this breaks backwards compatibility, you will need if based on version in both `readFrom` and `writeTo`
I've also started removing them in places I touch. Each one costs us an extra class in the classloader that never gets unloaded. If the constant is used in exactly one place, I do not see the point. If the constants are needed, I don't think they need an extra separate class.
these replacements seem to be wrong the if / else logic is obsolete now
I'd say yes... if you want to be able to parse script as a string, you want to be able to serialize it as as string. I believe serialization should be symmetric - you write what you read. For this reason, I believe the script type should be nullable. if you read a script like a string, the read state should be preserved for the writing.
Good point, I was thinking about fielddata_fields but we can't get them anyway if a doc is only in the translog...
Oops nevermind, I misread.
Ah, nope, I'm just bad at Java. `[Metric1, Metric2]` is exactly what I was wanting. :)
could these three methods somehow be in the base test class, at least partially? what I am looking for is avoiding copy pasting when writing new tests, and possibly not forgetting to cover important scenarios.
I think @talevy is talking about the `value` and not `path`. I think it is ok to add a null key.
``` java assertThat(provider.fetchCount, is(1)); ```
``` java assertThat(provider.fetchCount, is(2)); ```
Can you add a check for reparsing (ie taking a settings that have been run through archiver and using them in another settings builder) the settings works? ie the setting stays archived and doesn't disappear.
Nit: `parallel` -> `concurrent`
maybe we could randomize the names of the 2 settings we have in this test
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
Yeah, it's pretty new. :-)
Fine with me.
we should use `org.elasticsearch.common.xcontent.ObjectParser` for this instead of parsing all the stuff ourself
would be great if this logic could be unit tested.
Doesn't hurt, I guess, but it might obfuscate the fact that all the parsed aggregations don't implement equals/hashCode. At a quick glance people might think all subclasses properly implement equals()...
I suspect that some aggregations could be grouped under the same parsed aggregation implementation, so we won't really have a 1-1 relationship between the internal agg and the parsed agg. Like an aggregation of type "sum" (ie InternalSum) and "min" (ie InternalMin) can be parsed back using a same `LongSingleValueParsedAggregation`. In definitive I'm not sure we should add the getType() here or also in the Aggregation interface.
I understand. But this requires to grab back the type and delimiter where initializing the parsed aggregation directly with the name "type#name" would allow to parse back the result too. Also, in a client side point of view, the name is "type#name". But I'm nitpicking, we can change this later if we want.
Do we really need to also duplicate the typed_keys logic here? Can't we just print out the name of the parsed aggregation (it can be initialized with type#name)
now I see what you meant yesterday saying that we have to parse meta here
I think it's possible the ingest phase will take genuinely take 0 millis (i.e. <1ms)? in that case we want to report. I would suggest using a negative value to indicate "ingest never run" and suppress rendering in that case alone.
Minor - can we move the _shards above CREATED? will look better. now looks like this: ``` { "_index": "index", "_type": "type", "_id": "1", "_version": 1, "created": true, "_shards": { "total": 2, "successful": 1, "failed": 0 } } ```
I think we want shardInfo.toXContent(builder, request); here? like this we loose the request as params
I think we want `shardInfo.toXContent(builder, request);` here? like this we loose the request as params
You can probably use `aliasMap.values()` since you don't need the key for anything right? I don't think it's necessarily any better though, so either way is fine.
Based on our last conversation we still use `|` I thought we wanted to go to a less prominent char like `\u001F`
I am not sure if we should keep this analyzer - I think we can just use the `PrefixTokenFilter` by itself and move it somewhere in the completion namespace. Yet I think we should have some dedicated tests for this that use `ElasticsearchTokenStreamTestCase` there are some awesome helper methods that can find a lot of stuff that is not correctly set in the `TokenStream`.
not sure why we would have null here, but even if we had it, none of the following ifs are going to be true. I think you can remove this if then
lower cased now...
guava has a `Iterables.elementsEqual()` - which works slightly different, maybe your implementation is a bit faster
you could rewrite this as ``` ElasticsearchParseException e = expectThrows(ElasticsearchParseException.class, () -> factory.create(config)); assertThat(e.getMessage, ... ); ```
++, it's a java 8 only idiom, which is not a problem for ingest, no backports
I like this simplification!
I think it'd be nice to have an assertion on the text of one description just so we can look at it.
It'd be nice to be sure it contained that `not_found` wasn't found.
I still wonder if we should use a priority queue here (ordered by sequence number) so that operations are applied closer to in order than they otherwise would be? Something like: ```java private final Queue<Translog.Operation> buffer = new PriorityQueue<>(Comparator.comparing(Translog.Operation::seqNo).reversed()); ```
Instead of passing the clients in the constructor, I would like to make this class abstract where all the methods that require a client are abstract. Then the PersistentTaskExecutor can instantiate a method that delegates async requests via clients but tests can do something else (synchronously return something, throw exceptions or what ever)
size should always be maxReadSize and the last parameter should be Math.min(globalCheckpoint, from + size)
last parameter can be set to from.
I think we can set this to the followGlobalCheckpoint and send a pick request. No need to preflight imo
Why do we register `S3Repository.Repository.*` settings here? Those are extracted from the repository settings when it is created/registered, but I don't think we need to register a global `compress` or `throttle_retries` setting...
great! thanks @dadoonet
Thanks for adding this warning. Since ` metadata.name() ` refers to the repository name, we could maybe change this to: "ignoring use of named client for repository ["
can you remove this line break? :)
undo formatting changes in this class
I think an absurdly high limit could still be helpful? (in a follow-up PR)
Thanks for moving this to `InnerHitContextBuilder` and its subclasses!
Since timezone is now a string, we should probably check for `Strings.isNullOrEmpty()` instead of just null now. (or null/empty check, I'll leave that up to personal preference :) )
thanks for checking, that is fine then
Since we rely on the fact that index, timestampField, eventTypeField, etc cannot be null and fetchSize cannot be negative, we should validate that it's indeed the case. We could also make serialization more forgiving and avoid serializing the same default values on every request.
can we increase the timeout on the request? if one runs a debugger the test may fail to retry because a timeout happens, making it confusing.
why 1000? this should never hang right? we can just use get()? if it hangs it's an issue.
yeah that is true. nevermind then
can we set the timeout here to 0? in general we always try to make unit tests finish as quick as possible. this one waits for 1s per run.
true. nevermind then
maybe expand the explanation to "shard cannot remain on this node but throttled on moving to another node"
yeah, that was what I meant
you can fold this into the previous `if` block, so it reads: ``` if (in.readBoolean()) { this.nodeDecisions = Collections.unmodifiableMap( in.readMap(StreamInput::readString, NodeAllocationResult::new)); } else { this.nodeDecisions = null; } ```
same - please name it something like `explainOrThrowRejectedCommand`
These asserts are totally fine (and helpful!), but I think as a future direction, it would be nice if we encoded the invariants about a decision into the data structures themselves, so we make it harder to create an illegal state. It's totally not work for this PR, only an idea for future direction :)
removed? It does not seem to be used.
I am confused how this works when created is only within role mapping but we ignore role mapping
@bizybot can you open up a issue that describes this behavior of the object parser and label it with discuss? Then we can move this PR forward.
Request -> ExplainLifecycleRequest
nit: extra empty line
unused import now, no? https://github.com/elastic/elasticsearch/pull/16432/files#diff-208398fdbe888b55ad36dd4f161fdf48L22
I just realized, for this log message and all of the ones below it here, we only log `index` and totally omit `reason` because there is only one `{}` in the log message...
if the api is really internal, I think we can simplify this. Do we need to use a client here? Can we instead use the transport service directly? In that case we wouldn't need the RefreshAction, and the RefreshRequestBuilder. Otherwise the api ends up being exposed anyways, no matter if we say it's internal, but it doesn't have a corresponding REST handler, which makes things inconsistent.
ok...but client depends on the transport service anyway no? I think I don't get it
did you plan to add here the list of nodes or something? looks like there is a missing argument.
I suggest that we take advantage of this change to remove support for time-based expiration, which we don't need
Could you explain why this is needed instead of checking `expireAfterAccess <= 0`? I think it'd make the class more readable.
I don't think it changed the readability much - it made the checks simpler but then it left me wondering why two variables were needed. I was doing the "why does this have to be here, let me think hard about it" think.
I think the unlock calls should always be in a finally block
I was getting confused by invalidateAll - on second inspection you hold both locks when clearing the maps.
+1 to not swallow the original exception
Doesn't actually throw `IOException`.
This `{` block `}` fits the pattern we use elsewhere, but feels unnecessary in this context.
I think it'd be useful to see the filenames in the exception message.
Again, need to figure out what to do if ATOMIC_MOVE is not supported
I think this `close()` should be in a `finally` block in case the write fails
I think there is an issue here when `length` is a multiple of `PAGE_SIZE`: for example I think a length of `2*PAGE_SIZE` with `offset == 0` should use 2 buffers, but when I do the math here, this gives: `(2*PAGE_SIZE / PAGE_SIZE) + 1 = 3`.
good that you added this assertion :)
This assumption is wrong if `offset >= N * PAGE_SIZE` and `offset + length < (N+1) * PAGE_SIZE`. I think the only way to fix it would be to make ByteArray.get return a boolean which can be used to know whether a copy has already been performed.
I think it has the same issue as writeTo with lengths that are multiples of `PAGE_SIZE`.
same here. ElasticsearchAssertions.assertThrows wil help
if we use isEmptyCollection of hamcrest, we'll get the recoveredType content in the error message
yeah nevermind I was confused about some internal classes
The fact that we process noops differently than indexing / delete ops (w.r.t localcheckpoint) sounds like a bug (different) PR)
I don't think it needs to be an `AtomicLong` - it's only updated on this thread.
can we check for null before we start and then validate it's still null on the end? an alternative is just to synchronize this block, which is simpler (but remember to do the same in stopDisrupting)
We can use a set here instead (it's sorted at the end anyhow). ``` final Set<SnapshotId> snapshotIdsToIterate = new HashSet<>(snapshotIds); // first, look at the snapshots in progress final List<SnapshotsInProgress.Entry> entries = currentSnapshots(repositoryName, snapshotIds.stream().map(SnapshotId::getName).collect(Collectors.toList())); for (SnapshotsInProgress.Entry entry : entries) { snapshotSet.add(inProgressSnapshot(entry)); snapshotIdsToIterate.remove(entry.snapshot().getSnapshotId()); } ```
strictly speaking, this doesn't need to be volatile. We update it under a lock which guarantees the visibility of the changes.
typo - failIfCancled -> failIfCanceled
don't drink and code ð» (same line twice)
Super-minor, but missing a space between `if` and `(` here.
I don't get this part why do you change the way we read the `TranslogStats` here? can't this just be ``` Java translog = in.readOptionalStreamable(new TranslogStats()); suggest = new SuggestStats(); if (in.getVersion().onOrAfter(Version.V_1_2_0)) { suggest = in.readOptionalStreamable(suggest); } ```
I understand this is the oversight you've mentioned
I'm actually wondering if it would be better to commit with the `onOrAfter` line and just accept the errors for a build or two. The last good commit stuff should mean that only the intake build fails on this. You could also set up the backport for 6.x branch before pushing the change on master so you can push both at the same time and minimise the chances of builds failing.
I think consensus is to avoid build failures entirely whenever possible
In case this is left as a set, can we add a check to throw an exception if the set already contains the ThreadContext
Nit: missing `@Override`
This function is called a lot in tight loops and it's not a simple conditional as `timeoutExceeded` is volatile so there is a memory barrier for each invocation.
This empty line can go.
I see now. I think it is worth mentioning that this is controlled by the circuit breaker. Maybe right after the big about English not having that many variations.
but why? :)
I would add a null check here for the type given that it's only used from the java api, we can fail fast rather than doing it in validate
s/payload is/payloads are
these don't need to be static
well if it was a string all the way I wouldn't change it maybe, but given that the parser parses an object, I think this was a bug in the java api previously. We should rather have an Object here than rcompareed to moving to Strings everywhere
+1 on just `field`
I don't think we need to add logging to the builders: this only applies to users of the java API that would already get compiler warnings because of the deprecated annotation
In BaseTermQueryBuilder we convert BytesRef back to String in the getter, we could do here as well, otherwise client setting a String gets something different back here.
I would be using a `Set` in this circumstances.
ok I understand better your intention now. I think it is still weird from a user perspective to have to pass in `null`, not loving the nullable arguments. That said it is not a huge deal, can leave as-is.
Someday we're really going to have to standardize on American "canceled" or British/Australian "cancelled"... :)
typo - failIfCancled -> failIfCanceled
Can't recovery -> Can't recover
should we catch exceptions here to make sure we cancel everything we need
Typo, finalzlie -> finalize
maybe we could pass in null to the builder since the default is already handled there, that way the odd generateDefaultQuery could become private too :)
Also think this is right here. In JSON you get null here for ``` { "query": { "filtered": { "query": { }, "filter": { "range": { "created": { "gte": "now - 1d / d" }} } } } } ``` Which means the user specified something as query but its the empty set. In this case its not clear what to filter, but also not save to return any of Match_All/No_Docs query, since that would mean something different depending on any (potential) enclosing query, e.g. when this is used in "must" or in "must_not".
alright that's what I thought too, sounds good
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
I was having the same question in another query I was looking at. I think we made sure in constructors that the two builders are never null, but I was also wondering if if doesn't hurt having extra checks, in case e.g. some later change makes it possible to sneak in null query builders somehow. On the other hand, test should cover this. Sorry, undecided here, that's just what I had in mind in similar situation.
can we not wrap a translog but rather just keep this test translog next to the normal one? keep it simple and readable :)
Shouldn't we combine them? it looks so similar
can you please inline this while [adding docs](https://github.com/elastic/elasticsearch/pull/30176/files#diff-ed6e20d0c4d03d97ae9b7a9a33190c4bR1532)? We need to have more roll overs randomly
as in the previous test - you need way more evilness - more roll generations, more terms, move variance.
just fix a number, I don't think randomizing this adds much.
I think this has the same problem as in #17458 as it uses the first parser name to register the named writeable.
If we don't want to address this as part of this PR, let's add some TODO or norelease. I think we should do the same that we do for queries: make the parser a functional interface and use ParseField for parsing.
deprecated names match too. match should always return true, or rather throw an exception in strict mode if you use a deprecated name. I think it should be an assert. We had the same discussion with Colin in IndicesQueriesRegistry I think :)
the fact that the parse field matcher matches is a requirement, I think it should be an assert instead. It's really a our bug if it doesn't and we should catch it differently compared to "no function found"
I wonder if later on we are able to get rid of QueryRegistration and register stuff straight-away rather than when calling buildQueryParserRegistry. we will see later though!
And one downside even with being initialized before each test method, is some tests do multiple asserts like this inside a single method. So we'd have to clean up those tests to be separate test methods, but thats still fine.
Here would be something of an alternative maybe for the future, when java 8 is minimal (it would be less annoying due to effectively final and lambda): ``` public void test() { assertError(IndexOutOfBoundsException.class, () -> { int foo[] = new int[5]; System.out.println(foo[6]); }); } // test helper for expected exception // TODO: can we replace Runnable with TestMethod or similar interface that throws Throwable // so checked exceptions arent annoying? static void assertError(Class<? extends Throwable> expectedClazz, Runnable foo) { assertError(expectedClazz, null, foo); } // test helper for expected exception, with expected message static void assertError(Class<? extends Throwable> expectedClazz, String expectedMessage, Runnable foo) { try { foo.run(); fail("didnt hit expected exception, expected: " + expectedClazz.getSimpleName()); } catch (Throwable t) { if (!expectedClazz.isAssignableFrom(t.getClass())) { throw new IllegalStateException("got the wrong exception, expected: " + expectedClazz.getSimpleName() + ", got: " + t, t); } if (t.getMessage() == null && expectedMessage != null) { throw new IllegalStateException("exception had null message, but expected: " + expectedMessage, t); } if (expectedMessage != null && !t.getMessage().contains(expectedMessage)) { throw new IllegalStateException("expection message did not contain expected text: " + expectedMessage, t); } } } ```
It is a matter of taste i suppose, but i still hate all junit support for exceptions like this. The rule sucks because it has side effects, if we write another test that uses it, it can easily have some bogus leftover state from a previous test method? Personally i still do it tests like this: ``` try { something(); fail("should have hit expected exception"); } catch (SomeException expected) { assertTrue(expected.getMessage().contains("expected text")); } ``` This sucks too, in that its easy to forget the fail() part and have the whole test do nothing.
same here and in the rest of this method
I'd prefer using `IllegalArgumentException e = expectThrows(IllegalArgumentException.class, () -> prez.setRelevalntRatingThreshold(-1))` here like we do in many other tests and get rid of the @Rule
Is this because of https://github.com/elastic/elasticsearch/issues/12145? Just curious.
if you do `extends ToXContentToBytes` instead of `implements ToXContent` you get that for free
no worries as soon as you rebase you won't need to take care of boost and _name, it's done automatically.
I think we can simplify here and print everything out, default values included, that's what we went for in all of the other queries too.
I don't understand why there is either a setter (with null check & exception) here and then direct assignment to fields. Using either one of these would be fine I think. Same for the other options in this constructor.
maybe also rename the setting? (in addition to the constant)
oh sorry, I was not reading the diff correctly, it looked to me like setting sourceToLog was part of the constructor. Nevermind :)
I don't like this. the reason is that when you grep for `es.index` you find nothing. I think we should never do this.
right thanks for the explaining, I should have known, having worked on the search refactoring :)
Sure I was just wondering if there is a use case for this.
The `On` is superfluous. - `coalesceInput`, `greatestInput`, etc...
If the constructor is modified, this method won't be needed anymore.
removed? It does not seem to be used.
Do we want to _require_ a user provided key ? If I understand correctly, it really only protects against rainbow table attack when used in this context, but with the salt and potentially hard coded default key it seems we should be covered.
Set capacity to `2`
This effectivly means there is only one field loading concurrently on this service since you are locking on the `loadedDirectFieldData` I am 100% certain about all the implications but I'm 99% sure this is the wrong way to do that. If you want to prevent a single field from loading twice at the same time we have a nice datastructure for this called `KeyedLock` that you can use like this" ``` Java private KeyedLock<String> directLoadingLock = new KeyedLock<>(); //... final String key = fieldNames.indexName(); directLoadingLock.acquire(key); try { // load your stuff } finally { directLoadingLock.release(key) } ``` that way you can just remove all your synchronizaion
Well, I think this needs to be fixed here. There is no index created version in field data settings, this is an artificial thing that it sounds like you have added to workaround some other issue.
save -> safe
Old indentation was better because it made it obvious that the conditions weren't part of the body.
maybe a switch statement would make it easier to read? (now that we are on Java 7)
I'm happy we have all these tests. It is also another data point to move in the direction we discussed - i.e., failures should mark things as stale.
Can you add a textual description (makes it easier to understand)? I was wondering for example at first why we don't increase primary term upon full cluster restart (then I noticed we do, as isSameAllocation yields false if oldPrimary is unassigned primary).
I find the boolean condition quite hard to read, maybe negate the whole logic to get rid of all this weird `&&` and `== false`: ``` if (newPrimary.unassigned() || newPrimary.isSameAllocation(oldPrimary) || (oldPrimary.relocating() && newPrimary.isRelocationTargetOf(oldPrimary))) { // same primary term } else { // incrementing the primary term ... } `` ```
any chance we can shard this code with AllocationService
ah - now I see what you did it :)
I do not think we should log here. This is on the reload of a file and not an update to the ciphers settings
This is logic that I think should go into ReplicatedOperation.
I mean random number of replicas with random combination of non-active states
maybe randomize the number of shards and their states? (unassigned/initializing/closed)
it's usually a good idea to print the actual value as the assert message it can be very helpful if it doesn't reproduce
I am always getting confused by this one and refresh. Shouldn't this be `WRITE` and not `METADATA_WRITE`? We don't really change any metadata here.
I don't have strong feelings about it. I just find it confusing.
I don't think optimize should be `WRITE`. It is an administrative type action, you aren't actually passing data, just telling the system to do something.
+1 on keeping it `METADATA_WRITE`
ok, maybe we should think about improving this later on ;)
Make the method parameter `final` too; this is a safety guard against accidentally assigning to the method parameter instead of the member field.
Nit: spacing between the `)` and `{`: `){` -> `) {`
Make the method parameter `final` as a guard against accidentally assigning to it instead of the to the member field.
`limitedTo(long bytes)`? Clone is kinda non-specific.
I think the method name is a bit confusing as it doesn't set the limit to a new value but rather returns a new BigArray instance. I think we need a better name or maybe have new constructor `BigArrays(BigArrays arrays, long limit)`
I'm not convinced we should ignore failures. These tasks still occupy queue capacity, and there is no guarantee they failed quickly, a thread can be executing for awhile before failing.
Okay, I see later that we catch the overflow exception and that we skip adjusting; I need to think about this.
I don't understand wrapping the field name in backticks like this is markdown? (And a many other places.)
I think that these log parameters are backwards.
I see, it looks like the log message is written as if the size should come after "queue size" and the thread pool name should come after "threadpool: ".
Could you explain why this is needed instead of checking `expireAfterAccess <= 0`? I think it'd make the class more readable.
I don't think it changed the readability much - it made the checks simpler but then it left me wondering why two variables were needed. I was doing the "why does this have to be here, let me think hard about it" think.
I suggest that we take advantage of this change to remove support for time-based expiration, which we don't need
Or not. It looks like you are allowed to modify the segment's innards while you have this lock.
I was getting confused by invalidateAll - on second inspection you hold both locks when clearing the maps.
Sorry, I overlooked the null check. This is good!
You're solution is the best one. After thinking about this some more, I realized that my solution doesn't actually help at all because in the case where it would help it's going to be def anyway due to the promotions. You do need the 2-passes to get all the information necessary here.
Ahh, sorry. You are 100% correct.
Perfect! Thank you.
@uschindler Sorry again! I need to quit providing you with incorrect examples. I mean in this case -- `double x, def[] y = new def[1]; x = y[0] = 1`. the EChain for y will leave painless to believe a def is on the stack, but the duped value will be an int!
I think it's better to use the index version created to test whether the old or the new parent join should be used. This way you can make sure that the correct explanation is returned in the exception if the parent field is not filled.
I think it makes sense for term based queries (`fuzzy`, `prefix`, `phrase`) because they need to be aware of the internal representation of terms and we can make optimization based on the different options set on the field type (`index_prefixes`, ...). The `commonTermsQuery` is more a free text query with a very specific strategy. We should make sure that it uses `MappedFieldType#termQuery` to build the bag of terms internally but I don't think we should expose it in field types. This is just an optimized `matchQuery` which is why I used the term 'expert'.
IMHO we can also postpone such clean-up until after the branch is merged to master, just need to remember that we left a few things behind.
In other cases like this we went for reducing the number of classes, so here too, I'd go for adding these two simply as abstract methods.
In a followup PR we should merge SortBuilder and SortBuilderParser, I think. The latter one was only introduced as an intermediate step to avoid having to refactor all builders at once. Not sure if we can add the interface ToXContent there as well then.
Also `-test1,*test2*,-test20` or something along those lines? :)
I'm afraid we need to rely on the order if we want to be able to distinguish between negations (applied when a wildcard expression appears before the negation) and referring to indices that start with `-`. We will be able to get rid of it in 6.0 only when we will be sure such indices are not around anymore. I opened #20962. Can we also have a test where the wildcard expression is not the first expression but still before the negation? e.g. `test1,test2,index*,-index1`
@nik9000 Note that because of 5bbb1312b1b752a87d8ab1721042fad3f2133a7e this code in a slightly different place in 2.x (for the backport).
`foo`-> `{@code foo}`
thanks for adding this
ok let's avoid the concurrent put/computeIfAbsent issue for now, we can try to improve in the future if we observe slow concurrent access
I was getting confused by invalidateAll - on second inspection you hold both locks when clearing the maps.
Or not. It looks like you are allowed to modify the segment's innards while you have this lock.
I always think of `Iterator` as sitting between two entries rather than on the last entry it returned. But I see your way of thinking and am fine with keeping `current`.
I think the unlock calls should always be in a finally block
use simpler constructor.
We could avoid the anonymous class by just passing `metaData` to `PriorityComparator` and doing the work there. It seems like we used the anonymous class to avoid a constructor, but I recognize this is largely style.
OK. > On 20 Jul 2015, at 14:01, Shay Banon notifications@github.com wrote: > > In core/src/main/java/org/elasticsearch/gateway/GatewayAllocator.java: > > > ## > > - AsyncShardFetch<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> fetch = asyncFetchStarted.get(shard.shardId()); > > - if (fetch == null) { > > - fetch = new InternalAsyncFetch<>(logger, "shard_started", shard.shardId(), startedAction); > > - asyncFetchStarted.put(shard.shardId(), fetch); > > - } > > - AsyncShardFetch.FetchResult<TransportNodesListGatewayStartedShards.NodeGatewayStartedShards> shardState = fetch.fetchData(nodes, metaData, allocation.getIgnoreNodes(shard.shardId())); > > - if (shardState.hasData() == false) { > > - logger.trace("{}: ignoring allocation, still fetching shard started state", shard); > > - unassignedIterator.remove(); > > - routingNodes.ignoredUnassigned().add(shard); > > - continue; > > - } > > - shardState.processAllocation(allocation); > > - changed |= primaryShardAllocator.allocateUnassigned(allocation); > > - changed |= replicaShardAllocator.allocateUnassigned(allocation); > > I will do the assert when I remove the primaryAllocated flag in a different change > > â > Reply to this email directly or view it on GitHub.
can we add an assertion going out that going out of the primary shard allocator we don't have any primary shards in the unassigned list, unless we expect them to be there? (primaryAllocatedPostApi is false or restoreSource != null)
argh. Hidden by github ui. all good.
I think it'd be nice to remove this second ctor so we're explicit every time.
I think you can change this to a `Supplier<Analyzer>` now.
Ah! I get it now. LGTM
This could be `Strings.hasLength(tokenizerName)`
This is not good for backword compatibility. Instead it should do: ``` if (indexSettings.getIndexVersionCreated().before(Version.V_6_0_0)) { String tokenizerName = settings.get("tokenizer", "whitespace"); tokenizerFactory = ...; } else { tokenizerFactory = null; } ```
Typo: "recover" -> "recovery"
Nit: " . " -> ". "
Typo: "se" -> "so"
Maybe just clear a range of bits with `FixedBitSet#(int, int)` instead of clearing bit by bit? The implementation looks to be more efficient and would just require care around the offset wrapping.
The `<=` will need to be escaped.
I think we should use `debug` for the logging here
this method is entirely unused and you don't need that `pipelineStoreProvider` at all
please remove that blank line
same as above, function name says nothing about what it does.
This constructor doesn't seem to be necessary.
