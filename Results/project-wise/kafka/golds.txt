"different" for sure, but this implies that one might have an operator the other does not. The observed issue is, that even if both contain the same operator, they might be added in different order (and thus be named differently) to the `Topology`, thus we should stretch that order matters.
nit: is this change necessary? They are originally sorted alphabetically before.
Hmm, maybe we can move this check into the KafkaConsumer's catch block before `close` also.
It might be a personal preference, but I'd rather just suffer the duplication of having separate catch blocks for separate kinds of exceptions.
Checking my understanding. With this change, it should no longer be possible to expire a batch before linger.ms has completed and the batch has been closed. If so, do we still need the logic to abort appends on expiration? (It might be safer to have it anyway, just checking if it is still needed for correctness)
As above, not sure we should make the `threads` field accessible outside of the class. Trying to think if there is another way to test this...
Basic patch looks fine, but this code formatting won't pass checkstyle. After cleaning up you can verify it passes with `./gradlew clients:checkstyleMain`.
we would have already closed the task with `task.close(false)` at this point
Can we use something like `TestUtils.waitUntilTrue`? This approach will make tests unnecessarily slow.
Regarding `MetricNameTemplate`: makes sense. Regarding `*MetricsRegsitry`, I think even with these classes we cannot centralize them right? think: if we add a new metric in the future, and the developer need to add it both in the `*MetricsRegistry` and here; and if she forgot to add it in this class, nothing will break at compile time, so nothing is programmatically enforced.
Just to be more concrete here, I think we can move the expiration out of the loop https://github.com/apache/kafka/pull/10462/files#diff-6ca18143cc0226e6d1e4d5180ff81596a72d53639ca5184bf1238350265382a6R154 for fetching any records to join, based on the above analysis.
With regard to naming: we should also check that the store in only queryable is a name is specified via `Materialized`.
I think some high-level description of the purpose of `transactional.id` would be useful. We basically use it to tie two sessions together. We should also mention that it is unique to a producer "instance."
```suggestion * Options for the {@link AdminClient#alterConsumerGroupOffsets(String, Map, AlterConsumerGroupOffsetsOptions)} call. ```
Why did you separate the two cases? The respective `if`-bodies still contain the same code.
Yes, I think you should try to experiment with putAll()/range/reverseRange/prefixSeek operations as you proposed with a simple Kafka Streams app. That would be great to better understand the potential of direct buffers for Kafka Streams. Maybe experiment also with different key and value sizes. I am curious if we will also get such improvements.
nit: this is unused
In the other two variants, we used a literal `1` and `2` here. Not sure if it matters at all, since the way we get here is that `usedVersion == 3`.
After a second thought, I don't feel strong about it.
Do we still need this? It seems unused.
@ewencp Regarding making `OffsetAndMetadata` mutable, does that make sense if we do defensive copies of the passed in map as is being suggested? It seems to me that ownership rules would be inconsistent in that case and we would be doing plenty of allocation with the map copy anyway. It's also worth saying that due to boxing, we were already allocating `Long` instances, so the number of allocations doesn't change, it's just the size of each instance.
I think we can remove the mention of the rebalance listener since it is not invoked in this context.
Ack. Was not sure if it's an intentional change. Thanks for clarifying that it's an actual fix.
nit: "is" -> "were"
Given that this is only used in one place, and the string that it creates is itself added to a formatted string, I think it'd be a bit more readable if we removed this method and inlined all the logic where it's being invoked right now.
It seems like this would have initially appeared unnecessary because we already removed it on L230 when we first put it into the dirtyTasks map. But what appears to have happened is that we actually got an exception during commit, and added some more tasks in L252-L253, which were not removed from the task map. What is the overall algorithm here? Offhand, it seems like we should only remove the task after we know it is closed, which means we should delete the `iterator.remove();` on L230 and keep the line you've added here, along with adding a similar line between L264-265 (after closeClean). I'm also wondering if we should really do closeDirty on L271, or just add it to dirtyTasks. If we keep it there, then we also need to remove it from the task map at that location.
Well, my point is, that the check can be simplified. I don't think that `record.headers() == null` can be true; it's guaranteed that there is a headers object. Not sure if we can simplify the second check. It iterators over the headers map and does String comparison to find a header with key `v` -- seems to be rather heavy.
nit: `uoe` -> `expected`
Do we need to capture-and-rethrow here? Since the caller will always capture and swallow, this seems unnecessary to me.
Is there evidence that we really need all this stuff? It will just be another thing that we need to change when we move to a new version of the JDK. I think a better approach would be to take this stuff from a local file or an environment variable passed to the ducktape process.
The content of this test does not fit with the name of the test. There is no other topology that continues processing.
How about this: in `Sensor` we expose a public function `hasStats` which checks if its `stats` is empty or not. If it is empty then it means no `sensor.add` has ever triggered yet (e.g. all the `emptySensor` would be the case), in which case we can skip measuring at all. By doing this we can also remove the extra check on the caller for the config value --- i.e. we consolidate the logic to be independent of the config, but only relying on the sensor's `stats` map.
Is ignoring the right answer? Would it be better to fail fast? If not, at least a warning should be logged.
I think we should assert that the "predicate" and "negate" config were the implicit ones and not the ones defined by `HasDuplicateConfigTransformation`. I guess we could do this by having `HasDuplicateConfigTransformation`'s configs use different types ("negate is `BOOLEAN` in both) and then asserting the expected types.
They do the same thing, but the majority of calls are on wrapped().
There seems to be some redundance between `partitionsToRetry` and `remainingToSearch`. It might be nicer if we could get rid of `remainingToSearch` so that we only had to rely on `ListOffsetResult` to know if we should retry. I think the only thing we need is to avoid losing partitions in the call to `groupListOffsetRequests`.
Assuming `nFlightBatches` is a TreeSet suggested above, this code can be simplified to: ``` while (!inFlightBatches.isEmpty() && inFlightBatches.first().maybeExpire(deliveryTimeoutMs, now)) { expiredBatches.add(inFlightBatches.pollFirst()); } ```
Tiny nitpick: you can declare error in this line too as it's not used outside the loop anymore
A `raw type` is being used here, that should generally be avoided.
I disabled all IntelliJ auto-reformatting to avoid any unrelated reformatting.
Thanks for the explanation, and thanks for fixing the synchronization. As an optimization, I think we should use something like `ConcurrentMap` here rather than synchronized blocks, so that we can minimize the amount of time threads spend waiting. This will be a bit more tricky to use, but more scalable. I guess when I thought about KIP-511, I thought of it in terms of metrics and perhaps occasional samples of connections (similar to how we do request sampling by logging a few selected requests). I don't see why we'd ever need a full snapshot of all existing connections. The snapshot would probably be out of date by the time it had been returned, since new connections are closed and opened all the time. Reading the KIP more carefully, I see that KIP-511 does specify a metric which essentially requires each connection to register itself. Considering we don't even have a way to visualize or graph this metric, I'm not sure this belongs in JMX. I have to think about this more...
+1 to "based on the {@code topicExtractor}"
nit: can remove type arguments
req: Please use a constant for the number of stream threads here and on line 260.
I am not sure if it would be better, but it feels like this is the kind of tweaking of templates that should be done in the templates themselves based on forwarding parameters to the template via the class members. In other words, if there are bits that should be swapped out, maybe we should encode those as methods on this class or simply conditionals in the template instead of doing regex search & replace here.
Maybe add an assert checking `streamsString` contains the app-id. But considering this method will be removed, I'm also fine with it as is.
nit: add opening and closing curly braces for all the `if` / `else` blocks on lines 1102 to 1108
What about `merge()` operation? I think we could have a case for which there are multiple parent nodes.
+1, the above check for empty leader and epoch obviates the extra check we were doing in safeToFetchFrom. I missed that
+1. I think the appropriate functional interface is âJava.util.function.Consumerâ
How about using java stream? ```java Arrays.stream(TransactionState.values()) .collect(Collectors.toMap(TransactionState::name, Function.identity())) ```
I see - fyi you can actually retrieve idx from the node: `self.idx(node)` and the node from the idx: `self.get_node(idx)` Since these are more or less interchangeable, I'd lean toward making the method signatures consistent
Below we check and construct a subset of `validTopicNames`; we should skip if that subset is empty, and just return the future with exception with the rest invalid topic name.s
No I'm referring to the `generation()` itself: we call this function twice within the function and in between the generation object may have been changed.
netrics => metrics
nit: I would also create a local `consumerRecord1` as you did with `consumerRecord2`. Alternatively, you could use the global `consumerRecord2` instead of creating a local one. In my opinion, mixing the global and local makes the code less readable.
Same thing here with the `connectorProps` vs the `config`.
nit: add `final`
If you want a new paragraph, you need to insert a `<p>` instead of an empty line.
I don't immediately see the difference between the removed and added code.
nit: was -> were
How about just ``` log.info("{}: (stdout): {}", id, resp.get("log").toString()); ```
No need to reorder imports.
My bad, I hadn't noticed that the rethrown exception was actually different (subtle name difference). I blame the small screen on my phone. ;)
The topic may not be in the metadata due to some edge conditions, we cannot throw the exception in this case.
I think we should call `deserializer.close()` here
We should also update the java doc to mention the TopicId changed case
It might be useful to review the history behind `Utils.atomicMoveWithFallback`. It's not clear to me why this case is different from some of the other situations that it is used.
This seems suspicious... * Shouldn't all blocking operations have timeouts? * Should we be swallowing and ignoring InterruptedExceptions? It seems like a recipe for Streams to hang forever un-killably. But I feel like I'm missing something.
nit: I don't think there's any reason to mention this. Unexpected errors fall under `KafkaException`, which is listed below.
why removing this line? It is intentional to initialize the recorder with different metrics.
`e` is not a good variable name
Restore interrupt status by calling Thread.currentThread().interrupt();
Thanks. Will merge after Jenkins is green.
nit: 4 space indention only
and IMO `if(!isStopping()){throw e;}` can cancel this noise.
I think @omkreddy is just suggesting to create a helper to avoid the code duplication. Seems like a good idea to me.
Left this out of my previous review. This needs to change as well as it will return false for two `Segment` instances with the same `id`. Also, this statement will always evaluate to false as `Long.compare(x, y)` only returns `-1`, `0`, or `1`.
This still needs to be addressed
add missing generics to return type and remove "unchecked" suppression? nit: add `final` to parameters
orignal was better
It reads weird to say > disabling <code>enable.idempotence</code> I would write the sentence as: > Allowing retries while setting <code>enable.idempotence</code> to <code>false</code> and <code>" + MAX_IN_FLIGHT_REQUESTS_PER_CONNECTION + "</code> to 1 will potentially change the" I would also move this paragraph below: > Enabling idempotence requires this config value to be greater than 0...
Can we make this private? Doesn't seem to used anywhere else. It has an odd return value, which is less of an issue for a private method.
The one we are keen on is PLAIN. We will be using SASL with SSL, so PLAIN gives us the simplest secure authentication without having to distribute certificates for mutual client auth. Yes, a separate PR makes sense so that this one can be committed soon. I will raise another JIRA.
Ha, that existed. Strange, I remember searching for such a thing before and not finding it
Nit. Line too long
Ah, sorry I didn't think of this/mention it before, but I think we actually need to wait for a _transition_ to RUNNING, and not just for it to be in the state itself. It probably takes a little while after removing a thread for the rebalance to occur, so it's probably already in RUNNING. Pretty sure there's some other integration test util that watches for the REBALANCING -> RUNNING transition, though
Yeah, I think that's fine. We probably need a JIRA for any other built-in assignors we want to ship with 0.8.3 anyway, e.g. I assume we'll have a copartitioning implementation for kstreams.
For window / session stores, there's no putIfAbsent function and hence no metrics would be registered.
I think it makes sense to move this flush to `KafkaRaftClient::onUpdateLeaderHighWatermark`. It is possible for the high-watermark to increase without the LEO increasing. To avoid unnecessary flush calls, the leader should remember in `LeaderState` the LEO when it flushed the log.
```{@link org.apache.kafka.common.KafkaFuture#get}``` => ```{@link org.apache.kafka.common.KafkaFuture#get()}```
This is still missing in the KIP wiki page.
Ah, good call, that makes sense to me
Good catch. It's probably too late to change that though.
It seems like these two approaches are fighting for dominance in this code. Personally, I favor the "flat" design, where these methods don't call each other. It's just easier to read when each one in isolation lists all the operations it needs to do. It's also more general, since a hypothetical future version N might add some new metadata in the middle, or even drop some previous metadata and so wouldn't be able to call decodeVersion{N-1} in its implementation.
Let's keep the `L`
`<byte[]>` this explicit type is unnecessary
Should this call be governed by !dryRun
We do not have a unit test for delete group yet.
We can also get here if handshake has already failed (state == `State.HANDSHAKE_FAILED`) and there are still bytes to be flushed in `netWriteBuffer`.
After the iterator is returned, the lock is released, then the stream thread can still close the RocksDB store while iterator is not closed yet, right? An alternative approach I was thinking, is to keep track of a volatile "RocksObjectCount" for all associated objects, including RocksIterators / WriteBatch / etc, and let the close() call to only proceed when the count becomes 0. Note for WriteBatch since it is only going to be created by the same stream thread it does not actually matter, but just in case it will be created by different threads in the future. But there is still a race condition if the alternative approach is not carefully implemented such that after the query thread has called `validateStoreOpen()` in `range()`, but before the iterator was created, streams thread can kicks in and delete the store. So we need to increment the count first before checking if store is closed.
`compressor.close()` will re-fill the wrapper message metadata by re-computing crc, etc; it does not result in correctness issues, but may incur unnecessary costs, since they are not just "no-op" when called again.
Oh yea! @mjsax
The state transition is not great at the moment for passing exceptions to the user so any help there is appreciated. What @bbejeck says makes sense.
I think we need to handle preferred leader election in a special way. For example, if the assigned replicas are 1,2,3, isr is 2,3 and the current leader is 3, when doing preferred leader election, we want to keep the leader as 3 instead of changing it to 2.
Suggestion to improve the message: ```suggestion throw new ConnectException("Fail to retry the task after " + maxAttempts + " attempts. Reason: " + lastError.getMessage(), lastError); ``` And, if `maxRetries == 0` should we just call the function without any special handling, since we're not retrying? For example, should we add something like this very early in the method? Doing that would make it easier to phrase this message, since the `ConnectException` will only be used when at least 1 retry may be attempted. ``` if (maxRetries <= 0) { // no special error handling return callable.call(); }
Nit: maybe `("Topic: " + topic)`
nit: how about just using letters alphabetically from "A" than using multiples of `XYZ` only? Relying on numbers of letters may be bug-prone (see below).
nit: i guess we could combine these two statements ```java if (replicationFactor.isPresent() && sortedBrokerIds.size() != replicationFactor.getAsInt()) ```
nit: Since you imported statically also the other matchers, you could also statically import this one to be consistent.
I would omit this (not the test, just the sentence) and put examples into the web docs.
For regular API calls (ie, "main code") we should list them. For a test, no exception should ever be thrown, and if, the test fails. Which exception is irrelevant IMHO.
nit: `changelog, repartition and output topics names` (as there are other internal topics, we might want to rephrase this more general: ``` The returned set of topic names may include user (e.g., output) and internal (e.g., changelog, repartition) topic names. ```
Nit: add `final` (please apply this wherever possible -- of course only code you change :) )
I wonder if in this case we should always materialize the join table. It would help us with resolving this bug: https://issues.apache.org/jira/browse/KAFKA-4609
This formatting is going to fail checkstyle. There seem to be other failures as well. For the changes in this patch, run `./gradlew clean clients:test` to make sure everything will pass.
I'm not sure these add value since TransformationChain has log messages with the records, which should be sufficient to know whether the schemas are null.
Since we have a Jira ticket that is even referenced here, I would prefer to remove the ToDo from the code.
Ah, I was actually thinking that any message (in particular a consumed message?) after a shutdown complete would be a thing to raise an error over. Really just a sanity check, might not actually be of use.
docstrings go below the class (unlike every other language). same with other changes in this patch
> mm2-offsets.{source}.internal includes - so allowing dash as a separator may be problematic I am still not sure why this is problematic? In your Jira, you mentioned the following > MirrorMaker2 creates internal topics to track the offsets, configs, and status of the MM2 tasks. But, these topics are not affected by a custom 'replication.policy.separator' settings - that is, these topics may be replicated against the user`s intention. This issue can easily be fixed by handling `.internal` in `isInternalTopic` default implementation. I would suggest just doing this small fix instead. I don't think we need to use the separator or replication policy to define any of connect's topics as users have already a way to override them using `<CLUSTER_ALIAS>.config.storage.topic`, `<CLUSTER_ALIAS>.offset.storage.topic` and `<CLUSTER_ALIAS>.status.storage.topic` configs. No point of controlling the same config in two different ways.
`completeing` -> `completing` We should also probably mention that this is a temporary solution. And we should file a JIRA for the proper solution.
`ApiKeys` -> `ApiKey`
I was asking more for a semantic one -- as long as this is not expected then I'm happy for this piece as is :)
I added a TODO about this, we probably need to solve it in a subsequent release.
nit: unneeded newline
That's fine, might just need to be made clear on the release instructions wiki since it is different than how, e.g., the merge script is used.
Right. But note that the current dirty-key in cache is not enough determining if we have, **ever**, write for a key to the underlying store which is not deleted yet: dirty-key only contains the dirty-keys since last flush, i.e. the key not in the dirty-key is only a necessary, not sufficient condition. And that's why we can only consider not writing the tombstone if the read on this key returns null-bytes, indicating nothing was there.
I think it should be a KafkaException (or a subclass of it). IllegalStateException in this class refers to an invalid configuration that is more compile time than runtime, whereas a partitioning problem is purely runtime and only occurs with custom partitioners.
Because we're not using the `subscribe()` functionality, we don't need to configure a consumer group. It will use a null group by default (https://cwiki.apache.org/confluence/display/KAFKA/KIP-289%3A+Improve+the+default+group+id+behavior+in+KafkaConsumer)
why does this message differ, saying "short / string", but the rest just state the type. I think the string part is superfluous.
I think so, changed it locally.
nit: do we need the `numTasks` argument since the only caller is passing MIN_TASKS? Alternatively, we could replace `info.tasks().size() >= numTasks` with `!info.tasks().isEmpty()` and get rid of `MIN_TASKS`.
I moved the bounds into the plural check method, so we can check correct behavior for multiple bounds.
+1 for me on `AutoCloseable`
Ha, you are right. Glossed right over this.
Ok. We also have a check in `subscribe` to ensure that the set of assignors is not empty. There might be a way to remove the redundant checking. By the way, there's a typo above: `confingure`.
Do we need to call remove ever? Since `filteredOffsets` is constructed empty can we just do the following: ``` if (!globalNonPersistentStoresTopics.contains(topic)) { filteredOffsets.put(topicPartitionOffset.getKey(), topicPartitionOffset.getValue()); } ```
I guess you could just have a separate `setPreviousRecordTimestampIfNecessary(window, previousRecordTimestamp)` method that sets the `previousRecordTimestamp` to the window's max timestamp if it's larger. And then if it ends up that `previousRecordTimestamp == timestamp` then we can automatically skip all of the window creation below, which is nice
How about this? ```java // The consumer fetch position needs to be restored to the committed offset before the transaction started ```
nit: add `final` We try to use `final` where ever possible. Please also add below (including the for-loop).
This variable should be declare `volatile` because the callback is executed on a different thread.
I think this should be synchronized.
Already mentioned, but I think we can be smarter about caching some state to avoid unnecessary work here. Validation is only needed if we do an unprotected seek or a metadata update arrives. Probably this can be left for a follow-up. It's only a concern when the number of partitions and the poll frequency is high.
I have no strong opinion on close-parameter vs streams config. So ok with me.
I stepped through `testNoLeader` and it seems that -1 can indeed be a key in `isrMembers`. The `noLeaderIterator` makes the expectation explicit.
Iterating over the entire list on every added field looks a bit suboptimal. Since we are using this in the Converters and we convert every batch of messages, this may have actual impact. Did you check what would it take to change the data structure of fields from List to Map (using field name as a key) and then use containsKey to check if the field already exists? It should be more efficient, but if this has too much impact on the code elsewhere, maybe it isn't worth it.
I was just reading up the original KIP-98 design doc. Actually, when `beginTransaction()` is called, it's just a local producer-client state change. The transaction timeout should start ticking only after the first `send()` for the transaction. Hence, it's seems ok to call `beginTransaction()` pro-actively in `initializeTopology()`.
nit: avoid `this` if not necessary
We should probably change the exception class here since `ConfigException` takes a config name and value while this one is passing in the exception message and cause like other exception constructors. Then existing log entry would be sufficient as well.
prop: ```suggestion final boolean followupRebalanceNeeded = assign( TASK_0_0, TASK_0_1, TASK_0_2, new TaskId(1, 0), new TaskId(1, 1), new TaskId(1, 2), new TaskId(2, 0), new TaskId(2, 1), new TaskId(2, 2), new TaskId(3, 0), new TaskId(3, 1), new TaskId(3, 2) ); ```
The check 'if (deliveryTimeoutMs <= (now - this.createdMs))' inside maybeExpire() would be true. Looks like another method can be created inside ProducerBatch which expires the batch.
I think it is a bit confusing to call the generation valid if we are in the pending state. I am debating whether it is worth the complexity to add another `MemberState`, say `PENDING` for the state in which we have a memberId, but are not yet part of the group. Perhaps it would be sufficient to use something like this instead: ```java public boolean hasMemberId() { return !memberId.isEmpty(); } ```
I assume this was unintentional.
The purpose of this change was to highlight that the data structure is required to be concurrent. Of course if a method that existed in `ConcurrentMap` and not in `Map` was used, that would be a hard requirement. `putIfAbsent` used to be such a method but that's not the case after 1.8. In any case, the use of the more accurate interface is valid even if we don't explicitly use methods that don't exist in the parent. That's because the need for this implementation to be thread safe is a requirement here.
Should this be `num_lines=3` for all three (cf. L140-L142)
I think we don't need this one.
Why did you decide against passing in the spec or the arguments in the end? It makes the class more unit-testable (not that we have unit tests) and it's generally easier to read I find
Does this need to be in `o.a.k.streams.state` or this package? I'm just wondering..
Yeah, let's remove if it's unused. We can add back if we need it.
maybe a nit: I understand what you are doing here, but IMHO there should be two separate tests.
@shikhar This is needed because these tests reuse a common `expectPollInitialAssignment` which _only_ handles getting the member into the group and returns zero records. The subsequent expected poll call will actually retrieve the message and cause the records to be put into the sink task.
`null` is redundant
Is this only errors? I suppose we will need this even to return a successful response. Perhaps call this responseCode/responseData
This newline is not needed.
All of the log messages in this method could use a description of the callable. WDYT about adding a `Supplier<String> description` parameter, and using that in the log messages. For example, the `KafkaBasedLog` could supply ``` () -> "list offsets for topic '" + topicName + "'" ``` then this log message might be: ```suggestion log.warn("Call to {} will only execute once, since retryBackoffMs={} is larger than total timeoutMs={}"), description.get(), retryBackoffMs, timeoutMs); ```
Same thing here with the `connectorProps` vs the `config`.
typo: computer -> computed
```suggestion public void shouldIgnoreIrrelevantLoadedCheckpoints() throws IOException { ```
Nit: `.` full stop missing.
nit: add `final`
`logStartOffset` and `lastStableOffset` are not getting filled in when server responds with OffsetOutOfRange error. As @hachikuji pointed out, you need to fill that in on server side here: https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/server/ReplicaManager.scala#L1031
We should add this API to the `Consumer` interface.
1. Let's make it a warn instead of a debug. 2. The error message can be more specific here: `Error closing task producer for task {} while handling lostAll`.
nit: add `final`
Ack, thanks for the explanation.
This is what @guozhangwang was asking for.
Haha, I'm not sure whether we're saying the same thing. My suggestion was to blindly treat the exception as a top-level error. In other words, take the error code from the exception and use it as the top-level error code for new versions, and as the partition-level error code for old versions.
A more reliable way to check if a user explicitly sets the config is to check from config.originals(). Ditto for configureRetries().
Yeah, that works. I was even thinking of just extending SerializationException with that information and leaving the existing constructors. But I don't think it matters much whether it's a new ConsumerSerializationException or (the slightly awkward) SerializationException wrapping another SerializationException with the info just placed directly in the message.
I thought about this when tightening the FSM before but the unit tests reminds me of one thing: our current contract is that we only transit to PARTITIONS_REVOKED when calling onPartitionsRevoked, which is called only once at the beginning of the rebalance today, so keeping it strict is better just in case we have incorrect partial rebalance procedure. With KIP-429 this may be violated so we need to revisit our FSM once Streams adopt cooperative protocols. cc @ableegoldman who's working on this.
I was thinking we'd just use the release script from the older branches for older releases.
This should probably default to `NoOpStateRestoreListener` otherwise i think it is going `NullPointerException` if the user doesn't add a listener
I think this function is now two dimensional, i.e. the response might need to be something like: ``` Resource type is ANY and resource name is ANY ```
the `try{...} finally` has been removed
This exception isn't used in createTopics.
Might it be simpler to just do: ``` topicCounterMap.put(topic, prevPartition -1); ```
Nit: add `{ ... }`
Should this be a warning or even `info`? It doesn't seem like there's much for the user to do in this case.
Seems this method and `getConfigValue` are only used in `toHtmlTable` and `toRst`. Would it make sense to move these implementations into `ConfigDefUtils` as well? I tried this out locally and it seems to work. Then we don't need to expose these methods and the definitions here just become stubs. For example: ```java public String toRst() { return ConfigDefUtils.toRst(this); } ```
nit: add `final` nit: add space `entry : writeBatchMap.entrySet()` (I thought this was a checkstyle rule? Wondering if my memory is wrong because build passed)
Just noticed something else wrong with this message. `e` will get ignored. We should instead use `log.error(String.format("...", logPrefix(), appId), e)`
No need to apologize. :)
nit: blank missing :P
could be replaced by lambda.
Rather than sleep 12 times, you could wait for an `metadata.updateRequested` before doing the `update`.
Do we still need to verify that `channelMock.position` is called once? Given that the old test works, `channelMock.position(...)` should be invoked. If we don't do `when(channelMock.position(42L)).thenReturn(null)`, what would be the return value if `channelMock.position(...)` is called? It seems that channelMock.position() is called in the old code but not the new code. If so I am wondering which part changes this behavior.
Nice solution to this problem.
We could also use `hasRemaining` for these checks
About 5x to 10x the size of what the array holds.
This is a very confusing method. There is a risk that it may be invoked inadvertently when making changes, even though it is meant to be only for tests.
Why the second client will have two pending transactions? Upon migrated the task the initTxn should cause the pending transaction failed.
I think this was actually correct as it was (and ditto for the above). One alternative suggestion: ```suggestion * Set the handler invoked when an internal {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG stream thread} ```
"given a read-only key"
One scenario where we may hit this is during an upgrade when we have some consumers on older versions. Might not be worth checking that though.
This is a slightly different test. The window is much larger to ensure all the entries are in the same window and the last timestamp for (a, 0005) is such that it causes the resuling composite key to come after the one for (aa, 0004)
We do not need id as it is included in the prefix already.
just noticed this - I think we want `clean_shutdown=False` here to ensure we really kill the process if the normal attempt to gracefully shut it down failed
Overwriting the parameters `keyFrom` and `keyTo` might be dangerous, because it has side-effects outside of the method. Unless you want to have the side-effects. If you do not want them, please use local variables and specify the `keyFrom` and `keyTo` as `final`.
prop: I find the `assignment.` prefix a bit clumsy and I think we do not really need it. Other configs do also not have its context prepended like for instance `built.in.metrics.version`.
We are not very consistent unfortunately. But I suggest sticking to the approach that was used previously in the file.
Rather than trying to control when and when not to fail unsent requests, I wonder if we should use "request.timeout.ms" to selectively fail only those requests whose timeouts have expired? Then we could remove the `failUnsent` flag everywhere and just call something like `timeoutExpiredRequests()`. In that case, we could remove SendFailedException entirely and use TimeoutException. What do you think? The only problem is that I'm not sure whether this could cause strange behavior on coordinator fail-over. For example, suppose that we try to send a commit just before the coordinator crashes. In that case, the commit could get stuck in the request queue. We may find the new coordinator and the old coordinator may even come back before the commit's timeout has expired. In that case, if the commit eventually is sent to the old coordinator, then we'd suddenly see a NOT_COORDINATOR_FOR_GROUP error, which would cause us to find the coordinator again unnecessarily. Maybe all we need to address edge cases like this is a way to fail any pending requests to the coordinator when we find that it has failed.
Nit: `new Runnable()` not required, you can just override `run()` from `Thread`.
Do we need two parameters here? Could we still just use one `Map<TopicPartition, Long> checkpoint`, and then in `writeCheckpointIfNeed` if it is not null write it and then set it to null.
nit: As said in the other PR, this is a good idea but I would only do it if we do it for all exceptions.
Generate the type and write it out to the internal state.
original was better
Should this be `warn`. Its likely an incorrect set up that can potentially cause this and might be useful to know it by default.
Suggestion: "and transformed values with type {@code R}".
This isn't a REST extension necessarily, right? It's also used by Kafka via JMX. I think mentioning `worker restarts` and `rest extension` might be confusing
Seems like this file has a bunch of unintended changes.
Reading again, maybe you mean that an exception will be thrown back to the user although it may not be from the method one would necessarily expect. For example, `send` won't throw an exception due to a failed batch, but `commitTransaction` will. Instead of explaining in detail here, we should probably refer to the actual methods (which need to be updated as well).
This exception can't be thrown by listTopics.
Thank you for pointing this out! I will have a look at this in the next days.
ditto on removing before/after.
Why not replace the `initialized` check with a null check? In that case, `value` needs to be volatile and `initialized` can be removed.
nit: remove `this` and move one line down -- first initialize with parameters, than everything else
`isEmpty` is a little nicer than `size() == 0`
We can just hard-code `250` here.
I think you missed marking this one as "windowed"
nit: ` .. over the properties prefixed with {@link #CONSUMER_PREFIX} and the non-prefixed versions (read the override precedence ordering in {@link #MAIN_CONSUMER_PREFIX)..` ditto below.
Can we use an ordered set then? Just to make sure we can't end up with a task appearing more than once in the same list/set
Sounds interesting, cc @kkonstantine
`stores` -> `stored`
Maybe we should deprecate this method in favour of `partitions` with an explanation.
I think it's because of: ``` * <p> On some systems, closing a channel releases all locks held by the Java * virtual machine on the underlying file regardless of whether the locks were * acquired via that channel or via another channel open on the same file. It * is strongly recommended that, within a program, a unique channel be used to * acquire all locks on any given file. ```
Nit: please use single parameter per line formatting
nit: remove `this`
`ConsumerRecord<byte[], byte[]> consumerRecord`
Could we do "group mode" only in this example? The example doesn't really extend to multiple instances otherwise.
Looks good, thanks.
nit: we have tended to use an `int` for the version in other cases to avoid the annoying typecasts in the caller.
I think key-pairs of strings as list is brittle. But we inherited that.
+1. All for user readable assertions. If the bytes format is standardized then it should be tested in SubscriptionInfoTest.
nit: space before `{`.
This one is not needed since this tool should always be executed from trunk.
weird that the import became unused, even though there were no other code changes...
nit: do you think we should log at ERROR since this is not expected really? Right now we would sort of "hide" such bugs and still be able to proceed silently; I feel we should shouting out such scenarios a bit louder in logs.
I think this check each time is quite expensive if the partition size is large. So, I think we can do "lazy check" for this case. Because `allOwnedPartitions` is a `Set`, we can check if any duplicated partitions existed via the size sum. That is: ```java // get the partition size we're going to add int consumerOwnedSize = subscription.ownedPartitions().size(); int prevSize = allOwnedPartitions.size(); allOwnedPartitions.addAll(subscription.ownedPartitions()); if (allOwnedPartitions.size() < prevSize + consumerOwnedSize) { // duplicated partitions in 2 consumers found // log warning here // if we want to find out which partition cause the problem, we can also iterate them here. } ``` WDYT? Thanks.
Is this okay? If committed == null it means no offsets get committed for this partition in `getCommittedOffsets`, and we should check that we do not get any data in `partitionRecords ` but currently this check will always pass even if `partitionRecords.getValue().size() > 0`.
@ijuma I have been able to reproduce it on Windows, Mac OS, and Ubuntu. More [here](https://issues.apache.org/jira/browse/KAFKA-3129).
added `per key` (twice)
s/`is the protocol`/`the protocol is`
`KeyValueIterator` instance needs to close explicitly to avoid resource leak. Please fix it and the other similar places. Thanks.
Do we really want to mention `BigDecimal` here (it's really an implementation detail)? All the user needs to know is that the scale present in the value differs from the scale specified in the schema.
prop: change `stateStoreNames` -> `stateStoreName` here.
There is no `get()` for a `SessionStore` The key in the session store is a combination of the record key, start and end time. We only know the start time for the previous key so we need to find the previous session with the correct start time.
I'm wondering if we should use `CommitFailedException`. In the consumer, we do not expose illegal generation and unknown member id errors directly to the user.
nit: may worth explain how `queryableStoreName` can be find from `materialized` below.
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
Unclear why we're mixing some parameter substitution inline, and leaving others to the final substitution with the `args`. Made it confusing to figure out what was going on with the `JMX_PORT`, which looked like it had been lost since it wasn't in `args` any longer.
`replicaing` -> `replicating`
I'm fine either way, the main difference is that everything listed so far is global and not really specific to Connect (and can therefore be processed and logged immediately upon startup) whereas getting `plugin.path` requires doing some argument parsing and would be logged later on by the normal argument parsing `logAll` call.
TBH, no, I've never considered that! Thanks for the reminder. @RivenSun2 , sorry, I forgot the `AbstractConfig` is a public API. But since the v3.2.0 KIP freeze has passed, and I think this KIP might need more discussion, could you submit another PR to revert this change first? After KIP discussion/voting passed, we can start to work on it again. If you don't have time to submit a revert PR within this week, please let me know. Thank you.
I don't think an IllegalStateException gets thrown when empty lists come into the picture. Consider the following scenario: ``` java // assume polls may be interleaved consumer.subscribe(Arrays.asList("topic")); consumer.subscribe(new ArrayList<String>()); consumer.assign(Arrays.asList(new TopicPartition("topic", 0))); consumer.assign(new ArrayList<TopicPartition>()); consumer.subscribe(Arrays.asList("topic")); ```
Makes sense. If it's static, then we could also extract it to a separate file, which might be better than having one of the siblings define a class that both siblings use. Also, it would reduce the LOC in this class, which is nice for readability.
I figured. I think in this case capitalized is better, or simply start the sentence with "Any " to avoid the decision. ð
Ah you're right. My understanding is that to manual upgrade from version 1/2 to version 3, we set `upgrade.from` config accordingly, so first rebalance everyone use version 1/2 in subscriptionInfo and AssignmentInfo; then in second rebalance someone send subscriptionInfo with version 3, and someone send with version 1/2 (they have not bounced yet), so assignmentInfo with version 1/2 are sent back again.
nit: this looks like it wants to be a static constant now.
Okay I think this makes sense, let's just follow this pattern then.
`clientId` is not used
You might want to swap the order of the logger args and the `count`/`max` args. There are multiple overloads in `slf4j` and this is only one of them. There's also `(String)`, `(String, Object)`, `(String, Object...)`, and `(String, Throwable)`. The `(String, Object...)` version is actually the one you want to use as the most general version, the others exist purely as an optimization.
Yeah, I was wondering if it would make sense to pass the request context so that at least you could add the URL path (and maybe params) to the message. One additional nit by the way: when DEBUG is enabled, we'll see this message twice because of the log line above. We could print this only if debug level is not enabled or something.
What do you think about taking the name `CompletedFetch` here. It seemed a little more descriptive.
Nit: `restore` -> `consume` ? This consumer is used for regular processing -- "restore" sounds like fault-tolerance only.
I think caching the exception may actually be OK. For both `SerializationException` and `InvalidRecordException`, we've overridden `fillInStackTrace` anyway.
`.` at the end missing
super nit: `byteValues` on 164 and `windowed` on 168 should be final as well
I am wondering whether we can do better here. Encoding partition time in Base64 seems to me a bit a waste of space. As far as I can see, a 8 byte value is encoded in 11 bytes with Base64. Would be great, if we could store partition time in 8 bytes. I am also wondering why `metadata` in `OffsetAndMetadata` is a `String` and not something more bytes friendly.
It seems like it would be more direct to check `baseOffsetOfFirstBatch < 0`.
Do we expect `TimeOrderedKeyValueBuffer` to be queryable ever (I saw you changed it to extend StateStore)? If yes we need to make this variable as volatile since IQ threads may access `isOpen`.
The point is not that the next record is at a higher offset, but that the current position deterministically decides the next record to be returned. After we have caught the exception from the record at offset 1 (say), the position remains at offset 1. However, the next fetched record may be at offset 2. If we catch an error at that offset as well, the position will remain at 1 (I guess?) and the next record we try to return may be at offset 3. This makes the consumer less functional since the behavior of a fetch at the current offset depends on the history of previous fetches. The alternative is that the consumer always fetches from the current position. If the user wants to skip a message, they must explicitly seek to the next larger offset. Then the result from a poll is always deterministic. The user is in control and the consumer will not try to guess what they want to do. Whether by design or by accident, this is how the new consumer has worked up until now, so another thing to consider is whether changing this behavior will cause any compatibility issues.
I looked through the StreamsMetadataState and it does seem like it could technically be null if this instance was never assigned any active or standby tasks at all, ever. That really _shouldn't_ happen, but of course it can if you massively over-provisioned your app and we shouldn't throw an NPE over that. Seems like this is actually an existing bug that we should fix. Then we can improve the initialization check on the side
With an empty list it means "return me every topic you know".
These methods can throw any number of other exceptions, which we would catch and wrap when called via `send`, but would **not** catch and wrap when called via `commit`...
as above: avoid `/` Update to ``` log.warn("Unable to read '{}{}{}'. Using default inputValues list", "resources", File.seperator, fileName); ```
Personally I'm still a bit leaning towards making the groupName as a field inside `TaskMetrics` same for `ThreadMetrics`, since it is quite hard to debug a typo issue in this case, and more string constants, more likely we will hit this.
I think this way of triggering the exception is not only complicated but it even might be a source of flakiness. Could we have some more straightforward? I think the original solution (overriding getResponse) was better than this.
OK, added that.
```suggestion * If the return value of {@link ValueTransformer#transform(Object) ValueTransformer#transform()} is {@code null}, no ``` Please also fix this on the original method
`assertEquals` should be used here and any other place where we are comparing numbers. `assertSame` checks for reference equality and it may return false if the number is outside the cacheable range even if they're equal (the various `valueOf` methods used by auto-boxing cache numbers within a certain range).
Let's remove on both side: I think in J8 it is not really a big difference.
```suggestion * @param named a {@link Named} config used to name the processor in the topology. ``` Or something similar, it just reads a little bit on the terse side, which I think would confuse people initially. Please also apply this feedback to all the other param docs.
The suppression operator should not do this (evidenced by the fact that this change breaks the SuppressTopologyTest). The KIP specifies the behavior when the name is present: ``` * Use the specified name for the suppression node in the topology. * <p> * This can be used to insert a suppression without changing the rest of the topology names * (and therefore not requiring an application reset). ```
nit: add `final` to `String` (just to help us cleanup the code :)
Ah, yes, it's `org.apache.kafka.test.TestUtils#tempDirectory()`. My mistake. The protocol is for all temporary state in Kafka tests to use that method. The change I made in `QueryableStateIntegrationTest` is basically what we should do here as well.
There is a corner case in regarding the listener here: say a ListenerA class was previously used in the consumer, and now it wants to subscribe with another ListenerB class, after calling subscribe(), before sending a join-group request, a rebalance could be triggered upon, for example partition change, which will then use the new ListenerB class already. Not sure if it will be an issue though.
Nit: whitespace ```suggestion public void closeTaskErrorMetricGroup() { ``` Also, just curious, any reason we don't want to implement `Autocloseable` and rename this method to `close`? It'd align nicely with the precedent set in https://github.com/apache/kafka/pull/8442, for example, and would make this class easer to use with [Utils::closeQuietly](https://github.com/apache/kafka/blob/e8dcbb99bb3289193a9036599d87acd56e11499f/clients/src/main/java/org/apache/kafka/common/utils/Utils.java#L998-L1009) if we wanted to go that route in the future.
nit: should be `ConnectHeaders`. *probably* would be easy to figure out, but better to just get it right :)
nit: may as well fix alignment as well
Does replication factor matter in this test at all? I can't think of why it would matter for the replication factor, so it seems weird to make it 2 here.
See my question regarding using mocks above.
Personally I'd suggest we only keep a skip sensor for user to monitor correctness since the the "processed record sensor" is well covered in the throughput sensor already. And for that skip sensor we can use `Rate()`. For example, as in `record-error-rate` in `Sender.class`.
something like `inferredInternalTopics.containsAll(specifiedInternalTopics)` might be easier to understand here
I had the same question. It appears better to just duplicate the properties.
nit: move `key` to new line
Note that we are effectively only retrying 4 times with this logic, since if we happen to successfully send out all the record on the fifth retry (i.e. `needRetry` is not empty) we are still going to throw error here. So more strictly we should check ` --remainingRetries == 0 && !needRetry.isEmpty()`.
Why do we need this? The idea of the ticket was to change existing code that catches `TaskCorruptionException`: after we wipe out the local state store, we trigger a rebalance if standbys are enabled.
I think info log would also be OK here. I imagine users that are wondering why their standbys are not distributed as they would expect. With this information they can at least try to fix it on the config level. This log message should only happen at rebalance time, which should usually be rather seldom. If we decide to put the log message on info level, you should also change a bit the wording and not use variable names in it. Maybe some hints what the users can do to fix this would also be nice. Is it possible to separate the concerns of this log message and the one on line 135? Something along the lines of here the rack-aware standby assignment did not work due the tag config and on line 135 the assignment did not work due to too low number of instances. We can then put both on warn or info (do not forget to also check the related log message in the default standby assignor).
Yes. Got confused about the correct order...
nit: `final` + next line and might as well do the previous while you are at it ;-)
Any reason for using an empty list here rather than `null` as a sentinel? The empty list approach seems like it could lead to confusing results if you have a programmatically generated list which can sometimes be empty. Right now it's not a problem since we only expose `listTopics` and `partitionsFor(oneTopic)`. But wasn't there a proposal for something like `partitionsFor(String... topics)`, in which case this could affect the public API.
> I felt the same, but I picked this approach to make less changes in the code, since I am beginner here. That's fair. However, we should not "optimize" for fewer changes but for better code. :) > But, I need to give a thought on kind of prefixes we should use to make it unique for various fail cases. `validateMillisecondDuration()` will just add the prefix. Each called can pass in whatever prefix is suitable for it.
Is there a case when we don't need synchronization? Passing in the class from the constructor is fine, but I think we should just synchronize all the time.
This is an inter-broker request. So, no throttling needed.
I thought that retaining the fetches meant we wouldn't need this check anymore and we could merge the two loops.
I'm mostly concerned about the time to run tests. If it does not make a substantial difference either way, then we can leave it.
I think we need to use some suffix because otherwise we would generate two names, ie, end up with a naming conflict -- problem is, that a `KTable` results in two processors and we need a name for each.
Sure, no problem. It's a slim and harmless chance, that's why I mentioned.
I do not think this exception can be thrown from CreateTopics.
This is a little annoying, but you do that the Throwable is also a parameter. As far as I can see, there is no overload that takes a Throwable _and_ parameters. I assume that's why Anna did it like this. However, I didn't test to see if slf4j does a runtime check on the arguments to look for a Throwable (it would surprise me if it did).
`partitionAssignor.activeTasks()` -> `partitionAssignor.standbyTasks()`
Increase the timeout makes sense to me.
I don't think we really need to include the exception in the message since we'll get the full trace anyway.
It's a nuanced topic. It would be good to clarify if we can find a good way to say it. The operator itself never processes data out of order. It always respects the order defined by the topic. But upstream repartitions don't provide any guarantees about the order they _write_ to the topic. This is how data can logically become out of order, even if users take care to populate their input topics strictly ordered, which might in turn violate some expectations with `null`s in the picture. I'm concerned that if we start saying, "Kafka Streams processes data out of order", with no context, it'll create FUD. We should be up front about the limits of the system, but it doesn't benefit anyone to create the impression that we don't guarantee things that we actually do guarantee.
super nit: maybe reverse statement to `maxInFlightRequestsAsInteger > 5` IMHO easier to grok, but this is highly opinionated, so feel free to ignore.
We have multiple null check for `childrenProducerBatch` which is not necessary, instead we could just reject here if the given `childrenProducerBatch` is null to ensure it's non-null.
Is it intentional that there's a space before the colon? Also, is the stacktrace useful here? Or do we just want to print the error message. I haven't looked in detail, so a genuine question.
Is just checking connectionFailed enough? For example, the connection may be fine, but a batch can't be sent to leader because the max inflight requests to leader has been reached. In this case, it seems that we can timeout a batch in the accumulator before those that are still in flight.
I wonder if we should name the field `%sSizeInBytes`. I just looked at the result and having `"records":83` in the request log is not super clear to me.
Split into two test? Or rename accordingly.`testDelete` is not a good name IMHO.
Question regarding naming consistency: Also, we perhaps want to rename "aggregate key" to "count key" or sth, given that we renamed e.g. `aggValueSerializer` to `countSerializer`? (No strong opinion on this one. If we assume developers will be used to "aggregate key" because that term is used for all the other functions where one needs to pass in a selector, we should keep the current terminology when talking about `count`.)
Actually the old `hasPid` would always return false in this method since we reset the PidAndEpoch at the beginning, so we would always get a pid. Also, the `transactionCoordinator` check is also redundant since we always check whether there is a valid coordinator before sending requests that need it. So this is a good simplification.
I know this line hasn't been changed, but the `this` variable refers to the `ConnectorContext` that does not have a `toString()` method. Might be better to refer to `WorkerConnector.this` instead, so that it behaves like old line 87.
It actually would be helpful to include the exception's error message in this line, since the message alone might be bubbled up via the REST API. ```suggestion log.error("{} Error converting message key in topic '{}' partition {} at offset {} and timestamp {}: {}", this, msg.topic(), msg.partition(), msg.offset(), msg.timestamp(), e.getMessage(), e); ```
This method also seems to be testing `get`, rather than `put(k,v)`, so maybe we can just migrate away from the deprecated method.
this method won't work with empty `prefix` but that's not obvious just by reading its name.
Actually, it's not just older requests, the default was always `""` whereas I am seeing `null` after this PR. It looks like there are two issues: 1. We didn't set a default of `""` for clientId in the json schema. 2. The generated protocol code behaves differently with regards to default values. It only uses the default if the field is not present. The `Struct` code uses it if `value == null`. ```java Object value = this.values[field.index]; if (value != null) return value; else if (field.def.hasDefaultValue) return field.def.defaultValue; else if (field.def.type.isNullable()) return null; else throw new SchemaException("Missing value for field '" + field.def.name + "' which has no default value."); ``` This is the generated code _after_ I add the `""` default for `clientId`. ```java public void read(Readable readable, short version) { this.requestApiKey = readable.readShort(); this.requestApiVersion = readable.readShort(); this.correlationId = readable.readInt(); if (version >= 1) { this.clientId = readable.readNullableString(); } else { this.clientId = ""; } } ```
I think if you mark this method as `@Deprecated` as well, it will also suppress the warnings, which might be better because it preserves the deprecation notice from the interface.
Aren't you still missing setting the error code field on the struct in this case though? The pattern that seems to be used elsewhere, e.g. in `MetadataResponse`, is to make the constructor that takes the version contain all the fields as arguments as well as the version. Then all the decoded fields are kept as member variables and written regardless of whether that version contains them, but only written to the struct conditionally. For example, `MetadataResponse` has some code that looks like this in its constructor: ``` this.clusterId = clusterId; // This field only exists in v2+ if (struct.hasField(CLUSTER_ID_KEY_NAME)) struct.set(CLUSTER_ID_KEY_NAME, clusterId); ``` (after having constructed the `struct` with the correct schema). I think if the current code is working, it's just lucking out on `NONE`'s error code being `0` or something. I wouldn't think it would work as is since the field doesn't have a default value defined.
You might want change IntelliJ to use the `java.util.Objects.equals and hashCode (java 7+)` setting when generating `equals` and `hashCode` implementations -- it generates nicer, tighter code that plays better with our checkstyle.
Hmm.. I think the original logic made more sense. Even if `completeExceptionally` returns false, it's still an error, right? We would not want to then proceed to `future.complete` or the next operation.
nit: add empty line
I feel enforcing users to create OffsetMetadata upon commit brings some overhead, especially in practice most people do not want to embed any metadata with their commits. I would like to propose an alternative solution regarding the API: commit(Map<TopicPartition, Long>, ComitType, String /\* Commit Message _/) commit(Map<TopicPartition, Long>, ComitType, String /_ Commit Message */, ConsumerCommitCallBack) And the commit message will be used as the metadata for all the partitions included. It is based on my assumption that users usually would have a single commit message (i.e. the metadata string) per each commit call; if they want to have different messages for different partitions (for example in CopyCat @ewencp), they can call commit() multiple times with the metadata strings on each partition. This of course may cause more round trips for all sync-commit, but I would suggest people to use the following pattern: commit(async); commit(async); ... commit(sync); // last call Since now the commit calls are all ordered.
nit: we could just call `numPartitions()`. Alternatively, we might consider a friendlier representation such as "none" or "undefined."
```suggestion * <p>A {@code retryBackoffMs} that is negative or zero will result in no delays between retries. ```
thinking aloud: guess there is nt much value in wrapping a single provider.. so +1
Yes, a test is absolutely necessary!
would be favorable to order comparison result according to first citizen. Like `metadataTimestamp >= localPartitionTime ? metadataTimestamp : localPartitionTime;`
I seems that `TableTableJoinIntegrationTest` has a similar issue...
`InternalProcessorContext` is already public interface but it's in `internals` package, so I figured it is okay? Anyways, this is not much blocking this PR, so feel free to merge it anyways and we can keep discussing here while you merge.
nit: Indicate that this needs deep iterations on the entries.
Thanks for the details. Should we instead do a "clean up" within `getWriteBatches()` and only return open segments? Seems to be a better separation of concerns.
nit: This can be put in one line
might want to rename `workerId` so it doesn't shadow the member field. something like `workerIdOpt` could work
It seems like this new constructor only supports the "error assignment" code path. Can we just inline it? I admittedly didn't quite follow why we need this version check now.
Extra "for" in "milliseconds for that"
This check means we don't have to construct the exception message string if we're not going to throw.
Synced with @dguy offline on caching, the current semantics "only dedup on forwarding if it is the default CachingXXStore with wrapper RocksDB" looks OK to me. I think we need to re-consider the unification of caching with dedupping after this since now with user customizable stores this caching mechanism is narrowed to default state store suppliers only.
typo `reach` should be `each` (Might be somewhere else, too. Please double check.)
```suggestion capturedConsumedCallback.getValue().onCompletion(null, new ConsumerRecord<>(TOPIC, 0, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, null, TP0_VALUE.array())); ```
Can you remove `{}` since there is only one line after `if`? Otherwise LGTM
It looks like we don't support mixed mode testing. That seems worth a follow-up JIRA. It is definitely an interesting case from the perspective of the raft implementation since it involves two listeners.
Add the `@Overrride` annotation to this method.
We can remove this line now. `close()` will be cause automatically using try-with-resource clause.
This is going to call punctuate on every node - right? Which is not actually correct, I think something like @guozhangwang suggested might be a better approach.
This part is duplicated -- can we make DRYer? I suggest adding a checkpointsForGroup() method, and use that in both places.
`2` -> `entries.size() - 1`
I think this is a typo that can be reverted.
nit: I think we could use a more convenient type, such as `Map<Integer, InetAddressSpec>`. Ultimately this just needs to make it down to `KafkaNetworkChannel.updateEndpoint` so the conversion to the config value is unnecessary.
This should be `LOW` since the corresponding config for window size of a windowed serde is also `LOW`. The configs are grouped by Importance so you'll need to move it to the section below (and also it should be in alphabetical order).
I'd clarify to sth like: > 2) use specific data types (here: JSON pojo; but can also be Avro specific bindings, etc.) for serdes in Kafka Streams. To make it clear that this example does not showcase Avro usage.
Should we add the check in the `Sender.completeBatch()` as well to note call split in this case? Otherwise if the producer was sending uncompressed messages and one of the message in a batch a too large, it seems the producer will not fire the callback with correct exception. This would probably be a rare case because a big message will typically get sent in a dedicated batch if compression is none. But it is theoretically possible if user configured the producer batch size to be larger than the max.message.size.
Maybe checking that `get(tp)` never returns null? If not it should indicate a bug.
Let's avoid unnecessary blank lines. ```suggestion ```
Hmm, seems like we are exposing a class from an internal package (`requests`) in a public class.
Why not check `context.timestamp`? Checking the message of the exception is very brittle.
Removed this and pass in the `processorName` as `String` parameter directly.
Similar to `LeaderState::nonEndorsingFollower`, I think you want to add a method to `LeaderState` with the following signature `public Set<Integer> endorsingFollower()`.
Yes, the logging is what I had in mind. The log message is misleading otherwise.
Might be worth mentioning that this method also sends a new offset commit when autocommit is enabled.
@spena seems there are a few different conditions we can consider here: 1) record time < stream time - window length - grace length: the record is too late, we should drop it up front and also record the `droppedRecordsSensorOrExpiredWindowRecordDropSensor`. 2) record time >= stream time - window length - grace length, but < stream time: the record is still late, but joinable, since the stream time would not be advanced we would not have to check and emit non-joined records, but just try to join this record with the other window. Note that like @mjsax said, for the returned matching record, we also need to check if the other record time >= stream time - window length - grace length or not. 3) record time > stream time, we would first try to emit non-joined records, and then try to join this record.
Yes. Question is, if we can verify that all 3 streams instances are running and waiting to brokers to go online instead of plain sleep.
Also out of date here.
Dropped duplicate code, as discussed.
@fhussonnois can we move the logic from here to the `NamedInternal` to always generate the name to ensure we increment the counter for backward compatibility? Something along the lines of ```java private String orElseGet(final Supplier<String> supplier) { final String generatedName = supplier.get(); return Optional.ofNullable(this.name).orElseGet(() -> generatedName); } ```
Using `UNASSIGNED` might be confusing here since the connector/tasks have been assigned at this point. I think we should either stick to current state or target state here even though it isn't user visible as it'll make it clearer what's going on. (Relatedly, but not really important, `action` might be better named `targetState` or something like that given it is using the `TaskStatus.State` type.)
I vote yes for this. I think if we use this for writing snapshot from the state machine, then minimum size is a more interesting metrics for flushing to disk vs lingerMs. If we implement this so that either one has to be true then the client can set the `lingerMs` or `minSize` to MAX_VALUE if it wants to ignore those values.
Throttle time defaults to `0`, so this is not required
Should we trim this? ```suggestion this.dlqTopicName = connConfig.dlqTopicName().trim(); ```
nit: more simply ```java if ( acl.resourceType() != action.resourcePattern().resourceType()) return false; ```
Should we explain the magic number `1` here? Why `1`? Can it be any other positive number? One way to clarify would be to use a "label" variable like `int anyPositiveSize = 1;`, then call `JoinWindows.of("join-0", anyPositiveSize)`.
You can remove `: {}` as we are not passing any args anymore, that is, we are calling the second method instead of the first: `public void warn(String format, Object arg);` `public void warn(String msg, Throwable t);`
If we use a `List`, we should be able to simplify the logic below by using an enhanced for loop.
Now that this logic is not tied to offset commits, could we move this loop into `AbstractCoordinator.close(timeout)`? That would make it available to `WorkerCoordinator` as well.
It might be better to be more specific here. "if no authorizer is configured on the broker"
We should probably include the full package name `org.apache.kafka.common.metrics.MetricsReporter`.
This reminds me about the test coverage: maybe we should also test that store.put / delete can be triggered while the iterator is open, and if the put / deleted elements would not be reflected from the iterator.
No `else` needed since we used `return` for both other cases. For the exception, I think we can just throw `ClassCastException` since `IllegalStateException` doesn't fit very well for this case. I would also make the message a bit more generic to avoid it going stale when we add more `Records` subtypes. For example: ```java "The record type is " + partition.records().getClass().getSimpleName() + ", which is not a subtype of " + Records.class.getSimpleName() + ". This method is only safe to call if the `FetchResponse` was deserialized from bytes."
Are you sure you want the FQCN here? simple name is another option which might be nicer to print. But in any case, want to make sure we are deliberate here.
Preferred leader election is an optimization. If we can't move the leader to the preferred one, it seems there is no need to do anything extra.
maybe rename this to `setUp` and put the loop populating the array in this method
nit: could we move this initialization closer to its usage in L285? or just `.minus(Duration.ofDays(1))` could be simpler.
`this information` is ambiguous -- unclear from the context to what it really refers -- maybe better: `If no specific partition is specified the default behavior...`)
As discussed before, for `fetchAll(final long timeFrom, final long timeTo)` we actually do not need to trigger this function at all since we know it should always return true. I think we can either 1) claim that `fetchAll(final long timeFrom, final long timeTo)` is also not optimal and people should avoid using it with the new schema, or 2) try to still keep that impl as optimal as possible, i.e. in `AbstractRocksDBSegmentedBytesStore#fetchAll` we have a condition like this: ``` return keySchema instanceOf TimeOrderedKeySchema ? return new SegmentIterator<>( searchSpace.iterator(), (....) -> true, TimeOrderedKeySchema.toStoreKeyBinary(0, from, 0), TimeOrderedKeySchema.toStoreKeyBinary(0, to + 1, Integer.MAX_VALUE), true) : // else return the normal implementation ```
Question: What is the contract/the semantics, if any, for the order in which we turn multiple topics into a single stream? IMHO we should be a bit more explicit here, which includes the option to say "We _do not_ guarantee xyz..." /cc @guozhangwang
It seems that you are right, David. Closing when the selector is closed makes more sense.
Yeah, my PR removes all of these in favour of existing constants: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
I think it would be cleaner to extract this code to a separate method.
Let's wait until the KIP is merged before this one.
We could use a "for each" loop here, something like: ``` for (Class<? extends Connector> connector : connectorClasses) { connectCluster.configureConnector(connector.getSimpleName(), mm2Config.connectorBaseConfig( new SourceAndTarget(primary, backup), connector)); } ```
I would prefer to use `List` instead of `ArrayList` to be more generic.
update to `return stream(offsetReset, null, null, null, topics);` to avoid too many indirections. To this for other overloads, too, please.
If we don't need to track the pending offset commits, maybe we could move this into a `AbstractCoordinator.close(timeout, unit)`.
To be clear: we only need to do this if `(!records.isEmpty())`, right? But I guess you are suggesting that it's easier to reason about if we just do it at the start of the method? Generally, calling that method should be cheap but since we have to acquire a lock after your changes in this PR, it may make sense to avoid calling it if not necessary. Let's see what @hachikuji thinks.
We should annotate `withName()` as `@Override`
Yeah it's a little awkward/misleading, but ideally no one should be hitting this exception in the 1st place once we have this fix. So this seems fine for 2.6.2
Is it actually useful for `metadata.awaitUpdate` to throw an exception? Maybe it should simply return a `boolean`.
Instead of hardcoding these numbers, can we define them explicitly to make the code easier to read? Like this for example: ```java double JITTER_MIN_VALUE = 0.8; double JITTER_MAX_VALUE = 1.2; double jitter = Math.random() * (JTTER_MAX_VALUE - JITTER_MIN_VALUE) + JITTER_MIN_VALUE; ```
Do we really need 10 threads? Seems like 2 would probably be enough
We should update the tests for setting the `stateStore` and `recordConverter`
As an aside, it would be awesome to add `Optional` support to the generated classes. We have had so many bugs which were caused by sentinel values sneaking into unexpected places.
base -> based progress -> progressed
We could just use int.
This is an improvement, but seems a little verbose. How about this? ``` // execute delayed tasks (e.g. autocommits and heartbeats) prior to fetching records. // It is crucial for "at least once" delivery semantics to ensure that offset commits can // only be sent prior to updating the position in ``fetchedRecords``. ```
Should we get a `seed` value and log it (to allow reproducing if the test fails)? ``` final long seed = new Random(System.currentTimeMs).nextLong(); log(seed); final Random rand = new Random(seed); ```
nit: ```suggestion throw new ConfigException(DLQ_TOPIC_NAME_CONFIG + " has a topic name which matches the regex in " + SinkTask.TOPICS_REGEX_CONFIG); ```
Nit: please add `final` to all local vars and method parameters
It would be good to have a function in `version.py` to reflect this
Using commands is a really good idea. It makes the implementation so much clearer. One point to clarify is wether we want to prefix commands with `--` in order to remain consistent with the other command line tools. What is your take on this? It seems that we defined aliases for commands so we might be able to have both.
Nit: `enqueue` would be a little clearer.
Maybe not including `cluster` for all the client specific settings would be slightly better, WDYT? ``` "source.cluster.bootstrap.servers": "localhost:9092", "source.cluster.security.protocol": "SASL_SSL", "source.producer.some-producer-setting": 123, "source.consumer.some-consumer-setting": 123, "source.admin.some-admin-setting": 123 ```
This is not thread-safe. We should return the local variable instead of the field. Also, it would probably be safer to make the static field volatile.
This is not introduced by this PR, but: is line 934 necessary? We checked `sortedTasks.isEmpty()` at the head of the loop and there's no other operations on this list anywhere else.
@guozhangwang A metadata fetch could return in the middle of a rebalance (i.e. with the JoinGroup on the wire). In this case, we may end up discovering a new topic that we didn't know about before and adding it to our subscription (see `subscribeFromPattern`). We are able to catch this case currently because although the subscription has changed, `joinedSubscription` has not. With this patch, this is no longer true.
I think `record sends` reads better
Maybe we should clarify that we invoke the callback and deallocate after the iterations (because we close the batch here, one could say that we have done part of what one may consider expiration).
Maybe this should read: > Perform leader election for the partition of the topic passed in as argument and waits until leadership changes replica.
Looks like these could be replaced with: `assertThat(driver.readOutput(...), equalTo(new ProducerRecord<>(topic, null, timestamp, key, value)`
As I suggested before, to not expose the node information, we should remove this function.
I think we just want to get rid of the special handling for logical types, but if it stays, the handling here needs to change. Any user defined schema can have a name too.
Looks a little odd to use the offset commit interval as the poll timeout when commits have been disabled.
I'm afraid I might have led you down a rabbit hole. The `Worker.isSinkConnector(String name)` uses the Plugin mechanism to properly load the class with the correct classloader. My recent request to move that logic into the WorkerConnector would simplify the logic, exception in a case like this where we don't have a WorkerConnector instance. So perhaps the best thing is to use the new `worker.getConnectorType(className)` that basically just uses the `worker.isSinkConnector(className)`. Apologies for causing you extra work. It would have been nice for my suggestion to work out, but its the case where that isn't known that is causing the difficulties. Using the worker should always work (assuming the connector is installed to begin with).
Here you should test if the stream thread has the name of the stream thread that was removed before.
Nitpick: in Kafka, we generally set the field where it's first used unless it's an if/else where the field could be set in either.
I suggest to use HashMap and LinkedList here since only one thread will process all responses.
nit: extra blank line ```suggestion ```
if you have an unsigned ~~8-bit~~ 64-bit data source
Yes, those suppliers must return a new instance on `get()`, too, so the new check should be done for them as well.
We don't really care about the stack trace here or below, just the message. We know the `StreamsException` is generated from this class and the message is enough to identify the problem. Further, these are done in a retry loop so can become quite verbose if failed multiple times
We should use interpolation instead of string concat here.
```suggestion left.join( right, (value1, value2) -> value1 + value2, joinWindows, streamJoined ); ```
nit: this could be a `break` also.
We can still set `final` -- note, that `final` implies that the parameter `config` cannot be reassigned to a different `Map` -- the `Map` itself is still mutable though and thus it can be altered within `KafkaConsumer` later on. (Adding `final` is more a question of style here.)
It's definitely not a strong preference and the performance aspect doesn't really concern me either way. I am just trying to think through the full implications. One implication of discarding fetches is that it would be impossible to make progress unless the user handles the exception (either by propagating it or seeking to another offset). It's not clear to me if this is desirable or not. I also wonder whether some of these seek cases you mention are handled currently. Wouldn't it be possible even with the current patch to do a seek while a fetch is pending? In that case, the out of range error would apply to the previous offset and not the current one. That suggests to me that we ought to be checking the consumed position in SubscriptionState before throwing the exception.
from the KIP, I think this is supposed to be `source-task-metrics`
I'm sure there must have been a reason for this in the original implementation, but it still surprised me to see it. I think it makes sense for the resigned leader to help another candidate get elected. I'll file a separate JIRA about this.
Can we also rationalize the different names. Ig uess this method should be `checkpointsTopic`.
Thanks. I had this on my mind when I was working on the tests for the framework PR. It occurred to me that another approach would be to simply run a dummy query and check the returned position. But I guess that doesn't really count as a "unit" test, since the intervening store layers could in theory be changing the position as well, so that approach might not be testing what it thinks it's testing. This is more direct, and to be honest, I don't think it's that bad in the context of a unit test.
This should be `org.apache.kafka.common.message` to match the directory that the generated source files are outputted to
I think we can remove this warn and just rely on the info entry above.
`KafkaConfigBackingStore.this.sessionKey` is already a `volatile` member variable. So, given that no other common data structures are altered in this block, I'm suspecting that your change means that we might as well get rid off the `synchronized` block altogether in this `else if` branch here. I'd like to give it a second thought in the morning but lmk what you think.
nit: we can just call the function with three params which will then use `DEFAULT_TIMEOUT = 30 * 1000L;`.
Couldn't we just remove `tpr0` from the test then? It does not seem to bring much.
This is part of the public API, so we don't know all the ways its being used. I still think we're better off output a more complete message.
Instead of changing the usage of this method everywhere in the code base, how about generating an overloaded method which call this one with `verbose=true`? I only expect this one to be used by the request logger at the moment so it is also more convenient.
nit: let's use `DECIMAL_FORMAT_CONFIG` instead of the literal string here.
Why did you change this to a `Set`? It seems unrelated to the ticket.
It looks good to me.
This ended up printing out ``` AssertionError: num_produced: 1000, num_consumed: 869 ``` So I went and checked the console consumer log. Sure enough, I found this was the first message reported: ``` [DEBUG - 2015-08-20 16:44:53,298 - console_consumer - _worker - lineno:177]: consumed a message: 131 ``` So for some reason consumption didn't start with the first message. I ran the test and collected the `VerifiableProducer` log and it claims all were acked, they all went to partition 0, etc. I also logged the number of messages the `VerifiableProducer` claims were acked and that is 1000 as well. It seems something is still funky with this. How many times have you tried running to reproduce this? It sometimes passes for me, but maybe 50-60% of the time is failing. (By the way, it's kinda weird that the console consumer's per-message log goes to the test log, but verifiable producer is sent to a separate log file...)
We do not recommend using wildcards in imports.
nit: fix indention (we usually use 4 spaces, not 8)
firstException wouldn't be null at this point - see call on line 510 It seems call on line 510 can be removed
Existing issue: space after colon. No need for `()` in `getVersion` and `getCommitId`.
`expireMs` should probably be a `long` since we use it as if it's never null a few lines below.
I don't have a strong opinion on the log level `DEBUG` is fine with me.
`out-of-order` (with `-`)
Will that ever happen, though? In `maybeSetRunning` we only call `setState(RUNNING)` if all other threads are in the `RUNNING` state. So i guess it is more to stop moving to `REBALANCING` or `ERROR`
I am wondering if we should throw an `IllegalStateException` here, because it seems illegal to me to request a lock of a task directory in a state directory that does not exist.
`StateSerdes` is use to read/write into local stores and changlog topics. Because changelog topic should only be read/written by Kafka Stream, it seems we don't need a change there to me.
This call to the replacement mapping function may result in an exception, for example if the replacement value of `foo` is used on a field of type `DECIMAL`. It is proper to throw an exception, but would we not want to wrap that in a `DataException`? And speaking of failed replacements, it'd be good to have more such conversion failures in the `testReplacementTypeMismatch` unit test.
prop: ```suggestion assertThat( getMovements(stateConstrainedAssignment, balancedAssignment, tasksToCaughtUpClients, maxWarmupReplicas), equalTo(expectedMovements) );
`Map::put` returns the previous value.
This is very fussy, but for some reason, the phrasing here is bugging me. The addition of "must have" almost makes the event seem more uncertain and open to interpretation. Like we need to reassure the user that our deduction is correct. Maybe we can leave that part out? ```java log.info("Resetting the last seen epoch of partition {} to {} since the associated topicId changed from {} to {}"... ```
We need to think about how we can avoid this. The package structure appears to be working against us.
For an 0.11 release, the committer can still put the email together manually... We need some cutoff point for back porting -- it's just a convenience improvement for doing a release, not a bug fix. Thus, 1.0.0 seems to be a clean cut-off point IMHO.
I think we do not need to reset here since we are throwing the `InterruptException` again, which will set the flag as well.
Thanks, all. I share the concern that this change could suddenly break something. Since the transformer has access to the ProcessorContext, people well may be accessing these members within the `transform` method. For example, a transformer may suddenly start to get an NPE on the topic name, and so forth. This behavior change might be ok on the grounds that the context we previously provided was actually incorrect, though. If we do go ahead with this approach, we should be sure to make note of this potential in the upgrade notes. It wouldn't hurt to have a ticket as well, for visibility's sake.
@ncliang checkstyle fails because there's an extra single white space here: ``` [ant:checkstyle] [ERROR] /home/jenkins/jenkins-slave/workspace/kafka-pr-jdk11-scala2.13/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/isolation/DelegatingClassLoader.java:345: 'try' child has incorrect indentation level 13, expected level should be 12. [Indentation] ```
I can maybe understand a null value, but is a null key something we want to support? This is also making me wonder whether we should be implementing some mandatory namespacing.
If we're going to go down the route of wrapping everything, then we should hide the `MetadataResponseData` field so that it can't be modified to be different than the wrapped fields. So we shouldn't have `data` as a public method (it should be private, or absent)
I'd say calls as well. It's very common to apply similar style to both. In any case, with this still being a nitpick, I think it makes sense to have 1) all args in one line (not flexible) 2) args split in exactly as many lines are needed by the width - which leaves several args per line and 3) have 1 arg per line. There's not too much uniformity in AK right now, but wanted to let you know of a trend.
the fact that two variables are used here must be a remainder of an earlier iteration. ```suggestion KafkaCompletableFuture<U> result; ``` can be declared here at the top level and we can remove the inner declaration.
Personally, I like the existing design. The `DualColumnFamilyAccessor` has to do a lot of extra checking that isn't necessary if there's just one cf to deal with. If we collapse them into one class with a flag, we pay for it with a lot of branching. One thing I did find confusing was reasoning about the fact that the Dual accessor is embedded in this (Timestamped) class, and the Single accessor is embedded in the parent (non-timestamped) class. But, we're using it as an accessor for this (the child) class. This seems unnecessarily convoluted, and it's a little hard to see if it's actually ok, or just coincidentally ok, since the parent and child APIs are only semantically, rather than actually, different. It seems simpler to understand if we pull both accessors out into separate classes that take `db`, `name`, `options`, etc as constructor arguments, rather than closing over protected state.
Got it. May be we could have something like SchemaAndValueUtils to include such utils for it. Just didn't feel great seeing this method in the ConnectHeaders class.
You can just do i+=2 in the for loop.
Do we still need a shutdown hook to delete with `file.deleteOnExit();`? I think the latter can still be triggered even with abnormal exits.
This exception can't happen in DescribeTopics.
It's still making me a bit uncomfortable that we call `prepare/postCommit` during `handleRevocation`. and `handleAssignment`. Maybe I'm being paranoid but experience has shown it's been difficult for us to keep track of which methods need to be called when, and in what order. It seems like, now that we've decoupled flushing from committing, the only reason for calling pre/postCommit in `handleRevocation` is so that the record collector is flushed before committing offsets. So what if we extract the record collector flushing out into a separate StreamTask method that is only ever called in `TaskManager#commitOffsetsOrTransaction`? I haven't thought this all the way through but it just seems like we may as well go all the way in decoupling flushing from committing and split them out into separate methods. Maybe `preCommit` and `postCommit` have become relics of the past
prop: Please use `assertThat()` since it makes verifications a bit better readable.
Thanks for the discussion, all. One thing to note is that this config has "no" impact on high availability. Anyone who wants HA would configure num.standby.replicas, and this config applies on top of that one (for this reason, I like the name you picked. It is "extra".) I think you can make a case for per-node or per-cluster, but if we assume we only want to add one config, I think per-cluster is more valuable, since it lets you protect the brokers from overload, which a per-node config may not. Regarding whether we set the default limit low or high, I'd advocate for low. Some clusters are undoubtedly running close to the limits of their disk space or broker capacity, so suddenly letting every node double its traffic would result in serious operational consequences. On the other hand, if we start out low, then the probability of a crash becomes much lower, and the only problem is that the overall balancing process takes a long time. But, since the config is set low, there's a low impact on processing capacity while it's happening, so maybe there's no real impact over that long time. If you buy the argument that a low default is good, then the obvious choice is "1", but that would take a _really_ long time to complete balancing. The default of "2" is basically a compromise. It lets you balance twice as fast, and it's "probably" still low enough to cause a problem for no one. "5" also seems fine-ish, but the farther from "1" you move, the riskier the choice is. One final thought, when you say that some people would "need to change" the config, say from the default (2) to MAX_VALUE... It seems like this population is restricted to the people who really need to make sure that balancing happens absolutely as fast as possible (maybe because their application can't keep up unless the whole cluster is processing, or because they're scaling up to cope with a spike in input data). Hopefully, these people know that they need extra horsepower and are motivated to read the docs and locate the config they need to change. Also, hopefullly, this isn't the common case.
This class should have a `toString()` method that describes what's required, so some string like: > Comma-separated header rules, where each header rule is of the form '[action] [header name]:[header value]' and optionally surrounded by double quotes if any part of a header rule contains a comma
Could use `MockVaultConfigProvider.class.getName()` instead of hard-coding the class name so that changes are reflected automatically.
Is it possible that `key.compareo(endKey) > 0`? Just trying to not hide any potential issues with relaxed condition.
We can try that -- but we need to reduce `HEARTBEAT_INTERVAL_MS_CONFIG`, too, for this case -- its default is 3 seconds and it must be smaller than session timeout. Checking some existing tests, we have some that set them to 500ms / 1sec. Some other test reduce session timeout to 2 or 5 seconds...
nit: unneeded boxing
nit: add `final`
Ah, I didn't realize load takes that long, but in retrospect, it should have been obvious. Then, of course we shouldn't always load both, and my suggestion is just to match on the test name.
nit: `true` should go to new line.
I would expect this to be `UTF-8` with a dash. That's the format in https://docs.oracle.com/javase/7/docs/api/java/nio/charset/Charset.html
nit: mentioning the time unit seems redundant.
Not sure why this was changed.
bump (it looks like this didn't get changed)
`Failed to flush accumulated records` -> `Failed to flush all accumulated records...` Also, it would be much more useful if we could say `%d of %d` batches although I see we would have to expose a `size()` method in `IncompleteBatches`
This would update `updateEndOffsets` multiple time -- should we set it only once? Note, that `needsRestoring` will not be empty until the full restore is completed.
That's right. If we are still waiting for a new token to be completely received, we will need to turn off OP_WRITE.
nit: the phrasing "to never revoke" is a little awkward. Maybe something like this: > Note that you can leverage {@link CooperativeStickyAssignor} so that only partitions which are being reassigned to another consumer will be revoked.
Yeah, let's do that: we should try our best to avoid code duplicates.
We could do a small KIP and move the classes (preserving the old ones as deprecated). Overall, I don't have a strong opinion.
if you just have ``` log.debug("FindCoordinator request failed due to {}", e) ``` Then e.toString would be called which would usually be `e.name(): e.getMessage()`.
Hmm, I thought you planned to use the "parent processor node name" as the prefix if it is not specified, which seems more user friendly to me? EDIT: actually my bad, nvm.
`calcRepartitionNumForTopic` and `calcRepartitionNumForTopicInfo` are pretty hard to differentiate, better to name it more distinct.
nit: maybe we can wrap the flushing and hwm updating logic in a `flushFollowerLog` as well.
`minExpectedRecords` or something like that may be clearer.
Same as above. It will probably be particularly useful for incremental fetches to have the partitions explicitly in the log message.
We really ought to be able to factor out a helper here. The code looks identical for both the controller and broker cases.
While we should have the call to `super` above, do we really need this given that the default `available` implementation in GZIP is not very helpful? i.e., ``` super.available(); return inf.finished() ? 0 : 1; ```
The user is trying to access a partition that was not requested. I think we could raise `IllegalArgumentException` directly to the user.
For a follow-up, but we will probably need to add something like `AclAuthorizerBenchmark`.
> I think it's could easily happen that any past, present, or future versioned member reports a task sum that's beyond the end-offset sum of what the leader thinks the task contains. If the corruption comes from our code, we should throw. The leader fetches the end offset shortly before that code, so they are most probably up-to-date. If the corruption is caused by failure we should handle it gracefully.
`original` => `originals`
Why have an `addAdminResources(...)` method when it could simply call `register(...)` like the previous and next lines? The method is private, so it's not useful for subclasses. I understand that we'd be duplicating some code, but it seems more complex to have the method abstract the one call.
Yes, we don't use `Qty` as a suffix. We sometimes use `num` prefix and other times `Count` suffix (it would be nice to be consistent, but we're not there yet).
+1, it could make the reading a bit easier.
I wonder if there's a way to add this to `ResponseHeader` in a compatible way. It seems a bit annoying to have to add that to every response.
I'm assuming it's worth keeping this 2nd loop separate from the first one for performance reasons. At first glance it looks strange to iterate over the same collection twice in a row
I think it would be cleaner to pass `cacheSizePerThread` to `resizeThreadCache()` instead of the number of stream threads. We would then just call `getCacheSizePerThread()` once instead of once in `addStreamThread()` and once in `resizeThreadCache()`. We would also just need to compute `threads.size() + 1` once.
Why "queryable-store-name"? IIRC we don't say "queryable store" anywhere else in the docs -- we use the term "interactive queries", if anything.
We should not be logging at `ERROR` level for every single record if we aren't failing the task unless the user has explicitly enabled this by setting `errors.log.enable` to `true` in their connector config.
Since equality is measured by comparing timestamps something like `return Objects.hash(timestamp);` should be used instead.
Reading up to here, I'm convinced caps or no caps is random :)
Good call-- thanks for the correction.
same here as what i said below. You can use a `assertThat`
Sorry, I realized it now. Why do you not just pass `config` where you now pass `defaultProperties()`? In this way we would not need `defaultProperties()` anymore.
Got it, thanks for the notes.
That is on me. In this verification it is important to check for reference equality, because you want that `threadLevelSensor()` returns the sensor that is registered in the `Metrics` object or that was created by `Metrics#sensor()`.
This exception gets logged and then ignored by `createAndScheduleTasksAtomic`, right? I think it would be better to keep the original behavior where we create a task, and mark it as done and failed. Then, at least, the user could see the error message if something failed. The error would appear in the failed task status. The user shouldn't have to read the logfile to see the failure message.
Similarly, we can get rid of all this.
Yeah, that's my preference. Not sure if @ijuma thinks otherwise.
Could describe how the following transition can happen? 1) `rebalancing` -> `rebalancing` 2) `rebalancing` -> `not running` 3) `running` -> `not running`
If it's the same for every test, you could also just create a `getProperties()` method for the tests to call when they need the properties. This way, you won't need a field to store the properties in.
nit: a little annoying for a newline in the middle of a map type
Exactly. A sink, can only have a single topic, and this it's type is `String` -- for sources, it can be multiple and thus type is `Collections<String>` (or `Pattern`). And if you call `Collection#toString()` it will as `[]` -- but not for plain `String` type.
I don't think we need this method since tests can just access the `self.nodes_clean_shutdown` field directly. Also, from line 234 I can see `nodes_clean_shutdown` is actually a list of numeric ids, so `nodes_clean_shutdown` is a somewhat misleading name.
`get()` returns a `ValueAndTimestamp<Long>` -- not sure if we should add a `.value()` call to the right hand side or change the return type left hand side? Maybe easier to change to ``` Long aggForKey = localStore.get(key).value(); // ... ```
```suggestion "<li><code>org.apache.kafka.clients.consumer.CooperativeStickyAssignor</code>: Follows the same StickyAssignor " + ```
As discussed in the JIRA, I still think we should use `FileChannel.open`.
Should we enforce another rebalance when this happens? Otherwise we may live in a long period where all clients can support a higher version now while we still use lower version, so some advanced features (e.g. rack aware assignment in the future) cannot be picked, until the next rebalance is triggered.
We have this kind of challenges today in some other context. Hence speaking from the real experience! :)
Thanks for that note ewen. I learned something!
remove unnecessary newline
This part is not correct: we are passing clientId as `consumerId`, and memberId as `clientId` to the MemberDescription. We should just use the same string names, `clientId` and `memberId` in `MemberDescription` and pass in to constructors accordingly.
We need to check again after we grab the lock, otherwise the store might get closed after we check but before we grab the lock. Once we get the lock, we're guaranteed that this block is serialized wrt `close()`. But we can still check beforehand to avoid grabbing the lock if it is closed.
I read these as "should not parse X as Y", as in X is in the input, and a Y is the output. The input was a string which included an "unquoted embedded map key", and the output was a string, rather than a fully-parsed map. I now see the reading you're using, and it makes sense, since it refers to the innermost element that's being tested, rather than the whole input object.
nit: add `final`
nit: alignment looks a little off
Should this return a `DataInputStream` or simply an `InputStream`? Seems like wrapping into a `DataInputStream` is not relevant for this class and can be done by the caller. Same for the output case.
Hm...I'm not necessarily that concerned about calling `mainConsumer.committed` twice in rare cases (although maybe that would not be so good, since those rare cases happen to be those in which this is probably more likely to time out, right?) But personally, just coming into this code from the outside, it's super confusing to have two different methods for initializing the offsets. It seems more convoluted that way, to me. Also maybe I am missing some context here but why do we call `initOffsetsIfNeeded` from `initializeIfNeeded` rather than from `completeRestoration` in the first place? We don't need to initialize main consumer offsets until it transitions to running
formatting: no need for curly braces here
nit `RocksDB` without space
ok. Just curious what is target date when all implementation for this will be merged? cc@saisandeep
Still not addressed -- we should mention both methods return this iterator.
req: rename to `tasksToPreviousClients` or something similar that works "previous" into it
This is not introduced by this PR, but I think it is more natural as "a new {@link KStream} instance." Also how about "that contains" (or containing, again either is fine and we just pick one throughout the class files) "the same records as this {@link KTable}. The records are no longer treated as updates on the primary-keyed table anymore, but rather as normal key-value pairs in a record stream." Ditto below.
There is another possible reason. "metadata could not be refreshed within {@code max.block.ms}"
ditto on removing before/after.
This seems redundant.
That makes sense, we can `clearFindCoordinatorFuture` inside the hb thread as well.
One more thing -- missed this before: can't we remove `completedPartitions` and call `iterator.remove()` instead? Maybe we need to change the iterator to iterate over the `HashMap` instead of the "key-set" of the HashMap though.
`assertThrows` is what we use for some time now, and it's available to the branches that this PR will be backported. (same below)
Please extract this to its own method since the same code is also used on line 220.
I'd suggest naming this variable `resolvedOriginals`.
Earlier we discussed sending the task spec on the process' standard input. Did you decide not to do this? It seems like using a command-line option will be pretty awkward...
Perhaps clarify to: "by transforming each element in this stream into zero or more elements with the same key but with new values." Also, perhaps we should add an example? > Example: ("alice", "hello world") could be transformed into two new records such as ("alice", "hello"), ("alice", "world"). Note how the key stays the same as in the original record but (1) there are now two output records and (2) their associated values have changed from the original value.
:+1: Actually, I think `@link` would be preferable in all three cases, but they need to be properly qualified.
Actually I'm not too concerned of relying on `null` to indicate no need to checkpoint, what I originally pointed out is that we are unnecessarily accumulating and then distributing checkpoints between task manager and task, which is already resolved in your PR. So I'd suggest we still just use a single nullable `Map`.
The test name is not self describing: what about `shouldAlllowToSpecifyRocksDBConfigSetterClassAsString`
Do you think it would be clearer if we don't rely on the defaults, but just explicitly include both branches? Oh, also, this isn't an immutable builder, so you can just do: ```suggestion if (cachingEnabled) { stateStoreConfig.withCachingEnabled(); } else { stateStoreConfig.withCachingDisabled(); } if (loggingEnabled) { stateStoreConfig.withLoggingEnabled(new HashMap()); } else { stateStoreConfig.withLoggingDisabled(); } ```
Guess just a matter of taste... No performance issue of course.
> Question: How about we retire the executor in the Worker. It's only used for starting tasks. That executor is used for all the work tasks do, not just starting (`WorkerTask` is a `Runnable`)
```suggestion if (System.currentTimeMillis() > expectedEnd) { ```
Rewording suggestion: "a new {@link KStream} with the transformed key and value types"
Are you sure? I don't see this struct being used for read anywhere.
And replace this pattern on `StreamsUpgradeTest` as well.
prop: rename `taskCount` -> `minTaskCount`
The diff for the rest of the code seems to have gone wrong. Hard to tell what has changed and what the diff is. Might be ok.
This could be final.
This fails checkstyle. We need a space after `if`
Spoke to @hachikuji offline. There are two things to be resolved: 1. Ensure that the good records before a bad records in the same batch is delivered. 2. Do not skip over a bad record. This patch does 1 but not 2. I have created KAFKA-5211 to address 2 and will submit a patch for that separately. For this patch we will just focus on solving 1.
We should actually remove the reference to `KTable` as we don't currently support it
It seems problematic to pass in `self.prop_file` here `self.kafka.security_config.client_config(self.prop_file)` since `self.prop_file` is now a function and not a string
Okay I think I know what's the messy part here: we are setting the stores during KStreamJoin which is only at the parsing phase, but not the logical plan generation phase. The key difference is that the latter has access to the user's configuration whereas the former is not. And because of that we have an unclean settings, we should decide e.g. which stores to create only at the logical plan aka StreamStreamJoinNode. This is a general issue with Streams parsing/logical plan generation, and I will file a ticket for it.
Suggestion: ```suggestion // Use the desired topic for offsets ```
This case duplicates the one inside the while loop and it'd be nice to replace this with control flow that re-used that single case. I understand that the goal in the restructuring here was to catch a list of elements with no commas between them. I think you can do this by just skipping the comma consumption at the end of the loop if you look-ahead and see an `ARRAY_END`, but require it if the parser is not at the end of the array. Here's my thoughts in a longer form, feel free to skip reading this if you get it already: Before: ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with at least one element (NPE when there were no non-null elements) // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) COMMA? -> consumption ignored // next token is one of (element, array end) } ``` Your fix: You're changing the loop invariant to assume that the next token you see is an element, rather than possibly being an array end. This allows the loop to assume that element appears first, and then in each iteration force the loop to consume either a following comma, or an end bracket. ``` ARRAY_BEGIN // next token is one of (element, array end) ARRAY_END -> finish with zero elements // next token is an element while { // next token is an element !COMMA -> else fail from empty element parse element // next token is one of (comma, array end) ARRAY_END -> finish with at least one element, maybe null // next token is a comma COMMA -> else fail from missing comma // next token is an element } ``` My suggestion: Skip the final comma check if the next token is an ARRAY_END, but if the check happens, assert that the comma was consumed, rather than the condition being ignored in the original code. ``` ARRAY_BEGIN // next token is one of (element, array end) while { // next token is one of (element, array end) ARRAY_END -> finish with any number of elements // next token is an element !COMMA -> else fail from empty element // next token is an element parse element // next token is one of (comma, array end) if (ARRAY_END lookahead) { // next token is an array end } else { // next token is a comma COMMA -> else fail from missing comma // next token is an element } // next token is one of (element, array end) } ```
can you use the Utils.newInstance here . https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/utils/Utils.java#L312
`endOffsets.get(topicPartition)` can be replaced by `offset`
I think we would remove the `StickyAssignor` in the future if we realized that there's rare use cases that needs a eager sticky assignor; until then I'm fine with the current way as is.
We can use `ApiResult.unmapped()`
I see. So it seems this issue will only be exposed with EOS still, right (reinitializeStateStoresForPartitions is only triggered when EOS is enabled and offset out-of-range detected)? As for the fix: since the `storesCopy = new HashMap<>(stateStores)` is just for fixing concurrent access exception, how about we just use an iterators instead, i.e.: ``` iterator = .. for (iterator) { if (storeToBeReinitialized.contains(..)) { ... iterator.remove() stateStore.init(processorContext, stateStore); } } ```
Do we need this check here? Seems like we'll never hit this condition since we check after incrementing the size in the loop above and return if an overflow occurred.
Why not organizing the thread-level sensors as cache-level sensors as well? I.e. `Map<String, Deque<String>> threadLevelSensors = new HashMap<>()` where the string key is just `threadName`, since we will only remove sensors for the whole thread at once.
what threw me off with the original message is that it gave the impression that it had just finished restoring those partitions, giving the impression it kept restoring them over and over again. In reality this log message just reports that restoration is still in progress and that so far we have completed the given set of partitions, but it might log this message at arbitrary times during the restoration process, not only when a partition was completed.
Actually, I think we want to err on the side of correctness, so shouldn't we just drop the serdes at this point and set them to null? It seems like this would preserve the current behavior (where we also don't have serdes for the resulting k/v).
The channel is not being passed to `log.debug`.
Our system test currently doesn't do perf validation well. It would be useful to just run ProducerPerformance and ConsumerPerformance and see if there is any noticeable degradation.
More generally, you might find it easier to ensure that once you have the nodes allocated to you, they are all assigned a version, even if just the default `TRUNK`, before doing anything else with them.
I think the implicit assumption is that the parent "foo" doesn't exist (yet), right? If so, shouldn't we assert that it actually does not exist prior to continuing? Or do we feel `TestUtils.tempDirectory();` is sufficient? (I think it is, but still wanted to ask.)
nit: the other log message had a little more information (i.e. it described what the code was doing). Maybe this message could be "Reading to end of log offsets {}" or something like that.
Maybe we can use `setIfExists`.
Wildcard imports should be caught by checkstyle, and should fail the build. In any case, please replace with non-wildcard imports.
Let's use `epoch` instead of `currentEpoch`. Since we are using `currentEpoch`, the `endOffsetForEpoch.offset` will equal the LEO. If you instead use `epoch` then the `endOffsetForEpoch.offset`. will be `4` which is less than the LEO (`5`).
At this static member is imported, we can replace all `Errors.INVALID_REQUEST` by `INVALID_REQUEST` in this class.
nit: unused variable
There are projects outside of Apache Kafka that do use this class. While this class is not a public API and we technically don't have to avoid breaking compatibility, it's fairly straightforward to maintain API compatibility and so we should do that.
You have a point about checking via unit tests, but when the `AdminClient` attempts to create the topic, the check is against the full name. The check here only looks at the user-supplied name, which is only part of the topic name so that we could have a situation, although admittedly rare, where the unit tests pass, the full name fails. So I'm inclined not to have the check here or in the `Materialized` class. Let's see what others think. \cc @guozhangwang @mjsax @vvcephei @ableegoldman
Yes, `totalRequestCount` sounds clearer. We might also consider setting it back to 0 in `MockClient.reset`.
It might be a good idea to send a slightly larger batch of data, for example I think in other integration tests we did like 10,000 records. We don't necessarily need that many here but Streams should be fast enough that we may as well do something like 1,000 - 5,000
With fewer (outer) loop iterations, performance should be better.
Hmm this would fail for the old schema. I think we have to use `getOrElse`.
nit: we can still use the ternary operator here.
Maybe use Objects.requireNonNull
We typically don't use java serialization. Is Serializable needed? Ditto in a few other classes.
Need null-check since `remoteAddress` is null on the server-side since we are currently only setting for client connectons.
Sure @vitojeng . cc @mjsax
The point of this test should be that a global stream thread is not replaced but the client is shutdown instead. Hence, the uncaught exception handler should return `REPLACE_THREAD`, not `SHUTDOWN_CLIENT`.
Would be better to describe what `cases` are referring to.
You are an exemplary boy scout!
really? we have the position already from either the last record offset or from the previous call to `consumer.position(...)`
nit: remove empty line
Do we need follow same pattern as other properties to define a new property which refers to SECURITY_PROTOCOL_CONFIG? Example: public static final String SECURITY_PROVDERS_CONFIG = SecurityConfig.SECURITY_PROVIDERS_CONFIG;
nit: add `final`
We recently "fixed" `listAllTaskDirectories` to guarantee that it never returns null. We just missed to update all the null checks when we did that
Unified the non-null check into a single place.
We don't have to do this here, but as I'm reading this, I wonder why we can't push this logic into the builder. For example, we can add a builder method `requireTimestamp(boolean)`.
add `final` to all
There may be others which belong here like `ssl.client.auth`.
Seems like we could extract the `processingMode` initialization logic to the StreamThread level to share between task creator and task manager
Can't we simplify this to: ``` for (final StreamThread thread : threads) { threadMetadata.add(thread.threadMetadata); } ```
Nit: no "." at the end Please update everywhere.
If an OOM is thrown from here, it seems the available memory would be already decremented and not added back.
We should be providing an instance of the TimeWindowedSerde to the Streams DSL in the application topology, not using this config. That's the idea of this KIP -- a Kafka Streams application should pass in a `new TimeWindowedSerde(innerClass, windowSize)` rather than using this like a default.
I like the addition, we can reuse this when they inevitably do something else we'll need to warn our users about ð
I think `totalAborts` will always be 1 because this branch will abort the task, meaning `!doneFuture.isDone()` will be true for all the other MaintainLoop threads. Is there a reason to save the total abort rate in such case? Might as well change it to a boolean I think
Personally i feel adding `final` to any locals etc that don't change is good practice. It makes it immediately clear that the value of the field/local is fixed.
Seems just as efficient to me, especially since we only throw the first error.
Maybe we should have a static method in `OffsetForLeaderEpochRequest` that this class can pass the version to which returns `true` if it's 3 and higher.
Ya, sound just about right. :) update: I mean, it's preferable to fail fast when the assigment is tried than to let it blow up only when many lines after that, in a totally different context.
Whether it's a new config or a new API, we'll still need a KIP. If we go that far, we'll want to consider the other methods which probably suffer the same problem (e.g. `seekToBeginning`). A couple options that we have thrown around are the following: 1. Introduce a `max.block.ms` config like the producer has. 2. Overload the methods with timeouts. 3. Use the request timeout. Not sure the best way to go here to be honest. Maybe for `position()`, we should just raise a `UnknownTopicException` instead of retrying.
You can pass `numPartitions` to the `ArrayList` constructor so that the internal array is allocated with the right size.
Probably not, and since sensor names are only used for internal bookkeeping there should be no compatibility issues with the change.
We should update this test and use `assertThrows` instead of `try-fail-catch`.
I'm also curious what implications there are for changing the original DescribeTopicsResult when using old clients.
@rajinisivaram, the reason I was asking is that @cotedm was only able to reproduce this issue on Centos 7, which made it seem like it could be related to the OS network stack as well.
Can you please add `final` wherever possible.
It seems that this is an internal request and is never throttled.
I was thinking about this too. Using millisecond as unit for Map key is not prudent. After the switch to second as unit, we may need to check the two adjacent buckets keyed by ts-1 (sec) and ts+1 (sec).
Ditto here, we can rename it to leftJoin / rightJoin to indicate if this joiner is for left or right.
Hmm.. I am not sure this is sufficient. Any of the responses could return from the heartbeat thread.
Not sure we need the while loop since it waits for a day at least.
This can be taken out. When the `StreamThread` goes into the `runOnce` method and the state is `PARTITIONS_ASSIGNED` the `StreamThread` calls `taskManager.updateNewAndRestoringTasks()`. If the lock is held by another thread still cleaning up this call will return false and the state will not transition to running. In the next iteration of `runOnce()` the `StreamThread` will attempt the same operation again since the state has not yet been set to `RUNNING`
nit: maybe drop "serializable"? Reads a little redundant.
Can we just set the `recordCollector` in `setUp`, instead of keeping a persistent one? It just makes it easier to see that the state really will get cleaned in between tests.
@jeyhunkarimov Sorry for jumping in a little late. @guozhangwang is correct about the test. An example for unit-testing with regex defined topics using the `TopologyBuilder` is `TopologyBuilderTest#shouldSetCorrectSourceNodesWithRegexUpdatedTopics` (line 675)
@SinghAsDev Since KafkaConsumer has only one thread, even scheduled tasks have to be executed in that thread, which means the user has to wait for them. Since you can't really control when the tasks will be executed, in the worst case, it could turn a non-blocking call into a blocking one. And I don't see why error handling can't be handled asynchronously. For updating regex subscriptions, I wouldn't think it too much of a big deal even if we just ignored failures and waited for the next metadata update, though it would be easy to implement retries with backoff (I think we do this for heartbeats already).
Dropped this unnecessary duplicate code, as discussed.
This is not correct, it should be `buffer.remaining`. It seems simpler to just do `while (buffer.remaining())` with an early exit in the case read returns `-1`.
`expectedAssignedCount` is not used any more.
nit: fix indention -- either move `mockTime` one line down or indent other parameters to align with `mockTime`
This might be better named `TOPIC_EXPIRY_NEVER` since it indicates it should never expire, not that you have no info about expiration time yet.
We can call `selectKey()` instead which is like a syntax-sugar for such cases.
nit: I think we're guaranteed that `topicId` is not null (in spite of the inconsistent `equals`), but it's still a little nicer to write this check as `!Uuid.ZERO_UUID.equals(topicId)`
No, we have to fix it before AK 2.0. Once it is in a released API, we canât change it.
large and deeply nested method here -- recommend splitting into multiple smaller private methods where possible
This is also the default, I think.
Hmm, so actually I think the problem here is that we need to be able to parse generally because these can technically be passed in as `Map<String, ?>`, so the type is unknown. Another option is to replace this parsing with `ConfigDef`, which will handle both the `String` and `Integer` cases since its designed to handle both properties files and `Maps` passed in directly from code. To be honest, I think the only reason we didn't do this before is because this code came with the initial patch that was prototyped outside of Kafka and couldn't use internal APIs.
nit: add `final`
nit: new line
Is this condition check necessary? It is rare in code base.
Adding a parameter `version` for `encodeVersionThree` is very confusing to other readers. I'd suggest completely duplicate the code in `encodeVersionFour` and remove this parameter in `encodeVersionThree`.
A bit out of topic: since most of the time the restore consumer's position will be very close to the producer appending LOE, to achieve some batching we could set the restore consumer's max bytes to some larger value (by default it is 1K in `ConsumerConfig.FETCH_MIN_BYTES_CONFIG`)
> But maybe just using the implementing class name is fine. That was my though, too.
It does seem like kind of a gray area. Still, the TimeoutException isn't necessarily saying that it failed, just that we didn't wait long enough for it to finish the shutdown. But we have at least definitely initiated the shutdown -- besides, if the thread really is stuck in its shutdown then it's probably a benefit to go ahead with the `removeMembersFromConsumerGroup` call to get it kicked out all the sooner. But, in the end, we really make no guarantees about the application should a user choose to ignore the TimeoutException (though they absolutely can). I can imagine that some users might choose to just swallow it and decide that they don't care if the shutdown is taking a long time. It's hard to say
Maybe it's better to have two checks: first test for `TimeoutException` and if it's a different one, test for `RetriableException` second.
Do we actually need this? It seems that we wait until `inFlightRequestCount == 0` and there are no unsent data in the accumulator.
nit: add `final` (2x)
Here's my reasoning of the cases: 1. `receivedAssignmentMetadataVersion > supportedVersion`: this should never happen. 2. `receivedAssignmentMetadataVersion == supportedVersion`: normal case, the leader only knows up to `supportedVersion`, and hence sends this version back. 3. `receivedAssignmentMetadataVersion < supportedVersion`: if some other consumer used an even older-than-`supportedVersion`, in this case this consumer will again send the subscription with `supportedVersion`. So it seems we do not need to distinguish 2) and 3) since for either case, line 763 and line 770 will actually assign `usedSubscriptionMetadataVersion = supportedVersion` right? Or do you just want to distinguish the log entry? If that's the case I think simplifying this to: ``` if (receivedAssignmentMetadataVersion > supportedVersion) { // throw runtime exception } else { if (receivedAssignmentMetadataVersion == supportedVersion) // log normally else // log differently usedSubscriptionMetadataVersion = supportedVersion; } ```
nit: avoid double spaces
This makes stopbugs complain ... We should use `%n` in the format string instead of `\n`
nit: I feel like a jerk for saying this, but can we avoid the exclamation points? The enthusiasm can be a bit vexing for an operator who hits this error.
Minor simplification we can do below: ```java if (targetNode == null || !awaitReady(client, targetNode, time, requestTimeoutMs)) { transactionManager.lookupCoordinator(nextRequestHandler); break; } ```
The sentence "Note that the order of the tags..." is not applicable because there is no set in this case. It's just the order of the varargs.
```suggestion if (stateDir.exists() && !stateDir.delete()) { ``` Do we need to check `hasPersistentStores` here? It seems sufficient just to check if the directory exists.
nit: top of class
nit: Since we are reusing this function for aggregations as well now, better rename to `createReparitionedSource`.
nit: remove `get` prefix (similar below for `getPartitionTime()`
Was this left in accidentally? Looks like it overrides the line above, which seems more suitable for this test case.
nit: can we consolidate `producerFencedOnCommitTxn` to the more-general `commitTransactionException`? I.e. if you want to fence on commit, you just register the `commitTransactionException` as a ProducerFencedException
These aren't needed in these tests anymore, and `anyTimes()` wouldn't be ok here anyway. I think the `anyTimes()` was masking the fact that we could remove these now.
Oh.. I see. In this case, would it make sense to check `offsets.isEmpty()` first, then `!coordinatorUnknown()`, and the final else. That seems a bit more natural when reading it.
Overall hard to read because of formatting. Easier to read like: ``` condition ? // then : // else ``` Ie ``` materializedInternal.keySerde() != null ? new FullTimeWindowedSerde<>( materializedInternal.keySerde(), windows.size()) : null ```
null handling here again -- should probably be an exception if we can't find the info we need, which then converts at some point into a RestException
It's not thread-safe without the `synchronized`, since we're accessing variables that need synchronization. But let's move the `synchronized` keyword into `ConnectionStressWorker#updateStatus`, as described above, since that's a bit cleaner
As this method is not supported, maybe we can move this implementation to interface? The benefit is that we don't need to add similar code to both `MockController` and `QuorumController`
Ah, didn't realize this was a `RetriableException`. we might then want to add what topic caused the problem too. Otherwise, if the topic is not being created, clients (for example, Connect would be stuck in a retry loop forever without any guidance on what topic needs to be fixed). P.S: hopefully, we aren't skipping writing a KIP here since this does change the behavior of a public API.
nit: add `final`
Hmm.. I don't think it would necessarily require a KIP to check for negative offsets on the broker. I guess it depends what error code we return. In any case, we'd probably still want the validation on the client side.
nit: use `<>`.
Well, maybe I should have pointed them _all_ out the first time.
Just a suggestion: ```suggestion Objects.requireNonNull(newKeyValues, "The provided KeyValueMapper returned null which is not allowed."); ``` BTW, we should not output records since they might contain sensitive data.
nit: `OnOn` ->
nit: "failed on partition being lost {}" -> "failed on invocation of `onPartitionsLost` for partitions {}"
```suggestion "If auto.create.topics.enable is enabled on the broker, the topic will be created with " + "default settings", topic); ```
I originally thought the semantics of unsubscribe() is blacklisting. For example: subscribe("PageView*") unsubscribe("PageViewTopicA") will subscribe to all page-view topics except page-view-A. Arguably this can be done solely in subscribe() with"^" in regex, but I feel this semantics is more natural for users.
Previously, we would not throw the exception if `flush` returned `false`, but now we do. I assume that's intentional? May be worth explaining.
Maybe we can also make it a bit simpler to just rely on the left side: if the supplier is given on the left side (which would always provide the name), then we name the shared as `thisStoreSupplier.name() + "outerJoinSuffix"`; if it is not, then we look into `streamJoinedInternal.storeName()`, and the last resort as `outerJoinStoreGeneratedName`.
Can you also send an update to the VOTE thread? so all participants are notified. Thanks
Is it intentional to swallow this exception? At a minimum, we should probably log the exception at DEBUG level.
Should we wait until the consumer task completes before writing the checkpoint file? Otherwise, we could be reading the in-memory state while it's being updated.
Except that it would allow us to centralize the logic and simplify the code. That seems beneficial.
This is going to be modified and accessed on potentially different threads, right? If so, we should add the `volatile` modifier here.
Suggestion (can't add because of the deleted line): ``` List<Future<RecordMetadata>> futures = reporters.stream() .map(r -> r.report(this)) .filter(Future::isDone) .collect(Collectors.toCollection(LinkedList::new)); ```
Thanks for checking the underlying implementation @C0urante . That takes us to my earlier concern about this operation potentially blocking for too long to be in a `synchronized` block. And the potential of blocking does not have to do with acknowledging that the record was written only. The producer call has a metadata update call too. Going over the uses of `KafkaBasedLog` in Connect, I didn't find an example where we have `KafkaBasedLog#send` running in mutual exclusion. Contrary, similar concerns are probably the reason why we call `OffsetStorageWriter#doFlush` outside the synchronized block in `WorkerSourceTask`. I think we might be able to live with a rare race condition as the one you described, in order to avoid introducing unintended side-effects due to locking.
nit: There is an extra space before `+`.
We don't allow a third option [elsewhere](https://github.com/apache/kafka/blob/trunk/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/DistributedHerder.java#L1288-L1292) in the code, so probably we shouldn't here either.
i'm wondering if this one should be at `info` level? It would make it easier to find out when a thread has finished rebalancing. Right now it is a case of looking for some other message that happens during processing. Seeing as rebalancing shouldn't, in theory, happy that often, i think info would be ok.
I'm not sure what this test has to do with `StreamTask`? To me this test should be in `TopologyBuilderTest`. You don't need a `StreamTask` in this case to check that the `TimestampExtractor` was assigned to the source
Maybe we should say "and will be removed in a future major release". That makes it a bit less ambiguous.
Huh, looks like @vpapavas and I missed the need to close the iterator before.
Isn't it true that most of the time this method will get only supported `Callback` implementations? In those cases, we'll never need the `unsupportedCallbacks`. I originally thought it might be worth making this more efficient, but I don't think it's worth it since the default constructor for `ArrayList` is pretty efficient in recent JVMs (with lazy allocation of the underlying array when the first element is added to the list).
Where does it fail if we don't specify them? In KS they are required, because we pass the configs into a `StreamsConfig` -- but we don't use `StreamsConfig` (if I did not miss this) thus I think we can simplify the code here and just pass in empty `Properties`
OK, fair enough.
This works fine, though if you wanted to simplify, the key thing here is just that you are using a `Map<String, String>`, so you could get rid of the resource file and just create it on the fly: ``` Collections.singletonMap("schemas.cache.size", "1"); ```
Maybe we can go with this solution since it seems pretty safe. Shall we just remove the `log.debug` since we'll get that from the `drainRecords` call anyway? And let's run the system tests on this branch after that.
This should be `org.apache.kafka.common.message` to match the directory that the generated source files are outputted to
Not introduced by this PR, but please fix indention.
I missed this on the first pass, but would there be any harm moving this call to `enqueue`? That way we do not need to repeat this check for other scenarios involving chaining or partial failures. (For example, I assume we'd end up doing the same thing in `rescheduleMetadataTask`). We should probably also try to reuse `failWithTimeout` for a consistent exception message.
I suggest logging a message and passing in the error to the log message. e.g `log.error("Error while refreshing sustained admin client connection", e);` and ditto for all others. This makes it way easier to nail down errors
It's simplified because we have a clear mapping from eosAlphaStreamsProducer to its corresponding internal producer, which in the existing code reader always has to build this mapping manually by checking the initialization code.
This should probably say "Timeout expired while initializing transactional state ..."
That's where I'm referring to: `String fieldName = targetField.name();` but I didn't follow too many levels of redirection ...
nit: I do think a short message would be helpful here, even if it's just "Failed to deserialize record with type {type}"
There is a typo here, "an a".
It will good to clear the requests and test when empty as well.
It's actually pretty elegant! :)
I was mainly concerned that we'd need to check errors in both places, but I think we're good now since we ensure that top-level error codes will always appear at the top level (even for older versions).
Discussed this offline with @rajinisivaram and we think we think the first condition can be removed.
It would be better to use `assertThrows` instead of doing this because it is not clear where we expect this exception to be thrown. So, I would so something like the following: ``` if (version >= 6) { // Do the regular part } else { // assertThrows with the expected code that must throw. }
I don't, @guozhangwang may know.
Could we add the description in the metricName as well indicating this is measured in nanos not millis? Ditto elsewhere.
As an optimization I'd also add as the first check: ``` java if (other == this) { return true; } ```
Rather than adding a subclass of `SegmentIterator` we could use a functional interface to get the next iterator. The `hasNext` method in this is identical to the one in `SegmentIterator` expect for one line.
Am I misreading this or will this, combined with the `TimeoutException` from `maybeLeaveGroup` cause this to always throw a `TimeoutException`? Some tests seem to be throwing it, so I think this might be the case and not the behavior you want here.
It may be a bit tricky as they use different string concatenation methods.
I probably would have these 12 lines in a `consumerProps` method and also reuse it from `getConsumerConfigs`. But if you think it's better this way, then that's OK.
I think it would be better to wait until the Kafka Streams client id in state `RUNNING` and then verify if the history of the states transitions after adding the stream thread is first `REBALANCING` and then `RUNNING`. Currently, the order is not verified as far as I can see.
To a caller they are equivalent though. But I don't have a strong opinion here, and I guess avoiding unnecessary exception overhead makes sense.
How about using `e.toString()`? It shows the class name of exception. I feel it is useful also.
nit: maybe something other than `internalName`? `baseRepartitionTopicName`? I don't have any great suggestions ATM
```suggestion return new HashMap<>(connectorConfigCallback.get(herderRequestTimeoutMs, TimeUnit.MILLISECONDS);); ```
```suggestion List<Class<?>> expectedClasses = expectedClassesFor(schema); ```
Please get rid of this volatile. There is no longer a circular dependency here.
`topics created using through() method` -> `topics used in/by through() method`
Good pointed. I missed that the type is `String` (expected it to be `byte[]`). Hence, for efficient encoding, and to allow us to add a magic/version byte, we should first serialize the timestamp, prefix it with a magic byte and then "deserialize" it to `String`. ``` byte[] bytes = ByteBuffer.allocate(9) .put(MAGIC_BYTE) // add a corresponding "final static" variable .putLong(timestampe) .array(); String metadata = StringSerde.deserialize(bytes); ```
Thanks! I overlooked on its side effects..
nit: could be `private`. For what it's worth, I tend to prefer having these helper methods at the bottom of the file so that you don't have to hunt for the test cases, but it's a bit subjective.
`restoringTaskIds` never called.
We also need to make sure that inside StreamThread all the blocking calls that can possibly throw interrupted exceptions now are gracefully handled since otherwise it may cause undefined behavior.
Redundant space here ```suggestion "<p>Implementing the <code>org.apache.kafka.clients.producer.Partitioner</code> interface allows you to plug in a custom partitioner."; ```
Nit: add `final`
Shouldn't this also autoTick `nanoseconds`? It seems like it could be confusing if someone changed some code from using `milliseconds` to `nanoseconds` and suddenly the test would start failing.
There are already static imports for some Assert methods, so no reason not to make assertNull and assertNotNull static imports too. And I don't think the `asList()/forEach()` are really providing much benefit here. It would be clearer if you factored out a method: ```java assertNotNull(def.configKeys().get(prefix + HasDuplicateConfigTransformation.MUST_EXIST_KEY)); assertNull(def.configKeys().get(HasDuplicateConfigTransformation.MUST_EXIST_KEY)); assertImplicitConfigDef(def, prefix, PredicatedTransformation.PREDICATE_CONFIG, ConfigDef.Type.STRING); assertImplicitConfigDef(def, prefix, PredicatedTransformation.NEGATE_CONFIG, ConfigDef.Type.BOOLEAN); } private void assertImplicitConfigDef(ConfigDef def, String prefix, String keyName, ConfigDef.Type expectedType) { assertNull(def.configKeys().get(keyName)); ConfigDef.ConfigKey configKey = def.configKeys().get(prefix + keyName); assertNotNull("Implicit '" + prefix + keyName + "' config must be present", configKey); assertEquals("Implicit '" + prefix + keyName + "' config should be a " + expectedType, expectedType, configKey.type); } ```
```suggestion public static final String MILLISECOND_VALIDATION_FAIL_MSG_FRMT = "The \"%s\" for \"%s\" is incorrect, value: %s"; ```
It would be better to do the assertion in the test rather than here. It will make the test clearer.
We can use `assertThrows()` here. Same below
`requireNonNull` seems not to be necessary
`is [not] supported`
We should add parameter names here.
Maybe the name should simply be `readFully`. And `buffer` should maybe be `destinationBuffer`. And `startPosition` can maybe just be `position` for consistency with `FileChannel.read`. Finally, we need a mechanism to indicate that EOF has been reached. Maybe a `boolean` is good enough. The usual way of returning an `int` is a bit weird for the case where some bytes are read and then EOF is reached.
I'm not sure about this wording change. The producer does wait until the send is declared `complete` as far as I know. And once that is done, it's up to the kernel to send the data even if the JVM dies.
Might be simpler to call `recordFactory.advanceTimeMs()` and not specify the timestamp for each record explicitly? We also leave it as is.
Thinking about it a bit more, it seems struct's toString is the way to go. It's harder to mess up by using the underlying request struct. Builder toStrings are updated manually while struct toString just traverses the underlying struct so it will automatically pick up wire format changes.
This shouldn't be necessary. I believe the config parser will coerce the value to the type you declared the configuration as, `Type.CLASS`. Might be worth to double-check, but we shouldn't add a bunch of branches if they're not necessary.
Yeah, I think it's worth considering renaming those two configs. If someone created a KIP for that, I would vote for it. We would have to support the old names for a while, of course.
Should check `other` for `null`
ok - leave it as is i guess
I think we should call `deserializer.configure(...)` here
No, that's fine. Already merged. Thanks! :)
Good point.. what if we just call on the `FallbackPriorTaskAssignor` like we do when `listOffsets` fails, and then remove any tasks that involve internal topics we failed to create? And schedule the followup rebalance for "immediately"
I don't feel strong about my suggestion either :) Will leave it to anyone who has a strong feeling here.
nit: add `final`
I don't like the fact that we throw in two places... Could we at least make the name of `maybeRewrapAndThrow` a bit more explicit? It is only about `CancellationException` in the end so we could name it `maybeThrowCancellationException` or something like this. Moreover, the method does not really "rewrap" anything, right? It just checks the type and throw it.
No batch should have been drained.
My bad. `computeIfAbsent(keyValue.key, k -> new ArrayList<>());` computes a new `ArrayList` when key is missing. Was skipping over the code too quickly.
nit: A latest code style suggestion (which is not currently strictly enforced in AK Connect code) suggests to put every argument in its own line in the presence of multiline calls. You might want to apply this pattern in new changes, even if the checkstyle is not enforced right now.
Nit: double space
Just chiming in, I think we're just defining the metrics in this PR and then actually recording them later. We might change the actual metric type later on when we look at how it's going to actually get recorded, so maybe we shouldn't worry too much about the selected metric implementation right now.
nit: use final.
nit: add empty line.
You should also verify the return value of `removeStreamThread()` here.
To be more strict, should this be `keyFrom == null && keyTo == null`? I know that today they either are both null or neither are null, but it is future-risk vulnerable if we ever change the apis to allow null values on one side.
That's right, I don't think force quit uses the interrupt path. But anyways I don't think it's possible to force quit a Kafka Streams application until we get around to making it a desktop application. I was just trying to draw a parallel -- my concern here is just that there is absolutely no way to recover should a StreamThread hang during shutdown, meaning you will just need to kill the process and do an unclean shutdown. With ALOS it's maybe not so bad, but with EOS an unclean shutdown requires wiping out all state stores and completely restoring them from scratch. So there is absolutely something to lose besides just the annoyance of having to manually kill the Streams process. I just got a notification from a report of Streams being stuck during shutdown in an EOS application, so I promise I'm not making this up ð . I can point you to it if you'd like -- unfortunately we never even managed to determine the root cause, so there may be more bugs out there which cause this besides just the ones we currently know
These aren't getting serialized by Jackson the way I think you expect they are: ``` $ curl -s http://localhost:8083/connector-plugins | jq [ { "class": "org.apache.kafka.connect.file.FileStreamSinkConnector", "type": "SINK", "version": "0.11.0.0-SNAPSHOT" }, { "class": "org.apache.kafka.connect.file.FileStreamSourceConnector", "type": "SOURCE", "version": "0.11.0.0-SNAPSHOT" } ] ``` The types are still capitalized.
It would be nice to have a unit test for this.
Ah yes, I was thinking about ReadOnlyWindowStore exposed in IQ only. All good.
Same thing about `linger.ms` and "if" is missing in the sentence. ```suggestion "try sticking to a partition(no matter if the 'key' is provided or not) until the batch is full, or <code>linger.ms</code> is up." + ```
Do we want to support all these versions? I'd vote for only testing 1.0 and newer. 1.0 was released roughly 2 years ago.
Personally, I prefer (3) because the others provide redundant information.
Note that today for the public `#committed / #endOffsets` call if we do not get all the committed offsets after timeout we throw the exception -- i.e. we do not return partial results. So we may return no results and throw timeout but internally silently reset the position for some of the partitions.
as above. use `StreamsConfig#...`
Ah, I see. I was concerned that we could skip over the STARTING state, but the mock consumer won't let us. This LGTM, then.
nit: my preference is to mark all method params as `final`
I don't see sensors being removed, but for tasks we'd definitely want to remove them when the task gets reassigned to another worker. I haven't thought it through, but this might be the right place to be doing that rather than marking it unassigned.
This isn't related to AK as it's not server software but rather a test client. I think it's fine if we continue with 1 thread less
How hard could it be to have `cleanUp()` check set a flag for the shutdown thread to call clean up after it's done? We want to make sure the shutdown thread checks after it changes the state to `NOT_RUNNING` or `ERROR`. I think this a much more flexible pattern that would be good to support if it's running or rebalancing we would still want to throw and `IllegalStateException` or maybe `IllegalOperationException`. But either way it would be good to test when stream is in a` PENDING` state. But I think you would have to make that a unit test
Is this change intentional? Ditto below.
I think we can just relax ``` public int numberOfPartitions() { if (numberOfPartitions == -1) { throw new IllegalStateException("Number of partitions not specified."); } return numberOfPartitions; } ``` To allow it returning UNKNOWN.
@dongjinleekr you could do something like: ```java final Serde<K> keySerde; final Serde<VR> valueSerde; final String queryableStoreName; final StoreBuilder<KeyValueStore<K, VR>> storeBuilder; if (materializedInternal != null){ .... else { .... } kTableJoinNodeBuilder .withKeySerde(keySerde) .withValueSerde(valueSerde) .withQueryableStoreName(queryableStoreName) .withStoreBuilder(storeBuilder); ``` Alternatively you can make them non-`final` and set the default values and update the variables inside the `if` condition, and simply remove the `else` block. It's a matter of personal style so I'll leave it up to you.
Perhaps say that the repartitioning will happen automatically, i.e., user doesn't need to do anything.
Could we make this Constructor to call another overloaded constructor, to avoid duplicated codes? i.e. ```java protected JoinWindows(final JoinWindows joinWindows) { this(joinWindows.beforeMs, joinWindows.afterMs, joinWindows.graceMs, joinWindows.enableSpuriousResultFix); } ```
@hachikuji Yeah, I guess. The record parsing is a big chunk of code, but I guess there aren't really any other possible exceptions I can see there.
@ableegoldman If the log is truncated and then immediately more records are appended to go beyond the original log-end-offset, in old versions we would not throw the exception. After some thoughts I think it makes sense to report the lag as the whole log.
It might be slightly more efficient to describe all consumerGroups once (outside the for-loop) and then use the resulting map here.
Yes. It's not severely important, but it's the code style we try to introduce throughout the whole Streams code base: `final` everywhere if possible.
Itâs quite hard to read a function call that has a null parameters being passed in. In this context itâs easy because the change was just made. This is a nit.
Alternatively, we can get rid of those lists by just matching on whether the test name ends with "join" (we match on table name elsewhere in this PR)
Right now I think we should keep the (high) sleep times as is. But in general we may want to lower the sleep times in this PR. I don't know what a "good" value would be (preferably we'd be able to use `TestUtils.waitUntilTrue` eventually) -- using sleep just s*cks -- but I think Jenkins should be running a bit faster than Travis. Perhaps we should give it a try with `5s` rather than `10s`? That said, we perhaps don't want another iteration on this code, given that the 0.10 vote already started.
For testing, we might want to be able to use `MockTime` here. Not sure if this would be easy with this (not sure how to change it either -- to be honest)
nit: Please correct code style as mentioned above.
I'm wondering if we should also clear the fetched messages in the buffer when revoking the partitions as well? As suggested in the ticket itself: ``` corresponding message in the memory (Fetcher.completedFetches) of pausedPartitions was not cleared, resulting in Fetcher#fetchedRecords() still fetching the message ```
Flesh out the docstring here - it's important to have good docstrings in these test methods since the docstrings are actually propagated up to the test report as the test description.
We didn't specify this in the KIP but I think `toStream()` and `toStream(mapper)` should also have overrides with`Named`
Yeah, this makes sense. You could always update the entry in `nodesEverSeenById`, make `nodesEverSeen` a `List<Integer>` containing node IDs, and only add a node ID to `nodesEverSeen` when `nodesEverSeenById` doesn't contain the ID as a key. Then looking up a random node requires using both, but it's cheap and shouldn't even be happening most of the time.
Elsewhere as well, will omit below.
`Node node = awaitLeastLoadedNodeReady(requestTimeoutMs);` should give you the `node`.
Like we discussed offline, the downstream is actually not necessary.
Ditto: check `aclCreations` below.
Hmm, this one is kind of interesting. I was thinking pause would actually stop things, but I guess for sinks we can actually just pause the consumer. At first I thought we wouldn't want this because `pauseAll`/`resumeAll` were initially used just to pause the consumer when data was rejected with a `RetriableException`, which could, e.g., happen even if data is still being processed simply because a buffer got full or something. But these methods are also used to just pause work when the target state is paused. This makes me wonder if we're also not doing quite enough in those cases before marking the task status as paused -- in fact the connector may still be processing data, we're just not feeding it anymore. I think we at least need a flush + commit, and to be really sure (e.g. in the case of the HDFS connector) we'd probably need to actually `close()` as well.
Remove the last sentence, since the `reset` method is private, and looks like it's handle automatically.
Same question as above about `currentRecordTimestamp` (It seems best to me, to use the same variable name for the same think throughout all methods.)
Is this intentional? cc @enothereska
This doesn't fit with the pattern that we typically use for configuration keys. Prefixing should be done outside the class in question. Check out `StreamsConfig#getAdminConfigs` for an example of doing prefixing. "kafka" is also an odd prefix to use since both the client, broker, etc. all all part of kafka. If we want to use a prefix just for the broker it should be something like "broker".
On a second thought... `future.complete(syncResponse.memberAssignment())` above will trigger `joinFuture.addListener`'s `onSuccess`, which will enable the heartbeat thread right away, and hence there is a (very small) race condition. I think it is safer to just move the the above line inside `onSuccess` (line 395) to set it before enabling heart beat thread, and we would not need `AbstractCoordinator.this` prefix also.
We should use a randomly generated (and hopefully unique!) consumer group here so that we don't conflict with other people running a test.
Thanks! I just noticed this yesterday, and it did trip me up a little.
True there's nothing concrete. Google Java Style Guide mentions a logical order but nothing specific. There are some old Sun conventions: http://www.oracle.com/technetwork/java/codeconventions-141855.html and then, if you look at Intelij's rules, under Code Style -> Java -> Arrangement you get a feel of some other conventions. But beyond guidelines and given the absence of clear consensus my point is that, besides static initializer blocks, I'd expect member fields, constructors, methods in that rough order.
Currently only the constructor adds elements to the list. All other accesses afterwards are read-only. So, we would not need a synchronized list as far as I see. When we implement the add and remove streams thread APIs, we probably need synchronization. My proposal is to leave it a synchronized list now just in case we forget to think about it afterwards and then to reconsider how we synchronize the accesses.
Any reason why we don't just stick with return `AbstractNode` from these overrides? I don't see anywhere that we need it to be a `Processor` etc
Thanks for the explanation. The iterator returned by synchronized connections has to be synchronized by the callers. The code of `SynchronizedCollection` that seems to be used by `getPrincipals`: ```java public Iterator<E> iterator() { return c.iterator(); // Must be manually synched by user! } ``` So, it looks like we don't really have a choice here.
Is this suggested by IDE? :P I feel it is not necessary but if I do not feel strongly either.
Because we cleared them earlier now, the `membersWithOldGeneration` is not necessary any more. We can just iterate `membersOfCurrentHighestGeneration` here.
Seems ok to me to wait and fix alongside other issues like KIP-300 in a "new and improved" DSL (or whatever we do there). If users start to complain and request a fix sooner then we can re-evaluate, but it's not like this was a user-reported bug to begin with.
Yeah, I think it's worth the bit of logic to fail more quickly.
why this? You already have the position from above
Should it be `Class<L> listClass` ? (or `Class<List<T>` if we don't introduce `L`)
Recently, we prefer to use `assertThat()` instead of `assertEquals()`.
This can also happen when topic exists but offline, right? or when we simply fail to connect (network issues, etc)? I like the specific error message, but I'm concerned it may be misleading if there can be other causes to the error (and user is certain the topic exists...)
it also depends on what you want to check. asking the controller will tell you what state brokers should eventually be in, checking any random broker will tell you what state that particular one is in now. i.e. if you want to make sure its fully propagated you'd have to check all the brokers.
Sorry for so many messages, but I think we are leaking a file descriptor here so the right fix may be more involved.
Verifiable consumer necessarily prints something for every record right? I would think that could easily grow larger than the debug log. But in any case it doesn't look like anything is collected by default for VerifiableConsumer, so I'm not sure why any other log file size would be relevant for comparison...
Do you know why the sleep is needed ? From my experiment, 1 millis sleep suffices. The timeout for completed.await() below can be shortened as well since the allocate() call would return immediately.
You can replace this method with `new HashMap<>(source)`
Should be final
nit: use `andStubReturn` instead of `andReturn().anyTimes`. No need to change this now, don't want to block the fix, just fyi for future PRs
Better state "when calling `setState...` in \@code KafkaStreams, the passed instance is expected to be stateless since.." Because not everyone understand what does "... for reporting all state store recovery.." means, stating from the API point of view would be easier to understand. Ditto elsewhere.
I may be wrong, but my understanding was that 400 and above are errors for which error response is returned in `connection.getErrorStream`, while the code is currently reading response from the error stream for >= 300.
It's a public method, true, but `Metadata` is not considered public API (it's annoying that we don't make this crystal clear via package names). Still, you're probably right that it's not worth potentially breaking people for this small improvement.
this should be three test IMHO
nit: add `final`
You're right! I just checked the parameter, and make sure there's no such parameter called `time`. But, yes, it's put the wrong name. Thanks for the review!
I also like @kkonstantine's suggested format.
Nice catch. Though I'm curious how the unit test could expose this? :)
I think we should try to optimize for the simplest locking that is possible even if it is unnecessarily coarse. `Metadata` is a good example where it might be possible to do finer locking, but it's not really worth the effort. Otherwise we need to put a lot of effort into understanding current usage and making sure we don't break locking expectations in the future. There is really only the background heartbeat thread which is contending for these locks, so I'm not too worried about lock contention in general. > Also we can say that we don't provide synchronization for listeners (like ConsumerNetworkClient), it seems pretty independent of the other data in there anyway. Your alternative is also good, honestly I'd be good with either :). That's fair. As long as we can invoke listeners outside of the lock, it's probably ok. I think I'd still like to get rid of the listener because it makes the code harder to understand, but perhaps we can treat this as a separate issue.
The key Serde here, is for the new output key type, right? I think `input` stream is miss leading here.
I think we can probably remove "by design".
@rajinisivaram Just for curiosity I tried the IBM MacOS SDK. It has both classes. And neither work ð with our test harness! Anyway that JDK is not our priority
Looks like there are some checkstyle violations in the commit. It's probably choking on not having a space between the `catch` and open parenthesis. ```suggestion } catch (ConnectRestException e) { ```
In addition to this, this way of taking vararg allows a user to pass `null` (and this code will throw NPE). Normally these methods are declared like: `of(Integer replica, Integer... rest)` to make sure that invalid values can note be passed in.
This would wait forever. Maybe we should do: ```suggestion TestUtils.waitForCondition(() -> stateStore.get(high) != null, "The store never finished populating"); ```
prop: rename `taskToCaughtUpClient` to `taskEntry` or something, looks confusingly similar to `tasksToCaughtUpClients`
Nitpick: space missing before `conditionDetails`.
I think this can be a `final long` if we remove the check as I proposed below.
nit: It seems clearer to use `ConsumerPartitionAssignor.class` directly below.
I think 2 is the more common setting these days. It is a bit more unforgiving, which perhaps makes sense for this test case.
If you don't mind, let's defer this to https://github.com/apache/kafka/pull/7449, just so we have the JIRA to go along with it.
Include the exception in the log so there is an indication of what went wrong? Looks like it was previously included.
Add license header
My preference would be `requireNonNull` and add the message. First IMHO it's always better to have some sort of description v.s just a `NullPointerException` and second, there is less chance for error since we need to explicitly enable assertions. Just my 2 cents.
You could submit a minor follow-up if you like.
`Collections.emptyMap()` is the right one to use. `EMPTY_MAP` should give you a generic warning.
nit: use `private static` ordering (for consistency with the rest of the code base)
In this case everything is quite readable since all the things we're delegating to are super short method calls, I found the code that invokes this quite readable (but of course that's subjective)
@rajinisivaram can we not provide keytab an principal name instead of passing the jaas config. Its still another config management todo for the users.
We should probably assume that people won't be using request throttling immediately since it was just introduced. But the same can probably be said for transactions.
Looking at just this code, it looks like we record this for auth and reauth, even though it actually happens only once as expected. It would be more readable to move this code under the `if (channel.successfulAuthentications() == 1)`.
```suggestion * ReadOnlyWindowStore<K, ValueAndTimestamp<VR>> localWindowStore = streams.store(queryableStoreName, QueryableStoreTypes.<K, ValueAndTimestamp<VR>>timestampedWindowStore()); ```
Do we need to both consumer_properties and client_prop_file_override? maybe we can just use client_prop_file_override
Now that we have a benchmark, we could test `System.arrayCopy`. I suspect it doesn't make much difference either way since the number of bytes we have to copy with this logic would never be more than 10.
...if sending old values
Add a check to verify, whether the iterator has no more elements.
The functionality of process() now is completely covered by transform: users can define a transform function with return type R be "Void" and add a dummy "return null" in the end of the function. And then in KStream we can add public void transform(TransformerSupplier<K, V, Void>) to replace the "process()" call. Having both process() and transform() might be confusing to users, so I would suggest we just remove process() here.
Can remove if initialize above
If that's the case, then we may need a separate PR to go back further than 2.1. I'd say we'd want to correct this issue (which has irked quite a few people) as far back as 1.0.
Also minor `minOffset` -> `min_offset` `maxOffset` -> `max_offset`
Rather than this i think it would be better to add: `tempConsumerDefaultOverrides.put(ConsumerConfig.MAX_POLL_INTERVAL_MS_CONFIG, "300000");` to the `CONSUMER_DEFAULT_OVERRIDES` map in `StreamsConfig`
What about inlining `transformations` and having something like: ``` when(plugins.transformations()).thenReturn(Collections.singleton(transformationPluginDesc())); ```
nit: empty line
For even distribution, it would be useful to verify 2 things. (1) The leaders are distributed evenly when all brokers are unfenced. (2) If any broker is fenced, the new leaders are still distributed evenly.
could we move this `if(!dryRun)` to before `maybeSeekToBeginning`? Then we don't need the additional checks in `maybeSeekToBeginning` and `maybeSeekToEnd` you could just log the messages you want to log here or in another method.
Why do we need this? in L147 we wait until the output is received anyway.
I think what you have here works fine. Thanks @umesh9794 for your PR.
nit: maybe we could check for null first so that we avoid the nesting below (and reduce the diff) ```java if (position == null) throw new IllegalStateException("Missing position for fetchable partition " + completedFetch.partition); if (completedFetch.nextFetchOffset == position.offset) { ... ```
cool, thanks, this seems much cleaner to me
nit: This if statement is not required. The countdown latch won't wait at all if the timeout is <= 0.
To keep the test as simple as needed, what about simply using: ``` mm2Props.put(DefaultConfigPropertyFilter.CONFIG_PROPERTIES_EXCLUDE_CONFIG, "delete.retention.ms"); ```
Nit: remove "Note". "Additionally, enabling..." reads better.
slf4j logger methods logs exception if the last argument is throwable. so this is fine.
formatting: no need to curly braces
Is this change actually needed? The intent currently is to let `BoundField` be constructed only within the scope of a given Schema and to use `Schema.get` in order to get an instance. We do not expect a `BoundField` constructed in the context of one schema to be used for another schema. Note also that the includes test case does not cover this change, so we are probably missing another test case if we think this fix is important.
nit: in AK it's common to omit `get` prefix in getters. The name should be `processorMetadataForKey`.
It'd be better to avoid reformatting code to change indentation settings. AFAIK, in Streams at least, we tend to use indents of 4 spaces.
Update the above TODO with only admin client left.
I think the lock grabbing hierarchy of instance `stateLock` and thread `stateLock` is still vulnerable to deadlocks. For example: thread 1: `StreamThread.setState` --> grab `stateLock` of thread --> `stateListener.onChange` --> `checkAllThreadsDeadAndSetError` --> trying to grab `stateLock` of instance thread 2: `KafkaStreams.setState` --> grab `stateLock` of instance -> user-specified `stateListener.onChange` --> user calls `KafkaStreams.close` inside that callback --> wait for all the stream-thread to shutdown, but thread 1 is blocked on grabbing the instance `stateLock`.
nit (sorry): would be nice to be consistent with capitalization of the first letter.
It does not appear that `KafkaConsumer` (or rather the `SubscriptionState` class it uses) allows using both `subscribe(...)` and `assign(...)`. Given that line 133 was recently changed to `assign`, then shouldn't line 167 be changed as well to: ``` restoreConsumer.assign(Collections.<TopicPartition>emptyList()); ```
Drop "The .. the .. " -> "Topics consumer is subscribing to" or "Consumer's topic subscription" Same for rest..
nit: replace with <>
We should not use this annotation but rather use `assertThrows` (we still have some code that does not use `assertThrows` but we try to lazily migrate our tests, as it provides a better test pattern).
nit: missing a space after the comma. Also, it would be nice to be consistent with the use of comma vs period for the similar cases in this file
I would still try to keep this assertion, something among the lines of: ```java if (clashOnPrefix) { assertThat(valuesWithPrefix.get(0), either(is("a")).or(is("b"))); } else { assertThat(valuesWithPrefix.get(0), is("a")); } ```
The trickiness as demonstrated in the current PR though, is that if we first do the expiration we may get records that are matched to the current processing record, which need to be skipped from deleting/emitting before the join. I think it is still possible to simply the current logic without naive buffering. Because: 1) The current processing record's timestamp T is no larger than the updated max stream time T'; 2) The current processing record's matching record's smallest timestamp would be (T - window-size); 3) The expired records' largest timestamp would be (T' - window-size - grace-period), where grace-period >= 0. In other words, if the current processing's record timestamp T is smaller than T' (i.e. it's a late record and hence did not advance the stream time), then for all records that are within [T - window-size, T' - window-size - grace-period] assuming T - window-size < T' - window-size - grace-period, would have already been expired end emitted, and hence won't be found and matched; if the current processing's record timestamp T == T' (i.e. it is not a late record), then T - window-size is always >= T' - window-size - grace-period, which means that all joined record's timestamps should be later than the expired timestamps. That means, if we do the expiration first based on (T' - window-size - grace-period), the newly expired records' timestamps should all be smaller than any joined record's timestamps for that processing record generated later. And hence it is safe to just blindly expire them all without the `except` logic.
nit: could avoid the last space after `is correct.`
There is only one value returned. This method can be declared as void.
Should we change the name to maxTimestampMs too? Ditto below.
This `ArrayList` should be generic (that is, `new ArrayList<>(...)`).
nit: simplify -> `throws Exception` (also above)
Could we make the following function signatures a bit more consistent: ``` allAssignedTaskIds, suspended, restoring, running, previousTasks, runningTaskIds, allInitializedTasks ``` E.g. `Collection<T> XXTasks()` and then extract taskId / etc from the callers if necessary.
This whitespace change isn't needed
nit: missing closing parenthesis.
nit: no new paragraph required
This cleanup seems a bit awkward. It assumes that tests will initialize the driver but not close it, which seems like a strange abdication of responsibility. I think it would be cleaner and clearer to get rid of the driver field entirely. Tests that need the driver already initialize it; they can declare it as a local variable as well. Then, they clearly need to close it as well. Since `TopologyTestDriver` is `AutoCloseable`, one option is to declare the driver in try-with-resources style: ```java @Test public void myTest() { try (final TopologyTestDriver driver) { // the test code } } ```
Generally, replacing an `isEmpty` check with `count` is not a good idea as you can easily regress in performance. In this case, the deque implementation may have a cheap `size()`, but it's brittle and not something I think we should do.
Honestly it kind of seems like there is enough divergent logic to merit splitting this up into separate methods for the manual vs cleanup-delay cases.
nit: Could we add some java doc here to explain why we need this? Thanks.
Hmm, I don't think this is right. We still need to build Scala 2.12 separately since it requires Java 8.
Actually, that may complicate things by causing records to be given to `SourceTask::commitRecord` out of order (a record that caused a producer failure may be committed after a record that was dispatched to the producer after it). So probably best to keep the error-handling logic here, but I do still wonder if we can respect the logging-related configuration properties.
Is the logic changed here? It was `this.allKeys = (keyFrom == null) && (keyTo == null);`
Ah I see. MVN then :)
Mentioned offline, but a better solution (if Becket is right that the try/catch needs to cover this branch) would be the following: ```java fetchedOffsets = nextInLineRecords.fetchOffset; ``` Also, seems this variable shouldn't be plural.
Hmm, why do we want to skip the first replica? When election != Election.PREFERRED, we still want to consider the first replica as long as it's in ISR and is alive.
Maybe keeping it simple to always go with left is fine for now, I was just wondering if you have a specific reason for that :)
We can move that line after the `waitForCondition()` block to just commit once all records have been consumed.
nit: list the members list here would help trouble shoot.
I'd suggest to surround this command with an if-condition as below (if passing the argument as a collection, one more reason to change): ``` if (!topics.isEmpty()) requestUpdate(); ``` My reasoning is: why call `requestUpdate()` when there's no topics, right? Maybe nobody will ever call `addTopics` with an empty collection of topics so this optimization step is unnecessary. ;)
Not sure about this. I'd suggest using NO_TIMESTAMP and similar sentinels for the compatibility case.
unrelated, but maybe worth creating helper method that returns `Optional<GracefulShutdown>` to avoid these null checks throughout
See if you can refactor this code which is similar to what beginningOffsets has (apart from the condition between pos1 and pos2)
sorry, a bit late to the party, but if Kafka Connect can't create the topic but can still read / write to it, it should also have the describe rights. In which case, we can check if the topic exist using a describe? I feel that right now this might be introducing a bug. Say the Kafka Connect isn't authorized to create a topic and the topic doesn't exist, then it will still go on with the execution
I think i said this before, i think it is cleaner to bail out early if the topic is null. We then don't need to check again and for the main case, i.e, topic is not null, the code is outside of an `if` statement ``` if (topic == null) { this.stores.put(storeName, store); return; } ```
I told Bruno to do this -- we can discuss next week if you still have questions, but the motivation is to avoid letting the tasks of a topology/query get way out of sync with each other. This can result in missed output for example when a processor upstream of one side of a join is paused for a long time while the other continues proccessing records and trying to join them
Instead of letting the callee `maybeAutoCommitOffsetsSync` silently dropping the given offsets that no longer exists, I think we should let the callee to simply report unknown topics out to the callers after timer elapsed and let callers to handle them. The main reason is that unknownTopicOrPartition may just temporary and hence silently dropping them at the callee can lead to confusing behaviors. Note there are several callers: * When re-join group via `maybeAutoCommitOffsetsSync`: if `commitOffsetsSync` throws the unknown topic or partition exception after exhausting retries within the timer, the caller `maybeAutoCommitOffsetsSync` would log it upon capturing the exception and then wrap it as a `InterruptException` still. Note that the in the next poll call since `needsJoinPrepare` is false already we would not try to call `onJoinPrepare` again and if the topic is indeed deleted, the rebalance would remove the partitions from the subscription later. * When customer called via `Consumer#commitSync` directly: we can directly throw the timeout exception to the customer caller still. Note that since we would continuously log the error for `UnknownTopicOrPartition` error, user debugging it would still learn about the root cause why this commit call timed out.
I think that we can safely assume that when a request/response is serialized with `verbose` equals to `false`, we are not going to deserialize it. Therefore, I suggest to drop the handling of `verbose` on the read path.
nit: should be `Deserializer<?>` to avoid warnings about using a raw type
I think this check is redundant and should be removed, otherwise we should have it for all general RPCs with topic => partition structure.
This particular test doesn't make sense any more, since there is no "old" assignor type now that PartitionAssignor is removed
Same as before, parameters of `assertEquals` should be the other way round.
Fixed when merging the PR.
Yes, that may not be enough since we need to propagate the connected state through Selector.poll(). Could you try the following? In Selector, we maintain Set<String> immediatelyConnected; In connect(), we make the following changes. If connected is true { immediatelyConnected.add(id); key = socketChannel.register(nioSelector, 0); } else { key = socketChannel.register(nioSelector, SelectionKey.OP_CONNECT); } In poll(), we make the following changes. 1. if (hasStagedReceives()) || immedidatelyConnected.size() > 0) timeout = 0 This will make sure that select() will return immediately. 2. After the call to addToCompletedReceives(), we will add the following code. for each id in immedidatelyConnected get the KafkaChannel from id kafkaChannel.finishConnect() this.connected.add(id) immedidatelyConnected.clear();
I'm confused -- why wouldn't you run as a service with multiple processes? If you hand all the mirror maker processes the same config, they'll form a consumer group and balance the work between themselves.
A couple of things (applies to the same code a few lines below): - Is there a reason you changed `Map<String, String>` to `HashMap<String, String>`? - We can pass `1` to the `HashMap` constructor to avoid allocating a 16 entries array when we `put` `topic`.
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
Should this be `num_lines=2` (cf. L120)
nit: parameters are not aligned.
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
This is ok in terms of the test, but `LOCAL_CLOSE` is the state used for client-side disconnection. For server-side disconnections, the state would be whatever the client state was at the time the disconnection was detected. Could just use `ChannelState.READY`.
I believe PassThrough is only used for the cogroup but now I think you can remove it completely.
I tried to summarize both methods: What @guozhangwang 's meaning is, we can "lazily" detect the issue after assigning all unassignedPartitions. we don't need to clear the `potentiallyUnfilledMembersAtMinQuota` here, because as the "original" variable naming said: they are "potentially unfilled members", just keep them there. We "should not" assign partitions to them in this case because we've reached `expectedNumMembersAssignedOverMinQuota`. But if somehow, after assigning unassignedPartitions to all unfilledMembers, there are still some unassignedPartitions left. We can just assign them to `potentiallyUnfilledMembersAtMinQuota`. And after running out the `unassignedPartitions`, we can check: ``` numMembersWithMaxQuota == expectedNumMembersWithMaxQuota && numMembersWithMinQuota == expectedNumMembersWithMinQuota ``` to do error handling. VS. In @ableegoldman 's version , we find issue immediately and handle it. we computed the `potentiallyUnfilledMembersAtMinQuota` correctly (that's why we need to clear it). So, if the issue happened: > if somehow, after assigning unassignedPartitions to all unfilledMembers, there are still some unassignedPartitions left We can try to get member from `potentiallyUnfilledMembersAtMinQuota` and then assign unassignedPartition to the member. If we can't get member from it (i.e. `potentiallyUnfilledMembersAtMinQuota` is empty), we throw exception directly. Both ways can find errors when happened. Personally, I like Sophie's version more since it's much clear.
Sounds good. I prefer it the way you suggest anyway. I'll change it.
Well in `MirrorConnectorsIntegrationSSLTest`, we can override it, but we should put the default implementation in the base class
Please use static imports to make this more readable.
The Kafka cluster ID is passed into the constructor, but is this supposed to represent the Connect cluster ID or the Kafka cluster ID? Since this is in Connect code, without a context we'd assume it was the Connect cluster ID.
nit: can simplify a little bit ```java return allErrors.stream().anyMatch(this::shouldRefreshMetadata); ```
It's an interesting thought, but users may override the number of partitions for `__consumer_offsets`, so I don't think it will work. More generally, we are trying to avoid dependence in the clients on the `__consumer_offsets` topic since it ties the behavior of the client to what is more properly an implementation detail.
We don't need this on client side. Auth to Local is useful on the broker side where we enforce authorization to convert a principal into a local. On client side we are not using this.
Could we check that `close()` was not called, i.e. no exceptions get thrown in easy mock then? Ditto below.
I had a look at this as well and I could not find a clean way to do this. Overall, I believe that using commands is a great move for the future so I am also fine with leaving it as is. I think that we should aim for reworking the other tools to use a similar pattern in the future. We could perhaps file a JIRA to not forget about it.
This should be final.
nit: indentation is a bit off here.
since parallelism in streams task based, this would create a lot more RocksDB threads than available processors if each task maintains its own state store.
Nit: why not use boolean
Ok, I think that's what I was talking about. Not multiple child nodes, but multiple parents somewhere on the chain back from `repartitionNodeToBeReplaced` to `keyChangingNode`. This line of code seems to assume that there is always one path back to `keyChangingNode`, but in general, you could have a diamond (since this is a DAG and not a tree). like : ``` keyChangingNode | | c1 c2 \ / (something) | repartitionNodeToBeReplaced ``` If this can occur, then there would need to be multiple of `keyChangingNodeChild` which all need to be re-rooted. But I'm not sure it can occur.
Looks like we could deprecate it, but it's not listed for deprecation in the KIP. I'll defer to @guozhangwang on this one.
yeah, i was thinking we could inline this method into `close`, too
nit: As we always pass same value to this method, we can drop the parameter and use `time.milliseconds` within this method.
Should we start connect rest server if we want this code can running successfully. but I not seeing where to start the connect rest server in MirrorMaker. In my case, there got an exception which cause for unknown host url
Add missing `null` check for `materialized`
I see. Than please remove the next line `driver.process` and simplify to ``` new ProcessorTopology(...) ``` (we don't need variable `driver` for this case)
nit: final and the two below
Perhaps it would be better to change host using reflection in the test since this code looks out of place in the implementation? Then the `host` field can also be made final.
nit: braces unneeded
I think we should have a `log.info()` here to show the error. I'm afraid users might miss some error statuses once they get overridden, so it's good to have it persisted somewhere
Ditto above: "... to select the new key". And use `KeyValueMapper<K, V, K1>`.
We can use the `replace` overload that takes a `char`.
Since we use this check mutliple times, could you please extract `!streamThread.getName().equals(Thread.currentThread().getName()` to a variable named `callingThreadIsNotCurrentStreamThread` or similar.
Given that we always set the future to `null` here, is it correct that the reason that we do all of this logic is to potentially use a future initialised via `lookupCoordinator`? And is there a point in actually setting the `findCoordinatorFuture` in this method? If I understand the aim correctly, it could be clearer if we did: ``` java RequestFuture<Void> future = findCoordinatorFuture; findCoordinatorFuture = null; if (future == null) future = sendGroupCoordinatorRequest(); ``` But I may be missing an important detail. :)
We could mention the pending shutdown in error log instead.
```suggestion * Return a window definition with the window size and no grace period. Note that this means out of order records arriving after the window end will be dropped. ```
I think we can simplify the `fail` logic even further by combining `failWithTimeout` and `fail` and converting `failWithTimeout` to a boolean that determines whether or not the call should be failed with a timeout like so: ```java final void fail(long now, Throwable throwable) { if (failWithTimeout()) { log.debug("{} timed out at {} after {} attempt(s)", this, now, this.callRetryContext.tries() + 1, new Exception(prettyPrintException(throwable))); handleFailure(new TimeoutException(this + " timed out at " + now + " after " + this.callRetryContext.tries() + " attempt(s)", throwable)); } else { handleFailure(throwable); } } private boolean failWithTimeout() { return aborted || calcTimeoutMsRemainingAsInt(now, deadlineMs) < 0 || this.callRetryContext.tries() > maxRetries; } ``` And then we can replace all occurrences of `failWithTimeout` with just `fail`.
Don't think we need to change it from the for each loop. We don't need to remove the closed tasks as they are immediately cleared after the call to this method
To clarify, what I meant is just to move the initialization of the records variable from above to here (since we don't actually need it outside of the loop): ``` List<ConsumerRecord<byte[], byte[]>> records = fetchRecords(builder.build(), Errors.NONE.code(), 100L, 100 * i).get(tp); ```
Longer explanation from before: https://github.com/apache/kafka/pull/645#discussion_r47489229
Nit: add `final`
I think this call might not strictly be needed. We cannot return to the INITIALIZING state after beginning any transactions.
Looks like this is causing checkstyle errors.
Hmm.. we are pealing off two layers here. The second layer is window-store-facade, what's the first layer of WrappedStateStore? Ditto elsewhere.
Could we try to reuse https://github.com/apache/kafka/blob/03e788b29be6da0ef729f38448dc4345e68e398f/clients/src/main/java/org/apache/kafka/common/security/oauthbearer/internals/OAuthBearerSaslClient.java#L52 in this part of the code? I'm not sure how simple it is since I don't have extensive experience in Java, but reusing code and having explicit separators is always a good thing. If we could do it in the server as well, that'd be great
This logic should probably be put in `RecordAccumulator.abortExpiredBatches`. Otherwise, if we put this logic here and we call RecordAccumulator.abortExpiredBatches() from another place, RecordAccumulator.abortExpiredBatches() would still return partition to be expired even if metadata has expired.
It might be nice to have a sanity check here that `offset` is non-negative, since that would indicate we've unexpectedly received a sentinel value. I thought we did that already, but it's obviously not here.
Interesting. Which is more useful host:port or id? If the latter, let's just leave as is. Otherwise, then changing it here and other places sounds good.
Nitpick: a slightly nicer way to write this is: ``` java for (Iterator<Map.Entry<String, Long>> it = topics.entrySet().iterator(); it.hasNext(); ) { ... } ```
Yeah. I was thinking of the same thing, "hold the requests in purgatory". But like you said, maybe this optimization is not worth the added complexity.
Nit: rename to "repartitionForJoin"? Since we have the other repartitioning before aggregation in another class.
```suggestion assertThat(CLUSTER.getAllTopicsInCluster(), contains(changeLog)); ``` Equivalent, but gives a better error message when it fails.
oh, actually I think it can. I think this will produce two paths back: ``` changedKeyStream = stream.map(...) left = changedKeyStream.filter(fnA) right = changedKeyStream.filter(fnB) merged = left.merge(right) merged.join(otherStream) ``` And I *think* this code would only re-root either `left` or `right`, but they should both be re-rooted, right? If so, it might make a good test case.
suggestion: `because the URL of the leader's REST interface is empty` (otherwise it should have been `due to the URL of the leader's REST interface being empty`)
looks like place holder is missing for the last argument in the earlier code itself.
nit: We could instantiate a new `ListTransactionsOptions` here instead of using `null`. This would remove the `null` check below.
Seems like we transition to AUTHENTICATE before the TLS handshake (if TLS is enabled). If TLS authentication fails, will we also get a warning then? I think that would be good, but just checking as previous proposals didn't cover TLS.
final Why do we need to catch an fail here? We can just let the exception bubble out to fail the test
I think it would be better if the users don't have to look in the cause.
Committable offsets here should contain consumed offsets, and punctuation itself should never update those consumed offsets right? I think we can skip the call if `consumedOffsetsAndMetadataPerTask` is empty.
I see. You are talking about the broker side log cleaner thread -- not the local state directory cleaner thread. (windowed stores also use the concept of segments, not just topic-partitions). However, it seems we want to extract this fix into a separate PR to be able to cherry-pick it to older branches? Seems to be unrelated to this PR.
I am personally a little confused what `orElseGenerateWithPrefix` means? It's a personal preference, but I don't think it's easy to read. Similar for `suffixWithOrElseGet`. (Maybe it's just me, being not use to fancy Java8 constructs that are mimicked here...) Curious to hear what others think.
@lindong28 Now it's a lot clearer what you meant in your original email. You're basically saying that since `RemoteAccount.ssh()` blocks, `RemoteAccount.ssh_output()` blocks until all output is collected and `RemoteAccount.ssh_capture()` drives the whole process despite acting as a generator, there's no way to start a second process between when you start the first and when you start reading its output? I think it makes a lot of sense to provide support for that. More generally, I think the current set of `RemoteAccount.ssh*` methods could use some cleanup and potentially renaming to simplify things. Originally I thought the blocking `RemoteAccount.ssh()` would be the most widely used, but it turns out we've found more and more uses for capturing the output. @granders, a patch just to add Ducktape support for the approach @lindong28 is looking for should be quick and easy. I think it can look a lot like `ssh_capture`, but it'll have to return an iterable object after invoking the ssh command rather than treating the entire method call as a generator using yield. It might even make sense to just return the subprocess object and allow the user to do whatever they want with it, so the example would look something like ``` cmd = "same_as_before" proc = node.account.ssh_async(cmd) self.start_jmx_tool(node) for line in iter(proc.stdout.readline, ''): # same as the previous for loop ``` I think there are cleaner ways to expose this, but given how many `ssh*` variants we're ending up with, we may want to hold off on introducing much more until we sort out how to capture all of them with a minimum of methods.
That's OK too.
Since now the `StringBuilder` is being appended to directly, the `b.append` here would cause duplication of the accumulated content I think
Well, while we should have a check like this, it seems it should go to the top of this method, next to the key/value `null` check? We should also add a corresponding `lateRecordDropSensor` (cf `KStreamWindowAggregate.java`). We can also `return` from `process()` early, as if we have a late record, we know that stream-time does not advance and thus we don't need to emit anything downstream.
I'm not sure this is really the right place to test the `prefixScan` functionality for all of these different store types, this test class is really more for making sure the topology itself is all wired up correctly. If you're just trying to test a method on a specific store type, that generally makes sense to do in the test class for that store itself. In other words you don't need to have a separate test here for each underlying store type (eg `PersistentTimestampedStore` or `LruMap`, etc), there are dedicated test classes for that (like `RocksDBTimestampedStoreTest` or `InMemoryLRUCacheStoreTest`) That said, it sounds like the original bug report uncovered the missing implementations "when accessing the state stores through the processor context" -- which does sound like it could/would be reproduced through a test here. Maybe you can just pick a store type and write a single test that reproduces the issue when run without this patch, and I would consider that sufficient for this.
They can't construct a kafka producer with the changes made in this PR.
Nit: I personally dislike being shouted at by exception messages ```suggestion throw new IOException("Could not delete old class file"); ```
Might be worth noting what needs synchronization (accessed by heartbeat thread and user thread) and what is safe. I was having trouble sorting out which methods need synchronization and which ones don't. Seems like the shared state is `heartbeat`, `state`, `client`, `time`, `groupId`, `retryBackoffMs` (where `time`, `groupId`, `retryBackoffMs` are threadsafe)
I wonder if it would be preferable to use a more generic message which clearly mention the error encountered: `OffsetCommit request for group id {} returned error {}. Will retry.`. Without mentioning the received error, we don't really know what happened so the log is not that useful.
We should close the producer.
Seems like we could use a separate illegal state exception here for `RESTORING` as we should never hit it.
flip order of `headers` and `timestamps` to match method's name
```suggestion * @throws org.apache.kafka.common.errors.TimeoutException if the thread does not stop in time ```
Frankly, I am not sure if it makes a difference. Leave it up to you.
So we may have one extra `time.milliseconds()` for every poll. Not sure if this will be a problem. I recall that there used to be performance issue due to extra `time.millseconds()` in `consumer.poll()`. Do you remember this issue? But it seems we have to bear with this extra call in order to have this metric.
Btw: we maintain state quite redundantly (what is a general issue). Would it make sense to extract a helper class that wraps ``` private final Map<TaskId, StreamTask> restoring = new HashMap<>(); private final Set<TopicPartition> restoredPartitions = new HashSet<>(); private final Map<TopicPartition, StreamTask> restoringByPartition = new HashMap<>(); ``` and we only modify the state via the helper? The helper class can insure that all three data structures don't diverge. (Also ok to do in a follow up cleanup PR)
nit: `maxRecordTimestamp > timestamp` -> `maxRecordTimestamp >= timestamp` nit: missing space: `// We`
We can also remove "public" here to make it package-private.
nit: debug statement differs from other clients
The method name is confusing as it doesn't check if the thread is dead.
This seems to be redundant from above (or already the merged test...) -- restore-consumer and adminclient would be missing though.
I don't think this is valid since this callback is triggered by another thread. The assert failure can't be aware by test thread.
Should we still continue deleting the global state directory if the local task directories cleanup failed? I'm thinking if the local stores deletion fails while global store succeeded, we will throw an exception, and user may retry in which case `globalStateDir()` will be called and trying to re-create the folder and delete it.
It will be better to use `MockTime` rather than `SystemTime`. That will make it easier to test timeouts
Java doc for lifecycleListener
ð I "have a friend" who sometimes puts new classes in the same package so that they can use package private methods. This friend understands that such code is brittle.
Also , the 1-liner description "Transform the given value to a new value." needs updating.
I like your changes. What I meant is that we could change the constructor of `SourceGraphNode` to: ``` public SourceGraphNode(final String nodeName, final Set<String> topicNames, final ConsumedInternal<K, V> consumedInternal) ``` and the one of `StreamSourceNode` to: ``` public StreamSourceNode(final String nodeName, final Set<String> topicNames, final ConsumedInternal<K, V> consumedInternal) ``` In this way, we have a set of topics as soon as possible in the code path from the public API. I think this makes it clearer that it is not possible to have duplicates of topics internally. To keep this PR small, I would propose to just do the changes for `SourceGraphNode`, and do the other changes in a separate PR.
Should we `assertNull` for all three before anything is recorded to check that they are created lazily? (similar below)
Here also, would be great if you could make the params `final`
Nit: perhaps mention that the order of the listeners config is important: ```suggestion // correct listener is chosen when https listener is configured before http listener and advertised listener is http ```
Ideally we'd not wrap the exception if there are no retries, so I guess it just depends on how hard it is to make that work.
> LGTM? If this is a question, should it be LGTY? ð
Yes, that may work. It just that it would be good to avoid duplicating the same code in two places.
nit: could you try to deduplicate code here and in the other unit tests? Here for example, you could have one method like this: ``` private void shouldThrowIfNoPeekNextKey(final Supplier<MemoryLRUCacheBytesIterator> methodUnderTest) { final ThreadCache.MemoryLRUCacheBytesIterator iterator = methodUnderTest.get(); assertThrows(NoSuchElementException.class, iterator::peekNextKey); } ``` and then two public tests ``` @Test public void shouldThrowIfNoPeekNextKeyRange() { final ThreadCache cache = new ThreadCache(logContext, 10000L, new MockStreamsMetrics(new Metrics())); shouldThrowIfNoPeekNextKey(() -> cache.range(namespace, Bytes.wrap(new byte[]{0}), Bytes.wrap(new byte[]{1}))); } @Test public void shouldThrowIfNoPeekNextKeyReverseRange() { final ThreadCache cache = new ThreadCache(logContext, 10000L, new MockStreamsMetrics(new Metrics())); shouldThrowIfNoPeekNextKey(() -> cache.reverseRange(namespace, Bytes.wrap(new byte[]{0}), Bytes.wrap(new byte[]{1}))); } ``` Admittedly, in this specific case, we would not win much but for other unit tests in this test class it may be worth. Try and then decide if it is worth or not.
If we use `computeIfAbsent(...)` below, we don't need this line: ```suggestion ```
This was probably left by mistake.
nit: don't we need a space between the varargs type and the variable name? I'm surprised mainly at checkstyle here.
yes, I think so.
Nit: this line is too long.
This interface should be name `public interface SnapshotWriter<T> ...`.
It could be updated in a separate thread. I cannot see how that would be a problem though. We do have synchronization in `Metadata`.
It's super awkward, obviously, but since this is what happens when we process the configs in the real code we should try to replicate that in the test
right, i may also be playing fast and loose w/ terminology in my responses :) But I think we're on the same page as to the meaning of the different options. My concern with the HDFS uncommitted case is that compared to consumer lag where, at least roughly, you could pick a number and use it across all topics for alerting, this doesn't have that property. The value you would alert on for HDFS is completely different from the value you'd alert on for ES. In this way "lag" definitely seems inaccurate terminology -- the connector isn't really "behind", it just intentionally has uncommitted data. I see a few options: * Include both! Something like "processed-lag" and "committed-lag". * Don't use "lag" when referring to uncommitted data. It could just be something like "uncommitted-count" (which then opens the question of doing it per partition, max across partitions, or sum over all partitions). And of course these aren't necessarily mutually exclusive. The potential drawbacks I see with the first point is that maybe the processed lag just isn't that interesting since it is bounded by the # of messages that fit in a single fetch request anyway, and introducing both may lead to confusion if we're not super clear in the docs about which is more important to monitor. In particular, now that I've thought through it more I'm struggling to find a problem I could discover / diagnose based on the processed lag. The drawback to the second is that we're diverging from the terminology used elsewhere. But maybe that's fine since, as we're discovering through this conversation, they are in fact different things. You could always re-raise this in the KIP discussion thread to get additional feedback. Also, might be worth looking at whether streams has any relevant metrics and how they handled this. In some ways they have the same problem -- they have the actual consumer lag, but also the time for a message to make it through the topology and all downstream messages to be acked. At best I would guess they could track lineage within a subtopology and provide info based on that, but I am guessing those metrics may simply not be there due to the more complex processing graph that they have.
I don't know the IDE setting -- this case is rare enough that I "fix" fit manually if it happens.
probably not required to do a special logic for ConnectHeaders. The equals check using iterator below should probably be suffice.
This is a micro-optimization, so feel free to ignore. An alternative idiom is to call `map.get()` and check the result against null. This works because we know the value will never be null and it saves a hash lookup.
Perhaps we can lock the Sensor first and then lock the base metrics instance whenever we are removing a sensor. During addMetric, the sensor is locked first and then the Metrics object. If we follow the same pattern when doing removeSensor, we should not have any deadlocks right? What do you think? I'm still open to handling this in KAFKA-2419, but I want to be sure we have an acceptable solution.
Nit: add `final` to both parameters -- please follow a "one parameter per line" formatting.
As per our offline discussion, we'll leave it like this for now
`{@code null}` -- same below
Adding batch deletion here would be useful also. This has caused problems in Kafka previously.
Nit: ```suggestion * executed exactly once. If {@code maxRetries} is set to {@code n}, the callable will be executed at ```
nit: this alignment is a little weird. Typically we would align with the arg above
req: The `clientId` type should be `UUID`, or a generic for easier testing (c.f `StickyTaskAssignor`)
Did you have a specific use case in mind where this was possible? Typically deserializers are deterministic.
as above (more often below -- please fit all)
Nit: Can we change the wording of this to the following ```suggestion log.debug("{} attempting protocol downgrade and retrying.", this); ```
Hmm, I'm wondering if there's some reason we shouldn't make `addRequest(long, Callable, Callback)` synchronized and remove the synchronization from all the other HTTP call handling methods (`connectors`, `connectorInfo`, `putConnectorConfig`, `requestTaskReconfiguration`, `taskConfigs`, `putTaskConfigs`, `restartConnector`, `restartTask`) which are currently `synchronized` - they pretty much just call out to `addRequest`.
nit: `null` -> {@code null}`
Hmm, I am not quite sure what the new state GSSAPI_OR_HANDSHAKE_REQUEST is for. It's making the same call as the HANDSHAKE_REQUEST and there is no code to change saslState to GSSAPI_OR_HANDSHAKE_REQUEST.
That is a good catch @tedyu . Thanks for that. cc @mjsax for confirming.
You can also replace `return segments.get(key);` with `return previousSegment == null ? newSegment : previousSegment`.
Nit: extra empty line.
Needs `@param logContext` (and also `@param time the time instance`)
This is really inefficient if `buffer` is a `DirectByteBuffer` and it's not small. The bulk `put` method performs better by doing a JNI array copy if it's larger than 6 elements. It's also less code.
Fetch response v2 is actually different from v1 since the message format is different.
We can let this function to return the list of suspended tasks, so that in rebalance listener we can print it in log4j entry; by doing this we do not need the `suspendedActiveTaskIds`.
Hopefully we can remove this `sleep` as well
As we expect only `groupId`, I would verify the `groupIds` here and in `buildRequest`.
why are we using RETRY_BACKOFF_MS_CONFIG here? this is just a sleep to avoid a tight loop in checking whether the futures are done right? In that case we wouldn't actually be issuing a new request, so we can probably just use a constant set to some small value (e.g. a few hundred ms).
`</node>` -> `</code>`
Add a log saying that internal strings are used since inputValues.txt is absent.
This test is overly complicated. I think it could: - Create a topic - Produce messages to all partitions but one - Consume all messages - Start a single MirrorMaker2 instance primary->backup - Use `RemoteClusterUtils.translateOffsets()` to retrieve offsets - Assert offset for the last partition is 0 For example, something along these lines (this cuts a few corners so you'd need to improve it) ```suggestion @Test public void testReplicationWithEmptyPartition() throws Exception { String consumerGroupName = "consumer-group-testReplicationWithEmptyPartition"; Map<String, Object> consumerProps = new HashMap<String, Object>() {{ put("group.id", consumerGroupName); put("auto.offset.reset", "earliest"); }}; String topic = "test-topic-empty"; primary.kafka().createTopic(topic, NUM_PARTITIONS); mm2Config = new MirrorMakerConfig(mm2Props); // produce to all test-topic-empty's partitions *but the last one*, on the primary cluster produceMessages(primary, topic, "message-1-", NUM_PARTITIONS - 1); // Consume, from the primary cluster, before starting the connectors so we don't need to wait for discovery Consumer<byte[], byte[]> consumer = primary.kafka().createConsumerAndSubscribeTo(consumerProps, topic); consumeAllMessages(consumer, NUM_RECORDS_PER_PARTITION * (NUM_PARTITIONS - 1)); consumer.close(); waitUntilMirrorMakerIsRunning(backup, mm2Config, "primary", "backup"); Map<TopicPartition, OffsetAndMetadata> backupOffsets = RemoteClusterUtils.translateOffsets( mm2Config.clientConfig("backup").adminConfig(), "primary", consumerGroupName, Duration.ofMillis(CHECKPOINT_DURATION_MS)); OffsetAndMetadata oam = backupOffsets.get(new TopicPartition("primary." + topic, NUM_PARTITIONS - 1)); assertNotNull(oam); assertEquals(0, oam.offset()); } ```
Here we can further refactor a bit: ``` if (config.idempotenceEnabled()) { // read out the acks string value if (string value is null) // just log an info saying we are gonna override it to -1 else if (string value is not "all") // throw exception } ```
sounds good. Let's put it off for now.
this is for L134 - topic is not used
Would it make sense to move `hasPosition` to `TopicPartitionState`? Then we could just turn this into a null check on `position`.
Basically I was wondering if it is really necessary to pad four 0 bytes on the key schema. We use `seqnum` for window stores that are used in stream-stream joins, since we need to maintain values of the same `[key, timestamp]`, but for aggregation windowed key we would not need to maintain uniqueness, and hence not necessary to use `seqnum`. I'm basically asking if just `[from, key]` is good enough as the lower range.
Probably need to change after rebase
Should we finer-handling different error cases here? ``` /** * Possible error codes: * * REQUEST_TIMED_OUT(7) * INVALID_TOPIC_EXCEPTION(17) * CLUSTER_AUTHORIZATION_FAILED(31) * TOPIC_ALREADY_EXISTS(36) * INVALID_PARTITIONS(37) * INVALID_REPLICATION_FACTOR(38) * INVALID_REPLICA_ASSIGNMENT(39) * INVALID_CONFIG(40) * NOT_CONTROLLER(41) * INVALID_REQUEST(42) */ ```
As mentioned in the KIP discussion thread: it seem unnecessary complex for user, to specify all those value. The only parameter that is mandatory is the window size. If people call `KGroupedStream#windowBy` all other parameters also optional; they should be optional when reading a topic, too.
nit: "didn't went" -> "didn't go"
The logic is different for ListGroups. We have to send a separate request to every broker in the cluster and then aggregate the results.
Hmm this is interesting: for created the running tasks we call its `task.close` function whereas for `restoring` we only call `task.closeStateManager`, is it intentional? If yes why? cc @ableegoldman
Why do we need to call `getCause()` ? Does another `StreamsException` wrap the actual expected `StreamsException` ? If yes, this should not happen IMHO.
Nit: remove unnecessary spaces (same below)
Why are we not just checking the `sizeInBytes` ? Cache.size returns the number of items in the cache and is unrelated
I think this definitely helps clarify! A copy suggestion: ``` Attaching a state store makes this a stateful record-by-record operation (cf. {@link #map(KeyValueMapper) map()}). If you choose not to attach a state store, this operation behaves similarly to {@link #map(KeyValueMapper) map()} but additionally provides access to the {@code ProcessorContext} and associated metadata. ```
I see. So the distinction is because in the revoked case we get a chance to await on the errant record reporter futures before we commit offsets for the revoked partitions, but in the lost case we've already lost the partition and don't get a chance to commit offsets. Since we already do not own the partition, we should not be reporting errors for it and should let the current owner take that responsibility. It should be noted that the cancelation is best effort, so there is a chance we duplicate reporting for the errant record.
It might be useful to log both the old and the new value.
We can still follow the original pattern of calling a `listNodes` to any broker, get the result, and inside the response handling logic based on the result sending a `listConsumerGroups` to each node, and then group and flatten the result so we hide the node information of each sub-map it is belonging to.
nit: use static imports to get rid of `Assert.`
Or is your concern about `commit` throwing an exception? If that is the case, then the `try`/`catch` should just be around that method IMO.
Much appreciated. I probably should have done this when I created the first of these test cases, but thanks for helping to clean things up.
this line can be added to tail of above line
As the whole point of this PR is to provide better messages, I would also check in the test that the exception has the new enhanced message. Something like ```suggestion final Record<String, Integer> record = new Record<>("K", 0, 0L); assertThrows(NullPointerException.class, () -> supplier.get().process(record), String.format("KeyValueMapper can't return null from mapping the record: %s", record)); ```
This call raises an exception, which means the assertions below never get checked and the producer is never closed. It is possible that this leak is causing some of the recent build failures. ``` 00:57:22 Exception: java.lang.OutOfMemoryError thrown from the UncaughtExceptionHandler in thread "kafka-producer-network-thread | producer-20" ```
Have a look into `StreamsConfigTest`, e.g., `shouldSetDefaultBuiltInMetricsVersionIfNoneIsSpecified()`.
> That's correct. I may not have been clear above, but what I meant is that this change won't break compatibility with users currently **_not providing_** a repartition topic name as it will create multiple repartition topics thus keep their topology the same. Does that make sense? Ack. Just wanted to make sure we are on the same page :)
OK, will remove before merging.
nit (optional): Since a variable is used as a shorthand for the return value of this method, maybe a more intuitive name would convey the meaning better. E.g. `hasErrors` makes more obvious it's a boolean (`result` can be anything).
Nit: `late enough version` reads a bit funny. Maybe we can say "Could not validate fetch offsets for partitions {} since the broker does not support the required protocol version (introduced in Kafka 2.3)" or something.
nit: remove `else` here, return null at the end.
nit: move to next line or indent lines below
Well, won't we end up deleting the topics before closing it if we never reach the first `streams.close` ? Or does it not really matter in that case since something has already gone wrong (just curious, I'm fine with it as-is btw)
Similarly for `closeDirty` and `prepareCloseDirty`
Kinda, but it had a TreeMap before, so it used the "natural ordering" of the Strings which means... something. Anyway, are we okay with the fact that the ordering may change according to the person who built the docs? The kafka.apache.org webpage will then show whatever order the site-builder's JVM used? Or is it Jenkins? We don't really have any other choice, other than making everyone use LinkedHashSets, right? And we decided we don't want that.
Since this integer is decremented when `tryUnmuteChannel()` is called, would it be a bit more intuitive to name it `muteRefCount()`? If so, we may want to also rename methods such as `incrementUnmuteRefCount()`, `decrementUnmuteRefCountAndGet()`, `getUnmuteRefCount()` and `incrementChannelUnmuteRefCount()`.
@throws IOException If an I/O error occurs. See {@link FileChannel#read(ByteBuffer, long)} for detailed information on the exception cases.
Seems we're missing the second purpose.
nit: do we need the "" in the end for conversion? I think Java is smart enough without it.
This should go to `announce@apache.org` as well, that's actually the most critical one as that makes it "official".
```suggestion * 5) {@link FetchSnapshotRequestData}: Sent by the follower to the epoch leader in order to fetch a snapshot. * This happens when a FetchResponse includes a snapshot ID due to the follower's log end offset being less * than the leader's log start offset. This API is similar to the Fetch API since the snapshot is stored * as FileRecords, but we use {@link UnalignedRecords} in FetchSnapshotResponse because the records * are not necessarily offset-aligned. ```
Sorry -- mixed it up with `table`.
Please rename to `shouldCloseIterator()`.
@duy @jeyhunkarimov Got it. So I think the question is whether we want to partially solve the "not be able to have finer-grained caching" problem here or just keep it as is and wait for a more focused shot later in another ticket. I think we can argue that it is OK to be "soft" and potentially change it later when we have another mechanism for fine-grained caching. My concern, though, is that by opening the pandora box of allowing users to do caching like this we are not long complicating the internal implementation (which, as we talked, is OK as long as this tech debt can be simplified later), but also about exposing the internal classes like CachingXXStores to public user interfaces, and this box is hard to be closed later. Anyways, my take is that eventually the finer-grained caching support should be added, but not by exposing the CachingXXStores to users.
Seems like we don't need this variable? Same for other similar methods.
Should we produce the input before we start the KS instances? If there is no input, it's clear that Standbys won't restore as there is not data for restoring.
As mentioned above, I think this is the right idea, but shouldn't we just call: ``` java sensors.recordTopicFetchMetrics(entry.getKey(), metric.fetchBytes, metric.fetchRecords); ```
nit: we can just throw a `TopologyException` exception here.
Turns out I was wrong. Since in java all parameters except parameters of primitive types are references, modifications on the state of the objects the parameters point to are visible outside the method (what I meant with side-effects) also if the parameters are declared `final`. With `final` on parameters one can merely avoid modifications of the references stored in the parameters (not the modifications on the state of the object) within the method. I still think that `final` is great and that putting final on parameters makes code a bit better. Just wanted to correct my statement. Sorry for the confusion.
nit (formatting): might be easier to read if we move to new line: ``` log.info( "Could not create topic {}. Topic is probably marked for deletion (number of partitions is unknown).\n" ```
Great catch! Do we have a test for this bug? We should include this fix in 0.11.0.1.
super nit: the string is slightly malformatted. The script displays: Enter reviewers in the format of "name1 <email1>", "name2 <email2>: Also, Its not clear if I should actually type the quotes when entering reviewers.
nit: You've put a `.` at the end of this exception message but not to the others below. I would add it everywhere or remove it here.
You can just do something like `return new ArrayList<String>(Worker.getConnectorPlugins())`. No need to manually copy with a for loop.
```suggestion /** * Metadata of a task. */ ```
There is one place in this PR that we check for null when computing the records size, maybe we can use this utility function there.
This fail just raises an AssertionError from a thread. I'm not sure it will actually cause the test to fail.
Again, lines L#118 to L#123 can be replaced by: ``` assignment.keySet().retainAll(userAssignment); ``` same effect, as we want the intersection of `assignment` and `userAssignment`
I guess we could also get an auth error for the groupId.
This method either throw exception or return true, which indicates there is no need to have a return value.
Just realized I need to do another rebase on my PR. So if this PR is closer to be merged I'd suggest @RichardYuSTUG @mjsax you guys just move forward and I will rebase mine later.
Is this right? I thought it should be `position += limit`.
We can pass the serializers in the constructor and it's a bit more concise.
```suggestion * This will turn off fault-tolerance for the suppression, and will result in data loss in the event of a rebalance. ``` This isn't a "store", but rather a buffer internally used for suppression. Also, it seems appropriate to be a little more dire in our warning here because the internal nature of the buffer may make it less obvious to people what the downside of disabling this changelog is.
The value is that if anybody changes the default value or the allowed values by mistake, maybe during a refactoring, there is a test that shows the mistake. Of course it is not a 100% protection, but at least it won't go totally unnoticed.
`listStore.all()` will return a `KeyValueIterator`, which should be explicitly closed. I think we can re-use the iterator below this line, which is closed at the end.
Actually it looks like it is `synchronized(stateListener)` in `StreamThread`. But even that seems a bit wrong. I think the synchronization would be better to be done in this class rather than elsewhere
Since `StreamsException` ultimately implements the `Serializable` interface, could you add `serialVersionUID` as well as other constructor functions? You can take a look at `TaskAssignmentException.java` for example.
groupId is still here
Maybe we should enforce a minimum version number when querying all partitions? You can look at `ListOffsetRequest` for an example of this.
I believe this is fixed in my next PR.
original was better
nit: rename `errorCode()`
Will do this, ideally before feature freeze, but definitely before code freeze. Stay tuned.
MILLIS => MS to be consistent with other places. Ditto in a few other places.
`.toString()` unnecessary here are other similar logs.
nit: add `final` to both parameters (same below)
nit: remove `throws` declaration (not needed).
I picked up all the non-testing followup work in this PR so we could try to get it into 3.0: https://github.com/apache/kafka/pull/11114
nit: `<p>` not needed because there is no following paragraph
Do we want this to be `poll(0)`? Otherwise we're still blocking here.
This is an existing bug but it looks like we never release (`MemoryPool::release`) if there is an exception before adding to `completed`.
I think we can use `Class.isAssignableFrom` to see what type it is rather than catching the exception. See `ChannelBuilders.createPrincipalBuilder` for a similar use case.
```suggestion * ReadOnlyWindowStore<K, ValueAndTimestamp<V>> localWindowStore = streams.store(queryableStoreName, QueryableStoreTypes.<K, ValueAndTimestamp<V>>timestampedWindowStore()); ```
I dont remember why I did that. Looks like `future.get` would be better.
Should this be retriable? Same question for `FetchSessionIdNotFoundException`.
That is not my point. My point is that the objects that call the constructor, i.e. tasks and threads, have a time object that they use for the their metrics (and probably for other purposes). Now that we also have metrics in the `StreamsProducer` that needs a time object, it is inconsistent to create a new time object in the constructor instead of passing along the time object from tasks and threads into the `StreamProducer`.
Yeah I was not sure if we should do KAFKA-7245 to remove the API as it would be useful for PAPI users.
Tab should be replaced by 4 whitespace characters.
We can use `putIfAbstent()`
Yes, I think we should. And it's not even a diversion from the approach elsewhere because there's a KIP in progress to do so in classes like `SessionWindowedSerializer` as well
1) I think the max.poll.interval.ms is no longer set to `Integer.MAX_VALUE` in 2.3.0 (https://cwiki.apache.org/confluence/display/KAFKA/KIP-442%3A+Return+to+default+max+poll+interval+in+Streams). 2) For `Consumer#commitSync`, the `default.api.timeout.ms` is used if user do not specify the timeout, not the `max.poll.interval.ms`.
nit: I suggest to continue using the stream api here. It keeps the code smaller.
I think this can be replaced with `remainingToSearch.keySet().retainAll(value.partitionsToRetry)`.
Could we collapse the code path for having a queryable store name or not into the same function? For example: ``` filter(.. /*nothing*/) calls filter(.. (String) null); filter(.. "storeName") calls filter(.. storeSupplier); // if storeName is not null, otherwise pass null as well filter(.. supplier) do the actual impl, which checks if supplier is null or not ```
Re (1) if all use cases are single threaded then yes we can allocate some buffer(s) as part of the store. Otherwise, if you need to support multiple concurrent ops then you could pre-populate a queue with a N buffers, and N becomes the maximum number of concurrent requests you can server. If you're queue is empty then a request would have to wait until at least one of the outstanding requests completes and add its buffer to the queue. Again that might all not be needed given the API is single-threaded. Re (2), is there a max-size, maybe given by the maximum Kafka message size that is configured (if such a limit exists and is not too big)? If we don't want to change the API (I guess it would be the RocksDBStore interface that would be changed which is not exposed I think, but still) then splitting this work into part I where we copy heap to direct buffers, and then a part II where we directly serialize into direct buffers is a way to go.
I think truststore and ca could be stored in a single directory. The files are related and are created together.
nit: add `final`
`InterruptedException` is checked, so we can't throw it.
> I think the case you're referring to above is saying that for the out-of-order case, the previous record's right window should already exist -- this line is dealing with the right window of the current record. Ah. I missed this. @lct45: the explanation makes sense. Thx!
nit: rename to `shouldNotClearRecordForPausedPartitions()`
Should we really catch NPE here? It seems like if the user wants to return a non-null mapped key from a null key, then they should handle the null case specifically in their `keyMapper` and not just throw an NPE. In general, an NPE is a sign that something has gone wrong. I would be pretty surprised if I threw an NPE explicitly in my user code and it just got swallowed and interpreted as if I had actually returned null.
It would probably be helpful to include the old constructor. At least I can imagine users having test cases where they construct SinkRecords directly and it would be nice not to break those unnecessarily.
Damian suggest is actually different as it avoid the loops... That would also be fine. But using ArrayList plus for-loops is a mess IMHO.
As you point out, the old log message was: ``` log.info("{} flushing {} outstanding messages for offset commit", this, outstandingMessages.size()); ``` This log message had two things it'd be nice to keep: 1. `this` as the context; and 2. the number of records whose offsets were being committed (e.g., the number of acked records). I think both would be good to include, especially if we're saying the number of records whose offsets are _not_ being committed (yet). The `Pending` class seems pretty useful, but computing the number of acked records is not possible here. WDYT about merging the `SumittedRecords.committableOffsets()` and `pending()` methods, by having the former return an object that contains the offset map _and_ the metadata that can be used for logging? This class would be like `Pending`, though maybe `CommittableOffsets` is a more apt name. Plus, `WorkerSourceTask` would only have one volatile field that is updated atomically.
Nit: `assertThat` take expected result as first parameter IIRC (otherwise error message on failing test is "reversed")
There might be slight performance gain if we just say "Attempt to join group and receive member id required error." instead of passing in the error.
I think this is outdated based on the addition of schemaless support.
How about this? > ... if the commit failed and cannot be retried (e.g. if the consumer has been kicked out of the group). Users should handle this by aborting the transaction.
"Task " + taskId + " could not get partition information for topic " + topic
It's just not great having multiple paths that make the same type of request if possible. But I see why we at least want different handling of this request/response, and there was another JIRA to make this exact change anyway.
I think we should provide some context on the exception here.
Ditto here: use `entrySet()`.
`Not for this PR`: this is getting really messy here... instead of interleaving the suspending and committing logic, we should just do one loop over ALL tasks gathering their offsets, and then do another loop over the tasks from `revokedPartitions` doing a suspend.
This line is too long. We need the linebreaks back here
The issue with using a real file is that you can't test the scenario that we are trying to fix: `FileChannel.read` returns before the buffer is full. See `FileRecordsTest.testTruncateNotCalledIfSizeIsBiggerThanTargetSize` for an example of a mocked fine channel.
appending `KTable` source operators with `-table-source` is not in the KIP, so we'll either need to remove this or update the KIP
Here too, if the one above changes.
Yes, it should be safe to convert to bytes and compare using MessageDigest.isEqual since SASL/PLAIN uses UTF8. Means more object creation, but that shouldn't be an issue. Utils.isEqual() may be worth adding if we think we may use it in other places as well in future for constant time array comparisons (in which case, we can make it generic).
A helper for `awaitReady` might be useful as well. Might be a chance to consolidate the `awaitLeastLoadedNodeReady` path.
nit: conifg -> config (applies elsewhere too)
Typo: > or use the default RocksDB backend[] by providing ...
I don't think priority HIGH is a good choice for this. I guess, using broker default setting is good enough. MEDIUM (ie, "please double check"), might be better IMHO. Nit: can you pleas add this in alphabetical order (with whatever level we use).
I suspect the tests didn't catch this because we would still transition out of ERROR to PENDING_SHUTDOWN and finally NOT_RUNNING in this case. But really, we shouldn't transition to ERROR in the first place
I'm +1 on supporting the timestamps, even if it's not commonly used now, users will often look to tests for example usage (at least I do). I'm also +1 on removing `childIndex` for the same reason, but I don't have too strong an opinion on that.
We can simplify it to `stream().peek(throw).to()` without materializing a store.
I think these should all be `IllegalArgumentException`. The producer is not in an illegal state.
nit: `was` -> `were` (also below)
nit: add `final`
Can you please test with Java 11 or newer? Looks like you tested with Java 8 which uses the slower crc32c method.
This method tests multiple things at once and thus should be split into multiple methods. Also, use self describing names for the methods. For example for the first test: `shouldWrapUserSerdeFromConfig()` or similar.
I personally prefer consistent naming, ie, both `hop` or both `advance`.
We should add doc string that "for properties user specify both with and without the prefix, the one with the prefix will be used, only for BOOTSTRAP_SERVERS_CONFIG it will ignore the prefixed one but always try to use the non-prefixed one, since currently KS is only supporting to read / write from the same Kafka cluster", etc.
I'm not 100% sure if this should be `max` or `min`.
In unusedProperties(), we probably want to use the originals variable instead of the originals() method since we don't want to record those properties as used there.
I don't think we should add these configs to the public interface. Developers can already add Consumer & Producer Configs to the StreamsConfig - they both have all of the configs defined here and we should just use those. For example have a look at `StreamsConfig.getProducerConfigs(...)`
nit: since this is mostly indicating exit from the method, I think it can be trace level too.
I don't think `FileRecords` and `MemoryRecords` instances can be compared directly, if that's what the question is about.
Also, we should handle all errors as well so that when constructing the result we know it's successful and hence we do not need to set any errors below.
for headers, we need to do the same as for `recordValue` ? (I think you c&p from `compareValueTimestamp` -- there it's different because timestamp is a `long` and cannot be `null`.
The reason that we want to remove the shutting down replicas from ISR is to optimize for latency. If we don't do that, when the broker actually shuts down, it can block the producer for replica.max.ms before the replica can be taken out of ISR. So, I think this optimization is still useful.
Should we include the config source instead for compatibility? Also, just double-checking that it is intentional to leave the synonyms out of `equals`.
I think you are correct, we probably could carry on with the rebalance. We'd need to keep track of any active tasks that fail during suspension and remove them from the `prevActiveTasks` set that is updated in `removeStreamsTasks` For standby tasks we'd need to remove the state directory as that is what is used to determine if a thread has any cachedTasks. Alternatively we could change it such that we keep track of the previous standby tasks in a similar way to how we do active tasks.
I think I'd configure this right after creating the callback handler instead of in this method.
@agavra I don't think these should be public API.
While I think it would be fine, it would be "new" -- if we think `instance` is better, we might want to migrate all other code lazily to use `instance`, too. It's always best to have the same naming conventions throughout the whole codebase IMHO.
Can we use `UnsupportedVersionException`? The record is valid, it is just that the produce request version doesn't support it.
Okay. We do similar synchronization for `append`. The `LeaderState` has an `epoch` and it is final. The part that may be tricky to implement is the `epoch < currentEpoch` case.
`Arrays.asList` could be replaced with `Collections.singletonList`
`instanceof` checks for `null` too. I wonder if it's better to combine these two cases to say that we expect a list with at least one value (meaning a non-empty list).
This seems to defeat the purpose... If we really want to skip this test in this environment, we should rather put it in the beginning and do ``` if (isUnix) { return; } ```
I think that if you were to actually pass in a map here and then assert you get the same map back from `logConfig()`, it would be enough test coverage.
Can we just inline `doFlatTransform` now? There's no need to have 3 layers of indirection to build these processors.
Yes, it a bug in the current implementation...
What do you mean checking again? This is just checking the `ConfigDef` returned by the connector (which was only called on the previous line) and this method is called from places that wouldn't have already validated it.
ack. would probably be good to verify the minimal diff to rename back after we're confident of the current patch (and might reveal more info), but this isn't all that big a deal if it changes, just makes it a bit inconsistent.
Perhaps an exception would be better than an empty set since this would be unintentional? Otherwise the check itself is unnecessary since the following code would do the same thing.
I remember some of the metrics were lazily registered, i.e. they would only be registered if the corresponding action is called for the first time. Have we refactored it to always register all metrics up starting the task / process-node etc? Otherwise waiting for the stream state to transit to RUNNING may not guarantee all metrics should be already registered.
The convention (even though not enforced by checkstyle) is for `parent.checkForest(sensors);` to go in the next line for the Java code.
Probably fine currently given max number of retries we specify, but would really be preferable to do this iteratively (which also doesn't require copying/mgmt of kwargs like this).
Do we need `sleep` here and is it even sufficient to ensure we get the right behavior? I figure something like changing the format, then making sure at least one new message is produced + consumed would be the necessary and sufficient condition for proceeding to the subsequent change.
@sdreynolds I would suggest we use my suggestion since it addresses the problem with the relative time adjustments. It could also happen that `now` somehow gets far ahead of `nextCommit`. In this case, we we do not want a flurry of useless offset commits in order for `nextCommit` to catch back up. It seems simpler to reset the offset commit interval.
nit: avoid unnecessary `this.` prefix
I understand why. But other contributors might not (and I might forget why in the future and want to change it...). It's not obvious from the code and thus should be explained with a commend, IMHO.
It's a warning you can enable in IntelliJ IDEA. Not a huge deal.
I feel this optimization is not necessarily since calling `ByteArraySerializer.serialize()` does not introduce much overhead, but requires other instantiations of this class to override two functions.
That's fine. There are cases that you might want to invert the answer that says "I can't say". But we haven't finalized the design, that's why this helper method hasn't found its way to the base class yet. Still the goal will be to provide generic methods. As a reference, here's an example of negation of the above with `orElse(true)`: https://github.com/apache/kafka/blob/trunk/connect/runtime/src/test/java/org/apache/kafka/connect/integration/RebalanceSourceConnectorsIntegrationTest.java#L227 It's fine to simplify here. We can change if we ever generalize this checks.
How about ``` for (byte b : payload) { assertNotEquals(0, b); } ```
nit: should we add a new method that takes this additional parameter so we don't modify the existing calls.
same for tests below as well
If we let this take a set of connector names, we could test them all at once.
nit: add `final`
OFFSET_FOR_LEADER_EPOCH_RESPONSE is an inter broker request. So, we shouldn't add a throttle field.
nit: naming topicPartitions as topicPartitionsToClear would make the code more readable
Thanks, that makes sense. However, I think there may still be a problem. Any unsent requests will be targeted to the current coordinator at the time of `close()`. Discovering a new coordinator in the loop below won't help us unless we can retarget those unsent requests. What's more, we have logic in `AbstractCoordinator.coordinatorDead` to explicitly fail unsent requests to the coordinator.
As you would expect, Kafka has both forms. It does seem to favour the `Create` form more when looking at `KafkaConsumer` and `KafkaProducer`. It's a bit sad because we are unlikely to ever achieve consistency by choosing something different from the Java style guide (contributors will invariably use the Java recommended style and it's hard to spot all of these during code review).
@mjsax With the recent changes on IntegrationTestUtils, `waitUntilXXX` will use one consumer instance only so I'm wondering if it could still return more than expected results. Also for the mock time issue, could we eliminate the non-determinism by not using `System.currentTimeMillis`? We can augment the `MockTime` to set manual initialization values if necessary.
Worth explaining how the channel builder is closed now.
This should be done in the SSL class. The base class should not be aware of SSL and just use configurations from the concrete classes
Avoid reformatting in classed that do not have any change (please revert those classes).
Note that `Hashtable` uses 11 (a prime number) as the default.
nit: "Start restoring..."
nit: I don't think we should bother checking the string messages as it is quite brittle. The important thing is that the exception is thrown
I think my concern was invalid to begin with but your refactoring is certainly an improvement. LGTM ð
@llowrey : In the interest of time, @ijuma helped produce a new patch in https://github.com/apache/kafka/pull/1094. It would be great if you can verify if it fixes the problem. We will make sure that you get the acknowledgement when we commit the patch.
This field should be named live_leaders.
The above suggestion would also us to avoid having to pass the `requestVersion` down here.
Should be "threadsPerWorker"
I think both tables at line 319 and line 321 are materialized anyways even without the `Materialized` object: for 319, the `groupBy` operator would cause its parent to be materialized.
Yes, reading can be done from multiple threads. `volatile` would probably be enough for this use case.
Even if you are in 2.4+, if you want to switch from EAGER to a different COOPERATIVE assignor that new assignor still need to support both in order for a simple rolling bounce path. I think it worth mentioning this as well (maybe better in web docs than here in java docs, just wanted to bring this up).
I'm not sure we want to throw the static exception since we won't get a stack trace (at least currently).
FYI: Mine produces the same as John's
I considered this approach as well, but I think we can just drastically simplify this. I'm not sure there was originally a great reason for checking the base config, then connector config. I think this was an artifact of the two parts being split up originally (before we even had enrichment for transformations). We still need 2 parts since the connector may do additional validation, but we should only need to get everything we need together for the framework-level validation into one ConfigDef and then `validateBasicConnectorConfig` on that. I think a better approach might be to just make it easy to get the `SourceConnectorConfig.configDef()` and `SinkConnectorConfig.configDef()`, i.e. just make those public. Then you never need to instantiate the ConnectorConfig directly here. Instead, you use `ConnectorConfig.enrich()` on the `Source/SinkConnectorConfig.configDef()` as the baseConfigDef with the `requireFullConfig` parameter as `false`. In this way, this config never needs to instantiate the `ConnectorConfig` classes and you can leave their constructors as is. I think this has some other nice benefits, including that we don't *have* to skip the connector-specific validation even if there are errors during the basic validation. I'm not sure we want to make that change, but it would mean that even if you have a validation error (e.g. you are missing a connector name), you can still get connector-specific fields back in the result, which seems like a good thing to me since you'd still want to know about those fields as long as you had entered the `connector.class` correctly.
Reading the code details here, I think the `materialized` is not necessarily related to the `statefulRepartitionNodeBuilder`: it is only for materializing the resulted KTable, and hence should be only related to an `TableProcessorNode`. The fact that it is extending `RepartitionNode` which in turn extends `StatelessProcessorNode` actually points out the issue: it has a materialized `state` but is under the category of `stateless processor`.
How about moving the buffer allocation to `appendControlMessage`? Not sure we need different messages in the exception since we will have different stacktraces.
This only needs to be set when we first create the `OffsetCommitRequestTopic`, right? So it can be set inside the `getOrDefault` block.
nit: `is add` -> `is added`
I think we only use a wrapped WindowedStreamPartitioner if keySerializer is not null and is instance of WindowedSerializer? Otherwise we just rely on the DefaultPartitioner.
This is a good find. What happens if the metadata request itself is queued up to be sent to a node which is no longer online? Will it be stuck in `callsToSend` until it times out? I am wondering if we should check `NetworkClient.connectionFailed` after every poll() for all requests in `callsToSend` and reenqueue them as we are doing here. This is what we do in `ConsumerNetworkClient`.
nit: I'd suggest we just inline this function inside `StreamTask` since 1) this is only triggered with EOS enabled, and its name `deleteCheckPointFile` maybe a bit misleading, and 2) it is a very simply function anyways.
This is a validation failure (e.g. admin client validateOnly request), sobetter to say `validation failed`.
You should also include UnknownServerException here, which indicates an internal problem on the server side.
Also I think by just checking that 1->A and 1->B are there we do not guarantee there's no duplicates due to re-processing right? I think we should check that the offset on the input topic can be committed and also there's no duplicates in the output.
I think we can avoid this pattern if we refactor `parseVoterConnections` to use a new method called `parseVoterConnection` that knows how to convert a `String` to a `Node`.
I've noticed there's only a single rebalance, and we need at least 3. maybe set ` streamsConfiguration.put(ConsumerConfig.SESSION_TIMEOUT_MS_CONFIG, 1000); streamsConfiguration.put(ConsumerConfig.HEARTBEAT_INTERVAL_MS_CONFIG, 500);` or similar
ditto on removing before/after.
nit: method can be `private`
It's customary to use `Objects.requireNonNull(topicPartitions)`. Otherwise LGTM assuming all tests pass.
Harsha removed the check.
nit: I think we can remove `synchronized` here as well
The check itself (ie, for `isEmpty()` makes sense) but I would still try to avoid the `null`
Indeed, we could. I am not sure that it brings much more information though so I am fine with keeping it as it is.
In version 0, we should only allow passing in a single BrokerEndPoint.
Nit: single parameter per line formatting (same below)
I thought so, but wasn't excited with the grouping and it's not a long line anyways.
A ha, you're right! We only need the distinct count values. No need to refactor it then. Thanks for the explanation.
Idk, the current defaults make sense to me. If a user has a custom store and wants to use the new `backwardFetchAll` with both longs and Instants, all they'd have to do is override the long-based `backwardFetchAll` method (they have to implement the long version no matter what, since this is what gets used internally to Streams). If we just throw UnsupportedOperationException directly from the default implementation of the Instant-based `backwardFetchAll`, then they would have to override that as well in their custom store. So we should just let the Instant default to the long method so users only have to implement one method instead of two (plus they would have to do the Instant validation themselves, etc)
Ack. Thanks for the details.
Similar to the above, seeing a message that says `read` might be easier to read in context than `consumed`. How about: `Behind end offset {} for {}; last-read offset is {}`
I think this would never happen now since the passed in `recordPerTopicPerPartition` is always initialized.
The default ZK session timeout and ZK connection timeout are both 18 secs. So we can just change both to 18secs here.
Hmm, this pattern is a bit weird. As @guozhangwang initially said, it's as likely to introduce issues than fix issues. `closeStateManager` should just do the right thing. If we need to change the `catch` blocks, we should do it there.
So in my updated PR I change this line to line up with CompletableFuture.
original was better (ie. `{}`) maybe one parameter per line
Hmm.. should we enforce `partitions` to be not null actually? @hachikuji
I think this should probably be an `info` or `warn`.
Current code doesn't follow this. It's of course a matter of taste (as always). I think it makes sense as it makes diffs easier to read on Github if a parameter gets added/removed. Thus, going forward, I would prefer this formatting (and we should reformat "old" code incrementally -- similar to `final`). Btw: I added this rule to the new coding guidelines on the Kafka webpage. If we don't want the rule, we should remove it. Also, the guideline says 120 chars at max length. I am fine with 100, too, if there is a strong opinion on this.
nit ```suggestion public EagerBufferConfigImpl(final long maxRecords, final long maxBytes, final Map<String, String> logConfig) { ```
`out-of-order` (this may be a typo on other places, too) Can you fix everywhere? `window end` -> `window closed` (same -- please also fix elsewhere)
I see. That makes sense. I run into the same issue and put a workaround in #4636 -- we should clean this up, after we put proper testing for older versions into place as discussed in #4636.
FWIW, I'd rather just inline it and avoid maintaining APIs that are just for tests in our production code.
Since the is specific to v2+, the constructor used doesn't even really need the `responseData` parameter -- if there was a top-level error it seems there will never be response data so we can just use a dummy empty list in `OffsetFetchResponse`.
Could you create a JIRA to keep track of this task: after java7 is dropped, we can add them as static functions for the `StreamsMetrics` interface itself (this is only supported in java8), and then also fix `ProcessorNode` and `StreamTask` to get rid of hard cast of `impl` classes.
nit: extra line
Do we actually need two fields? From looking at the code, it wasn't clear to me.
This is using the "try-with-resources statement" so it will take care of the close.
We should probably use the producer's max block time instead of the request timeout.
Can be final
The rest of the exceptions are listed as "suppressed by" the exception we're throwing.
According to the result of CPU reduction, the skip operation does not reduce data decompression, but it reduces CPU consumption. Is a large amount of CPU consumption in the GC pressureï¼ @ijuma
I am not sure about the additional sentence. It's not quite accurate since it depends on the size of the active log segment.
Well, `getCacheSizePerThread` would eventually return zero (with growing number of threads), what means that every put() into the cache would result in an immediate eviction. So I don't think we need to do anything for this corner case.
We could probably use `ByteBufferOutputStream` which already handles expansion.
Since this is usually the entry point where users would call `toString`, the indent is used for wrapping it. For example, `toString()` prints ``` Kafka Streams Thread Tasks Topology States ``` `toString(">")` prints ``` >Kafka Streams > Thread > Tasks > Topology > States ``` We do not need to let users override the internal ones, only the entry point of nested prints.
I think in general we shouldn't call this `toString`. People would confuse it for the actual `toString` method and would suppose the same or similar behavior. For instance `toString` methods aren't expected to throw exceptions. So in my opinion we should call this something like `readAll` or `readAllBytes`.
why bother with this? `NodeFactory` is private in `TopologyBuilder` so it is not going to be anything else. Plus it wouldn't matter if we used the interface rather than `instanceof`
Should be something like: ``` assertThat("KafkaStreams did not transit to RUNNING state within " + timeoutMs + " milli seconds.", countDownLatch.await(timeoutMs, TimeUnit.MILLISECONDS)); ```
I'd be in favor of either just adding the new method to the list (without removing another one) or deleting this whole list. Personally, I feel the list is a little redundant with this interface itself.
I think this is a throwback from before rebasing against https://github.com/apache/kafka/pull/1778/files#diff-10752971682d4575c93ddec45e0553f0L755 We shouldn't need to catch any exception here.
Shouldn't this be a config exception? It is not really invalid partitions.
In this test we would have multiple punctuator indeed but they would be executed by a single thread sequentially so that's fine.
Does the heavy-handed locking with `synchronized` rather than implementing the multithreaded loading with finer-grained locking have some motivation here? It's protected API, but URLClassLoader already has some fine-grained locking via ClassLoader's `getClassLoadingLock(name)`. I'm mainly curious because this approach is actually different from what is recommended in the "Recommendations for Multithreaded Custom Class Loaders" of the doc you linked. It seems like it should work, but disables multithreaded gains added in JDK7. The implementation used in `ClassLoader` seems to just allocate a lock object per `name` which is pretty easy to just copy even if we end up using different lock objects here than in `ClassLoader`.
just be wary that this entire loop capturing state is a bit dangerous. of course you don't expect it to happen, but it's possible there is a rebalance (unintentionally due to timeouts) and you get some inconsistent set of results wrt connector state/location. at a bare minimum, tons of repeated tests locally and many repeated tests on jenkins would be warranted here to avoid any potential flakiness, especially given AK jenkins' penchant for unexpected timing issues.
Nit: we don't need the `<p>` tag because there is only one paragraph.
The only case I can think of that might have high concurrency on RocksDB state store is with interactive queries. Without interactive queries there is no concurrency on the state stores since only the stream thread that has assigned the stateful task owning the state store accesses the state store.
+1 for `getSimpleName` for the class. In addition to the David's suggestion, I think we should also remove the 2nd `due to`, because there is already 1 `due to` in the sentence. ex: `rebalance failed: '$message' ($class)`
nit: `partitionTimeMap` -> `partitionTimes`
Rather than doing `if(nodeFactory instanceof blah)` could we add an abstract method `ToplogoyDescription.Node describe(...)` to `NodeFactory` and then implement it in the subclasses. My skin crawls when i see `instanceof` :-)
I actually think neither of these supressions are necessary here. You mentioned before that you'd make a pass and remove the "unchecked" supressions. While you're doing that, can you re-evaluate other supressions that are currently in the code? I think it might be a good practice to remove supressions when possible.
Thanks for adding coverage for sliding windows.
For one thing, it's nice for _us_, so we can easily tell when it's been deprecated "long enough" to remove. I can recall trudging through git history in the past to figure this out. For users, maybe you don't care, but I personally find it nice when my libraries do this for me. It's just good bookkeeping, and it gives me some confidence that the maintainers are doing proper, tidy maintenance. If it provides a "third party" supporting opinion, the Scala language designers thought this was important enough to build it in as a separate field of the "deprecated" annotation: https://docs.scala-lang.org/tour/annotations.html
please remove this change (unnecessary Indent)
Perhaps: `With the COOPERATIVE protocol, owned partitions cannot be reassigned...`
Is this necessary? my IDE says it is redundant.
can we just return here to make it clear that we are baling out? We then don't need the further `if(!initializable.isEmpty())` checks below
I don't see how wrong usage elsewhere inspires wrong usage here. Despite that, I still prefer `Applying transformation` since this log message is not a paragraph in a text where we need to be precise and need to list the acronym explicitly along with what it means. This is a log message that needs to be succinct and can be read in context. A transformation here implies a connect SMT.
A test is missing for a global stream thread that calls the uncaught exception handler.
Yeah. I think it's good given it's a variable - we sort of expect it to be set I guess. It would be really cool if Java supported having `final abstract` variables
nit: `the normal-consumer.poll` -> `main consumer#poll()`
Still not sure about the name since this already includes more than just `cipher`. But since it is an internal class, it should be ok to leave it as is for now.
Should we use `result` here instead of `numWriteTries`? If not, maybe we can change generateBatch() to return a boolean instead
Hmmm... Not sure. The "it might change in the future" argument is valuable. What do others think? Splitting seems to be the save option. \cc @enothereska @bbejeck @dguy @guozhangwang
```suggestion log.warn("The eager rebalancing protocol is deprecated and will stop being supported in a future release. " + "Please be prepared to remove the 'upgrade.from' config soon."); ```
indent is not aligned with above lines.
nit: if you use a local variable for `lastSequence`, then you can also use it in the log message below.
nit: add `final`
IMHO, we should always get the exception and assert on the error message (otherwise, it exception might be throw because of. different reason the the test does not test what it is support to test -- we have seen this issue in the past).
we can use `TestUtils.assertFutureThrows()` here too
This is an inter-broker request as well and clusterAction should be true.
Yes, I had the same thought as @guozhangwang, but I am also not familiar with direct buffers.
nit: there is not "partition stream time" -- there is "stream time" and "partition time" :)
nit: Would it be clearer to initialize this to `time.milliseconds() + CLOSE_TIMEOUT_MS` and avoid the sentinel check? It doesn't seem too worthwhile to avoid the system call.
If this already exists, we should check to see if it's equal to the new information we wanted to register. If it is, we can skip the decrement metric + increment metric dance.
It probably makes sense to wait a short time, but not very long, to send the request to the broker. I'm not sure how that interacts with the rest of the client close logic
We probably also want to close the last batch for append in line 279.
Lines 45 and 46 should use the static constants in this class for the name of the topics: `TOPICS_REGEX_CONFIG ` rather than `SinkTask.TOPICS_REGEX_CONFIG`, and `TOPICS_CONFIG` rather than `SinkTask. TOPICS_CONFIG`.
Similarly here, would it make sense to integrate that check into keyBytes? I think there are similar cases in other stores.
nit: `aggregated` -> `aggregate`
Might want to emphasize "the policy configured on the broker"
nit: parameters on a separate line
Nit: ```suggestion log.warn("Executing {} only once, since retryBackoffMs={} is larger than total timeoutMs={}", descriptionStr, retryBackoffMs, timeoutMs); ```
```suggestion final MemberToRemove memberToRemove = new MemberToRemove(groupInstanceID.get()); ```
Is it more convienent to pass in the `log` object from AbstractTask to the PartitionGroup constructor? It is created with the logContext including the task-type / task-id.
I see. I did not make the connection to the other discussion. I think we can leave as-is.
```suggestion final Bytes toBytes = Bytes.wrap(to.getBytes()); ``` Please also check other occurrences of this additional space.
consumer is unused.
Yes, it probably doesn't make a big difference and it happens rarely. So, we could just keep the logic in this PR.
nit: "Only one source node with regex subscription pattern can be defined in the topology, and there is an existing pattern: {}". EDIT: actually, could we union multiple patterns with `[pattern1] [pattern2] ..`? https://docs.oracle.com/javase/7/docs/api/java/util/regex/Pattern.html Note that if we do this, we need to deserialize data differently based on which sub-patterns its topic name matches to.
The parameter names need to be updated.
While we're making this timestamp change, we should also add a docstring to `WallclockTimestampExtractor`, explaining that, if my understanding is correct, it yields processing-time semantics (= time when records are being consumed/processed).
ok - i see what you are saying. That probably feeds into another issue, though. I know we don't support it now, but the global caching on/off switch is probably too coarse grained. I think we should be able to decide on a per store basis if we want it to be cached or not. I think this has already been asked for by at least a couple of people.
Same question here about just using a static ConfigDef instead of a static method.
This doesn't seem accurate -- this class no longer provides logging, it seems like maybe this has moved to `InMemoryKeyValueLoggedStore`.
That looks correct to me with the clarification that "in response to a request" has two cases: 1. The leader handles a fetch request. This implementation calls "update high watermark 2. The follower handle a fetch response. This implementation calls "update high watermark" I think that `pollListeners` should only fire a `Listener::handleCommit` for new listeners in `pendingListeners`.
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
Hmm...I'm a little less sure about this, but I think we should make sure that WrappingStoreProvider's view of the stream thread storeProviders also stays up to date when threads are added/removed. Basically if a user calls KafkaStreams.store() then adds/removes a bunch of threads without refreshing the store provider, any subsequent get() on that provider would only see the threads that existed at the time KAfkaStreams.store() was called if we make a copy like this. We should be able to just modify the WrappingStoreProvider constructor/local field to be a Set or even a Collection instead, since all it ever does is loop over this. Then we can just pass in storeProviders.values() and it's all good
I'm fine with these as is, but you could also change the methods to be `static` in `Worker` and accept the `WorkerConfig` as a parameter since that's the only class member they use. Would get rid of all the distracting mocks and expect calls and focus the tests on the key functionality of those methods.
Ah right, I think then it is not blocked on anything (the KIP was semi-orthogonal to this).
Hm, kind of annoying that we have to return Properties here, but (as far as I know) there is no way to make an immutable Properties
`repartitionTopicName` and `repartitionTopic` is a bit confusing. I'd suggest just keeping the `GroupedInternal` as a field to replace key/valueSerde and `repartitionTopicName` in the constructor and retrieve its fields later. Ditto for other internal class's constructors (you already replaced serdes with the object in some classes, just trying to suggest consistency here).
Clear as crystal ï¼ï¼
nit: remove `this` if not required (code style)
It seems like we don't need to mention 0.11 here since the requirement for 2.5 is stricter.
The `SinkConnectorConfig` class isn't part of the public API; we can modify it without a KIP if we want.
Interesting design. If I'm understanding the code correctly, the get() returns a future that only gets triggered when you've reached the end of the topic. It copies the offsets out for the desired key, and returns them. So that "guarantees" that you have seen all messages in the topic, including any that might have been in-flight when the caller called get(). Is that right? It's not a complete guarantee though, right? There might have been some messages stuck a producer's retry loop somewhere. Or, messages that have been written to the master but not all the in-sync replicas yet.
Assuming we do not need eosUpgradeModeEnabled, I'd suggest not using multiple booleans to specify a single state as it is more error prone. Instead we can just have enum if we have to.
I guess this method no longer throws at all? (also applies to close)
It seems not possible in Java
nit: this is not introduced in this patch, but it'd better to add the log prefix as other logging entries do.
What about: > Demonstrates how to perform a join between a KStream and a KTable, i.e. an example of a stateful computation. > In this example, we join a stream of pageviews (aka clickstreams) with a user profile table to compute the number of pageviews per user region. I think, for all these examples, it is less important to summarize what exactly the example is doing ("we join pageview stream with a user table to achieve XYZ") but which techniques we're demonstrating ("how to join kstream with ktable"). Users will rarely look for how to compute pageviews by regions, but they will surely want to see how they can join "their" KStream instances with "their" KTables.
We do expect RemoteStorageManager to have strong consistency on the data. We only relax the requirements on metadata consistency. So, it would be useful to make this clear.
nit: I think it is not necessary to break to multiple lines.
Seems like this could be made `final`.
`topics created with the through() method` as above
Yeah, our attitude towards IllegalStateException has been pretty cavalier thus far, and it's one of the main things I'm concerned about with the REPLACE thread functionality. We should definitely be on the lookout for possible IllegalStateException occurrences in the codebase and try to triage them so things aren't just completely screwed up if Streams is allowed to continue after hitting one
Nit: Can you insert this method further down -- we want to order method overloads with regard to number of parameters -- it simplifies to keep track of what overloads are there.
Hmm, doesn't seem like this is correct. >version ['1', '0', '0-SNAPSHOT'] major_minor ['1', '0'] Extracting ['tar', 'xf', '/Users/ijuma/src/kafka/core/build/distributions/kafka_2.11-1.0.0-SNAPSHOT-site-docs.tgz', '--strip-components', '1'] Traceback (most recent call last): File "./release.py", line 235, in <module> command_stage_docs() File "./release.py", line 227, in command_stage_docs cmd('Extracting ', 'tar xf %s --strip-components 1' % docs_tar, cwd=os.path.join(kafka_site_repo_path, docs_version(version))) File "./release.py", line 108, in cmd output = subprocess.check_output(cmd, *args, stderr=subprocess.STDOUT, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 566, in check_output process = Popen(stdout=PIPE, *popenargs, **kwargs) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 710, in __init__ errread, errwrite) File "/System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/subprocess.py", line 1335, in _execute_child raise child_exception OSError: [Errno 2] No such file or directory: '/Users/ijuma/src/kafka/../kafka-site/10'
We prefer to use `assertThat()`: ```suggestion assertThat(throwable.getMessage(), is(...); ```
The identity function could pass this test, but wouldn't have the behavior we need in the BasicAuthSecurityRestExtension. I wonder if there's a way to confirm that the mockConfiguration has been evaluated prior to calling `get()` on the returned supplier.
We don't use TopicAuthorizationException in listTopics
Nit: this is actually a timestamp column with a null value, and it might be worth calling that out here. ```suggestion "null_timestamp_to_int32:int32" ```
Since the code and enum id coincide exactly, is it worth having this map? Maybe we can add it later, if needed and simply look for it in the `values()` array.
nit: fix indention (similar below)
This is a little hard to read. A vanilla `if` statement may be better: ``` if (connectorName != null) { assertTrue(context.startsWith("[" + connectorName)); } ```
This would be a side-effect in an otherwise pure function.
I don't think we need this because we always compile against the current version. The runtime error won't happen unless `shouldPrintMetrics` is true.
I think we may not need this, just the other method, but it would be good to verify. Similar for other classes.
this doesn't seem right -- the JIRA suggests that the group should be a section header for all config keys with that group
Not sure what EE is here.
This might count in the micro-optimization category, but if there are no interceptors (which will probably be a majority of the time), maybe it would be better to store null and skip the interceptor invocation? This is less of a concern for the consumer since records are handled in batches, but the producer interceptor is called on each record pushed.
I think now I understand the reason that part of the partitions can be removed here. If a task is indeed being removed, it should be triggered in the TaskManager#onAssignment; here TaskManager#onRevocation is triggered after the previous call so the tasks map should have been updated --- i.e. the task would not be inside task-manager anymore, and if it is due to regex pattern (like this test) the current condition is okay: we should not suspend the task unless all its input-partitions are included. Otherwise, we can just update the input partition of that task --- right now it is final so we cannot update it, but I think thatâs fine since we would no longer pipe any records to that task and there will be no committed offsets for that partition either --- in either case, we can remove it from the remainingPartitions.
Might be nice to have an overload which sets only `groupId`.
Ah right, we only create the metrics object in this mock processor context, and in practice metrics is closed following another path. Thanks for the explanation.
This method name is a bit confusing since `Empty` here refers to a `LeaderAndEpoch` with `noNode`. Could we use `currentLeader` everywhere and remove this method? It's a bit difficult to reason about with both of them present.
nit: missing . at end
nit: We could omit `res` and return directly in the two places below.
We should check the keys too in every case in this test.
It seems we don't need the `deliveryTimeoutMs` in the sender. It is only used as an argument passed to the accumulator. But the accumulator already has the config.
Should this be `num_lines=2` (cf. L121)
In general, we should rely on default IMHO. And as you set `ack=all` it seems you care about reliable data delivery, so setting `retries=0` seems to contradict it somewhat.
I was not sure. It seems like having a generation=-1 doesn't cause any spoilers here, but I'm always suspicious when sentinels get mixed into the code. One way to force ourselves to be honest would be to use `Optional<Integer>`. Maybe it's good enough if we just have a good test case.
This caching logic might work if the leader does not change. But I have the impression that it is possible to end up in the same problem when the leader changes. Because as far as I see, the new leader will not have build up its cache. (or even worse has an outdated cache from a previous time it was leader) Which I think can still cause troubles. I see two other possible solutions: - The easiest one to implement I think is keep the previous code, but change the type of the `currentAssignment` parameter from a `Map<String, List<TopicPartition>>` to a `Map<TopicPartition, String>`, or keep the type but do a post-processing step on this list where double TopicPartitions are removed before doing the `sortPartitions`. - Another possibility is putting a generation counter in the schema, and only keep assignments with the maximum generation counter. (or those where it is still missing for backwards compatibility). The first possible solutions is easy to implement but makes it a little less sticky. (which I do not mind) The second solution is more sound, but implementing it in a backwards compatible way is a challenge.
```suggestion * @deprecated Since 3.0.0; use {@link MockProcessorContext#setRecordTimestamp(long)} instead. ```
SG, thanks for the explanation!
Does it make sense to move this check above a little bit? ```java if (offsetAndMetadata != null && subscriptions.isAssigned(tp)) { ``` That will make the log message less confusing.
This part is a little mysterious to me. We return an error, but the topic is created anyway? That seems surprising.
@dongjinleekr Could you please take a look at this ```throws```? It was added by your PR (https://github.com/apache/kafka/pull/7083).
nit: `final` is redundant for `private` methods
nit: as in `position` below, `this` is not required
Should we use the private static constructor in this class? Ditto below.
wrong class name
Sorry, out of KIP scope... never mind.
// and if auto-commit disable or the coordinatorUnknown is true, the future will be // the asynchronous commit operation will not do. --> // null future means no offset commit request sent, so it is still considered completed
Why not leaf the code "as-is" and change this line to: ``` if (suspended.values().contains(task)) { task.closeSuspended(clean, false, firstException); } else { task.close(clean, false); } ```
Kind of annoying that the response doesn't give us an instance of `Errors` directly.
The Kafka project tends not to prefix accessors with `get`: ```suggestion public int handleSnapshotCalls() { ```
If we would have written `throws Exception` from the beginning on, this change would not be necessary... (Just to back up my preferred coding stile to only use `throws Exception` in tests.)
Either way works for me. Now I'm thinking about why the Selector metrics had the "node-" prefix. Maybe it's only because the node ids were simple integers before.
nit: These are the same descriptions as above. How about creating a static `Field` instances or at least extracting the message.
Instead of this, I think people should just use a separate method to iterate the simplified version.
This gets initialized during the rebalance and IQ isn't available until Streams has reached RUNNING.
It took me a second to get this -- can we explicitly check `if startTime == timestamp + 1` instead of falling back to `else` and implicitly relying on the fetch bounds? You can just get rid of the `else` altogether or throw an IllegalStateException if none of the specific conditions are met and the else is reached, whatever makes sense to you
During a rebalance, we should delete all entries for partitions we don't own any longer. Should we also pre-populate this map when we init a task (cf `StreamsTask#initializeMetadata()`)
redundant log message. `readEndOffsets(Set<TopicPartition>)` has similar log.
Should the second sentence be "Will find new coordinator and retry"? That seems to be what we use everywhere else.
Maybe we can also add sth. like `possibly because an older versioned client is used to send input topic messages to Kafka that do not have timestamps encoded` ..
(and similarly move the `lastCommitMs = now` to after `maybeCommit` returns)
Can you point out where it would fail? Unclear to me atm.
Nit: somehow I don't like `blah`. Otherwise LGTM
Nice explanation! + 1 to reset to `Long.MAX_VALUE`
ah right, `lastUpdateMs` will make sure that bucket would be full on the first `record()`.
I don't know of any, but I haven't checked. I thought it might be straightforward to add one, but it's up to you.
This is a no op.
The JIT can easily inline this method, so it doesn't actually do anything. The BlackHole implementation in JMH is a lot more complex: http://hg.openjdk.java.net/code-tools/jmh/file/cde312963a3d/jmh-core/src/main/java/org/openjdk/jmh/logic/BlackHole.java#l117
`stores` -> `stored`
nit: `final` (also next two lines)
Maybe we could put this to `INFO` but change the message slightly to say "This could be an issue for IQ" or something along those lines. Just a thought.
Is this a server-side bug? the topic id exists in `topicsByName` but there is no `TopicControlInfo`.
Nit: fix indention (`final` keyword should start at same indent)
Maybe "to specify callbacks for producer.send() or to call .get() on the returned Future:..."
Not really sure. I feel like this is breaking the contract currently. On the other hand, the behavior its useful for (being able to check exit flags, or do anything else that requires waking up) is already possible given the current behavior...
This approach creates a temporary object, so it's not clear that it's better. It would need benchmarking to confirm.
We cannot disable tests like this.
I had a similar thought, that it looks like good fodder for unit testing, but I did like the safety blanket of verifying the actual partition counts. I guess I'm fine either way, with a preference for whatever is already in the PR ;)
I was referring not so much to the `toString`, but specifically to its use as the logging prefix. In the producer `TransactionManager`, we use `[TransactionalId Foo]` for example. I don't feel too strongly about it, so we can leave it as is if you prefer.
That's true, but perhaps that could be a call to `clearAssignment` directly from `unsubscribe`? If we only clear the assignment here, then it wouldn't be cleared until the user calls `poll` after calling `unsubscribe` which doesn't seem quite right.
```suggestion builder.addGraphNode(streamsGraphNode, transformNode); ```
In current design (KIP-19), expiration of a batch in the accumulator is to avoid holding the batch forever in the accumulator when the partitions has no leader. If the batch can be drained, that means it can still make progress. In that case, we probably don't want to expire that batch.
Some `@param` descriptions are missing.
We intentionally disable auto-commit so that it does not interfere with other test cases. If we are testing auto-commit behavior in a test, we just enable it locally for that test case (see `testAutoCommitDynamicAssignment` for example). Let's continue to follow this pattern.
The method never returns false. We can keep it as void if so.
Yeah, either way works for me. Seems unlikely someone using a bleeding edge library like streams would be on an ancient Slf4j ð
Good point. As long as `SharedTopicAdmin` admin won't be recycled. That's negligible anyways, I was referring to the pattern mainly.
nit: unnecessary extra space.
One thing I can think of is that the changelog topic of the joining streams's materialized stores were not deleted, and hence upon starting on the next test case, the store would be pre-populated and hence cause join result to be wrong (note that the state dir is a `@Rule` which means it will get cleaned up on each test case, and in the next run it will not be the same directory path). And the reason that it does not always fail is that we have to hit it that the two tests (with and without caching) consecutively. So think with your fix in `2.0` and `trunk`, it is Okay to leave the appID as is for now.
nit: "topic name to limit search to. REQUIRED if --partition is specified."
`ProcessorSupplier#toString` is usually not implemented, and it does not matter much either, hence I'd suggest removing this line.
I believe the goal is to use constant-time comparison to prevent timing attacks, hence the walk through the arrays.
it's => its
+1 from me as well for putting both accessors into separate classes
Mainly just trying to consolidate the logic for updating the retry state so that we don't have to remember to do it for new APIs. Also, eventually we want to have exponential backoff logic. I was thinking `CallContext` would be a good way to encapsulate any additional state that we would need.
The input is the same for each test so the output is too, right? Maybe we can we pull all the output verification into a single method
Good point. 1. Subscribe(empty) should still trigger a rebalance by sending a join-group request with empty subscription, so that it will then be assigned with no partition, but still live in the group; 2. Unsubscribe() should, in the future, trigger a rebalance by sending a leave-group request and reset its generation. 3. Pause() does not trigger a rebalance, but just stopping the fetching of some assigned partitions. We can leave this in the future ticket.
I think if we deprecate a class we do not need to deprecate all its member functions, but we need to check any callers that may pass in this class object or return this class object as deprecated. Reference: https://stackoverflow.com/questions/15908887/how-to-annotate-deprecation-of-a-class-in-java
Note to self: remove this conflict marker before merging.
Yes, it does. The copy constructor is used below. ```java Map<String, Object> result = new RecordingMap<>(values(), prefix, true); ```
nit: ```suggestion final KafkaMetric metric = metric("prefix-scan-rate"); ```
These log messages really make most of the individual log messages within the SMTs less valuable, since the record will include the key schema, key, value schema, and value. I've highlighted some of the log messages in individual SMTs that I think are worthwhile. Also: ```suggestion log.trace("Applying SMT transformation {} to {}", ```
\cc @bbejeck Can you have a look here? You know the optimizer code best.
Since the criterion is StreamsGraphNode::isKeyChangingOperation, I don't see why the call on line 407 is needed: if there is no key changing operation, null would be returned anyway.
Do we need this boolean? Also seems a bit odd that `topologyOptimizer.optimize(..)` doesn't return a `Topology` - i understand it is because of existing code, but is there a way we could make it return a `Topology`
I think this should be *above* the previous line? Order of output could be confusing given current phrasing. Might also want to include `isKeyConverter` in the log.
nit: **It** has no effect if a different TRANSACTION_BOUNDARY_CONFIG is specified.
I know this is currently only called within a synchronized block, but this method implementation requires that be the case. What do you think about making this method synchronized, removing the synchronized block around the call in `close()` (lines 141-143 above), and leaving the other synchronized blocks as-is. I know that's overkill, but it's actually no more overhead and it's safer in case somebody in the future calls `tryStop()` outside of a synchronized block.
Yeah, the underlying store compares the serializer bytes lexicographically, it doesn't have any concept of "Integer" or any other type. And the really tricky thing is that it scans lexicographically, which means from left to right, whereas when we serialize things we usually do so from right to left. eg `2` in binary is `10` whereas 11 in binary is `1011` and 13 is `1101`. The problem here is that the serialized version of 2 is a different number of bytes than the serialized form of 11/13, so the lexicographical comparator is effectively comparing digits of a different magnitude.
Let me know if you plan to address or ignore this -- I am fine either way.
WDYT about renaming `lag` to `rank`, or `effectiveLag`, or something else that reminds us this isn't the actual literal lag? cc/ @vvcephei
Ok, I've done enough kicking the tires to say that it is possible to get the generic type argument to Serde in most (but not all) cases. It's not a trivial algorithm. I'd estimate it at one day of work. If the current code is sufficient, then I recommend we go with it in this PR and have a follow-up PR for just this feature. While researching the issue, I found this article that pretty accurately describes what's going on: https://www.javacodegeeks.com/2013/12/advanced-java-generics-retreiving-generic-type-arguments.html
It seems that we have an existing issue in the handling of case INITIAL. If we can't completely write all bytes of the sasl token, we have to rely on the next call of authenticate() to finish writing the remaining bytes. However, when the write completes, we will go to the initial state and try to send the token again. It seems that we should be transitioning to the INTERMEDIATE state after the write completes. The same issue seems to exist when transitioning from SEND_MECHANISM to RECEIVE_MECHANISM_RESPONSE, if we can't write all bytes in SaslMechanismRequest in one send call.
Why do we add `KeyValueStore`, but not `WindowStore`/`SessionsStore` ? If this can be any dummy, I would rename to `dummyStore` -- otherwise it might be confusing.
Why is it useful to include `this.getClass()` in the log message? Are we missing information from the log context? Possibly more useful would be to mention that this is due to a JoinGroup response.
Not really against the style, just a nit of mine (My IDE recommends removing it). feel free to ignore.
nit: add empty line between functions, ditto below.
Doesn't follow AK setter convention. Any reason to maybe set this in an `initialize` method? Seems like it should be called up front, rather than repeatedly. Anything else that should be set only once? Removing unnecessary setters might help with the usability.
I'd prefer that we use `TimeUnit.SECONDS.toMillis(10)` and `TimeUnit.SECONDS.toMillis(1)` here. It avoids having to do any math when looking at the code.
nit: we can use `offsetData.compute` to replace the `getOrDefault` and `put` below.
@huxihx I'd suggest we remove any Streams' related changes in this PR, since we've already created a separate JIRA (above) for tracking any follow-up works on the streams side, and @vvcephei is working on that already.
If this checks out, then I think we actually don't need to track this variable.
typo: FOLLOW_REPLICATION_THROTTLED_REPLICAS -> FOLLOWER_REPLICATION_THROTTLED_REPLICAS
No need to pass in a `Named` -- we can just pass in the actual name as `String` directly -- otherwise we call `suffixWithOrElseGet` twice for no reason
name seems unused.
We can do this in a separate JIRA, but there is a TODO in this class to send the list offsets requests in parallel when resetting multiple partitions (currently we reset each partition separately, which means one ListOffset request for each partition). Should be an easy refactor after the changes from this KIP. I'll open the JIRA.
Fix this reference? There is no `AdminClient#describeTopic(topicName)` method
Could we use `TestUtils.waitForCondition`? That will time out if it takes too long for the condition to become true.
Do we need 3 Kafka nodes for this test? Seems like it doesn't rely on multiple Kafka nodes.
nit: insert empty line
This is synchronized and will await on the produceFuture. `await()` is called by `awaitFlushCompletion()` which is called when a user calls `flush()`. I am concerned that a user can call `flush()` and end up effectively dead locking other operations on the ProducerBatch, as getChildrenProducerBatch and addChildrenProducerBatch will not be able to be called by other threads - my concern is that the sender thread may become deadlocked in splitAndReenqueue in this state.
We should spell out that if the string is empty, it's because the remote end didn't send this information
Nit, to improve readability and precision, especially around how many Kafka transactions would be used: > Whether to enable exactly-once support for source connectors in the cluster by using transactions to write source records and their source offsets, and by proactively fencing out old task generations before bringing up new ones.
We don't have unit test coverage for this exception case
remove "on a window basis"
+1 to this
nit: remove this line
Before further optimization, we can use `store.putIfAbsent` for now.
I think these two overloaded `maybeAutoCommitOffsetsAsync` functions can be merged: compared with the other that returns `void`, this function did the following more: 1) `client.pollNoWakeup();` -> this has already been called inside the `commitOffsetsAsync` callee at https://github.com/apache/kafka/pull/11340/files#diff-0029e982555d1fae10943b862924da962ca8e247a3070cded92c5f5a5960244fR982, so this is not needed. 2) `invokeCompletedOffsetCommitCallbacks();` -> I think this is not required in the async call. As a result, we can just leave one `maybeAutoCommitOffsetsAsync` function that returns the future.
nit: this looks misaligned
Same here: not only CREATED, but also RESTORING and SUSPENDED tasks should not be included in `consumedOffsetsAndMetadataPerTask` and we should not let the task-manager to peek its state.
When error, could we print all the received records from all four topics too? Just 2 cents from my past flaky test fighting experience.
Can remove both `Long.valueOf`
We should be able to get rid of this since we have the default method.
Nitpick: maybe the rules should be at the end since they could be long. Something like: ``` java throw new NoMatchingRule("No rule applies to " + kerberosName + ", rules " + principalToLocalRules); ```
Here, not necessary either.
Refer to the `processing.guarantee` config here.
I wonder if a better location for `null` checking configs is inside `transform`. To me, it seems it is, because this way the check is in one place and we are protected against future uses of `tranform` with a `null` argument. Also, in contrast, seems that `configTransformer` can not be `null`.
@junrao If I understood your proposal correctly, we will keep Rate calculation the same, but additionally implement TokenBucket (traditional way) which will tell us when quota is violated. This would be much easier. However, I think, it would not fix our issue (that we are trying to fix) of too large throttle times during bursty workload. ClientQuotaManager calculates throttle times by comparing rate (based on how we record Rate) to quota, which I think would result in the same behavior as before unless we change the way we calculate throttle time as well.
I'd consider making this extend org.junit.rules.ExternalResource - it can then be used as a JUnit ClassRule or Rule. The benefits being that the JUnit framework takes care of startup and shutdown
I think you mean `\"FileStreamSinkConnector\"` here. Also, I know it doesn't work for the `FileStream` case, but should we support also dropping the `Sink` or `Source` part? I don't feel like I have a good feel for how frequently we'll have both implemented. For example, while you could implement both source and sink for JDBC, I'd guess that the vast majority of users are looking for the source connector and so that is likely the only JDBC connector class available.
I think the deprecation warning was part of a scheme to mark which tests should be rewritten: https://github.com/apache/kafka/pull/8864/files#r439685696
nit: I don't think we need the iterator
I concern that by stripping off just the first byte for base key and index key, we would be paying too much byte array copies which would be much slower than other stores (for which we just blindly copy-paste the bytes). Maybe we can have some optimization in-place for the first draft? E.g.: 1) for index key, we know we just need to add the first byte and strip the last four byte of seq (? is that right, need to double check). 2) for base key, we can just do a swap-copy from the index key to switch the position of timestamp and key.
nit `java.util.` can be removed
"If ConfigProvider is not provided" --> Strictly speaking, the parameters don't pass `ConfigProvider` instances, so this sentence is not very accurate. We need to be very careful about the terms we use, and we should not use the term "ConfigProvider" when we really mean "ConfigProvilder properties".
nit: I would delete this line
nit: Just my usual habit, I think we should get a separate test file `HostInfoTest` instead.
> Yes, that is a little odd -- as I said, happy to change advancedNowAndComputeLatency to now = time.milliseconds() within maybeCommit(). Sounds good to me, let's do it
You can use `getResourceAsStream` instead of `getResource` which makes some of the steps redundant.
Assume the following thread list [t2, t3, t4], `threadIdx` would be 4, which is already there. You should keep the currently used `threadIdx`s and check those to decide on the next `threadIdx`.
nit: add `final`
IMHO the current docs don't make it clear what the difference to e.g. `map()` is.
I think it is a timing issue: when all the threads of an instance start at the same time, there could be a short period of time when the first rebalance get triggered, so the transition is `created -> running -> rebalancing -> running ..`; but if some threads start later than other, then the instance may be not in the `running` state before coming to the `rebalancing` state, so the transition is `created -> rebalancing -> running .. `.
nit: This line is too long. ```suggestion private final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, "test", StreamsConfig.METRICS_LATEST); ```
Also, I think in the exception thrown if `configEntries == null` should mention whether the system property is set or not as this would be helpful for people who thought it was set.
The order in each group should be based on... `ConfigKey.orderInGroup` :-)
```suggestion * Set the handler invoked when a {@link StreamsConfig#NUM_STREAM_THREADS_CONFIG internal thread} * throws an unexpected exception. These might be exceptions indicating rare bugs in Kafka Streams, or they * might be exceptions thrown by your code, for example a NullPointerException thrown from your processor * logic. * <p> * Note, this handler must be threadsafe, since it will be shared among all threads, and invoked from any * thread that encounters such an exception. ``` I think it's wrong to say that this is invoked when the thread abruptly terminates, because it's not. That's how the JVM handler works, but we're actually executing this handler while the thread is still running, and in fact that thread itself is what calls the handler. It also seemed appropriate to elaborate a little more on the usage of this method.
Just to clarify, I would support doing the former, ie don't check whether it's RESTORING here at all. But we should at least be consistent
`true` as initial value of `ignoreExceptons` changes default behavior. Users might be relying on exceptions being propagated to callers, thus we should not change this.
Same here, one parameter per line and align
My understanding is that we reset the producerId if we find one partition for which we have expired all in-flight requests. My question is how this affects the in-flight requests of other partitions? If one of them happens to need retry, wouldn't we hit this case? But since the sequence number isn't changing, I think it should be safe to continue retrying with the old producerId. Alternatively, maybe we should drain all partitions before resetting the producerId. That's a bit heavy-handed, but hopefully this case is rare in practice.
Similar here, maybe we could leverage `transitionTo` to help throw the exception.
I thought we would catch and save the first exception thrown by a rebalance listener callback, and then rethrow after all rebalance callbacks have been invoked? In this case that would mean `handleAssignment` would still get called, and then we would throw an IllegalStateException and bail on the rest of `handleAssignment` for no reason. The IllegalStateException itself is not the problem, since only the first exception (the TaskMigrated) would ultimately be thrown up to `poll`. But we should still go through the rest of `handleAssignment` in order to properly clean up the active tasks and manage the standbys (since we don't need to close standbys in case of TaskMigrated)
How about adding a bit of detail about how this works and behaves, including: * what do variables look like? * how the map of properties for config providers are used? * what are the config provider properties (probably warrants a separate paragraph and list of known properties)? * what happens if the config provider properties don't define the config providers? * what happens if the config provider properties are provided in the `originals` rather than the `configProviders` map (or rather `configProviderProps`)? I also think because this class is subclassed a lot, it's worth being a bit more explicit than we typically are in the `@param` to say whether the parameter can be null. For example: ``` * @param definition the definition of the configurations; may not be null * @param originals the name-value pairs of the configuration; may not be null * @param configProviders the map of properties of config providers which will be instantiated by the constructor to resolve any variables in {@code originals}; may be null or empty * @param doLog whether the configurations should be logged ```
I think we don't really need to make this change anymore, since it's only refactoring the existing code that we don't need to actually change anymore. (This PR is no longer using this logic in multiple places.)
Could use Collections.emptySet() if reduced to Set
nit: better log the latest supported version as well.
nit: Please fix code style.
Thanks for the explanation. I checked the logback implementation and it does indeed use the argument array. Maybe it's not such a big deal since we have the log level guard.
I was referring to the @throws clauses at the bottom where neither seems to have been added. Seems like both are possible.
This is a weird line break. It would be better to shorten the line by assigning the result of `mapper.apply` to a variable.
Hmm, I like `InvalidTopicException` over `IllegalArgumentException` if we are raising it through the future. Typically `IllegalArgumentException` is raised directly.
I'm not terribly thrilled about a hard-coded retry limit here. Let me think a little more on this but I understand that there may not be a much better way.
TBH I don't remember right now any reason for this. Probably just kept it consistent with stream time punctuation. Right now, I can't think of any reason why punctuating immediately would be desirable though.
nit: move closing `}` to next line
Yes this sounds good. IN case you want to run it locally, feel free to read the README.md file, which includes cmd for running a single test.
You're right, I got confused by the misleading `currentThread` name. Hmm, seems like it's not easy to include the thread name for the thread that is currently holding the lock.
It would be difficult to give meaningful enum names in short time. Using two boolean parameters seems to be better for the moment. If there is ever need for 3rd boolean, we can refactor the code.
I was also confused by this logic for a while and I got an optimization idea from the [Raft dissertation](http://wcl.cs.rpi.edu/pilots/library/papers/consensus/RAFTOngaroPhD.pdf) about this, The sentence below is taken from section "5.4.2 Committing entries from previous terms": ``` There are some situations where a leader could safely conclude that an older log entry is committed (for example, if that entry is stored on every server), but Raft takes a more conservative approach for simplicity. ``` so we can also update commitIndex(highWatermark) if logEndOffset of all followers have passed the highWatermark. I don't think this is a good idea since it makes the logic opaque but will not necessarily really optimize any performance, so I just mention it here and feel free to ignore it ð.
This seems fine at the moment since this isn't particularly performance critical. For the longer term if we have many of these downgrades, we could consider using ApiVersions in the underlying NetworkClient to make the decision before sending the request.
Yeah, I have a slight preference to just lock `SubscriptionState` every time since it is the simplest option. I don't think contention is a major problem since there's only the heartbeat thread which is sleeping most of the time. Unless there's some reason to think the cost of lock acquisition itself is a concern.
nit: move `}` to next line
Do we need to lock here? I think the lock has already been taken out from the callers of this method
Another option would be to put a "deprecated" annotation here.
Not sure if these configs actually come from the default configs. I think these may be explicitly configured in the tests.
nit: We could use `singletonMap` here.
We can just use `ktableSource.queryableName() != null` to do this check (we can get the source ktable node via: ``` final KTableSource<K, V> ktableSource = (KTableSource<K, V>) processorParameters.processorSupplier(); ```
OK, let's keep it for now.
`int` is what you want here, not `Integer`, right? It looks like we don't want or need this to ever be null. Should we throw an exception if latencyMs is set to a non-positive number? It's not clear what that would mean, or who it would be useful to. A millisecond is a relatively large amount of network latency. I suppose we can add a nanoseconds field later, though, if that becomes an issue.
I was wondering about that too. It seems consistent with the other things we have there.
Sorry for that -- You are of course right. `final` only for iterator loops...
typo: kStreamhould... -> kStreamShould In fact i'd probably rename these methods to begin with should, i.e., `shouldAddTimestampExtractorToStreamWithOffsetResetPerSource` etc
I think we should make the `MetricsReporter` interface itself extend `Reconfigurable`, rather than just `JmxReporter`. We might want to reconfigure other metrics reporters at runtime, and there is no reason to special-case just this one.
This message didn't need to be specialized.
Yeah. Might be worth to just remove this one even if we need to update all implementations.
We need to keep the old method as before and deprecate.
nit: make `Metrics` a field
This could use a docstring e.g. `"""afsadfasd"""`
StreamThread.getName() will return with a prefix of "StreamThread" already. EDIT: nm, this is just too minor.
Yeah from looking at the validation code, I'm not sure we'd hit this point. But if we did wouldn't we want to throw an exception as we do in the validation section? Although I think we may use a number higher greater than latest supported version for version probing.
nit: You can use the `topic(...)` helper function instead of `Arrays.asList(...)`. See examples in other unit tests.
But @cadonna , will this remove the metrics whenever any store on the instance is closed? That seems to make sense with the current eager rebalancing, but with KIP-429 we will only close the ones that are migrated to another consumer.
I'm not really clear why this is done in a separate loop. Are you trying to avoid the work of collecting valid records unnecessarily? Also, I think the loop below still has the OFFSET_OUT_OF_RANGE check.
As for implementation, we could just call toStream().selectKey(), which will add two processors instead of one, but maybe more illustrative on the topology.
Makes sense @ewencp, not sure how I missed that sentence when I read it originally.
We have a rule w.r.t using `@expected` the rule is that it should only be used for single line tests where you can guarantee that the exception can only come from the line that is being executed. In all other cases you should use `try{...}catch(...)`
This method does not take an `Aggregator` as parameter...
nit: **revoke** partitions that **were** previously owned but **are** no longer assigned
`INFO` seems rather chatty to me. `DEBUG` or even `TRACE` might be better.
upto => up tp
It looks like we are not calling `configSynonyms()` anymore, so we can remove that private method
I'm not sure if we should set `requestRejoin` in the base class (`CoordinatorResponseHandler `). For example, `HeartbeatResponseHandler` also extends from it, but for that request if we get a disconnect, we should just mark the coordinator as dead in order to re-discover it; and then after new coordinator rediscovered retry sending heartbeat request and if that succeed just proceed as normal. Setting it here will force heartbeat request disconnection to also trigger a join group.
This conversion is a bit unfortunate as we have to traverse all the partitions again to build the `List<ListOffsetTopic>`. Instead, we could compute it directly within `groupListOffsetRequests` and could receive `Map<Node, List<ListOffsetTopic>` directly here. That seems doable but I may have missed something.
Actually let me put in this way: `restoredPartitions` could just be local to this function? It's only usage outside is in `clear` so it seems we can keep it local or just use `restored` directly and remove it from `clear`.
```suggestion + "not all connectors are capable of defining their own transaction boundaries, and in that case, attempts to instantiate a connector with " ```
Nit: go we need to include the groupId? It's repeated in line 316.
Ditto above, if we do not expect this to ever happen, we do not need to `Thread.currentThread().interrupt();` and instead just log error and throw as IllegalState with the error message indicating this should never happen.
If we call this twice and build two list, we cannot guarantee load balanced assignment across threads. Assume you have two thread and 3 active and 3 standby tasks. We would end up with: ``` t1: a0, a2, s0, s2 t2: a1, s1 ``` However, after assigning all active tasks, we should not start to assign standby tasks on the first thread but on the "next" thread: ``` t1: a0, a2, s1 t2: a1, s0, s2 ``` We can achieve this, by building a single list of active and standby tasks IMHO. Or do you think that this kind of load balancing is secondary? \cc @guozhangwang @dguy
I would personally prefer, to keep the condition in the `while` conditions instead of using `if() break` construct.
`ProducerRecord` is actually guarantee to have a non-null timestamp -- not sure if we need this check -- actually similar for other fields like topic or header
IIUC, spotbugs complained if these were not here.
`KTableSource#materialize()` should be good enough -- it will set the `queryableName` (AFAIK, this won't make the store really queryable, but it's just a proxy to enforce materialization).
nit: this could be a normal "for each" loop.
nit: since we're not using the index, maybe use `for` with implicit iterator
nit: make the keys a `Set<String>` and then do `assertThat(keys, equalTo(Utils.mkSet("2","3")`
Let's keep it as is then.
nit: avoid double blank lines
Hmm, in that case we can do this as-is then: I need to think through what's possible under the context of KIP-429 anyways so we can have a thorough discussion in a later PR.
ditto on removing before/after.
nit: -> `shouldThrowForInvalidSocketSendBufferSize()`
nit: add `final`
This breaks with an NPE when the user does not specify the partition explicitly in the `ProducerRecord`. We should use `tp` as the partition.
I think it was never inferred before, it was actually the type `ProcessorSupplier<Object, Object>` (just my theory). I think if old code will fail to compile, we should not change the public API. Note, the existing methods would be deprecated as part of implementing KIP-478 anyway, so maybe we should just leave the public APIs alone.
Any thoughts about this @dguy @guozhangwang -- this is a different issues than the newly created JIRA (even if we might be able to subsume it with it). The issue described here would also be there, if we only assign stateful standby tasks.
Just see the `timeWindowMixAggregatorsTest` below -- seems it's a super set of this test and hence, having the second one only seems to be sufficient.
@becketqin : Yes, you are right. It does seem that checking connectionFail state achieves the same thing. It's just that using muted partitions seems simpler and avoids having to pass in networkClient to recordAccumulator, which is a bit weird.
Let's open a jira for getting rid of the toPartitionDataMap if we don't address it in this PR. It's a pretty large part of the cost here and there are only a few places we would have to deal with it. I think we should fix it sooner rather than later too.
Seems like this is the same in `testReadFullyOrFailWithMultiReads`. Maybe we can extract it to a helper method.
Should we qualify that "exactly once" for idempotent producer relies on the user enabling maximum retries and not attempting their own retry logic. Also, there is still the case of expiration in record accumulator. Finally, I'm not sure it's worth mentioning that the guarantees are only provided for the lifetime of the producer.
This seems wrong, we have 2 `STDOUT_CAPTURE` and no `STDERR_CAPTURE`. Why did the first one change to `STDOUT` since we're still redirecting stderr to the file? (It's also not obvious to me why we changed this to use `tee` but it seems to not affect anything critical here.)
Do we make use of this new argument anywhere? I can't seem to find any
nit: Could we indent the block such that `}});` is aligned with `ListOffsetsResult`? Same for other tests.
This is the same code that is in `NetworkClient.correlate`. Maybe we can make that a static public method and reuse it.
Not sure if this is clear, but all classes under `errors` are public API. As such, we should consider the naming of such classes carefully. It would be good to take a pass at all the names before the release and make sure they still make sense.
There is not reason to specify this twice. If you want to test that it work for both parameter names, it should be two different test, each testing one parameter name
nit: curious why `storeType` is not enum but raw string. Typo in `in_memory` could make it `ROCKS_DB` type. e.g. `in_memry`. Maybe it's register in `in(ROCKS_DB, IN_MEMORY),` when defining and checked there
Should this be `num_lines=3` (cf. L115 and L135)
nit: put `@Override` on its own line
Could we have one more test case similar to this, but in which the paused partition already has a position? This verifies that `updateFetchPositions` does not overwrite the current position.
original was better
`state` is shared between threads. I think this block needs a `synchronized(AbstractCoordinator.this)` (and same below)
Nit: ```suggestion throw new ConfigException(String.format("Invalid header config '%s'", config), e); ```
Remove unnecessary `toString()` once the Entry type is set above. Other similar cases below too.
True. I went ahead and did that in KAFKA-3807. I'm not sure which will land first, but feel free to do it here.
```suggestion LOG.warn("listOffsets request failed.", e); ``` Thanks! (minor suggestion to make the log message more typical)
Hmm, good point. Maybe just letting `send` throw the TimeoutException is OK.
req: Could you compute those from the above maps? It might make maintenance easier.
Fair enough. Thanks for the validation.
They do the same thing, but the majority of calls are on `wrapped()`.
Yeah, good point. I've been on the fence here, because the calls might block one way or the other anyway. Good thing is that the locking is per connector instance. Let's keep the synchronization. We can always return with some performance benchmarking on the topic and revisit locking for connectors _and_ tasks if we can afford to do that. But let's follow the `synchronized` method style (e.g. `onPause`, `onResume` in your examples above) if the synchronization applies to the whole method.
```suggestion if (storeSupplier.retainDuplicates() && enableCaching) { ``` Should we only log if we're changing the configured caching? (Also applies below)
Can we swap the `if/else` so that we don't have to negate the first `if`? That seems unnecessarily confusing.
Actually I'm not sure why we need this additional block if we are already holding the lock. The predicate wouldn't be used after this method returns.
There may be a couple validations we have in `ZkAdminManager.describeClientQuotas` that do not appear here. For example, we detect invalid mixes of ip and user searches: ``` if ((userComponent.isDefined || clientIdComponent.isDefined) && ipComponent.isDefined) throw new InvalidRequestException(s"Invalid entity filter component combination, IP filter component should not be used with " + s"user or clientId filter component.") ```
Update return type to `L` (if we introduce `L`)
nit: the expectation should be the first argument
I was thinking: ``` if (tries > 0) Thread.sleep(tries > 1 ? 10 : 2); ```
Both of these are currently failing for me in a local virtualbox cluster. The first looks like a legit failure since the data doesn't seem to match, the second looks like maybe it's failing to create a topic perhaps because the previous test didn't tear down properly? The log for the second one indicates the topic already exists. ``` ====================================================================================================================================================================================================================================================================================================================================================================================================================================== SESSION REPORT (ALL TESTS) session_id: 2015-08-19--004 run time: 1 minute 40.540 seconds tests run: 2 passed: 0 failed: 2 ====================================================================================================================================================================================================================================================================================================================================================================================================================================== test_id: 2015-08-19--004.kafkatest.sanity_checks.test_mirror_maker.TestMirrorMakerService.test_end_to_end status: FAIL run time: 1 minute 2.808 seconds Traceback (most recent call last): File "/Users/ewencp/confluent/ducktape.git/ducktape/tests/runner.py", line 81, in run_all_tests result.data = self.run_single_test() File "/Users/ewencp/confluent/ducktape.git/ducktape/tests/runner.py", line 130, in run_single_test return self.current_test_context.function(self.current_test) File "/Users/ewencp/kafka.git/tests/kafkatest/sanity_checks/test_mirror_maker.py", line 94, in test_end_to_end assert len(self.consumer.messages_consumed[1]) == self.num_messages AssertionError -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- test_id: 2015-08-19--004.kafkatest.sanity_checks.test_mirror_maker.TestMirrorMakerService.test_lifecycle status: FAIL run time: 37.728 seconds Traceback (most recent call last): File "/Users/ewencp/confluent/ducktape.git/ducktape/tests/runner.py", line 78, in run_all_tests self.setup_single_test() File "/Users/ewencp/confluent/ducktape.git/ducktape/tests/runner.py", line 122, in setup_single_test self.current_test.setUp() File "/Users/ewencp/kafka.git/tests/kafkatest/sanity_checks/test_mirror_maker.py", line 58, in setUp self.k2.start() File "/Users/ewencp/kafka.git/tests/kafkatest/services/kafka.py", line 55, in start self.create_topic(topic_cfg) File "/Users/ewencp/kafka.git/tests/kafkatest/services/kafka.py", line 115, in create_topic node.account.ssh(cmd) File "/Users/ewencp/confluent/ducktape.git/ducktape/cluster/remoteaccount.py", line 79, in ssh return self._ssh_quiet(self.ssh_command(cmd), allow_fail) File "/Users/ewencp/confluent/ducktape.git/ducktape/cluster/remoteaccount.py", line 206, in _ssh_quiet raise e CalledProcessError: Command 'ssh vagrant@worker4 -o 'HostName 127.0.0.1' -o 'Port 2202' -o 'UserKnownHostsFile /dev/null' -o 'StrictHostKeyChecking no' -o 'PasswordAuthentication no' -o 'IdentityFile /Users/ewencp/kafka.git/.vagrant/machines/worker4/virtualbox/private_key' -o 'IdentitiesOnly yes' -o 'LogLevel FATAL' '/opt/kafka/bin/kafka-topics.sh --zookeeper worker2:2181 --create --topic topic --partitions 1 --replication-factor 1'' returned non-zero exit status 1 -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- ```
Nit: line too long
If you change the `toInclusive` to `true` in this test, the test also passes. That means, that you are not testing `toInclusive` in this test. I suggest the following test: ``` public void shouldExcludeEndOfRange() { final RocksIterator rocksIterator = mock(RocksIterator.class); rocksIterator.seek(key1Bytes.get()); expect(rocksIterator.isValid()) .andReturn(true) .andReturn(true); expect(rocksIterator.key()) .andReturn(key1Bytes.get()) .andReturn(key2Bytes.get()); expect(rocksIterator.value()).andReturn(valueBytes).times(2); rocksIterator.next(); expectLastCall().times(2); replay(rocksIterator); final RocksDBRangeIterator rocksDBRangeIterator = new RocksDBRangeIterator( storeName, rocksIterator, Collections.emptySet(), key1Bytes, key2Bytes, true, false ); assertThat(rocksDBRangeIterator.hasNext(), is(true)); assertThat(rocksDBRangeIterator.next().key, is(key1Bytes)); assertThat(rocksDBRangeIterator.hasNext(), is(false)); verify(rocksIterator); } ```
If we do this, we should have an array of `byte`s and can just call `Stringâ(byte[] bytes, Charset charset)`.
Not sure this really clarifies the process. The sentence "The assignment of topic partitions will be assigned to consumers that subscribed to the topics in a round robin fashion." doesn't add any detail. I'd say something like "When subscriptions differ across consumer instances, the assignment process still considers each consumer instance in round robin fashion but skips over an instance if it is not subscribed to the topic. Unlike the case when subscriptions are identical, this can result in imbalanced assignments." and then include the example you provided here.
I think we should also log the error in `failed && isRetriable()` case
I think we can call the one-parameter `produce()` in line 144 above as well
Yeah, I don't feel too strongly in this case. The advantage generally is that the scope of the test case is clearer which makes failures easier to investigate.
It looks like there should only be a single `StreamStateListener` and `threadState` should be a member.
It's useful to have a toString in any case, but I'd probably include the name of the class `KerberosShortNamer` in the `toString`.
The producer's `close(...)` method can throw an `InterruptException` if the method fails to join the IO thread. This can theoretically happen even if the timeout is 0 if the thread is interrupted (e.g., the executor is shutdown) _before_ the join can wait. Although the likelihood of this is small, what do you think about catching `InterruptException` and ignoring the error? ```suggestion } catch (InterruptException t) { // ignore, since this is likely due to the worker's executor being shut down } catch (Throwable t) { ``` Two things. First, the producer throws `InterruptExeption`, not `InterruptedException`. Second, even though the `WorkerSourceTask::close()` that calls this `closeProducer(Duration)` method doesn't _directly_ use the executor, the `Worker` does use that same executor to stop this `WorkerSourceTask`, which ultimately does call `WorkerSourceTask::close()`. IOW, this `closeProducer(Duration)` method is always called from the executor, and the executor could be shutdown at any moment, thus the potential `InterruptException`.
Here and for the next two tests, it would be better to rewrite the tests to following: ``` final Exception e = assertThrows(NullPointerException.class, () -> new InternalTopologyBuilder.Source(null, Collections.emptySet(), null); assertEquals(<expected message>, e.getMessage()); ```
Can we retain Set type? maybe required to eliminate duplicate mechanisms.
this should be declared volatile (considering the double-checked locking below)
Instead of doing this, we can simply override `toString` in each enum. However, if we go with my suggestion of renaming the enum values, the `toString` will be the right one by default, I think.
This seems to only verify the direct parent -- however, we should rather use `repartitionRequired` flag to determine if we need to insert a repartition topic or not.
nit: we can move `inputRecordTimestamp` up and use it here.
Also, it should make sure the input arguments (from ```ProducerRecord```) are equals to getter of ```TestRecord```. For example: ```java assertEquals(expectedRecord.getHeaders(), producerRecord.headers()) ```
This is defined in `CogroupedKStreamImpl` and here -- seems to be redundant -- make the other one package private and reuse in this class instead.
`LATEST_27` musts be imported above.
I think we can remove the `to()` operator to verify if we don't fail with a NPE.
It is probably not enough to just turn off OP_WRITE at SASL completion time. After completely sending a challenge token, the client needs to turn off OP_WRITE. Otherwise, while waiting to receive the next token from the server, the client will be busy checking in the selector.
nit: Do these tests need a `PowerMock.verifyAll()` at the end? I see a `PowerMock.replayAll()` call but not any `PowerMock.expectLastCall()` or anything that makes it seem like powermock is being used functionally here.
nit: remove empty lines
nit: remove empty line
nit (rename): `shouldMaterializeKTableFromKStream` (a good naming patter is "should <doSomething> <condition/operation>"
What do you think about combining these log messages? ```suggestion int ceilTasks = (int) Math.ceil((float) totalActiveTasksNum / totalWorkersNum); log.debug("New average number of tasks per worker: floor={}, ceiling={}", floorTasks, ceilTasks); ```
May be worth adding an error message for `aasertTrue` (in all the places where assertTrue is used).
`must` -> `can be specified ... if the no-arg constructor is called and hence it is not passed during initialization`.
If it's no longer used, we should remove it.
As above for this and the next ctor
Consider moving this line into the block above
This is used for both producer and consumer, so we'd better name it `props` not `consumerProps`.
consumer_properties is still in parameters ```suggestion kafka_opts_override="", client_prop_file_override=""): ```
Do we need to add `@SuppressWarnings("deprecation")` here, too? And elsewhere in this class
We can use `Collections.singletonMap()` here
Could you please extract the values `"Key1"`, `12345L`, `"Key2"`, and `"6789"` into variables and use the variables in the checks below? I am sorry, I missed that in my previous review.
nit: unneeded newline
This one also shouldn't be deprecated.
Wrong signature of `aggregate(...)`.
Is this method used anywhere? The only caller I can find is `DeleteGroupsResponseTest` and that also test the Errors is None. If we decide to keep it, we can remove `.code()` from both sides of the equals
```suggestion ``` Do we need both of these debug messages? After all, `worker.assign(...)` is just adding a string to a collection. How about keeping the first one since this is at this point an on-going process and we've not actually assigned anything to the actual worker node.
One concern is making things too magical. However, it does seem that there's no scenario where someone would want transactions without idempotence. So, I'm in favour of this suggestion.
if you have an unsigned ~~8-bit~~ 32-bit data source
Do you know why we had this deprecated? Do we consider it a public API? Below we have code which checks for null `SharedTopicAdmin`. Seems like we can probably get rid of that. The only usage I could see was in a test case.
```suggestion * Grace period defines how long to wait on out-of-order events. That is, windows will continue to accept new records until {@code stream_time >= window_end + grace_period}. ```
Then we wouldn't have caught this bug ð . The most dangerous aspect of the generated protocols is the down-conversion to older formats since it gets poor test coverage.
Second parameter should be `serverConfigs`
Thanks for the details. Seems I did not have full context.
Just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. Would you mind to not move configs that get deprecate and add the new config at the "right" place. Thanks a lot. :)
You can also remove the `@SuppressWarnings("deprecation")` at the top of the method.
In fact, even the producer code is pretty similar, so you could have a methods like the following which is called by both `getBaseConsumerConfigs` and `getProducerConfigs`: ``` java private Map<String, Object> clientProps(Set<String> configNames, Map<String, Object> originals, Map<String, Object> overrides) { Map<String, Object> props = filter(configNames, originals); // enforce streams overrides if not specified by user for (String keyName : overrides.keySet()) { if (!props.containsKey(keyName)) props.put(keyName, overrides.get(keyName)); } } ```
nit: you can return directly from these branches and get rid of `result`
Hmm, not all partitions with ISR containing the shutting down need to change the leader.
i'd probably extract lines 121 -> 130 into a method, i.e, `findSourceNode(...)` Also, we -> if
nit: `ALLOWED == result`
Can we please add a method `isDone` which is basically `finalState() != null)` and then use it here and everywhere else we do `batch.finalState() == null`? It would be much easier to understand.
Do we need to mention something about producer and broker settings required to make this true? For the producer case, we can probably say that we do it automatically if the settings haven't been overridden.
Please add `{}`, too
I'm +1 on demoting these log entries! :)
We also need to update `equals()` to include `topicPattern`
This should return `-1` as old `BadValueTransformer`
I believe it would be easier to interprete if you avoid using the if-else block and created the log statement in one assignment using conditionals. String logStatement = "{} partition" + (count > 1 ? "s have leader brokers" : " has a leader broker") + " without a matching listener, " + (count > 1 ? "which is " : "including ") + "{}"; log.warn(logStatement, count, missingListenerPartitions.subList(0, Math.min(10, count)));
nit: unnecessary newline
Yes, that matches my understanding and suggestion.
I think this was my bad from before. This store is not a timestamped store.
Seems we should get rid of this one after we have updated the full DSL to use the new `Record` type.
This makes me think (in a more general sense), that what would be the upgrade path for people to switch from at-least-once to exactly-once? For example in this case all the metrics would be broken as we are not having new clients. I looks to me that operation-wise it would be some burden on users to switch on / off this knob. cc @sriramsub @enothereska @dguy @bbejeck Anyways, this may be a more general discussion that we can have separately.
Also, `GzipOutputStream` doesn't seem to call `flush` on the underlying stream: ```java public void close() throws IOException { if (!closed) { finish(); if (usesDefaultDeflater) def.end(); out.close(); closed = true; } } ``` So, seems pretty safe to follow that example.
Can't we pass a `null` and add a check with `transitionToRunning()` -- it's not a critical code path...
Both should be final.
I think it would be better to have a test that shows that a new thread that replaced a failed one, actually is able to process records. So, I would let the new thread process some records and then shutdown the client with a normal close. Maybe similar applies to the shutdown tests. First let the client/application process some records and then throw an exception that shuts down the client/application. I guess, this last paragraph is something for a separate PR.
Yeah, that's a good point. Scratch that idea.
Ok. Makes sense. And for compaction, windows do have the same start timestamp, so the topic does not grow infinitely anyway (same as for non-windowed KTable).
nit: extra space.
Doing `store.put(key, newAgg)` in `if (value.oldValue != null)` and `if (value.newValue != null)` is inefficient. Consider doing it once.
We usually don't indent but align -- at least, all other code is formatter like this IIRC. But it's a nit anyway...
these calls aren't needed, right? `close` does nothing anyway. And if they did do something, then you'd probably want to do it in `tearDown` rather than here.
I think there might be a bit more to it than this. Do we need to consider the flushing of the StateStores and the producer, too? I.e, we have state in the state stores that is going to get flushed - that state is related to the offsets that we are not committing. That state is not-only going to be flushed to disk, but also written to the changelog topics. Although, without EOS i'm not sure we can do much. We can't guarantee that the state hasn't already been flushed to the store and the changelog, i.e., eviction can happen at any time.
Do we want the raw topic names (without the prefix) or the decorated ones here? BTW The function/variable names are a bit confusing but they stored different things. Maybe we should just rename them to be more clear.
Is this a good default timeout? The default timeout in `TestUtils.waitUntilTrue` is 5 seconds.
why this override? we haven't needed something like this for the other autogenerated files
That is right, since Kafka Streams processor topology traversal is Depth First, when we finished one child route we need to go back to the next child route, and hence resetting the the currNode.
Could we just initialize the task in `setUp` with the testCache so that we do not need to explicit re-initialize it here? If not we need to at least close the task before re-initialize it.
an non-empty => a non-empty
@enothereska is right, if you make that additional change, I'll merge your PR. Thanks!
same as above for parameters
I know that this check was here in some fashion before, but I'm drawing a blank on why we need to verify this log line. It seems like _just_ checking the version number logs and nothing else would be the key to a long and happy life.
Are you sure this is correct? It's too different packages and thus the full package name in required IMHO.
Just a reminder, `ByteBuffer` again :)
I see, in that case it's probably fine.
Immediately should be lower case.
My suggestion would be to move the logic from the core module `kafka.common.Topic.scala` to the client module. And then replace all usages of the old Topic class in core with the new version added in clients. `org.apache.kafka.common` is where we want all common client and server classes/logic to live.
Thinking about it twice, maybe this requirement is a bit too restrict: for example we may have a low-traffic topic with N partitions and a high-traffic topic with N \* M partitions and we still want to join them as partition1 with partition1-M, etc. Admittedly this will bring other problems when we change number of partitions, but maybe worth considering.
Personally I still think a clear EXPIRED state would be clearer. We can let batch.done() method take a FinalState argument instead of inferring the state from the exception.
We're missing the license header here
I think we throw for all three cases.
two calls to createWorkerTask
I think these lines are too long. The ones in the other methods too
we can narrow the try/catch block inside the if block.
Why "klass" in the resulting string? Just use "class".
Nit: we typically put `null` on the right hand side in the Kafka codebase. Same below
@junrao Regarding "With this change, if we record a large value, the observed effect of the value could last much longer than the number of samples. " -- This will not happen with this approach. If we record a very large value, we never move to the bucket with timestamp > current timestamp (of the recording time). This approach can only add the value to older buckets, which did not expire, but never to the buckets "in the future". For example, if we only have 2 samples, and perSampleQuota = 5, and say we already filled in both buckets up to quota: [5, 5]. If new requests arrive but the timestamp did not move past the last bucket, we are going to be adding this value to the last bucket, for example getting to [5, 20] if we recorded 15. If the next recording happens after the time moved passed the last bucket, say we record 3, then buckets will look like [20, 3].
`name()` -> `wrapped.name()`
Here too, is this kind of moot now that we can just track the `previousRecordTimestamp`? IIUC all we really want to do is make sure that the left window is not empty, which is actually a pretty simple calculation in terms of the `previousRecordTimestamp`
Got it. So in the autocommit mode, the offsets will be committed on close. Further, any asynchronous commits pending will wait until the timeout before the close proceeds. If the coordinator cannot be found within the timeout, the close proceeds without committing anything. The default timeout in all cases will be 30 seconds. I think it make sense to put this in the java doc.
I would also try to uniformize the logs and would use debug all the time except for the unexpected errors.
Same question for ProcessorSupplier for using a delegate, but is minor to me.
The advantage of using `ConfigDef.validator` on the `response.http.headers.config` config key is that this constructor call would throw an exception if any invalid value is used, and much sooner, too.
Also below, when calling `stateListener.onChange(state, oldState);` -- would we need to call `stateListener.onChange(newState, oldState);` instead? Otherwise, `state` could change before we do the callback because the lock is released already.
It seems that both loginContext and mode can just be a local variable.
We are slightly changing the behavior here: if the metric does not exist, previously it is just an no-op, while now we will create the metric first then deletes it.
If I got this correctly, we have 3 overloads (topic, topic+consumed, topic+ consumed+materialized). Does a 4th with topic+materialized not make sense? Btw: with consumer+materialized, users can specify key/value serde twice (ie, if default serde must be overwritten, they need to do it twice? -- maybe we can improve this?) If double specification is required, we should have a check that both key/value serdes are the same? Applies to `#globalKTable()`, too.
Please reformat as follows: ``` setupGetNewSensorTest( metrics, THREAD_ID + ".task." + storeName + SENSOR_PREFIX_DELIMITER + storeName + SENSOR_PREFIX_DELIMITER + TASK_ID, recordingLevel ); ``` This applies also to the other locations where the second argument is too long for the line, i.e., lines 322, 343, 364, 385, 406. Sorry if I missed that in my previous review.
One side effect of doing this is that it can force the leader to change unnecessarily. For example, the current leader could still be in newIsr, but may not be the first in replica list. bestLeader() will cause the leader to change in this case.
Sounds good. The proposed `unsubscribe` will clear the state set by `assign` and `subscribe` methods, so that will address my concern. Thanks!
This is not a guarantee that we give in the KIP. Assuming that always the first stream thread is removed is too strict for this test.
Hmm, if there is any exception from here, we probably want to bubble it up to the caller. For example, in SocketServer.processNewResponses(), if send() hits any exception, we want to call updateRequestMetrics(() and avoid updating inflightResponses, and move on to the next response in the queue in the same loop.
nit: add `final`
I think @vvcephei 's confusion comes from a change that we now require all tasks to be transited to `suspended` before transiting to `close`: previously, we allow e.g. a running task to be closed immediately and inside the task itself the logic actually did the "running -> suspend -> close" logic, i.e. it is totally agnostic to the TM. In a refactoring with eos-beta we changed it. So now the responsibility is kinda split between the two: TM needs to make sure the transition is valid and the task verifies it. By doing this we avoided the "pre-/post-" functions.
i think this would be better off as a test rather than in `setUp`
nit: ... for "header" compaction strategy.
what about the case that both if's are `false` -- can this happen? If not, we should throw an exception
For compatibility, the mbean needs to be `kafka.controller:type=KafkaController,name=GlobalPartitionCount`. That means you need to pass "KafkaController" here instead of "ReplicationControlManager".
Seems like a lot of the changes in these files are just re-spacing? Not sure if we want to do this, although it is a pain that they are 2-space indented matching the Scala code despite being java files. In particular, there are at least a couple where the imports haven't even changed (which is why I'd expect them to make it into this patch).
nit: fix doc
There are no ..
Ok, we can keep this as its.
If you need to assert that _at least_ `numTasks` are running, probably it's safer to use `>=` here. If you are starting more than 1 tasks, these tasks might start fast enough and you might miss your assertion, e.g. the number will go from 0 to 4. Again assuming that your assertion is that _at least the connector and 1 task are running_.
likewise, this one can be static
Update return type to `L` (if we introduce `L`)
nit: move `process()` to next line (easier to read)
For another, it seems to me "null" is more suitable than empty string.
Ack, thanks for the explanation.
Will do. My question regarding the null setting was about the DBOptions & ColumnFamilyOptions in RocksDBGenericOptionsToDbOptionsColumnFamilyOptionsAdapter, why they are not set to null too. As for the long name, it's probably a german language thing ;-)
Exception message doesn't look right (the word "list").
```suggestion public static void addAvgAndSumMetricsToSensor(final Sensor sensor, ```
If logger.error call does not result in an exception, the test will fail anyway because of expected RuntimeException. If an exception is thrown, this line is not executed
I would rename it to `REPLACE_STREAM_THREAD`.
I submitted a PR for KAFKA-2711. I think we do need clientPrincipalName, and I hope this is clearer with the changes in that PR: https://github.com/apache/kafka/pull/390
Doing this would also make the compile complain about all instances that instantiate MetricNameTemplates with a non-order-preserving Set, which I think is what we want. As it currently is implemented in the PR, I don't think the compile actually catches anything.
For your consideration: message could be more direct . `Is this a plaintext response?` --> `The broker expects SSL, is your client configured for SSL correctly?` (or something of that nature)
He means that you don't need an `else` in this case.
It will be worth mentioning that it includes the root cause since this is in `Utils`.
Typo: "which not matches with"
not required after `<pre></pre>` block
nit: fits in one line
no worries. fyi, you still can, you just define a local function that has your check logic. you can `def foo()` anywhere.
Could be simplified as `topicManager.makeReady(Collections.singletonMap(leaderNotAvailableTopic, internalTopicConfig));`
It turns out that passing the size of the destination array makes `toArray` slower, so passing `0` is both more concise and faster. Source: https://shipilev.net/blog/2016/arrays-wisdom-ancients
I don't think it's safe to reuse `nowMs` here since we may have blocked on `free.allocate`.
This is for possible future extensibility if we want to add new fields: with raw types (map) we'd have to change the signature of the API.
This should be `CLIENT_DNS_LOOKUP_CONFIG` since other configs have that suffix.
I wonder if distinguishing like that, with `null` and `empty` pays off. Why not return an empty collection in both cases and simplify the checks on the return values of this method? This method doesn't seem to be the one to use when somebody wants to determine whether a topic exists or not.
Since all stores will be at least wrapped with `MeteredXXStore` we can add the error handling only at the metered store layer to be consistent. Besides, the inner `RocksDBSessionStore` would actually be `<Bytes, byte[]>` typed always, so this would not help. Same for the RocksDBWindowStorebelow.
But currently we call `advanceNowAndComputeLatency` pretty much at the end of the `maybeCommit` method, so there shouldn't be a noticeable difference between advancing `now` at the end of `maybeCommit` vs advancing it immediately after `maybeCommit` returns, right? I'm also ok with just advancing `now` inside `maybeCommit`. The main thing that felt off was just that we compute the latency for no reason inside `maybeCommit`, and ignore the result
On second thought, I'm fine with keeping the predicate.
I was going to ask why we're using the `test` prefix for a benchmark, but then I realized that many of the kafka benchmarks do that and I somehow didn't notice. :) Given that, it seems fine to leave it like this for now.
Can you elaborate? Why is ``` You can increase the producer configs `retries` and `retry.backoff.ms` to avoid this error. ``` not suitable for a `RetriableException`? (With "current" I referred to the old/existing one, not the updated/new one.) As said above, I think it would be best to have two hints -- one for timeout, and one for all other retriable cases. Thus, we would add a second hint.
Not sure this makes sense. I'd expect we'd attempt to retry the metadata request if needed (e.g. to find the leader). I'm guessing this logic was copied from deleteRecords? We could possibly leave this as a follow-up and fix both APIs at the same time. If we don't fix it, it would be a regression in the consumer group tool because the consumer's list offset APIs have proper retry logic.
I think parameterize this class with `eos-alpha` and `eos-beta` is a better idea --- for some tests that do not rely on the flag and hence would be a duplicated one, we can move it to a separate non-parameterized class.
Ditto here, we should retain some version of this test and any others that are specifically intending to test the behavior of the old API (until the deprecation period has elapsed and we can remove it)
nit: add `final`
Why does it have the same issue if added to `MaterializedInternal`? ``` class MaterializedInternal extends Materialized { protected MaterializedInternal(final Materialized m) { super(m); // } public static MaterializedInternal fromMaterialized(final Materialized m) { return new MaterializedInternal(m); } } ```
We can use the dev version of the tool on the Kafka node via code like this: ``` node = self.kafka.nodes[0] cmd = ("%s org.apache.kafka.tools.ClientCompatibilityTest " "--bootstrap-server %s " "--num-cluster-nodes %d " "--topic %s " % (self.dev_script_path, self.kafka.bootstrap_servers(), len(self.kafka.nodes), list(self.topics.keys())[0])) ``` And then further down we can define the DEV script path like this: ``` # Always use the latest version of org.apache.kafka.tools.ClientCompatibilityTest # so store away the path to the DEV version before we set the Kafka version self.dev_script_path = self.kafka.path.script("kafka-run-class.sh", self.kafka.nodes[0]) self.kafka.set_version(KafkaVersion(broker_version)) ``` I tested this locally and it solves the problem.
We need to turn off OP_WRITE when saslServer is complete.
`szTest` is a terrible test name: `shouldThrowTopologyExceptionIfTaskCreatedForUnknownTopic`
This is Linux-specific (and even potentially Linux-version-specific). We should not fail the test if this doesn't succeed. Let's catch the error and log it, but continue, in that case.
nit: unnecessary newlines
Thanks, all. This doesn't seem like the best way to verify what we're trying to verify, but it also seems about the same as before. I'm happy to leave this here for now. If/when the test breaks again, I'd prefer for us to put in a more reliable and direct mechanism.
nit: due to **partition** lost
There was also a test failure that seems to show that this may not be the right fix.
It's not critical, but you might want to catch any exceptions from this `project` call and wrap them in another `SchemaProjectorException` so you can include info about which field failed projection.
nit: this can be simplified to `LONG_DESERIALIZER.deserialize(rawTimestamp(..))`.
nit: additional new line
By doing so we do not need to change the current APIs at all.
This issue might resolve itself if you get rid of the `KTableSource` processor (the purpose of `KTableSource` is to model the case when a topic is consumed as table).
Fair enough. Probably the risk of users accidentally subscribing to the offsets topic offsets any inconvenience for users who are actually trying to do so.
Just want to point out that this assumes all controllers are voters. It would be worth a follow-up to support controllers as observers as well.
I would remove `<` and `>` here in replace with `"... value=" + expectedValue + "..." ` -- we used `<>` just to mark a `<k,v>` pair, but not required for value itself (cf. different of `compareValueTimestamp` and `compareKeyValueTimestamp`) missing space before `but`
```suggestion import java.util.Map; ```
nit: doc how the output of `iperf` looks like. helps with understanding this code and regex.
Sounds good. Would be helpful for users to understand. The exception message should explain what they need to do to avoid the exception.
```suggestion final JoinedInternal<K, V, VO> joinedInternal = new JoinedInternal<>(joined); ```
Just a minor nit. Using "(admin)" instead of "admin" as you have already done for the others admin client related messages.
nit: this seems unnecessary. We're already using the constant below anyway.
prop: - Remove `Target` - `thread` -> `stream thread`
```suggestion // This characterizes the production of tombstone messages when Json schemas is not enabled ```
This check existed before in the original KIP-19 patch but was removed to address https://issues.apache.org/jira/browse/KAFKA-2805. I am not sure if it should be added back.
Here are the current bulk loading configs: ``` dbOptions.setMaxBackgroundFlushes(4); columnFamilyOptions.setDisableAutoCompactions(true); columnFamilyOptions.setLevel0FileNumCompactionTrigger(1 << 30); columnFamilyOptions.setLevel0SlowdownWritesTrigger(1 << 30); columnFamilyOptions.setLevel0StopWritesTrigger(1 << 30); ``` Setting aside the problems these are causing users [even for active tasks](https://issues.apache.org/jira/browse/KAFKA-9062), they basically mean "shove everything into the lowest file level and never attempt to limit these writes". This is useful if you're just trying to shove a lot of data into a store as fast as possible but not necessary need to use it immediately after, which is (debatably) the right thing for restoring tasks but definitely not appropriate for standbys*. We will attempt to restore a batch of records once per main thread loop, which means doing a lot of other stuff in between. There's no reason not to just use normal mode writing for standbys AFAICT -- also bulk loading will make IQ on standbys pretty annoying at best. *In the larger scope, perhaps when we move standbys to a separate thread, I'd say we actually should be turning on bulk loading. BUT we need to issue a manual compaction every so often, and ideally not flush them during every commit (related to [KAFKA-9450](https://issues.apache.org/jira/browse/KAFKA-9450)
```suggestion // If a task was previously assigned to a client that that is caught-up and still exists, give it back ```
Not sure if it's related, but there was a bug in `SslTransportLayer` that was fixed yesterday that would cause the producer to time out sometimes while waiting for metadata response: https://issues.apache.org/jira/browse/KAFKA-2801
`encodingValue` can still be null right, as `configs.get(..)` could still return a null.
Suggestion: ```suggestion final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingDisabled(); ```
```suggestion // when the interval has elapsed we should try to update the limit offset for standbys reading from // a source changelog with the new committed offset, unless there are no buffered records since // we only need the limit when processing new records ```
This should be the same unit as the unit in `Rate`, right? If so, I think someone could create Rate as: ```new Rate(TimeUnit.MILLISECONDS, new TokenBucket())``` Or ```new Rate(new TokenBucket(TimeUnit.MILLISECONDS))```
This TODO should be removed
nit: unneeded newlines
Thanks for cleaning up the variable names ð
Hmm... in this case not sure whether we actually need a sentinel. What we want is the earliest time after which we can send the request. And by definition this value should always exist, i.e. it won't be undefined. By default it will be 0 which means we can send request anytime. Anyway, this is an internal variable and I don't have a strong opinion. I will let you decide this :)
We should not use `MockProcessorSupplier` but write the result into an output topic and use a `TestOutputTopic` for verification of the result (the `MockProcessorSupplier` should be removed completely mid-term...)
```suggestion /** * Names of the state stores assigned to standby tasks of the Streams client. * * @return names of the state stores assigned to standby tasks */ ```
For my benefit: what is the reason for removing this? I also don't understand the related change in this file.
I think it does do trimming for the splits, based on the regex that's used for the splitting. I tried out a few local examples and they seemed to confirm this; parsing something like `" \t foo \t, \tbar\t , b a z "` returned the list `["foo", "bar", "b a z"]` for me.
Do we need to shutdown the dead stream thread? `completeShutDown()` will be called anyways.
Same thought as above.
I don't think we have examples in Connect where we refer to an argument in the name of a method. Maybe we don't want to change this just yet with the opportunity of the changes introduced by this feature. Another observation is that we don't use `get`, `set` and possibly `build`. But since it wouldn't be obvious if it's an action or an object maybe leaving `buildRestartPlan` might be fine here. (`restartPlan` would be the alternative)
If this code was only called from tests, then channels would remain in `explicitlyMutedChannels` forever :-) It is actually called by the broker - mute/unmute to control reading from the channel and hence the need to track explicitly muted channels.
This test case doesn't seem different than `testInvalidRecordSize`.
Just ran some more tests locally to confirm my suspicion.
Note to future me: I didn't get this far in the PR.
You can actually use "{}" here for the prefix. Slf4j supports this: http://slf4j.org/faq.html#paramException. Same for the other cases.
I think I'd remove it or at least tag it as an integration test.
nit: remove `this`
nit: space 4 after `=`
If there any case for which we would pass a non-null valueSerde here? If not, we should remove the parameter entirely.
Does it make sense to do this check before the epoch validation? If we're not the leader and received an old epoch (which, if i understand, seems likely if we're _not_ the leader anymore), we will silently ignore in the above case.
Should we also handle the corrupted tasks here (before this line), so that they can be already cleaned up before the next round? Or, alternatively, should we move `taskManager.handleCorruption(e.corruptedTaskWithChangelogs());` to before the attempted commit (it looks like it could be outside the try block as well).
This seems overly complicated. An easier structure to follow would be something like this: ```java String expectedType = "KafkaController"; Set<String> expectedMetricNames = Utils.mkSet( "ActiveControllerCount", "GlobalTopicCount", "GlobalPartitionCount", "OfflinePartitionsCount", "PreferredReplicaImbalanceCount" ); MetricsRegistry registry = new MetricsRegistry(); try (QuorumControllerMetrics quorumControllerMetrics = new QuorumControllerMetrics(registry)) { assertMetricsCreated(registry, expectedMetricNames); } assertMetricsRemoved(registry, expectedMetricNames); ```
```suggestion .getStore(300_000L, storeName, streams, QueryableStoreTypes.keyValueStore()); ```
nit ```suggestion private static final long RETENTION_PERIOD = 10_000L; ```
nit: As key and value is accessed, we might want to iterate throw the `.entrySet` instead of `keySet`
The map is not used.
Nit: since we require a non-null `Duration`, we should state that here: ```suggestion * @param timeoutDuration timeout duration; may not be null ```
Can we use `assertThat(node.name, equalTo("source1")` or `assertEquals("source1", node.name)` instead of `assertTrue` for assertions like this? Elsewhere in this test, too
Hmm, are security configs really relevant here if we don't do anything with ACLs? Seems like a lot of parameterizations here and we already get coverage from the `test_file_source_and_sink`? In general we've started to be more careful about a ton of parameterizations and covering more within each test since the setup/teardown costs can be quite substantial.
We should fix right away -- otherwise it might slip.
nit: one space.
nit `{@link org.apache.kafka.common.serialization.Serdes#Long()}` -> `{@link org.apache.kafka.common.serialization.Serdes#Long() Serdes#Long()}`
Checkstyle fails because it expects indentations to be 4 spaces
All nodes in the cluster have access to the global connector configuration and can respond to REST apis, but the `Worker` class only tracks the connectors being executed on that particular node. To find the type of a connector which is not executing on that node, we probably have to pull the classname out of the config using `ConnectorConfig.CONNECTOR_CLASS_CONFIG`.
Seems like "topic won't be created" is specific to one of the requests.
retainLatest() and this method have a lot in common. We could potentially refactor it, but not too concerned if its left as-is.
Should we avoid calling `recordCollector.close()` unless `eosEnabled`? It seems like this block used to be guarded by `if(eosEnabled)`, but it's not anymore.
partitions is not used
```suggestion byte[] value = valueConverter.fromConnectData(topic, record.valueSchema(), record.value()); ```
"If no selection operation is currently in progress then the next invocation of one of these methods will return immediately unless the selectNow() method is invoked in the meantime." I read that to mean that that `poll(Long.MAX_VALUE)` will not return immediately since a `selectNow` was invoked in the meantime . Might be worth a unit test to verify that it works as expected.
Minor nit, but I think something like this would be more accurate/complete. Applies to this and the broker config. What do you think? If the `MAX_COMPACTION_LAG_MS_CONFIG` or the `MIN_COMPACTION_LAG_MS_CONFIG` configurations are also specified, then the log compactor considers the log eligible for compaction as soon as either: (i) the dirty ratio threshold has been met and the log has had dirty (uncompacted) records for at least the `MIN_COMPACTION_LAG_MS_CONFIG` duration, or (ii) if the log has had dirty (uncompacted) records for at most the `MAX_COMPACTION_LAG_MS_CONFIG` period.
nit: `if (sum = value) else (sum += value)`
Hmm.. Might not be too important, but it doesn't seem necessary to include the retry backoff in this check. If the user sets retries=0, then the backoff shouldn't matter.
nit: this can be `private synchronized Optional...` and we wouldn't need the synchronized block below
I think keeping it in nested condition is fine, even further, I think `if (receivedAssignmentMetadataVersion < 3)` should not happen since in this case the leader should have failed and not returning anything, so we can add an `else` to throw RTE to make it more strict.
I think it would be good to check that the registry doesn't already have something registered before we do this (since otherwise we'll be overwriting whatever that is).
to be differentiate from the previous error log: `base state directory ...`
We don't need to call `toString()`
nit: Seeing the line right above, one would think this fits in one line
In a batch of records, if the first record failed, it will cause all the rest record's callback to add a warn entry and hence swamp the log file. I feel it is better to just modify line 95 to sth. like "error sending to topic and partition, will not updating offset of this partition anymore and this exception should be eventually thrown to the user".
Not sure how using Collection would really help -- the element type for Maps would be `Entry<TopicPartition, OffsetAndMetadata>`, which won't implement any useful interface that would be interchangeable with a `List<OffsetCommitInfo>` where the `OffsetCommitInfo` contains both the topic partition and the offset and metadata. For mutability, in Copycat I just handled this at the application level -- subsequent updates are handled in a secondary map and they are merged once the commit completes. Would be nice to avoid having to do this if possible.
Instead of adding a new setDeleteHorizonMs() method, would it be better to just add another constructor for MemoryRecordsBuilder that includes DeleteHorizonMs? This way, it's more consistent with how DeleteHorizonMs is set in another classes.
Hmm, it seems that we should only do `newLeader != partitionInfo.preferredReplica()` if this is a preferred leader election.
I was more thinking about 1000 stateful tasks, because the task offset sums might also inflate the subscription.
I think you also need to remove the trailing `{}`. Exceptions get logged without requiring anything in the formatter string if they are the last trailing argument.
When the user calls subscribe(), we should set a flag in SubscriptionState saying that a rebalance is needed. As of yet, the user's assignment hasn't changed. When the user calls poll(), we check the flag and begin the rebalance. Once the rebalance completes, we set the new assignment and begin fetching. I'm not sure I see a way for any fetches from the old assignment to reach the user.
Nit: including "execute" here is completely unnecessary. ```suggestion log.warn("Attempt {} to {} resulted in RetriableException; retrying automatically. " + ```
Yeah, I can't think of a strong reason for either option, so I guess we can leave it here.
Instead of having an `else` with a nested `if/else`, we could keep it flat: ```scala if (fileAlreadyExists) ... else if (preallocate) ... else ... ```
please see my earlier remark about localizing as much as possible and adding a tear-down.
Why do we need this check? It seem that `parentNode` cannot be `null`, and that it would be `this` always, too? (assuming one parent node, what is not generic)
We should add a similar check for `TransformerSuppliers` -- This check must be done in the DSL code though, as `Transformers` are a higher level concept. I checked the code and all passed transformers through https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/kstream/internals/KStreamImpl.java#L1251 -- so we can add the check there.
nit: `this` is not really needed, since it's not ambiguous here as in constructor,
```suggestion Utils.closeQuietly(retryWithToleranceOperator, "retry operator"); ```
> I think cleanest the way to do it backwards compatibly is to introduce a new store hierarchy and deprecate the old one. I am afraid that might be the only way to do it -- deprecation hell -- users won't be happy -- thus we should think hard if it's worth to do or not...
OK, I overlooked that the overload of `requireNonNull` without the message is used in the code under test. However, I think it would be better to use the overload with message, i.e., ``` public static <T> T requireNonNull(T obj, String message) ```
The reason I ask is that I was expecting this would be implemented with a `ConfigDef` validator, but I didn't see one defined.
Ah - you are not doubling the elapsed time because you are actually doing a modulo on the window size. That said, I think the current code should still be correct. Note that in your test you haven't actually created three samples because you didn't call record at the 60 second or later mark. i.e., if you debug through you will find only two samples. So the "current" time is taken off now minus the `lastWindowMs` of the "current" sample which is the second sample and that ends up being 105 seconds for me (which is correct because the current sample has not rolled over due to the absence of a record).
No reformatting, please
I think this `if` block can be written this way too so we can avoid the extra nesting (since Java performs short-circuit evaluation for `&&` and `||`): ``` if (subscriptions.isAssigned(tp) && subscriptions.isOffsetResetNeeded(tp) && !resetOffset(tp)) failedPartitions.add(tp); ```
We have a `org.apache.kafka.streams.internals.QuietStreamsConfig` to use.
We can use `assertThrows` here.
I think the invariant that we try to maintain is that we should have a position if we are in the FETCHING state. I'd suggest we detect this in `transitionState` and raise the exception at that point. Otherwise, we could reach an illegal state and the consumer would just stop fetching the partition. Failing fast is probably preferable. What I have in mind is just something like this: ```java private void transitionState(FetchState newState, Runnable runIfTransitioned) { FetchState nextState = this.fetchState.transitionTo(newState); if (nextState.equals(newState)) { if (position == null && (nextState == FETCHING || nextState == AWAIT_VALIDATION)) throw new IllegalStateException(); this.fetchState = nextState; runIfTransitioned.run(); } } ```
There is an extra unnecessary space.
@rajinisivaram Can you please double check if these methods can actually return `null`? It looked to me like they would not, but I didn't look deeply.
Same question here as earlier about the `Locale`
Looks like txn.id timeout is 1 min as of current: ```val coordinatorEpochAndMetadata = txnManager.getTransactionState(transactionalId).right.flatMap { case None => val producerId = producerIdManager.generateProducerId() val createdMetadata = new TransactionMetadata(transactionalId = transactionalId, producerId = producerId, lastProducerId = RecordBatch.NO_PRODUCER_ID, producerEpoch = RecordBatch.NO_PRODUCER_EPOCH, lastProducerEpoch = RecordBatch.NO_PRODUCER_EPOCH, txnTimeoutMs = transactionTimeoutMs, state = Empty, topicPartitions = collection.mutable.Set.empty[TopicPartition], txnLastUpdateTimestamp = time.milliseconds()) txnManager.putTransactionStateIfNotExists(createdMetadata) ``` As we are also considering setting the txn timeout to 10 seconds, this might be a real problem
nit: remove empty line
Might be better to just propagate the exception and fail. We wouldn't expect to actually hit this in practice.
nit: We could use `assertNull` here and in the other tests when the future returns `null`.
Check TROGDOR.md. > All Trogdor RPCs are idempotent except the shutdown requests. Sending an idempotent RPC twice in a row has the same effect as sending the RPC once. Because the request is idempotent, sending it twice has the same effect, including the same result code.
This is the JIRA describing the motivation, just FYI: https://issues.apache.org/jira/browse/KAFKA-3519
Should we set `lastRecord` to null here? Otherwise it seems like we might misinterpret which record had the error.
Rather than do this bookkeeping here, could we pass the `ErrorHandlingMetrics` instance to the `WorkerTask` class in its constructor, and then close it in `WorkerTask::removeMetrics`? It'd align nicely with the existing contract for that method, which is that it will "Remove all metrics published by this task."
No, I mean something like: ```java String mBeanName = getMBeanName(prefix, metricName); KafkaMbean mbean = removeAttribute(metric, mBeanName); ... ```
Not important -- just look funky to me. We concatenate multiple strings and thus all should have the same indent -- why would we indent the first differently? I would format as follows (even if I know that you don't like that the plus goes into the next line): ``` "string1" + "string2" + "string3" ``` This avoid the "ambiguity", of multiple string parameters, vs one concatenated parameter: ``` method( "param1", "param2", "param3", "param4"); // vs method( "param-part-1" + "param-part-2" + "param-part-3", "new-param"); // vs method( "param-part-1" + "param-part-2" + "param-part-3", "new-param"); ``` Thirst and second hard hard to distinguish (where do parameters start/stop), but third makes it clear, that it's two parameters but not one or four, what is hard to tell in the middle case. Of course, double indent also fixes this but it's weird to me: ``` method( "param-part-1" + "param-part-2" + "param-part-3", "new-param"); ```
nit: insert empty line
Thanks @dguy. That makes sense. @original-brownbear, maybe you can do a follow-up that does that.
This is a blocking call, and @guozhangwang just proposed KIP-520 to make it more efficient by allowing to pass in multiple partitions at once. Should we wait for KIP-520 to be implemented? If now, we should make sure the update this code after KIP-520 is merged. I am also wondering how we should handle `TimeoutException` for this call? Maybe not, but might be worth to clarify? \cc @guozhangwang
super nit: should we assert greater than `0.0`? But I don't have a strong opinion here though.
nit: some extra newlines here.
Should be final
We should create this table from a stream. Otherwise we don't verify that `toTable()` does materialize the table (as required if used in a foreign key join) automatically. (ie, `toTable()` should not take a `Materialized` parameter in this test, but the join must still work).
Yep, i understand there are other `assertNextOutputRecord` methods. I'd probably replace them too (not in this PR!) . I feel using `assertThat` is better in this case as we are just comparing the `ProducerRecord`. I don't see the need to have a method with multiple assertions when it can all be done in a single assertion.
Isn't this the same as: ``` clientsPerTagValue.computeIfAbsent(tagValue, (ignored) -> new HashSet<>()).add(clientId); ```
Since these exception messages are unrelated to the bug you're fixing, it would be better to leave the inconsistent punctuation for another PR.
It's not required to protect the await, but is to get the logging.
Does this work for you? I think you need `-E` instead of `-e` to have a regex in sed.
We typically use `(` instead of `{` for `toString` (although there is some inconsistency.
as before, this could be if-then-else without the increment below for the `if` case.
On a second thought, it might also be relevant for production code since we now can restart the stream thread after a fatal error. This is not yet possible for a global stream thread, but it might be possible in future.
I think we cannot just pass in `null` and rely on default serde types from configs, since users are not expecting the repartition to happen here from the DSL, and they thought they have provided enough serde informations on places they "think" a repartition will happen. So observing a `ClassCastException` at a place they are not expected would be a bad experience. As of now, without serde inheritance we may have to "restrict" the optimization, to only apply to cases where two or more repartition nodes are direct children of the common key-changing parent node. Moving forward we can consider the options @bbejeck provided, and personally I think serde inheritance would be a good place to start.
Seems like we should use `3L` instead. The leader would not have been able to advance the high watermark past the fetch offset of `3L`.
We need to override the `newRecord(...)` that has all the parameters: ```suggestion public InternalSinkRecord(ConsumerRecord<byte[], byte[]> originalRecord, SinkRecord record) { this(originalRecord, record.topic(), record.kafkaPartition(), record.keySchema(), record.key(), record.valueSchema(), record.value(), record.kafkaOffset(), record.timestamp(), record.timestampType(), record.headers()); } public InternalSinkRecord(ConsumerRecord<byte[], byte[]> originalRecord, String topic, int partition, Schema keySchema, Object key, Schema valueSchema, Object value, long kafkaOffset, Long timestamp, TimestampType timestampType, Iterable<Header> headers ) { super(topic, partition, keySchema, key, valueSchema, value, kafkaOffset, timestamp, timestampType, headers); this.originalRecord = originalRecord; } @Override public SinkRecord newRecord(String topic, Integer kafkaPartition, Schema keySchema, Object key, Schema valueSchema, Object value, Long timestamp, Iterable<Header> headers) { return new InternalSinkRecord(originalRecord, topic, kafkaPartition, keySchema, key, valueSchema, value, kafkaOffset(), timestamp, timestampType(), headers()); } ```
`InvalidTopicException` indicates that the topic name itself is invalid, not that it collides with another topic name
)by -> ) by (space needed)
recommend sticking with T, U, V (or A, B, C for higher-kinded) type parameters
Changing the test to expect a failure.
Since the usage is a bit different, maybe we could change the name to `requiresPosition`. Then this check seems a little more intuitive: ```java if (this.position == null && nextState.requiresPosition()) { throw new IllegalStateException("Transitioned subscription state to " + nextState + ", but position is null"); } ```
Can we actually wrap the whole `testProcessorRandomInput` test in the try-catch? Or at least, everything after the initial setup? Would be nice to have the seed in case something weird happens during the processing itself
I don't think we consider `SslFactory` a public API, so I think we are probably good here.
If you guys are not feeling strong, then let's just do this :)
```suggestion // This characterizes the production of tombstone messages when Json schemas is enabled ```
nit: `If subscribe is called previously with pattern, or assign is called previously.` This is to make the explanation more concrete. Ditto below.
For TaskCreator and TaskManager here's my thoughts: ideally the taskCreators could be constructed inside task-manager, but for unit testings we want to mock the creators sometimes so we create them outside of task-manager, inside stream-thread. So for this special case I think passing the ProcessMode into these two classes are okay, since for most other cases the hierarchy is natural and we would only see the construction of such parameters in a single place.
i'd prefer we use asserThat, i.e., `assertThat(value, equalTo(deserializer.deserialize(...))`
nit: could be simplified as `eosEnabled`
I see. So we exploit that possible state transitions are limited. Thanks for explaining. Makes sense.
I would disable auto-formatting...
I'm not sure these add value since TransformationChain has log messages with the records, which should be sufficient to know whether the schemas are null.
It seems that t is never null. So perhaps it's simpler to just start the thread after t is created.
looks like we don't have any matching prefixed ACLs for this resource. It is good to add few matching prefixed ACLs
We should connect the state stores with this request processor instead of enforcing us to remember which processor to set while initializing. E.g. here we can do (note I removed the procNames): ``` private void doTestValueGetter(final StreamsBuilder builder, final KTableImpl<String, Integer, Integer> table2, final KTableImpl<String, Integer, Integer> table3, final String topic1) { final Topology topology = builder.build(); KTableValueGetterSupplier<String, Integer> getterSupplier2 = table2.valueGetterSupplier(); KTableValueGetterSupplier<String, Integer> getterSupplier3 = table3.valueGetterSupplier(); InternalTopologyBuilder topologyBuilder = TopologyWrapper.getInternalTopologyBuilder(topology); topologyBuilder.connectProcessorAndStateStores(table2.name, getterSupplier2.storeNames()); topologyBuilder.connectProcessorAndStateStores(table3.name, getterSupplier3.storeNames()); try (final TopologyTestDriverWrapper driver = new TopologyTestDriverWrapper(topology, props)) { KTableValueGetter<String, Integer> getter2 = getterSupplier2.get(); KTableValueGetter<String, Integer> getter3 = getterSupplier3.get(); getter2.init(driver.getProcessorContext(table2.name)); getter3.init(driver.getProcessorContext(table3.name)); // same below ``` Ditto elsewhere for initializing the getters.
In the case of the error code, I think it might be better to be explicit.
nope, that's not possible
What is the motivation for this change? It seems a little odd that we update the fetch positions for all assigned partitions if the position for one partition is `null`.
Would it be possible to extract test code in this class and `RocksDBRangeIteratorTest` that actually tests code in class `RocksDbIterator` to a test class `RocksDbIteratorTest`. I think that would make the code more maintainable.
Why the wording is different for this function and the one above? I think no matter if it is windowed or not the return KTable object should have similar semantics, but only different on windowed or not.
Is the `try-catch` still needed here? And is it possible that some `Exception` be thrown from `restoreCallback.restoreAll` below? If yes we need to think if we want to handle it here, or in higher-levels of the call trace.
I think most (all?) of these assertions are very obvious and the long text is just repeating the code. Does the text add value of is it just noise? Also, the lines should not be longer than the GitHub review window.
Same as above, I'd prefix with "Implementation detail: ..."
This should be called `topicExists` or something like that. `newTopicName` then becomes `topicName`. The variables inside the method should also be changed and the exception should include the variable, not a hardcoded value.
nit: ... suspended task is not reassigned
`MockProcessor` does not support callbacks...
I filed this: https://issues.apache.org/jira/browse/KAFKA-13235.
@vvcephei we should fix the return statement -- should not be empty
I guess doing this incrementally will not work. What about one (or multiple) PR that add `final` wherever possible over all files (maybe package by package to split it up in multiple PRs)? It's dumb work, but I would volunteer... If we do in incrementally, it also distracts from actual code changes for a PR and add noise that makes reviewing harder.
nit: let's keep calling this `savedLoader` as in the other places where we call this method because: a) naming consistency might pay off here more than elsewhere, b) calling it old might be misleading because you are keeping the reference because you want to restore it somewhere (rather than replace it as "old" would imply)
I believe the messages is in correct - it is the whole partitions for which any offsets are not committed. `log.warn("Synchronous auto-commit of offsets for partitions {} will be abandoned", toGiveUpTopicPartitions);`
the naming used above seems better here ```suggestion Throwable exception = null; ```
I think we can just keep the logic to maintain the topic-partition set and not exposing tasks instead, the key is that in `rebuildMetadata`, we can still reconstruct the topic-partition set. What I have in mind is the following: 1) we remember the `final Map<TaskId, Set<TopicPartition>> partitionsForTask = partitionGrouper.partitionGroups(sourceTopicsByGroup, fullMetadata);` constructed from StreamPartitionAssignor at the `StreamsMetadataState`. This can be pass via the `assignor -> taskManager -> streamMetadataState`, i.e. at `setPartitionsByHostState` we pass in both `tasksByHosts` and `partitionsForTask`. 2) And then at `rebuildMetadata` we can get the `Set<TopicPartition>` from `taskId` directly.
Here and everywhere else. Got doesn't sound right. Maybe something like: `shouldThrowOnInitTransactionIfProducerIsClosed`
Why we need an atomic long here? Seems there's no concurrency.
Also, does the below `assertEquals` not subsume the `assortNotNull` ? Seems redundant to check for not-null first.
Just a nitpick. It doesn't need to be a object method as it doesn't use any of the instance fields. When reading and maintaining a lot of code it is good to know that a method doesn't use instance fields.
The parameters can be `final`.
Nit: no need newline. Also I think we do not need the `TimeFirstWindowKeySchema.` since it is within this class right? Ditto below.
Probably a tough case to hit in practice, but I can't say it's impossible.
nit: make this string and the one below static final.
The read/write of ```closed``` must be in lock so this improvement is not acceptable to ```BufferPool```.
nit: sufficient to implement `NameSuppressed` now only
Do you want to pass in `autoAdvanceMs` for record creation? Default is zero.
That is expected. You need to add a member variable `ProcessorContext context` to the class and assign `this.context = context` in `init()`. In `transform()` you can use `context.timestamp()` to get the current timestamp.
Please use a collection with at least two topics to test the loop over the collections.
Nit: `A method for...` (as above)
Ah, you are right. Sorry.
Please use 4 spaces instead of 8 for indentation. Same applies to the changes below.
There might be a few cases where we used `Connector` when creating the mock if it didn't previously matter to the test. e.g. https://github.com/apache/kafka/blob/trunk/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/distributed/DistributedHerderTest.java#L355 is one case I can find. https://github.com/apache/kafka/blob/trunk/connect/runtime/src/test/java/org/apache/kafka/connect/runtime/standalone/StandaloneHerderTest.java#L635 might be another case, where we used Connector since I think both source and sink tests might use that same code. I guess the `Class.forName` is probably ok since we've swapped in the correct `ClassLoader` at this point, though not really ideal as we're doing more lookups when we already have the instance of the connector. I think it would be better to fix the tests (though I'm not sure off the top of my head how many changes this will require...)
I know this is only a test class, but returning `Collections.emptyMap()` would be the nicer thing to do here
this four lines can just be one line: `Topics.validate(topicName)`
My bad, I thought the `upgradePhase-Starting a REBALANCE` message is used somewhere in verification and thought with the augmented log4j it can now be replaced, but now I see it is only for debugging purposes.
This scenario can happen when a rebalance migrates some tasks from one thread to another, within the same process / JVM. And I think we should still try to close the channel while shutting down the processor state manager, since otherwise the number of channels will just grow indefinitely due to rebalances that move tasks around, although very slowly.
Below, maybeWaitForPartitionsAssignment() may add new assignedMetaPartitions. We need to seek those partitions from the beginning.
Could also be neither. Error message should be fixed
I believe that a call to `DeleteRecords` can advance the start offset to an arbitrary offset which could be in the middle of a batch. I do not think today that we have any hard guarantees that we won't return batches or even records that are lower than the current log start offset. It might be worth experimenting with this to clarify what the behavior is today. With that said, given the fact that we always return the whole batch anyway, my preference would probably be to try and keep the log start offset aligned on a batch boundary.
nit: add `final`
Minor style point: I'd probably put as a method inside ZK, but that's a bit subjective really.
A verb is normally expected following 'if no xx' How about naming this test: shouldGetSerdesFromConfigWithouUserSerdes
Seems like `handleCompletedMetadataResponse` also needs to be updated.
If `valueAndTimestamp != null` should this be `max(valueAndTimestamp.timestamp(), context.timestamp())`
I believe that Java (or the ALU) will do exactly the same thing whether you say `maxPollTimeMs >> 1` or `maxPollTimeMs / 2`, but your human colleagues might appreciate the latter ;)
Ah right. I can't think of a better way neither.
Shouldn't the first argument be `KeyValueMapper<K, V, K1> selector`? We only care the aggregation key.
If the serialization failed we wrap it as a StreamsException -- with this PR it seems a regression that we do not do it any more.
I'd suggest to use a more descriptive test name, e.g. in the form of `shouldDoXYZ`.
nit: Maybe update the message to "Max retries maxRetries for <call> reached."
For functions that include the StreamPartitioner instance, better add "... and a customizable {@link StreamPartitioner} to determine the distribution of records to partitions".
I was looking up the format in more detail and understand now what going on. The code does not seem to be ideal IMHO, but no need to change it in this PR.
Let's avoid TODOs in the code. We can point to the relevant part of the code in the JIRA.
nit `getMetadata` -> get`
nit: weird alignment
This should be in the "assigned in `configure`" section of fields.
Was this intentional or just for debugging? Verifiable consumer can generate a huge amount of output, so its pretty risky to save it, especially if we don't have a way to ensure it is at least compressed first. We definitely always need to grab it to do verification, but not necessarily save it by default with the output (which would happen even if the test was successful).
The consistency point is true IIRC -- for `streamTimePunctuationQueue.schedule(schedule);` we also punctuate immediately -- there is hard to change as we would need to consider the timestamp of the very first record we process. I am just thinking, if we should keep the current behavior and put the burden on the user to ignore the very first punctuation call? We had a similar ticket in the passed already, but no conclusion how to proceed: https://issues.apache.org/jira/browse/KAFKA-6092
`checkpointTopicSufficx` -> `checkpointsTopicSuffix`
indicate the client support quota => indicate that the client supports quota
We should also clear the sessionHandlers map here, just for tidiness.
The boolean makes it easier to do the check, but doesn't help with cases where the caller forgets. So the exception is better from that perspective.
This is s repetition of `"data"` case -- similar below -- we should put all int/long/double cases etc together to void code duplication using "case-fall-through" pattern.
Could we let `writeHeader.writeHeader` take the `ByteBufferOuputStream` instead of the `ByteBuffer` as the first parameter to avoid exposing this private function? It seems to be only used here and in the MemoryRecordsBuilder, whose caller has the `bufferStream` at hand as well.
This is really just the timestamp of the previous record, right? Can we call it something that reflects that
I'm still wondering, when the instance state has already been in `not running`, how could the `setState` be still called? Here's my reasoning: 1) `NOT_RUNNING` is set only after all threads have been joined; 2) when a thread has been joined, its state has already been set to `dead`; 3) so after instance's state has been set to `NOT_RUNNING`, `setState` should never been called anymore.
No strong opinion. It's an unlikely case anyway, so I'm not sure it calls for special treatment.
This change is unnecessary.
We shouldn't always use assign here. If the developer has not specified any partitions, we can use the partitions of the group itself.
A record. Same everywhere else An record is mentioned
3 seems quite a small number. It might be good to use 20 or something if there isn't a good reason not to.
I think we should consider add a byte for indicating versions so that we can have better upgrade patch in the future in case we are evolving the serialization format. Similar rationales for versioning RocksDB state files and subscription metadata, or anything that involves serdes.
Nitpick: we typically do this like: ``` java return "KerberosShortNamer(principalToLocalRules = " + principalToLocalRules + ")"; ```
Another nit: you can use == to test enums. It reads a little nicer, but more a matter of preference.
I was not sure if `MaterializedInternal` constructor can be public if `Materialized` constructor is protected. But as it can be, we don't need a static method (that would have been a workaround if `MaterializedInternal` constructor would have been protected, too)
We would like to avoid wildcard import in the code base.
As we've been discussing for other tests, this is not sufficient. I saw topic creation fail and found a leftover mirror maker process still running. Looking at the log from the previous run, it failed with an exception saying the process took too long to exit. I think in this case it might have been because I increased the consumer.timeout.ms, but this is just generally a problem. I think we need to catch the exception and `kill -9` the process if it doesn't exit gracefully.
Since it's put inside test class now, we cat declare it as `private`.
I guess the problem is we don't have a separate principal in tests that we can assign those to. Could we separate out `Create` and `Alter` into another method, so that tests can set them as necessary or would that impact every test? We expect brokers to have only `ClusterAction`, but our docs and generally everyone expects broker to have more permissions. This sort of makes our tests run with a combination of permissions that we never expect a principal to have - broker principal should have only ClusterAction, no one else should have ClusterAction. Separating out into two methods may be better even if we end up using the same principal in tests.
nit: could be set to final and refactor as: ``` final Integer partition; if (partitioner != null) { final List<PartitionInfo> partitions = producer.partitionsFor(topic); if (partitions.size() > 0) { partition = partitioner.partition(topic, key, value, partitions.size()); } else { throw new StreamsException("Could not get partition information for topic '" + topic + "' for task " + taskId + ". This can happen if the topic does not exist."); } } else { partition = null; }
Not sure if this is the best fix. It seems that the issue is that the customized rateStat is only reflected in Rate, but not in total. It seems that we can extend Total to also allow a customizable stat. That way, rate and total can be updated consistently and we don't need customized code in record().
We should consider using the Timer abstraction in the Fetcher methods too.
if you added a method to `NodeFactory` `String[] parents()` then in `SourceNodeFactory` you implement it by returning `new String[0]` This code becomes ``` String[] predecessorNames = nodeFactory.parents() for(final String predecessorName : predecessorNames) { ... } ```
Could also have a cross-reference to `ConsumerRecordTimestampExtractor` that says "If you need event-time semantics, use `ConsumerRecordTimestampExtractor`" or sth like that.
Should this say > client operations that do not explicitly accept a timeout or > client operations that do not specify a timeout
I don't think we can do this. Also, I would only mention it, when we start to deprecate an API.
Can't we just `put`? If there are duplicates (which is rare), we will simply overwrite, no? Same question for other places where we do the same.
I think, we need also remove AdminClient configs, too.
@C0urante, what do you think about doing something like the following instead of the `instanceof` block? ``` Integer rebalanceTimeoutMs = config.getInt(DistributedConfig.REBALANCE_TIMEOUT_MS_CONFIG); if (rebalanceTimeoutMs != null) { herderRequestTimeoutMs = Math.min(herderRequestTimeoutMs, rebalanceTimeoutMs.longValue()); } ``` This still uses the `DistributedConfig.REBALANCE_TIMEOUT_MS_CONFIG`, but otherwise is simply checking for the existence of that property to determine if `herderRequestTimeoutMs` should be set to a new value.
we can also remove the entry in `updatedEndOffsets` if this is true.
should not have an implementation but call overloaded method.
```suggestion return Collections.emptyList(); ```
It seems like we lost the case where we should set the value to the `key.defaultValue`. You more thoroughly handle other cases (deprecated values, no default value), but I think this line was removed and should still be at the tail end of the branches that have been added to this logic.
here it might work better to use `TestUtils.waitForCondition` instead of an arbitrary sleep call
Nit: let's remove this blank line, since there already are quite a few.
This block may be a bit easier to follow if the if-else block sets up the Map of properties that will be used for the config provider properties, and then instantiate them in one place. Something like: ``` Map<String, String> providerConfig; if (configProviders == null || configProviders.isEmpty()) { providerConfigs = indirectVariables; } else { providerConfigs = mapValuesToStrings(configProviders); } Map<String, ConfigProvider providers = instantiateConfigProvider(providerConfigs, originals); if (!providers.isEmpty()) { ... ``` I know the if-else could be simplified further, but I think this is simple to follow.
The priority queue defines priorities primarily based on user defined delays (`addRequest` takes a `delay` as argument. The sequence number should break ties between requests that have the same priority, which is a specific time in the future). Because the priorities depend on user defined delays, such priorities might correspond to the creation time of a request, but this is not required. Thus, `compareTo` needs first to compare deadlines, and if they are equal use the sequence number to break ties.
Is the `thenApply` really necessary here? It seems that `KafkaFuture.allOf(futures.values().toArray(new KafkaFuture[0]))` already returns what we need here.
@ijuma I think this question is addressed below -- pausing partitions in the network thread effectively is backpressure and turns the network thread into a pure heartbeating thread while processing is being performed. You can also, of course, choose to buffer as much or as little as you want by adjusting when you decide to pause the collection. I'd say the current docs explain this well enough, though I think a few code examples (in the somewhat defunct examples jar) would be the most helpful way to show how to make this work in practice.
How about "if the proposed replica assignment is invalid. For example if some of the partitions have different number of replicas or a duplicate replica assignment was found"
We should do this check first
why not just log this stuff at info level? we're not on a performance path (this gets executed once every rebalance right?), and it can always come in handy when you're debugging.
Why do we need this? For custom configs, we don't enforce any restrictions.
wow, I don't think we actually catch the case where the replica set is empty. Let me open a separate PR for this
I'm guessing the root source of this all is a bad assumption that the assignment would be stable if a stable `CLIENT_ID` was used? I remember we discussed that back when you first wrote this test, I'm sorry for any misinformation I supplied based on my own assumption about how the CLIENT_ID would be used :/
I don't think that will work, because the metadata object that is maintained in AdminClientRunnable does not fetch information about any topics. In general the way the Metadata object works is a very poor fit for AdminClient-- it was designed for producers and consumers, where you have long-running subscriptions and so forth. It is much simpler and better just to make the metadata call here-- we can always optimize this later with a cache if needed.
(@thomaslee reminds me that `send()` can throw and then we're left with a dangling reference)
Would it be better to get the value only when the return type is an integer rather than do that when it the type is non-null? For example, something like: ``` Integer rebalanceTimeoutMs = null; if (config.typeOf(DistributedConfig.REBALANCE_TIMEOUT_MS_CONFIG) == ConfigDef.Type.INTEGER) { rebalanceTimeoutMs = config.getInt(DistributedConfig.REBALANCE_TIMEOUT_MS_CONFIG); } ``` This may be a bit easier to read, and it's also going to cast to an integer only if the value actually is an integer.
nit: line too long
I changed the cast to `Long.valueOf`.
We need to add `@SuppressWarnings("deprecation")` to make the build pass.
This logic is not exactly the most straightforward. What about something like this? ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { Versioned versioned; if (pluginImpl != null) { versioned = (Versioned) pluginImpl; } else { versioned = (Versioned) pluginKlass.newInstance(); } return versioned.version(); } return "undefined"; ``` or ``` if (pluginKlass.isAssignableFrom(Versioned.class)) { if (pluginImpl == null) { pluginImpl = pluginKlass.newInstance(); } return ((Versioned) pluginImpl).version(); } return "undefined"; ```
I see. So we should add it elsewhere, too (of course not as part of the IQ work).
Thanks for double checking this! Then it lgtm.
Similarly for `ProcessorNodeTest`: the only difference is that for that test case we can introduce another overloaded constructor for `MockProcessorContext` which takes a `StreamsMetrics` object, and then pass a real `StreamsMetricsImpl` only for that `testMetrics` class while for all others just use the other constructor which always use a `MockStreamsMetrics` object.
There's also an expected error: `PRODUCER_FENCED` which should be handled here.
Strictly speaking not a bug, just kind of confusing. And a reorganization of code could suddenly make this test fail despite it not currently representing realistic behavior. I guess it's a bug in the sense that the mock is not actually expressing the behavior we expect from it.
Sorry for the delay, I suggest we revert this part to properly scope this PR.
we should not hard-code version 3, but programmatically find the highest supported version and send something higher , so that this code doesn't have to be revisited if there is a new version
This condition seems unnecessary complex. Should it not just be: ``` if (mappedKey == null || value == null) { ```
this local variable is redundant
From my understanding, this must either be without the last `{}` or using `e.toString()`? (Cf. https://stackoverflow.com/questions/6371638/slf4j-how-to-log-formatted-message-object-array-exception)
By the way, I think we should also check if the record is so old that even the latest window it could possibly create/affect would be dropped, and then not process the record at all. (ie basically check if the current record's right window would be dropped) We can record on the lateRecordDropSensor and log the message using the current record's left window.
Mainly my goal is to encapsulate as much of this logic in `TransactionManager` as possible to make testing easier. After revisiting this logic, I feel there's a bit of inconsistency and/or redundancy between this check and `TransactionManager.canRetry`, which will return false if the producerId and epoch are not an exact match. As far as I can tell, the only reason this parallel logic exists is because of `Sender.canRetry`, which includes the following: ``` ((response.error.exception() instanceof RetriableException) || (transactionManager != null && transactionManager.canRetry(response, batch))); ``` So we seem to be trying to prevent unsafe retries in the case of a retriable error. I am wondering if we can consolidate this logic in `TransationManager.canRetry` and then change this check to use `&&`. That is: ``` ((response.error.exception() instanceof RetriableException) && (transactionManager == null || transactionManager.canRetry(response, batch))); ```
as above (similar below)
nit: This could be simplified: ``` java final PriorityQueue<StreamsGraphNode> graphNodePriorityQueue = new PriorityQueue<>(5, Comparator.comparing(StreamsGraphNode::buildPriority)); ```
I see, this is indeed weird, please file a JIRA so that we could clean in a follow-up PR if others feel the same way.
Nit: can you pleas add this in alphabetical order.
This can be reverted.
keep this one and call `print(keySerde, valSerde, null)`
Can we split this as follows: ``` final StoreQueryParameters parameters = (StoreQueryParameters.fromNameAndType(keyValueStore, QueryableStoreTypes.keyValueStore()).withPartition(numStateStorePartitions + 1); final InvalidStateStoreException exception = asserThrows( InvalidStateStoreException.class, () -> storeProvider.getStore(parameters) ); assertThat(exception.message(), equalTo("...")); ``` And remove the `(excpected = ...)` annotation. (1) We should always limit the code that might throw the exception (eg, if `withPartition` would throw an `InvalidStateStoreException` the test should fail, but would pass in it's current setup) (2) We should always verify the exception cause -- `getStore()` could throw an `InvalidStateStoreException` or multiple reasons and we should make sure it's throwing for the reason under test. Same below for the windowed case
Yeah this is observed in another PR review, and should be fixed by now. cc @dguy
I don't understand what this test is doing. Why do we need background clients instead of producing upfront and consuming the data mirrorred at the end of the test? It looks like we are testing the primary->backup scenario but we are restarting the backup cluster. The source connector should not interact with the backup cluster.
We can return `listeners != null && listeners.contains("SSL")`
Yes, this should on an internal package (eg `common.internals`).
super nit: the delta really doesn't matter in this case I'm wondering if `assertEquals(i, (int) totalMetric.measurable().measure(config, time.milliseconds()));` would be more clear, but this is subjective so feel free to ignore.
This needs to go outside of the `try` because the call to `release()` is in the `finally`. If we're going to do this, I would suggest moving the validation checks outside of the `try` as well.
@kkonstantine I don't feel strongly about it, but others do. Probably largely due to (with hindsight) the opposite default of what would have been ideal, i.e. would have been better to have to opt out of by-default immutable references rather than opt in. We definitely already have some divergence within the broader AK codebase (`streams/` uses `final` more aggressively, not sure if it's checkstyle-enforced, Connect tends to use `final` mostly just for class fields). `clients` is a bit of a mix, but less `final` in `for` loops than not. And `core` is scala, so different story altogether. I have no hard and fast rule here, main reason I even asked is because in this diff it is being removed from what was already there. No need to get hung up on it, but the other argument is to not change it in favor of minimizing diffs and maximizing mergability/cherry-pickability :) There are tradeoffs no matter which direction you choose....
Regardless how high performance we want this code to be, as a matter of principle we shouldn't create an exception (and pay the cost of filling its stacktrace during instantiation) if we don't need to throw it. I sketched a modification just with a +1 line, but feel free to adjust to your style of preference. ```suggestion ConnectException e = null; for (ErrorReporter reporter : reporters) { try { reporter.close(); } catch (Throwable t) { e = e == null ? new ConnectException("Failed to close all reporters") : e; e.addSuppressed(t); } } if (e != null) { throw e; } ```
nit: use RecordQueue.UNKNOWN instead of -1
Changed it locally.
no need to use `this.` outside the constructor. Here and below
I would favor a complete long number in this case instead of removing `L`.
not sure whether this is a kind of behavior change. The docs of ```KafkaConsumer#poll``` indicates that ```timeout``` is used to wait available records. ``` * This method returns immediately if there are records available. Otherwise, it will await the passed timeout. * If the timeout expires, an empty record set will be returned. Note that this method may block beyond the * timeout in order to execute custom {@link ConsumerRebalanceListener} callbacks. ``` Maybe we can introduce a new API ```poll(Duration, Options)``` (similar to KafkaAdmin. The options enables us to adjust the poll behavior for specific use cases. Also, it opens a room to give various ```poll``` in the future.
Nit: add `<p>` to get an empty line -- otherwise, generated HTML does not render correctly. Same below.
This can be tricky since finishConnect() can throw an IOException. This is dealt with in the while loop starting at line 293. We can deal with it here again, but we will end up duplicating more and more code. Have you considered iterating both keys from selector and immediately connected keys together? That complicates the iteration a bit, but will avoid code duplication.
We can give a clear message saying null is not supported. If it's an NPE somewhere down the stack then the user doesn't know if it's a bug or not.
Mentioned offline, but it seems we don't need the `isInTransaction` check here. No matter the state, if the producer is fenced, we should raise.
ditto on removing before/after.
in not -> is not
We have `testJoinGroupRequestVersion0RebalanceTimeout` but `testOffsetFetchRequestBuilderToStringV0ToV7`, so rename `testJoinGroupRequestVersion0RebalanceTimeout` â `testJoinGroupRequestV0RebalanceTimeout` for consistency
acquireAndEnsureOpen can be moved here
Yes I'm talking about using a `mock(Producer.class)`.
Maybe it would be good to weaken a bit this statement like "This is conceptually equivalent to calling ..." or similar. See also the other occurrences.
This should be: `return aggregate(initializer, aggregator, windows, aggValueSerde, windowedStore(aggValueSerde, windows, storeName))` - it is probably one of the reasons you have test failures
nit: extra space between `printed` and `options`
This is fine, but note that the new consumer record here is just a roundabout way to create a ProcessorRecordContext. It'd probably be better to just directly instantiate the context we want.
Yeah, I think that should be fine. I just wasn't sure how much I wanted to trust the request completion handling logic. I guess it would break a lot of expectations elsewhere if it were broken though, so probably no additional harm from relying on it here.
Do we need this Constructor? It looks like it's only called from `parse()` which has the version so it could call the other constructor
@becketqin It's ok with me, but is it worth removing the unneeded break after `awaitMetadataRefresh`? I also think it's a little clearer if the check for `isDone` is done first thing after calling poll() as I did in the snippet above. More generally for this problem, I think we should have some better options for doing these loops generically without so much pain when we finally switch to Java 8.
Maybe an `assert` for unit tests (are `asserts` common in Kafka code base?). As `WrapperSerde` is private, nobody else can use it -- so no need to check for `null` IMHO.
typo: The title of the last column should be `DELETE_SEGMENT_FINISHED`.
Yes. @dengziming in that example, the user has incorrectly configured the cluster. The user was configured it so that all of the controllers have each other's listener (connection) information but the cluster ids are different. The question is do we want to catch those misconfiguration early by shutting down the brokers/controllers? Or do we want to continue executing with the user potentially missing that the controllers/brokers are incorrectly configuration? There have been conversation of having the first controller leader generate the cluster id and replicate that information to all off the nodes. The currently implementation generate the cluster id in the `StorateTool` which the user has to run when configuring the controllers. I am okay leaving it as is and addressing this in a future PR.
nit: parameters on a separate line
Typo. `my.custom.config` -> `my.custom.config2`
If this exception is thrown all the way up to the user, we should update the java doc string as well.
we should do this `assertTrue` thing for the CooperativeStickyAssignor as well
Oh duh, I thought this was StreamTask. In that case, why would we check for RESTORING at all? We don't check for RESTORING state anywhere else in StandbyTask AFAICT (maybe Guozhang thought this was StreamTask like I did? ð )
debug line should be removed.
again, naming of the test
You can use `<>` to rely on type inference, eg `new HashMap<>;`,
I've found that avoiding using anything related to the type of a variable in its name is usually for the best. It takes a few more seconds to come up with an appropriate name, but it definitely pays off when reading, and even in generic uses as this one here it's still better IMO. E.g. I'd call this at least `chain` or something.
```suggestion @Evolving public class WindowRangeQuery<K, V> implements Query<KeyValueIterator<Windowed<K>, V>> { ```
if these cant be null, then your checks can be simpler. return configKey.equals(that.configKey) && configValue.equals(that.configValue)
If I put ``` assertThat(store1.isOpen(), is(false)); assertThat(store2.isOpen(), is(false)); assertThat(store3.isOpen(), is(false)); assertThat(store4.isOpen(), is(false)); ``` on line 202 in `shouldThrowStreamsExceptionForOldTopicPartitions()` the test fails. Hence, we leak a state store.
I think we misunderstood each other. I was asking for an integration test that verifies that the rebalancing works for the maximum length of the tags. To see if the subscription has still a size that works. Maybe also in combination with many tasks.
How about something like this: For consumer group that uses pattern-based subscription, after a topic is created, any consumer that discovers the topic after metadata refresh can trigger rebalance across the entire consumer group. Multiple rebalance can be triggered after one topic creation if consumers refresh metadata at vastly different times. We can significantly reduce the number of rebalance caused by single topic creation by asking consumer to refresh metadata before re-joining the group as long as the refresh backoff time has passed.
"*" is considered "LITERAL" for compatibility reasons
Still not used.
Do you think it would make the code more clear if we rename the `keys()` to `rawKeys()`? Looking at the `RawKeyAccess`, the `keys()` makes sense. But looking at the `RocksDBTimeOrderedWindowStore.keys()`, the name does not tell much about what keys.
I think we still need this check. There may be a rebalance between the time a fetch response is handled and the time it is returned to the user.
Are you sure it's actually returning something? Have you tested it with a rocksdb store or just with the in-memory store? I think the in-memory store would handle this fine since it never serializes the key/timestamps, but if you have a rocksdb store (or a caching layer) then the range query works by looking up any data between the serialized bounds. Unfortunately a negative long is lexicographically greater than a positive long when serialized to bytes. The "negative" is encoded as a leading 1 -- which means the lower bound ends up being "larger" than the upper bound. I would assume that would result in no data being returned, but I'm not actually 100% sure what would happen
```suggestion INVALID_RECORD(87, "This record has failed the validation on broker and hence will be rejected.", InvalidRecordException::new), ```
nit: you could add a static import and make these all just `getBytes(UTF_8)
I think we should probably move this log statement since this method doesn't actually reset offsets.
I was referring only to the newly introduced methods and their tests. Not the whole class. Not a big issue.
nit: add `final`
New default name for the merge-node
This is not introduced in this PR: we can try to get the record collector in the constructor and cache it instead of trying to access it every time. I checked all the access patterns of this field and they should not be modified dynamically.
```suggestion * ReadOnlyWindowStore<K, ValueAndTimestamp<Long>> localWindowStore = streams.store(queryableStoreName, QueryableStoreTypes.<K, ValueAndTimestamp<Long>>timestampedWindowStore()); ```
@dguy EDIT: nvm. Since this is pure in memory, it will not matter at all when upgrading in a rolling bounce since it will be lost anyways. I confused myself yesterday night about what to keep compatibility during rolling bounce.
The hashCode of `MemoryRecords` takes into account the buffer position, so it's kind of useless. `FileRecords` doesn't even define it. We should consider defining the hashCode and equals of `Records` to be identity based.
why `suspendImpl`? That is a pretty horrible name for a method. Similarly `commitImpl`
I think I would move the method to a test utility so that tests can use that instead.
This must be `OUTPUT_TOPIC_2`
@mjsax @bbejeck I renamed the method. Apologize for my poor method naming skills.
```suggestion * <p>Note: The current implementation of either forward or backward fetches on range-key-range-time does not ```
nit: Please fix code style.
@guozhangwang I think we shouldn't relax schema validation. We would have to think through all the implications of accepting bad data. Is the performance really that much worse? I thought the biggest benefit was avoiding the allocations, which we should still be able to do.
Much better than returning null
FYI, there is already a metric for fetch request latency.
nit: Worth double-checking, but I think we require "read_committed" to be lower case.
Nit: I know this is following the [existing style](https://github.com/apache/kafka/blob/c2ee1411c8bb73fcf96c12abeedbfe6fde2c6354/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/rest/resources/ConnectorPluginsResource.java#L101-L118) in the code base, but do you think the separate `getConnectorPlugins` method is actually bringing anything to the table readability-wise? Think we could just as easily eliminate the `getConnectorPlugins` method and inline it directly here. Same thought with `getConnectorConfigDef`.
Since `RETRY_BACKOFF_JITTER` and `RETRY_BACKOFF_EXP_BASE` will be the same for all the clients, should we move these two defaults in `CommonClientConfigs.java` instead? That way we can access this across the `Consumer`, `Producer`, and `KafkaAdminClient`.
As above for this and next ctor
I see. There may not be a nice way to wire in the thread id from a static context. If we can't get the thread id, I'd suggest accepting the change here so that at least the message points to the right file.
nit: `task.id()` -> `taskId`
Wonder if there's any harm retaining the top-level error regardless of the version. Seems more consistent with how we handle the case of constructing from a `Struct`.
Why is this necessary? In the `for` loop above, each partition that finished restoring should be removed vai `it.remove();` -- hence, if `allTasksRunning()` return `true` `restoring` should be empty ? Similar for `restoringByPartition` given the two new lines this PR adds.
nit: single parameter per line
... should not be...
The wording here is a bit confusing. It makes it sound like we are restoring partitions that have already been completed
You verify the wrong name here. ```suggestion assertThat(name2, CoreMatchers.not(Optional.empty())); ```
you can just compare the primitive longs, no need to do all this boxing to `Long` type
Before this PR, the `unUsed` set contains both `unUsed` and `unKnown` configs, because we didn't separate them. After this PR, we hope we can separate the `unUsed` and `unKnown`, so we created a new method `unKnown`. Under this situation, I don't think it makes sense to make `unUsed` set contains both `unUsed` and `unKnown`. That will just confuse other developers.
This overload can be removed, too IMHO
nit: remove empty line
It seems we may release the memory for the expired batches before the response is returned. This means the underneath ByteBuffer is still referred by the ProducerBatch instance in the inFlightRequests. I am not sure if this would cause any problem, but it seems a little dangerous.
The reason is a bit weird. I wonder if we could just leave it empty in the beginning.
```Calling flush() from callback is not allowed since it makes deadlock.```
We did the dot to _ conversion for Yammer metric mostly because reporters like Graphite typically use dot to represent hierarchy and quite a few people are using the existing Graphite reporter that may be confused with dot. Since Kafka metric is new, we could just let individual reporter deal with this issue, instead of changing the metric name directly.
I believe the jira was under the kip's main jira, but I can make the link clearer.
Suggest creating this once and reusing it throughout the instance's lifetime. Is there a benefit to use a random number here? We could simply start from partition 0 and cycle through all partitions throughout all the refreshes
The indentation should be four spaces instead of eight.
Only `close(long, TimeUnit)` has been deprecated.
You can reduce this code a lot by using `SchemaBuilder.type(readerType)` to handle all these cases instead of using `SchemaBuilder.int8()`, `SchemaBuilder.int16()`, etc.
Ack. Overlooked this change :)
Hmm, would be good to get these constants out of here, but seems they don't appear in the clients jar yet. Not something we need to do now, but we might consider this for the future, and the fact that we have the AdminClient in clients might be good enough reason (though since these are really broker configs, I'm not sure how much we can do with them in the AdminClient).
nitpick: it's a little weird to use `Boolean.TRUE` instead of just `true`.
I don't doubt it works but it's not obvious if one has to check the implementation of `ConcurrentSkipListMap.doPut()` to get confidence. Actually, a better argument - https://docs.oracle.com/javase/7/docs/api/java/lang/Comparable.html#compareTo(T) states: The implementor must ensure sgn(x.compareTo(y)) == -sgn(y.compareTo(x)) for all x and y.
I think this test condition is unnecessary. The `poll` in the line above completes only when the future is done. Same below.
If you only have `file.setWritable(true, true)` then the directory will still be writeable by non-users, I assume? I actually don't know the details of the `File#setXXX` methods -- but we don't want it to be writeable by just anyone. Should we instead do something like ```suggestion set &= file.setWritable(false) && file.setWritable(true, true); ```
Also I think the checkstyle will fail as well for this code style.
nit: not really sure we need two separate constants even though they are separate fields in the struct.
Yes it will
I think you can also drag this line into `getSensor()`. Sorry for not noticing it before.
This field is unused
Just to avoid allocating an empty list in the common case where we don't throw any exceptions.
This code is also getting the connector class name twice. Probably be better to do that once before calling the `onCompletion(...)` method.
I think what you want here is `Records.LOG_OVERHEAD`.
Curious what the reason for this is.
nit: add `final`
Stale docstring (copied from reassign_partitions_test)? Perhaps unecessary, since you have a detailed docstring in the test method
It seems a bit odd that `CommitFailedException` is a `KafkaException`, whereas `RetriableCommitFailedException` is an `ApiException`...
Could this result in NPE? May be we can directly throw an IllegalArgumentException here.
Should be fine.
I think this is equivalent to `for node in self.nodes`, which might be clearer
Can we make this method return `OptimizableRepartitionNode` just for symmetry? I.e., you can see that we're replacing a bunch of `OptimizableRepartitionNode`s with a new `OptimizableRepartitionNode` instead of replacing them with a generic `StreamsGraphNode`.
We don't want to do it this way, because, we want restore and calling `mainCosumer.poll()` to interleave -- otherwise, we might drop out of the consumer group as restore is expected to take longer than `max.poll.intervall.ms`. Hence, within this method, we should only do a single `poll(restoreCosumer, 10)` an return afterwards -- the main loop will make sure that this method will be called again to resume the restore.
We can make this a little clearer and save some duplication with a signature like this: ```java protected synchronized void resetGenerationOnError(Errors error, ApiKeys api) ```
It looks like there is an extra whitespace after return.
Would you mind "fixing" this test to? i.e., using `@Test(expected = SomeException.class)` is bad form for tests with more than a single line. The exception could potentially happen anywhere and my be masking actual bugs. In these cases it is always better to use the same pattern as below, i.e., ``` try { performExceptionThrowingAction() fail("KABOOM! shouldn't get here"); } catch (SomeException e) { // pass } ```
Unless I'm missing something, we are not actually using the boolean value anywhere. All we do is check if the optional is present. Would it be simpler to just return the boolean directly? also nit: having `assert` in the name is misleading since there are no assertions. I would suggest `isConnectorAndTasksRunning` or `checkConnectorAndTasksRunning`
Hopefully, there's no danger of these counters overflowing, but regardless, I think the math would still work out if we did reset them here.
This function is only used in unit test, we should not expose.
Oh, I see. I did not think about that dependency. Nevertheless I think somehow it would be possible to move `initializeTopology()` to `StreamsTask` without an `instanceof` but that needs a bit more thoughts and refactoring and it is out-of-scope for this PR.
No need, if it's valid then the `name` version is fine. I'm probably just out of date.
nit: Can we just merge these two test into one? I feel the second is almost a super set coverage of the first.
given that these `EnumSets` are used so much throughout the code, we should just calculate them once and reuse them, rather than recalculating each time. There are only 3 listener types so it could just be in a static map or something.
There is a related JIRA about that but whether we'd keep it as is still open questions, I think we can make this assumption still atm but just bring it up FYI. https://issues.apache.org/jira/browse/KAFKA-7125
> in case now is reduced How could this happen? Seems to be impossible to me.
looks like the test is failing at below `self.kafka.stop_node(node)` call, without `snapshot.trust.empty` config. Can we check for topic/znode existence in ZK after upgrade. We can use ZK cli/kafka-topic describe? This way we can test ZK server availability and znode data existence after upgrade.
@ssanthalingam thanks for updating, no apologies necessary!
Rate actually allows the windowSize to be close to the full samples * perSampleWindow. The logic around `config.samples() - 1` is just to make sure the windowSize contains at least that many full windows. So, to match that behavior, it seems that burst should use `config.samples()`.
nit: avoid unnecessary `this.` prefix
Actually even for standby tasks, it should also be beneficial to use bulk-loading right (e.g. if the standby is far behind the active and has a large amount of records)? I'm thinking that in the long run, maybe we could optionally allow restore callbacks to be triggered for standby as well: we can use some simple heuristics such that if the changelog log-end offset - standby task's store offset > certain threshold, we trigger onRestoreStart(), and then we can goes back from the "sprinting" mode to normal mode after we've been close enough to the log-end offset. At the mean time, we can maybe hack a bit so that when `segment.toggleDbForBulkLoading` we set a flag and in the other we reset the flag, then during restoreAll we check the flag to decide whether enable bulk loading for newly created segment.
No need to repeat `is thrown` in the 2 lines above.
We should use try-with-resources here (for `DataInputStream`).
nit: `1` -> `1L`
nit: space after comma.
@miguno Actually, we do not enforce this guarantee. For many UDFs, we just hand in a reference to key and/or value and if the user would alter the object, we would not notice...
Maybe add one more sentence: > .. underlying fetch behavior. The consumer will cache the records from each Fetch request and return them incrementally from each `poll`.
This list is small anyway, so I'm not too worried about the cost, but this seems wasteful. Seems like this promotion check should be a simple lookup in a precomputed table.
I missed the part about "messages," so yeah, no confusion about the listTopics() API. I think it still may be worth clarifying that messages from internal topics will only be included if those topics are explicitly subscribed to.
use `try-catch` plus `fail()` for this line and remove annotation `@expected` -- right now, for example, a bug in `builder.stream` raising `NullPointerException` would not get detected. ``` try { stream.peek(null); fail("Should not allow null Action"); } catch (final NullPointerException e) { // expected } `@expected` should only be used in "single line test" for which it is clear that no exception can happen before the actual tested code.
cleanRemovedTasks -> cleanRemovedTasksCalledByUser
nit: naming -> `shouldAcceptDefaultBufferSizes()` Also, I am wondering why we check for default buffer size? The ticket was about the issue, that `-1` was not accepted. Thus, while having this test is ok, we should actually test for `-1` to have a test that covers the reported issue.
lol, I forgot to apply my own suggestion to use 'interpreted', good catch.
ok - i still think `timerStartedMs` is a better name. i can't think of anything else
If the record is null, this isn't doing any schema compatibility checks besides the check for optional/required check at the top of this method. This is causing the logical type test to fail.
Do we need to do this for so many stores? i think 2 would be sufficient as the test becomes quite noisy and it is difficult to see the intent
`..the sender buffer due to memory unavailable..`
we should not use Java keyword `assert` but Junit `assertXXX` methods (`assertEquals` for this test)
```suggestion assertTrue(StreamSupport.stream(serviceLoader.spliterator(), false).anyMatch(sl -> sl instanceof DirectorConfigProvider)); ```
Not part of this patch, but this name seems a little misleading. In addition to stopping the connector, we also remove it from the connectors that are managed by the Worker. I'm wondering if it makes sense to separate the notion of connector _installation_? Maybe that would get around some of the awkwardness with removing the connector when we're just restarting it and needing the set copy in `stopConnectors()` above.
It's not really clear to me why we need a test case with two consumers.
@vvcephei The log files are deleted when a processor is stopped and started (note, this does not apply if one does a `processor.restart()` but only on explicit `processor.stop()` plus `processor.start()`). Thus, first occurrence in the log is L96 and this is second one).
The problem is that `previousTasks()` is called in a bunch of places other than in `onPartitionsRevoked`. For example: 1. in the finally block of `onPartitionAssigned`. At this time the all the suspended tasks are logically closed and removed. 2. in `streamThread.prevActiveTasks()` by the `StreamsPartitionAssignor`. At this time `onPartitionRevoked` is called so that suspended tasks are constructed. 3. in `streamThread.shutdownTasksAndState()`. At this time the suspended tasks should logically be empty. I think the reason that it works now is because `suspend()` returns the copy of the values so iterator.remove does not actually moves it. In other words `suspended` list is never cleared except in `maybeResumeSuspendedTask` until the thread is shutting down. So it sounds like this list may increase indefinitely across rebalances? Ideally we should have empty suspended list at the end of each `onPartitionAssigned` and do not rely on it for `previous tasks`.
nit: Could we also assert that the file names have been renamed to the new style as well? @dguy
@amethystic I believe Jun is suggesting that it is abnormal for `readFully` (i.e. if you can't fill the buffer, then something is wrong). I think a case can be made for that. I think the downside is that the error messages may not be as good as if the callers do the check themselves. The upside is that we avoid the situation where the caller forgets to check. We'd have to verify that these semantics are right for `FileRecords.readInto` since it doesn't perform any checking atm.
Similarly as in `StreamTaskTest`, we should just use a different `cache` object in the `testMetrics` function than the class field `cache` which gets a real `StreamsMetricsImpl` directly.
`punctuate(long timestamp) {}`
This test doesn't seem to correspond to the code -- the context object provides one TopicPartition that you can set as the one causing the error, but then this pauses two partitions.
Why not make it `final` and return an empty list? It seems better to avoid using `null` if possible
`ConfigProvider` was introduced in AK 2.0, so this change can't be backported to earlier branches.
fair enough - we still don't need the assertion though as it is already true as of line 69
The point is that the coordinator discovery logic below is unneeded.
This is not in this PR: I realized that in `KGroupedStreamsImpl#repartitionIfRequired`, in the return statement: ``` return KStreamImpl.createReparitionedSource(this, keySerde, valSerde, queryableStoreName); ``` We pass the `queryableStoreName` as the prefix of the repartition topic. That seems not correct to me? cc @enothereska since it seems from one of your previous commits,.
Glad to help! :)
I would prefer `advance` instead of `hop`. As we discussed, `slide` should not be used to avoid confusion with sliding windows and `offset` would overload Kafka's usage of this term.
Using `TableProcessorNode` implies that we make all decision about materialization in `doToTable`? -- However, I am wondering if this is correct. When we call `StreamsBuilder.table()`, we create a `TableSourceNode` (within `InternalStreamsBuilder#table()` that allows us to defer decision when we build the actual `Topology`. This has the advantage that we can take into account how the `KTable` is used downstream. For example, if we use it downstream in a stream-table join, we need to materialize the table -- but if we decide to non materialized here, we can't change this decision later on using `TableProcessorNode`? (Correct me if I am wrong.)
Does this need to work with ipv6? Might be worth comparing with `ClientUtils.parseAndValidateAddresses`.
Nit: add `final`
Also, I think it reads a bit weird. Not clear that "encoding an unsigned integer" in brackets means when reading the message.
Case 1): yes, the queued requests will eventually be timed out with the exception set. I'm thinking the loop would cover it as it would catch `TimeoutException` and retry.
That would mean loading data from disk to compute equals and hashCode for FileRecords. That's pretty unusual for such methods.
Could make this assertion a little stronger: ``` assertEquals(new TestElement(i, i), coll.find(elements.get(i))); ```
Do we still need maybeCommit at line 369 then? EDIT: never mind.
Oh, yeah, I'm 100% on board with you there. `// visible for testing` always reads to me like `// setting a trap for the future:`.
Nit: In unit tests, "ensure" usually means "verify". We're instructing here, not verifying. But we're setting up one of the two important conditions in this test, so maybe phrase it like that? ```suggestion // When automatic topic creation is disabled on the broker ```
Out of curiosity, why do we add two `{}` around the code logic hereï¼
nit: maybe we split 50 to 20/30 to avoid some reading difficulty? :)
Is this a valid restriction for the broker? Would there be cases where multiple mechanisms may be required? In the original Kafka Security proposal, there was mention of one port supporting multiple SASL mechanisms. I don't know how common that is though. Probably not for this release, but it may be worth thinking about how we would do that in a compatible manner if we decide to do it.
You can drop the "public" here, since the tests are in the same package.
There are lots of occurrences of `checkReplacementSchemaless(singletonList(`. Perhaps it would make sense to create a second `checkReplacementSchemaless(String replacement, Object value)` that returned `checkReplacementSchemaless(singletonList(replacement), value)`, and then most of these lines could be simplified a bit. Same for `checkReplacementWithSchema(...)`.
I was playing around with some ideas to simplify this parsing logic since we're mostly doing the same thing over and over. I think some helpers might do the trick. This is what I'm thinking: ```java private static int readMore(ByteBuffer buffer, DataInput input, int bytesRemaining) throws IOException { byte[] array = buffer.array(); // first copy the remaining bytes to the beginning of the array // do not use System.arrayCopy since it will allocate a new array for same src/dest int stepsToLeftShift = buffer.position(); int bytesToLeftShift = buffer.remaining(); for (int i = 0; i < bytesToLeftShift; i++) { array[i] = array[i + stepsToLeftShift]; } // then try to read more bytes to the remaining of the array int bytesRead = Math.min(bytesRemaining, array.length - bytesToLeftShift); input.readFully(array, bytesToLeftShift, bytesRead); buffer.rewind(); // only those many bytes are readable buffer.limit(bytesToLeftShift + bytesRead); return bytesRead; } private static int skipLengthDelimitedField(ByteBuffer buffer, DataInput input, int bytesRemaining) throws IOException { boolean needMore = false; int bytesRead = 0; int bytesToSkip = -1; while (true) { if (needMore) { if (bytesRemaining > 0) { int bytesToRead = readMore(buffer, input, bytesRemaining); bytesRemaining -= bytesToRead; needMore = false; } else { throw new InvalidRecordException("Invalid record size: expected to read more bytes in record payload"); } } if (bytesToSkip < 0) { if (buffer.remaining() < 5 && bytesRemaining > 0) { needMore = true; } else { bytesToSkip = ByteUtils.readVarint(buffer); if (bytesToSkip <= 0) return bytesRead; } } else { if (bytesToSkip > buffer.remaining()) { bytesToSkip -= buffer.remaining(); buffer.position(buffer.limit()); needMore = true; } else { buffer.position(buffer.position() + bytesToSkip; return bytesRead; } } } } ``` With these helpers, the state machine becomes a little simpler. For example: ```java case READ_KEY: bytesRemaining -= skipLengthDelimitedField(buffer, input, bytesRemaining); state = ReadState.READ_VALUE; case READ_VALUE: bytesRemaining -= skipLengthDelimitedField(buffer, input, bytesRemaining); state = ReadState.READ_NUM_HEADERS; ... ``` If we could get this working, then we may not need to reuse states.
https://github.com/apache/kafka/blob/trunk/streams/src/main/java/org/apache/kafka/streams/StreamsConfig.java#L453 Note that inside the function it calls `originals()` which is parsed on the consumer config in which default values will be auto-filled when it is not specified by the user.
That is not what I meant. But it might not matter much anyway. While we need to loop over all used names in L951 below to reuse, we don't need to compute `names` from scratch but would just modify `names` each time we add/remove a thread. But it's not perf-critical so re-doing the computation is fine, too.
Yes, we should add this as a possible reason as well.
Might be worth avoiding `null` -- no `null`, no NPE :)
I think we might want to skip the re-registration higher up the call stack. In `StateManagerUtil#registerStateStores` we call `store.init` on each store which ultimately results in this `registerStore` being called
We should probably check that `clientId` is still null.
Here, I would use `bb` as the prefix to cover the case where a key is a prefix of the prefix. ```suggestion final KeyValueIterator<Bytes, byte[]> keysWithPrefix = byteStore.prefixScan("bb", stringSerializer); ```
Hmm.. I don't think it's safe to modify `topicPartitionOffsets`. This is shared by multiple calls following the initial `getListOffsetsCalls`. It would be better to create a new map. It might bee worth having a test case which uses two partitions with different leaders to verify this case is handled correctly.
We should remove the javax.xml.datatype.Duration usage since it's not part of the Java base module.
As mentioned above, IIUC this PR will sometimes pass a null `offsetStorageReader` (IIRC for sink connectors), but this class currently expects that to be null. Might be worth adding a `Objects.requireNonNull(...)` call here to help catch that situation.
You could phrase it differently: "Move the window by the given advance size." or "Advance the window by the given timespan." (or similiar)
nit: remove blank lines.
Not sure why we would lose the generics? Can't it be change to: ``` private <K,T> String repartitionIfRequired(final String queryableStoreName, final RepartitionNode.RepartitionNodeBuilder<K, T> repartitionNodeBuilder) ```
Just to be explicit, are you saying that `ClusterMetadataAuthorizer.addAcl` will be applied before the future returns, or just that the record will be committed. I guess the latter is really all we care about since the change must get propagated to the whole cluster in any case.
What do you think about renaming this local `generation` variable (and the one below) to distinguish them from the `AbstractCoordinator` field (or vice versa)? To make it easier to keep track of which `generation` variables can be null (these) and which cannot (instance variable). Not sure there's a better name out there, just something to consider.
```suggestion "part of a group or is participating in a rebalance right now. You should first call poll to complete " + ```
nit : can use assertNull
nit: We use singular verbs in other functions (e.g. line 54 above), would be better to be consistent.
I think we probably should clean these up so they are more useful for users, but won't block merging this on that. I was thinking something more along the lines of: ``` UUIDDeserializer deserializes UUIDs in standard 36-byte hexidecimal string representation. ``` then followed by the encoding details, i.e. the stuff a user wants to know. Many users won't even think about the fact that what's going into the deserializer (or out of the serializer) is actually a `byte[]`.
`downstream` is a bit confusing: Found the child node of the key changer {} from the repartition {}.
For cases such as this, I think it's good practice to have a temp variable where the map is populated and then wrap it in a Collections.unmodifiableMap while assigning it to the static field. That way we're sure the map is not modified accidentally.
these should probably be defined as class constants so users can specify the startup modes without having to use literals. this helps if you have an IDE indexing stuff, and lets you prefix in ways that clarify the meaning, e.g. `STARTUP_MODE_LISTEN = 'LISTEN'`. kind of unfortunate we haven't migrated to py3 yet, 3.4 added real enums which would be nicer here.
I think what you just described is precisely what I would consider something worthy of logging at `WARN` level. i.e. something went wrong and it is very likely that the application will behave in unexpected ways. `ERROR` level to me should be reserved for catastrophic failures that the application can not recover from. Something that would prevent the worker to start up, in this case. But, at the end of the day, everyone has their own interpretations and there is no right or wrong answer here. Now, `WARN` level being polluted by unused configs - that is something that should be considered a bug that we should fix separately, IMO.
bit-nitpick :) ``` // modulo 2 operation if ((keyValue.length & 1) != 0) ``` most definitely optimized out by JIT because the divisor is known (`2`). Is it too hard to read? Sometimes it's good to train ppl who read the code by example. Can't be more nitpicking than that and if you want to keep uniformity with other versions of `getTags` elsewhere never mind. Not 100% sure either, leaving here to ask what you think in general for such optimizations that are JIT optimizable too.
This could be named as `commitInternal`
Why we want to return a clone of the groupMetadata? If we can declare all the fields as final, and whenever we update we always create a new ConsumerGroupMetadata object, then I think we can safely return the cached object directly.
req: Actually deleting topics after test is critical for some tests: I've encountered some cases where the same topics are reused mistakenly across different test cases within the single class. But I feel that it is better to put the topic deletion in the `@after` function while leaving `cleanUp()` as part of the test function itself.
nit: add missing empty line
This variable can be dropped.
To re-start this thread, I also feel like we should have our own check for Named operations to use. * we may want to make operation names more restrictive than topic names, for example to prevent collisions with automatically-generated partition names * the topic validation throws an exception that mentions the name is "an invalid topic name". This statement is nonsense if I'm naming an operator. We should throw an exception that says it's an "invalid operator name" or similar.
Thanks. Any chance of adding record.NO_CHECKSUM and record.NO_SIZE? We have several places in the code where we call the constructor with -1 and I think this will improve readability.
nit: parens unnecessary
nit: we could use `else if` here.
I think this method would be clearer like so: ``` private long computeLatency(long now) { return Math.max(time.milliseconds() - now, 0); } ```
Same clarification as above.
Nit: fix idention
Cool. I think the fewer configs overall, the better. If we can get away with just the Serde configs then let's do so to keep the API surface area smaller for users ð
But you can simulate a previous assignment by setting the previous assignment in the subscription, right? You don't actually need to have executed the previous assignment.
nit: add `final` (also within the loop)
i think this should be `maybeForward` - `checkForNonFlushForward` indicates to me that it is just going to check and return if it should forward.
Looked into this part as well. I think extracting `initializeNewTasks` for active tasks and standby tasks is a bit overkill than just letting `StandbyTask.initialize()` return true.
I don't believe this is resolved. I still think we shouldn't catch Throwable
I think we can `computeIfAbsent()` here. It will replace `containsKey`, `put` and `get`.
nit: maybe set 5 to a variable `numRetry` to make it more clear
Nit: `final` and formatting
We use to log all leader and isr changes in info even for clean leader election.
@chia7712 Okay. Let me see. :smiley:
@agavra instead of adding the `CachedConfigs` class could we perform the parsing at instation time in the `JsonConverterConfig` class and store results there, exposing them through getters? For example: ```java public class JsonConverterConfig extends AbstractConfig { private final DecimalFormat decimalFormat; // ... public JsonConverterConfig(Map<String, ?> props) { super(CONFIG, props); this.decimalFormat = DecimalFormat.valueOf(getString(DECIMAL_FORMAT_CONFIG).toUpperCase(Locale.ROOT)); } // ... public DecimalFormat decimalFormat() { return decimalFormat; } } ``` The `CachedConfigs` class adds a bit of cognitive overhead to this part of the code base; if we can avoid adding another utility class to have to track it'd be nice.
RocksObject -> {@code RocksObject} setConfig -> {@link #setConfig} close -> {@code close}
nit: please use `final` everywhere
I am not sure about this. It's a really dangerous method as it implicitly casts in an unsafe manner.
Sounds good. An alternative is to add an `abstract Logger log()` to AbstractTask's interface, which would make it clearer that the logger is still going to have the appropriate class name.
I do not know how to do that.. or if it is even possible. I think adding this extra step is not too bad as in `release.py` we already wrap some other places where we need to remove `-SNAPSHOT` anyways, this is just for confirming, that in trunk maybe we'd update `release.py` as well.
On a side note, maybe we should add a global error code fields in addition to per-partition for those global errors like not-coordinator, illegal-generation, unknown memberId, etc.
I think the message needs to be updated.
Please also fix this on the original method (line 1739)
If we are using `MockTime` then it should be fine.
should we apply a try-catch patter instead of annotation? It's not a single line test? (same below)
I would move all of these apart from the first two to the declaration of the fields themselves.
I don't think this is in the KIP. I also think it should be named `queryableStoreName()` I think we generally don't use getXXX on the public API
Do you really need to verify this? You already verify (indirectly) in `getMetrics()` that your code specifies the correct group `consumer-coordinator-metrics`. IMO, the creation of the corresponding `MBean` is not part of the code you want to test here.
Nit: please use braces even for single-line if bodies
Nit: we use a single space after a period.
I moved `transportLayer.removeInterestOps(SelectionKey.OP_WRITE);` from `case COMPLETE` to here in my latest PR.
the broadcast was tested above already -- we should remove it -- one test for one feature
I am just realizing, that `other stream` is not right here either -- it's used for both input streams, as both will have the same key type.
I will leave it up to you, as long as you ensure the tests itself are mutated correctly, it's not easy to eyeball such a change for no-op.
```batch.closeForRecordAppends``` does NOT release the byte array hosted by ```MemoryRecordsBuilder``` ```java public void closeForRecordAppends() { if (appendStream != CLOSED_STREAM) { try { appendStream.close(); } catch (IOException e) { throw new KafkaException(e); } finally { appendStream = CLOSED_STREAM; } } } ``` ```appendStream``` is a wrap of ```bufferStream```. Not sure whether calling ```batch.closeForRecordAppends()``` can resolve the OOM or not. ```java this.appendStream = new DataOutputStream(compressionType.wrapForOutput(this.bufferStream, magic)); ```
It is bad. The exception will just be logged and will never propagate back to the Streams Thread so we will end up losing data. This is why it was done the way it was.
Why do we need this? If we don't inject an error, we start phase 6 in RUNNING state and it should not rebalance.
nit: "in `transform()` and `punctuate()`"
e.getMessage will be more accurate.
I don't think this is safe to remove since it allows the connector to perform validation beyond what you get from the `ConfigDef`. This method is used both for the validation endpoint and for `putConnectorConfig` where I think you want any exceptions thrown by the connector's validation.
For each standby of a single active task the set `clientsOnAlreadyUsedTagDimensions` is computed from scratch. I think this is not necessary since the clients on already used tag dimensions that we found for the first standby are still valid for the second standby and the clients on already used tag dimensions found for the second standby are still valid for the third standby and so on. This is true because we only add clients to the set `usedClients` but we never remove any. I think we can compute `clientsOnAlreadyUsedTagDimensions` incrementally for each standby of a single active task instead of computing it from scratch each time.
nit: `remove` -> `removed`
BTW, I think changing the return type from `void` to something else would be considered backward compatible, so this type of change is acceptable.
Okay, thanks! I have limited time at the moment. I'll try to look at it this week.
@xvrl: The only reason the interface was optional is that we needed to retain support for Java 7, which didn't have default methods. Since we don't have to worry about Java 7 any more, let's make the interface part of the type.
Again minor, but maybe IllegalArgumentException
Why not just use `new LogContext()`? Then we don't need the null check below.
nit: the `20` here means version 2.0, since we mistakenly made a compatible breaking change in 2.0 and this test is specifically for that. So let's just keep the suffix.
I think @hachikuji 's suggestion may be better: do not call ``` AbstractCoordinator.this.rejoinNeeded = false; ``` in `JoinGroupResponseHandler#handle()`, but in `SyncGroupResponseHandler#handle()`.
Are these calling the right method? ```suggestion shouldHandleWindowRangeQuery( ```
eventually all 4 threads should be down
Should we also include group state `DEAD`? New groups in the source cluster appear as dead in the target cluster.
Should simply return true here, right? As written now it is adjusting internal state, and it is best to isolate state manipulation to as few places as possible.
Ah, I see. Edit: Actually, upon closer inspection, it appears that I had got the order mixed up. Looks like all things are accounted for. That was my mistake.
This seems different to the old expected result.
There's a trailing comma issue
We can actually just delete these lines now.
I'd vote for doing the flattening internally than expose the node information in the results, as this is supposed to be internal implementation details that is better not leaking out. The Scala API returning `Map[Node, List[GroupOverview]]` was not a well designed one in my hind-sight.
What are your thoughts regarding returning the same `"No such logger"` value? It might be more informative to JMX users
nit: `Instead, they will fall within the [0, timeDifferenceMs]` -> `Instead, we will put them into the [0, timeDifferenceMs] window as a "workaround",`
nit: A null value
Wonder if we should consider adding max inflight behavior directly to `MockClient`. Seems like a notable difference from `NetworkClient`.
As I mentioned before, we can do a filtering of null keys here as well since if the key is null, it is going to random partitions and hence meaningless for joins anyways; for example we can add a private `addFilteringSink` in `TopologyBuilder` that filters the null keys. Hence the later filtering on the join operators are only for cases where repartition did not happen before the join.
This seems error prone to be checking for this, rather than using the ConsumerRecord's timestamp type.
nit: Could we also briefly explain the issue in the tests? Personally, I tend to read tests to understand the expected behavior and the issue with versions earlier than 9 is not immediately apparent
Same with this, we are actually testing the deprecated method here, so we can justify the suppression.
nit: extra line can be removed
This should not be static, but it can be final.
`selector` -> `serialized`
Consider using java.util.Collections.addAll()
We don't need backwards compatibility with the original signature of createTopics. It's not a public API
It's true that the `DistributedHerder.run()` is ultimately catching and handling this exception. But I feel like many users might not understand the significance of such an error nor how to correct their configuration. Rather than just re-throw that exception, we should probably wrap that exception with one that has a more instructive message, such as something like: > Enabling exactly once for source connectors requires a Kafka broker version that allows admin clients to read consumer offsets. Disable the worker's exactly once support for source connectors, or use a newer Kafka broker version. Plus, should this if block be before the `log.debug(...)` on the previous line? Seems like that log message might just confuse the situation since the worker will not read "to the end of log offsets with consumer".
nit: can remove the type params from this line and the next
nit: we are not "overriding" them, but duplicate them with the prefixed props right? If the user has already applied the prefix then this function would mostly be a no-op.
is the `X` just a placeholder? we can just fill in `1.1.0` and update if this slips from the release
Ah sorry, didn't see it there at the bottom ð
Can we simplify the param-doc? Mabye: "The MockProcessorContext allow a `Processor` to access those config during runtime?" It it required to lost all of those with the corresponding methods? nit `{@link StreamsConfig}`
It's not any more JDK dependent than running a loop is JDK dependent (JIT optimizations vary more than this method that changes less often). Anyway, if it's 4 bytes, it doesn't matter.
same as above, missing . at end
nit: This should go in one line.
```suggestion "Note: This SMT will cause precision loss during conversions from, and to, values with sub-millisecond components."); ```
Right, I was referring to the difference to the old assert and that the new check and error message contains less troubleshooting information than the old one, but I understand that it might seem irrelevant given that the producer part can be trusted, thus the "nit" :)
Your description was very helpful. No need to change the value.
@kkonstantine The argument for `final` on method arguments is that you shouldn't reassign these variables (which is different from whether you mutate the values or not).
may be rename `partitionsByHostState` in other places too? cosmetic change. your call
Why not just make `suspend` a no-op if the task is RESTORING? That seems more in line with how we handle things elsewhere
Ah, gotcha. Thanks.
"InMemoryKeyValueIterator" -> `getClass().getName()
Maybe we can also check if the revoked partitions are equal to the current assigned partitions.
You don't need this block because `ObjectOutputStream.close` closes the stream you pass to it.
replace `restoringPartitions` with `needsRestoring.keySet()` to get rid of the unnecessary variable.
nit: conventional in Kafka to drop `get`. Same in `getLastAckedSequenceNumber`
unnecessarily verbose for a log message IMO (see reply in previous thread)
Good point, @mjsax .
Would it be the acme of foolishness to suggest that we just always "load-two"? Then, we wouldn't have to maintain the extra lists of tests at the top of the file, and we wouldn't need this condition here. And also, we'd eliminate a difference among the benchmarks, since the brokers would be loaded with the same dataset in all cases (even if one of them is unused).
I think debug logging would be sufficient for this one as well as the log entry below for normal disconnect.
should read: note that offsets _are_ always committed.
nit : missing new line
Are all negative numbers acceptable? If so, the negative numbers which get positive by overflow (like `-1610612735`) encounter error.
It seems to me the method ```waitForTransitionFromRebalancingToRunning``` can do the assert as well because we always call ```assertThat(waitForTransitionFromRebalancingToRunning(), is(true)``` in this test.
The producer in the `WorkerSourceTask` automatically resends records, but if the producer fails to resend the [WorkerSourceTask enqueues the unsent records in `toSend`](https://github.com/apache/kafka/blob/08e8facdc9fce3a9195f5f646b49f55ffa043c73/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/WorkerSourceTask.java#L343-L348) and send them again. It is true that this happens after each call to `poll()`, but if the send fails then `toSend` is non-null and upon the next iteration of the loop it will not call `poll()` and will then try resending whatever is in `toSend`. This will continue to happen as long as `toSend` is not null. However, in the current PR, even though this might happen, the loop may still ask for the source partitions and offsets and will synchronously commit them using the `offsetWriter`. So it is possible that a record with a particular offset `o1`, for a source partition `p1` fails to send and is retried, but then a connector then sets a later offset `o2` for the same partition and the connector commits offset `o2`. If the connector were to fail at exactly that point (which is possible), the `o2` offset may have been committed without the `o1` record being written. I understand that in your particular use case, you probably would only set the offsets for a particular partition if records were not written recently, but that doesn't change the fact that the `WorkerSourceTask` might be attempting to resend the previous records for quite some time. What if your new block of code were only performed if `sendRecords()` succeeded? I think there are a couple of issues with that as well. First, the offset writer is called synchronously, whereas other calls to commit offsets are sent a separate commit thread that calls multiple tasks. Now there are multiple threads committing offsets with potential race conditions and concurrency issues. Second, it still is a complicated API, and will developers truly understand when and how they use `getSourcePartitionAndOffset()`? Can I call it to read the last offset committed for a particular source partition? The worker doesn't ever set the offsets there. The WorkerSourceTask has a single, ordered pipeline for all records that each have their offsets. I still believe the best and most reliable and deterministic way to solve this is to use that same pipeline.
duplicate line of 340, can probably pull out of the if. Then there should be no need to make a separate method as the only divergence is a log msg.
It is probably good to always have ms in the name variable name that represents time in ms. Probably not a big deal here since this is local variable.
prop: I would not add the client if it is already contained in the set.
I am wondering would it be better to have this logic in `kafka.Kafka.main()` instead of in the exception? Also it seems that after calling shtudownSystem() the thread will continue to run in this case, which is different from the previous behavior, i.e. system.exit() does not return. If we do so we need to inspect all the cases where we call `System.exit()` and make sure all the threads will exit after we change it to throw the exception. By putting this logic in `kafka.Kafka.main()`, we can still call System.exit() in any of the Kafka thread after catching the `FatalExitError` exception and it is guaranteed the thread won't run anymore.
This can probably be left at `debug`. Before it was very spammy because we didn't check if the partition was already inside `newPartitionsInTransaction`.
I think this `if/else` block here can be removed and just go with ``` java for (final ProcessorNode child : children) { forward(child, key, value); } ```
nit: new line
We should not expect an exception here but add a `fail(...)` after `streams.setUncaughtExceptionHandler(null);` -- and thus, not rethrow within catch.
This microbenchmark doesn't seem to be written correctly. you are creating a singleton list of an int[] array in `testCreateHashSet1`. `inits` needs to be an `Integer` array rather than a primitive array to get the expected array/hashset behavior.
Nitpick: if you pass the deserializers via the constructor, it's a bit more concise. This applies to all tests.
nit: add `final`
like above, no need for security protocol here
You need to be careful about ordering here and how you check this. The old code first validates the IDs aren't the same and then tries to set the value (because the only way the IDs shouldn't match is if no thread is currently in a Consumer method call). This new code tries to set it first, and if it fails, it assumes that it is still set when comparing the IDs. However, if the initial call fails because another thread is accessing the Consumer, but then it finishes and calls release(), then calling `currentThread.get().getID()` will fail because it will have been reset back to `null`/`NO_CURRENT_THREAD` and you'll get a `NullPointerException`. Same goes for the subsequent call to `currentThread.get().getName()` in the error message. I think you want to call `currentThread.get()` _once_, and hold onto that value. No matter what happens, if at some point during this method call the value was a different thread, then we should trigger the `ConcurrentModificationException`. The problem is that you can't be guaranteed you'll perfectly capture the thread that was in conflict because `compareAndSet` doesn't let you know what the value was if it wasn't the expected value. So I think the error message creation just needs to be careful about this -- it's possible we see a conflict, but we cannot actually get the `Thread` object that caused the conflict (we couldn't do this with IDs either -- calling `currentThread.get()` when creating the error message could, by that point in time, return -1). I think the JDK8 version of AtomicReference may have methods that let you accomplish this, but atm we're stuck with JDK7.
They are set to whatever is set in `StreamsConfig`, default is `earliest`.
Looks like dead code here
remove this line
I mean it's odd to submit an empty job to the executor in order to verify progress. Why not call `get` on the close future itself.
I don't think this this is what we want. We're not using an `Error` anywhere else in the producer. I'd suggest we just throw `TimeoutException`, but it is a `RetriableException`, which would be misleading if we do not allow retrying. We could either introduce a `FatalTimeoutException`, or we could try to make this API safe to retry. For example, to implement the latter, we could cache the result object so that on retry, we continue waiting for it.
So to make sure we actually use "stream-time" we should change the test to actually punctuation twice? Would you mind doing a follow-up PR? Might also be worth not use a different timestamp compare to "wall-clock time" to make sure we don't by accident pass in current wall-clock.
Makes sense, we can do that later.
IIRC, Java doesn't fully implement variance, but this is the basic concept (in scala) of what's going on with those `extends` return types: https://docs.scala-lang.org/tour/variances.html
I think this is because this function is only for init the getters, which requires the state stores is connected, hence accessible in `init` to the node.
If we change the definition of the available memory here, we may have to change a few other places as well. e.g. `deallocate()`, `unallocatedMemory()`, etc.
Maybe we should say `Consumer process took more than %d s to become alive`? Because the other timeout has the word `start` in the name, it would be good to avoid using it here as it might be confusing.
Similar to above: we should be able to test with via unit tests using `Topology#describe()`
nit: rename this.to -> this.rawToKey
This can be static
I think your IDE is adding extra braces. (I know this is a bit annoying between Apache Kafka & Confluent projects since they use different styling. iirc default IntelliJ styling works for Kafka if you are using IntelliJ)
```suggestion /** * Source topic partitions of the active tasks of the Streams client. * * @return source topic partitions of the active tasks */ ```
For the streams-broker communications I think it would make sense, yes. We could open a follow up JIRA, probably doesn't need to hold back this KIP.
So this is assuming the following `balance()` call could run beyond the next GC? In that case imho `assignedPartitions.clear()` would look better (having almost the same impact).
I don't think it's necessary to warn in this case. Maybe debug, but not warn. If callers are concerned, they can check the parameters before calling the method.
@bharatviswa504 @ijuma Couldn't we just change the thread ID that we store to an `AtomicReference<Thread>` to store the entire `Thread` object instead of the ID and make `NO_CURRENT_THREAD` `null`? You would just need to be careful to `currentThread.get()` once and once you verify it is non-null you can `getName()` safely. In fact, this is best effort concurrency detection, so it's even ok to call `currentThread.get()` twice as long as we're careful about null values in all cases.
Whoops, that was my bad
I have no clue about this. \cc @enothereska @dguy
Just see the test from below with "many windows" -- I think we can merge them into one test
nit: it was correct before
nit: I think formatting corrects this (at least on intellij). Can be fixed below too ```suggestion for (Object item : items) { ```
This condition is reversed, we should call `pollNoWakeup` if a fetch has been sent.
Hmm... Seems rather wasteful to decompress another time just to validate the record count. What I had thought is that we could hook the logic into `DefaultRecordBatch.RecordIterator` so that we can do this validation as part of the single pass we do over the records when validating. As a matter of fact, we seem to already do part of the validation there. If the number of records that we consumed is greater than the count, then we raise `NoSuchElementException`. That should probably be changed to `InvalidRecordException` and then we just need to check for the underflow case.
True, but I find the naming a little more clear, but we can chalk this one up to personal preference, feel free to ignore.
nit: move to line above (however, this is an internal API, and I am not even sure if we need to add this at all.
At this point, we know that `mappedKey != null`, otherwise, we would have dropped the record.
If we have a common default, it may make sense to have an overloaded method without `waitTime`.
Got it. However, we probably want to make the api in interceptor consistent with producer Callback. Similar things can happen in the producer callback where we don't have the full metadata, but just the topic/partition. Currently, we just pass a null RecordMetadata. It may be useful to preserve the available metadata there. It's just that changing the exception type in Callback is an incompatible api change.
`null` check is redundant as `null instanceof StringDeserializer` will return false anyway.
nit: define `KeyValue<Windowed<String>, Long> deserialized` once before the `if - else` statement then you can call `results.add` once by moving the `results.add` to outside the `if - else`
This line looks about the same as L665. I'm wondering if we really need the "else" in this case.
There's actually a kafka-specific version of `TimeoutException` that you should use to keep in line with other kafka APIs. It's `org.apache.kafka.common.errors.TimeoutException`
```suggestion /** * Port on which the Streams client listens. * * This method is equivalent to {@code StreamsMetadata.hostInfo().port();} * * @return the port on which Streams client listens */ ```
Hmm, let's just have this delegate to the super method. It's internal, so we need not include the original record details. ```suggestion return super.toString(); ```
can be simplified to `@SuppressWarnings("unchecked")`
I would not use variable names in log messages.
Can we add an assertion like the following to ensure that both requests were sent? ```java assertFalse(client.hasPendingResponses()); ```
@mjsax @vvcephei I ran the new commit locally and I think I get the difference here: In the ToplogyTestDriver#pipeInput: ``` // Process the record ... task.process(); task.maybePunctuateStreamTime(); task.commit(); captureOutputRecords(); ``` I.e. each record would cause a commit immediately, and in this case, when processing the two records from the repartition topics, each of them will trigger the `pipeInput` once and hence commit once, i.e. the processing of the original one `pipeInput` would cause two `pipeInput` from the repartition topic, and hence commit twice, and flush twice. While in the old `KStreamTestDriver`, we do not commit from the repartition-topic piped record, hence only result in one flush.
Since the type expected by `writeByte` is `int`, it seems like the previous code was OK? Otherwise we do two conversions.
Why remove this check? The `valueGetter.get` does an actual table lookup, which would be wasteful if we're going to skip this record anyways because the mapped key is null. Also, I'm pretty sure the lookup would throw an NPE
This should be `org.apache.kafka.common.message` to match the directory that the generated source files are outputted to
Nit: add `Cannot be {@code null}.` (maybe somewhere else, too)
I can't tell if you're trolling me ð . The method `prettyString` below still does not handle manual assignment. Maybe it could be something like this? ```java public String prettyString() { switch (subscriptionType) { case NONE: return "None"; case AUTO_TOPICS: return "subscribe($topics)"; case AUTO_PATTERN: return "subscribe($pattern)"; case USER_ASSIGNED: return "assign($partitions)"; } } ```
Should we eventually shutdown the broker due to the IOException? IIUC, currently the exception gets logged and only the consumer thread dies. cc @junrao
Not sure what has changed here.
For this specific API, I suspect it is ever commonly used in PAPI, so I'm fine with not supporting it right away, also as a way to encourage users to change code sooner than later, if there's anyone.
Moved from the MeteredKeyValueStore. I still hope we can refactor the store hierarchy later to get rid of this entirely.
I would suggest using `try with resources`: https://docs.oracle.com/javase/tutorial/essential/exceptions/tryResourceClose.html
My preference is to reduce the number of parameters where we can, especially for consistency WRT KIP-182, but I don't have a strong opinion, so I'd be okay if we left it as well.
If you want to do this, you could use `ThreadLocalRandom`.
`<code>` -> `</code>`
Passing in a `JsonNodeFactory` instance might be better here, because then the `JsonConverter` instances and `JsonDeserializer` in each converter will all use the same `JsonNodeFactory`. As it currently stands, the `JsonDeserializer` has it's own instance of the `JsonNodeFactory`, and it's possible that they could be set up differently in the future and not caught.
+1 -- also below in other tests.
How about: ```suggestion + "/opt/connectors\n" + "Do not use config provider variables in this property, since the raw path is used " + "by the worker's scanner before config providers are initialized and used to " + "replace variables."; ```
I changed the type to boolean here (and on line 89) - compilation passed. This would avoid unboxing.
nit: these can be replaced by `if self.jmx_tool`
I am thinking that, without any idea of how the ratio is affected by this config, users will choose either 0 or MAX_INT. Not a big deal for me if you don't bother to get it.
Nit: `streamsBuilder` -> `builder`
This closes the task since the second parameter is true -- I don't think we can just skip over this step entirely. I'm also not sure what we expect the semantics for flush() to be if offset commit is not enabled (and this might need clarification in the KIP as well). The flush() call here may not be superfluous if the connector uses that as a signal that it should flush and commit offsets (all in the destination system).
If we want the burst to be more similar to original behavior, it seems like this should be `#samples`. With the current implementation, we can do 1 unit of work in the oldest window and then accept a burst right at the end of the last (not full yet) sample. Which means that the max burst size is almost at #samples * quota (if sample = 1 sec, quota is in units/second). Does this sound right to you? Also, I think we should take into account `config.timeWindowMs`, because it could be something other than 1 second.
Hey, I'm sorry, but can you explain what's going on here? `Sensor` doesn't override `equals`, so I'm not seeing how this assertion works.
Does this factory need to extend key-value store factory? It seems a general in-memory factory, not specifically for key-value stores, right? And same for OffHeapFactory.
as above update test name
nit: Seems that this is not the right place for this method. It's now between static and non-static field members. It's used in the constructor, but still, it should probably be placed lower in the class.
It might make sense to either a) get rid of the caching of aliases or b) fill the entries in proactively during loading of classes. Then we would be able to make `pluginLoaders` non-concurrent and make this class simpler to reason about since all data would be filled in during initialization.
Nit: `A method for getting...` sounds clumsy to me
Just realised we don't need this anymore.
Haha, to clarify, I was trying to suggest moving this line above null check. Something like this: ``` java FetchMetrics topicFetchMetric = this.topicFetchMetrics.get(topic); if (topicFetchMetric == null) { topicFetchMetric = new FetchMetrics(); this.topicFetchMetrics.put(topic, topicFetchMetric); } ```
@hachikuji I suppose that depends on whether you find booleans eventually become confusing at the call site.
Should we have a case for the old consumer too? I think we can delete one of the 0_9_0 tests, since there are so many of them.
This is definitely much clearer than the first try!
Could we put this test to `AbstractKeyValueStoreTest` so that all types of kv stores will test it? Ditto below.
We can merge these two functions into one since the `hasSstFiles()` is the only caller of `hasSstFiles(File)`.
I'd suggest using 100ms not 10ms, since this call is in a larger while loop in `StreamThread.runOnce`, and hence I concern doing `poll(0)` would unnecessarily increase the restoration latency.
Regarding your latter point, I think you are conflating two different things. This `close` method does the same as `flush` in that it calls `writeBlock`. So it is correctly implemented. The thing that changed is that for the underlying stream, it calls `close` without calling `flush`. Anyway, we can be conservative and do a `out.flush()` before `out.close()`. I think that's clearer than calling the `flush` since `finished = true` already.
nit: don't need `<K, V>` can just be `<>`
nit: ```suggestion " is empty, without a committed record. Falling back to latest known offset."); ```
I could be missing something but a range of 1 to 9 state stores seems large to me for an individual task to have
We definitely need `@Override` annotation to make clear that we change how `scan(url)` will function when is called by `scan()` on the base class.
This is all the same for all three methods except for the `KStreamAggregate`/`KStreamWindowAggregate`/etc right? I think if you wanted to further deduplicate things you could factor this out into a method that accepts a `Function< KGroupedStreamImpl, KStreamAggProcessorSupplier`>, and then each of the `build` methods can just pass in a function that returns `new KStreamWindowAggregate` or so on. I'm not sure it's really worth it or not, but it can be done in case you were wondering. Up to you whether you want to do it
original was better
nit: `{@code null}`
`KafkaProducer.partitionsFor()` could block up to max-block-time when the metadata of the topic does not exist, so if it returns null it means the producer cannot fetch the metadata within the block time period, which should not be common. Also the same function will be called in `send()` and if it returns null we treat it as an unexpected error.
nit: I guess you could use `computeIfAbsent` here as well
I see the problem with original approach after looking your test case. Now I think the new approach is correct.
```suggestion throw new ConfigException(innerSerdePropertyName, innerSerdeClassOrName, "Deserializer's inner serde class \"" + innerSerdeClassOrName + "\" was not a valid Serde/Deserializer."); ```
I think, we should not keep this constructor. It seems to me that we risk to have different time objects for thread/tasks and their producers which has the potential to lead to inconsistent time between these components. If the removal of the constructor makes this PR too large (and I suspect it will), I recommend to make a separate refactoring for this constructor change and get that merged before this PR.
nit: break line (too long)
At a high level, our store ecosystem looks like an onion. On the outside, we have a <K,V> store, and on the inside, we have a <bytes,bytes> store. All the layers in between have different responsibilities, like changelogging, caching, add metrics, etc. The nice thing about this PR is that it gives us one clean layer that's responsible for the transition `<K,V> <=> <bytes, bytes>`. When we need to look at the de/serialization into/out-of the stores, we have exactly one place to look. The prior code did mostly this, but to accommodate cache flushing in conjunction with the fact that the cache layer is below the transition from objects to bytes, we had to poke a hole in the onion and tell the caching layer (a bytes layer) how to deserialize. So, then there were two layers that independently know how to de/serialize, and the onion had a hole in it. This idea to move the serialization out to the TupleForwarder is basically the same, but in the opposite direction. Again, there are two components that need to perform serialization (the serialization layer and the tuple forwarder), and again, we need to poke a hole in the onion so that the tuple forwarder can communicate directly with an inner layer. It's not always practical to go for a "pure" design, but if readability is the goal, then it seems like we should try to avoid mixing layers, unwrapping layers, etc. as much as possible. To be fair, this is just my take on the situation.
This needs to be there otherwise the test won't run
Not sure, if we need this here either -- input stream and output stream do have same type -- and Serdes are actually used to write and read.
As above: add a `topologyDescription` verification step -- we should see a repartition topic. We should also not get a state store when reading the data from the repartition topic into the `KTable` for this case.
This will be a little annoying to handle when we incorporate the client compatibility KIP since we'll have to check for the presence of these errors at both levels. One option might be to enhance the parsing of the response to check for the presence of one of the top-level errors in the partition data. If it is there, we could insert it at the top level as well. Currently I think we just put `Errors.NONE` at the top level for old versions.
Would it be possible to describe the strategy in more detail here? Something along the lines of how each record is assigned a new partition? I also wonder if it suffices to describe the RoundRobinPartitioner as the `strategy can be used when user wants to distribute the writes to all partitions equally`. In many cases, the DefaultPartitioner also tries to do this, though I am aware of the cases where it doesn't. (https://issues.apache.org/jira/browse/KAFKA-10888).
OK. Let's leave it as it is for now. My larger point is that the sticky assignor should be a pure function. It takes inputs (subscriptions) and generates outputs (assignments). There shouldn't be any need to carry state between rebalances. It sounds like that is just a convenience for test purposes. In a follow-up, we should try to improve this.
unnecessary type in constructor, can use `new HashMap<>()`
Actually the constructor of all such description classes can just be default package-private since they are only used by KafkaAdminClient, and hence can just be private APIs, and we do not need to deprecate-overload any more.
nit: Let's make all variables as final or none in this block.
What about promotion? We need to actually perform the type promotion. It isn't valid, for example, to use an `int8` field's `Byte` value directly for a `float32` field.
From String#compareTo() ``` while (k < lim) { char c1 = v1[k]; char c2 = v2[k]; if (c1 != c2) { return c1 - c2; ``` Should the size comparison follow the same ordering ? i.e. size1 - size2
This is for statically use this single util function (otherwise we have to call `ValueAndTimestamp.getValueOrNull` when calling).
ditto on removing before/after.
Currently this is reverse order. Probably better to just do `return Integer.compare(k1.orderInGroup, k2.orderInGroup)` here.
nit: `repartitionNameOverride` won't ever be `null` from doing the checks for the name on lines 571 and 576, so we can get rid of this line
Sure, I understand that. That was not the question, but might not be too important anyway.
Note that the restore-consumer is shared for both restoring active tasks, as well as for updating standby tasks, and it would only start updating standby tasks until all active tasks has completed restoring and now in running state. This means at a given time, the restore-consumer would only be assigned with restoring active tasks, or with standby tasks; on the other hand, the `changelogReader` is only used for restoring active tasks. So far this logic is still correct, but I'd suggest we handle such two cases like `closeSuspendedActiveTasks` and `closeStandbyTasks` separately, and also clear standby records / reassign restore-consumer separately.
nit: remove empty lines
`localIdOrSentinel` would be more accurate, I think.
nit: indent not aligned, as @mjsax mentioned above.
We need to specify what are the input message format needed for the value string: it seems needed to be an integer. Also stating the full string of the cmd line tool would help.
Can do this in a follow-on
Right, now I remembered, we had this issue in Kafka Streams Java Doc as well. For consistency how about just add the prefix for each exception? Admittedly for some of them it is not necessary.
How about this: `If the reduce function returns null, it is then interpreted as deletion for the key, and future messages of the same key coming from upstream operators will be handled as newly initialized value`.
Nitpick, how about: ``` java public static File tempDirectory(Path parent, String prefix) { final File file; prefix = prefix == null ? "kafka-" : prefix; try { file = parent == null ? Files.createTempDirectory(prefix).toFile() : Files.createTempDirectory(parent, prefix).toFile(); } catch (IOException e) { throw new RuntimeException("Failed to create temporary directory", e); } file.deleteOnExit(); Runtime.getRuntime().addShutdownHook(new Thread() { @Override public void run() { Utils.delete(file); } }); return file; } ```
Just to clarify, you do not need to create 12 tasks to reproduce the issue, just task10 and task00..05 should be sufficient..
This seems to have the same issue as in SaslClient in that we need the logic to turn off OP_WRITE here too. Suppose that the server tries to send a token, but couldn't completely flush the writes. We get in here and completely flush the output buffer. Now, if the OP_WRITE is not turned off, the selector will be woken up all the time before the server receives the next token from the client.
we remove `try-catch-fail` here -- if there is an exception the test won't pass anyway. (same below)
I don't think this is necessary. The SecurityFileChangeListener thread may not yet have started, but the watch services are already registered after `factory.configure(configs)`. The file change below should queue a change even if the thread hasn't started.
nit: extra newline
typo `operaate` -> `operate`
@chia7712 `InterruptedException` is not thrown anymore; This method does not call `KafkaFutureImpl#get` method anymore. It's safe to remove it.
Why does this need to be a `Long` instead of a `long`? The numerical value of the variable is only immutable if we use a `long` here.
Wild thought: should we let `unlock` return a boolean indicating if the unlock is executed, and assert `unlock` here instead of line 317 below? Maybe can be done in another PR.
Should we have a variable for the data directory? It seems like we reference it in many places.
thanks. that sounds good! can you name it something like `consumer_supports_bootstrap_server`? There are a bunch of other bootstrap server functions (`acl_command_supports_bootstrap_server`, `topic_command_supports_bootstrap_server`, etc.) so it would be good to be clear
Is it possible to trigger infinite loop: raiseError -> reconfig -> raiseError -> reconfig ...
{code..} than -> A client supplier that..
Nit: Can we keep `SUSPENDED` after `RUNNING` case? We use the same order in all methods and always follow the "natural" state transition order, that is CREATE, RESTORING, RUNNING, SUSPENDED, CLOSED.
We need to update this based on what the previous registration was, if any. If the previous registration was also fenced, we do not want to increase the fenced broker count. It is also possible for the new registration to start as unfenced. Please look at the record definitions. It would be useful to have a helper function that took as an argument the previous registration (or null) and the new registration (or null), and updated the metrics accordingly.
Log this kind of stuff at `debug`, it's useful info to have
nit: line to long (break each parameter in it's own line)
If this line is duplicated, it should go in a method. When I proposed to move it inline, I was apparently not aware that the same line was used somewhere else.
I don't have a strong preference, it seemed a bit more resilient to changes elsewhere, but it is a private method as you said.
we shouldn't enforce. un-schema'd formats like json might be fine sharing the topic. we should continue to discuss what additional metadata we add to the DLQ messages, but with the right metadata, there's really no problem sharing the same queue if someone wants that simplicity. even in decoding avro, they can still decode based on schema ID, they just need enough context to figure out what to do with it
Yes, it looks like it affects the log message printed, right? It doesn't explain the behavior you are seeing.
Nit: `Note, this maximum number offsets` is redundant right? Seems like "Only used in ListOffsetRequest v0" would be a more concise version and achieve the same thing. Same applies for every similar instance in this PR.
This is only one reason why the request might be invalid. Probably best to just say "if the request was invalid" -- the specific exception text explains more about why it was invalid.
Maybe we can combine this log message with the initialization one below? The `subscribe` API does not actually do any IO or anything, so it doesn't seem worth logging separately, though it does seem useful to know what topics are being subscribed to.
Aha, so there was a good reason for it ð
Nit: keep the text of L672 and here in sync.
This could be: ``` .reduce( (value1, value2) -> Math.max(Integer.parseInt(value1), Integer.parseInt(value2)) ) ```
I don't think this one needs to change. AFAICT it is only `transform` that has the issue
"or null if this was not redirected"
I see. Thanks.
This is the default.
While I'm in favor of code re-use, in this case, the code in `Topic.validate` is not too large and could be easily ported to a `Named.validate` method. By doing so, Kafka Streams can change naming rules as needed. I realize that `Materialized.as` uses`Topic.validate` to validate the name of the store, but I'd suggest updating to use `Named.validate` there as well. NOTE: If we do this, we'd need to update the KIP EDIT: Actually I'm not sure we'd need to update the KIP as most likely this method would not be publicly accessible.
It's a bit anti-pattern to use `null` and `""` indicating two different sentinel cases: the partitions is owned by different clients, or the task is new. I think there's a better way to save on not redundantly iterating through taskPartitions: e.g. we let it to return a `Collection<String>` (and rename to `previousConsumers...` which is the union of the claimed owners of the partitions, and then in the caller we can just treat: 1) it's a singleton, 2) it's empty, 3) it's a plural, differently.
Catching `Throwable` will also catch errors which I don't think we want to do. But I don't even think we want to catch all exceptions and rethrow them as unchecked. The `deleteAllTopics` method is already marked as throwing `Exception`. If anything is thrown, we can let it bubble up and fail the test.
It's not introduce in this PR, but while reviewing it I found in `OffsetAndMetadata` we are storing nullable `Integer` directly whereas in `OffsetAndTimestamp` and here we are still maintaining the `Optional<Integer>`. Maybe it's better to make the first one consistent with others.
Even though UpdateMetadataRequest_v0 has identical structure as LeaderAndIsrRequest_v0, the set of brokers used are slightly different. In UpdateMetadataRequest_v0, we pass in all live brokers. In LeaderAndIsrRequest_v0, we pass in all live brokers that are the leaders. So, we can keep the names as they are.
nit: a bit more natural? ```java if (results != null && results.size() != futures.size()) { ```
Typically, I would prefix such an implementation detail with, doh, "Implementation detail: ....". This highlights that the information is not part of the API contract, but rather a FYI.
nit: use `assertThrows` instead of try-fail-catch construct.
would `RECORD_TRANSFER_MAX_DURATION` be a better name here? `RECORD_MAX_DURATION_MS` seemed to indicate that we are recording the max duration.
I'm not sure this should be necessary either. IIUC, the "future" subscription info isn't supposed to really be a descendant of the current protocol, just a stand-in for _some_ protocol version bigger than ours, in which case all that really matters is the version number. Its role is just to join the cluster and get downgraded to the "latest" version, in which case it should be able to defer to SubscriptionInfo.
I feel that generally speaking the `commit-on-every-pipeInput` of TopologyTestDriver is debatable, especially since we call `pipeInput` recursively from repartition topics, which means each of the new / old records via the repartition topic would be triggering once. Will merge this PR still as-is and we can discuss if we want to change this behavior later.
Yeah, protocol changes definitely need a KIP. Probably makes sense then to split the bug fix into a separate patch.
A little confusing to set `local_temp_dir = "/tmp"` since it in theory should never be set to `/tmp` I think this line is actually not necessary since `local_temp_dir` can be set inside the try block, and be available to the surrounding scope
With 2) under eos-beta, when committing the txn we would avoidably commit the sent records from other tasks; so I'm wondering if we should also commit them as well, otherwise some outgoing records would be included in the txn while the incoming partition offsets would not be committed.
requires new constructor. Same below in other places
Ah. That makes sense. Thanks! Not sure if we want/need to change the behavior. Also, it would require a KIP imho, because people may have tests in place testing for the current behavior... Not sure if it's worth it.
nit: we could make the warn log entry more clear that we did not override the registered the store, e.g. "Skipped registering state store {} since it has already existed in the state manager, ..."
Okay :) I guess it is personal taste then, I'm going to merge as is.
Great to see this test case !
On the other hand I was debating whether it's worth to use `buf.duplicate().get()` instead of flipping on the expense of creating a lightweight ByteBuffer object. Advantages is that we don't mutate the current buffer but instead work on a throwaway object.
There's still a usage as `applicationId + "-" + topic` in the `SinkNodeFactory` subclass. The structure of that class is now a bit odd as the `applicationId` is passed as a parameter, but it's a non-static so it captures the parent reference and actually uses it for at least one other member of the parent class (`internalTopicNames`). I'm fine committing as is if this is consistent with trunk since then a clean up could easily be cherry picked if that was desired. But it looks like this patch and what's on trunk differ significantly. This method name doesn't even seem to exist on trunk? Are you sure you want to diverge so wildly? It's going to make any more backports/cherrypicks really annoying...
I think we can leave `WakeupException` and `InterruptException` out of this. In both of these cases, we would probably just want the application to close. I think the main thing we want this example to show is the "normal operating" exceptions.
I will make a separate PR to fix this.
I think marking it as deprecated in html would be better than skipping it. So if #2456 is definitely going in we can close this PR then.
we're in Java8 now... I think you can do: `(key,value,context) -> { ... }`
Seems good enough as a bug fix, but I was wondering whether we could detect the dynamic topic is configured or not to make sure we are not actually allowing some other bugs to catch in TTD
We don't need any of the 3 lines above right? We do it all inside the finally.
OK. So strictly speaking this patch changes behavior in the sense that `out.flush()` is not guaranteed to be called. I would have kept it just to avoid unnecessary problem in the future if I were to write this patch. I really don't think an extra line of `out.flush()` would be a problem. But since the patch is already committed, I would't bother to change it as well since there is very little chance this can be a problem.
Use one line per parameter? Ditto below.
Can we cover the other error cases? For example, INVALID_REQUEST and UNKNOWN_TOPIC_OR_PARTITION. It also looks like it's possible to receive no error, but an unknown offset. Having all of these test cases protects us when we change the code in the future.
Shouldn't catch the exception since https://github.com/apache/kafka/pull/1778/files#diff-10752971682d4575c93ddec45e0553f0L762
@rondagostino Thanks for the PR. Couldn't we just use substring until the first "=" ? Something like this would be easier to read? ``` int index = urlSafeBase64EncodedUUID.indexOf('='); return index > 0 ? urlSafeBase64EncodedUUID.substring(0, index) : urlSafeBase64EncodedUUID; ```
Perhaps this can be private and we can expose a `buildUnsafe` method that sets `validate` to false. Then we will be less tempted to accidentally use the API.
I think this change is debatable. You make it a bit more visible that the lock is held when mutating the structure, but some of the logic is duplicated. I'd leave it as it was, personally.
anti-pattern: ``` if (...) { return x; } else if (...) { return y; } else { return z; } ``` Can be simplified to: ``` if (...) { return x; } if (...) { return y; } return z; ```
This should be `private` not `public`.
Instead of using `toMap`, can't we just to `new HashMap<String,String>(props)`
```suggestion resizeThreadCache(threads.size() + 1); ```
There should never be multiple requests, right? If there were, a second request might arrive between 168 and 169, violating the desired property. In that case, we should grab a lock instead. As long as there's only one requesting thread, and it always waits for the commit right after requesting, then we should be good.
Maybe worth a mention that only the legacy `ControlledShutdown` is missing the client id field.
I would restructure all these fields like: ```java private final long startMs; private final long sleepTimeNs; private final long targetThroughput; private long sleepDeficitNs = 0; private boolean wakeup = false; ```
That class is different because it doesn't actually `define` the config, it's just an undeclared "extra" config that gets passed around to be interpreted inside the serde. Actually, this _is_ a bug, and that config _should_ be `define`d there the way you do it here.
Might be nice to rewrite this using `assertThrows` ? (Similar below.)
+1 to what @mjsax said. The `source` should never be null. So you should change the `StreamThreadStateStoreProviderTest`. It just needs to have the topic name extracted to a field on line 73. And then that same topic name used on line 189 in `new TopicPartition(...)`
Could we make sun.security.jgss.native a property in the broker/client config file? In general, it seems that other than the jaas config file, it's better to specify other properties from config file instead of system properties.
I would assign `storeToChangelog.getKey()` to a variable called `storeName` to make the code more readable.
Do we need `String.format` here? Seems like String concat would be fine.
```suggestion addValueMetricToSensor( sensor, TASK_LEVEL_GROUP, streamsMetrics.taskLevelTagMap(threadId, taskId), name, PROCESS_RATIO_DESCRIPTION ); ``` req: Please use `StreamsMetricsImpl#addValueMetricToSensor()`
This is wrong. Unsynchronized access to a map could cause more than just "stale or inconsistent" data. It could cause null pointer exceptions or other issues. We cannot access this without synchronization.
For suspended tasks, could the closure process be simpler? For example we have already closed the topology as well as committing the states, etc. Ditto below.
The idea is that `Configuration` can be set in other ways (see the PR discussion), so we fail if we can't find the configuration (a few lines below), not if we can't find the system property.
Ditto, check `topicNamesList` below.
```suggestion * A byte array comparator used on lexicographic ordering, but only comparing prefixes. ```
I am not sure what you mean by `test multiple reads` here. I think we're testing two things here: 1. That the first read doesn't cause a side-effect to the channel that could prevent the second read from succeeding. 2. That we can read into a smaller buffer than what's in the file channel. "multiple reads" is a little unclear as it sounds like we are causing the underlying file channel to do multiple reads, which I don't think we are.
Ditto on the properties and the driver.
For future-proof: if we pre-register the members then starting all three would still have one rebalance, and hence stableGeneration would be 1 here. So instead of hard-code it to `3` assuming always three rebalances, we can just use extract_generation_from_logs to assign to `stableGeneration` instead.
Do we need an integration test for this? Using `Topology#describe()`, I think we could verify this with a unit test.
Could you also verify that the stream thread was not replaced? You could use `KafkaStreams#metadataForLocalThreads()` for that.
I don't think we need a synchronized block here since `start()` is always called once at the very start
I don't think it's necessary to keep a central registry of all this information for all connections. We really just need the metrics, most of which can just be simple counters. If we need more information about a connection, we can look at the request context of that connection. But it doesn't have to be stored here.
Yes. Sorry for using the wrong name...
Are we sure this should not be an error? Should we not rethrow the exception? After all it may make data readable to the outside world. I do not request a change, I just wanted to put it up for discussions.
This may indicate a bug in `SessionWindowedDeserializer`
The current implementation of `addToCompletedReceives` moves receives from staged to completed state if the channel is not muted. I think it will better to replace `!channel.isMute()` with `!explicitlyMutedChannels.contains(channel)`. Buffers have already been allocated for the staged receives, so we should allow them to make progress and release the buffers.
This can be static
nit: align params
value type is `long`
When Dana implemented exponential backoff, she disabled it for Streams and Connect. I don't think there's a good reason not to enable it for those two and hence this PR. In the Streams case, I think those two configs are actually used for the `StreamsKafkaClient`.
I'd suggest copying and using what we've been using elsewhere to assert that a connector and its tasks are up and running: https://github.com/apache/kafka/blob/trunk/connect/runtime/src/test/java/org/apache/kafka/connect/integration/RebalanceSourceConnectorsIntegrationTest.java#L324-L337 It works fine with the `waitForCondition` method that accepts a timeout. Eventually (maybe soon) this type of assertion will go to `EmbeddedConnectCluster` and will be made available for every Connect integration test. However, I suggest we don't take on this refactoring now and we just copy the method from the test above.
Never seen it in Kafka or in other software? I don't think it's a bad idea to accept the current time as a parameter. It makes your code way more testable for one thing
We might want to add a min version check as well, based on #986 changes.
The restore consumer needs to override one param: `consumerProps.put(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, "earliest");`
Ah got it, I'm still think about it as the string template and was overlooking that. SG.
For `reportingStoreListener`, better rename it to `globalStoreListener` as it is the instance-level listener, but it is not necessarily used for reporting only.
nit: add `final`
This won't log the error. We want to use the public void error(String msg, Throwable t); overload, so we need to change e.getMessage() -> e
I actually like `RankedClient` more. Thank you!
minor: we can just calculate the `numPartitions` in this overload, and then in the other which has `numPartitions` passed in always blindly use that one.
maybe use `TestUtils.waitForCondition` here while not probable this could hang.
Not a big deal, but since you're using both key and value, you might want to just iterate over `entrySet` instead of `keySet`.
Currently our equals method assumes non-null addresses. I can't think of a case where we would want it.
Oh sorry, I misunderstood the code.
I mean the `ProductionExceptionHandlerResponse` class itself
typo: **longer** than
How about making ```SizeDelimitedSend``` be a static method in ```ByteBufferSend```? For example: ```java public static Send withSizeDelimited(ByteBuffer buffer) { ByteBuffer sizeBuffer = ByteBuffer.allocate(4); sizeBuffer.putInt(0, buffer.remaining()); return new ByteBufferSend(sizeBuffer, buffer); } ```
`doWork` is just one iteration. `ShutdownableThread` has the loop. I'm ok with the change, but we probably will need to copy over some of the shutdown logic.
As far as I can tell, it shouldn't be possible to abort a batch after it has been completed. Is this correct? If so, I think it might be better to continue to raise `IllegalStateException`. It's preferable to keep the allowable state transitions as narrowly defined as possible since it ensures faster failure for unexpected paths.
Maybe we can close the first group here and verify that the sensors/metrics are no longer registered? A similar check for the sink would be good.
But `ProcessorStateManager` doesn't handle global tasks
I am not entirely sure about this. I think that `SASL_JAAS_CONFIG` should be prefixed with the SASL mechanism otherwise we ignore it. In this case, we log a warning in `loadServerContext`. I suppose this is the reason why we don't use a generic message for both cases here. It does not make sense to say that `SASL_JAAS_CONFIG` is not set if we don't use it without the prefix.
unnecessary whitespace change
Maybe we could make this assertion precise? I think we expect the request count to be 0.
@SinghAsDev you are not increasing `pos`! It should be `topicsToSubscribe[pos++] = topic`, right? In fact, I would use a list as below: ``` List<String> topicsToSubscribe = new ArrayList<>(partitions.size()); blahblahblah .... subscribeTopics(topicsToSubscribe.toArray(new String[0]), true); ``` But I am fine with the array too.
nit: ```suggestion final Set<String> logMessages = appender.getEvents().stream() .filter(e -> e.getLevel().equals("WARN")) .map(LogCaptureAppender.Event::getMessage) .collect(Collectors.toSet()); ```
Since`keysWithBytesBuffered` was cleared earlier, it needs to be populated regardless of the status of staged receives. I think `"if(..) { keysWithBytesBuffered.add(..); }"` should be done outside the outer if that checks staged receives.
For this case, we should not get a state store.
Line 124 here seems not correct any more: now that we've initialized `assignedActiveTasks` it would never be null. And since we added `addedActiveTasks` we should not condition on `assignedActiveTasks.isEmpty()` anymore.
The prefix for kilo, is lowercase `k`
Yes, that's more or less what I was concerned about. We are trying to achieve a specific result here (and brand-new 'Header' instance each time), but it's only achieved via a side effect. On the other hand, I just took a closer look at the code, and I see that there's a better reason to keep using `ConsumerRecord`, namely that `updateProcessorContext` is used both for regular processing (with "real" records) and for punctuation here with this dummy record. It seems like a good idea to prevent those code paths from diverging, so I'm +1 with keeping this change as-is.
Does it make sense to change the parameters to `Integer firstBroker, Integer... rest)`? Then assert if `firstBroker` is null. That will make sure that we don't get empty list of brokers and rest of the code that handles this object doesn't have to bother about this case.
No reformatting, please
nit: add `final` (same below)
Well, it's not at the end of the file right? But if you'd prefer to keep it that's fine too, was just a "super nit" suggestion ð
Oh, I see. Definitely wasn't obvious by reading the test.
This probably needs to check `clientResponse.hasResponse()` otherwise it could throw `NullPointerException`
There's some redundancy here. SMT=Single Message Transform + transformation Given that you log the name of the transformation I'd use `"Applying transformation {} to {}"`
I think we can do it in a follow-up PR after merging this one.
Well, the `FallbackPriorTaskAssignor` also gets the same input but can't look at the lags. I figured if we're going to make a distinction between assignors that can check the lags and those that can't, StickyTaskAssignor should fall into the latter category.
oh sorry, I forgot this is the condition for staying in the loop. my mistake.
Need to change ">=" to ">" in the exception statement here.
Nit: add newline
should this have a suffix at all? I don't think the `funcName` requires one. If it does, at a minimum we should not use `-sink` as it's used above and doesn't accurately describe its role.
You also get futures back when you submit them, so you can also get that barrier by waiting on the futures. But this seems fine too, I don't think collecting the entire set would cause any problems.
Yes, I understand the need to have a length at the tagged field level. Mainly I was thinking about the redundancy when the type of the tagged field is known. It's a little annoying to serialize the string length twice, for example. Anyway, thanks for explaining.
Can we actually include UUID type? It always 16 bytes.
That is correct. Though for "windowed KTable", I think it is simply a list of tables where each table represents the aggregate results for that window. As for the docstring we are only talking about key value types for windowed operations, while talking about semantics for non-windowed operations, which is inconsistent. More specifically, for non-windowed aggregation, if we say: `returns a {@link KTable} that contains records with unmodified keys and values for type <R> that represent the latest (rolling) aggregate for each key.` Then for non-windowed aggregation, we should be equivalently informative: `returns a windowed {@link KTable} which can be treated as a list of {@code KTable}s where each table contains records with unmodified keys and values for type <R> that represent the latest (rolling) aggregate for each key within that window.`
Is there a way to make this sentence bold? :)
Did you mean: ```suggestion setBrokerId(3). setBrokerEpoch(100). ```
Do we need a newline here, either at the beginning or the end? Depending on who happens to edit the `console_consumer.properties` file last and whether their editor leaves newlines at the end of files, it seems like this could break.
This means that if there is no change to a remoteLogMetadataCache, but there is new record for other partitions in the same metadataPartition, we still need to flush remoteLogMetadataCache.
Default methods are not going to port backward past `2.0`, since default methods are a Java 8 feature. To work with Java 7, you'd have to make this an abstract class. I'm not sure it's worth that change, since there are quite a few other things that will likely have to change when backporting. For example, `HeaderConverter` was introduced in AK 1.1, and `ConfigProvider` was introduced in AK 2.0. Removing these won't be trivial, so that means we're probably going to need separate PRs for some of these older branches.
Ack. Fine to leave as is -- was just a thought.
I like this. We will be able to pack port this to `2.0`, `1.1`, and `1.0` branch -- not sure if there will ever be a `0.11.0.4` branch -- thus, might not be worth do back port further to support 4-digits.
If using `ConfigDef.Validator`, all of these lines would go away, and we actually don't need mocks of any kind.
Are all `SSLExceptions` fatal? Also, we should probably update the log message.
It might still be nice to see the stacktrace here (even if it also gets logged elsewhere). If you want to do it, don't forget you have to change to using `String.format` for the variable substitution. I don't feel strongly in this case, so I'll defer to you whether you want to do this or not.
I thought it was called `rightWinAgg` because it's the aggregate that goes in the current record's right window. Of course we had to find this aggregate from some other existing window, eg from the "last window left of the current record".
we should avoid to use this construct but use `assertThrows()` instead.
make params `final`
Not necessarily something we have to do here, but I think we should be able to get rid of this loop and just rely on the next iteration of `runOnce()` to handle retries.
Why not simply: `TestUtils.tempDirectory("qs-test")`? That will use the OS's default temp directory (more concise and better behaviour IMO).
I see. Fine with my both ways -- as long as it's intentional and we know about it, it's ok.
Suggest just using "return" here. Then you can have the loop be a regular for loop.
This is not actually needed.
We could change `DefaultRecord.readFrom` to take a `DataInput` (instead of `DataInputStream`), change `KafkaLZ4BlockInputStream` to implement `DataInput` and then only wrap if the returned value is not already a `DataInput`. That would remove a layer of indirection and if it's possible to implement `readFully` more efficiently in `KafkaLZ4BlockInputStream`, then it could be a win. If you have time, it may be worth a try.
Can we easily make these non-static and protected so that they can be customized by a subclass if needed? We should avoid making too many changes other than what's required, but if this only affects a few other lines it might be worth it.
Should we remove this class? Currently they can only be 2 types of connectors, source or sink connectors. This seems to introduce a third implementation of the `abstract Connector` class, but testing seems sufficient without it.
nit: `pc` -> `oldProcessorContext` `apiPc` -> `newProessorContext` `ssc` -> `stateStoreContext` below `c` -> `context`
req: Please rename this unit test to reflect the new verifications.
+1 - this line and the next shouldn't be needed
typos: Drop "is an" before "fatal error"
MetricsReporters have been optionally reconfigurable since 1.1.0, before Java 7 support was dropped. Any metrics reporter implementation that implements Reconfigurable is reconfigured by the broker when any of its configs changes. Since then, we have adopted the same approach for other interfaces like Authorizer as well.
nit: we can combine these two `try` blocks: ```java try (LocalLogManagerTestEnv logEnv = new LocalLogManagerTestEnv(1, Optional.empty()); QuorumControllerTestEnv controlEnv = new QuorumControllerTestEnv(logEnv, b -> b.setConfigDefs(CONFIGS), Optional.of(sessionTimeoutSec))) { ... ```
@gwenshap meant that `kafka.common.Topic.InternalTopics` should be removed in favour of the `INTERNAL_TOPICS` defined in this PR.
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
This would be less mysterious if this method were inlined into `updateLimitOffsets`. Right now, it's not terribly clear why it's ok to set the "last update offset time" in a method that doesn't update the offsets.
Looks like a styling issue is failing the build. A whitespace is missing before and after a couple of`+`'s on this line.
nit: move this to where we call `enforceRebalance` as well
Actually I was only suggesting to make the current Dual accessor to be more general currently it assumes the `old` to be `default`, and `new` to be `withTimestamp`. what I was suggesting is only to make these two parameterized; so that in the future we only have two accessor impls: 1) XX-CF only; which we already do in this PR. 2) XX-to-YY upgrade: old XX CF to YY CF upgrade accessor. All that being said, I'm okay with such refactoring as follow-ups.
nit: we prefer the following formatting (similar below) ``` public void onRestoreStart(final TopicPartition topicPartition, final String storeName, final long startingOffset, final long endingOffset) { ```
this one, too
Maybe we should say `initialized` instead of `created` for consistency with the consumer.
I think we can just have one function between `values` and `groups` here. I'd suggest we use ``` public Map<TopicPartition, KafkaFuture<Void>> deletedGroups() ```
Nit: add `final` to parameters
Yeah, I am not sure. I was thinking we might run into situations where we are trying to detect when a cached image has changed. It is a conventional thing to do, but I don't feel too strongly about it.
Yes, we should remove `sleep` in the tests and ensure they work without them.
nit: let's move `keyTo == null` up first so that if it does not satisfy, we do not need to trigger `getKey` anymore.
minor: seems like we got rid of the `new_consumer` parameter in the other cases below when using the default.
Don't need to copy the future here. We're synchronized so the couple of lines can be reduced to `client.poll(joinFuture)`.
```suggestion left.join( right, (value1, value2) -> value1 + value2, joinWindows, streamJoined ); ```
Users can make it consistent using connect API's configuration. For now, to keep the backward compatibility for the most use-cases, let's fix `isInternalTopic`
For readability, could we mark the final results for each window? We want to make sure all the intermediate results are as expected, but what we really care about is what we got in the end. It would just help to have the critical output easier to find and get oriented in the tests
(nit): not sure if this is any clearer that `1` (and `0`) above.
With the above change, this would be `new KStreamMap<>(new KeyValueMapper<K, V, KeyValue<K1, V>>) { apply(k, v -> new KeyValue(mapper.apply(k, v), v))}`
Should we indicate the method of leader election that was performed here? Or at least indicate if it was an unclean election
Ah. Great catch!
Hmm.. I think it should be ``` self.driver.stop() self.driver.wait() ``` instead as used in other places. Not sure why the test itself did not fail though, without calling `stop()` the `wait()` call should fail.
`.size() == 0` => `isEmpty()`
nit: additional new line
:+1: It looks like the two-arg constructor is unused.
new line for `MockValueJoiner`
nit: I think the check for `userConfiguredTransactions` is redundant now.
Should be `final` here.
It's just noise. They can make sense in cases where it's not obvious that an empty implementation is desired, but `configure` is not one of those cases.
Alternatively, now that we enforce checkpoint during suspension, we could just remove the `pre/postCommit` for active tasks in `handleAssignment`. It just seems nice to be able to assert that we never call `pre/postCommit` after a task is suspended
Nit: rename `vts`
My rationale is mainly around typos :) In the past I have some experience spending much time on troubleshooting a typo caused issue, since these issues are usually not well exposed in the exception messages, e.g. if you had a `stream-record-cach-metrics` in one of the lines it would be hard to find out..
Does it make sense to actually declare the kafka cluster id as in the previous test (member field) and return it here? Maybe the code might start using it at some point.
Apparently the my understanding of `TreeSet` is not accurate. It uses the comparator to decide whether the entries are the same or not. We can use a TreeMap<Long, Set<ProducerBatch>> then. We may also want to bucket the timestamp a little bit, say one second to avoid huge amount of Sets created for each ms in the `TreeMap`.
Should be: ``` Thread.currentThread().interrupt(); ```
might want to highlight the `balanced` pieces below here, that's ultimately the critical bit beyond just running what we expect (which tbh, makes the most important part of these tests hard to find)
OK, looking deeper into this, there is a difference: if someone else had called `setConfiguration`, `getConfiguration` would return that while here we override the value of configuration with the JAAS file. Neither option is ideal, but that's because of the global nature of this setting. I think just using `getConfiguration` is probably better, but I thought I'd mention it here for completeness.
a `toString` override would be nice (as per KIP discussion)
Do you want to prevent NPE? Maybe easier to rewrite to ``` if (props != null && StreamsConfig.OPTIMIZE.equals(props.getProperty(StreamsConfig.TOPOLOGY_OPTIMIZATION))) { ```
@rajinisivaram Sorry should have caught this before -- instead of `time.sleep` here, using `wait_until` on the checks for errors below and then moving the assertion for `self.producer.num_acked == 0` to below those `wait_until`'s might make the test more robust. We'll still have a timeout on the `wait_until` calls, but it can be a lot more conservative and the test may be able to finish a lot faster.
nit: seems like it would be more useful for the log message to indicate the topic ids that changed instead of the unrelated epochs.
nit: feels like overkill to deprecate test cases. Since they reference RETRIES directly, I don't think we need to worry about them not getting removed
