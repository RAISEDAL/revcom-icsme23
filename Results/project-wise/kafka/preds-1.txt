Nit: insert `<p>` tag to actually get the new paragraph rendered. Nit: `Topology -> `{@link Topology}` It's not really clear what "deterministic" means. We should elaborate more.
nit: {@link KGroupedTable}
Btw, we should take the chance and make `version` and `commitId` final. Something like: ```java private static final String version; private static final String commitId; static { Properties props = new Properties(); try (InputStream resourceStream = AppInfoParser.class.getResourceAsStream("/kafka/kafka-version.properties")) { props.load(resourceStream); } catch (Exception e) { log.warn("Error while loading kafka-version.properties :" + e.getMessage()); } version = props.getProperty("version", "unknown").trim(); commitId = props.getProperty("commitId", "unknown").trim(); } ```
nit: move to line above.
I think the answer to this question is that it is possible to expire while the batch is still being built because closing the batch can be arbitrarily delayed by inflight fetches.
I don't think we need this check. It is null from the beginning as there are no global stores associated. Also, as i said above, i think the field should be private
@ewencp Yeah, we can do that and I was debating whether I should suggest it. I wasn't sure if we wanted to make a change that could impact the common path so that the error message could include the thread name for the `currentThread`. You reviewed the original commit that introduced `acquire` and `release`, so you are in a better position to judge. :)
Why do we want to disallow calling `start()` twice? Could be idempotent no-op, too.
I think we can.
I was going to leave this, but since there's one other change to be made, I think you can just do: ```java recordsLag.add(this.metrics.metricName(name + "-max", ``` And similarly for `avg`. That avoids having to compute `toString` on the topic partition again.
I guess that's possible, but _if_ the join result is large, we could run into memory issue buffering all join results? Also, sorting could be expensive and we can actually avoid it, and still guarantee that results are emitted in timestamp order: - we know that left/outer join result would have the smallest timestamps and thus we can emit those first (given that we use timestamped-sorted store anyway, we just scan the store from old to new and emit - for the inner join result, we get the output sorted by timestamp, too, because for the join key, data is sorted in timestamp order in the store, too
I was using this test to print the topology and it shows two sub topologies while it should be one (seems the reason is that you use the same `StreamsBuilder` as in `setup()` method. Also, the naming of the operators seems to be incorrect. Also wondering if `KGroupedStream#cogroup()` needs on overload that takes a `Named` parameter? Maybe not, but the specified `Named` from `aggregate()` would need to be used for other processors, too. Atm there is this weird `COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test` ``` Topologies: Sub-topology: 0 Source: KSTREAM-SOURCE-0000000000 (topics: [topic]) --> none Sub-topology: 1 Source: KSTREAM-SOURCE-0000000001 (topics: [one]) --> COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test Processor: COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test (stores: [COGROUPKSTREAM-AGGREGATE-STATE-STORE-0000000002]) --> test <-- KSTREAM-SOURCE-0000000001 Processor: test (stores: [COGROUPKSTREAM-AGGREGATE-STATE-STORE-0000000002]) --> KTABLE-TOSTREAM-0000000005 <-- COGROUPKSTREAM-AGGREGATE-KSTREAM-SOURCE-0000000001test Processor: KTABLE-TOSTREAM-0000000005 (stores: []) --> KSTREAM-SINK-0000000006 <-- test Sink: KSTREAM-SINK-0000000006 (topic: output) <-- KTABLE-TOSTREAM-0000000005 ```
We should also mention somewhere that we do not support concurrent transactions.
```suggestion * Options for {@link Admin#electLeaders(ElectionType, Set, ElectLeadersOptions)}. ```
Just want to check my understanding. The user may attempt to commit offsets while the broker has a JoinGroup in purgatory. In this case, we would send the older generation which would be doomed to fail with `ILLEGAL_GENERATION` once the join completes. In this case, should we still reset the generation as we do below? I am wondering if it is useful to remember the generation that an offset commit was sent with (perhaps inside `OffsetCommitCompletion`) so that we only reset if necessary.
I'm not very familiar with the direct buffer usage pattern, but currently it seems we would still try to allocate a new buffer for each put call, whereas I "thought" the main benefits come from reusing the buffer across multiple put calls? @vamossagar12 @ableegoldman @cadonna please correct me if I'm wrong.
Detail: just to be sure, I would initialize it to `this.generation`, to make sure the generation always increments.
I think this and following usages around `latestSupportedVersion` are related to the upcoming version probing code. It's a little mysterious to have a "latest supported version" always equal to the "current version" in this PR in isolation, but I don' think it's actually problematic.
Should require non-null for `fetchPosition`
Can you please elaborate why we no longer read the header during construction? It seems to me that `checkHC` could be a constructor parameter and then we could keep it as a private and final variable and less changes would be required. But maybe I am missing something. Note that public and mutable variables are generally avoided in Java.
I don't think it's _that_ big a deal to have to allocate the `OffsetMetadata`. And certainly the performance overhead of the allocation isn't a concern. I only care about the verbosity because the vast majority of use cases only care about the offset and not the metadata, and we're making that large fraction of cases harder. And would OffsetMetadata then be changed to be mutable, so it's convenient to just maintain the map where I update only the offset in that struct? Or do all my updates to that map (which I probably update for every single message processed) require a `new OffsetMetadata()`, bloating those statements and making them less clear? Or do I just maintain the `Map<TopicPartition, OffsetMetadata>` and have to convert it every time I call commit? On the other hand, maybe most users don't even specify the offsets manually anyway and the concern here is unwarranted since 99% of the cases are handled by `commit(CommitType)` and `commit(CommitType, ConsumerCommitCallback)`? In other words, I'm worried because I want the very common case to be clean, easy to read, and concise. I'm not yet sure whether this change would actually affect that common case.
We're returning the collection directly here which violates the synchronization. Actually there's some inconsistency between `groupSubscription` and `subscription`. The latter is effectively immutable in the sense that we do not update the set once it is created. Perhaps we can do the same for `groupSubscription` which would fix this problem.
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
Add to the end, "as long as they still match the subscribed pattern"
Strictly speaking, this shouldn't be necessary as `SCHEMA_TYPE_CLASSES` should have a `Schema` instance for all `Schema.Type` literals. And with `SchemaBuilder` a connector or converter cannot create a schema instance with a null `Schema.Type`. However, it is possible to construct a `ConnectSchema` instance with a null `Type` reference (like what `FakeSchema` essentially does in the existing test), which of course without this change would result in this method returning a null list. So +1 for this line change since it simplifies the error handling in the calling code.
Much better name :)
- It's a contract that `KafkaConsumers` _guarantees_ that `header != null`. \cc @hachikuji to confirm. - And we know that KafkaStreams never writes headers into changelog topics. Thus, I don't see any reason to check for something that we know is the case, ie, we know that `header.size() == 0` in old format. For everything else, we could throw `IllegalStateException`. Of course the header API is limiting and we cannot get `size()` and thus `record.headers().lastHeader("v") == null)` is what we need to do... :( -- but we can safely remove the first `null` check -- it could even mask a bug and we should rather fail for this case. We can also do a version check as suggested by Guozhang.
not used: can be removed
We avoid using time-based operations in integrations since they usually leads to flaky tests. Consider using `TestUtils.waitForCondition()` with a timeout.
Instead of using `.format` and `+` to create the string, maybe use same way as `cmd` is constructed (using % to format, and multiline string without `+` but by ending with `\`)
Shouldn't you verify if topology 1 still produces output records at this point? When I read the test name I would expect that verification here.
For create / destroy maybe that's okay, but `process` is at the very critical path so we have to be careful not to incur any overhead.
Can you please explain why it's better to warn than to fail-fast in this case? Just want to make sure I understand the reasoning for the choice.
nit: I'm sure these fit in a line shorter than the one below
Do we need to validate twice before grabbing the lock? Maybe only the validation at line 283 is sufficient.
I think we can move this into the block above line 70 to 72 and simplify: ``` if (!needsInitializing.isEmpty()) { initialize(); updatedEndOffsets.putAll(restoreConsumer.endOffsets(needsInitializing.keySet())); } ```
Understand. That part can be refactored - goal is to reduce unnecessary comparison.
I'd probably just `return error` here (I'm not a fan of `return`, but `break` isn't much better and I assume you wrote it like this to avoid a call to `getSuperclass()` in the very common case where we find the `Errors` on the first attempt). While I am nitpicking: space after `if` is missing.
Why don't we extract this loop into a separate method that takes an interface like: ``` scala interface WaitPredicate { boolean test(); } ``` Then we can reuse the logic from the different variants.
Could use `equalsIgnoreCase` directly.
The other constructor calls the parameter `sampledStat`. We should be consistent.
typo: `per reach record`
The `CachingKeyValueStore` doesn't throw an NPE here, rather `org.apache.kafka.common.utils.Bytes.LexicographicByteArrayComparator.compare` does. We probably should add `Objects.requireNonNull(...)` to `CachingKeyValueStore#put(..)` etc
Ok, it's your call. I think this might make the tests flaky, but I guess we can figure that out later.
Maybe just check that `minikdc` is not None here
Instead of pulling the value out with a regex, what do you think of `streamsString.contains("appId")`. Although what you have works as well.
`joinThisName` is used in the store of `thisWindow` which is to be queried by the other stream, so my personal understanding is that: 1. for inner-join (`rightOuter` = false, `leftOuter` = false): both window-store has `JOINTHIS_NAME-store`. 2. for outer-join (`rightOuter` = true, `leftOuter` = true): both window-store has `OUTERTHIS_NAME-store`. 3. for left-join (`rightOuter` = false, `leftOuter` = true): the left window-store `THIS_NAME-store` and the right window-store `OUTERTHIS_NAME-store`, since we will join with `null` if the right window-store returns null (hence "outer"), but not vice-versa.
Just curious, could we possibly call this function for the same node more than once? It seems yes as you are checking `!keyChangingOperationsToOptimizableRepartitionNodes.containsKey(node)` here, but I cannot tell from the code...
nit: ```newPosition``` can be created lazy.
Are we ever going to need to use the return value here? Instead of using a `Supplier` maybe we could use a `Runnable` in the signature and we could get rid of the `return null` statements.
Another reason for having these classes in common (i.e. KAFKA-5265) is that they can potentially be used by the Authorizer interface when we move it to Java.
Also - this method gives the ability to construct different configs for different nodes - so it seems like the logic for setting `self.security_config` doesn't belong here since it is independent of the node, and would have unintuitive behavior if it did become dependent on the node? (e.g. configuration of one node affecting configuration of other nodes)
This is not necessary, since the for loop below would be a no-op.
I think upon close(), we can also use `maybeAutoCommitOffsetsAsync` and then we can remove the whole function fo `maybeAutoCommitOffsetsSync`.
Shouldn't need this line, it's handled by the superclass's constructor.
Here it is better to use to distinct records, because if the code contains a bug that adds a record twice, you would not discover it.
Adding to `connectorProps` won't change the already instantiated `config`.
nit: add `final`
By the way, I wonder if we should just say it should be idempotent? Seems redundant to mention KafkaProducer.
For standby tasks `init` is no-op, so we can just remove it? PS: logically we should call `resume` not `init` here, but the former is also no-op anyways..
Note this correction
Let's call this "StdoutMonitor" since that makes it more clear what it is doing. We may want to pass things other than status eventually. Also, the instance variable is called `stdoutMonitor`, which suggests that this is a better description.
No need to reorder imports.
Do we need this? Can't we just use the Time we pass into the constructor in tests? Not a big deal really, just wondering
This dates before this PR, but while reviewing it I realized that line 898 in prepareTopic: ``` topic.setNumberOfPartitions(numPartitions.get()); ``` is not necessary since the `numPartitions` is read from the topic.
nit: remove `this` (not required)
I thought we changed the order of this in the 3.0 patch. We should be checking for a changed topic id before comparing epochs.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
One caveat is that when we are closing the Kafka Streams instance with a specified timeout value, this function may violate that timeout and wait for longer time since we call `thread.join()` without a timeout value.
Oh you mean `UnsupportedForMessageFormatException`? That doesn't seem to be added.
why removing this line? this test is used to make sure we can't initialize the `recorder` multiple times with different task id.
nit: line to long should be ``` private void emitExpiredNonJoinedOuterRecords(final WindowStore<KeyAndJoinSide<K>, LeftOrRightValue> store, final Predicate<Windowed<KeyAndJoinSide<K>>> emitCondition) { ```
Since condition is just a comparison, you can put the comparison here directly
We should not use Java `assert` statement but proper unit testing asserts, ie, `assertThat(e.getMessage(), equalTo("..."));`
nit: 4-space indention plus move `builder` down one line
@hachikuji Why don't we catch the exception here? If the task is being stopped, a wakeupexption is kind of noise in log especially for the application which needs to monitor error log.
If we throw InvalidTopicException directly, be change public API (possible exception are part of the API) and thus, this would require a KIP.
need a check for null on `obj` here as well
But why is this needed here? I don't know what the other test is doing but I don't understand why it's used here
nit: not introduced by this PR, but let's rename it to `otherWindowStore` for naming consistency.
original was better
I meant to have "Note that enabling idempotence requires this config..." before "Allowing retries...". And break the two parts with a paragraph.
Hmm, normally `IllegalArgumentException` indicates that the argument to a function is bogus, right? That's not really the case here-- the function argument was fine, but the topic wasn't set up correctly. This can probably just be a generic `RuntimeException`, since we don't have a need to make it something fancier.
Can the mechanism be made a configuration option? I haven't looked through the code yet to see if the implementation relies on this mechanism, but it will be good if it was configurable.
I think these need to be `volatile` if we want them to work cross threads. I was thinking we should consider using `AtomicInteger` to avoid the need to increment these variables inside synchronized variables. I know it has a smaller cap (INT_MAX) but I imagine that should be enough for such a test
nit: `{@link KeyQueryMetadata}`
We normally use `assertThat()` in new and refactored code. Please also change the other occurrences. ```suggestion assertThat(hasStateTransition(KafkaStreams.State.REBALANCING, KafkaStreams.State.RUNNING), is(true)); ```
I would prefer defaulting to range just for consistency. We have seen similar cases in the producer where the behavior of partitioner's hashing function changes a bit, causing offset manager migrated for mirror-makers and hence resetting offset and data duplicates.
We avoid using time-based operations in integrations since they usually leads to flaky tests. Consider using `TestUtils.waitForCondition()` with a timeout.
We are tracking the LEO in two places: 1. In `ReplicatedLog::endOffset`. This gets increase every time the log gets appended: https://github.com/apache/kafka/blob/28ee656081d5b7984c324c3ea3fc9c34614d17db/core/src/main/scala/kafka/log/Log.scala#L1302 2. The `LeaderState` also stores what is now the LEO. One suggestion is for `LeaderState` to instead store the "flush offsets". In `LeaderState` the follower's flush offset is the LEO but for the local replica the "flush offset" may not be the LEO. An example of the high-watermark increasing but the LEO not changing: 1. follower: LEO = 10 2. leader: LEO = 100, FlushOffset = 100, HW = 0 Follower successfully fetches for offset 10 => Leader: LEO = 100, FlushOffset = 100, HW = 10. Follower successfully fetches for offset 20 => Leader: LEO = 100, FlushOffset = 100, HW = 20. In this example if the leader already flushed to the LEO then there is no need to flush again when increasing the HW.
request "got" re-sent to the control
nit: `isolate ... form other client configs` -> ``` override ... for the main consumer client from the general consumer client configs. The override precedence is the following (from highest to lowest precedence): 1. main.consumer.[config-name] 2. consumer.[config-name] 3. [config-name] ``` Ditto below for other two.
nit: flip both lines: ``` final long startTime = next.key.window().start(); windowStartTimes.add(startTime); ```
This can just be referencing LEADER_AND_ISR_REQUEST_PARTITION_STATE_V0.
nit: align parameters.
nit: we can use `map#compute` to replace getOrDefault + put.
typo: byteArrray -> byteArray
These two calls boils down to ``` Fetcher#retrieveOffsetsByTimes(Map<TopicPartition, Long> timestampsToSearch ...) ``` I wonder if they can be combined (to save roundtrips).
`rebalancing()` should never throw an `InvalidStateStoreException` as it is just constructing the `CompositeReadOnlyKeyValueStore` wrapper. The underlying stores should not be accessed until `get`, `range`, or `all` are called. So, i think this is safe to leave it as it is
I think at the moment, we should never get here, so `IllegalStateException` is fine.
This warning seems to miss the most likely scenario, that the user just passed the arguments in the wrong order.
Actually, at line 387, the batch may or may not already been closed, and we should only call `close()` only when it is not closed yet.
Ditto here about error message
Not sure. PENDING_SHUTDOWN indicates a clean shutdown while this lets the thread fail.
> > I think we need to handle preferred leader election in a special way. For example, if the assigned replicas are 1,2,3, isr is 2,3 and the current leader is 3, when doing preferred leader election, we want to keep the leader as 3 instead of changing it to 2. > > Hmm, wouldn't we want to switch the leader to 2 in that case, since 2 is more preferred? Well, currently the contract is just that if every broker picks the preferred replica (i.e. 1st replica), the leaders will be balanced among brokers. If not, all other replicas are equivalent. Moving leaders among non-preferred replicas just creates churns without benefiting the balance.
```suggestion if (attempt < maxAttempts) { Utils.sleep(retryBackoffMs); } ```
Nit: maybe `("Topic: " + topic)`
@eliaslevy Since this part is covered in other unit test case, we want to remove redundant coverage to leave the unit test as succinct as possible.
nit: it would improve readability to factor out some functions for some of the work here. Here we can have a separate function with a nice name for building the assignments
Could you please add some line breaks? This and some of the other verifications are too long.
nit: `This` -> `{@code MockProcessorContext}` "this" , "here" etc is bad style IMHO
nit: simplify `InterruptedException, IOException` to `Exception`
super nit: no `.` at the end or start sentence with `[T]he` :)
Nit: you can also add `final` here: `for (final Map.Entry.....)`
Nit: rename to `doStreamTableLeftJoin` to differentiate with stream-stream join.
We should not include this along with the unit tests since it's not a unit test.
This is a useful log message. But since in a busy Connect worker it's unlikely these log two messages will be adjacent, how about instead using a single log message: log.trace("Cast field '{}' from '{}' to '{}'", field.name(), origFieldValue, newFieldValue);
Since we have a Jira ticket that is even referenced here, I would prefer to remove the ToDo from the code.
Would it make sense to validate here that idx not in self.nodes_clean_shutdown? (although we might want a set instead of a list). Seems like it should be an error to receive a valid message after receiving a "shutdown_complete" message
I'm not sure in this. So in case of two properties (k1=v1 and k2=v2) do you generate the `--consumer-property k1=v1 --consumer-property k2=v2` string? The repeated property didn't work when I tried it out and it only picked up the first one. I think you need to pass `--consumer-property "k1=v1,k2=v2"` as with some other commands. In case the "k1=v1,k2=v2" format is needed, there is a nice one-liner way to do it: ``` ','.join("%s=%r" % (key,val) for (key,val) in k.iteritems()) ```
We did not have this check before, why is it needed? Also checks here are only applied when running in "driver" mode.
How about `completeExpiration` or `expirationDone`? Also, do you think we should add safeguards to ensure that the batch can't be completed more than once? Maybe at least we can add an assertion that `expiryErrorMessage` is null in `RecordBatch.done`.
Yes, it makes sense to return a range for an ApiKey instead of a single version. I was just wondering if this method is redundant given NodeVersions.apiVersionRange(ApiKey api). Also, it feels a bit weird for a public facing class to reference Protocol, which is not a public facing one.
the method ```clean``` catches ```Exception``` already. Could we get rid of those try-catch statements? the code ```log.error("{} Failed to release the state directory lock.", logPrefix());``` can be moved to ```clean```. For example: ```java public synchronized void clean() { // remove task dirs try { cleanRemovedTasksCalledByUser(); } catch (final Exception e) { log.error("{} Failed to release the state directory lock.", logPrefix()); throw new StreamsException(e); } ``` ```java private void cleanRemovedTasksCalledByUser() throws Exception { for (final File taskDir : listAllTaskDirectories()) { final String dirName = taskDir.getName(); final TaskId id = TaskId.parse(dirName); if (!locks.containsKey(id) && lock(id)) { try { log.info("{} Deleting state directory {} for task {} as user calling cleanup.", logPrefix(), dirName, id); Utils.delete(taskDir, Collections.singletonList(new File(taskDir, LOCK_FILE_NAME))); } finally { unlock(id); // for manual user call, stream threads are not running so it is safe to delete // the whole directory Utils.delete(taskDir); } ```
@ijuma Sorry, I don't know of a standard way of doing this,
nit: `Older` -> `older`; `topic Id` -> `topic ID`; `TopicId` -> `topic ID`; `Epoch` -> `epoch`.
This is fine for everything past 1.0.0, but if we do want to make things releasable using this script on trunk (similar to how people use the merge script probably), then we'd want to maintain support for the 4-component version and validate ones starting with 0 vs >= 1. I'm fine going either way (not maintaining that for simplicity and bug fixes on older branches will need to use the older release script, or just adding in a bit more logic here).
Sounds good. Actually I've seen the same situation for our current caching layer flushing logic as well: e.g. `put(A, v)` -> `delete(A)` and both only hit the cache layer. When flushing we tried to read the old value and found its null bytes, so we know nothing was flushed for `A` and nothing written to downstream before so we can skip putting a tombstone to underlying store as well as downstream. For suppression buffer though, it is harder since you do not have an underlying store to fetch the old value, and of course reading the whole changelog to see if there's any updates on this key `A` costs you everything. But suppose we always have a persistent buffer, this may be an easier task.
Could you make the error message to be more specific? E.g. "Partitioner generated invalid partition: %d.." to differentiate that a partitioner is used.
This won't log the error. We want to use the public void error(String msg, Throwable t); overload, so we need to change e.getMessage() -> e
This should be package-level protected: ```suggestion // Visible for testing static void validateHeaderConfigAction(String action) { ```
Changed it locally.
nit: unneeded newline
This isn't our fault. When we added the timestamped stores, we chose not to make SessionStores timestamped because the session bounds already have the end timestamp available, which is identical to the timestamp we would have stored in the value.
I think we should test for the exception -- if we change the behavior intentionally, we should remove the `fail` as well as the `try-catch` instead of allowing both behavior to pass (it's an either or form my point of view). IMHO, tests should be on an as narrow code path as possible: if we change behavior and a test fails, we are forces to reflect on the change, what is good as it guards against undesired behavior changes...
Is there similar behavior in the map parsing? I see a similar comma consume call being ignored. Consider the following test: ``` SchemaAndValue schemaAndValue = Values.parseString("{foo:bar baz:quux}"); assertEquals(Type.STRING, schemaAndValue.schema().type()); assertEquals("{foo:bar baz:quux}", schemaAndValue.value()); ```
If we are using this in KIP-447 as well, perhaps it makes sense to move it int the `consumer` package.
In 1.2.0 we add an optimization to avoid writing the checkpoint file if there is nothing to write (i.e. the available offset map is empty): this is not a bug fix but just some optimization. If you have other persistent stores in your topology the checkpoint file will still be written. Here is the JIRA ticket: https://issues.apache.org/jira/browse/KAFKA-6499
> That being said, I get that this is confusing. Do you think changing the check to `if (endTime == windows.TimeDifferenceMs() && !isLeftWindow(next))` would make it seem cleaner? Haha no, I don't think saying `if (!isLeftWindow(next)): then next = latestLeftTypeWindow` would be less confusing. If we call a variable `leftTypeWindow` then it should _always_ be a left type window. That said, I now see what you meant here and it's the same problem as above, with the same fix of replacing `latestLeftTypeWindow` with `previousRecordTimestamp`. In that case I think we can just remove this check entirely (ie, don't explicitly check if it's the combined window), and all we need to do is make sure `previousRecordTimestamp` is set correctly
For the purpose of understanding EOS, the main exceptions that are worth calling out are `ProducerFencedException` and `FencedInstanceIdException`. I would suggest we write the example like this: ```java try { ... producer.commitTransaction; } catch (ProducerFencedException e) { throw KafkaException("The transactional.id $transactionalId has been claimed by another process"); } catch (FencedInstanceIdException e) { throw KafkaException("The group.instance.id $instanceId has been claimed by another process"); } catch (KafkaException e) { // If we have not been fenced, try to abort the transaction and continue. This will raise immediately // if the producer has hit a fatal error. producer.abortTransaction(); } ```
`final` is for the var `activeTasksMetadata` (not for the method). We try apply a "use `final` whenever possible" policy. It's just some nit.
This adds an additional `get` when compared to the previous solution.
Since we don't do coordinator discovery in this loop, do we need to reinitialize the `coordinator` variable? If the connection fails, then pending request count should drop to 0 already.
We could update the timer so that the min was the `requestTimeoutMs` for the second `close` too.
As an alternative, which might align better with Kafka in general, would be to set the timeout via `StreamsConfig`. This keeps the API clean. @enothereska argument that `close()` should not have any arguments is quite valid to keep APIs consistent within Kafka.
The test case `BrokersToIsrsTest.testNoLeader` suggests that it is a possible case. It looks like the path through `ReplicationControlManager.handleNodeDeactivated` could result in a `PartitionChangeRecord` which has leaderId set to -1.
Be careful about changing this -- it should probably be a LinkedHashMap or some similar order-preserving Map if we do this. Depending on the serialization format, they may be sensitive to field ordering so being able to preserve the ordering will be important. Even within a single process a converter could end up randomizing schema field orders and breaking equivalence if an order randomizing map was used. The alternative would be to add an extra Set to SchemaBuilder, which requires extra allocations but doesn't require jumping through hoops to preserve the behavior of the `fields()` method.
Isn't this a behavior change? IIRC, we had a discussion to do this change, or to maybe make it configurable if we want to interleave processing with recovery.
Other classes implement this as: ``` this.processorName = name; return this; ``` Why the difference? I we think that using this pattern to guaranteed immutability is better (what might be a good idea), we should consider to rewrite _all_ code -- of course, if a separate PR). I cannot remember atm, why we did not implement similar method immutable? Can you remember @bbejeck? We introduced this pattern with KIP-182.
It seems to me that we could have a single `createSaslClient`. Most of the code is the same apart from the mechanism, clientPrincipal and the exception message.
That makes sense, however you might be able not include the new field from the hash to prevent a chaotic assignment if you wanted
Understand. That part can be refactored - goal is to reduce unnecessary comparison.
This docstring could be improved. Perhaps we can just mention that we will may have a memberId before we are part of a group generation.
> Was also wondering if there could ever be an exception thrown by addListener which would cause the listener to not be added or the completion handler to not be called? Hm good question ... find it hard to imagine as implemented unless we end up with multiple listeners executing on the consumer thread & a listener that precedes this one throws or something along those lines. And in that scenario right now I think we'd expect the exception to bubble out of KafkaConsumer.poll(), which would at least give us a clear signal that something went terribly wrong.
Maybe consider replacing `Stack` with `Deque` as `Stack` is synchronized and `ownedSensors` only adds in the constructor and removes values in `synchronized` block already.
Should this be `num_lines=3` (cf. L116 and L126)
and -> a
I suggest passing all of the variables we access in this constructor via`SustainedConnectionWorker.this.spec` to be switched to parameters we pass upon instantiation
Actually I was really just asking for people's opinions :) the cons are that these classes will be in different packages which may looks a bit weird.
nit: not related to this PR, but the above `TODO` can be renamed as `TODO KIP-300` to be more specific.
This test just needs a rename: it calls `shouldNotAllowToResetWhileStreamsIsRunning()` and should have the same name. There are two separate test below: one for invalid input topic and one for invalid intermediate topic. (or did you mean something else, @bbejeck )
```suggestion capturedConsumedCallback.getValue().onCompletion(null, new ConsumerRecord<>(TOPIC, 1, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TP1_KEY.array(), null)); ```
`... retry attempts due to timeout. The broker may be transiently unavailable at the moment. ..` Ditto above.
There are some request header tests in `RequestResponseTest`, we should move them here so that we can find them all in one place.
There is an inconsistency with above code: `Map.Entry` vs `Entry` -- I guess we should use `Map.Entry` everywhere.
Likewise, this log message could be changed to: ```suggestion log.warn("Attempt {} to {} resulted in RetriableException; retrying automatically. " + "Reason: {}", attempt, description.get(), e.getMessage(), e); ```
Adding to `connectorProps` won't change the already instantiated `config`.
Seems this could be a function as well. For example: ``` java Map<TopicPartition, PartitionInfo> partitions(Map<String, InternalTopicMetadata>); ``` (I'm looking for small independent chunks of code that can be taken out of this function.)
Ouch! Sorry about that!
Nit: `.` full stop missing.
One question: it seems the `bulkLoadSegments` set will only keep increasing in size since we only initialize it once in `bulkLoadSegments = new HashSet<>(segments.allSegments());` and then do this ad-hoc addition here, when segments are dropped they will not be removed from `bulkLoadSegments` as well, right? I'm thinking, if we could just call `final Set<Segment> bulkLoadSegments = new HashSet<>(segments.allSegments());` here every time, since 1) if the store does not exist yet, the `getOrCreateSegmentIfLive` will call openDB that makes the open flag for the newly created store, and 2) if the store does exist already, then `toggleForBulkLoading -> segment.toggleDbForBulkLoading` will make sure the store is open here.
Nit, suggested rewording ```java log.info("Fetch offset {} is out of range for partition {}. We only have log segments in the range of {} to {}. Resetting offset.", fetchOffset, tp, partition.logStartOffset, partition.lastStableOffset); ```
nit: there's some redundance printing both the offset and the OffsetAndMetadata. Maybe it would be most useful to print just the offset and epoch
Ditto here about error message
nit: add `final`
I think using a string and the `NonEmptyString` validator would be a little clearer. That would allow us to skip any additional checks in `start`.
iiuc, this is actually the bug that we are fixing here. On the current trunk, if flush or cache.close throws, we do _not_ close the wrapped store. Now, with this change, we still call flush, cache.close, and wrapped().close, regardless if some of them throw.
I wonder if we ought to just assume that the error goes at the top-level. It's a little weird to receive a partition-specific error code here and then assume that it should be used for _all_ partitions.
I don't have all the context, but isn't `3` pretty low? We don't do exponential back-offs, so the recommendation for no data loss is typically higher.
Well, we wouldn't want to just remove that clause -- in the case of `SerializationException` you want to maintain the `SerializationException`, but if there's some other `RuntimeException` (which there can easily be for serializers that aren't aggressively catching exceptions and converting to `SerializationException`) then you still need to convert it to a basic `KafkaException`. I think you could do this: ``` try { // parse record } catch (SerializationException e) { throw new SerializationExceptionException("Error deserializing key/value for partition " + partition + " at offset " + logEntry.offset(), e); } catch (RuntimeException e) { throw new KafkaException("Error deserializing key/value for partition " + partition + " at offset " + logEntry.offset(), e); } ``` as long as we're confident there aren't any other `KafkaExceptions` we'd want to handle differently (i.e. any other more specific types of `KafkaException` where we'd want to preserve the same type instead of generalizing to `KafkaException`).
Thinking about this, I am wondering if we should just change the FSM to allow this transition and simplify the code here? \cc @guozhangwang
This is fine for everything past 1.0.0, but if we do want to make things releasable using this script on trunk (similar to how people use the merge script probably), then we'd want to maintain support for the 4-component version and validate ones starting with 0 vs >= 1. I'm fine going either way (not maintaining that for simplicity and bug fixes on older branches will need to use the older release script, or just adding in a bit more logic here).
Rather than setting this to `null` if it isn't an instance of `BatchingStateRestoreCallback` perhaps you could set it to an instance of an internal class that implements `BatchingStateRestoreCallback`. The benefit being that the `null` check is then only done once here and not also in `restoreAll`
This is part of the public API, so we don't know all the ways its being used. I still think we're better off output a more complete message.
Ditto on removing before/after
Typo: should be "or larger than the number of available brokers"
This adds an additional `get` when compared to the previous solution.
That makes sense. But what I don't know is, why we only consider `partitions` in the first place...
Do we need this? Can't we just use the Time we pass into the constructor in tests? Not a big deal really, just wondering
Ah, yes, the magic is hardcoded here.
nit: add `final`
Throwing `IllegalStateException` is served as the purpose that "this should never happen, and if it does it is a bug and hence it is ok to fail and stop the world".
This test just needs a rename: it calls `shouldNotAllowToResetWhileStreamsIsRunning()` and should have the same name. There are two separate test below: one for invalid input topic and one for invalid intermediate topic. (or did you mean something else, @bbejeck )
I see. `MaterializedInternals` must be `public` and cannot enlarge the scope if `Materialized` constructor is `protected`... What about adding a public static method `MaterializedInternals#fromMaterialized(Materialized)` that calls the copy constructor? This way, we could make it protected IMHO.
Ditto here about error message
It is not particularly critical, but my suggestion was to keep the same `for` loop, but add something like > while (!metadata.updateRequested()) Thread.yield() > metadata.update(...) or `Thread.sleep(1)` instead of `yield()`. Now each update corresponds to a request to update metadata from the `partitionsFor`. like it does in the real scenario. You need to make sure that the thread terminates in this case.
I don't think we need to mock `generation()` in this test.
This is not a suggestion for change: while working on removing `KStreamBuilder` and `TopologyBuilder` I realized in some unit tests we may still need this class to access the internal topology builder. So probably we cannot remove it even after that, but we can discuss this later in the cleanup PR.
```java if (tagged) { buffer.printf("int _sizeBeforeBytes = _size.totalSize();%n"); } ```
If only Java made it possible to declare immutable local variables and method parameters in a more concise way!
I'm not sure how significant it is for the timeout to be a multiple of the refresh interval. The scheduling might not ever align anyway since it depends on poll() getting invoked at the right time. I also don't see why a separate mechanism would be needed for a hard-coded value. We're not expecting high granularity, just a way to avoid the cache growing unbounded over time. My concern is that we are technically changing the semantics of `metadata.max.age.ms` for the producer. Before it only controls how long we wait before refreshing metadata; now it also sets an expectation on the frequency of writes to each topic. Admittedly, the change should be transparent to the user, but it feels like an unneeded dependence.
Not sure why it's the case? I think the previous pending txn should have aborted in step 4.
What's our plan for the global thread? I didn't think of this during the KIP discussion, and sorry if it was brought up there and I just forgot about it. But it seems like we should still give users a non-deprecated way to set a handler for the global thread.
"with a read-only key"
We could use `SortedMap` (or even `TreeMap`) here instead of the generic `Map`. Then we wouldn't need the ugly cast below.
@guozhangwang @dguy we cannot guarantee that all the entries for one key will necessarily precede the entries for the next key. The following code still fails with this patch, and only returns `0001` and `0003`, since the key for `("a", "0005")` will come after the key for `("aa", "0004")` ``` final RocksDBWindowStoreSupplier<String, String> supplier = new RocksDBWindowStoreSupplier<>( "window", 0x7a00000000000000L, 2, true, Serdes.String(), Serdes.String(), 0x7a00000000000000L, true, Collections.<String, String>emptyMap(), false); windowStore = supplier.get(); windowStore.init(context, windowStore); windowStore.put("a", "0001", 0); windowStore.put("aa", "0002", 0); windowStore.put("a", "0003", 1); windowStore.put("aa", "0004", 1); windowStore.put("a", "0005", 0x7a00000000000000L - 1); final List expected = Utils.mkList("0001", "0003", "0005"); assertThat(toList(windowStore.fetch("a", 0, Long.MAX_VALUE)), equalTo(expected)); ```
Hmm, it seems like the `log.isTraceEnabled()` checks are not useful in some of the cases at least. If you pass up to 2 parameters, there is no benefit. See the underlying code: ```java if (isTraceEnabled()) { FormattingTuple ft = MessageFormatter.format(format, arg1, arg2); logger.log(FQCN, traceCapable ? Level.TRACE : Level.DEBUG, ft.getMessage(), ft.getThrowable()); } ``` For more than 2 parameters (it would be nice if slf4j would have overloads for more parameters), there is an array allocation, which is generally pretty cheap as well.
Was there a `stop_node` method here before? It's a good idea to have both `stop_node` and `clean_node` defined. Or, if you expect the process to actually be gone by the time we hit the "stop" portion of the service lifecycle (`stop_node` is the "graceful shutdown" option), it's helpful to do a check that the process is actually gone (i.e. check that the actual state matches our expectations of what the state should be) and at least log a warning if the process is still running
Just to follow the question above, could we directly restrict the range at this caller as: ``` (Math.max(earliestSessionEndTime, currentSegmentBeginTime()), Math.min(latestSessionStartTime, segmentEndTime)) ```
Metrics configs have a common context but not a consistent prefix, but that might be for historical reasons. I just find the name of the config a bit long and as you said we could always cluster them in the docs. That was just a proposal and will not fight for it.
Seems like the indenting should be adjusted to the left, right? Applied to other changes in this file too.
Sounds good. I'm also ok with a more incremental change if it ends up being more complex than I suggested.
To be realistic, the second parameter should be `Collections.singleton(topic)` rather than `emptySet`.
I actually had a similar thought, but I am torn though. Using two variables required to keep them "in sync" was is not great. However, using `null` is less explicit... Thus overall I am fine either way as both seems to provide the overall same good/bad ratio.
nit: We could revert this change as it does not bring much and re-align like it was before.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
iiuc, this is actually the bug that we are fixing here. On the current trunk, if flush or cache.close throws, we do _not_ close the wrapped store. Now, with this change, we still call flush, cache.close, and wrapped().close, regardless if some of them throw.
Typically, most users push logs to something like elastic/splunk and should be able to lookup the logs from the archive. I'm not too concerned about this since properties file based credentials store shouldn't typically be used in a production environment. So,I'm fine leaving the log statement in here. But let's see what the committers have to say fro this :).
nit: missing `<p>` for new paragraph
@wicknicks would be useful to have some unit test for this class.
This can just be referencing LEADER_AND_ISR_REQUEST_PARTITION_STATE_V0.
Nit: "For instance, the transactional APIs require brokers with version 0.11.0 or newer."
This is not correct. We return `UnknownTopicOrPartitionException` if the topic is not found.
This should be three tests.
nit: remove empty line
`Constructor<List<T>>` (or `Constructor<L>` if we introduce `L`)
Nit: go with single parameter per line.
That makes sense, I think keeping it as-is is better.
As above: use `assertThrows` and verify error message
I guess in the end we will find these classes a better place (currently they are a bit scattered, e.g. `KeyValueStoreFacade` is in the materializer class).
as above: we need to remove adminPrefix configs
If we hit an exception in `handleRevocation` why would we continue here? Are we still in a "clean enough" state to actually continue? Below we call `completeTaskCloseClean(task)` what seem incorrect for this case as it might close clean task even if we did not successfully commit before.
do we need both the `expectedStarts` and `expectedRestarts`? It seems like the former should be just one more than the other.
`than` -> `that`
Blank line can be removed.
Is the current implementation vulnerable to the following race condition? 1. thread1 grabs `CHANNELS` lock, get the channel object from the map; and then exists the `CHANNELS` lock; 2. thread2 grabs the lock, release the lock on it, close the channel, remove from the map. 3. thread1 now calls `channel.tryLock`, which throws `ClosedChannelException`.
Yes. But if we add some more parameters later on, it would simplify the diff. But it's also ok to keep as it.
This is the same code as in `KTableFilter` -- we should refactor and share code.
Let's rename `headers1` and `headers2` here too
Hmm.. Is it actually safe to abort following a TimeoutException? I think this would cause an illegal state error in the producer. To handle this correctly, the application should retry the commit.
I wonder if more of this code is generic and should be pushed somewhere else.
response version should be 1.
It was removed from the other versions of `group` but not from here.
Oh right duh I was thinking it was just a single bit but it's a byte. In that case we should have a test that verifies it goes from `0` to `1` to `2`, etc -- might be good to verify the behavior on overflow as well, if you call `subscriptionUserData` the max_value number of times
nit: newline after if condition, also space before and after `!=`, and space after `if`.
This works (note that `Properties implements Map<Object, Object>)`: ``` Properties p = new Properties(); Map<String, Object> foo = new HashMap(p); ``` So you should be able to do `getBoolean(new HashMap(props), ...)` (Need to omit the generics though...)
We already import the class on L26, so let's remove this import.
If the subscription changes, the `onPartitionsRevoked` would be triggered and the owned-partitions in subscription would not include them. The original reasoning is just to make sure all partitions except the ones that are attempted for reassignment-hence-revocation-first are owned by someone. But like we discussed in the other PR, today we are not checking these conditions anyways, e.g.: 1. assignor assign one partition to multiple consumers. 2. assignor assign one partition to no one. They are both bad situations but Coordinator does not check for those today. We discussed about this and think it worth a more general solution as a separate JIRA.
That is, in this way, it makes the check lightweight, and if we want to find out which partition cause the issue, we can "lazily" iterate them after the size check failed.
this will never be called if one of the assertions fails
That's not what I see when I look at the code. The following code populates `completedSends`: ``` java if (channel.ready() && key.isWritable()) { Send send = channel.write(); if (send != null) { this.completedSends.add(send); this.sensors.recordBytesSent(channel.id(), send.size()); } } ``` `channel.write` looks like: ``` java public Send write() throws IOException { Send result = null; if (send != null && send(send)) { result = send; send = null; } return result; } ``` And `send` looks like: ``` java private boolean send(Send send) throws IOException { send.writeTo(transportLayer); if (send.completed()) transportLayer.removeInterestOps(SelectionKey.OP_WRITE); return send.completed(); } ``` Why do you think we are not waiting for the request to go down the OS layer? I don't see any unflushed JVM level cache/buffer in the code above.
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
Use diamond (`<>`).
Great catch, thanks @showuon !
nits: not sure if we should `:` after `Invalid value` in the error message. Otherwise LGTM. Thanks for the update.
nit: should be `named` can't be null
Thanks for the explanation @dguy, very helpful to understand where caching and sequence numbers come into play. It might be worthwhile to put this in a JIRA somewhere. I do think it would be a useful optimization to have eventually, as fetches have some setup / teardown overhead.
nit: if you want a new paragraph you need to add `<p>`
nit: add `a {@link Named} config`
As above. Not sure if we need this, as the store should be wrapped with `MeteredWindowStore`.
Since these two branches do the same thing and half of the inner conditional is the same, it seems like you could just combine it all into one condition and only have one copy of that code.
Do we still need these 2 blocks? In `setup()` we already consumed all messages
yeah, other stuff from `RuntimeMXBean` was just a suggestion, obviously i wouldn't limit to that. classpath was the main one i saw that is useful. i don't think that it's too confusing since it is also alongside a bunch of other general system info. also, we still support the classpath approach, we just won't fix conflicts. we've definitely had cases on the mailing list that ended up being classpath issues that we probably could have spotted the likely root cause more quickly if we had had access to the classpath info.
Oh... Thanks for the reminder. @RivenSun2 , could you summit a small KIP for this change? Thanks.
Actually a more general question is that for assign(), is checking subscription.isEmpty() sufficient or not. Today we allow subscribe(empty_list) whose semantics is different from unsubscribe(), but they will leave the same state in subscription map.
You actually do not need `this` here, right? The values are the default initialization values in Java. And `super` is also called in the default constructor. So actually, you could remove this constructor completely.
I think that's the optimal compromise. Keep `null` since it's a keyword and avoid starting a sentence with it. *Any* seems to work fine here.
`receivedAssignmentMetadataVersion >= EARLIEST_PROBEABLE_VERSION` should be guaranteed at the server side as always right? If that is true, I'd suggest we refactor it as: ``` if (usedSubscriptionMetadataVersion > receivedAssignmentMetadataVersion) { if (receivedAssignmentMetadataVersion < EARLIEST_PROBEABLE_VERSION) { // throw illegal state exception. } // .. below logic } ``` So that we can detect potential bugs.
We no longer need `DEFAULT_OUTPUT_TOPIC_NAME` if all caller will use `createTopic` now
Calling `super(...)` makes `test_context` a field in the test object. I.e. no need for `self.context = test_context`
Instead of `new MetricName("batch-size-avg", "producer-metrics", "", tags)`, I think we should use `metrics.metricName("batch-size-avg", "producer-metrics")`, right? The doc says `Please create MetricName by method {@link org.apache.kafka.common.metrics.Metrics#metricName(String, String, String, Map)}`. Same for other MetricName instantiation.
Would it be worth having the rate limiter have 2 levels: the first level logs every error and the second logs every nth error? My concern is that simply cutting off logs entirely once we hit a certain # of messages can mask later messages. You don't want to mask those entirely, you just want to cut them off. I think any approach using timestamps is probably going to get too complicated. But I think still printing every 1000th message would be useful so you eventually see the problem.
Add the stream task id prefix here as well for both exception message and the warning log entry.
nit: `fetchOffset` instead of `fetchedOffset`? I think this is meant to describe the offset from the fetch request.
I don't think this is necessary to add here. AFAICT `StreamsKafkaClient` is only used in `InternalTopicManager` and it can just be constructed there
We can do it in a follow-up if you prefer. I was thinking it was as simple as setting `isFetched` to true, but I could be wrong.
`[because] the tool`
ditto for the rest of the test
I don't have the full context on the history, but it would not be easy to change the API... I talked to Jason about it, and it seem we can just move forward with this PR as-is, and could do a KIP later that allows us to store metadata as `byte[]` type if we really need to change it. Atm, the metadata is just a few bytes and the overhead does not really matter IMHO.
This message should say "Consumers earlier than 0.10.1.0..." since KIP-74 was part of 0.10.1.0.0.
```suggestion public HighAvailabilityTaskAssignor(final Map<ID, ClientState> clientStates, final Set<TaskId> allTasks, final Set<TaskId> statefulTasks, final AssignmentConfigs configs) { ```
@becketqin Yes, my preference, as mentioned above, is to deal with that problem separately. We should not make behavioral changes without first raising the issue at least in a separate JIRA. The unintuitive thing about the proposed behavior to me is the fact that although the consumer's position remains at the offset of the failed record, the next returned record will be from the offset after that position. You can see this in the test case below: the consumer's position is at 1, but the returned record is at offset 2. This makes the behavior less deterministic. It would be nice to maintain the invariant that the next fetched record is always the first record at an offset greater than or equal to the current position.
Hmm, why do we still keep it? Based on the reviews for previous version, I believe that there is some strict ordering for getting `localMetadata` initialized to be non-null on L352 first before hitting this logic, but still a null check sound more resilient to me, unless we want to have a NullPointerException to be thrown explicitly.
null means "return me every topic you know". The empty list means no topics. (This changed in a previous AK version)
Just checking... Is the intent to roll back the "hack" to also catch UnknownProducerId and initiate a rebalance to recover? Note, if this was not the intent, then there are similar catch blocks below.
Use `File.separator` instead of `/`
That is right, and originally we use `Metrics.metricName()` to leverage on the most common configs which is `"client-id" -> threadName`. But here you have removed it. Is that intentional? I think for thread-level we should have just one tag: `"client-id" -> threadName`, and for task-level we should have two tags: the one with thread level plus the task id, and for cache / store / processor-node we should have three tags, the two from task-level plus the record-cache-id / store-name / processor-node-name.
What is the reason for having `assertDoesNotThrow` here and below? The test will fail if an exception is thrown, so seems like unnecessary noise.
For the SSL case, stagedReceives can be less than the max. OK to add an assert like the following? ```java assertTrue("stagedReceives '" + stagedReceives + "' is greater than max expected '" + maxStagedReceives + "'", stagedReceives <= maxStagedReceives); ```
```suggestion * is an empty {@link java.lang.Iterable Iterable} or {@code null}, no records are emitted. ``` Please also fix this on the original method
FWIW - this is probably something that could be tested easily with good usage of a real Mocking framework (rather than hand coded stubs). We should probably start making use of something in streams as it would save a lot of effort and with correct usage lead to a better overall design.
Yeah if it exists elsewhere let's just leave it as is for now.
nit: add `{@link Named}` here and elsewhere below
Yep. Thanks, @bbejeck !
Might be excessive to add `final` everywhere. I'd say if it's self-evident that things aren't mutated I could skip final.
This is neat, but we shouldn't use it. There's an IntegrationTestUtil for getting a temporary folder, which is hooked in to support for different testing environments to set their desired temporary file location.
As we can "unset" listener to a `null` value then it's better to protected calls to `listener` against NPE, that involves checking `if (listener != null)` before calling (shrug).
Nit: ```suggestion @Override public void close() { ```
i think leaving as is should be fine atm, and tbh at least they are both close enough together to be easily modified together. if we think this is useful enough, i'd file a jira dependent on the jdk8 update so we can follow up.
Maybe we can still improve the little helper. For example: ```java short readUnsignedIntAsShort(Readable input, String entity) { int val; try { val = input.readUnsignedVarint(); } catch (Exception e) { throw new MetadataParseException("Error while reading " + entity, e); } if (val > Short.MAX_VALUE) { throw new MetadataParseException("Value for " + entity + " was too large."); } return (short) val; } ```
Not critical, but `for num_started, node in enumerate(consumer.nodes, 1)` would probably be more idiomatic.
see my question above about using mocks.
`Count is a {@link SampledStat} that maintains a simple count of what it has seen.` So with this stat, its value will be increased for the window period, then suddenly drops to zero, then start rising again. So it's hard to alert on such a metric, on the other hand `Rate(Count())` will record the average rate per time unit (here second), so users in practice can easily set a threshold for alerting, and even if they want "zero tolerance", setting the threshold to be 0 can still satisfy their needs.
We could refactor out a helper function here.
Do we need this? It seems that it's easier to just duplicate the property for producer and consumer.
I don't think so. We never write headers in the changelogger. Note, that the changelog topic is used to recover the store content. However, rows in a store only have a key and a value. There is no header that we could write, because the on put, the current record header does not related to the store content. Similarly, `suppress()` serializes the whole record context and store it in the value IIRC.
Your understanding is correct @mjsax .
seems like it should at least be info, if not warn
I could not find where you decrement the number of remaining standbys. If you get a value from this map and put it into an `int` variable, you do not have a reference to the `Integer` value in the map anymore. This might become a problem in `StandbyTaskAssignmentUtils#pollClientAndMaybeAssignRemainingStandbyTasks()`.
nit: including the acked offsets to checkpoint as well.
nit: new lines are generally not recommended to break object type declaration with object name. For this specific line I think we can still make them in one line.
Why are we splitting the handling of metadata between both `Metadata` and `Fetcher` now? Is this just so that this topic-partition metadata is not persistent in `Metadata` since calling `partitionsFor` doens't really imply anything about whether you'll continue to need updated metadata for the topics passed in here? Even so, this split seems less than ideal...
Might be simpler to just update the Jira and do all at once? > Any thought about how the prefix text should look like? The suggestion you made via wrapping one `IllegalArgumentException` with the other, was good. Just you proposed "outer" error message could be used to be passed in as prefix.
Safer to synchronize on `ExpiringCredentialRefreshingLogin.class` in case this class gets sub-classed later.
This can just be referencing LEADER_AND_ISR_REQUEST_PARTITION_STATE_V0.
For these messages in the case where the fetch does not match the current consumer state, it might help to clarify them by stating that the fetch is stale. It took me awhile to figure out all the cases when looking directly at this code; a user just seeing the log message probably isn't going to fare so well. The one here and the one in the `partition.errorCode == Errors.NONE.code()` case could probably both have "stale fetch request" added somewhere in the error message.
Yes, you have to check each task individually, but nothing prevents you from submitting them all at the same time. I am assuming that any overhead here is really associated with task startup time, so this allows for it to be parallelized.
Ack, I get it now. Thanks for clarifying.
`newInstance()` can throw `ExceptionInInitializerError` and `SecurityException` as well.
Typo: should be "or larger than the number of available brokers"
Maybe use log parameters instead? ``` java log.warn("Error executing interceptor onSend callback for topic: {}, partition: {}", record.topic(), record.partition(), t); ```
For standby tasks `init` is no-op, so we can just remove it? PS: logically we should call `resume` not `init` here, but the former is also no-op anyways..
`Integer.toString` is a slightly more concise way of doing this.
Please use string interpolation. There are a few other places like that.
Should we mention the "problem" with out-of-order data for this case? Should we ever recommend to _not_ return `null` ? We had a discussion at some point to actually disallow returning `null` because a "delete" is not a valid aggregation result.
Maybe we can set this to `false` in the `shouldDisableIdempotence` block? Seems a bit more natural.
createTime -> creationTime
Minor but I'm not sure if we'd prefer the builder's toString or the underlying request struct's toString as was formerly the case.
It would be better to either introduce a method to verify this condition or to change `connectionFailed` to return `false` if there is no `ConnectionState` for this node. The former seems safer.
Would something like the following work? ``` buffer.printf("_node.set(\"%sSizeInBytes\", new IntNode(%s.sizeInBytes()));%n", target.field().camelCaseName(), target.sourceVariable()); ```
This test case passes without the fix. It doesn't look like it even goes through the auto-commit path.
Alternatively, we can change the first arg `KeyValueMapper<K, V, K1> keySelector` and the second arg `KeyValueMapper<K, V, Long> valueSelector`. If we define special value selector classes, `LongValueSelector<K, V>` whose apply method returns `long` (not `Long`), `DoubleValueSelector<K, V>` whose apply method returns `double` (not `Double`) and so on, we can overload the `sum()` method and allow summing over different data types (and avoid object overheads), I think. In this case, SumSupplier is no longer a subclass of AggregatorSupplier.
That's just a mistake. Initially I had separate priorities for `ADD_PARTITIONS` and `ADD_OFFSETS`, but forgot to adjust the `END_TXN` priority after combining them.
Why use the delegate? Why not just call the methods on the `WorkerConnector`'s fields from within the `SourceConnectorContext` and `SinkConnectorContext` methods? E.g., @Override public void requestTaskReconfiguration() { ctx.requestTaskReconfiguration(); }
It actually would be helpful to include the exception's error message in this line, since the message alone might be bubbled up via the REST API. ```suggestion log.error("{} Error converting message value in topic '{}' partition {} at offset {} and timestamp {}: {}", this, msg.topic(), msg.partition(), msg.offset(), msg.timestamp(), e.getMessage(), e); ```
It seems like we can migrate away from the deprecated method in this test.
nit: I'm sure these fit in a line shorter than the one below
There's a bit of a change in behavior in this PR. We would previously return an empty string for older request versions and now we return `null`. Is that intended @cmccabe? cc @hachikuji
IMHO, it's better to pass along the deprecation instead of suppressing it. They both cause the compiler not to issue warnings about the use of deprecated APIs in the method body. This difference is that if we suppress it here, then any `groupBy` calls on a `KStreamImpl` reference *will not* issue a warning, whereas calls on a `KStream` reference will issue the warning as desired.
Definitely. This is one of my favorite gripes. Using more specific types whenever possible allows the compiler to do more work for us.
Do we really need to print `super.toString`? Ditto above.
I think `handleRetriableError` is a bit misleading. I mean it handles both retriable and non-retriable error. From this perspective the old naming was better (from my perspective).
nit: align parameters.
I don't think it's _that_ big a deal to have to allocate the `OffsetMetadata`. And certainly the performance overhead of the allocation isn't a concern. I only care about the verbosity because the vast majority of use cases only care about the offset and not the metadata, and we're making that large fraction of cases harder. And would OffsetMetadata then be changed to be mutable, so it's convenient to just maintain the map where I update only the offset in that struct? Or do all my updates to that map (which I probably update for every single message processed) require a `new OffsetMetadata()`, bloating those statements and making them less clear? Or do I just maintain the `Map<TopicPartition, OffsetMetadata>` and have to convert it every time I call commit? On the other hand, maybe most users don't even specify the offsets manually anyway and the concern here is unwarranted since 99% of the cases are handled by `commit(CommitType)` and `commit(CommitType, ConsumerCommitCallback)`? In other words, I'm worried because I want the very common case to be clean, easy to read, and concise. I'm not yet sure whether this change would actually affect that common case.
This one is still not using a tab.
How about: ```suggestion * <p>The task will be executed at least once. No retries will be performed * if {@code timeoutDuration} is 0 or negative, or if {@code timeoutDuration} is less than {@code retryBackoffMs}. ```
this line is still a bit long... You could try a static import for `singletonList`.
I could not find where you decrement the number of remaining standbys. If you get a value from this map and put it into an `int` variable, you do not have a reference to the `Integer` value in the map anymore. This might become a problem in `StandbyTaskAssignmentUtils#pollClientAndMaybeAssignRemainingStandbyTasks()`.
is old metadata missing expected after we start off? Might be useful to add a debug log or trace if this is not normal.
It seems we are using the same application id twice in `StreamStreamJoinIntegartionTest` ``` STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG, appID + "-outer"); ``` This might be the root case -- deleting all topics would solve the issue, too, as it prevent to start with a corrupted state.
nit: `This` -> `{@code MockProcessorContext}` "this" , "here" etc is bad style IMHO
This statement is a bit misleading, how about "to the format indicated by the given magic value".
Can you elaborate? Seems to be orthogonal to the timestamp fix.
nit: Please fix code style.
ah, right. nah, that's fine. just when reviewing I had the thought that if we guaranteed non-`null`/non-empty in the constructor, this wouldn't be necessary. i realized that it was actually intentional, but easy to miss when reviewing here and not getting the same highlighting as an IDE
nit: empty line.
I think this config property key seems a misfit, and probably reflects an earlier incantation of the design before KIP acceptance. It might be worth - in a separate PR - renaming this to something like `errors.tolerance` to better align with its purpose.
iiuc, this is actually the bug that we are fixing here. On the current trunk, if flush or cache.close throws, we do _not_ close the wrapped store. Now, with this change, we still call flush, cache.close, and wrapped().close, regardless if some of them throw.
@guozhangwang i'm not sure why we would want to enforce caching? Perhaps the custom store is already an in memory store? Why would we cache that? Perhaps there is some other reason why they don't want caching for a given store.
typo: `per reach record`
```suggestion capturedConsumedCallback.getValue().onCompletion(null, new ConsumerRecord<>(TOPIC, 1, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TP1_KEY.array(), null)); ```
Yeah, the logic seems right to me.
nit: this loop is a little unconventional. Maybe we could use `pollFirstEntry` instead of the iterator? Similarly in `setNumKip500BrokerNodes`.
When you make `initializeSnapshotWithHeader` private, you may need to slightly change this implementation. E.g.: ```java return supplier.get().map(snapshot -> { RecordsSnapshotWriter<T> writer = new RecordsSnapshotWriter<>( snapshot, maxBatchSize, memoryPool, snapshotTime, lastContainedLogTimestamp, CompressionType.NONE, serde); writer.initializeSnapshotWithHeader(); return writer; }); ```
As `KafkaStreams` implements the `AutoCloseable` interface now, `close()` should be called automatically when the `try {}` block is left -- that is the whole purpose of `AutoClosable` and try-with-resource construct -- it frees you up to call `close()` explicitly (so you cannot forget any longer).
nit: add `final`
Yes, does not hurt to leave it. Just for sure.
Hmm.. `first` and `last` of RocksDBStore are not used anywhere, I think it is a leftover of the code clean up introduced in KAFKA-4499 (cc @RichardYuSTUG ). Maybe we can just remove these two functions from RocksDBStore.
Hmm, not sure if this is being inherited from other tests in this class, but this isn't the behavior we'd expect. The logic is now somewhat confusingly split between `ConnectorPluginsResource.validateConfigs()` and `AbstractHerder.validateConnectorConfig()`, but since `connector.class` is missing, we expect a `BadRequestException`. This test only works because this answer doesn't match what would actually happen in `AbstractHerder`.
It might be nice to factor out a helper to build the controller and broker nodes. It would make it a little easier to process this method visually.
As above: need to keep default value.
I'd clarify to sth like: > 2) use general data types (here: JSON; but can also be Avro generic bindings, etc.) for serdes in Kafka Streams. To make it clear that this example does not showcase Avro usage.
This wording could be improved: "Batch splitting cannot be used with non-compressed messages, NOR with message format versions v0 and v1"
It seems this still needs to be executed for `minReceivedMetadataVersion >= 2`
Rather than have a list of futures, why not have a single `Future` delegate that is either a `CompletableFuture.allOf(...)` or a single feature? This makes the constructor a little more complex, but it would simplify all of the other methods tremendously since they merely have to delegate (except for `cancel()` and `isCancelled()`, which can stay the same: ```suggestion public ErrantRecordFuture(List<Future<RecordMetadata>> producerFutures) { if (producerFutures == null || producerFutures.isEmpty()) { future = CompletableFuture.completedFuture(null); } else { futures = CompletableFutures.allOf(producerFutures); } } ``` This will make `get(long, TimeUnit)` behave more correctly by requiring that all futures complete within the stated time.
Should we mention this in the KIP? It was not specified there - even though this is the same behavior as the old AlterConfigs, in the context of the KIP this non-transactional functionality isn't obvious I fear
Perhaps: > The record consumed from the input topic has an invalid (negative) timestamp, possibly because a pre-0.10 producer client was used to write this record to Kafka without embedding a timestamp, or because you are reading from a pre-0.10 topic after upgrading the Kafka cluster to 0.10+. [...]
Changed this to generate a name `<userName>-cogroup-merge` to align to `<userName>-cogroup-agg-<counter>` instead of just `<userName>` for the merge node.
@vamossagar12 Up to you I guess. I'm ok doing it all here since the changes seem pretty small.
Instead of "Using the newly updated metadata," maybe we can say this: > Resetting the last seen epoch to {}.
For consistency: {@link KafkaStreams} instance
`late` -> `out-of-order` -- if it's _late_ it would be _after_ the grace period and would be dropped.
nit: double space
Cheating the compiler, woohoo!
We shouldn't return `null`, but instead return a "unknown query" result.
This is not introduced by this PR but: `processorSupplier` can be reused for `addProcessor` and `ProcessorParameters` constructor below for both the physical and logical plan generation. Similarly the storeNames can be reused for both as well.
Well, if you want to match the use of `DESTROYED`, `RUNNING` probably makes the most sense since that is the target state you want the connector/task to be in. But I'm not picky, either one works.
We should limit this suppression to the method for which we really need it instead of the whole class
Hmm, we're using a raw type here and a few other places. This is discouraged (type checking is disabled in these cases). If we don't want to propagate the generics when we use the superclass, we should probably drop them.
nit: it was correct before
Can just return `name.startsWith(acl.resourceName())`
nit: line too long
Maybe use log parameters instead? ``` java log.warn("Error executing interceptor onSend callback for topic: {}, partition: {}", record.topic(), record.partition(), t); ```
Nit: this can be written more concisely by using `Arrays.asList`.
If there are pending async commits, then the coordinator must be known (because we explicitly fail all requests to the coordinator in `coordinatorDead`), so I'm not sure I see the value of rediscovery here. However, I think there is some value in calling `ensureCoordinatorReady` prior to invoking `maybeAutoCommitOffsetsSync` and also prior to sending the LeaveGroup.
This exception can't be thrown by DeleteTopics.
```suggestion "<li><code>org.apache.kafka.clients.consumer.StickyAssignor</code>: Guarantees an assignment that is " + "maximally balanced while preserving as many existing partition assignments as possible.</li>" + ```
Here if we refactor to `left / right` then this logic can be simplified as well since we would only care whether the deserialized key/value are left or right.
One more thing, let's call this `recordsOrFail` to make it clear that the operation is not necessarily safe.
(especially given that below you use the simple name)
The number has changed and 5 is no longer relevant.
Sorry for being late on this. Populating static variables from a non-static method is generally not a good practice since it's generally not thread-safe. Given how JMH works, it's fine for those fields to be non-static right? Also, it seems more realistic since the data is isolated per run.
Fair enough :)
nit: `{@link KeyQueryMetadata}`
Another nitpick: to use 0 as the base store prefix, and 1 as indices and so on; the main thinking is that in the future we may extend it to have multiple indices with a single base.
When a stream is created from multiple topics, we do not have any ordering semantics across those topics, but within a single topic we still follow the within-partition ordering.
@llowrey, it would also be interesting to know the environment where you can reproduce this. I tried writing a test that connects 1 million times to a Java EchoServer and `connect` always returns false.
You and I had the exact same thought: https://github.com/apache/kafka/pull/3164/commits/a7bc3e6e98ad3f983f5619601b216e83142afe42
nit: "can not" -> "cannot", same below
Do we need to do this `close` and `open` here? We do it also on lines 283 & 286
This intermediate `List` is not really useful. We could just change the loop below to iterate over the connector classes and call `getSimpleName()` on each of them
This is the callback from the `StreamThread`s so it will be called from multiple threads, i believe. See the inner class `StreamStateListener`
`return stream(null, null, keySerde, valSerde, topics);` Do the call directly instead of the cast.
Seems the only thing we really care about is offset commits when shutting down. As long as we send the LeaveGroup, it's probably fine not to await its response (because of one of your previous patches). Because we now have the check for `pendingAsyncCommits`, I'm wondering if it's actually necessary to await all pending requests from the coordinator? At least if we keep the check, maybe we could ensure that we are not in the middle of a rebalance since that would unnecessarily delay shutdown.
`hasFetchedRecords` avoids the cost of populating the map returned by `fetchRecords`. No locking is needed for that. So, if I understood the suggestion right, it would look something like: ```java if (fetcher.hasFetchedRecords && client.hasPendingWakeup()) client.poll(0, ...) ``` I guess by calling `poll(0, ...)`, we don't have to expose `maybeTriggerWakeup()`.
It's internal. So should be fine.
Sorry for the forth and back -- for `assertThat` you original code was correct and expected argument is second one... (it different for `assertEquals` -- my bad(!)).
@rajinisivaram Thanks for the detailed explanation. Yeah, I was basically wondering if topic expiration was a "good enough" fix for all of these cases. You may have some unnecessary logging until a deleted topic is expired (for example), but it seems like it wouldn't be too bad since the expiration timeout is 5 minutes, which also matches the default metadata refresh interval. Since we're not attempting to fix the problem of log spam while a message for a deleted topic is queued (which seems like the most likely source of excessive metadata error logging to me), do you think the early removal still makes a big difference in practice? If so, then it may be worth keeping.
nit: Normally for getters we have the convention of dropping the `get` from the method name.
Making timeouts configurable could be a good idea, but it's better done in a general way in its own PR.
My fault! I missed the parameter. I looked at the next parameter in the `StateRestorer` constructor which is a `long`.
@mumrah Have we considered dropping the `PartitionData` class entirely in favour of using `FetchRequestData .FetchPartition` directly in the broker? The main difference is that `FetchPartition` does not have an `Optional` for the leader epoch but returns the default value (-1) instead.
and -> a
calc -> calculate
For case 3, we should log an ERROR entry indicating that we are going to proceed with commit failed still and it may result in duplicated data being consumed, and for such cases we should notify the user.
as above mentioned, the `listStore.all()` is not closed here.
I think we can use a utility method provided by the `ConfigDef` class here: ```suggestion List<String> topics = (List<String>) ConfigDef.parseType(SinkTask.TOPICS_CONFIG, props.get(SinkTask.TOPICS_CONFIG), ConfigDef.Type.LIST); if (topics.contains(dlqTopic)) { ```
Nit: var should be named `deserializeValue`
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
nit: toString not necessary
nit: also add java doc for type `T, O` here
These changes are going to break existing users. For example, I have connectors with a few settings prefixed with `consumer.`. I wonder if we could keep the old behaviour (even if partially broken) while adding the proper prefixes
Add a reference to KIP-511 here
I think the name of the function is better defined as `interleaveTasksByConsumers`
> Just clarifying: After the group has formed, both leader and follower can still trigger a rebalance: leader will trigger a rebalance if the existing topics number of partitions has changed (including the topic is deleted); follower will trigger a rebalance if the subscription has changed (both due to a metadata refresh with regex pattern or user called subscribe again). Is that right? Yes, right. > And if we change the consumer coordinator to allow passing regex to the leader, I think joinedSubscription can be removed completely and only leader need to trigger rebalances unless users call subscribe again on any of the consumer member, is that right? The leader will still have to deal with the potential for a metadata update during a rebalance, so I'm not sure we can remove `joinedSubscription`. At least we won't need this funky logic to try to change `joinedSubscription` after the rebalance though.
`The default "all" setting` -> `The default setting "all"`
deliveryTimeoutMs should be mentioned
@rondagostino are we ok with merging this to trunk? Since this is not required for existing tests which either use ZK or PLAINTEXT brokers, not planning to backport to older versions.
yes, it seems to be not what this test is checking on. I think we can drop it here.
That is a good point. I think adding a boolean flag in addition to the `future` result indicating if it may be incomplete is better than exposing the node map. I.e. we could have two fields inside `ListConsumerGroupsResult`, a `boolean` and a `KafkaFuture<Collection<ConsumerGroupListing>>` (I think we do not need to have nested KafkaFutures so I did not have that inside `Collection`, but correct me if I overlook anything).
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
I don't think it makes a big difference either way. The intent of the offset commit interval is just to make sure committed offsets don't fall too far behind. It does not need to be a strict schedule. It seemed more intuitive and simpler to me to reset the interval. In any case, we should get rid of this relative tracking of the next commit. If we use an absolute time, then we will not have problems like this in the future.
This is a fairly complicated line, so I'd recommend pulling out the connector class name as a variable assignment just before line 433. And, these 3 lines are calling `configState.connectorConfig(connName)` multiple times, so that should probably be pulled out to a local variable as well.
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
We should log an error that prints out what the two configs actually are
As I understand it, handleResponse will always be called by AdminClientRunnable from the single 'network thread' (KafkaAdminClient.thread).
Does this test ever encounter this exception? I don't think we will be able to backport this test to < 2.6 because the method won't exist at all, much less generate the exception that is being caught here. If anything, this generates a less informative NPE later in `put`, and hides the actual root cause.
if you have an unsigned ~~8-bit~~ 16-bit data source
The test should describe what it is doing, i.e., `shouldThrowStreamsExceptionWhenBrokerCompatibilityResponseInconsisent`
Should we still log it, perhaps as a warning? If I understand the background, this case is unexpected except with 0.10 brokers, so it seems like swallowing it could mask an important condition.
It seems to me that we could have a single `createSaslClient`. Most of the code is the same apart from the mechanism, clientPrincipal and the exception message.
```suggestion final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.emptyMap()); ```
These timeout loops are indeed painful. This one could be structured a little more nicely. For example, there's probably no need to check the result of `awaitMetadataUpdate`; we can just let the loop logic handle the timeout. Also, it might be more natural to `break` after first checking `future.isDone`. That might make the timeout check in the middle unnecessary.
I don't think this is necessary to add here. AFAICT `StreamsKafkaClient` is only used in `InternalTopicManager` and it can just be constructed there
I might be mistaken, but this doesn't seem sufficient. It seems like we should compare the out of range offset with the current consumed position and only throw the exception if they are equal. Presumably if the user has seeked to a new position, then they wouldn't be interested in an out of range error from a previous fetch.
if we keep ending up with this pattern, it might be clearer to create a `Listener` implementation that delegates to a list of listeners instead of chaining them manually this way
Filed this one: https://issues.apache.org/jira/browse/KAFKA-12607.
Adding to `connectorProps` won't change the already instantiated `config`.
This should be three tests.
The order is not really that important here, either way works
nit: `leaveReason = "consumer poll timeout has expired..` So that the whole log entry would read as `Member sending leaveGroup request to coordinator due to consumer poll timeout has expired ..`.
```suggestion capturedConsumedCallback.getValue().onCompletion(null, new ConsumerRecord<>(TOPIC, 1, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TP1_KEY.array(), null)); ```
Please increase timeout to 30 seconds.
`assertNull`s shouldn't be here but few lines bellow.
This is part of the public API, so we don't know all the ways its being used. I still think we're better off output a more complete message.
Understood. I think that we should revert this. I think that it makes sense to wait until we complete the migration of the remaining requests. We should have them pretty soon now.
That was my other thought. We might wrap one DataException into another but that's not a big deal. In this code `Decimal.toLogical` is now used, and if you follow the refs, there's a `new BigInteger(value)` in there that might throw `NumberFormatException`. Improbable, but thought we could be on the safe side with the more general catch block.
Should be final.
Q: I might have missed the discussion. Why does an unknown offset result in `1` and not in `Long.MAX_VALUE`? Sorry if you have already answered this question elsewhere.
Any reason this isn't in `setUp` since it's needed for every test? Also, is there a reason `MirrorMaker.start()` isn't using the `wait_until` to wait until the node comes up? Seems like all callers of `start()` would want this functionality.
use `try-catch` instead of `expected` annotation -- not a single line test.
maybe use "a", "b", "c" as values, as the transformer counts the number of calls to `process` (for better distinction with next test)
nit: `log.error("Exception caught while post-committing task: {}", task.id(), e);`
Existing issue, space should be after the colon.
I'm not sure how significant it is for the timeout to be a multiple of the refresh interval. The scheduling might not ever align anyway since it depends on poll() getting invoked at the right time. I also don't see why a separate mechanism would be needed for a hard-coded value. We're not expecting high granularity, just a way to avoid the cache growing unbounded over time. My concern is that we are technically changing the semantics of `metadata.max.age.ms` for the producer. Before it only controls how long we wait before refreshing metadata; now it also sets an expectation on the frequency of writes to each topic. Admittedly, the change should be transparent to the user, but it feels like an unneeded dependence.
@mjsax I think I'm sold on your arguments, let's keep them as WARN then :)
`earlier or later` -> `before or after` (to avoid confusion with the term "late data")
`if (ignoreWhenShuttingDownOrNotRunning && (state == State.PENDING_SHUTDOWN || state == State.NOT_RUNNING))`
never mind - I see this isn't a change from what was happening before. Still seems good to do, but not necessarily in this patch
@mjsax is right. Just to clarify, state store / changelogs today only do header-agnostic serde, so the scope of this PR is only for sink nodes.
Nit: remove the `:` after "type", since this forms a readable sentence.
Why remove this? Do we need to instantiate this class now? (I only see static members still).
Since we are adding `fenced` to the RegisterBrokerRecord, do we also need to add a `fenced` field to the BrokerRegistrationRequest RPC? Or is it the case that only the controller will set the fenced state of this record
Instead of "Using the newly updated metadata," maybe we can say this: > Resetting the last seen epoch to {}.
Nit: too many blank lines.
If we run the script to do the actual release, we have this information already. It would be good to reuse this. Ie, we can keep this as-is, however add a second method that takes this information as parameters. This allow us to call the new method from here, after we collected the information, but also at the end of the regular execution of the script and pass in the information directly. Thus, if a committer does a release, it's not required to call the script again but the email template will be generated directly.
`result` is unused in this code block. To be future proof, I'd suggest being explicit by returning an empty list here, and declare `result` right above the block that is being used at.
Are there ever situations where users would want the old behavior (to have access to the `ProcessorContext` for the record that triggered the lookup, rather than the context for the record that's being looked up)? For example, if the topic name is relevant for the transformer and all records (including the current one that triggered the lookup and the one being processed) are from the same topic, then the old behavior gives access to the topic name but this new behavior doesn't.
nit: plural (`Reflections`) seems more appropriate because it refers to the library/class.
There's no need to copy entry.getValue().sourceTopics into a HashSet just to iterate it. Later down you put individual soureTopic into a topicToTaskMap which already eliminates possible duplicate keys...
Nice tidy up of this test class :-)
Ok, it looks better now. Let's leave it this way, with two lines.
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
I looked at it closer. I still think it's better to split them out, but I also don't think it's a correctness issue right now, so I'd be fine with merging what you have.
i think leaving as is should be fine atm, and tbh at least they are both close enough together to be easily modified together. if we think this is useful enough, i'd file a jira dependent on the jdk8 update so we can follow up.
@guozhangwang No need to divide by 2 in the for-loop as it hops by 2 each iteration, so when it reaches `keyValue.length - 2` the next value of `i` will be keyValue.length. ;)
Good point, thanks for clarifying.
InvalidTopicException happens when the topic name can't be represented in the request, or if it is not found, not if it collides with another topic name.
I know that's kind of another large change, so feel free to tell me to drop it  Or one of us can consider as followup work.
req: You do not need to verify the `activeTaskCreator` here, since you are not testing `handleAssignment()`.
> I've been going back and forth on whether to add this as a "per-cluster" or "per-instance" config, @vvcephei and I discussed briefly but @cadonna any opinion? If we do go with cluster-wide I think we should make the default pretty big, but I'm now leaning towards towards making it per-instance. Thoughts? per cluster: - (+) We would have more freedom in the assignment algorithm, because we do not need to consider the value of this config for each client. - (-) How should we react to distinct values on clients? How should we even know whether there are distinct values configured? We could just say Streams assumes the values of this config are the same on all clients and whatever is specified on the group leader is the truth. per client: - (+) Each client host might differ in performance and users might want to adapt the value of this config for each client - (-) Within the algorithm, how should we know the value of this config for a specific client? Don't we need to adapt the protocol to get all values at the group leader? Since assignment and restoration (a.k.a. warming-up) is done on stream thread level, it might be better to specify the value per stream thread. For example, 1 would mean that one extra replica per stream thread might be assigned. If a Streams client has three stream threads it can host up to three extra replica. The config would be global (a.k.a. cluster-wide) but users could account for different performances of the hosts by specifying different number of stream threads (which they probably have to do anyways). Here again, the value specified at the group leader is the truth.
Should probably add this as the first bit in this method: ```suggestion String strValue = (String) value; if (value == null || strValue.trim().isEmpty()) { return; } ```
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
Similar questions below.
If case of failure, we detect the failure only after `session.timeout.ms` (default 10 seconds) hit -- to speed up the test, we could decrease the session timeout via `StreamsConfig`
I think this one and `ADD_OFFSETS_TO_TXN` should have magic v2 set has well.
Might be better to add a catch-clause for this case instead? ``` try { ... } catch (final UnknownTopicOrPartitionException ignoreAndSwallow) { } catch (final InterruptedException | ExecutionException e) { throw new RuntimeException(e); } ```
Don't we need to set version 0.10.1 for those initially? Otherwise, they will have trunk version
I am wondering, if we should to even more refactoring an pass in `Serialized` directly here to reduce the number of parameters. Not sure though if the win out weights the refactoring effort. Same for the other PRs btw. Any thoughts? \cc @guozhangwang @bbejeck
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
I wonder if a safer way to do this from a compatibility perspective would be to provide a default method for `close(Duration)` which invokes `close(long, TimeUnit)`. Similarly for the producer.
Do we want this to be `error` or `warn`? Maybe `error` is right, so take this as a question. :)
Might be nice for demonstration purposes if the two records actually have different keys. Maybe: ```suggestion aTopic.pipeInput(1, "999-alpha"); bTopic.pipeInput(999, "beta"); ```
exception can be improved a bit - "failed to flush within X ms, successfully completed Y/Z batches". wuold help distinguish between slow connection and no connection.
@mjsax What you suggested sounds right to me.
It seems that we need the logic to turn off OP_WRITE here too. Suppose that the client tries to send a token, but couldn't completely flush the writes. We get in here and completely flush the output buffer. Now, if the OP_WRITE is not turned off, the selector will be woken up all the time before the client receives the next token from the broker.
Better be `cooperative-sticky`? `cooperative` is too general I think.
nit: add a space so it is "StreamsMetadata {...} topologyName=xyz"
Actually I was really just asking for people's opinions :) the cons are that these classes will be in different packages which may looks a bit weird.
nit: I think it's better to just print the e.message in a single line.
Actually `this.name` is still the processor node name, not the KTable name as mentioned in the JIRA. However, after thinking it a bit more, I feel there are a few corner cases when using the state store name may be cumbersome: even after KAFKA-3870 and KAFKA-3911 is merged, still not all KTables will be backed by a state store (for example, a KTable generated from another KTable.filter, which is just a view of the other table). And if we call `filter` on both of these KTables, they will actually share the same state store names, which are confusing. So just using the processor node name, admittedly are not very intuitive for users, may be the least bad solution here.
Does `TopicsInfo` work for a map key? Looking at its override equals, it doesn't seem to check all fields for equality.
nit: maybe it's more helpful to use the error directly here since no one knows the codes.
nit: full-stop after the description.
I am wondering why this is not an assertion. Would the broker ever be expected to return only a subset of the partitions in a full fetch request? To be honest, I think it would be fine to skip these checks and just assume the broker gives us the right thing.
By the way, I sort of feel it would make our lives easier if we used `KafkaRaftServer` directly instead of building the controller, broker, and raft managers ourselves. For one thing, that would make it trivial to support mixed mode. We don't have to do that here, but I'm kind of curious if there is a reason that we don't.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Could we expose this like the following instead? ``` public KafkaFuture<ListOffsetResultInfo> partitionResult(TopicPartition partition); ``` Then we can keep the map internal.
nit: need to update this since resource name is before pattern type now
@guozhangwang if the end offset is less than the checkpointed offset, how is it possible to _not_ throw a `TaskCorruptedException`? I thought that was thrown after checking this exact condition? edit: what I mean is, do we think this is a possible state? If so, we should explicitly check for it and throw `TaskCorrupted` if detected. (If not, it's an illegal state and thus the check here is appropriate)
Could store `entry.getKey()` in a local variable since it is used several times
Should we handle the case when `adminListener` is empty or blank? See line 126 above.
This method name doesn't follow Kafka code conventions.
I would prefer a second loop to guarantee a consistent reflection on the task committed state.
Discussed this with @junrao. The main challenge with this option is having the top level error field for every response. This would probably affect a lot of code: 1. We would need to handle this top level error code everywhere. 2. A bunch of protocols that currently have a top level error code would no longer have them, so a bunch of code would have to be updated as well. So, it doesn't seem appropriate to do this as part of this KIP.
This intermediate `List` is not really useful. We could just change the loop below to iterate over the connector classes and call `getSimpleName()` on each of them
What about checking for the state and do the clean-up only if the state is not `PENDING_SHUTDOWN` and not `ERROR` and not `NOT_RUNNING`? In this way we are safe for future changes that break our assumption on state transitions and we make sure not to do unnecessary stuff when we are shutting down.
That is correct: ``` {@link org.apache.kafka.streams.kstream.KTable KTable} ``` will show on java docs as `org.apache.kafka.streams.kstream.KTable`, while the above will show as `KTable` whose ref links to `org.apache.kafka.streams.kstream.KTable` still.
Let's keep the existing `trace` and `error` log lines in the `else` block. My suggestion is to add a line at the debug or trace level in the `if` block so users can know if an error is ignored.
This implementation of `equals` will return false for timestamps of the same value; maybe this could be something like `return Long.compare(timestamp, otherTimestamp) == 0`
nit: as in `position` above, `this` is not required
It's better to do `instanceof` than this. The JVM folds the `instanceof` into the trap it needs to ensure JVM semantics.
This should be three tests.
Alternatively, we could ditch the `driver` field and just make it a local variable in every test. Having it as a field made more sense when it was `setUp` in each methods, but now that it's instantiated in each test, it would be simpler to limit the scope to a local variable. Each test would need to call close at the end, but that's fine with me. If anything, it demonstrates proper use of the driver.
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
I used `equalToObject()` because it makes the intent more explicit.
This shouldn't throw an exception. The existing logic where we fail the task is what we want to do here.
Hmm, `DataInputStream.readFully` only throws an exception if we ask it to read past the end of the InputStream. So supposedly, if we fix the underlying InputStream, it's enough either way. The following PR does that: https://github.com/apache/kafka/pull/2025/files#diff-eaa7e4414f285da2ff8e4508456078d2L192
`hasFetchedRecords` avoids the cost of populating the map returned by `fetchRecords`. No locking is needed for that. So, if I understood the suggestion right, it would look something like: ```java if (fetcher.hasFetchedRecords && client.hasPendingWakeup()) client.poll(0, ...) ``` I guess by calling `poll(0, ...)`, we don't have to expose `maybeTriggerWakeup()`.
For transition to `NOT_RUNNING`: the instance will only shutdown if the user uncaught exception handler decides to shutdown the whole instance, by calling `close()`, in this case it will still go through the `PENDING_SHUTDOWN` transition first? For `REBALANCE -> REBALANCE`, this is related to the thread-level `partition revoked -> partition revoked`, which I'm still wondering if we can avoid. Let's sync a bit on that.
Doing in `@Before` is fine. But we don't need to call `new` each time. `this.props` will be a new empty `Properties` instance anyway -- we don't need the second object.
The DescribeGroup API has to be sent to the group coordinator, which is potentially a different node for each group. You use the FindCoordinator API in order to lookup the coordinator for a given group. The logic should be something like this: 1. For each group in the request, send a FindCoordinator request to any node in the cluster. 2. Group the results by coordinator id. 3. Send DescribeGroups to each coordinator from 2. Ideally, we should also handle retries correctly. It could happen that the coordinator moves to another node by the time we send DescribeGroups. In this case, the error code will be NOT_COORDINATOR. We should handle this by looking up the coordinator again.
Ack. By bad.
ok, I get that though I think that's just tech debt. for any test related files, we really shouldn't be using anything other than `PERSISTENT_ROOT` so that we can at least attempt to ensure each test/service gets a clean workspace
`KeyValueStore` -> `TimestampedKeyValueStore`
```suggestion "<li><code>org.apache.kafka.clients.consumer.StickyAssignor</code>: Guarantees an assignment that is " + "maximally balanced while preserving as many existing partition assignments as possible.</li>" + ```
Is the current implementation vulnerable to the following race condition? 1. thread1 grabs `CHANNELS` lock, get the channel object from the map; and then exists the `CHANNELS` lock; 2. thread2 grabs the lock, release the lock on it, close the channel, remove from the map. 3. thread1 now calls `channel.tryLock`, which throws `ClosedChannelException`.
`info.version()` could be replaced with `receivedAssignmentMetadataVersion`
That has its own complications because if my provider is only providing TrustManagerFacotry.PKIX then it can't provider other services+algorithms that might be expected in calls like SSLContext.getInstance(String protocol, String provider). SSLContext.getInstance might look for TLSv1.1 or TLSv1.2 etc which my provider doesn't really have and I don't have a way to fallback anymore once I go route of specifying "provider" in getInstance() calls. In short - once we have a Provider providing a Standard service+algorithm we may have to implement other services+algorithm also otherwise it may not work (like I mentioned for SSLContext)
The `ProducerPerformanceService` would have to call `super.stop()` for this to be invoked right? I don't think it does it presently. Please correct me if I am wrong.
remove unnecessary newline
I'd suggest flatten the map to abstract away which nodes contains which consumer groups as they are supposed to be internal information, we have the freedom to change those internal impl whenever we want. Once we expose such a public API it will be partially public information and hence hard to change.
We need to check again after we grab the lock, otherwise the store might get closed after we check but before we grab the lock. Once we get the lock, we're guaranteed that this block is serialized wrt close(). But we can still check beforehand to avoid grabbing the lock if it is closed.
Unless i'm misunderstanding something, I think these test names are inverted. ```suggestion public void shouldParseUnquotedEmbeddedMapKeysAsStrings() { ```
nit: add `final`
nit: after.. what? I think you can drop "in time after." Here is the assertion that is used: ``` assertThat("Condition not met within timeout " + maxWaitMs + ". " + conditionDetails, testCondition.conditionMet()); ```
Hmm, `DataInputStream.readFully` only throws an exception if we ask it to read past the end of the InputStream. So supposedly, if we fix the underlying InputStream, it's enough either way. The following PR does that: https://github.com/apache/kafka/pull/2025/files#diff-eaa7e4414f285da2ff8e4508456078d2L192
@mjsax if `resume()` is called on the consumer `verify` will fail the test.
format: no need for curly braces
nit: as above, use `@link`
@jeffchao traditionally Kafka used key,value pairs in properties and pass it everywhere and each implementation takes look at this config and pulls their interested key,value pairs. Example, authorizer interface https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/security/auth/Authorizer.scala#L35 . The pluggable class when it gets instantiated a configure method will be called and all the key,value in server.properties will be passed and it will pick whats relevant to the class. We can do the same here instead of asking users append key,values into the a config which is hard to configure and hard to get it right.
`long,long` is used for `WindowStore` while `Instance,Duration` (or `Instance,Instance` if we correct it) is use for `ReadOnlyWindowStore` that return the same iterator.
req: I think we want to introduce some `acceptableLag` config within which a task is considered caught-up, otherwise this is way too strict. ie the condition should be `lag <= acceptableLag`
Why the qualification that says "that generates stateful processors"? AFAIU nothing prevents the user from supplying a state-less transformer (supplier), even though yes, you can also provide the names of state stores when calling this method.
You've added a few empty lines in this file. We should remove these
I think we ditch the before/after methods as I previously recommended.
`schemaType` is null means that the value type is not supported by the Connect's Data API. May be we should throw an exception with a message indicating this.
I think this is a better approach, but we need to be careful about the callee inside hb thread: ``` if (findCoordinatorFuture != null || lookupCoordinator().failed()) ``` i.e. a hb thread sending a discover-coordinator request would also cause a future to be assigned, but that future would only be cleared by the main thread caller. Thinking about that for a sec I think this is okay, but maybe worth having a second pair of eyes over it.
the method `restorePartition` is no longer used and can be removed
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
This test replaces `shouldGetThreadLevelSensor()`. Thus, you can safely remove `shouldGetThreadLevelSensor()`.
@tadsul We could perhaps convert this to a immutable map and store `in `originals` like we do for `values`.
How about "runs an external command for the worker."
Oh, and a question just for my understanding: Initially I would have suggested that `branch` should perhaps be named `partition` but then I realized that `branch` is different from (say) Scala's `partition`. Notably, we ignore/exclude any data records that do not match any of the criteria = no catch-all bucket for `branch`, although this behavior does exist in `partition`. I suppose we don't need any such `partition` method? Or, why did we go with `branch` instead of `partition`? (I understand `branch` to be a combination of `partition.filterNot`.)
same... `@link` > `@close` for this case.
I actually had a similar thought, but I am torn though. Using two variables required to keep them "in sync" was is not great. However, using `null` is less explicit... Thus overall I am fine either way as both seems to provide the overall same good/bad ratio.
Nit: can be `final`
Great catch, thanks @showuon !
You are right, this is fine. I was confused about the checkpointedOffsets in standbyTasks before.
Actually `Worker.startTask` is what I was referring to. All we do is submit the `WorkerTask` to an executor. I'm trying to understand the benefit of the parallelization.
Just a small nit: this is how my brain works -- otherwise the condition is "reverse" and I need to flip it in my head
Why the qualification that says "that generates stateful processors"? AFAIU nothing prevents the user from supplying a state-less transformer (supplier), even though yes, you can also provide the names of state stores when calling this method.
I haven't seen this struct being used.
nit: rename to `processor` because this test uses only one processor (the numbering is confusing otherwise)
Not sure if this will actually be cleaner or end up more complicated, but you may be able to reuse some of the `StickyTaskAssignor` code here which does similar things
Thanks for the explanation: checking per-commit is indeed easier. Moving forward we can even make them two separate PRs for other reviewers to easily review.
There are some request header tests in `RequestResponseTest`, we should move them here so that we can find them all in one place.
Below we break into `brokerResources` and `unifiedRequestResources` and send two requests; we should check them and skip if possible respectively.
@becketqin Yes, my preference, as mentioned above, is to deal with that problem separately. We should not make behavioral changes without first raising the issue at least in a separate JIRA. The unintuitive thing about the proposed behavior to me is the fact that although the consumer's position remains at the offset of the failed record, the next returned record will be from the offset after that position. You can see this in the test case below: the consumer's position is at 1, but the returned record is at offset 2. This makes the behavior less deterministic. It would be nice to maintain the invariant that the next fetched record is always the first record at an offset greater than or equal to the current position.
`KeyValueStore` -> `TimestampedKeyValueStore`
Also - this method gives the ability to construct different configs for different nodes - so it seems like the logic for setting `self.security_config` doesn't belong here since it is independent of the node, and would have unintuitive behavior if it did become dependent on the node? (e.g. configuration of one node affecting configuration of other nodes)
I'm thinking exactly the opposite :) if we have a bug which would cause us to create a state store, checking it twice may actually mask the bug: we would end up creating the state store, and then on the second check not getting it, so the behavior is still correct, and it'll be hard for us to discover we are creating state stores unnecessarily. If we have a bug and do not create state stores when needed, then we would behave in the old way without the fix; the key point here is that, we only have one decision point to make, and either that decision is correct or buggy, we can get it surfaced quickly.
IIUC, this changes the behavior of the `WorkerConnector` created below. Prior to this PR, the `WorkerConnector` was always created with the `Worker.offsetBackingStore`, even for sink connectors. However, with this PR, the `WorkerConnector` will be instantiated with a null `offsetReader` parameter, which will cause a NPE in `WorkerConnector#doShutdown()` and `WorkerConnector#cancel()` since `WorkerConnector` does not check for a null parameter there.
Can/Should these be immutable values? Maybe you can use the singleton `Collections.emptyList()` to avoid making memory allocations.
This definitely doesn't cover the full space of errors that are possible here -- `asSubclass` could throw a `ClassCastException`, `newInstance` could also throw `SecurityException`. I think the `catch` was broad because this ensures that except for extreme cases like other `Throwables` or `Errors` we get everything converted to `KafkaExceptions`.
nit: would be nice to be consistent on the pattern we use here
Better be `cooperative-sticky`? `cooperative` is too general I think.
We can use `ApiResult.completed()`
Hmm I'm still not clear where did we break the topology order here: let me go through my reasoning and lmk where I got it wrong: 1. in `InternalTopologyBuilder` when we construct the `InternalTopology` the following parameter is constructed: ``` new ArrayList<>(stateStoreMap.values()), ``` So `ProcessorTopology#stateStores()` is in order. 2. in `AbstractTask#registerStateStores` we get stores from `ProcessorTopology#stateStores()` which is in order, and hence we are calling `store.init` in order, and hence call `ProcessorStateManager#register` in order as well. 3. The resulted `stores` in `ProcessorStateManager` should be in order then as well.
nit: we do this same thing in the other `#resize` for thread count changes, can you factor it out into a helper method? Then I think we can narrow the scope and make only that helper synchronized (should double check that though)
Maybe consider replacing `Stack` with `Deque` as `Stack` is synchronized and `ownedSensors` only adds in the constructor and removes values in `synchronized` block already.
maybe "Restoration completed for partitions:"
This is an interesting question. One low-fi solution would be to think about using `equals()` (I think to pull this off, we'd need to introduce a requirement that serde/serializer/deserializers implement equals in a way that would be semantically sound for us. This would not be a back-ward compatible change. On the other hand, since callers actually subclass `Serde<T>` with a fixed type like `Serde<String>`, it actually should be available at runtime. I don't remember the hoops you have to jump through to get it right now, but I'll revisit it tomorrow.
I was debating the same thing. Won't `NetworkClient` keep the node under the `CONNECTING` state though? It seems like either approach involves a change in the contract that could affect users who are not expecting it. It's an internal class though, so we just need to make sure that the affected Kafka code is updated (if necessary). It would be nice to include a test for this so that we can verify that things truly work under this scenario.
Perhaps we can use a better name for keysWithBytesFromSocket since selectedKeys() include keys ready for writes too.
Could be simplified to `not hasattr(node, "version") or node.version > LATEST_0_8_2)`
Ouch! Sorry about that!
Also, this is failing checkstyle because there is no space after the comma. I think there are a couple unused imports in this class as well (you can check the jenkins build for more detail).
Definitely. This is one of my favorite gripes. Using more specific types whenever possible allows the compiler to do more work for us.
Any reason you change to import all classes under `java.util`? I think we should import what we used in this class only.
Thanks for cleaning up the code duplication.
I don't think it can be. It needs to be a TimelineHashMap to work and needs to receive the snapshot registry in the constructor.
Ah ok fair enough -- thanks!
I reordered the method from "few parameter" to "more parameters" to make it easier to navigate within the file.
@fhussonnois thinking about this some more, what is the motivation for doing a validation here for processor names? When Streams starts up the `AdminClient` will attempt to create any internal topics and the full topic names are validated at that point, so we don't need this check up front. \cc @guozhangwang
make it if-then-else since we dont't need the increment in the line below? Also split this line since we don't include the statement in the same line as `if`.
The serialization package is open to everyone (it's public API and at the lowest layer). So I don't think we should worry about that. It's not like we're avoiding a dependency here, we are just hiding it via a string based config (that still requires the default constructor to be present).
Since shouldBeSinkNode.get(0) may not be SinkNode, consider renaming the variable
This was a separate bug, I guess? Might be worth mentioning in the PR description.
Thanks for the explanation @dguy, very helpful to understand where caching and sequence numbers come into play. It might be worthwhile to put this in a JIRA somewhere. I do think it would be a useful optimization to have eventually, as fetches have some setup / teardown overhead.
i think leaving as is should be fine atm, and tbh at least they are both close enough together to be easily modified together. if we think this is useful enough, i'd file a jira dependent on the jdk8 update so we can follow up.
Could we expose this like the following instead? ``` public KafkaFuture<ListOffsetResultInfo> partitionResult(TopicPartition partition); ``` Then we can keep the map internal.
We probably want another constructor `ChannelState(State state, String remoteAddress)` for non-authentication-failure states where we store `remoteAddress`.
Nit: `Note that {@code InvalidStateStoreException} [is] not thrown directly but only [its] sub-classes.`
Can we also assert that the state gets to `RUNNING` after the new thread has joined
Nit: might be worth adding a simple assertion on the result just to make sure.
Something does not work as expected in this algorithm. According to this doc, the assignor should fall back to distributing tasks on least-loaded clients. However, the following test case fails: ``` @Test public void shouldDistributeTasksOnLeastLoadedClientsWhenThereAreNoEnoughUniqueTagDimensions() { final Map<UUID, ClientState> clientStates = mkMap( mkEntry(UUID_1, createClientStateWithCapacity(3, mkMap(mkEntry(CLUSTER_TAG, CLUSTER_1), mkEntry(ZONE_TAG, ZONE_1)), TASK_0_0)), mkEntry(UUID_2, createClientStateWithCapacity(3, mkMap(mkEntry(CLUSTER_TAG, CLUSTER_2), mkEntry(ZONE_TAG, ZONE_2)), TASK_0_1)), mkEntry(UUID_3, createClientStateWithCapacity(3, mkMap(mkEntry(CLUSTER_TAG, CLUSTER_2), mkEntry(ZONE_TAG, ZONE_1)), TASK_0_2)), mkEntry(UUID_4, createClientStateWithCapacity(3, mkMap(mkEntry(CLUSTER_TAG, CLUSTER_2), mkEntry(ZONE_TAG, ZONE_1)), TASK_1_0)) ); final Set<TaskId> allActiveTasks = findAllActiveTasks(clientStates); final AssignmentConfigs assignmentConfigs = newAssignmentConfigs(1, CLUSTER_TAG, ZONE_TAG); new ClientTagAwareStandbyTaskAssignor().assign(clientStates, allActiveTasks, allActiveTasks, assignmentConfigs); assertEquals(1, clientStates.get(UUID_1).standbyTaskCount()); assertEquals(1, clientStates.get(UUID_2).standbyTaskCount()); assertEquals(1, clientStates.get(UUID_3).standbyTaskCount()); assertEquals(1, clientStates.get(UUID_4).standbyTaskCount()); } ``` The standby task for active task 0_0 can be put on client UUID_2 and the standby task for active task 0_1 can be put on client UUID_1 without breaking rack awareness constraints. Standby tasks for active tasks 0_2 and 1_0 cannot be put on any client without breaking rack awareness, so they should be distributed on least-loaded clients. However, that does apparently not happen, because client UUID_3 and UUID_4 are not assigned any standby.
nit: new lines are generally not recommended to break object type declaration with object name. For this specific line I think we can still make them in one line.
maybe use "a", "b", "c" as values, as the transformer counts the number of calls to `process` (for better distinction with next test)
Add definitions for `WorkerConfig#CLIENT_DNS_LOOKUP_CONFIG` and make this just `CLIENT_DNS_LOOKUP_CONFIG`.
nit: add `final`
That's what Bruno originally did, but the original `cleanRemovedTasks` method branched on the `manualUserCall` flag in several places and was pretty difficult to follow (imo). So (also imo) it's cleaner to split it up into two methods that make it clear what the expected behavior is in each case. Just my 2 cents
This logic is repeated in a couple of places. I'm wondering if we could change `MaterializedPeek` to take the `InternalSteamsBuilder` as an additional constructor param and have the logic inside the class, and this block of code could be replaced with `new MaterializedPeek<>(materialized, builder).maybeIncrementTopologyCount()` or something like that.
Sounds like a good idea
nit: "another thread wrote to ..."
@rajinisivaram, hmm, I'd rather us specify the details or link to a config that specifies them. With security, people often struggle so the more information we can provide, the better.
This part will have some conflicts with @mjsax 's PR, just a note.
Nit: add `final`
guaranteed -> guarantees
Yeah, it's not pretty. However, reducing the concurrency of `BufferPool` in the common path is not desireable. We definitely need to handle OOMs correctly, but they are relatively rare and it's OK if that path is slower.
There's now a `Utils.mkProperties` method you can use (in conjunction with `mkMap`) to set these at the declaration site instead of setting them (redundantly) before every test. Then you won't need the `@Before` at all.
Personally I think we should call out the specific method that was removed so we don't cause undue panic. It was only a single method, after all.
suggest returning an `Optional<SustainedConnection` rather than `null` when none can be found - it helps avoid NPEs
If only Java made it possible to declare immutable local variables and method parameters in a more concise way!
Sure, that would work. Maybe `getFirstPartitionError` is a clearer name? Or you could bundle the exception throwing as well into a single `maybeThrowFirstPartitionError`? Either way is fine with me, but I'd prefer not to additional fields without a clear case that they're needed.
I think the basic idea makes sense and is what I was expecting. It might not feel too elegant, but I think a simple approach is best initially. An interesting point to consider is what would happen if an offset fetch is in-flight while a rebalance is in progress. When it returns, the offsets may be stale. I am wondering if it makes sense to fence the response using the group generation. In other words, we record the generation at the time of the request and then verify when we receive the response that it matches the current group generation.
As we can "unset" listener to a `null` value then it's better to protected calls to `listener` against NPE, that involves checking `if (listener != null)` before calling (shrug).
The issue is that local cache may not contain this topic metadata yet or not up-to-date, and that's why we may want to send an `MetadataRequest` in these two function calls.
It seems you can move this line after line422.
Maybe consider replacing `Stack` with `Deque` as `Stack` is synchronized and `ownedSensors` only adds in the constructor and removes values in `synchronized` block already.
We should not print the stacktrace imho, but verify the exception message using `assertThat`.
I think this parameterization is a pretty good idea, and I can add it to my delete topics PR. But if we are going to change the public API, we should update the KIP and potentially update the mailing list with the changes.
That's not what I see when I look at the code. The following code populates `completedSends`: ``` java if (channel.ready() && key.isWritable()) { Send send = channel.write(); if (send != null) { this.completedSends.add(send); this.sensors.recordBytesSent(channel.id(), send.size()); } } ``` `channel.write` looks like: ``` java public Send write() throws IOException { Send result = null; if (send != null && send(send)) { result = send; send = null; } return result; } ``` And `send` looks like: ``` java private boolean send(Send send) throws IOException { send.writeTo(transportLayer); if (send.completed()) transportLayer.removeInterestOps(SelectionKey.OP_WRITE); return send.completed(); } ``` Why do you think we are not waiting for the request to go down the OS layer? I don't see any unflushed JVM level cache/buffer in the code above.
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
I'm ok saving this for #7409.
We don't need a PriorityQueue for this because the batches in the RecordAccumulator is already in order. So we just need to keep the draining order.
I personally was on the side of always using task stream time everywhere but more people feel that we should use processor stream time :P Anyways, all I'm trying to say is that we need to make an educated decision here, and if we concluded that either 1) we rely on task time here, but still use processor time on other expiration logic, or 2) we rely on processor time on all logic, or 3) we rely on task time on all logic, we have a good rationale for whichever we choose.
nit: would be nice to be consistent on the pattern we use here
Please add the exception at the end of the line so that we can get a stack trace, including any "cause" exceptions. Example: ``` log.error("{}: Failed to start the external process.", id, e); ```
I think the logic here is not correct: we should still resume the main consumer and assign standby partitions if active tasks are all running; we should only alter the logic of returning flag with both active / standby all running.
nit: The mention of join group comes out of nowhere
i.e., add `fail` after this line
Thanks for the explanation, makes sense.
Would it have to? I would see each call to subscribe as replacing the previous one. Perhaps if we wanted to support multiple regex subscriptions, we could do: ``` java void subscribe(List<Pattern> patterns); ``` And we could require users to use '^' for blacklisting. This would be consistent with the changes proposed in KAFKA-2388.
We shouldn't return `null`, but instead return a "unknown query" result.
We should include `startPosition` in the message.
`KAFKA-13046: Improve the test coverage for stickyAssignor` is created. Let me handle it! :)
nit: add `final` and line too long
Should be final.
We should explain why the key ("temp") is hard-coded here.
nit: maybe we can pull out a variable for `metadata.topic()` since there are 10 or so uses
I think this config property key seems a misfit, and probably reflects an earlier incantation of the design before KIP acceptance. It might be worth - in a separate PR - renaming this to something like `errors.tolerance` to better align with its purpose.
same here -- sounds like CachingKeyValue with TimestampStore
The serialization package is open to everyone (it's public API and at the lowest layer). So I don't think we should worry about that. It's not like we're avoiding a dependency here, we are just hiding it via a string based config (that still requires the default constructor to be present).
Uggh, yeah, I forgot about this. We kind of inherit some annoying types from Kafka's config setup but I tried to ensure we're using String types where possible. It gets a bit hard to figure out what is valid where -- the JsonConverter actually gets passed a `Map<String, Object>` as that's what is returned by `AbstractConfig.originalsWithPrefix`, but in practice they are all `String` so type erasure allows this to work...
If there are race conditions, we need to fix them. Remember that Streams itself has to use AdminClient.
We should have a constant rather than using '262' directly
@nicolasguyomar We already log the memberId here as we log the entire generation object (which includes the memberId). This was changed recently: https://github.com/apache/kafka/commit/7e7bb184d2abe34280a7f0eb0f0d9fc0e32389f2#diff-15efe9b844f78b686393b6c2e2ad61306c3473225742caed05c7edab9a138832L504. Previously, it was logging the generationId only.
Ditto, I'd suggest just duplicating the code since we may add more logic for version 4 anyways.
nit: don't need `result` can return ` new ConsumerRecords<>(mergedRecords)` directly
nit: these three can be package private
Yeah I think that makes sense here
> What would be the hint for `RetriableException`? The current hint seem to be appropriate.
Does this actually buy us anything here? If `forceClose` is false, then doesn't that mean that there are no more in-flight requests? I think we still increment the in-flight request count even if the client doesn't expect a response.
nit: remove empty line
`info.version()` could be replaced with `receivedAssignmentMetadataVersion`
nit: why double space? (similar below and further below)
Another tab here that should be replaced.
nit: add some sanity check on these numbers (like should be non-negative etc). Also update `toString` method to include this information.
EDIT: nvm, I think I understand it now.
Perhaps we should not change the return type here unless we decide to make the more extensive `LinkedHashSet` change across all APIs (and corresponding KIP).
Please split this up into a separate check for `if ((stateDir.exists() && !stateDir.isDirectory())` and then throw an accurate exception, eg `state directory could not be created as there is an existing file with the same name`
nit: top of class
This method seems to be the exact same as `TimeWindowedKStreamImpl#materialize()` -- we should share the code.
nit: I'd make this final with no assignment, then assign it in both branches below.
Again, a bit more information would be more useful: ```suggestion // Then if we delete the connector, it and each of its tasks should be stopped by the framework // even though the producer is blocked because there is no topic ```
I'm wondering if we should make this `info` or `warn` level. It doesn't seem like it would be very verbose, and it might be nice to see by default because it will have secondary effects later on when we try to start a new transaction, but get blocked. But I also don't feel strongly about it, so I leave it to your discretion.
nit: extra space before `anyObject`
Would it make sense to do this check even before checking if the coordinator is known? Moreover, it seems that we could skip calling `doCommitOffsetsAsync` entirely by returning a completed future directly. What do you think? ``` if (offsets.isEmpty()) return RequestFuture.voidSuccess(); ```
This method seems to be the exact same as `TimeWindowedKStreamImpl#materialize()` -- we should share the code.
Same thing here as above: probably need to use `worker.getConnectorType(className)` here.
IMO, this would be a bit cleaner with a separate executor with a single thread for the status updater.
nit: we can do without the curly braces here and above. However, these will soon be replaced by the actual impl
Should we chain the caught exception? We expect this to be the close exception, but it could also be a timeout or an authentication failure. Might be useful to know in some scenarios.
nit: add `final` and line too long
I'm happy for this to be merged if @hachikuji is happy fwiw.
It seems this test is always using `Cluster.empty()`, which means it never tests state transitions from a topic that is in use to a topic that falls out of use and gets `UNKNOWN_TOPIC_OR_PARTITION` errors.
Adding to `connectorProps` won't change the already instantiated `config`.
Just a suggestion: ```suggestion Objects.requireNonNull(newPair, "The provided KeyValueMapper returned null which is not allowed."); ``` BTW, we should not output records since they might contain sensitive data.
Same as above, e.g. `shouldNotThrowWithoutPendingShutdownInRunOnce`
nit: the name is a bit awkward. How about `maybeInvokeOnPartitionsLost`? We can change the others similarly.
```suggestion log.trace("Topic creation by the connector is disabled or the topic {} was previously created." + ```
This is an interesting discussion. I don't have the full context of these discussions, but I can see the argument for keeping things simple and letting users rely on the regular expression for achieving their goals. I am not sure if it's any simpler to provide two separate regular expressions than just one with the appropriate negation. The latter is easier to write a unit test for too.
I think at the moment, we should never get here, so `IllegalStateException` is fine.
Hmm.. this makes me thinking: does it worth "working around" it to move the naming mechanism of the shared store to `sharedOuterJoinWindowStoreBuilder` above such that it always goes along with the other two store's naming patterns? As you can see here, if the store names are not provided but just the store suppliers, the existing stores would use customized name but the shared store would still use system-provided names.
Adding to `connectorProps` won't change the already instantiated `config`.
@zhuchen1018 : But the issue is that we already processed the response. Next time, when we come back to handleCompletedReceives() again, we will get a response intended for a request different from what's in the head of inFlightRequests.
This is where we leave the group. Any offset commits which haven't yet been sent will definitely fail after this, so I think we need to move that loop into the try block.
Same issue here wrt connector name vs type. We probably need some chain like `connectorType(connectorClass(map))`.
Why is the order of these methods different than in `ConnectorStatusListener`? Also, the `TaskStatusListener` methods always forward the method to the delegate _last_, whereas the methods of the `ConnectorStatusListener` use a mixture. Let's make them consistent.
nit: as in `position` above, `this` is not required
same question here and below about locking around a `volatile` variable. Is this the only reason to lock here? One would think so based on previous usage.
I saw the client doesn't use SASL, and I know that if it would, the test would fail because our current SASL client tries to authenticate before sending ApiVersionRequest. However, the requirements for this patch were to allow clients to send ApiVersionRequest to SASL port before performing SASL authentication. So we need to test them...
Good call. I'll update the code to throw an exception like in `Worker` when creating a source and sink task.
Shouldn't the indentation be as follows? ``` log.debug( "Encountered assignment error during partition assignment: {}. Will skip the task initialization", streamThread.assignmentErrorCode ); ``` The first parameter is one or two characters too long, though.
Make all locals `final`
Nit: in `parseValue`, we changed this to `NO_DEFAULT_VALUE.equals(key.defaultValue)` due to findBugs warnings.
These iterators need to be closed or they'll leak resources (it's the same for IQv1 as well).
Would it help to actually list the method that was used, in case somebody thought they were using basic? ```suggestion log.trace("Request credentials used {} authentication, but only {} supported; ignoring", BASIC, method); ```
Ah. Thanks. I missed the line in the constructor when a `StreamsConfig` is created -- thought there is no `StreamsConfig`. Makes sense now.
Nit: "Assigning tasks to streams clients: ..."; also better to be `log.debug`.
Nit: ```suggestion public void testDefaultCustomizedHttpResponseHeaders() throws IOException { ```
I think we need to skip all the code in this else block if the partition is no longer assigned.
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
Nit. use `{ }` for all code blocks
nit: also add java doc for type `T, O` here
Technically we may still have a connection. Do we need to close the client first before we decrement these? (ditto for others)
I feel we could actually simplify the test by calling `streamsProducer.kafkaProducer()` every time for the check for the internal producer, instead of keeping a reference here, as the `eosAlphaMockProducer` and `eosAlphaMockProducer` look quite similar.
Yes, I am suggesting that we allow the user to retry after a timeout. The simplest way to do so is to cache the result object so that we do not send another InitProducerId request. Instead, we should just continue waiting on the one that we already sent.
I don't mind diff noise if it makes things better btw (even slightly)
Maybe we can still improve the little helper. For example: ```java short readUnsignedIntAsShort(Readable input, String entity) { int val; try { val = input.readUnsignedVarint(); } catch (Exception e) { throw new MetadataParseException("Error while reading " + entity, e); } if (val > Short.MAX_VALUE) { throw new MetadataParseException("Value for " + entity + " was too large."); } return (short) val; } ```
Though now I look at the message for `UINT16` I see it would be consistent with that. Still I think because there are two types involved here, the Java type and the network type, including both is clearest.
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
As above: need to keep default value.
Should this be `error.message()` like a few lines above? Same question for other cases where we are still using `error`.
It would be good to elaborate on why we need to do this as it's not obvious by just reading the code.
nit: Could we move `new DeleteTopicsRequestData.DeleteTopicState().setName(topic1)` to a new line in order to align it with the following `new DeleteTopicsRequestData`? There are few other cases like this.
That is right, thanks @omkreddy .
Could you please already open the follow-up PR with scaffolding and link it here? I think otherwise we risk to forget about it.
Nitpick: We don't need to explicitly check for `other == null` -- `instanceof` (which is required for the casting logic anyways) will return false if its first argument is null.
This warning seems to miss the most likely scenario, that the user just passed the arguments in the wrong order.
How much effort would it be to have a test case for this? We have a few LeaveGroup tests in `ConsumerCoordinatorTest`.
nit: use `{}` instead of string concat for `retries`
Can you please explain why it's better to warn than to fail-fast in this case? Just want to make sure I understand the reasoning for the choice.
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
I think nicer to just `return requests.first()` here
nit: I think it's better to just print the e.message in a single line.
just `name` should be fine
My bad. My suggestion inserted a typo. At least I saw it before I start the build. ```suggestion return new HashMap<>(connectorConfigCallback.get(herderRequestTimeoutMs, TimeUnit.MILLISECONDS)); ```
Strictly speaking, this shouldn't be necessary as `SCHEMA_TYPE_CLASSES` should have a `Schema` instance for all `Schema.Type` literals. And with `SchemaBuilder` a connector or converter cannot create a schema instance with a null `Schema.Type`. However, it is possible to construct a `ConnectSchema` instance with a null `Type` reference (like what `FakeSchema` essentially does in the existing test), which of course without this change would result in this method returning a null list. So +1 for this line change since it simplifies the error handling in the calling code.
nit: we can use `map#compute` to replace getOrDefault + put.
nit: typo in description
Good find! > However, gradle does not allow the usage of Base64 since it "could not be found" according to the compiler anyways. How did you try to use it? Everything from the standard library should be available... I would prefer to use Base64 if we can. If not possible, we can still fall back to using String, but I would really like to avoid it if we can.
I'm assuming this is just extracting the inlined function and hence skipped and did not compare line by line :)
I think it would be more straightforward to have two separate test cases which call `doTestConversion` with a boolean parameter to indicate whether overflow should be tested.
Okay, could we have two signatures then? ``` Collection<T> XXTasks(); Collection<TaskId> XXTaskIds(); ```
I'm not sure returning `true` is valid. We don't actually know if all the threads have shutdown. Though, i'm not entirely sure what to do about it. Perhaps we need to extract the shutdown Thread as a field and then we can check if it is still running. If it isn't running then we can return true, otherwise we should try and join on the thread with the provided timeout
Space was missing before the parenthesis, and "if" should be added to the sentence. ```suggestion "each record in a series of consecutive records will be sent to a different partition (no matter the if 'key' is provided or not)," + ```
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
Good point, I think we should add `this.nano += TimeUnit.NANOSECONDS.convert(autoTickMs, TimeUnit.MILLISECONDS)` in `nanoseconds()` as well.
nit: I'm sure these fit in a line shorter than the one below
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
you don't need this. Junit gives you a new instance of the test class for every test method
We can use `TestUtils.assertFutureThrows()` here too
We can remove `requireNonNull` here, because `getter.keySerde()` would already throw a `ConfigException` if the default serde is null.
Remove about two lines code and something like below? copyMapEntries(nextConfigs, configs, SslConfigs.NON_RECONFIGURABLE_CONFIGS); copyMapEntries(nextConfigs, configs, SslConfigs.RECONFIGURABLE_CONFIGS); copyMapEntries(nextConfigs, configs, SecurityConfig. SECURITY_PROVIDERS_CONFIG)
typo: byteArrray -> byteArray
I don't think we need this `null` check either.
That's not what I see when I look at the code. The following code populates `completedSends`: ``` java if (channel.ready() && key.isWritable()) { Send send = channel.write(); if (send != null) { this.completedSends.add(send); this.sensors.recordBytesSent(channel.id(), send.size()); } } ``` `channel.write` looks like: ``` java public Send write() throws IOException { Send result = null; if (send != null && send(send)) { result = send; send = null; } return result; } ``` And `send` looks like: ``` java private boolean send(Send send) throws IOException { send.writeTo(transportLayer); if (send.completed()) transportLayer.removeInterestOps(SelectionKey.OP_WRITE); return send.completed(); } ``` Why do you think we are not waiting for the request to go down the OS layer? I don't see any unflushed JVM level cache/buffer in the code above.
yes, it seems to be not what this test is checking on. I think we can drop it here.
Minor but I'm not sure if we'd prefer the builder's toString or the underlying request struct's toString as was formerly the case.
I think this could be `String` or `Class` type. Not sure. For any case, we should test for both cases.
By the way, `kafka.metrics.reporters` is a horrible config key name because it suggests that it is configuring the "Kafka metrics" system (which, as you know, is separate and different from the Yammer metrics system), but actually no, it configures Yammer. :disappointed:
This implementation of `equals` will return false for timestamps of the same value; maybe this could be something like `return Long.compare(timestamp, otherTimestamp) == 0`
ditto on removing before/after.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Would it be better to provide default value, probably 1, for this configuration? Otherwise this patch will break existing tests/tools that use `ProducerPerformance`.
Actually, I'm not sure we necessarily even _need_ to call on the `FallbackPriorTaskAssignor`, we just need to schedule the followup and remove the affected tasks from the assignment
Did @guozhangwang suggest to rename this DF to `2.2`? I actually think the descriptive name might be better. It seems like it'll be less work in the long run to remember what exactly is different about the different CFs.
The code is correct, but confusing to read for me as a human...
How about defining two helper methods, one for each cases? * `private void maybeRewrapAndThrow(ExecutionException exception)`; and * `private void maybeRewrapAndThrow(CompletionException exception)`
Should we just assertTrue result.readyNodes.size() > 0? Ditto in line 348.
Yes, and more generally, my understanding is that we also need to consider if the consumer may return a "super-list" of the expected values, for example (still assume the above expected `{A, 1}, {A, 2}`): * `{A, 1}, {A, 2}`: this should be correct. * `{A, 1}, {A, 1.5}, {A, 2}`: this should be correct. * `{A, 1}, {A, 2}, {A, 2.5}`: this should be wrong, since `{A, 2}` should be the last for the key. * `{A, 2}, {A, 1}`: this should be wrong. * `{A, 2}, {A, 2.5}, {A, 1}`: this should be wrong.
Ok, it looks better now. Let's leave it this way, with two lines.
I see your point now, this is exactly the messy code that we were trying to fix. I've looked at the source code again, and I think we can actually not remove the state at all since the same object will be add to the state stores via `store.init` immediately within the same function call. So I think we can actually do: ``` if (storeToBeReinitialized.contains(A)) { A.close; delete state dir; A.init(); } ``` In that loop.
One thing I would suggest we do is to create an intermediate struct to store all the parameters, in case later we need to add more fields for sensor creation.
This isn't used in this class. Probably should move to `AssignedStreamsTasks`
nit: align parameters.
Could you please add some line breaks? This and some of the other verifications are too long.
@bbejeck That is a good question! Originally I thought it is okay to always calling `hasNext` inside `next()`, as long as we make sure `hasNext` implementation is idempotent, i.e. calling it multiple times before `next()` does not have side effect is sufficient. But by making it idempotent we could have the corner case you mentioned. For example: ``` t0: call `hasNext()` -> store is still open -> call `makeNext` -> `next` field is set. t1: store is closed. t2: call `next()` -> call `hasNext()` again ``` Without this check, at `t3` we would still return the `next` field.
Just realized, that the method does use `synchronized` keyword anyway... it's guarded against this already. Same for `start()`.
It'd be more powerful to do an assertion on the complete set of returned plugins, since that will only require one test run to discover all differences between the expected plugins and the actual ones: ```suggestion Set<Class<?>> excludes = Stream.of(ConnectorPluginsResource.SINK_CONNECTOR_EXCLUDES, ConnectorPluginsResource.SOURCE_CONNECTOR_EXCLUDES) .flatMap(Collection::stream) .collect(Collectors.toSet()); Set<ConnectorPluginInfo> expectedConnectorPlugins = Stream.of(SINK_CONNECTOR_PLUGINS, SOURCE_CONNECTOR_PLUGINS) .flatMap(Collection::stream) .filter(p -> !excludes.contains(p.pluginClass())) .map(ConnectorPluginsResourceTest::newInfo) .collect(Collectors.toSet()); Set<ConnectorPluginInfo> actualConnectorPlugins = new HashSet<>(connectorPluginsResource.listConnectorPlugins(true)); assertEquals(expectedConnectorPlugins, actualConnectorPlugins); verify(herder, atLeastOnce()).plugins(); ``` (This assumes we split out `CONNECTOR_EXCLUDES`, but the same general strategy should apply even if we don't).
The message doesn't seem to match the condition above.
Do you know why we have all these ReadOnlyWindowStore methods also declared here in WindowStore? We don't need reverse variations of these I guess? 
Space was missing before the parenthesis, and "if" should be added to the sentence. ```suggestion "each record in a series of consecutive records will be sent to a different partition (no matter the if 'key' is provided or not)," + ```
If it doesn't add too much to the runtime, I think it would be good to include some more cases like you suggest.
nit: add `{ }` to block
We can save this for a follow-up, but it doesn't seem too difficult to allow the consumer to seek to the offsets that were successfully fetched. I think we just need to change the type to something like `Map<TopicPartition, Either<Errors, OffsetAndMetadata>>`.
state.isRunning() is as below ``` public boolean isRunning() { return equals(RUNNING) || equals(STARTING) || equals(PARTITIONS_REVOKED) || equals(PARTITIONS_ASSIGNED); } ``` if its not too much work, we can rename to something like `state.isAlive()` , that captures what we want to check .. your call.
We can reuse `streams`.
We can define two static variables of `NoOpStateRestoreListener` and `NoOpStateRestoreCallback` instead of creating a new instance multiple times.
Relatedly, I think there might be some sort of checks in unit tests in maybe the producer or consumer that validate metrics are unregistered, might be able to use a similar approach here.
suggest returning an `Optional<SustainedConnection` rather than `null` when none can be found - it helps avoid NPEs
What if that never happens? It's better to always have a timeout in tests.
Can you split this out into 2 tests please?. One for each method that is being tested. Thanks
Any reason why this block of code isn't in the `if(tasksByTopicGroup.get(topicGroupId) != null)` block? After the `for(..)`? If it is not null then it is going to have some tasks, right? So numPartitions will always be > -1
This part and the line 525-529 below can be extracted out of if condition.
an -> a
`earlier or later` -> `before or after` (to avoid confusion with the term "late data")
Well, we wouldn't want to just remove that clause -- in the case of `SerializationException` you want to maintain the `SerializationException`, but if there's some other `RuntimeException` (which there can easily be for serializers that aren't aggressively catching exceptions and converting to `SerializationException`) then you still need to convert it to a basic `KafkaException`. I think you could do this: ``` try { // parse record } catch (SerializationException e) { throw new SerializationExceptionException("Error deserializing key/value for partition " + partition + " at offset " + logEntry.offset(), e); } catch (RuntimeException e) { throw new KafkaException("Error deserializing key/value for partition " + partition + " at offset " + logEntry.offset(), e); } ``` as long as we're confident there aren't any other `KafkaExceptions` we'd want to handle differently (i.e. any other more specific types of `KafkaException` where we'd want to preserve the same type instead of generalizing to `KafkaException`).
@guozhangwang if the end offset is less than the checkpointed offset, how is it possible to _not_ throw a `TaskCorruptedException`? I thought that was thrown after checking this exact condition? edit: what I mean is, do we think this is a possible state? If so, we should explicitly check for it and throw `TaskCorrupted` if detected. (If not, it's an illegal state and thus the check here is appropriate)
Yes, does not hurt to leave it. Just for sure.
Nit: you can also add `final` here: `for (final Map.Entry.....)`
`replicaing` -> `replicating`
Don't we need to set version 0.10.1 for those initially? Otherwise, they will have trunk version
Hmm. I feel the `final` would be worth capitalizing the var name.
Why do we need this? Seems to be a wrapper for `NetworkClient`, but does not add too much value IMHO.
nit: Please fix code style.
Is `|| memberId.equals(Generation.NO_GENERATION.memberId)` really necessary? My understanding is that a reset `memberId` implies that `generationId` was also reset. I guess that it does not hurt to have it.
Calling `super(...)` makes `test_context` a field in the test object. I.e. no need for `self.context = test_context`
an -> a
I wonder if the id check is sufficient. If a broker was reprovisioned with a new IP address, for example, we'd probably want to update this collection with the new Node.
@alexjg The code is actually looping in this line, before the `waitForCondition` call is actually triggered, I think that is why you are seeing the indefinite hanging.
It's worth including the broker here as it was originally intended.
is a topic node
Below we break into `brokerResources` and `unifiedRequestResources` and send two requests; we should check them and skip if possible respectively.
Is this ok to do for both reasons this would be called? Do we actually want to request a commit when in the case of the connector throwing a RetriableException? That'll result in the connector being forced to flush all its data.
For a nice example where caps make sense see right below, where two sentences are included.
+1 to this
Should we call close in the `finally` block? Here and elsewhere
By the way, `kafka.metrics.reporters` is a horrible config key name because it suggests that it is configuring the "Kafka metrics" system (which, as you know, is separate and different from the Yammer metrics system), but actually no, it configures Yammer. :disappointed:
@dguy @hachikuji if it sounds good to you I can go ahead and make this change while merging.
We don't use null entries in JSON, because it gets too confusing. You should check against empty string here.
Actually `this.name` is still the processor node name, not the KTable name as mentioned in the JIRA. However, after thinking it a bit more, I feel there are a few corner cases when using the state store name may be cumbersome: even after KAFKA-3870 and KAFKA-3911 is merged, still not all KTables will be backed by a state store (for example, a KTable generated from another KTable.filter, which is just a view of the other table). And if we call `filter` on both of these KTables, they will actually share the same state store names, which are confusing. So just using the processor node name, admittedly are not very intuitive for users, may be the least bad solution here.
Do we want a `ConnectException` here instead? Not sure.
I think, it is better to keep the default initial capacity of an `ArrayList`. Otherwise, the first time a stream thread is added, we immediately run into a memory allocation. Since we do not know how many stream thread we might expect, let's use the default. We could also consider using a `LinkedList` since we never access by index in production code.
You are right. NVM.
Hmm, we want to check inter.broker.protocol.version >= 0.10.0. This is easier if we can use the case object in core. Since we only need to use the old protocol when SaslClientAuthethicator is used at the broker side. Perhaps, we can check inter.broker.protocol.version in the broker code and pass a flag into inter.broker.protocol.version. The places where we use SaslClientAuthethicator are in ReplicaFetcherThread, ControllerChannelManager, and KafkaServer (for controlled shutdown). When used in clients (producer/consumer), SaslClientAuthethicator will always use the new protocol.
This dates before this PR, but while reviewing it I realized that line 898 in prepareTopic: ``` topic.setNumberOfPartitions(numPartitions.get()); ``` is not necessary since the `numPartitions` is read from the topic.
nit: add a space after "multiple". i.e. `despite being claimed by multiple[ ]`
Hmmm... Seems to be in issue... The actual final return type is `KTable<Window<K>, V>` and thus is window-type agnostic. So we already have such a "container". -- However, `windowedBy(SlidingWindow)` returns a `TimeWindowedKStream`... Return types are not easy to change... And I don't think we can just switch from `TimeWindow` to `SlidingWindow` as concrete type either for the sliding window case... Maybe we are stuck and cannot fix the bug without a breaking change? For this case, we would indeed need to carry on with the KIP (but we could only do it in 4.0...), but I am wondering if it's worth fixing given the impact? Also: we have a few issues with the current DSL that we cannot fix easily (eg KIP-300). Thus, a long term solution could be, to leave the current API as-is, and built a new DSL in parallel (we did this in the past when we introduced `StreamsBuilder`). This way, we can change the API in any way, but it would be a long-term solution only. It might also help with regard to the new PAPI that uses `Record` instead of `<K,V>` type, and that is not easily adopted for `transform()` (and siblings). We could change the whole DSL to `Record` (ie, `KStream<Record<K,V>` -- or course we don't need `Record` in the generic type -- it's just for illustrative purpose). It would also cover the "add headers" KIP, fix KIP-300, we could introduce a `PartitionedKStream` (cf current KIP-759 discussion) and a few other minor issue (like rename `KGroupedStream` to `GroupedKStream`) all at once... And we could cleanup the topology optimization step and operator naming rules (which are a big mess to understand which `Named` object overwrites others...) -- We can also get rid of the wrappers for `KeyValueStore` to `TimestampedKeyValueStore` and change the interface from `Materialized<XxxStore>` to `Materialized<TimestampXxxStore`) -- In the past it was never worth to start a new DSL, but it seem we collected enough individual cases to maybe justify this investment now? The only thing that we should consider is our investment into "versioned state stores / version KTables". If we build a new DSL it should be compatible to it -- if we cannot guarantee it, we might want to wait until we understand what API we need to versioned KTables in the DSL and make the cut afterwards? \cc @ableegoldman @guozhangwang @vvcephei @bbejeck @cadonna (also @inponomarev @jeqo @vcrfxia)
```suggestion if (attempt < maxAttempts) { Utils.sleep(retryBackoffMs); } ```
This logic seems a bit complex to me, and also if we return at line 229 `restoreBatchCompleted` is not called as well. Is this correct? How about: ``` restoreRecords = new list.. nextPosition = -1; for (...) { if (restorer.hasCompleted) { nextPosition = record.offset(); break; } else { restoreRecords.add(...); } } if (nextPosition == -1) nextPosition = consumer.position(restorer.partition()); if (!restoreRecords.isEmpty()){ restorer.restore(restoreRecords); restorer.restoreBatchCompleted(currentPosition, records.size()); } return nextPosition; ```
`innerDeserializer` could be null; we should handle to case to avoid a NPE calling `getClass()`
If we swallow the exception here, and the test always throws an IO exception, we will never notice. I guess it would be better to use `fail()` with a message.
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
im not *100%* sure, but i think you want this to also hit the controller. i hit the controller in my personal client, and @cmccabe is doing it here https://github.com/apache/kafka/pull/2472/files#diff-7378a806dbf302c1e7a9098c4780d2a8R283
Is the current implementation vulnerable to the following race condition? 1. thread1 grabs `CHANNELS` lock, get the channel object from the map; and then exists the `CHANNELS` lock; 2. thread2 grabs the lock, release the lock on it, close the channel, remove from the map. 3. thread1 now calls `channel.tryLock`, which throws `ClosedChannelException`.
We probably shouldn't change this default to true -- we should override it in the specific test we need by calling `self.mark_for_collect(consumer, 'verifiable_consumer_stdout')` where `consumer` is the `VerifiableConsumer` instance. stdout for verifiable consumer can result in _huge_ log files, so collecting them by default will result in very large archived data for some tests.
You could just do `selector.poll(100)` instead of `poll(0) + sleep(100)`. `poll()` returns when an operation is ready, so we are not waiting unnecessarily.
nit: seems you can use `new ArrayList<>`
Should be final
Could you elaborate why we check commitNeeded for task00 and task01, while check for commitPrepared for task02 and task10 here? I'm needing some clarification here.
Actually I was really just asking for people's opinions :) the cons are that these classes will be in different packages which may looks a bit weird.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
@rajinisivaram Thanks for the detailed explanation. Yeah, I was basically wondering if topic expiration was a "good enough" fix for all of these cases. You may have some unnecessary logging until a deleted topic is expired (for example), but it seems like it wouldn't be too bad since the expiration timeout is 5 minutes, which also matches the default metadata refresh interval. Since we're not attempting to fix the problem of log spam while a message for a deleted topic is queued (which seems like the most likely source of excessive metadata error logging to me), do you think the early removal still makes a big difference in practice? If so, then it may be worth keeping.
The `CachingKeyValueStore` doesn't throw an NPE here, rather `org.apache.kafka.common.utils.Bytes.LexicographicByteArrayComparator.compare` does. We probably should add `Objects.requireNonNull(...)` to `CachingKeyValueStore#put(..)` etc
nit: add `{ }` -- we use curly braces for all blocks nit: remove double space after `==`
When you make `initializeSnapshotWithHeader` private, you may need to slightly change this implementation. E.g.: ```java return supplier.get().map(snapshot -> { RecordsSnapshotWriter<T> writer = new RecordsSnapshotWriter<>( snapshot, maxBatchSize, memoryPool, snapshotTime, lastContainedLogTimestamp, CompressionType.NONE, serde); writer.initializeSnapshotWithHeader(); return writer; }); ```
I'd suggest keeping the format slightly closer to what we had before. Specifically: `Task threw an uncaught and unrecoverable exception. Task is being killed and will not recover until manually restarted`
super nit: I know this pre-existed, but IMHO line 77 a little tough to read what about ``` innerStateSerde = getStateSerdes(context.applicationId(), bytesStore.name()); .... private StateSerdes<Bytes, byte[]> getInnerStateSerdes(String appId, String storeName) { return WindowStoreUtils.getInnerStateSerde(ProcessorStateManager.storeChangelogTopic(appId, storeName)); }
original was better
maybe: `inputKeySerde` and `inputValSerde`
Nit: "For instance, the transactional APIs require brokers with version 0.11.0 or newer."
It may also be useful to have a test that checks that IBM Kerberos classes are available if `Java.isIBMJdk` is true and `com.sun` Kerberos classes are available if false. In particular, you could check the classes `com.ibm.security.krb5.internal.Config` and `sun.security.krb5.Config` which are loaded in `SaslChannelBuilder`.
Should we preserve the error message? Otherwise the user can't actually tell why this happened, they'll see the same error message for both stale config and forwarding errors. It's pretty important to expose enough info to tell what's going on because in cluster mode the user making the request may not have easy access to the worker logs.
Why do we return `Optional` here? Doesn't makes sense just by itself, unless some bigger picture requires it.
Hmm, I just noticed this... It applies to the other test, too. I can see some value in asserting that `range(null, null)` returns the same thing as `all()`, but I wonder if it would be better to validate that they both return the _right_ thing. It's just the fact that the underlying implementation delegates `all()` to `range(null, null)` that's making me think of it.
Since this only returns tasks whose previous client was caught up, I think we can simplify the first half of `assignTasksWithCaughtUpClients` as just ``` tasksToPreviousClients.forEach((t, c) -> assignment.computeIfPresent(c, (k, v) -> { v.add(t); return v;})); unassignedTasksWithCaughtUpClients = new ArrayList<>(tasksToCaughtUpClients.keySet()); unassignedTasksWithCaughtUpClients.removeAll(tasksToPreviousClients.keySet()); ```
Nitpick: `maxWaitMs` would be a better match for Kafka's naming convention.
nit: formatting: (we should also get the exception an verify the error message) ``` final TopologyException exception = assertThrows( TopologyException.class, () -> new StreamTask( ... ) ); assertThat(exception.getMessage(), equalTo("...")); ```
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
Not for this patch, but we should do a KIP to add support for batch topic creation.
Thanks for the catch!
Maybe we should simply pass the `ProducerRecord` in the constructor? We could then also just use the `ProducerRecord.toString` in the error so that we don't have similar issues in the future.
prop: make the value a `SortedSet` so we can just insert clients as we build the map and use a custom comparator to automatically sort the clients based on lag
OK, makes sense. Didn't know about policy of internal checks. Would be good to have it written down somewhere.
nit: instead of `new HashSet<>(Collections.singletonList(tp0))`, you can use `Collections.singleton(tp0)`
With this approach, it seems we could drop this case? There is also the insertion of the null for the UNSUPPORTED_FOR_MESSAGE_FORMAT case in `handleListOffsetResponse` that we probably can drop.
Ah, my bad. I think the variable I had in mind is actually called `Double.BYTES`. Not 100% sure it's defined for all possible primitive types, but I would hope so
Have you thought about rearranging the parameters so that the operation is last? It's the only parameter that might be a lambda, and having it last would be more readable.
@rajinisivaram makes sense. I was thinking if we can break the JAAS config file and made them into client config properties. But just passing JAAS config file will make it easier and extensible.
Also, 5ms seems a bit extreme. Maybe this could be 20ms or so and we could use the minimum of this and the configured retry backoff so that users can adjust it lower if they need to.
Is there a reason why this is passing in `time.milliseconds` while the others don't? There is some scope to use a common time value in all of these records to avoid multiple calls to `time.milliseconds()`.
```suggestion * ReadOnlyWindowStore<K, ValueAndTimestamp<VR>> localWindowStore = streams.store(queryableStoreName, QueryableStoreTypes.<K, ValueAndTimestamp<VR>>timestampedWindowStore()); ```
This syntax is a bit hard to follow with the conditional at the end. Can you rewrite it to something like: ```python self.jmx_tool = None if jmx_object_names is not None: self.jmx_tool = ... ``` (and also check the attributes as mentioned above)
I think we can simplify these functions. Something like this: ```java private static byte readByte(ByteBuffer buffer, DataInput input, IntRef bytesRemaining) throws IOException { if (buffer.remaining() < 1) readMore(buffer, input, bytesRemaining); return buffer.get(); } private static long readVarLong(ByteBuffer buffer, DataInput input, IntRef bytesRemaining) throws IOException { if (buffer.remaining() < 10 && bytesRemaining.value > 0) readMore(buffer, input, bytesRemaining); return ByteUtils.readVarlong(buffer); } private static int readVarInt(ByteBuffer buffer, DataInput input, IntRef bytesRemaining) throws IOException { if (buffer.remaining() < 10 && bytesRemaining.value > 0) readMore(buffer, input, bytesRemaining); return ByteUtils.readVarint(buffer); } ``` I think we shouldn't need more than one call to `readMore`.
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
nit: remove empty line
This would require a separate KStreamVoidTransformProcessor, but I feel it worth the internal cost for simpler public APIs.
Can initialize to `new HashMap<>()` here as is done with `invalidExtensions` below.
I think it'd be useful to verify the behavior of casting all of the logical types to strings, just so that we verify the formats (e.g., timestamps, times, and dates should use the ISO 8601 representation) and have some regression tests for the future to help ensure we maintain backward compatibility.
Was there a `stop_node` method here before? It's a good idea to have both `stop_node` and `clean_node` defined. Or, if you expect the process to actually be gone by the time we hit the "stop" portion of the service lifecycle (`stop_node` is the "graceful shutdown" option), it's helpful to do a check that the process is actually gone (i.e. check that the actual state matches our expectations of what the state should be) and at least log a warning if the process is still running
In `StreamsConfig` we do populate the map from consumer / producer's default values first then use user specified values to overwrite, so it should be safe to `config.getInt` where `config` is of type `StreamsConfig`.
We can drop the parenthesis here. Same below
This whole logic could be simplified as: ``` private void verifyExceptionalState(ThrowingRunnable action) { assertThrows(TaskMigratedException.class, action); // This task should be closed as a zombie with all the other tasks during onPartitionsLost assertThat(assignedTasks.runningTaskIds(), equalTo(singleTaskId)); EasyMock.verify(t1); } ``` so that new test just needs to put in the intended action. Here `singleTaskId` is a class level parameter I defined to replace the singleton list, which is not highly required.
Could combine these into a single `testCycleCollection()` method if you put a `null` value in the list (e.g. `"A", null, "C"`) and for every one of the 4 positions (0-2 and cycling back to 0) you also check the `peek()` value. I think it would be clearer compared to what you have currently since the last 2 methods you have now are a bit haphazard.
Nit: maybe `("Topic: " + topic)`
nit: double space
Instead of pulling the value out with a regex, what do you think of `streamsString.contains("appId")`. Although what you have works as well.
Sounds fine to me.
nit: could be useful to log the type of exception in the assertion message.
If stop throws we won't count down the latch. No harm will result except there will be an erroneous log messages about exceeding the stop timeout.
`should be the same` -> `should be 1000` Also let's swap the arguments as the expected value should come first: ``` assertEquals("1000", backupConfig, ... ```
The `enable.idempotence` will be true by default in 3.0, so we should perhaps have the "up to 5" thing first.
@cnZach Looks like the intention was to print out the exception with stack trace? You would want to use: ``` public void warn(String msg, Throwable t); ```
nit: add a size? There are a few cases in here where we could do this.
You are right. Checking ```Error reading field 'field2'``` should be enough for this test case.
SGTM. We can keep it as is then.
rewrite test as above using `assertThrows()`.
Do we need to wrap with the LinkedHashMap? Could we just do `Collections.unmodifiableMap(metrics.metrics());`
There is only 1 `GlobalStreamThread`, so this field could be `GlobalStreamThread.State`, i.e., we don't need a map
Up to you I guess. No need to expand the scope even further for a tiny nit.
AK convention is to not use `set` setters or `get` getters.
This might not be safe. If we use the "zero-copy" flag as suggested below, we can just duplicate the ByteBuffer instead.
Let's move this helper into `ListOffsetRequest`
We should use `aasertThrows` and verify the error message similar to the `TransformerSupplier` test
nit: move to line above.
The deserialized is actually different since we need to differentiate between `timeWindowed` and `sessionWindowed`. It is partially because our signatures for time windows and session windows are not the same.
I guess that's possible, but _if_ the join result is large, we could run into memory issue buffering all join results? Also, sorting could be expensive and we can actually avoid it, and still guarantee that results are emitted in timestamp order: - we know that left/outer join result would have the smallest timestamps and thus we can emit those first (given that we use timestamped-sorted store anyway, we just scan the store from old to new and emit - for the inner join result, we get the output sorted by timestamp, too, because for the join key, data is sorted in timestamp order in the store, too
We could detect if the processorTopology contains only `StaticTopicNameExtractors` and still throw in that case if the topic name isn't in the topology.
Why could we not fix this? The underlying issue seems to be the state transitions of `StreamThread` -- it allows to go from `CREATED -> RUNNING` -- if we change this, and we can only go to `CREATED -> PARTITION REVOKED` we should be able to tackle this issue? (Maybe a different PR to do this though.)
Hmm, if we performs an unclean leader election, the only replica in ISR should just be the new leader since the data in existing ISR is not guaranteed to match with the new leader.
Maybe I am wrong, but shouldn't this be moved inside the `while` loop, so it is initialized every time a new assignment is selected? Because, now I think only the first consumer will be challenged against this previous partitions.
Cool, I was kind of hoping you would put this in a separate integration test class
Okay, could we have two signatures then? ``` Collection<T> XXTasks(); Collection<TaskId> XXTaskIds(); ```
the field "ERROR_CODE" is never used.
Minor: maybe move this to initialization? ``` java int newTaskCount = configs.size(); ```
nit: `This` -> `{@code MockProcessorContext}` "this" , "here" etc is bad style IMHO
There's now a `Utils.mkProperties` method you can use (in conjunction with `mkMap`) to set these at the declaration site instead of setting them (redundantly) before every test. Then you won't need the `@Before` at all.
Let's remove the brace changes please.
That's what Bruno originally did, but the original `cleanRemovedTasks` method branched on the `manualUserCall` flag in several places and was pretty difficult to follow (imo). So (also imo) it's cleaner to split it up into two methods that make it clear what the expected behavior is in each case. Just my 2 cents
I think this is the issue you reported in the Jira. The `RaftClient.Listener` should not use `RaftClient.leaderAndEpoch` to determine if it is the leader. It should instead use `RaftClient.Listener.handleLeaderChange`. For this state machine `ReplicatedCounter` we should look at the `claimedEpoch` variable. I am going to create an issue to remove this method. cc @hachikuji
need to update `./gradlew uploadArchivesAll` at line no: 644
We can use `==` to compare enums.
Just to follow the question above, could we directly restrict the range at this caller as: ``` (Math.max(earliestSessionEndTime, currentSegmentBeginTime()), Math.min(latestSessionStartTime, segmentEndTime)) ```
nit: do we still need this function? Could we just reference the `metricLock` object directly? Since it is private my understanding is that it was not intended to be used outside this class.
I think we need to skip all the code in this else block if the partition is no longer assigned.
Is this step necessary given step 1 and 2? The election != Election.PREFERRED case is covered in step 1 and the other case seems covered by step 2.
Seems like we should move this above into the top-level `process` instead of first calling `processInOrder` and then calling `processEarly`. For one thing, since we actually do need to iterate the full range for the early records, we can just call `processEarly` without having to decide between `processInOrder` and `processReverse`
nit: The sentence sounds slightly better if you remove `the`
nit: add `final` (we use `final` whenever possible)
Do we lose anything if we use `Set` instead of `Collection`? Seems like set is the right semantics.
This is also related to the following PR https://github.com/apache/kafka/pull/1015 that uses sentinels in a number of places. It would be nice to be consistent on -1 versus null.
Got it. For future readers the function is `maybeCompleteShutdown`.
consumerThread -> rebalancingConsumerThread
nit: looks like we're missing a space after the comma. It was a problem in the original as well.
I think this should only be done after the store is in a valid state, i.e, after restore. Otherwise there is a chance we can try and query or write to the store before it is ready
I am not sure we want to move all the tasks in a topology? Maybe we can do that by task or sub topology? maybe topology is best but I will need to think about it a bit
I think the basic idea makes sense and is what I was expecting. It might not feel too elegant, but I think a simple approach is best initially. An interesting point to consider is what would happen if an offset fetch is in-flight while a rebalance is in progress. When it returns, the offsets may be stale. I am wondering if it makes sense to fence the response using the group generation. In other words, we record the generation at the time of the request and then verify when we receive the response that it matches the current group generation.
Understood. I think that we should revert this. I think that it makes sense to wait until we complete the migration of the remaining requests. We should have them pretty soon now.
nit: should be `<L extends List<Inner>>` to avoid warning about using a raw type
I hope we can get rid of those conversion in the future :)
Ah, I was suggesting to just replicate the `shouldInstantiateAssignor` and `shouldInstantiateListOfAssignors` tests exactly, but with the `classTypes` being eg `StickyAssignor.class` instead of `StickyAssignor.class.getName()`. For example ``` classNames = Collections.singletonList(StickyAssignor.class); List<ConsumerPartitionAssignor> assignors = getAssignorInstances(classNames, Collections.emptyMap()); assertTrue(assignors.get(0) instanceof StickyAssignor); ```
The parameters should be the other way round (expected is `conns` and actual is the metric value).
I see your point now, this is exactly the messy code that we were trying to fix. I've looked at the source code again, and I think we can actually not remove the state at all since the same object will be add to the state stores via `store.init` immediately within the same function call. So I think we can actually do: ``` if (storeToBeReinitialized.contains(A)) { A.close; delete state dir; A.init(); } ``` In that loop.
Thanks for identifying this issue. Piggybacking on OP_WRITE may not be the best way to fix this though. I was thinking, if connected is true, we can probably just call socketChannel.finishConnect() and register the socket channel with OP_READ, which is what PlaintextTransportLayer.finishConnect() and SslTransportLayer.finishConnect() will do. Then, we don't need to change the logic in poll.
Should be more specific about the type of error being caught -- catching all exceptions should be reserved for very special cases, like protecting the top stack frame of a thread to avoid uncleanly exiting the thread. I suspect that here you specifically want to capture `CalledProcessError`, which indicates an issue running the command on the remote host and/or `ValueError`.
nit: those lines can be rewritten (simplified?) as: `return (topic != null) ? topic: metrics.sensor(name1);`
Can we put the worker ID into the prefix here? We may be running multiple workers at once.
Should this be `num_lines=3` (cf. L116 and L126)
Like said earlier, I think we could just return `return new StreamsResetter().run(parameters, cleanUpConfig) == 0`
`validateStoreOpen()` can be outside of lock block.
nit: if you want a new paragraph you need to add `<p>`
Ok. then LGTM
> this logic Seems only needed because we have the check in 309 (?) No, I don't think so. It should be for line 279: ```java // to handle the case that when there are still unassignedPartition left, but no more members to be assigned. if (unfilledMembersWithUnderMinQuotaPartitions.isEmpty() && unfilledMembersWithExactlyMinQuotaPartitions.isEmpty()) { throw new IllegalStateException("No more unfilled consumers to be assigned."); ``` In line 309, it is just an early error detect and log for it. Not related to `potentiallyUnfilledMembersAtMinQuota` (or now `unfilledMembersWithExactlyMinQuotaPartitions` members)
You might consider using `OptionalDouble`.
We can use `List<Class<? extends Connector>` to avoid the warning
That's a good point.
@xiaodongdu, I was not suggesting getting rid of the field. It's fine to have a new field, but we should call the field `kafkaClusterId` rather than `clusterId` since the latter could be misinterpreted to mean the _Connect_ cluster ID.
Maybe doesn't matter, but seems a little more intuitive to check that the error is not NONE.
@hachikuji is correct. We can't do blocking operations in the admin client service thread. We certainly can't do blocking operations that wait for the service thread itself. This will deadlock. I think it's a good idea to have a coordinator node provider, but we need to build out a little more infrastructure to make it possible. I have a change which should help with that, at https://github.com/apache/kafka/pull/4295
As above: need to keep default value.
super nit: not part of this PR proper, but maybe set `RuntimeException` returned from the `suspendTask()` call to variable then use it in the `assert` statement? Makes things a little easier to understand.
nit: toString not necessary
And nitpick: there should be a space after the comma.
Let's make this protected. ```suggestion protected InternalSinkRecord(ConsumerRecord<byte[], byte[]> originalRecord, String topic, ```
ditto here, should be moved to RocksDBStore#close
Not required. Client will be automatically closes, as we use Java's "try with resource" feature.
Now seeing the example (super helpful) I am wondering if we can/should be more fancy. I think, it's actually three cases: ``` rekeyed = stream1.map(); merged = rekeyed.merged(stream2); merged.groupByKey()... ``` For this case, without optimization, we would insert repartition _after_ merge _before_ groupBy -- this mean, we repartition stream2 for no good reason. Could we repartition _before_ merge? Checking first parent might catch this case? ``` rekeyed = stream1.map(); merged = stream2.merged(rekeyed); // similar to above put change order of childen merged.groupByKey()... ``` This case is similar, but we might not detect if, if we don't check all parent nodes. Thus, we might miss to insert an repartition topic at all in current code? ``` rekeyed1 = stream1.map(); rekeyed2 = stream2.map(); merged = rekeyed1.merged(rekeyed2); merged.groupByKey()... ``` For this case, we should do the repartition _after_ merge -- otherwise, we would create two repartition topics what is not desired (for the case, that `rekeyed1` and `rekeyed2` are not used elsewhere, too). If `rekeyed1` or `rekeyed2` are use like this: ``` rekeyed1 = stream1.map(); rekeyed1.groupByKey() rekeyed2 = stream2.map(); merged = rekeyed1.merged(rekeyed2); merged.groupByKey()... ``` we would still need two repartition topics, because we need content of `stream1` not be mixed with `stream2` in line 2. Also, as `rekeyed1` will be repartitions already before merge(), we don't need to repartition again but `stream2` should be repartition on it's own before merge(), too. Does this make sense? (note, that merge requires that key and value type of both input streams are the same, and thus, we can use same Serdes independent where we insert the repartition topic(s))
In line 58 above, in `recordLatency()`, we need to mention that `If the passed sensor includes throughput metrics (e.g. it is create via the XX function), the throughput metrics will also be recorded as a single occurrence of this event.`
IMHO the `close` method is little easier to follow by putting `if(clean)...{ }` block in a private method, possible name `closeIfClean(clean, task, t)`
To keep this logic same as one in `Call::fail` method, lets set the new time as: > nextAllowedTryMs = now + retryBackoffMs
Although the checkstyle rules currently do not enforce curly brackets in if/else blocks that contain a single statement, because this statement here spans multiple lines, I feel it'd be best to enclose it within `{ }`, even if that's optional.
This seems to always enforce a materialization, but I think we should materialize only if we need to.
We should improve this test by moving this line outside/before `try`
Just one minor point, if we don't have EOS enabled, we could end up pulling duplicates in some tests like the `StreamsUpgradeTest::upgrade_downgrade_brokers`
visibility could be restricted to be package-level (i.e remove keyword `protected`)
nit: braces unneeded
An error is intended to shut down the worker. So we should call `doneFuture#complete` here.
Perhaps clarify to: "by transforming the value of each element in this stream into a new value in the new stream"
We can use the `replace` overload that takes a `char`.
nit: ```suggestion log.warn("Thread " + streamThread.getName() + " did not shutdown in the allotted time"); ```
Shouldn't this be `timeoutMs - (time.milliseconds() - startTimeMs)`? Also, it's not too big of a deal, but the checks for `Long.MAX_VALUE` seem like overkill.
Let's capitalize the log statements for consistency. There are a few of these.
`earlier or later` -> `before or after` (to avoid confusion with the term "late data")
We can remove the extra call in the variable here. ```suggestion CallRetryContext failedCallRetryContext = failedCall.callRetryContext(); ```
IMHO the `close` method is little easier to follow by putting `if(clean)...{ }` block in a private method, possible name `closeIfClean(clean, task, t)`
You could also use `MemoryRecords.EMPTY` here (I think).
@rajinisivaram Thanks for the detailed explanation. Yeah, I was basically wondering if topic expiration was a "good enough" fix for all of these cases. You may have some unnecessary logging until a deleted topic is expired (for example), but it seems like it wouldn't be too bad since the expiration timeout is 5 minutes, which also matches the default metadata refresh interval. Since we're not attempting to fix the problem of log spam while a message for a deleted topic is queued (which seems like the most likely source of excessive metadata error logging to me), do you think the early removal still makes a big difference in practice? If so, then it may be worth keeping.
Ack. By bad.
Nit: why not `failIfNotReadyForSend`? One character longer, but reads a bit better. :)
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
nit: not introduced by this PR, but let's rename it to `otherWindowStore` for naming consistency.
Nits: ```suggestion throw new ConfigException(String.format("Invalid format of header config '%s'. " + "Expected: '[action] [header name]:[header value]'", config)); ```
Still not used
Aha! Thanks. Yeah, I'd be in favor of coding defensively here as well.
When I suggested it, I thought we could do a bit better, maybe something like `(id: 5, www.example.com:9123)`, but maybe that's actually worse.
I'm not sure how significant it is for the timeout to be a multiple of the refresh interval. The scheduling might not ever align anyway since it depends on poll() getting invoked at the right time. I also don't see why a separate mechanism would be needed for a hard-coded value. We're not expecting high granularity, just a way to avoid the cache growing unbounded over time. My concern is that we are technically changing the semantics of `metadata.max.age.ms` for the producer. Before it only controls how long we wait before refreshing metadata; now it also sets an expectation on the frequency of writes to each topic. Admittedly, the change should be transparent to the user, but it feels like an unneeded dependence.
Interesting. It is good to hide this logic from the state machine. Looking at the epoch and not at the LEO is okay because at this point we guarantee that the only records with that epoch are control records (e.g. LeaderChangedMessage). I am wondering if the state machine may want to know this before it can process state machine requests. Maybe this is okay because the brokers/replicas will learn about the new leader through the `Fetch` and `BeginQuorum` protocol and not from the state machine (Kafka Controller) itself. It is possible that the leader will receive Kafka Controller message from replicas/broker before it knows that it is leader. Most likely the Kafka Controller will reject them but the replicas/brokers need to keep retrying. This is specially important for heartbeat messages.
Minor typo "will is"
It seems like this test would be more useful just as an assertion of the default behavior.
Now seeing the example (super helpful) I am wondering if we can/should be more fancy. I think, it's actually three cases: ``` rekeyed = stream1.map(); merged = rekeyed.merged(stream2); merged.groupByKey()... ``` For this case, without optimization, we would insert repartition _after_ merge _before_ groupBy -- this mean, we repartition stream2 for no good reason. Could we repartition _before_ merge? Checking first parent might catch this case? ``` rekeyed = stream1.map(); merged = stream2.merged(rekeyed); // similar to above put change order of childen merged.groupByKey()... ``` This case is similar, but we might not detect if, if we don't check all parent nodes. Thus, we might miss to insert an repartition topic at all in current code? ``` rekeyed1 = stream1.map(); rekeyed2 = stream2.map(); merged = rekeyed1.merged(rekeyed2); merged.groupByKey()... ``` For this case, we should do the repartition _after_ merge -- otherwise, we would create two repartition topics what is not desired (for the case, that `rekeyed1` and `rekeyed2` are not used elsewhere, too). If `rekeyed1` or `rekeyed2` are use like this: ``` rekeyed1 = stream1.map(); rekeyed1.groupByKey() rekeyed2 = stream2.map(); merged = rekeyed1.merged(rekeyed2); merged.groupByKey()... ``` we would still need two repartition topics, because we need content of `stream1` not be mixed with `stream2` in line 2. Also, as `rekeyed1` will be repartitions already before merge(), we don't need to repartition again but `stream2` should be repartition on it's own before merge(), too. Does this make sense? (note, that merge requires that key and value type of both input streams are the same, and thus, we can use same Serdes independent where we insert the repartition topic(s))
nit: `,` (comma) doesn't seem required in the sentence.
IMHO the `close` method is little easier to follow by putting `if(clean)...{ }` block in a private method, possible name `closeIfClean(clean, task, t)`
nit: This block is repeated in many tests. I wonder if we could define an helper for it.
You want the loop to read even when there is no data from the network. So the condition needs to be something along the lines of `if (channel.ready() && (key.isReadable() || channel.hasBytesBuffered()) && !explicitlyMutedChannels.contains(channel) && !hasStagedReceive(channel))`
Nit: add `final`
This wording could be improved: "Batch splitting cannot be used with non-compressed messages, NOR with message format versions v0 and v1"
> Committable offsets here should contain consumed offsets, and punctuation itself should never update those consumed offsets right Yes. > I think we can skip the call if consumedOffsetsAndMetadataPerTask is empty. For non-eos, yes, because for non-eos `commitOffsetsOrTransaction()` would only commit offsets via the consumer (this can be skipped if empty). However, for eos (alpha and beta), we might have a pending transaction that we need to commit on the producer, too.
A better way is to first call `this.mockTime.milliseconds()`, then `this.mockTime.sleep(1000)` then call the `milliseconds` again with the second batch.
I'm ok with the names, but I don't have a strong opinion. We still have time to address between now and the final PR though.
Calling `maybe_start_jmx_tool` after each line that gets read from the producer process doesn't seem quite right. I think we want the behavior to be: - start producer "asynchronously" - start jmx tool asynchronously - wait for producer to finish - process each line of producer output I think it would look something like: ``` cmd = "same_as_before &" # now the cmd is "async" node.account.ssh(cmd) wait_until(producer is alive) self.start_jmx_tool(node) wait_until(producer is finished) for line in node.account.ssh_capture("cat /mnt/producer-performance.log"): # same as the previous for loop ```
It does seem like we could pass the node id to `RequestSend` without much issue.
At this point we have a lot of repeated code with `toRst()`. Would probably make sense to refactor to share the majority of the code for each config's main set of fields.
`late` -> `out-of-order` -- if it's _late_ it would be _after_ the grace period and would be dropped.
nit: add `final`
Understand. That part can be refactored - goal is to reduce unnecessary comparison.
How are dependencies for test plugins handled here? If someone wants to expand these tests to include a test plugin that requires some library that isn't available in the classpath for compilation during these tests, what (if anything) would they have to change in order to make things work? It seems unlikely enough that this would be needed any time soon so proactively making changes to support that seems unwarranted, but it'd probably be useful to at least note that the test plugins here are a little fragile if there's any current limitation on what dependencies they can rely on.
Do we still need `needsJoinPrepare` now? It seems to me that we need to call `onJoinPrepare` whenever `needRejoin` is true.
Yes, we can open a JIRA to do it later.
nit: make the test name more descriptive, like `testFlushCompleteSendOfInflightRecords`
a standby task is never in
`expectedTimestamp` parameter missing (insert before `expectedHeaders` to align with method name.
nit: ```suggestion log.warn("Thread " + streamThread.getName() + " did not shutdown in the allotted time"); ```
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
Thanks for the explanation. A bit subtle as you had said. :)
I think the logic here is not correct: we should still resume the main consumer and assign standby partitions if active tasks are all running; we should only alter the logic of returning flag with both active / standby all running.
nit: log an error and include the `inputRecordTimestamp`
Also discussed offline with Becket, but this test can probably be simplified significantly
nit: I think there's no need to reference the JIRA. The explanation seems clear enough without any additional context.
I don't think this will ever be true, i.e., in `start` we set the state to `RUNNING` and then we call `globalStreamThread.start()`. So the listener will be invoked with `RUNNING` while the instance is already in the `RUNNING` state. The `StreamThread`s aren't started until after `globalStreamThread.start()` returns.
add check for restore-consumer and admitclient
Could you add a flag after ```producer.flush()```? We should make sure ```producer.flush()``` fails.
Throwing `IllegalStateException` is served as the purpose that "this should never happen, and if it does it is a bug and hence it is ok to fail and stop the world".
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
Also, are we fine with the config logging being bumped up to `info` (which is what `logAll` does) vs `debug` (which is what it was here).
Why is `false` (inexact decimals) the default for the no-arg constructor? If this is an attempt to maintain backward compatibility, we should consider whether this bug, when fixed, compatible. Seems like it would be, since having the deserializer use the trailing zeros would be fine/better than not using them.
Consider renaming to `safeToDropTombstones`: ```suggestion boolean safeToDropTombstones() { ```
nit: fix indention (same below in other constructor)
Could you test `maybeRecordE2ELatency()` through `process()` and `forward()`? Although you test `maybeRecordE2ELatency()`, you do not test if the recording is done during processing, but that is the crucial thing, IMO.
Make all params `final`
Nit: should the method be named `testOptionsDoesNotIncludeWadlOutput()` instead? The point of this PR is to prevent including WADL in the OPTIONS output, but the existing method name makes it seem like we're testing the content of the WADL output.
I think there's an edge case where `timeoutMs` is positive but small enough that the condition on line 77 is not met but the while loop on line 85 is not satisfied because the end time has already passed. In this edge case, we might not call the callable function (even once). One option is to change the while loop to be a do-while loop so that we always go through one loop. Another option is to compute the remaining time before line 77 and not update it before the while loop. Either would work, but one of the options may require fewer duplicated lines.
Seems this duplicates `L733`. Might be good to extract into a small helper method.
Thinking a bit more. This is a bit tricky since we probably can't just continue here. For channels like SSL, we need to do the handshake after the socket is connected. Currently, the handshake will be triggered immediately after the connection is established through channel.prepare() and this has to be done in the same poll(). Otherwise, the selector may not be able to select the key again for initiating the SSL handshake. This applies to all those immediately connected keys not coming from the selector. So, to get around this issue. We can probably create a new KeyIterator that iterates both keys in this.nioSelector.selectedKeys() and those in connectableChannels. The iterator can return a <key, alreadyConnected> tuple. For keys coming from selectedKeys(), alreadyConnected will be false. For keys from connectableChannels, alreadyConnected will be true. Then, we just need to change line 291 to check if (key.isConnectable()) || alreadyConnected) and leave the rest of the code as it is. This way, keys in connectableChannels will be handled in the same as way as those from selectedKeys().
nit: no need newline of 104 below.
We can use `computeIfAbsent(...)` to eliminate the prior newly-added line: ```suggestion allAddedPlugins.computeIfAbsent(pluginClassName, n -> new ArrayList<>()).add(plugin); ```
Should we call close in the `finally` block? Here and elsewhere
same question around log level as above
Yeah, I think that there's a larger "lookback" feature that I wasn't aware of when I implemented Suppress. It seems like it needs a first-class solution, and probably just mixing in this interface would just surface a different exception at run time. I'm not sure without spending some time to look at it, but it seems we need to enable "old values" upstream and then add the ability to store the old values as well. Actually, this may already be partially supported, with the FullChangeSerde. The other missing API is the valuegetter. We might need to actually implement that, acting as a cache (look in the buffer first, then look upstream), or, since we know the buffer _always_ reflects the upstream state anyway, we can just directly look upstream.
This data construction seems better to be put in the `AlterConfigsResponse` constructor.
Let's keep this as a private method.
nit: maybe we can pull out a variable for `metadata.topic()` since there are 10 or so uses
Ah, yeah, you'd need to do something more like what actually happens in the actual KafkaConsumer/`getAssignorInstances` code. eg ``` @Test @SuppressWarnings("unchecked") public void shouldInstantiateAssignorClass() { Object classTypes = Collections.singletonList(StickyAssignor.class); List<ConsumerPartitionAssignor> assignors = getAssignorInstances((List<String>) classTypes, Collections.emptyMap()); assertTrue(assignors.get(0) instanceof StickyAssignor); } ```
Ok, sorry, I'm thinking more about this now with review, and I guess this will always just be either 0 or 1 batch of messages since the processing -> put() will be synchronous for each batch collected from the consumer. So I guess maybe the committed - consumed makes sense as it is the total still thought to be somewhere in flight (or more accurately, not yet known to be guaranteed delivered into the destination) does actually work. I think, as you mentioned, lag is just confusing there because you could be completely done processing, the data could be in the destination, and we may just not yet have gotten to a periodic commit yet. I mainly would worry about that since connect defaults don't commit all that frequently and it is hard to say what it means if, e.g., the HDFS connector returns a large "lag" since it *needs* large "lag" to write large files. :( sorry, i think this might need some more thought
That does not sound right. If we throw a `StreamsException` the thread will die.
i think leaving as is should be fine atm, and tbh at least they are both close enough together to be easily modified together. if we think this is useful enough, i'd file a jira dependent on the jdk8 update so we can follow up.
nit: those lines can be rewritten (simplified?) as: `return (topic != null) ? topic: metrics.sensor(name1);`
Does that cause issue when a sensor/metric is added concurrently during removal? For example, 1. removeSensor(n1): complete until line 173. 2. a new sensor is added and we add a metric of the same name (as the metrics to be removed in step 1). 3. removeSensor(n1): complete the rest of the steps. After step 3, we may have removed the metrics added in step 2. Or step 2 will fail when adding the metric.
Yes. But if we add some more parameters later on, it would simplify the diff. But it's also ok to keep as it.
Ditto here. I think we should consider getting rid of the metadata request and exposing any exceptions from this request to the user's expected delete record response, instead we just rely on the whatever the current metadata (up-to-date or not) and if there is no leader known we set the future exception immediately.
line/sentence formatting `{@code null}`.
Not for this patch, but we should do a KIP to add support for batch topic creation.
Nit on the spacing so the description of parameters is column-aligned. ```suggestion * @param callable the function to execute. * @param maxRetries maximum number of retries; must be 0 or more * @param retryBackoffMs the number of milliseconds to delay upon receiving a * {@link org.apache.kafka.connect.errors.RetriableException} before retrying again; * must be 0 or more ```
Not sure if we need to make these `Optional`. `0` seems to be a good default value for these.
req: Lag should be a long
We can do it in a follow-up if you prefer. I was thinking it was as simple as setting `isFetched` to true, but I could be wrong.
Because there is not `CogroupedKStream#reduce()` method this sentence is not useful and should be removed.
We can remove the extra call in the variable here. ```suggestion CallRetryContext failedCallRetryContext = failedCall.callRetryContext(); ```
It's probably more of an issue now, but I think we may have already not been entirely thread safe with the methods we can call when starting connectors/tasks. In particular, `reconfigureConnectorTasksWithRetry` can invoke `addRequest`, and `addRequest` expects to already be locked but `reconfigureConnectorTasksWithRetry` doesn't guarantee that. I'm guessing we've missed that issue until now because that happens rarely and I think the only thing that could conflict with it would be external HTTP requests. I think the only other piece that needs to be protected as fallout from this parallelization is the step where we call `configBackingStore.putTaskConfigs` in `reconfigureConnector`. The backing store is not thread safe (and neither is its underlying `KafkaBasedLog`).
Nit `.` at the end
@junrao We are relying on fall-through for the second case, so it's not straightforward to make that change.
nit: `log.error("Exception caught while post-committing task: {}", task.id(), e);`
Thanks, looks good. Yes, it's O(1), but a lot less efficient than returning a local variable. Take a look. :) ```java public V get(Object key) { Node<K,V>[] tab; Node<K,V> e, p; int n, eh; K ek; int h = spread(key.hashCode()); if ((tab = table) != null && (n = tab.length) > 0 && (e = tabAt(tab, (n - 1) & h)) != null) { if ((eh = e.hash) == h) { if ((ek = e.key) == key || (ek != null && key.equals(ek))) return e.val; } else if (eh < 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) { if (e.hash == h && ((ek = e.key) == key || (ek != null && key.equals(ek)))) return e.val; } } return null; } ```
Hmm, I thought we'd have `LATEST_0_10_1` and `LATEST_0_10_0` instead of `LATEST_0_10` (which doesn't make sense because we have multiple feature releases in the `0_10` line.
nit: "which provide underlying producer and consumer clients for this {@code KafkaStream} instance".
Can this be a `byte`.
the message format => that message format
More specifically, during `onPartitionsRevoked` the restore-consumer is assigned either: 1) with active restoring task partitions, or 2) with standby task partitions With 1), upon `onPartitionsAssigned` we would continue restoring active tasks while no standby tasks would be processed yet, hence we could update restore-consumer with revoked partitions and newly added task partitions that needs restoring; With 2), upon `onPartitionsAssigned` there are two cases: 1) if there are newly added task partitions that needs restoring, we should "revoke" all standby tasks since we need to first go to restore those active tasks; 2) no new active tasks need restoring, we should only "revoke" those standby tasks that are re-assigned.
You can find it as the leader of the offset partition in ZK, though you will need to have a ZK connection to do that.
As we expect a specific `groupId`, I would check the provided `groupIds`.
ditto about the log level (also for the below uses of `debug`)
We don't use LeaderNotAvailableException in listTopics
Use `File.separator` instead of `/`
this overwrite of mm2config should go in the setup method, IMHO
Minor: maybe it's better override the override the acks to always be trimmed string inside `postProcessParsedConfig`, and then here we just check that the value is `all` or not; this way we can keep `parseAcks` as private static inside `ProducerConfig`.
prop: Could we pass into `getMovements()` the number of warm-up replicas and only compute as many movements as needed instead of computing all movements and then using just the first couple of movements.
nit: add `final`
Sure, but that led to the opposite problem, in which the enum was inconsistent with the state. In regard to position, I think we should handle this at transition time as mentioned below. If we ensure that position is not null in the fetching and validating states, then I don't see a problem changing `hasPosition` to check it directly.
nit: we usually align the parameters, like this: ``` public static Bytes toTimeOrderedStoreKeyBinary(final Bytes key, final long timestamp, final int seqnum) { ```
I feel a bit weird here as we don't need `prepareCloseClean` anymore. This API usage is a little complicated upon when we should do it and we don't.
Should we add it to `createTopicNames` also? Otherwise we will retry and fail again.
ditto on (what I think is) the impossibility of this condition being false.
Hmm.. I was looking into how the producer handles various operations after the call to close(). Unsurprisingly, there is a bunch of inconsistency. For send(), as far as I can tell, the logic looks like this: 1. Check whether the sender thread is closed and raise an error if it is 2. Refresh metadata if needed 3. Check if the accumulator is closed To be honest, I don't know why we don't just check if the sender thread has begun shutdown, but perhaps that's a separate issue. For transactional requests, it seems we don't currently do any checking to see whether the producer has been shutdown. At least I couldn't find any checks in `commitTransaction()`. To make this solution work, I think we should have those checks. Basically the user should see some kind of error indicating that the producer has already begun shutdown and the operation is no longer allowed. As it is, they would probably see an illegal state error indicating the transaction already began aborting or something. This could be a simple check in `TransactionManager` if we add a `close()` method as suggested elsewhere.
Unfortunately, the consumer groups are not aggregated in the same way that topic metadata is. To get all the groups in the cluster, you have to send the ListGroups request to all nodes.
I asked you exactly that a few months ago :) You referenced some old PR but basically the takeaway was, a restoring task hasn't initialized anything but its state, therefore needs to close only the state manager
I think we need to insert a `fail` here to fix this test
depending on the decision regarding naming sources for `builder.table` we'll need to update this test.
This method is not `synchronized`. So there could be a race condition here. I think it should be: ``` final NamedCache cache = getOrCreateCache(namespace); final LRUCacheEntry result = cache.putIfAbsent(Bytes.wrap(key), value); maybeEvict(namespace); return result; ```
Overall LGTM. But can we format it differently? We should start a new line for each sentence. If we update the docs later, it make the diff simpler to read.
nit: should we have a newline for each partition? Otherwise that ling maybe too long.
In the ZK based code, we also take live brokers into consideration when selecting a new leader.
This is not correct. It's blocking, which turns this into a blocking API rather than a non-blocking one.
nit: `child` -> `toChild`
EDIT: just realizing that we are re-throwing the exception anyways after re-closing the state managers. So this should be fine.
Similarly, everything up to the fetch (i.e. coordinator lookup, join group, and sync group) are pretty much the same in all of these methods. Maybe we turn it into a function (e.g. `prepareRebalance`).
request "got" re-sent to the control
Just copying over the suggestion to here, so it's easy to find ```suggestion final Throwable throwable = assertThrows(NullPointerException.class, () -> supplier.get().process(record)); assertEquals(throwable.getMessage(), String.format("KeyValueMapper can't return null from mapping the record: %s", record)); ```
Could you add a flag after ```producer.flush()```? We should make sure ```producer.flush()``` fails.
I'm wondering if we should move this config to LOW as it is already deprecated and hence would suggest users to never change it any more.
> and re-using the `KGroupedStream` results in an `InvalidToplogyException` when building the topology I thought, if there is no user topic-name, old code would create multiple repartition topics? And re-using `KGroupedStream` only throughs if there is a user topic-name (and this restriction is lifted with this PR)
Should we call close in the `finally` block? Here and elsewhere
Currently in this file the indentation style used is: ```java protected boolean maybeAddConfigErrors(ConfigInfos config, Callback<Created<ConnectorInfo>> callback) { ``` Still, once we move to single arguments per line it should be: ```java protected boolean maybeAddConfigErrors( ConfigInfos config, Callback<Created<ConnectorInfo>> callback ) { ``` I'd pick one of these. (First I confused `callback` for a local variable)
I think the basic idea makes sense and is what I was expecting. It might not feel too elegant, but I think a simple approach is best initially. An interesting point to consider is what would happen if an offset fetch is in-flight while a rebalance is in progress. When it returns, the offsets may be stale. I am wondering if it makes sense to fence the response using the group generation. In other words, we record the generation at the time of the request and then verify when we receive the response that it matches the current group generation.
placeholder may not be required for exception
This test fails on the mac on this line as the path is not `/tmp` but starts with `/var/folders...` by changing the assertion to `startsWith("process-state-manager-test Failed to write offset checkpoint file to [` then the test passes
Should we call close in the `finally` block? Here and elsewhere
We lack unit test coverage for this case
Perhaps we should not change the return type here unless we decide to make the more extensive `LinkedHashSet` change across all APIs (and corresponding KIP).
I think we can be more concise and simply say `// Single writer thread, multiple reader threads`
I don't think we need this `null` check either.
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
this line can be merged. for example: ```java FindCoordinatorRequestData data = new FindCoordinatorRequestData() .setKeyType(CoordinatorType.GROUP.id()) .setKey(this.rebalanceConfig.groupId); ```
I double people will update this script correctly. We can only hope, that release managers verify this before sending the email... As an alternative, we can also wildcard this, and let release manger insert those manually. Similar to `<DETAILS OF THE CHANGES>` above.
Thanks for doing this. I also noticed it was missing and fixed it in this PR: https://github.com/apache/kafka/pull/10085/files#diff-1da15c51e641ea46ea5c86201ab8f21cfee9e7c575102a39c7bae0d5ffd7de39R134-R137 Maybe reconcile the two changes and we can merge this one.
I just realized, that we use different wording for topics as array of Strings and topic pattern: "there is no ordering guarantee" vs "there are no ordering guarantees" -- I think we should clean this up for consistency. Would you mind to add this fix to this PR? The singular version sounds better, IMHO.
I think, it would be good to verify that a second call to `peekNextKey()` right after the first call to `peekNextKey()` returns the same value, since this is the main difference between `next()` and `peekNextKey()`.
@guozhangwang i'm not sure why we would want to enforce caching? Perhaps the custom store is already an in memory store? Why would we cache that? Perhaps there is some other reason why they don't want caching for a given store.
Seems like we could push these some of these checks in `TransactionState.beginTransaction()`. Same for the other APIs.
Should the error message not point out what went wrong, ie, "messages in the first batch were [not] processed in a timely manner" -- same below
nit: those lines can be rewritten (simplified?) as: `return (topic != null) ? topic: metrics.sensor(name1);`
nit: `e` -> `fatal`
Just to follow the question above, could we directly restrict the range at this caller as: ``` (Math.max(earliestSessionEndTime, currentSegmentBeginTime()), Math.min(latestSessionStartTime, segmentEndTime)) ```
nit: one parameter per line -> move `retryBackOffMs` to its own line
I wonder if we can just get a Map with the default size. I don't expect this code path to be very hot
This command has always left a trailing `,`. You could potentially omit the commands after the `cut` and just do a split/join in python that will give exactly what we want. Also, not sure if it was intentional or not, but this command seems to elide the alphabetical sorting that's in the command on the wiki.
+1 for consistency
This approach seems pretty weird. Are we modifying state in `ConfigDef` during validation? I feel like there are a few different issues with this -- it won't be thread safe, it ties state to the `ConfigDef` that shouldn't really be part of it, and it allows different config validations to get conflated. Why would we even be modifying the config keys in validation? Seems like validation should only generate `ConfigValue` objects.
```suggestion /** * Task ID of the task. * * @return task ID consisting of subtopology and partition ID */ ```
Suggestion: ```text Returns `partition.records` as `Records` (instead of `BaseRecords`). If `records` is `null`, returns `MemoryRecords.EMPTY`. If this response was deserialized after a fetch, this method should never fail. An example where this would fail is a down-converted response (e.g. LazyDownConversionRecords) on the broker (before it's serialized and sent on the wire). ``` ```
We usually avoid writing to standard out in test cases. A few more of these.
Lines L#93 to L#98 can be replaced by: ``` assignment.keySet().retainAll(subscription); ``` same effect, as we want the intersection of `assignment` and `subscription`
nit: as mentioned elsewhere, I don't think we need to add all of these exceptions to the method. They are all runtime exceptions, so it's still up to the user to read the docs.
The log level is a tricky one. In the producer, messages for errors are all at debug level (for instance when we transition to error state in the transaction manager). So having this higher than debug may not add much value.
In my PR (https://github.com/apache/kafka/pull/7304) I've refactored this part in StreamTask. I'd suggest we merge that one before this.
Nevermind, I was thinking of `position += n`, but `limit` is actually the result of that (bounded by records.size).
The serialization package is open to everyone (it's public API and at the lowest layer). So I don't think we should worry about that. It's not like we're avoiding a dependency here, we are just hiding it via a string based config (that still requires the default constructor to be present).
```suggestion * Disable the changelog for this suppression's internal buffer. ```
I'm wondering if we should move this config to LOW as it is already deprecated and hence would suggest users to never change it any more.
as above mentioned, the `listStore.all()` is not closed here.
Probably want to make this a `ConcurrentHashMap` or `synchronize` access to it. It can be modified etc from multiple threads
This is added in #986 as well. The later patch to go in will have to rebase, or we can extract out the common code as a separate PR. I am fine with either way. FYI @becketqin.
placeholder may not be required for exception
nit: we can use `map#compute` to replace getOrDefault + put.
It seems that we need the logic to turn off OP_WRITE here too. Suppose that the client tries to send a token, but couldn't completely flush the writes. We get in here and completely flush the output buffer. Now, if the OP_WRITE is not turned off, the selector will be woken up all the time before the client receives the next token from the broker.
original was better
nit: empty line.
Thanks for the updates. Looking better. :) One thing I wasn't too clear about. For the `shouldRecord` case, we can pass a number to make the comparison more efficient. It's pretty similar to using `ordinal`, but the number is explicit instead of being based on the order of definition. Classes like `ApiKeys` and `SecurityProtocol` do that. We could also just use the ordinal if it's just used internally. Another thing is that enums get a `name` method that returns the declaration name. In this case `INFO` and `DEBUG`. So, again, if it's an internal thing, we could potentially reuse that. Defining it explicitly is fine too (we tend to do that for public enums. Finally, we don't use getter notation in Kafka so `getValue()` should be `value` (if we decide to keep it).
What about client security related properties? It's weird that we pick up "bootstrap.servers" from one prefix, but the corresponding security properties under a different prefix. If we do provide the security related properties in the same prefix, they seem to be duplicated from those under prefix REMOTE_LOG_METADATA_COMMON_CLIENT_PREFIX, REMOTE_LOG_METADATA_COMMON_CLIENT_PREFIX or REMOTE_LOG_METADATA_CONSUMER_PREFIX.
Cleaner to just check if `tasks.isEmpty` after the loop is over.
The next 2 methods aren't used in this PR. I guess they are used in one of the others...
nit: add `final` (2x)
Personally I think it makes sense to just disallow calling `ofTimeDifferenceAndGrace(...).grace(...)` entirely, this seems like abusing the API
`This conversation was marked as resolved by wcarlson5` :)
I was thinking something like this: ``` java long nowMs = time.milliseconds(); long deadlineMs = nowMs + timeout; do { RequestFuture<Map<TopicPartition, OffsetAndTimestamp>> future = sendListOffsetRequests(timestampsToSearch); client.poll(future, deadlineMs - nowMs); if (!future.isDone()) break; if (future.succeeded()) return future.value(); if (!future.isRetriable()) throw future.exception(); long remaining = Math.max(0, deadlineMs - time.milliseconds()); if (future.exception() instanceof InvalidMetadataException) client.awaitMetadataUpdate(remaining); else time.sleep(Math.min(remaining, retryBackoffMs)); nowMs = time.milliseconds(); } while (deadlineMs > nowMs); throw new TimeoutException("Failed to get offsets by times in " + timeout + " ms"); ``` Not sure if it's any better though. If so, only marginally.
In two of this control messages we pass the `currentTimeMs` in this one we don't. It is nice to be consistent. I think that `appendLeaderChangeMessage` passed the `currentTimeMs` because it want to use the same time for the entire `poll` call.
s/assignments/oldAssignments, and name could be simplified as `toNewAssignment`
```suggestion * ReadOnlyWindowStore<K, ValueAndTimestamp<V>> localWindowStore = streams.store(queryableStoreName, QueryableStoreTypes.<K, ValueAndTimestamp<V>>timestampedWindowStore()); ```
Can you elaborate? I don't see any point in the code where we would return between adding the topic and awaiting the update.
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
This log entry could be misleading, that even if there is an exception happened and hence no task created, it will still print as `created ...`; and in practice I have once encountered this issue before which affected the trouble shooting process, I think we should try to piggy-back fix it.
I am wondering, if we might want to remove this method? Do use it only at one place and can easily pass the record timestamp there instead? Or is it useful for some special cases? Of course, this would require a KIP and separate PR -- it's might also not be high priority and just creating a JIRA for it might be fine. WDYT? \cc @guozhangwang @bbejeck
I don't think a reference to `protocol_api_keys.html` is required here; because that file is loaded as a server side include (SSI) inside `protocol.html`. I would prefix the anchor labels with something like `The_Messages` (which is the referred main section name) instead to make them uniform. The hyperlinks should work fine after fixing this.
I find having a method specific for SSL strange. Callers should not have to know, this should be retrieved automatically based on the cluster being targeted
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it 
I think the basic idea makes sense and is what I was expecting. It might not feel too elegant, but I think a simple approach is best initially. An interesting point to consider is what would happen if an offset fetch is in-flight while a rebalance is in progress. When it returns, the offsets may be stale. I am wondering if it makes sense to fence the response using the group generation. In other words, we record the generation at the time of the request and then verify when we receive the response that it matches the current group generation.
We tend to use the steam api for such small transformations but I don't feel strong about this.
I feel logging all of the records even at TRACE level will be too much. For example, our system tests often have TRACE enabled. Huge single-line log messages are difficult to consume both visually and in systems like elastic.
I think one thing to take care is to explain / make clear when to use what mechanism: 1. We have a repartition graph node used for implicit repartitioning before aggregates and joins. 2. In some other places, e.g. here in selectKey, we do not create a repartition node but use a flag instead. It is better to elaborate why we made this design.
I'm not very familiar with the direct buffer usage pattern, but currently it seems we would still try to allocate a new buffer for each put call, whereas I "thought" the main benefits come from reusing the buffer across multiple put calls? @vamossagar12 @ableegoldman @cadonna please correct me if I'm wrong.
Is`atexit` is the right approach here? The registered function will only run when the entire ducktape process finishes (i.e. _after_ all ~215 tests finish). Use of the `tempfile.mkdtemp` will still avoid path collisions from concurrent processes, so maybe it's good enough. Another possibility that at least results in immediate cleanup: put directory removal into `clean_node` (but check the containing directory is present before removing to avoid errors)
nit: add `final`
Do we need this? Can't we just use the Time we pass into the constructor in tests? Not a big deal really, just wondering
I think we should always assign the `next.value.timestamp` value to a variable with an explicit name, eg `windowMaxRecordTimestamp`, because it's pretty non-obvious what it means and easy to forget
If you want to check that records for non-pause partitions are cleared, we should have a separate test.
We need to remove this too, right? We shouldn't forward anything regardless of whether it's a left join, if the mapped key is null then there's nothing to map it to
I think `kafkaOffset` was incorrectly changed to `Long`. We'll always have a Kafka offset, so it should be `long`. Also, the current version breaks compatibility since the old signature constructor is no longer available.
Why not something like: ``` final List<String> storeNames = Arrays.asList(parent1.valueGetterSupplier().storeNames()); storeNames.addAll(Arrays.asList(parent2.valueGetterSupplier().storeNames())); return storeNames.toArray(new String[storeNames.size()]); ``` ? I don't think it is on the critical path so performance shouldn't be an issue
what's a requested topic partition? Also, above we mention just `partition`
Sorry for the forth and back -- for `assertThat` you original code was correct and expected argument is second one... (it different for `assertEquals` -- my bad(!)).
I guess it's kind of a confusing error to see. The case on the broker is when the write to the log failed because of a timeout. I wonder if it would be useful to suggest the cause in the message. For example: > JoinGroup failed with a REBALANCE_IN_PROGRESS error, which could indicate a replication timeout on the broker. Will retry.
Cheating the compiler, woohoo!
nit: as mentioned elsewhere, I don't think we need to add all of these exceptions to the method. They are all runtime exceptions, so it's still up to the user to read the docs.
Can we also include the cause when we throw exceptions? It's not always helpful, but it has been invaluable for debugging many times since we started to include the cause.
Why are we splitting the handling of metadata between both `Metadata` and `Fetcher` now? Is this just so that this topic-partition metadata is not persistent in `Metadata` since calling `partitionsFor` doens't really imply anything about whether you'll continue to need updated metadata for the topics passed in here? Even so, this split seems less than ideal...
How about the following to simplify the string construction below: ```java String clientEnabled = System.getProperty(ZK_SASL_CLIENT, "default:" + DEFAULT_ZK_SASL_CLIENT); String contextName = System.getProperty(ZK_LOGIN_CONTEXT_NAME_KEY, "default:" + DEFAULT_ZK_LOGIN_CONTEXT_NAME); ```
nit: maybe iterate over `entrySet()` instead.
Similarly here, this state check could be internalized.
This should say `AdminClient`, not `Consumer`.
Let's use try with resources here and the other test so that the file is closed after it's used.
Ack, I get it now. Thanks for clarifying.
This first argument (`1L`) can be missed, given that that's the only line in which we pass 2 arguments. I'd add one argument per line.
Hmm, if we convert arrays to bytes, we need to be careful. If the arrays have different sizes, then the operation is not constant time.
EDIT: nvm, I think I understand it now.
That makes sense, let's keep it in that sense. EDIT: Actually, I'm wondering that if the `monitor` would always grep the same log4j entry in the outside verification or it always try to grep the new lines after the inner verification? If it's the first case, then the outside verification would always be redundant as we are doomed to just grep the same lines.
Style nit for "note" and whitespace between `Bytes` and `byte[]`: > (note, state stores always have key/value types {@code <Bytes,byte[]>} should be > (note: state stores always have key/value types {@code <Bytes, byte[]>}
I understand that. My question is whether there is some thinking on which configs make sense to be set by users. Ideally, we'd do that instead of being reactive.
Oh you're totally right, sorry for letting my paranoia start spreading conspiracy theories here  Given all this I'd still claim that the FSM is in need to being cleaned up a bit (or a lot), but if you'd prefer to hold off on that until the add thread work then I'm all good here. Thanks for humoring me and explaining the state of things. I just wanted/want to make sure we don't overlook anything, since there's a lot going on. For example in the current code, if the global thread dies with the old handler still in use then we'll transition to ERROR. However the user still has to be responsible for closing the client themselves, and it will ultimately transition from ERROR to NOT_RUNNING. Whereas if we transition to ERROR as the result of a SHUTDOWN_APPLICATION error code, the user should NOT try to invoke close themselves, and the ERROR state will be terminal. That's pretty confusing eg for users who use a state listener and wait for the transition to ERROR to call close(). We should make sure that ERROR has the same semantics across the board by the end of all this work. Anyways I'm just thinking out loud here, to reiterate I'm perfectly happy to merge this as-is. But for reasons like the above, I think it's important to tackle the FSM in the next PR and make sure it all gets sorted out by the next AK release
Child-Index was deprecated recently -- should we remove it? Also, with KIP-251, we should capture output timestamps, too.
Please adjust indentation: ```suggestion mkMap( mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()), mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId), mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()), mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2), mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class), mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class) ) ```
nit: we may as well move this check into `ConsumerGroupMetadata` since we have some other null checks there.
In other words, I'm recommending that we specifically say something like "Producing deletes from your aggregations may cause unexpected results when processing dis-ordered data. Streams always processes data in the order it appears in the topic. If the topic is populated out of order, you may have late arriving records, which can cause records to become unexpectedly re-created after they have been deleted. Out-of-order data can be a problem for non-deleting aggregation functions as well, but it's especially surprising with aggregations that produce deletes." :/ ... you see what I mean by saying that it's a nuanced topic.
One question: it seems the `bulkLoadSegments` set will only keep increasing in size since we only initialize it once in `bulkLoadSegments = new HashSet<>(segments.allSegments());` and then do this ad-hoc addition here, when segments are dropped they will not be removed from `bulkLoadSegments` as well, right? I'm thinking, if we could just call `final Set<Segment> bulkLoadSegments = new HashSet<>(segments.allSegments());` here every time, since 1) if the store does not exist yet, the `getOrCreateSegmentIfLive` will call openDB that makes the open flag for the newly created store, and 2) if the store does exist already, then `toggleForBulkLoading -> segment.toggleDbForBulkLoading` will make sure the store is open here.
I think the expectation is that these 2 would be atomic (i.e. would be bad if one thread executed 615, then another thread executed 615 again and got the same sequence number, before the first thread got a chance to execute 616). Also I think the expectation is that batches that are ordered one after another in the queue would get the sequence numbers in the same order (i.e. that batch that is later in the queue would get higher sequence number). Previously these expectations were protected by the queue lock so "poll", "get sequence", "update sequence" would execute as atomic block, with this change the operations could interleave.
ditto for the rest of the test
`hop` vs `advance` is subjective :) I am fine with `hop`, too; it's called a `HoppingWindow` after all. `advance` is just a term that is quite common in literature so I am somewhat used to it.
Can you please explain why it's better to warn than to fail-fast in this case? Just want to make sure I understand the reasoning for the choice.
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
Could store `entry.getKey()` in a local variable since it is used several times
I think we can just add these configs as part of the PR.
I think you missed this one.
@mumrah : equality for the generated messages should mean bytewise equality. So if two FetchResponseData instances contain the same data, they should be equal, even if one is using MemoryRecords and the other is using FileRecords. Same for hashCode, of course. If it's too much trouble to change the Records class, you can just write a static utility method in MessageUtils and invoke it from the generated classes. I expect that we won't be doing this kind of comparison except in tests, so you don't need to optimize the method too much.
Throwing an exception here would just cause a `caller.fail`, and then caused a `handleFailure` instead. I think it's better just setting the exception in the future directly.
`timestamp` missing (three times)
In the case of controlled shutdown, currently, we ignore the unclean leader election flag and always to elect a new leader cleanly.
NPE: ![image](https://user-images.githubusercontent.com/925755/55269396-d55f3480-5292-11e9-9c29-78c524d63c65.png) I'm not using a topic pattern, equality should still work.
For standby tasks, I think cleanup the state directory is fine; adding it into the rebalance protocol needs bump up the metadata serialization version for upgrade and hence more complicated.
Hmm, should we do that? So for, we only guarantee old version of java client can talk to new version of server. But there is no guarantee that new version of java client can talk to old version of server. So, it seems simpler to always let the new client send SaslHandshakeRequest. This also makes it easier to add ApiVersionRequest in the future (KIP-35).
nit: add `final`
nit: `client1` -> `kafkaStreams1` nit `createClient` -> `createKafkaStreams` (similar for all other variables eg `clientStates` etc) It's technically a client, but also consumer and producer are and we also use `consumer`/`producer` as variable name there -- makes it easier to read -- otherwise it unclear what client it is.
This wording could be improved: "Batch splitting cannot be used with non-compressed messages, NOR with message format versions v0 and v1"
I think this should be used in the define method below too.
We could iterate through v1 to v5 here to test every case.
Using generic types instead of raw types for collections is preferable (we can fix elsewhere in the file too) ```suggestion List<?> items = (List<?>) value; ```
Likewise, this log message could be changed to: ```suggestion log.warn("Attempt {} to {} resulted in RetriableException; retrying automatically. " + "Reason: {}", attempt, description.get(), e.getMessage(), e); ```
nit: move `Serde.String()` into next line (also, I would prefer to not have static import `Serde` but prefix. I was initially confuse why this compiles and why it's not `new String()`... (because the method name starts with capital `S`...)
nit: should be `named` can't be null
@spena just ping to make sure you get this on the follow-up PR.
Yes, I think it's worthwhile to check the result of `Connector.config()` just in case `Connector.validate()` is overridden and the default check there is no longer used.
the drawback of renaming here is that the name `start_cmd` is used with `start`/`start_node` pretty standardly across the rest of this code base
@vahidhashemian, yes, that's what I mean.
none from what I can see, but I'm not sure it's worth holding up the PR for it.
Nit: remove unnecessary `this`.
Since this isn't implemented, perhaps lets not mention it? I found it confusing
AFAIK no timestamp type defaults to CreateTime, so I think this test and the test below will test the same thing. But need @becketqin to confirm this.
I don't think it makes a big difference either way. The intent of the offset commit interval is just to make sure committed offsets don't fall too far behind. It does not need to be a strict schedule. It seemed more intuitive and simpler to me to reset the interval. In any case, we should get rid of this relative tracking of the next commit. If we use an absolute time, then we will not have problems like this in the future.
nit: avoid unnecessary `this.` prefix
explain why `Integer`, `Long` is used instead of `int`, `long`
```suggestion for (final Map.Entry<TaskId, SortedSet<ClientIdAndLag<ID>>> taskToRankedClient : statefulTasksToRankedClients.entrySet()) { ``` Just to resolve a warning about referencing the subclass instead of the interface.
nit: we can keep the send() call without the partitioner argument which will then call this function with null.
This assertion tries to capture 3 cases: 1. All good, return `Optional.of(true)` 2. The boolean logic in the method is `false` (e.g. tasks are not ready, connector is not ready, an error response was returned etc). Please return `Optional.of(false)` 3. Exception was thrown and I can't say. Return `Optional.empty()` So based on this, how you'll interpret (3) is up to you on the `waitForCondition`. And here you want to treat it as `false`. That's why `orElse(false)` is more appropriate.
typo: byteArrray -> byteArray
`replicaing` -> `replicating`
ditto here and others below
Yes, you have to check each task individually, but nothing prevents you from submitting them all at the same time. I am assuming that any overhead here is really associated with task startup time, so this allows for it to be parallelized.
nit: add `final`
This can just be referencing LEADER_AND_ISR_REQUEST_PARTITION_STATE_V0.
The current implementation is problematic in the sense that all cached data will be removed if users subscribe to the existing set of topics and `topicPartitionsToClear` is empty. Can we replace `clearBufferedDataForTopicPartitions(...)` with `updateCompletedFetches(Set<TopicPartition> assignedPartitions)`? updateCompletedFetches will keep only those data whose partition is still assigned. This will fix the problem above and also makes the logic in the caller simpler. Instead of having to determine the partitions that have been removed, the caller only needs to provide the latest assigned partitions as `subscriptions.assignedPartitions()`.
This is where we leave the group. Any offset commits which haven't yet been sent will definitely fail after this, so I think we need to move that loop into the try block.
Also, `consists` should either be preceded by a `that` or it should be changed to `consisting`
could we extract these 3 lines into a method, say `verifyCallbackStatesCalled` or something better! the same block of code is repeated 3 times in the test so would make it easier to grok
nit: `completeRefresh` to be more concrete in what it completes? Complete can be understood to mean a total completion of the connection, whereas this completes a single refresh (something finer-grained and more often)
Ideally we want to get rid of this method as it makes no sense in tests that are not SSL.
nit: formatting -> should be in the line above.
I get the intention for lazy initialization. Asked generally since I wanted to be 100% sure about the expectations w.r.t. concurrency. I think it's best to keep `volatile` since the field is not final and might be accessed in sequence by different threads, but `synchronized` can be skipped if there's no concurrent execution by different threads.
The goal of the ticket is to actually remove this check.
The test should describe what it is doing, i.e., `shouldThrowStreamsExceptionWhenBrokerCompatibilityResponseInconsisent`
No kidding... I assumed it was possible to create topics without cleanup policies but it looks like you're right. My bad!
@llowrey, it would also be interesting to know the environment where you can reproduce this. I tried writing a test that connects 1 million times to a Java EchoServer and `connect` always returns false.
nit: seems these could be final? Same in `ConsumerUserData`.
Also, 5ms seems a bit extreme. Maybe this could be 20ms or so and we could use the minimum of this and the configured retry backoff so that users can adjust it lower if they need to.
Same (should be threads_per_worker)
Huh. Bummer that you have to make it queriable in order to use the in-memory store. I never noticed that before.
I think we can be more concise and simply say `// Single writer thread, multiple reader threads`
Better be `cooperative-sticky`? `cooperative` is too general I think.
Should we chain the caught exception? We expect this to be the close exception, but it could also be a timeout or an authentication failure. Might be useful to know in some scenarios.
Here also. It looks like you used the IDE code generator to make these, but they don't seem to be correct. Perhaps there's a configuration wrong somewhere? Here's what mine produces: ```java @Override public boolean equals(final Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; final Movement<?> movement = (Movement<?>) o; return Objects.equals(task, movement.task) && Objects.equals(source, movement.source) && Objects.equals(destination, movement.destination); } ```
I don't think you want to get rid of the `validateBasicConnectorConfig` call. The default just calls validate, but in `DistributedHerder` it also validates there won't be a conflict between the worker and consumer group for sink connectors.
This should not have the `sink` suffix
In two of this control messages we pass the `currentTimeMs` in this one we don't. It is nice to be consistent. I think that `appendLeaderChangeMessage` passed the `currentTimeMs` because it want to use the same time for the entire `poll` call.
See also `handleGroupRequestError`. If the coordinator is in the middle of being moved, we want to retry rather than fail.
the method name changed to `windowedTable` and `windowSize` parameter is missing
Nit: "..and producer's {@link DefaultPartitioner}".
Thanks for the catch!
SGTM. We can keep it as is then.
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
Please include TopicDeletionDisabledException here.
Please adjust indentation: ```suggestion mkMap( mkEntry(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, CLUSTER.bootstrapServers()), mkEntry(StreamsConfig.APPLICATION_ID_CONFIG, appId), mkEntry(StreamsConfig.STATE_DIR_CONFIG, TestUtils.tempDirectory().getPath()), mkEntry(StreamsConfig.NUM_STREAM_THREADS_CONFIG, 2), mkEntry(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.StringSerde.class), mkEntry(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.StringSerde.class) ) ```
 fair enough
This can (and should) be a unit test, since we don't need to produce data or run Kafka to build and verify the topology.
Ditto on the properties and the driver.
Just a question: Why is this not `6L` ? (it should be `5L` after you applied the fix you want to do in a follow up PR).
The overhead is minimal. The benefit is clarity: if someone looks at the code it is immediately obvious that null is not allowed.
Is this test needed? It seems that loginContextName can never be null.
building a topology is done on the main thread when calling `StreamBuilder.build()` so I think it's safe to remove `synchronized`.
iiuc, this is actually the bug that we are fixing here. On the current trunk, if flush or cache.close throws, we do _not_ close the wrapped store. Now, with this change, we still call flush, cache.close, and wrapped().close, regardless if some of them throw.
Why are we changing this? The constructor with a single argument takes a message and not the groupId
It's probably better to create two constructors, one for each version. We can then mark the v0 constructor as deprecated and can remove it in the future.
I wonder if it is worth refactoring this to remove duplication, i.e, add a Functional interface, then implement it three times to just perform the op on `globalStateRestoreListener` then have a method sth like: ``` performOnGlobalListener(GlobalListenerAction action, String storeName, TopicPartition partition) { if (globalStateRestoreListener != null) { try{ action.perform(); } catch (final Exception e) { /// streams exception stuff } } } ``` Other methods delegate to this new method. The guard and error handling are encapsulated in one place. When we eventually get to java 8 we can just do a lambda call
Seems to fit in one line
I could not find where you decrement the number of remaining standbys. If you get a value from this map and put it into an `int` variable, you do not have a reference to the `Integer` value in the map anymore. This might become a problem in `StandbyTaskAssignmentUtils#pollClientAndMaybeAssignRemainingStandbyTasks()`.
Do you know why we have all these ReadOnlyWindowStore methods also declared here in WindowStore? We don't need reverse variations of these I guess? 
nit: insert space `String... expected`
```suggestion log.trace("Behind end offset {} for {}; last-consumed offset is {}", endOffset, topicPartition, lastConsumedOffset); ``` nit: multiline calls don't need to be on their own line in AK and tab is equal to 4 spaces (here we need 2 tabs)
This check `records.size() < offset` seems a bit sketchy to me. Basically we are assuming that the input topic `data`'s starting offset is always 0, and there is no "holes" in the topic partitions so that the `offset` indicates the number of records we can read from the input topic. Maybe a more robust way to do that would be 1) read the input topics `data` and optionally `repartition` based on `withRepartitioning`, stop when the current record's offset is equal to or larger than the committed offset, and remember the number of records; 2) read the output topics (again optionally `repartition`) from the beginning to the end (use `seekTo`), and check that the number of records are the same as the number of records read from the input. Then we do not need to truncate, and also in verification we do not need to check list size again since they are already checked here.
It's better to keep the parameters aligned (having same indentation)
EDIT: just realizing that we are re-throwing the exception anyways after re-closing the state managers. So this should be fine.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
I wonder if it is worth refactoring this to remove duplication, i.e, add a Functional interface, then implement it three times to just perform the op on `globalStateRestoreListener` then have a method sth like: ``` performOnGlobalListener(GlobalListenerAction action, String storeName, TopicPartition partition) { if (globalStateRestoreListener != null) { try{ action.perform(); } catch (final Exception e) { /// streams exception stuff } } } ``` Other methods delegate to this new method. The guard and error handling are encapsulated in one place. When we eventually get to java 8 we can just do a lambda call
We probably have to keep the `size() == 0` behavior for compatibility.
Hmm.. I was looking into how the producer handles various operations after the call to close(). Unsurprisingly, there is a bunch of inconsistency. For send(), as far as I can tell, the logic looks like this: 1. Check whether the sender thread is closed and raise an error if it is 2. Refresh metadata if needed 3. Check if the accumulator is closed To be honest, I don't know why we don't just check if the sender thread has begun shutdown, but perhaps that's a separate issue. For transactional requests, it seems we don't currently do any checking to see whether the producer has been shutdown. At least I couldn't find any checks in `commitTransaction()`. To make this solution work, I think we should have those checks. Basically the user should see some kind of error indicating that the producer has already begun shutdown and the operation is no longer allowed. As it is, they would probably see an illegal state error indicating the transaction already began aborting or something. This could be a simple check in `TransactionManager` if we add a `close()` method as suggested elsewhere.
nit: parameter/line formatting
nit: move below the shortcut return below.
`earlier or later` -> `before or after` (to avoid confusion with the term "late data")
Don't we need to set version 0.10.1 for those initially? Otherwise, they will have trunk version
I would prefer a second loop to guarantee a consistent reflection on the task committed state.
style nit: normally we'd use braces around blocks unless they're a single line
I guess in the end we will find these classes a better place (currently they are a bit scattered, e.g. `KeyValueStoreFacade` is in the materializer class).
We could actually show the client state by: `"Some clients didn't reach state RUNNING without any stand-by tasks. Eventual status: [Client1: {}, Client2: {}]", client1IsOk, client2IsOk`
@gwenshap looked into this and showed me why it doesn't work. Could we use a plain socket to send the api versions request to avoid the issue? It's a bit difficult to verify that we are doing the right thing with the current test. For the second question, the current thinking is that we will do that after 0.10.0.0.
I wonder if this could be generalised further? Probably a broader discussion, but `KStreamPeek` is really the same as `KStreamMapValues` (there may be others). They just don't share a common interface for the action. I personally feel this would be a better rationalization of classes etc than combining `KStreamForeach` and `KStreamPeek`
Yes, I am suggesting that we allow the user to retry after a timeout. The simplest way to do so is to cache the result object so that we do not send another InitProducerId request. Instead, we should just continue waiting on the one that we already sent.
Nit: I know this was inherited from the existing code, but it would be nice to do something like `ByteArrayDeserializer.class.getName()` for serializers and deserializers.
The first exception will be the "cause"
`skipBytes` doesn't avoid decompression though, the `readBlock` call below decompresses the buffer: ```java class: KafkaLZ4BlockInputStream public long skip(long n) throws IOException { if (finished) { return 0; } if (available() == 0) { readBlock(); } if (finished) { return 0; } int skipped = (int) Math.min(n, available()); decompressedBuffer.position(decompressedBuffer.position() + skipped); return skipped; } ``` We do avoid GC pressure though.
Maybe we should say `a partition (which consists of log segments) can grow to...`
IMO, the code would be easier navigable if you inline this method. Without the removed check, there is not really a reason to have a method here.
Also, I would not rely on reading the code to assume one way or another. You'd want to test it too.
I see. I do not have a strong preference actually. But I remember we use singulars not plurals in many other classes and just wanted to be consistent. If it is actually the opposite case I'm happy to have them all to be plural.
Hmm, why did we do this? I thought we'd have a try/catch block.
same as before. Would be much nicer to add a method on the abstract class rather than using instanceof
nit: just to better visually separate condition from `if`-block ```suggestion if (historySize >= 2 && stateTransitionHistory.get(historySize - 2).equals(before) && stateTransitionHistory.get(historySize - 1).equals(after)) { return true; } ```
Why do you remove `transform` ? We only add a new `flatTransform` but `transform` is not removed.
@hachikuji Did you misread `startTask`? It directly invokes `Worker.startTask` afaict.
This is assuming that `totalTopics` is always a multiple of `MAX_BATCH_SIZE. Is that always true? Perhaps it is better not to make that assumption in any case.
Ok, I was thinking more along the lines that we have just one requestCommit instance while we would have multiple punctuator instances all using it. It looked like a bug, but it seems like it'll be fine.
@rajinisivaram makes sense. I was thinking if we can break the JAAS config file and made them into client config properties. But just passing JAAS config file will make it easier and extensible.
this is the kind of assertion that could become flaky given incremental population of `connectors`.
Nit: `Note that {@code InvalidStateStoreException} [is] not thrown directly but only [its] sub-classes.`
I'm not very familiar with the direct buffer usage pattern, but currently it seems we would still try to allocate a new buffer for each put call, whereas I "thought" the main benefits come from reusing the buffer across multiple put calls? @vamossagar12 @ableegoldman @cadonna please correct me if I'm wrong.
Also, it might be better to use `synchronized (AbstractCoordinator.this) { }` to mutate both `rejoinReason` and `rejoinNeeded` in order to ensure that they are consistent with each others.
This block can be moved outside of the `try-catch-block`
if we make this `<String, TopologyDescription.AbstractNode>` then can we do away with the casts below? I think we know that they will always be `AbstractNode`
Maybe use the `addNode()` available on this class for consistency? (applies a few times in this file)
For this case, the input `KStream` key was not changed, and thus no repartition topic should be created. We should only get a single sub-topology.
It's a little nice for future reference when we also say when it became deprecated, such as "since 2.6".
These blocks of assertions are quite hard to read. Can we try to make them more digestable? We could perhaps extract temporary variable to reduce the number of `.get()`. We could also define an `verifyDescription` helper that verify a `LogDirDescription` for instance. It may be worth having dedicated unit tests for the new and the old APIs as well.
Do we really need to set a fatal error for every consumer, or could we just remove the problem partition from the assignment and set NEEDS_REJOIN? Or is it better to just fail fast
Can you do something like: ```java static final int tableSizeFor(int cap) { int n = -1 >>> Integer.numberOfLeadingZeros(cap - 1); return (n < 0) ? 1 : (n >= MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : n + 1; } ```
Right, sorry I misread that line.
Also, I just looked at `ConnectRecord.toString()`, and it does _not_ print the schemas. I wonder if it's worth changing that to include whether the key schema and value schema are null; e.g., ``` @Override public String toString() { return "ConnectRecord{" + "topic='" + topic + '\'' + ", kafkaPartition=" + kafkaPartition + ", keySchema=" + (keySchema != null ? "..." : "null") + ", key=" + key + ", valueSchema=" + (valueSchema != null ? "..." : "null") + ", value=" + value + ", timestamp=" + timestamp + ", headers=" + headers + '}'; } ```
The order is not really that important here, either way works
Do we need this config? `producer.send(record).get();` ensures we get a response from the request so I don't see the value in the config
nit: `sooner` -> `as soon as possible`
nit: What do you think about sprinkling a bit of docstrings in this interface while we're rewriting it? I like the original description of `An MBean that allows the user to dynamically alter log4j levels at runtime.`
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
Can `rebalancing()` throw a `InvalidStateStoreException` ? If yes, we need to split this an apply try-catch-fail pattern instead of using `@expected`
nit: use "{}.x." vs. string concatenation
Would it be better to provide default value, probably 1, for this configuration? Otherwise this patch will break existing tests/tools that use `ProducerPerformance`.
Similarly here, I think we can move these checks into `TransactionManager` and just pass the batch.
Not required. Client will be automatically closes, as we use Java's "try with resource" feature.
The verb following 'should' would be in active tense. consider naming this test: userSerdesShouldBeInitialized
`assertNull`s shouldn't be here but few lines bellow.
You can use `EnumMap`.
I'm not very familiar with the direct buffer usage pattern, but currently it seems we would still try to allocate a new buffer for each put call, whereas I "thought" the main benefits come from reusing the buffer across multiple put calls? @vamossagar12 @ableegoldman @cadonna please correct me if I'm wrong.
nit: should we merge this into existing test? If not, rename to `shouldChooseNextRecordBasedOnHeadTimestampe`
The call to `closeGracefully` can result in some responses being returned from the brokers. Is it intentional that we do not invoke the completion handlers? I think this probably makes sense since anything awaiting the responses has probably shutdown by now, but wanted to check.
Maybe we can just a better name for `path` since it makes this code look suspicious.
Don't we have to do something with the futures returned by `send`? How do we know if the requests completed? Also, cc @hachikuji.
This logic would become `inFlightRequests.remove(batch)` when a `TreeSet` is used for this.
```suggestion ConfigDef.Type.LIST, ```
nit: move first parameter to next line, too
> most recent max timestamp Huh? I think I know what you're trying to say here but it seems like two different phrases got a bit mixed up here
Should have a comma after "for example"
nit: can we make this `if startTime == 0` ? That seems slightly easier to understand, and then all the conditionals can be in terms of startTime which is a bit more intuitive since that's what we're iterating over. Context switching between startTime and endTime kind of makes me lose my train of thought
What happens if `millisRemaining` is, say, 2 and `retryBackoffMs` is 1000? If `millisRemaining` is positive, then shouldn't we sleep for the smaller of `millisRemaining` or `retryBackoffMs`? IOW: ```suggestion Utils.sleep(Math.min(retryBackoffMs, millisRemaining)); ```
This line is a bit long. ```suggestion final RemoveMembersFromConsumerGroupResult removeMembersFromConsumerGroupResult = adminClient.removeMembersFromConsumerGroup( config.getString(StreamsConfig.APPLICATION_ID_CONFIG), new RemoveMembersFromConsumerGroupOptions(membersToRemove) ); ```
a logger should always be private -- if classed extend `KTableSource` the should create their own logger with the corresponding "child" class name.
Isn't this a behavior change? IIRC, we had a discussion to do this change, or to maybe make it configurable if we want to interleave processing with recovery.
```suggestion expect(rocksIterator.isValid()).andReturn(false); ```
We can use JUnit "expect exception" here. For example in SchemaBuilderTest.testInt64BuilderInvalidDefault.
In the case of controlled shutdown, currently, we ignore the unclean leader election flag and always to elect a new leader cleanly.
We should probably mention that due to consumer design restriction, currently we only allow one stream throughout the topology to be created from regex patterns.
This signature should be consistent with the consumer and producer. For example: ```java public void close(long timeout, TimeUnit timeUnit) { ```
I cannot see how a unit test for the rebalance listener does not make sense. I would rather unit test the listener in isolation and then mock it in the other unit tests.
@guozhangwang i'm not sure why we would want to enforce caching? Perhaps the custom store is already an in memory store? Why would we cache that? Perhaps there is some other reason why they don't want caching for a given store.
Maybe: Include in the log the Connect key, value, and other details of records that resulted in errors and failures.
We also need to explain a bit why we add a type converter at this layer of the store hierarchy.
Is there a `Locale` that would work for lowercasing these that would work and not vary by the JVM config? I think based on the restricted characters, just using something like english should be ok.
nit: remove the `<` and `>` here and next line. Just to keep it consistent with everywhere else we do this
this line is still a bit long... You could try a static import for `singletonList`.
as above -- add check for two missing clients
Do we need to do this `close` and `open` here? We do it also on lines 283 & 286
nit: add a size? There are a few cases in here where we could do this.
`nodes` is not a good name -> `subTopologySourceNodes` is better.
nit: move this `if` statement below/above version check on line 62
nit: use static imports to get rid of `Assert.`
nit: as mentioned elsewhere, I don't think we need to add all of these exceptions to the method. They are all runtime exceptions, so it's still up to the user to read the docs.
would be nice if this was a method in the config
Does this mean you manually assign this consumer to read all partitions? So the consumer group id doesn't matter or is not used? I couldn't see where a consumer group was being set. That means that each instance of this code consumes the entire topic, right? Which is exactly what you want. I ask because I have many use cases where I want a consumer to get all partitions. We currently do it by trying to create unique consumer group ids, but that is kind of annoying.
Fair enough, let's keep it inside StreamThread for now. In a longer term refactoring, maybe we could have an StreamsUtil class where such static functions / fields can be stuffed in.
req: This is unnecessary
I'm fine as well, will make a reference to 10055 of this PR
topics is a Set. What's your intention for the second parameter ? If you want the number of topics logged, you should use topics.size().
I'd clarify to sth like: > 2) use general data types (here: JSON; but can also be Avro generic bindings, etc.) for serdes in Kafka Streams. To make it clear that this example does not showcase Avro usage.
Can we change the naming to use `ALL_CAPS`? For example, compare with the definition of `RemotePartitionDeleteState` in this PR.
Why replace `null` with `"null"` ? (similar for value)
No, what I was suggesting is to add synchronization to the methods inside `Heartbeat` itself. For example: ``` public synchronized long timeToNextHeartbeat(long now); ```
I would remove `will`: `This tool reset[s] offsets` same below
> Hmm, for production, do we ever restart a thread even for illegal-state or illegal-argument? If the user decides to restart a stream thread in its exception handler it is possible.
I just realized, that we use different wording for topics as array of Strings and topic pattern: "there is no ordering guarantee" vs "there are no ordering guarantees" -- I think we should clean this up for consistency. Would you mind to add this fix to this PR? The singular version sounds better, IMHO.
Also, it seems like our convention for docs versions is quite bad. If we didn't want to use `.`, we could use something else like `_`.
Just copying over the suggestion to here, so it's easy to find ```suggestion final Throwable throwable = assertThrows(NullPointerException.class, () -> supplier.get().process(record)); assertEquals(throwable.getMessage(), String.format("KeyValueMapper can't return null from mapping the record: %s", record)); ```
Good that we have a test case where the expected output is hardcoded instead of generated by the test (avoids issues where a bug in the construction of the string can cancel out a bug in the parsing code. :)
We don't use ReplicaNotAvailableException in listTopics
I think it'd be useful to verify the behavior of casting all of the logical types to strings, just so that we verify the formats (e.g., timestamps, times, and dates should use the ISO 8601 representation) and have some regression tests for the future to help ensure we maintain backward compatibility.
I know, but you can save it in a static final.
+1 on assuming a single children, check-and-throw-otherwise
@rhauch I don't believe that's the effect the code here has. In the method call: ```java assertEquals( connectorName != null, connectorName != null ? context.startsWith("[" + connectorName) : false ); ``` if `connectorName` is null, then both arguments are guaranteed to evaluate to `false`. I think your intent may have been something like this: ```java assertEquals( connectorName != null, context.startsWith("[" + connectorName) ); ``` which would probably be acceptable, but may also benefit from a `message` that clarifies the expected behavior, possible something like `"Context should begin with connector name if and only if connector is non-null"`
Yes, does not hurt to leave it. Just for sure.
Nit: space missing after `for`.
nit: move below the shortcut return below.
At this point we have a lot of repeated code with `toRst()`. Would probably make sense to refactor to share the majority of the code for each config's main set of fields.
nit: I would rather use the full name instead of using acronyms.
Let's be consistent and just use string concatenation for both fields.
Similarly here, this state check could be internalized.
As mentioned above, we can make this constructor default access.
From my understanding, neither the `ConsumerRecord` nor the `ProcessroRecordContext` are the issue, but the shared `Header` object -- it's just a "side effect" that creating a new `ConsumerRecord` creates an new `Header` object internally.
@mumrah Have we considered dropping the `PartitionData` class entirely in favour of using `FetchRequestData .FetchPartition` directly in the broker? The main difference is that `FetchPartition` does not have an `Optional` for the leader epoch but returns the default value (-1) instead.
nit: missing . at end
Not a big fan of variable shadowing, which below you avoid by calling the local variable `tCompletableFuture`. Probably good idea to apply the naming here to and remove `this.`
Nit: var should be named `deserializeValue`
Should Builder pattern be used for the Sender ? That way the code is more readable when new parameter is added.
Should this be `num_lines=3` (cf. L116 and L126)
Cool, I was kind of hoping you would put this in a separate integration test class
We could use `SortedMap` (or even `TreeMap`) here instead of the generic `Map`. Then we wouldn't need the ugly cast below.
Effectively what we are doing is sorting the assignments for each partition using the generation and picking the latest two for the current and previous assignments. Is that right? Could we simplify the logic by building a `SortedMap<Integer, String>` for each partition where the key is the generation and the value is the memberID? Then the current assignment would be the last entry and the previous assignment would be the one prior.
This class is public API, so we cannot remove `setTimestamp` but can only deprecate it. We also need to update the KIP to mention the deprecation and the newly added methods.
req: `subscription` -> `subscription info`
nit: remove newlines
nit: it's a small thing, but the assertion failure message is more useful if we use the `Errors` type. ```java assertEquals(Errors.NONE, Errors.forCode(createTopicsResponseData.topics().find("foo").errorCode())); ```
Should we mention this in the KIP? It was not specified there - even though this is the same behavior as the old AlterConfigs, in the context of the KIP this non-transactional functionality isn't obvious I fear
You could probably create the `StreamsConfig` in an `@Before`
nit: as in `position` below, `this` is not required
Could you add a flag after ```producer.flush()```? We should make sure ```producer.flush()``` fails.
I'm not sure this is a good idea. If we're unlucky, the partition we're interested in may not be listed. Since this is an exceptional case anyway, I would suggest using the more verbose message.
There are some reason to move from varargs to Collections? It's breaking a lot of projects.
I think upon close(), we can also use `maybeAutoCommitOffsetsAsync` and then we can remove the whole function fo `maybeAutoCommitOffsetsSync`.
IMHO the `close` method is little easier to follow by putting `if(clean)...{ }` block in a private method, possible name `closeIfClean(clean, task, t)`
@showuon I just looked at the implementation of 'topLevelError' and I realized that it checks the partition errors as well. Therefore, it seems that we don't need to check them again afterwards. Sorry for this. I was not aware of this.
I think this is the issue you reported in the Jira. The `RaftClient.Listener` should not use `RaftClient.leaderAndEpoch` to determine if it is the leader. It should instead use `RaftClient.Listener.handleLeaderChange`. For this state machine `ReplicatedCounter` we should look at the `claimedEpoch` variable. I am going to create an issue to remove this method. cc @hachikuji
For some test cases we may want to use the same `MockTime` object on both server and client, for example in window store changelog truncation (cc @dguy ). So instead of creating the object internally we may want to pass it through parameters.
I feel we do not need the "topic-" prefix for the tag value as it will be shown as "tag-key"-"tag-value" already.
nit: replace with `this(new RequestHeaderData(struct, headerVersion), headerVersion)`. Consolidates c'tor logic to one place.
Out of curiosity, why do we do this here? In the normal case, we only update the position of the duplicate buffer, it seems.
Hmm, why do we still keep it? Based on the reviews for previous version, I believe that there is some strict ordering for getting `localMetadata` initialized to be non-null on L352 first before hitting this logic, but still a null check sound more resilient to me, unless we want to have a NullPointerException to be thrown explicitly.
nit: can we make this `if startTime == 0` ? That seems slightly easier to understand, and then all the conditionals can be in terms of startTime which is a bit more intuitive since that's what we're iterating over. Context switching between startTime and endTime kind of makes me lose my train of thought
This isn't used in this class. Probably should move to `AssignedStreamsTasks`
I like this cleanup, but I think we still need the `null` check. Since it's possible for the value to be `null`, we should probably be defensive about it. Or were you thinking that we should just let the `NullPointerException` occur and kill the connector? Something in the middle of these two cases might be to log a warning so hopefully the connector developer can fix their code. (The only reason we even need to validate this is due to the `SinkTaskContext.offset(Map<TopicPartition, Long> offsets)` variant, the single partition variant with `long` obviously doesn't have the same issue.)
When I suggested it, I thought we could do a bit better, maybe something like `(id: 5, www.example.com:9123)`, but maybe that's actually worse.
Perhaps: > The record consumed from the input topic has an invalid (negative) timestamp, possibly because a pre-0.10 producer client was used to write this record to Kafka without embedding a timestamp, or because you are reading from a pre-0.10 topic after upgrading the Kafka cluster to 0.10+. [...]
Also kind of a nit, since technically this does work, but wouldn't it make more sense to just remove the `advanceNowAndComputeLatency` call in `maybeCommit`, and then just call `advancedNowAndComputeLatency` here as before? Otherwise we're just computing the latency inside `maybeCommit` for no reason, and throwing out the result.
nit: remove -- not used
Ditto here, we can use AssertionError
There's one extra thing to do. We should set `minTime = MAX` before opening the `store.all()` so it resets the minimum in case there are no records available in the iterator. This is an example I run: I have a few records in the shared state store (1,5,7). Then a new record arrives that expire all the 3 records. Record 50 for instance. For each record, the minTime will be set to 1, then 5, then 7. Now for every new record after 50 that is still part of the window, the condition at the beginning of this method `minTime > maxStreamTime - ...` will be false, thus opening the iterator again and again. If we reset the minTime to MAX, then the next time, the iterator will be opened, but no records will be available, so minTime will stay in MAX. And the future records that do not expire will not open the iterator because `minTime (MAX) >= maxObservedTime - ...`
Should we start with 0 credit or the full burst credits? The benefit of the latter is that during initialization, the requests won't be throttled as much due to a cold start.
nit: maybe use meaningful names? e.g. `topic_creation_start` Even better would be to add some kind of `timed` function
probably better to just create a method that returns the principal name and host. might be easier to extract all of it using a simple pattern matcher instead of going through bunch of indexofs and substrings.
Why do we need this? This is logged anyway.
`than` -> `that`
Do we need to test this -- seems to be not part of this test method and should be it's own test, if we don't have one yet.
@mjsax I think I'm sold on your arguments, let's keep them as WARN then :)
How about setting initial size of `records`? `new ArrayList<>(ids.size())`
We should check `stream` parameter is not null here.
Nit: "For instance, the transactional APIs require brokers with version 0.11.0 or newer."
The implication here is that wakeup won't work if you've fetched data and keep calling poll() when you have max records set small, right? This seems like it could be a problem for anything that takes a long time to process messages since the wakeup may be an indicator that the application needs to shutdown...
Ideally, we'd always use brackets on control flow operators.
Since this is basically just a pass-through method anyway, there isn't that much to test here -- you could simplify this test just to use a simple set of connectors you create yourself. There's a lot of code in this test when all you really want to see is that the set makes it back out of the call to ConnectorPluginsResource
> Mainly because I was more comfortable verifying that topics actually get created when using repartition operation. I guess that is fair. (I just try to keep test runtime short if we can -- let's keep the integration test.)
This approach seems pretty weird. Are we modifying state in `ConfigDef` during validation? I feel like there are a few different issues with this -- it won't be thread safe, it ties state to the `ConfigDef` that shouldn't really be part of it, and it allows different config validations to get conflated. Why would we even be modifying the config keys in validation? Seems like validation should only generate `ConfigValue` objects.
I guess we could pull this into the `partitionsAutoAssigned` block.
nit: should be `named` can't be null
Thanks for the explanation. A bit subtle as you had said. :)
Alternatively, we can change the first arg `KeyValueMapper<K, V, K1> keySelector` and the second arg `KeyValueMapper<K, V, Long> valueSelector`. If we define special value selector classes, `LongValueSelector<K, V>` whose apply method returns `long` (not `Long`), `DoubleValueSelector<K, V>` whose apply method returns `double` (not `Double`) and so on, we can overload the `sum()` method and allow summing over different data types (and avoid object overheads), I think. In this case, SumSupplier is no longer a subclass of AggregatorSupplier.
This looks unintentional.
The log level is a tricky one. In the producer, messages for errors are all at debug level (for instance when we transition to error state in the transaction manager). So having this higher than debug may not add much value.
Hmm.. I was looking into how the producer handles various operations after the call to close(). Unsurprisingly, there is a bunch of inconsistency. For send(), as far as I can tell, the logic looks like this: 1. Check whether the sender thread is closed and raise an error if it is 2. Refresh metadata if needed 3. Check if the accumulator is closed To be honest, I don't know why we don't just check if the sender thread has begun shutdown, but perhaps that's a separate issue. For transactional requests, it seems we don't currently do any checking to see whether the producer has been shutdown. At least I couldn't find any checks in `commitTransaction()`. To make this solution work, I think we should have those checks. Basically the user should see some kind of error indicating that the producer has already begun shutdown and the operation is no longer allowed. As it is, they would probably see an illegal state error indicating the transaction already began aborting or something. This could be a simple check in `TransactionManager` if we add a `close()` method as suggested elsewhere.
Using `admin = null` here allows to GC the unused admin instance earlier, right? Not a big gain, but also I don't see much benefit by using a variable such as `useAdminForListOffsets`
`... retry attempts due to timeout. The broker may be transiently unavailable at the moment. ..` Ditto above.
It seems we are using the same application id twice in `StreamStreamJoinIntegartionTest` ``` STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG, appID + "-outer"); ``` This might be the root case -- deleting all topics would solve the issue, too, as it prevent to start with a corrupted state.
nit: Add `.` at the end of the sentence.
Similarly `Consumed#toString` is not implemented either, we can remove this line.
We can return `false` on the first mismatch no need to check the rest of the arrays.
with in => within
I looked at it closer. I still think it's better to split them out, but I also don't think it's a correctness issue right now, so I'd be fine with merging what you have.
One of the annoying aspects of the code below is that we have a lot of redundant logic for constructing a call in the context of a previously failed call. I wonder if it would simplify the logic if we added a constructor which accepts the failed call as an argument and then adjusts `tries` etc accordingly.
nit: extra spaces after the `->`
Actually a more general question is that for assign(), is checking subscription.isEmpty() sufficient or not. Today we allow subscribe(empty_list) whose semantics is different from unsubscribe(), but they will leave the same state in subscription map.
```suggestion final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.emptyMap()); ```
Hi, may I ask why do you do `@link` instead of `@see` annotations? :)
The additional validation doesn't hurt, but it might be more natural to move this check into the `if` below since we don't actually cast unless the condition is true.
To get rid of the test failure, you need to change this: ```suggestion final KafkaMetric metric = metrics.metric(new MetricName("prefix-scan-rate", STORE_LEVEL_GROUP, "", tags)); ``` Sorry, the failure of the test is my bad. I missed the issue with the different metrics versions when I requested to change this in a previous review.
Also, I just looked at `ConnectRecord.toString()`, and it does _not_ print the schemas. I wonder if it's worth changing that to include whether the key schema and value schema are null; e.g., ``` @Override public String toString() { return "ConnectRecord{" + "topic='" + topic + '\'' + ", kafkaPartition=" + kafkaPartition + ", keySchema=" + (keySchema != null ? "..." : "null") + ", key=" + key + ", valueSchema=" + (valueSchema != null ? "..." : "null") + ", value=" + value + ", timestamp=" + timestamp + ", headers=" + headers + '}'; } ```
the changes to the optimizer code LGTM
I see what you intended. Thanks for the response.
I think people want to use a global store in DSL, too. And forcing people to call `build()` to add one, is not a good idea IMHO. (cf option (2)). Also, if you argue like this, we could remove `addStore`, too, because people can also add the store via `builder.builder().addStore()` -- however, in KIP-120 discussion, it was explicitly requested to add both methods to `StreamsBuilder` to avoid this pattern. Also note, people who are new and want to use a stateful process() will always ask: how can I add a store? There is not API on `StreamsBuilder`.
same question as above about moving this above the call to `configure`
Maybe use a semicolon instead: "task failure; 'all' changes..."
Nit: the method is `Transformation.close()`, not "stop". The log message should probably reflect that.
This should be three tests.
That does not sound right. If we throw a `StreamsException` the thread will die.
Good thought. Lag was originally proposed in the KIP, but it's not what we're using anymore.
This is an interesting question. One low-fi solution would be to think about using `equals()` (I think to pull this off, we'd need to introduce a requirement that serde/serializer/deserializers implement equals in a way that would be semantically sound for us. This would not be a back-ward compatible change. On the other hand, since callers actually subclass `Serde<T>` with a fixed type like `Serde<String>`, it actually should be available at runtime. I don't remember the hoops you have to jump through to get it right now, but I'll revisit it tomorrow.
Would this not be slightly better if we used `Errors.forCode` and then did a switch on the enum? Also, we should not compare to `0`, we should use `Errors.NONE`.
nit: add `{ }`
@nicolasguyomar We already log the memberId here as we log the entire generation object (which includes the memberId). This was changed recently: https://github.com/apache/kafka/commit/7e7bb184d2abe34280a7f0eb0f0d9fc0e32389f2#diff-15efe9b844f78b686393b6c2e2ad61306c3473225742caed05c7edab9a138832L504. Previously, it was logging the generationId only.
nit: Could just to `new ArrayList<>();`
Changing old version encoding would break our upgrade path, ie, all existing `encodeVersionX()` methods cannot be modified.
nit: in kafka we usually don't use `get`/`set` prefixes
I'd err on the side of not adding configs for now and only add them if we find a need, so this seems fine.
I think we should probably retry on coordinator level errors. Take a look at some of the other consumer group APIs to see how we handle errors. For example, see `ConsumerGroupOperationContext.hasCoordinatorMoved`.
Not sure if it makes sense to convert a `TimeoutException` into a `TaskMigrated` exception... Also note that we created https://issues.apache.org/jira/browse/KAFKA-7932, so it might be best to tackle all Streams related changes there? \cc @vvcephei
The fact that we're ignoring it suggests that it's not an `error`. For something that indicates something unexpected has occurred, but that we can handle it and continue correct execution, we should use `warn` level. Also, the type of exception will be captured in the stacktrace, so I would just say something more descriptive like, "Channel closed unexpectedly before lock release."
https://github.com/apache/kafka/blob/trunk/core/src/main/scala/kafka/log/LogConfig.scala#L150 can reference to this new field.
Changed this to generate a name `<userName>-cogroup-merge` to align to `<userName>-cogroup-agg-<counter>` instead of just `<userName>` for the merge node.
Like DescribeGroups, we need to find the coordinator for the group to send the OffsetFetch request to.
Shouldn't we pass the time remaining before the timeout to this call? Similarly, we should take the timeout into account when backing off after a failure.
Nit: `describeTopics(Collection<String> topicNames, ...)`
Nit: might be worth adding a simple assertion on the result just to make sure.
Yes, this seems fine then.
nit: fill in `@return` docs
This should also be synchronized
We should spell out that if the string is empty, it's because the remote end didn't send this information
Should this be included here, or should it refer to a dedicated section in the connect docs? I guess there's two cases: bootstrapping a whole new connect cluster, or upgrading an existing one. For the bootstrapping case it's not completely clear whether the "preparing" round is required.
I feel a bit weird here as we don't need `prepareCloseClean` anymore. This API usage is a little complicated upon when we should do it and we don't.
remove "on a window basis"
We can make this clearer if it helps. Maybe something like FullFetch? Not sure if there is a better option
In `transform()` we have a sentence: ``` The {@link Transformer} must return a {@link KeyValue} type in {@link Transformer#transform(Object, Object) transform()} ``` Might be good to add this here too and point out it might be a an `Iterable` plus example. Compare `flatMap()`: ``` * The provided {@link KeyValueMapper} must return an {@link Iterable} (e.g., any {@link java.util.Collection} type) * and the return value must not be {@code null}. ```
Ah nvm then --- let's just keep it out of the scope of this ticket for now.
It's a bit awkward to modify `onJoinPrepareAsyncCommitFuture` inside the `maybeAutoCommitOffsetsAsync` function since the function name itself indicate a general purpose, but specifically for join-prepare --- though I understand today it is indeed only used for that caller. How about letting the `maybeAutoCommitOffsetsAsync` to return the future instead of the boolean, and then let the caller a.k.a. the `onJoinPrepare` today to check if the future is completed or not.
Do you mean it should NOT be included...
Would it be cleaner to just close/remove the task producer inside `tryCloseCleanAllActiveTasks`? Could we just close/remove the task producers before closing clean or do we specifically need to close them first? I don't remember...
Nice one on projecting the value!
Double.valueOf not required, auto-boxing can be used. Here and in the lines below.
If `taskId == null` we should call `break` to terminate instead of finish the whole loop.
I think we should probably include information about the received `kerberosName` in the error message and use `principalToLocalRules.toString` instead of `toString`.
Below we break into `brokerResources` and `unifiedRequestResources` and send two requests; we should check them and skip if possible respectively.
recommended; ditto below.
Perhaps replace this NOTE with `If the configuration is not null, it will have been transformed...`
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
That's a good idea. Note: Kafka does not use this JUnit functionality yet (i.e. no use of ExternalResource, ClassRule, Rule as far as I can tell). @ijuma: Would it ok for us to introduce this? There's no additional dependency etc., it's just using a new JUnit feature that was introduced in 4.7 (we're on 4.12).
do we need this invalid config step here
This is an internal class -- no need to mark as deprecated.
Not sure if it makes a big difference, but we could use EnumSet for these.
Nit: param alignment.
nit: `java.util.` can be removed (note, we only specify the whole package for `Topology`, because otherwise we would need to add an `import` statement and get a warning about "unused imports" and a failing build.
Again, `ConfigProviders` doesn't make sense here. The `config.providers` property is listing the _names_ of the ConfigProviders, whereas the other `config.providers.<providerName>.class` (for example) specifies the name of the `ConfigProvider` implementation class for the named provider. IMO, we should use the term `ConfigProvider` to mean one of two things: 1. The name of the `ConfigProvider` interface 2. The instances of the `ConfigProvider` implementations that are instantiated by this class. Always using "instances" in these cases will help disambiguate the use of `ConfigProvider`. Also, it's probably worthwhile to begin this paragraph with: > The "{@code config.providers}" configuration property and all configuration properties that begin with the "{@code config.providers.}" prefix are reserved. The "{@code config.providers}" configuration property specifies the names of the config providers, and properties that begin with the "{@code config.providers.<providerName>.}" prefix correspond to the properties for that named provider. For example, the "{@code config.providers.<providerName>.class}" property specifies the name of the {@link ConfigProvider} implementation class that should be used for the provider.
Thanks for clarifying this.
Fair enough given the complexity of the setup. I guess what disturbs me most is the fact that the setup is so complex.
Also kind of a nit, since technically this does work, but wouldn't it make more sense to just remove the `advanceNowAndComputeLatency` call in `maybeCommit`, and then just call `advancedNowAndComputeLatency` here as before? Otherwise we're just computing the latency inside `maybeCommit` for no reason, and throwing out the result.
You should use try with resources here too.
This should be: ```suggestion final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1); ```
Ditto on removing these before/after methods.
We should also validate (in our tests) that the user cannot modify the underlying stream because, as I understand the proposed semantics, "an unchanged stream" is an invariant we want to guarantee as part of the contract.
For transition to `NOT_RUNNING`: the instance will only shutdown if the user uncaught exception handler decides to shutdown the whole instance, by calling `close()`, in this case it will still go through the `PENDING_SHUTDOWN` transition first? For `REBALANCE -> REBALANCE`, this is related to the thread-level `partition revoked -> partition revoked`, which I'm still wondering if we can avoid. Let's sync a bit on that.
req: Could you please rename `StreamsMetricsImpl metrics` to `StreamsMetricsImpl streamsMetrics` and then format the code like this ``` final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, "test", StreamsConfig.METRICS_LATEST); ```
How about the following to simplify the string construction below: ```java String clientEnabled = System.getProperty(ZK_SASL_CLIENT, "default:" + DEFAULT_ZK_SASL_CLIENT); String contextName = System.getProperty(ZK_LOGIN_CONTEXT_NAME_KEY, "default:" + DEFAULT_ZK_LOGIN_CONTEXT_NAME); ```
Need to check if `group` is `null` in both `k1` and `k2`. Using this on, e.g., `DistributedConfig` from Kafka Connect doesn't currently work.
```suggestion public void setUncaughtExceptionHandler(final StreamsUncaughtExceptionHandler uncaughtExceptionHandler) { ``` We prefer to resist the urge to abbreviate, especially in the public-facing APIs.
nit: we can throw illegal-state if the state() == RESTORING since it should never happen.
The typo is still there.
nit: I don't feel strong about the style here, but maybe we should consider align with other functions which has the first parameter on the same line with function name.
Similarly here, I think we can move these checks into `TransactionManager` and just pass the batch.
nit: we can throw illegal-state if the state() == RESTORING since it should never happen.
Hm. What if we hit a TaskMigratedException during `handleRevocation`? We would never finish committing them so `commitNeeded` would still return true and `prepareCommit` would return non-empty offsets right? It's kind of a bummer that we can't enforce that the task was committed. What we really need to do is enforce that we _attempted_ to commit the task -- regardless of whether or not it was successful. If the commit failed we know that either it was fatal or it was due to TaskMigrated, in which case the task will have to be closed as dirty anyways. This might be beyond the scope of this PR, but just to throw out one hacky idea we could add a `commitSuccessful` parameter to `postCommit` and then always invoke that after a commit so that `commitNeeded` is set to false. (If `commitSuccessful` is false we just skip everything else in `postCommit`)
Looks like this constructor was removed? We can't remove public constructors from a class in the public API.
AK convention is to not use `set` setters or `get` getters.
Testing against log message is error-prone and hard to maintain, I think just making sure the thrown exception type is expected should be sufficient.
Should we still do `taskManager.setClusterMetadata(fullMetadata);` before returning? I'm not sure if it will give us any good but just bringing this up..
as above `final` and one parameter per line
nit: empty line.
It seems to be added on line 703.
We could port this function when it is actually needed.
This message is a little strange. We can certainly represent the topic id, but it is invalid. I wonder if it would make sense to raise `IllegalArgumentException` directly instead of through the result since this is likely a logical error of some kind.
Discussed offline. This can instead be the producer's retry count. If the retry count is zero, then we will have to allow for at least one metadata request past its max age. So the staleness threshold will be: `retryCount * (backoff + requestTimeout) + maxAge`
> I ignore 1 out of every 2 punctuations Uh. That's kinda painful... I think we need to discuss this in more details, ie, what semantics we want to provide. \cc @bbejeck @dguy @guozhangwang @miguno
Why remove the empty line? It make it harder to read the code, as logical blocks are separated by blank lines atm. (similar below)
yes, it seems to be not what this test is checking on. I think we can drop it here.
@ewencp Yeah, we can do that and I was debating whether I should suggest it. I wasn't sure if we wanted to make a change that could impact the common path so that the error message could include the thread name for the `currentThread`. You reviewed the original commit that introduced `acquire` and `release`, so you are in a better position to judge. :)
@hachikuji @tedyu @ijuma OK, I am going to revert and commit for now. We could improve on it later if we make updates to the code again.
It seems that we compare with this value to check if there is no leader or epoch. It's a bit more robust to check if both `leader` and `epoch` are empty, no? Then it still behaves correctly if we have some code that passes empty to both constructor parameters.
The DescribeGroup API has to be sent to the group coordinator, which is potentially a different node for each group. You use the FindCoordinator API in order to lookup the coordinator for a given group. The logic should be something like this: 1. For each group in the request, send a FindCoordinator request to any node in the cluster. 2. Group the results by coordinator id. 3. Send DescribeGroups to each coordinator from 2. Ideally, we should also handle retries correctly. It could happen that the coordinator moves to another node by the time we send DescribeGroups. In this case, the error code will be NOT_COORDINATOR. We should handle this by looking up the coordinator again.
Nit: fix line break
Why remove the empty line? It make it harder to read the code, as logical blocks are separated by blank lines atm. (similar below)
validateStoreOpen() can be outside of lock block.
That's a good point.
It would be better to use `NetworkTestUtils.checkClientConnection(selector, node, 100, 10);` which actually uses the connection.
This does not really align with the name of the test. Is it intentional to have it? The test basically verifies that the first request is failed with an `UnsupportedVersionResponse` error and that the second request does not get any response.
nit: not related to this PR, but the above `TODO` can be renamed as `TODO KIP-300` to be more specific.
Nit: ```suggestion * @return list of {@link ConfigValue} instances that describe each client configuration in the request and includes an {@link ConfigValue#errorMessages error} if the configuration is not allowed by the policy; never null ```
getters should not use get. i.e. use `networkDevice` here, etc.
It's a fair point that `Cluster` is public and we should be careful about what we add there.
add `final` twice
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
This was the checkstyle error that was failing your build.
We should test settings with the `source.cluster.` prefix too. Same in the test below
Don't we need to keep the existing methods for backward compatibility? We could perhaps deprecate them.
nit: use `logContext
This should probably just return a boolean
`postCommit` only writes a checkpoint for non-eos. Thus, we still need to write a checkpoint in `close()` for the eos-case (if just blindly for all cases as we do atm).
Would we want to consider building the `Set` the first time this method is invoked then caching for subsequent calls? Although looking at the code this doesn't seem to be on a hot code path and the task assignments could change, so I'm not sure. The same goes for the method below.
Could you try to factor out some setup code? For example, in each test you create and initialize the names of the topics, member IDs and the consumer IDs. You could initialize a bunch of topic names and IDs globally and reuse them in the tests. Another example is the creation of `partitionPerTopic`, which is really similar in all tests, only the number of partitions vary. Factoring out setup code, would make the tests more readable IMO.
We need to be able to remove just a few specific metrics without disrupting the others, while also making sure to actually close/cleanup during an actual shutdown
I might be mistaken, but this doesn't seem sufficient. It seems like we should compare the out of range offset with the current consumed position and only throw the exception if they are equal. Presumably if the user has seeked to a new position, then they wouldn't be interested in an out of range error from a previous fetch.
Nit: remove `this` (we try to avoid `this` wherever possible)
`while` seems to be missing
make this into a different test, i.e., `shouldSupportNullInFloatSerde` or similiar
This was not addressed yet. the whole sentence can be removed
Note this correction
Sorry for my denseness... Why are these "not re-assigned"? They're part of a data structure called "assigned tasks", which seems to imply that they are assigned.
Incase => In the case
Below we break into `brokerResources` and `unifiedRequestResources` and send two requests; we should check them and skip if possible respectively.
nit: I think it's better to just print the e.message in a single line.
I had a look at this and your are right. It seems that keeping `TopicPartition` is better and difficult to change. In this case, have you considered pushing the conversion to the `Builder` by providing an overload of `setTargetTimes` which accepts a `Map<TopicPartition, ListOffsetPartition>`? That could make the code in the `Fetcher` a bit cleaner.
Do we need to clear it here? I feel it is unnecessary as it will be cleared in `reset` anyways.
Should this be included here, or should it refer to a dedicated section in the connect docs? I guess there's two cases: bootstrapping a whole new connect cluster, or upgrading an existing one. For the bootstrapping case it's not completely clear whether the "preparing" round is required.
Not required. Client will be automatically closes, as we use Java's "try with resource" feature.
I think we do not need to back off here, since the request will be parked in the queue anyways during retries.
Nit: move into the `if` block where it is used. (also add `final`)
Isn't this a behavior change? IIRC, we had a discussion to do this change, or to maybe make it configurable if we want to interleave processing with recovery.
nit: add a blank line before this one to make it easier to read
never mind then. I'll leave this to AI.
I don't think we need all this, if we delay adding the store to `writeToTopology()`
Should have thought of this before, but `CollectionUtils.groupDataByTopic` already does this.
@cmccabe (My suggestion might not be good) If it has to check `futures`'s `size` every time, what about assign one time and use many times? Because JVM has to calculate size everytime when it is called. ```suggestion final int futuresSize = futures.size(); if (throwable == null && results.size() != futuresSize) { ```
This test doesn't seem to belong here. The test class is `InMemoryKeyValyLoggedStoreTest`, yet the test is `shouldCreatePersistentStore` If anything this should be moved to `StoresTest`, but maybe it is already covered
Nitpick: Is there a better term than "join-tuples"? Perhaps we should highlight a bit more that that we return tuples of values (but e.g. not of keys).
Do we really want to always set like this? What's if a user want to provide a custom Long-Serde that just works fine? Maybe we should only overwrite if value serde is `null` ? It's just a thought -- not sure about it.
This dates before this PR, but while reviewing it I realized that line 898 in prepareTopic: ``` topic.setNumberOfPartitions(numPartitions.get()); ``` is not necessary since the `numPartitions` is read from the topic.
nit: remove empty line
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
Oh yeah, duh. Nevermind this 
We need to call `transactionManager#failIfNotReadyForSend` here, so that we don't try to append to the batch when we are not ready to send. Also, we should remove `failIfNotReadyForSend` from `TransactionManager#maybeAddPartitionToTransaction`
This would require a separate KStreamVoidTransformProcessor, but I feel it worth the internal cost for simpler public APIs.
Nit: line too long
There are two input streams in this test, and thus we should create a second `TestInputTopic` to pipe input via both.
Is just checking leaderNotConnected enough? For example, the leader connection may be fine, but a batch can't be sent to leader because the max inflight requests to leader has been reached. In this case, it seems that we can timeout a batch in the accumulator before those that are still in flight. Also, would it be simpler to implement this based on muted partitions? If a partition is muted, we know there is still an outstanding request for the partition and we can disable expiring batches from that partition. This only applies when guaranteeMessageOrder is true, but is probably what we care about anyway.
@mumrah Have we considered dropping the `PartitionData` class entirely in favour of using `FetchRequestData .FetchPartition` directly in the broker? The main difference is that `FetchPartition` does not have an `Optional` for the leader epoch but returns the default value (-1) instead.
Seems like `assertFalse` would be more appropriate here. There are a few cases like that. Also, it would be good to verify the buffer contents.
We should also mention somewhere that we do not support concurrent transactions.
I think you'd want to use actual listener ports, not the JMX one. The JMX one is presumably opened very early when the process starts, but we want to make sure the Kafka service is actually up, running, and ready to serve traffic. That's why the previous version was checking for a message that happens much later in the startup process.
Safer to check `is not None`
nit: I would move this block up, before calling `listOffsets`, in order to have the response ready. Same for other tests.
I wonder if more of this code is generic and should be pushed somewhere else.
This was changed to`INVALID_PRODUCER_EPOCH` in the kip. Let's change it here too.
you don't use `windowedDeserializer ` or `inner` below -- can be removed IMHO
+1 -- also note that this sort of only makes sense when using the named topology feature, as otherwise you don't have multiple topologies and not really any reason to set any of these configs differently in the TopologyConfigs vs StreamsConfig passed in to the KafkaStreams constructor. That said, it will definitely happen, so I guess we should check for overrides whether the topology is named or not. Maybe you can use the `isTopologyOverride` method, and remove the check for `namedTopology ~= null`? ie, you can/should use `isTopologyOverride`
Should this be `num_lines=3` (cf. L116 and L126)
```suggestion @Evolving public class WindowKeyQuery<K, V> implements Query<WindowStoreIterator<V>> { ```
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
iiuc, this is actually the bug that we are fixing here. On the current trunk, if flush or cache.close throws, we do _not_ close the wrapped store. Now, with this change, we still call flush, cache.close, and wrapped().close, regardless if some of them throw.
Ack, makes sense. I'm fine with either approach, although looking at the next few lines it doesn't look like there's a good, single place to reset it.
Nit: ```suggestion throw new ConfigException(String.format("Invalid header name '%s'. " + "The '[header name]' cannot contain whitespace", headerName)); ```
Map.Entry<String, String> to avoid the check below
nit: the previous location seemed a little better since it was listed next to `autoCommitIntervalMs`.
Sounds good. I think this is convincing :)
nit: we can keep the send() call without the partitioner argument which will then call this function with null.
req: Could you use not the same topic partitions for the changelog topic partition as for the assigned topic partitions? It had a hard time to understand that those topic partitions are just there for convenience. At least give them new variable names with a more realistic naming. Maybe you could also vary the number of topic partitions in the maps from 1 to 3.
This warning seems to miss the most likely scenario, that the user just passed the arguments in the wrong order.
Do we need to validate twice before grabbing the lock? Maybe only the validation at line 283 is sufficient.
same question here and below about locking around a `volatile` variable. Is this the only reason to lock here? One would think so based on previous usage.
`{@link TimestampedWindowStoreBuilder}` should probably be `{@link TimestampedWindowStore}`.
Nit: capitalization isn't quite right, see `reauthenticationLatencyMs` for example.
nit: `toString` can be used implicitly
nit: add a size? There are a few cases in here where we could do this.
`Constructor<List<T>>` (or `Constructor<L>` if we introduce `L`)
nit: could be useful to log the type of exception in the assertion message.
Compiler still gives some warning here, as you are erasing here the java generic type. Adding the `<>` infects the rest of your code with the `? super T` you have to add at the correct places.
Any reason this isn't in `setUp` since it's needed for every test? Also, is there a reason `MirrorMaker.start()` isn't using the `wait_until` to wait until the node comes up? Seems like all callers of `start()` would want this functionality.
Just one minor point, if we don't have EOS enabled, we could end up pulling duplicates in some tests like the `StreamsUpgradeTest::upgrade_downgrade_brokers`
I think, it would be good to verify that a second call to `peekNextKey()` right after the first call to `peekNextKey()` returns the same value, since this is the main difference between `next()` and `peekNextKey()`.
This does a system call every time. We can use `InputStream`'s `readAllBytes`: https://github.com/openjdk/jdk/blob/master/src/java.base/share/classes/java/io/InputStream.java#L389
Yes, I think we ought to use a Kafka schema definition even for the user data so that we can avoid dependence on java-specific serializations.
Sorry, I found we already log the error in `autoCommitOffsetsAsync`. We should remove the logging here. And make the if condition simpler as: ``` if (future == null || future.succeeded() || (future.failed() && !future.isRetriable())) { onJoinPrepareAsyncCommitCompleted = true; }
Why this and other 4 tests below cannot reuse the `runGenericBenchmark` common function? It seems it is not necessary to use a separate thread for these tests to distinguish them from others that can leverage this common function.
You can use the default constructor `ReplicationControlTestContext ctx = new ReplicationControlTestContext();`
@dguy @enothereska This `synchronized` here seems suspicious. Is it really the aim to synchronize on the listener instance when updating variables like `threadState`? Seems like a bug.
I think we should probably include information about the received `kerberosName` in the error message and use `principalToLocalRules.toString` instead of `toString`.
I've logged https://issues.apache.org/jira/browse/KAFKA-12380 for shutting down the worker's executor. Again, it's not an issue in runtime, but a *potential* issue in our tests.
OK, makes sense. Didn't know about policy of internal checks. Would be good to have it written down somewhere.
That makes sense. I did not think about the reconfiguration case.
I've seen this a few places -- `SchemaAndValue` already has `SchemaAndValue.NULL` field which does the same thing -- no need to repeat a bunch of times in a bunch of classes.
This should disappear with my suggestion.
`nodes` is not a good name -> `subTopologySourceNodes` is better.
I think we can refactor the logic here as the following: 0) suppose the received record timestamp is T1, the current stream time is T2 >= T1; and we found one or more matching record from the other side, with timestamp T1' <= T2' <= T3' etc. The joined record would have the timestamp of T1` = max(T1, T1'), T2` = max(T1, T2'), where T1` <= T2` <= ... 1) After we get all the joined records, we do not call `context.forward()` yet, but just cache them locally. 2) We then range query the expired records store, and generate the joined records (and also delete the records), again we do not call `context.forward()` yet, but just cache them locally. 3) We merge sort on these two sorted-by-timestamp list, and then call `context.forward()` on the sorted join result records to emit. In this we do not need the following complex logic.
fair enough :)
nit: `COGROUPKSTREAM-AGGREGATE -`
It will result in the same list of versions -- both equally good IMHO.
I guess both are acceptable solutions (ie, creating two repartition topics or throwing an exception). Your proposal is more user friendly but results in a more expensive deployment. The question might be, what do we try to optimize for? \cc @vvcephei @guozhangwang
Changed it locally.
Naming this the same as the one in `WorkerTest` is causing failures in `WorkerTest` because the search for the connector by reflection finds both classes.
above (some some more times below)
store not used
Same here. We should use `builder.stream().toTable()`
```suggestion log.debug("New average number of connectors per worker rounded down (floor) {} and rounded up (ceil) {}", floorConnectors, ceilConnectors); ```
Are you planning to add this? It should be straightforward once you set a limit on the maximum size.
You can click on the below links named "Details" to see the failure message. Also try using `./gradlew checkstyleMain checkstyleTest` to check locally.
req: no longer used
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
That was what I meant.
Can you please explain why it's better to warn than to fail-fast in this case? Just want to make sure I understand the reasoning for the choice.
This syntax is a bit hard to follow with the conditional at the end. Can you rewrite it to something like: ```python self.jmx_tool = None if jmx_object_names is not None: self.jmx_tool = ... ``` (and also check the attributes as mentioned above)
I don't think so. If `A` connects to itself, it's still a single node: ``` topology.addSource("source",...); topology.addProcessor("name", ..., "parent"); // throws because "parent" no added yet topology.addProcessor("source", ...); // throws because "source" is already used topology.addProcessor("processor", ..., "processor"); // throws because it connects to itself --- note that internally, we would add "processor" first before setting up the connection (ie, the parent is know then setting up the connection as we just added the parent) --- however, we do have an additional check in the code to throw if people build a loop like this ```
As this does not change, I wonder if we could direct initialize `consumerProps` when it's declared
FYI: There is the static nested class `Record` in `TopologyTestDriverTest`, that can be used to compare records.
I miss @shikhar!
Nit: To make sure we don't have any default/fall-back offset of zero encoded anywhere, it might be better to test with different offsets values for endOffset/beginningOffset and the target offset? Atm, if we would `seekToBeginning` as fallback instead of `seektToEnd` this test would still pass. Maybe best to just use 5, 10, 20 (or similar) for start, end, target.
Nit: we don't need this tag before the parameter list.
Let's use `Map` on the left side instead of `HashMap`
```suggestion ``` Do we need both of these debug messages? After all, `worker.assign(...)` is just adding a `ConnectorTaskId` to a collection. How about keeping the first one since this is at this point an on-going process and we've not actually assigned anything to the actual worker node.
Perhaps if the user configures a transactionalId, then we should enable idempotence automatically. We can raise an exception only if the user has explicitly disabled idempotence.
if you have an unsigned ~~8-bit~~ 16-bit data source
Actually `this.name` is still the processor node name, not the KTable name as mentioned in the JIRA. However, after thinking it a bit more, I feel there are a few corner cases when using the state store name may be cumbersome: even after KAFKA-3870 and KAFKA-3911 is merged, still not all KTables will be backed by a state store (for example, a KTable generated from another KTable.filter, which is just a view of the other table). And if we call `filter` on both of these KTables, they will actually share the same state store names, which are confusing. So just using the processor node name, admittedly are not very intuitive for users, may be the least bad solution here.
Personally I think it makes sense to just disallow calling `ofTimeDifferenceAndGrace(...).grace(...)` entirely, this seems like abusing the API
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
Nitpick: I'd call this `deserialize`.
> What would be the hint for `RetriableException`? The current hint seem to be appropriate.
Just some nitpick: we started to to order all configs alphabetically here -- it make it a little simpler to keep an overview and to maintain the code. Would you mind to not move configs that get deprecate and add the new config at the "right" place. Thanks a lot. :)
You can also remove the `@SuppressWarnings("deprecation")` at the top of the method.
Can you please explain why it's better to warn than to fail-fast in this case? Just want to make sure I understand the reasoning for the choice.
Why do we copy the result of `handleDeleteTopicsUsingIds`? Seems like that method is already returning a fresh map.
I believe we should surround this section of code with the following to be sure we never drop the last ISR member: ``` // never remove the last ISR member if (partition.isr.length > 1) { int[] newIsr = ... etc... } ```
key -> topic
Can just return `name.startsWith(acl.resourceName())`
Understand. That part can be refactored - goal is to reduce unnecessary comparison.
We can use `<>` in the right-hand side. Also, we can just pass the serializers in the constructor to make the example simpler.
nit: newline for better IDE debugging.
Actually on a second thought.. if users configures `-1` it means they probably do not care about enforced processing, while on the other side the INFO entry may flood the logs here. So NVM.
NPE: ![image](https://user-images.githubusercontent.com/925755/55269396-d55f3480-5292-11e9-9c29-78c524d63c65.png) I'm not using a topic pattern, equality should still work.
nit: add `final`
as above mentioned, the `listStore.all()` is not closed here.
@SupermanScott This change looks ok, but this is failing checkstyle: ``` :connect:runtime:checkstyleMain [ant:checkstyle] /Users/ewencp/kafka.git/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinator.java:280:1: File contains tab characters (this is the first instance). [ant:checkstyle] /Users/ewencp/kafka.git/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinator.java:282:21: '}' should be on the same line. [ant:checkstyle] /Users/ewencp/kafka.git/connect/runtime/src/main/java/org/apache/kafka/connect/runtime/distributed/WorkerCoordinator.java:293:21: '}' should be on the same line. :connect:runtime:checkstyleMain FAILED ``` Looks like simple indentation cleanup. You can easily check that these are fixed by running `./gradlew :connect:runtime:checkstyleMain`.
It should always be called from the same thread, though we've taken a simple approach to locking in this class where everything is protected as far as I can tell. This does technically introduce a behavioral change though, since `heartbeatThread` is being reset to `null` whereas it was not before, but this doesn't seem like a problem.
@dguy you'll need a lock for `putIfAbsent` too since the individual locks in put/get are not sufficient (e.g., value could change in between get and put).
Just a suggestion: ```suggestion Objects.requireNonNull(newPair, "The provided KeyValueMapper returned null which is not allowed."); ``` BTW, we should not output records since they might contain sensitive data.
How about instead keeping this private and only exposing `reOpenTaskProducerIfNeeded`, which would take care of doing nothing if there's no task producer, etc. I'm concerned that otherwise, someone might call `createTaskProducer` when there's already one there, leading to a "producer leak".
To clarify: the PR hasn't been merged yet. Note that if this change were to cause a problem for LZ4, we would have the same problem for GZIP (due to the JDK implementation). In other words, we have to ensure that the underlying output stream has a good `close()` implementation anyway since we support GZIP as well.
IMHO the `close` method is little easier to follow by putting `if(clean)...{ }` block in a private method, possible name `closeIfClean(clean, task, t)`
this could be: `assertThat(serializer.serialize(topic, null), nullValue())`
The order is not really that important here, either way works
This is an interesting discussion. I don't have the full context of these discussions, but I can see the argument for keeping things simple and letting users rely on the regular expression for achieving their goals. I am not sure if it's any simpler to provide two separate regular expressions than just one with the appropriate negation. The latter is easier to write a unit test for too.
Here you should just need a queue as for `clientLevelMetrics`. We need a map for the other levels because there can be multiple objects for each level, e.g., there might be multiple stream thread and each one manages its sensors under a key in the map. However, there is only one client on client level.
> and re-using the `KGroupedStream` results in an `InvalidToplogyException` when building the topology I thought, if there is no user topic-name, old code would create multiple repartition topics? And re-using `KGroupedStream` only throughs if there is a user topic-name (and this restriction is lifted with this PR)
No need to check null. We always have to forward oldAgg and newAgg, anyway.
I think it might be ok for `windowSize` to be greater than `segmentInterval` as the window will comprise multiple segments, but I could be wrong about this. \cc @guozhangwang @mjsax
make this into a different test, i.e., `shouldSupportNullInFloatSerde` or similiar
nit: "active tasks {}, standby tasks {}, suspended tasks {}, and suspended standby tasks {}"
It might be nice to keep the tasks/topologies that have failed in another list entirely. Then when reprocessing after an exception we can run all the good tasks first and commit them before running the failures. This will be important for EOS as we con't commit only part of a transaction. The larger part of that doesn't need to be done it this PR but keeping the groups separate would be nice in my mind
Maybe mention the advantage of using this over `Thread.sleep`.
ah, i missed that it was in the Validator and not ConfigDef itself.
If users specify the wrong processor node it will cause NPE, which is a bit hard to reason. Better check null on `child` and throw an informative error message before calling forward.
Unify "create task" code with `shouldThrowExceptionIfAnyExceptionsRaisedDuringCloseTopology` -- it's almost the same and both test cases can use the same topology structure.
Oh, we handled this in `throwIfOffsetOutOfRange` previously.
Should it be "...consumption...is coupled"? Currently it is "...consumption...are coupled".
I don't think we need this test as the previous tests already prove that the data is deerialized or not. So this is really just testing the same things
I think the idea is to verify that the actual version probing rebalance takes place, ie that the partition assignor actually handles the version probing once it's detected. And that it signals to the stream thread which also handles it correctly in turn. But idk -- I've probably broken and fixed the version probing test 2 or 3 times now due to this one line in particular. So, I'd be happy to see it go. I probably have too much bad history to make an unbiased call here though 
Typo: "you can create [a] windowed ..."
Infinite loop doesn't seem to make sense. Should this be re-written as? ```java protected Header makeNext() { while (original.hasNext()) { Header header = original.next(); if (!header.key().equals(key)) { continue; } return header; } return this.allDone(); } ```
To be realistic, the second parameter should be `Collections.singleton(topic)` rather than `emptySet`.
spelling -> recrord -> record
The logic for a valid topic name is actually a little more complicated than this. The server side validation exists in `kafka.common.Topic.scala`. We also shouldn't duplicate the logic. So if we move it to the clients package, removing the Scala version and replacing its usages would be good too. Also #898 (KAFKA-3219) may change this logic a little bit too.
It seems you can move this line after line422.
nit: 'else' can be dropped
Seems to fit in one line
I don't think so. If `A` connects to itself, it's still a single node: ``` topology.addSource("source",...); topology.addProcessor("name", ..., "parent"); // throws because "parent" no added yet topology.addProcessor("source", ...); // throws because "source" is already used topology.addProcessor("processor", ..., "processor"); // throws because it connects to itself --- note that internally, we would add "processor" first before setting up the connection (ie, the parent is know then setting up the connection as we just added the parent) --- however, we do have an additional check in the code to throw if people build a loop like this ```
what about `assertEquals("consumer record size is not zero", 0, records.count());`? It can also be applied in a few other places
It seems like your indentation is set to 8 spaces instead of 4.
Yeah if it exists elsewhere let's just leave it as is for now.
Look like a ProcessingContext builder method while it is not. Wouldn't it be better to keep this void
I see that you are actually printing the sink nodes. I'm wondering if this if condition is necessary since in line 85 this function will be skipped anyway.
@apovzner @dajac : Currently, we calculate the delayed time based on QuotaViolationException.value and QuotaViolationException.bound. I was thinking that we could pass some additional info in QuotaViolationException so that we could calculate the delayed time properly. Overall, it seems that decoupling the observation from token bucket based quota might be easier to understand. As for monitoring the remaining credit, we could add a separate metric. Also, it seems that quota only makes sense for rates. So, instead of making quota available on arbitrary measurable, we could just make it work for Rate.
As above. Not sure if we need this, as the store should be wrapped with `MeteredWindowStore`.
This doesn't look right..why would we need to pass in the `key` and `value` to `createRightWindow` ? The distinguishing feature of the current record's right window is that it doesn't include the current record at all. I see that `createRightWindow` ultimately calls `putAndForward` which takes a key and value, but that just seems misleading. I think we should either pass in `null` to `putAndForward` for things we don't need, or better yet (imo) don't use `putAndForward` for the right window creation and just have a clean separation between creation of the right window and everything else
Since we don't do coordinator discovery in this loop, do we need to reinitialize the `coordinator` variable? If the connection fails, then pending request count should drop to 0 already.
nit: We should use `groupId.idValue` here and in the others.
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
How about putting the `server.stop()` and `server = null` in a finally block? Also, `CloseableHttpResponse` is `AutoCloseable`, so we could actually use a try-with-resources here: ```suggestion server = new RestServer(workerConfig); try { server.initializeServer(); server.initializeResources(herder); HttpRequest request = new HttpGet("/connectors"); try (CloseableHttpClient httpClient = HttpClients.createMinimal()) { HttpHost httpHost = new HttpHost(server.advertisedUrl().getHost(), server.advertisedUrl().getPort()); try (CloseableHttpResponse response = httpClient.execute(httpHost, request)) { Assert.assertEquals(200, response.getStatusLine().getStatusCode()); if (!headerConfig.isEmpty()) { expectedHeaders.forEach((k, v) -> Assert.assertEquals(response.getFirstHeader(k).getValue(), v)); } else { Assert.assertNull(response.getFirstHeader("X-Frame-Options")); } } } } finally { server.stop(); server = null; } ```
Nit: `throw new IllegalStateException("Stream-client " + clientId + ": Unexpected state transition from " + oldState + " to " + newState);` Capitalize `S` and add `:` (same blow)
Why is serviceName a property inside JaaS config? Could this be made one of the Kafka Sasl configuration properties instead? Presumably it is used only by Kafka code and hence doesn't belong in jaas.conf? IBM JDK Kerberos module throws an exception because it doesn't recognize this property.
On a second thought, the overhead should be minimal: a few young gen objects only. So mvn.
4th overload makes sense to me as well. I like the idea of placing the serdes in `Consumed` into `Materialized`, but I'm trying to think would there ever be a case where they need to be different? I can't ATM, so I it's a yes for me.
If a line is too long, either move right hand side of assignment to a new line. If it is still too long put each argument and the closing parenthesis on its own line. Examples are: ``` final Sensor actualSensor = streamsMetrics.storeLevelSensor(THREAD_ID, storeName, TASK_ID, sensorName1, recordingLevel); ``` and ``` final Sensor actualSensor = streamsMetrics.storeLevelSensor( THREAD_ID, storeName, TASK_ID, sensorName1, recordingLevel ); ``` In this case please use the former. Please check also the other changes for too long lines.
Ideally, we want to log this when the record is reflected through replay in the controller. That's also when we could log the new leaderEpoch.
AK convention is to not use `set` setters or `get` getters.
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
@parafiend Looking at this again, adding to `failedSends` in `poll` can result in multiple disconnect notiifcations for a channel (we have to guarantee exactly one). `failedSends` are processed on the following `poll()`. But for the write exception here, we process `close()` in the catch block and the channel is added to `disconnected` list. In the next poll, when `failedSends` are processed, the channel will be added again to `disconnected` list. It would be better to set a flag rather than update `failedSends` and change the close in the catch block to: ``` close(channel, !sendFailed); ``` This will close the channel in the current poll without waiting to process any outstanding requests.
@spena just ping to make sure you get this on the follow-up PR.
Your words sound good to me, but they are directly in contradiction to the code here, which skips suspending and committing active tasks because it assumes they have already happened. In other words, there is an assumption here that the active tasks are in some kind of "committed" state, while the standbys are in either "created" or "running". If we're going to have a branch that explicitly assumes the task is already committed, then I'd like to verify it, otherwise experience says it will become false after refactoring, and we'd wind up trying to track down an IllegalStateException later on. On the other hand, if these transitions are idempotent, we can just include them in both branches (or rather move them outside the conditional block).
These methods look like they are identical to those in the previous test class above
git: The sentence "So setting the strategy ... matching the given strategy name" reads a bit confusing here. I think we only need to state that when the change of the policy would take effects (the next time when compaction is triggered by the log cleaner thread), and emphasize that for "timestamp" and "header" we would always still retain the last record.
remove var -- only used once.
For compatibility, the mbean needs to be `kafka.controller:type=KafkaController,name=GlobalTopicCount`. That means you need to pass "KafkaController" here instead of "ReplicationControlManager".
@granthenke Heh, I didn't even mean for the actual credit. But sometimes it's useful in tracking down where an issue was first introduced, the reasoning for the way a particular chunk of code is written, etc. It's an inconvenience, not a serious problem, especially for a set of changes this size.
Nit: fix line break
does always apply -> always applies
Good point @zhuchen1018. We should probably update `waitTime` in that case too.
This assertion tries to capture 3 cases: 1. All good, return `Optional.of(true)` 2. The boolean logic in the method is `false` (e.g. tasks are not ready, connector is not ready, an error response was returned etc). Please return `Optional.of(false)` 3. Exception was thrown and I can't say. Return `Optional.empty()` So based on this, how you'll interpret (3) is up to you on the `waitForCondition`. And here you want to treat it as `false`. That's why `orElse(false)` is more appropriate.
method should be static
`Constructor<List<T>>` (or `Constructor<L>` if we introduce `L`)
rewrite test as above using `assertThrows()`.
How about using lambda? `(groupInstanceId.map(s -> ", groupInstanceId=" + s).orElse(""))`
What's the benefits of using a callback here than calling `openIterators` directly? I think adding to `openIterators` outside of the constructor makes sense, but cannot think of the rationale of doing this upon closure.
Thanks for splitting out https://github.com/apache/kafka/pull/7076 @ableegoldman Please review the new PR, too, @pkleindl
i think leaving as is should be fine atm, and tbh at least they are both close enough together to be easily modified together. if we think this is useful enough, i'd file a jira dependent on the jdk8 update so we can follow up.
nit: line too long
What is the reason for having `assertDoesNotThrow` here and below? The test will fail if an exception is thrown, so seems like unnecessary noise.
Ah, now I got it! Sorry! Makes sense! In that case we can reuse `REPLACE_THREAD` also for the global stream thread. Forgot about that!
It seems to me that we could have a single `createSaslClient`. Most of the code is the same apart from the mechanism, clientPrincipal and the exception message.
Perhaps we should not change the return type here unless we decide to make the more extensive `LinkedHashSet` change across all APIs (and corresponding KIP).
Adding an extra "if" statement on every call to `read()` seems like a very heavy price to pay for this feature. We should look at where we're using the total length and check there, I think.
This implementation of `equals` will return false for timestamps of the same value; maybe this could be something like `return Long.compare(timestamp, otherTimestamp) == 0`
`KafkaAdminClient#prettyPrintException` includes the class of the throwable in the string, which this method does not. `KafkaAdminClient#prettyPrintException` is also intended to generate a short (one line) description, not dive into the stack traces and causes. I'm sure there's some unification we could do at some point, though, if we had more utility methods for dealing with exception text
Not sure if we want to provide information on a topic on which user does not have permissions.
The original intent of the test was to ensure, we don't write into non-exiting topics, ie, create a topic out of nowhere -- but with the new abstraction that cannot happen anyway I guess.
nit: blank line missing here
This computation of `broker_ids` can be simpler with a set comprehension like `{node for node in self.nodes if self.is_registered(node)}`
This test seems to be overlapping with `shouldCreateTopicWhenTopicLeaderNotAvailableAndThenTopicNotFound`. I don't think we need both to return `LeaderNotAvailable` unless they are evaluating different scenarios.
Even though the config is invalid, the passwords may be valid, so it seems safer not to include them. It would be nice if the sensitive entries in the JAAS config would be communicated in some way to improve debuggability (in the future). Btw, a nit: we seem to use inconsistent capitalisation of the word JAAS in our messages. It would be nice to make that consistent.
You are right. Never mind.
nit: extra line
Yes but you've redefined it in this class (https://github.com/apache/kafka/pull/4485/files#diff-48c2761c8e3ea24263f9cd1b020363e7R56). So we either use the redefined field (and remove `CommonClientConfigs.`) or get rid of the redefined and use the `CommonClientConfigs` field.
same question around log level as above
nit: move to line above.
Also kind of a nit, since technically this does work, but wouldn't it make more sense to just remove the `advanceNowAndComputeLatency` call in `maybeCommit`, and then just call `advancedNowAndComputeLatency` here as before? Otherwise we're just computing the latency inside `maybeCommit` for no reason, and throwing out the result.
I might be missing something, but in both cases, you just want to use regular expressions, right? There is no need to mess around with predicate functions.
Is there a specific action on the mock we wish or can verify here instead of implicitly using a aux variable for that? Replay, expectation and verify should help us verify the action or its absence. I'd have to check closer what such action could be, if there's any. Maybe you can see that more easily.
> What would be the hint for `RetriableException`? The current hint seem to be appropriate.
The topic/partition-level errors are the following today: ``` /** * Possible topic-level error codes: * UnknownTopic (3) * LeaderNotAvailable (5) * InvalidTopic (17) * TopicAuthorizationFailed (29) * Possible partition-level error codes: * LeaderNotAvailable (5) * ReplicaNotAvailable (9) */ ``` For 5) we should be able to retry, and for 9) we can ignore -- right now we only check topic-level errors but not partition-level errors (line 3642 below).
nit: add `final
Same here: we should leave this test here until we remove the deprecated API. (and just suppress the warnings for only this test method)
nit: add `final`
I see. `MaterializedInternals` must be `public` and cannot enlarge the scope if `Materialized` constructor is `protected`... What about adding a public static method `MaterializedInternals#fromMaterialized(Materialized)` that calls the copy constructor? This way, we could make it protected IMHO.
This seems like an odd way to accomplish this. I guess it works ok, but seems like a lot of jumping through hoops to get the remote file. Is this just to avoid saving a copy locally? If we need to do stuff like this, it might be better to turn it into a utility in ducktape.
Harsha address this, I believe.
nit: formatting: (we should also get the exception an verify the error message) ``` final TopologyException exception = assertThrows( TopologyException.class, () -> new StreamTask( ... ) ); assertThat(exception.getMessage(), equalTo("...")); ```
This is needed if you want to persist the limit across a reboot. But we are not rebooting here. Get rid of this.
nit: unnecessary newline
I think the idea is to verify that the actual version probing rebalance takes place, ie that the partition assignor actually handles the version probing once it's detected. And that it signals to the stream thread which also handles it correctly in turn. But idk -- I've probably broken and fixed the version probing test 2 or 3 times now due to this one line in particular. So, I'd be happy to see it go. I probably have too much bad history to make an unbiased call here though 
Could we rename this to something like "remainingPartitions"
Thanks for the clarification @hachikuji
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
Nit: get rid of empty line: `public void configure(Map<String, ?> configs, boolean isKey) { }`
Could we do this after we have `UnknownTopicOrPartitionException` happened? I think this issue is rarely happened, we can "lazily" clean it up. So, we can move this line into below `catch` block. (and need to add an `UnknownTopicOrPartitionException` case)
I think you should create an interface rather than passing in the `AssignedTasks` class, it seems you only need a single method. The contract should be on an interface rather than the class.
It seems to be clumsy to get a "random" `AbstactStream` to call the method. Better make `ensureCopartitionWith()` a static method and pass in the full set of `groupedStreams` -- for the join case, you would pass in both `AbstractStream` that needs to be copartitioned.
Might be overkill if this is the only use case, but we could also add a composite validator.
It might be nice to factor out a helper to build the controller and broker nodes. It would make it a little easier to process this method visually.
`timestamp` missing (three times)
```suggestion import java.util.Collection; ```
nit: add a newline here too.
explain why `Integer`, `Long` is used instead of `int`, `long`
just `name` should be fine
It should be something like "Sent by an (admin) client to get data about a specific consumers group like main information about members in such group."
It might be nice to factor out a helper to build the controller and broker nodes. It would make it a little easier to process this method visually.
> I've been going back and forth on whether to add this as a "per-cluster" or "per-instance" config, @vvcephei and I discussed briefly but @cadonna any opinion? If we do go with cluster-wide I think we should make the default pretty big, but I'm now leaning towards towards making it per-instance. Thoughts? per cluster: - (+) We would have more freedom in the assignment algorithm, because we do not need to consider the value of this config for each client. - (-) How should we react to distinct values on clients? How should we even know whether there are distinct values configured? We could just say Streams assumes the values of this config are the same on all clients and whatever is specified on the group leader is the truth. per client: - (+) Each client host might differ in performance and users might want to adapt the value of this config for each client - (-) Within the algorithm, how should we know the value of this config for a specific client? Don't we need to adapt the protocol to get all values at the group leader? Since assignment and restoration (a.k.a. warming-up) is done on stream thread level, it might be better to specify the value per stream thread. For example, 1 would mean that one extra replica per stream thread might be assigned. If a Streams client has three stream threads it can host up to three extra replica. The config would be global (a.k.a. cluster-wide) but users could account for different performances of the hosts by specifying different number of stream threads (which they probably have to do anyways). Here again, the value specified at the group leader is the truth.
Makes sense. There is still some cleanup to do.... `windowedDeserializer` is not use anymore in the test but only `windowedDeserializer1` -- also, setting up `props` has `put` and later `remove` that can both be removed... When cleaning up: consider what is *required* to set up the test, and what is not. Remove everything that is not required.
Not sure why we want to close the batch here since we will close the batch in batch.maybeExpire().
Yup, that makes sense to me. I'm thinking about the world where standbys (and also restoring tasks) are executed on different threads. The concern about IQ are valid indeed that with a large set of un-compacted L0 files. In the even larger scope, where we would have checkpoints I'd believe that bulk-loading would not be very necessary since we would not have a huge number of records to catch up any more :)
req: drop the `!caughtUpClients.isEmpty()` check here, if it's in the map it should have at least 1 caught-up client
This might fix the issue, but don't you think it's a little weird that it's necessary? Wouldn't we have the same problem anywhere that we call `stop`? I'm wondering if we need to fix this in ducktape itself.
Uggh, yeah, I forgot about this. We kind of inherit some annoying types from Kafka's config setup but I tried to ensure we're using String types where possible. It gets a bit hard to figure out what is valid where -- the JsonConverter actually gets passed a `Map<String, Object>` as that's what is returned by `AbstractConfig.originalsWithPrefix`, but in practice they are all `String` so type erasure allows this to work...
```suggestion final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.emptyMap()); ```
Cool, yeah that addresses my concern 
There is a built-in for this `Function.identity()`
nit: I would rather use the full name instead of using acronyms.
one liner? partitionsInFlight = sendInOrder ? new HashSet : null;
Nice catch. Reminds me though, why the second rebalance may not be deterministic in migrating tasks back? I thought our algorithm should produce deterministic results? cc @ableegoldman
Would it be slightly simpler to use `private long nextAllowedRetryMs = 0`? In general `long` seems simpler than `Long`
Might be good, to add a verification step for the `topologyDescription` similar to above (base on past experience, I am a little paranoid to make sure we do the correct thing when building the topology).
```suggestion /** * Changelog topic partitions for the state stores the standby tasks of the Streams client replicates. * * @return set of changelog topic partitions of the standby tasks */ ```
aren't these just the defaults? if so, they can be omitted.
I think we can use a utility method provided by the `ConfigDef` class here: ```suggestion List<String> topics = (List<String>) ConfigDef.parseType(SinkTask.TOPICS_CONFIG, props.get(SinkTask.TOPICS_CONFIG), ConfigDef.Type.LIST); if (topics.contains(dlqTopic)) { ```
nit: "can not" -> "cannot", same below
Hmm, we seem to be sanity checking a) that we are assigned this partition and b) the user code is not jumping ahead of the current position without actually performing a seek. Is this right? If so, these seem like things we should warn about if a connector is trying to do that since it indicates the connector is almost definitely broken.
Nit: or empty **if** this worker ....
Similar to the mute in `poll()` - the mute could be delayed until a buffer needs to be allocated? It is possible that the channel already has a buffer allocated, in which case, we want it to complete read.
Both of these cases are still testing the same thing. I think you are intending to set an invalid record count, but this is actually changing the size of the batch (i.e. the size in bytes). So whether it is 2 or 10, we're validating the same path.
It seems we are using the same application id twice in `StreamStreamJoinIntegartionTest` ``` STREAMS_CONFIG.put(StreamsConfig.APPLICATION_ID_CONFIG, appID + "-outer"); ``` This might be the root case -- deleting all topics would solve the issue, too, as it prevent to start with a corrupted state.
This can be package protected and final: ```suggestion final LinkedList<Future<Void>> futures; ```
Hmm.. I was looking into how the producer handles various operations after the call to close(). Unsurprisingly, there is a bunch of inconsistency. For send(), as far as I can tell, the logic looks like this: 1. Check whether the sender thread is closed and raise an error if it is 2. Refresh metadata if needed 3. Check if the accumulator is closed To be honest, I don't know why we don't just check if the sender thread has begun shutdown, but perhaps that's a separate issue. For transactional requests, it seems we don't currently do any checking to see whether the producer has been shutdown. At least I couldn't find any checks in `commitTransaction()`. To make this solution work, I think we should have those checks. Basically the user should see some kind of error indicating that the producer has already begun shutdown and the operation is no longer allowed. As it is, they would probably see an illegal state error indicating the transaction already began aborting or something. This could be a simple check in `TransactionManager` if we add a `close()` method as suggested elsewhere.
Most tests end up calling this method twice, once explicitly and once via `teardown()`. Let's pick one way and stick with it.
a logger should always be private -- if classed extend `KTableSource` the should create their own logger with the corresponding "child" class name.
Is this necessary? The leader epoch is -1 by default.
nit: move `windows` to next line
I see what you mean, and yea that is a fair point 
Sounds legit. Thanks.
Could we fail the test right here? It doesn't seem like there is much benefit to returning the missing metrics from the method. That would let us simplify this a little. Instead of this: ```java Set<String> missingMetrics = getMissingMetricNames(expectedMetricNames, expectedGroup, expectedType); assertEquals(Collections.emptySet(), missingMetrics, "Expected metrics did not exist"); ``` we could have: ```java assertRegisteredMetrics(expectedMetricNames, expectedGroup, expectedType); ``` We could probably also drop `expectedGroup` since we only have `kafka.controller`.
Think you might have forgotten to remove some debugging here
nit: ```suggestion private static final String storeName = "InMemorySessionStore"; ```
Should we guard against NPE? (same blow)
If we're just returning `true` for `matches`, we don't need to provide a `RequestMatcher` at all.
```suggestion * @param timeoutDuration timeout duration; must not be null ```
And why is this test deprecated as well? More generally it seems the `context#getStateStore` function was being deprecated but it was not explained in the KIP wiki.
If we're just testing broker compatibility I don't think we even need this part of the test.
Not sure about this test the title says `shouldUseSpecifiedNameForGlobalTableSourceProcessor` but it's asserting the names of state-stores. But we can fix this in one of the following PRs.
why do we make lines longer? harder to read now
Also a quick question: if `Consumed` does not specify the same serde as `Materialized`, should we just use different serdes then? I'm asking this mainly because today we will do a deser reading from Kafka and then a ser writing to state store, and maybe we can avoid this deser/ser together as an optimization. But if we allow different serdes here we cannot do that.
I know. It's just that we already use a mocking framework and we could use something like: `EasyMock.expect(factory.apply(EasyMock.anyObject())).andReturn(mockTopicAdmin).anyTimes();` if we also defined `factory` to be a mock as well. That could allow us to evaluate expectations on the mock more accurately (e.g. with a capture if we had to). But sure, if we need something quick and easy we can go with that. It's just that I noticed a mixed use of mocks with this variable that simulates what the mocking framework offers already.
The worker only maintains the state of the connectors that it is executing. A specific connector will only be running on one worker. The other workers will not have any state for the connector. So we will only be able to determine the connector type on the worker which is executing it.
Yeah, `FetchResponse` will most likely be the last one to convert because we'll have to figure out how zero-copy will work.
i think leaving as is should be fine atm, and tbh at least they are both close enough together to be easily modified together. if we think this is useful enough, i'd file a jira dependent on the jdk8 update so we can follow up.
nit: do we want to consider setting `producer` to null here as well if `eosEnabled`? I realize this branch of the code should only get exercised when closing, but just in case we make changes I don't think it will hurt.
Looks like you can do these 7 lines in a `@Before` method and not repeat it in all of your tests
How about clarifying this a bit: ```suggestion // Generate a new consumer record from the modified sink record. We prefer // to send the original consumer record (pre-transformed) to the DLQ, // but in this case we don't have one and send the potentially transformed // record instead String topic = record.topic(); ```
I'm wondering if we also need to delay the call to `client.wakeup()`? For example, consider the following sequence: 1. disableWakeups() 2. wakeup() 3. poll(0) 4. enableWakeup() 5. poll(Long.MAX_VALUE) The underlying wakeup on Selector would effect the `poll(0)`, but we would suppress the exception. Then there would be nothing to wake us up from the `poll(Long.MAX_VALUE)`.
git: The sentence "So setting the strategy ... matching the given strategy name" reads a bit confusing here. I think we only need to state that when the change of the policy would take effects (the next time when compaction is triggered by the log cleaner thread), and emphasize that for "timestamp" and "header" we would always still retain the last record.
We should check that `inputRecords.hasNext` is false after the for loop, or any manners to make sure that pairing lists have the same size.
Let's be consistent and just use string concatenation for both fields.
This needs to be `totalAbortedThreads`
could this be changed to `usedSubscriptionMetadataVersion > receivedAssignmentMetadataVersion && receivedAssignmentMetadataVersion >= 3`
I don't think this works. This branch only handles connections which are completed "immediately" in `doConnect`. This is not the common case, which is why all of the test cases in `SelectorTest` fail with this change.
Actually maybe we should wrap it in an `if hasPersistentStores` so that users won't get this warning if they don't have any persistent state
How about: ```suggestion "Variables cannot be used in the 'plugin.path' property, since the property is " + "used by plugin scanning before the config providers that replace the " + "variables are initialized. The raw value '{}' was used for plugin scanning, as " + "opposed to the transformed value '{}', and this may cause unexpected results.", ```
This is a useful log message. But since in a busy Connect worker it's unlikely these log two messages will be adjacent, how about instead using a single log message: log.trace("Cast field '{}' from '{}' to '{}'", field.name(), origFieldValue, newFieldValue);
I don't see how this is going to work as the callback is happening on the Producer's Send thread
I don't think it's _that_ big a deal to have to allocate the `OffsetMetadata`. And certainly the performance overhead of the allocation isn't a concern. I only care about the verbosity because the vast majority of use cases only care about the offset and not the metadata, and we're making that large fraction of cases harder. And would OffsetMetadata then be changed to be mutable, so it's convenient to just maintain the map where I update only the offset in that struct? Or do all my updates to that map (which I probably update for every single message processed) require a `new OffsetMetadata()`, bloating those statements and making them less clear? Or do I just maintain the `Map<TopicPartition, OffsetMetadata>` and have to convert it every time I call commit? On the other hand, maybe most users don't even specify the offsets manually anyway and the concern here is unwarranted since 99% of the cases are handled by `commit(CommitType)` and `commit(CommitType, ConsumerCommitCallback)`? In other words, I'm worried because I want the very common case to be clean, easy to read, and concise. I'm not yet sure whether this change would actually affect that common case.
We could probably just bump up the number of parameter limit in the checkstyle file to 14.
> It seems like the remaining behavioral difference is that the new code will, if no other leader can be chosen, set the leader to -1 (offline). If we don't do this, controlled shutdown easily gets stuck if there are any partitions with replication factor = 1. Maybe we can tune this a bit later? It's fine to revisit that later. The tradeoff is that if we wait, it slightly increases the probability of availability since another replica could join isr.
+1 for 100 tasks. Thanks.
Note this is indeed fixed in trunk but not in older versions.
Hmm... Yeah, maybe the call in the metadata listener is sufficient. But we definitely don't want to fetch metadata for all topics. Also, it seems unnecessary to request a metadata update blindly. I think `metadata.setTopics` was previously requesting the update only if the topics are not already contained in the Metadata.
What happens if `millisRemaining` is, say, 2 and `retryBackoffMs` is 1000? If `millisRemaining` is positive, then shouldn't we sleep for the smaller of `millisRemaining` or `retryBackoffMs`? IOW: ```suggestion Utils.sleep(Math.min(retryBackoffMs, millisRemaining)); ```
I think we should clear `immediatelyConnectedKeys` at the end of each `poll()` as well.
Why is this needed? This is worse than the previous approach as it opens, closes and reopens the file.
This should never happen, right? maybe we just don't check it and get an NPE if somehow driver gets set to null after the setup.
Yeah if it exists elsewhere let's just leave it as is for now.
This null check is redundant as we check for null in `toTable(Named, Materialized)` anyway -- can be removed
I guess if you are removing `this.` above, you could remove it here as well for consistency.
This is common enough that there's a util for that and is used extensively: ```suggestion Utils.closeQuietly(retryWithToleranceOperator, "retry operator"); ```
Cool, I will create a JIRA ticket for now to keep track of it.
OK, makes sense. Didn't know about policy of internal checks. Would be good to have it written down somewhere.
Hmm, but if the value is null, we won't hit those points: https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/config/ConfigDef.java#L638. With this patch, both of these tests fail: ```java @Test(expected = ConfigException.class) public void testEmptyTopicNotAllowed() { sourceProperties.put(FileStreamSourceConnector.TOPIC_CONFIG, ""); connector.start(sourceProperties); } @Test(expected = ConfigException.class) public void testNullTopicNotAllowed() { sourceProperties.put(FileStreamSourceConnector.TOPIC_CONFIG, null); connector.start(sourceProperties); } ```
I had to stare at the `SampledStat` code most of today. I actually think the original code is correct. The elapsed time should be the time elapsed in the current window plus the previous (non-obsolete) windows. It seems this is exactly what the current code is doing. Your change I think would effectively almost double the actual elapsed time. Maybe we can discuss this offline.
You only need to crate that instance once, right? It can be a member of the class
Blank line can be removed.
nit: add a space so it is "StreamsMetadata {...} topologyName=xyz"
As before, we can use `assertThrows`.
Sounds fine to me.
`HashMap` can be replaced by `Map`.
From the default implementation and netty implementation, it looks like they would never be null. But I guess it is ok to do the null-check here since we may make SSLEngines pluggable.
i know it was motivated by findbugs, but this was probably a good refactoring anyway :) `RestServer.httpRequest` to *make* an http request has always been a bit awkward
With further reading, I think the timer should still be 7 days for pid expiration.
nit: needs a comma after the `{@link ...}`
Yes, I think we ought to use a Kafka schema definition even for the user data so that we can avoid dependence on java-specific serializations.
`assertNull`s shouldn't be here but few lines bellow.
We should also check to make sure there are no invalid empty task IDs. In that case we should throw an exception and not try to create anything, similar to the above exception...
I was thinking we need to do something about the `ProcessorContext`, too. The interface is quite broad. I think what you have suggested is ok, but I'd probably like to see `register` moved elsewhere, too. At the moment the `ProcessorContext` is accommodating initialization and processing, which means we have methods on it that aren't valid in all circumstances. IMO it would be nicer to have more focussed interfaces that make it less likely that you can do something that isn't allowed. The interfaces can all be implemented by the same object, of course.
Intuitively, I would expect `cachedRecordFetchException` to be set to null on the next line.
As I understand it, handleResponse will always be called by AdminClientRunnable from the single 'network thread' (KafkaAdminClient.thread).
We can compute this once and pass it to `removeAttribute`.
That does not sound right. If we throw a `StreamsException` the thread will die.
as above, your "link" markup
@dguy @enothereska This `synchronized` here seems suspicious. Is it really the aim to synchronize on the listener instance when updating variables like `threadState`? Seems like a bug.
In my PR (https://github.com/apache/kafka/pull/7304) I've refactored this part in StreamTask. I'd suggest we merge that one before this.
Making sample age super high sounds better to me, comparing to having a ballpark check.
this global variable isn't great. Can't we hit some rest endpoint that can return this internal values out of the extension? probably makes for a better end to end test too.
Should be final
Same here. We should use `builder.stream().toTable()`
yes, it seems to be not what this test is checking on. I think we can drop it here.
Isn't this the same as: ``` tagKeyToTagValuesMapping.computeIfAbsent(tagKey, (ignored) -> new HashSet<>()).add(tagValue); ```
Yeah, you can use a volatile field and synchronize on the assignment if still null. And then file a separate Jira to remove it from the class in a separate PR.
If stop throws we won't count down the latch. No harm will result except there will be an erroneous log messages about exceeding the stop timeout.
This is needed if you want to persist the limit across a reboot. But we are not rebooting here. Get rid of this.
This should be package-level protected: ```suggestion // Visible for testing static void validateHeaderConfigAction(String action) { ```
make it if-then-else since we dont't need the increment in the line below? Also split this line since we don't include the statement in the same line as `if`.
> Hmm, for production, do we ever restart a thread even for illegal-state or illegal-argument? If the user decides to restart a stream thread in its exception handler it is possible.
Can we call this property "priority" instead of "id"? I found this statement setting one node's "id" to another node's "id" worrisome, and I had to do some archaeology to determine that the "id" is actually just used as the priority in the topology building.
You are right @hachikuji . For line 1597 to be true, I think the test needs to do another round of fetch. > // The high watermark advances to be larger than log.endOffsetForEpoch(3), to test the case 3 Line 1614 wants to fail because of an invalid offset and epoch based on the leader epoch cache. Not because it is greater than the high watermark. ``` assertThrows(IllegalArgumentException.class, () -> context.client.createSnapshot(invalidSnapshotId4.offset, invalidSnapshotId4.epoch)); ```
Let's make this protected. ```suggestion protected InternalSinkRecord(ConsumerRecord<byte[], byte[]> originalRecord, String topic, ```
Should be larger
Was this intentional? `VALUE_SERDE_CLASS_CONFIG` is deprecated.
modifiers should be in the order `private final`
I'm not convinced we should allow this
Nit: fix line break
The Achilles heel of implementing new KTable features has historically been that we forgot to test them in a context that required the ValueGetter to work properly, of which Join is a notable use case. I'd actually say it should be required for every KTable operator to have a test where it's the source of a Join. For stateless operators, we should test both with and without a Materialized argument on the operator.
Is it really worth having this catch here? I think it's best to just let the exception propagate. Any method under test can throw an unknown exception after all.
I feel a bit weird here as we don't need `prepareCloseClean` anymore. This API usage is a little complicated upon when we should do it and we don't.
I think we're testing `testDir` Occupied here, not `AppDir`.
"... is called previously... " without a subsequent call to `unsubscribe()`? Same below.
It is a shame we have to do it like this, but i don't see a viable alternative
make this into a different test, i.e., `shouldSupportNullInFloatSerde` or similiar
The passed in value would be true for both alpha and beta right? if yes we can just name it eosEnabled.
What about checking for the state and do the clean-up only if the state is not `PENDING_SHUTDOWN` and not `ERROR` and not `NOT_RUNNING`? In this way we are safe for future changes that break our assumption on state transitions and we make sure not to do unnecessary stuff when we are shutting down.
Overall, confusing indentions and line breaks...
Nit: it'd be better to avoid changing lines that don't need to be changed. Helps to keep the PR as small as possible.
There is the following in the constructor, so the thread can be null. ``` if (!isKrbTicket) { // if no TGT, do not bother with ticket management. return; } ```
nit: new Integer(1) => Interger.valueOf()
nit: fix typo `store[s]` ;)
nit: Indentation of those lines seems to be off here.
Yes, does not hurt to leave it. Just for sure.
I think this method can still block regardless of requestTimoutMs at least due to the following calls: ``` updateFetchPositions() -> coordinator.refreshCommittedOffsetsIfNeeded() -> fetchCommittedOffsets(missingFetchPositions) -> ensureCoordinatorReady() { // Using zero as current time since timeout is effectively infinite ensureCoordinatorReady(0, timeoutMs = Long.MAX_VALUE) }```
I'm thinking whether it makes more sense to let `MockProcessor` encapsulate a delegate `MockApiProcessor` so that we could also use existing tests to verify the correctness of the migration.
In other words, I'm recommending that we specifically say something like "Producing deletes from your aggregations may cause unexpected results when processing dis-ordered data. Streams always processes data in the order it appears in the topic. If the topic is populated out of order, you may have late arriving records, which can cause records to become unexpectedly re-created after they have been deleted. Out-of-order data can be a problem for non-deleting aggregation functions as well, but it's especially surprising with aggregations that produce deletes." :/ ... you see what I mean by saying that it's a nuanced topic.
This logic seems a bit complex to me, and also if we return at line 229 `restoreBatchCompleted` is not called as well. Is this correct? How about: ``` restoreRecords = new list.. nextPosition = -1; for (...) { if (restorer.hasCompleted) { nextPosition = record.offset(); break; } else { restoreRecords.add(...); } } if (nextPosition == -1) nextPosition = consumer.position(restorer.partition()); if (!restoreRecords.isEmpty()){ restorer.restore(restoreRecords); restorer.restoreBatchCompleted(currentPosition, records.size()); } return nextPosition; ```
If you use the `assertEquals` that takes a `double`, you can pass a `delta` value, which makes the code a lot more concise.
We do not throw `InvalidTopicException` "if [the topic] is not found"
Seems like the indenting should be adjusted to the left, right? Applied to other changes in this file too.
We added 1 line to this right? I don't know why the diff shows such a large change...Actually nevermind, I see the rest of the code now.
nit: add `final`
nit: I don't think the copier uses group instance ID (maybe we could add support for that separately?), so I don't think `FencedInstanceIdException` is possible at the moment.
nit: fill in `@return` docs
I know this is a bit opinionated, but ... I think we should make an effort to make all locals `final` where possible. It is just a few extra keystrokes (that intellij can do for you!), and it helps to eliminate a class of bugs.
I wasn't aware that `finally` blocks had a large impact on performance, and haven't been able to find anything definitive on the subject that indicates they are. Can you provide a reference that backs up this claim? Fwiw, using a `finally` block would be more concise and readable here: ```suggestion try { return Utils.newInstance(klass); } finally { compareAndSwapLoaders(oldClassLoader); } ```
I don't think we need extra `toGiveUpTopicPartitions` to store the partitions to be deleted. We can log the warning message in L1103 here directly
I believe just returning from the catch branch is fine. No need for this variable. (you return from any path)
The variable name should be changed.
"... as producer is closed" Same elsewhere
prop: abortTransaction can also throw ProducerFenced.
Could you test `maybeRecordE2ELatency()` through `process()` and `forward()`? Although you test `maybeRecordE2ELatency()`, you do not test if the recording is done during processing, but that is the crucial thing, IMO.
nit: we can make this a `static` function and rename it to something like `convertToVoters`.
I like the use of `Optional`. I think, you could make it even simpler: ``` final Sensor sensor = Optional.ofNullable(metrics.getSensor(fullSensorName)).orElseGet(() -> { final Sensor newSensor = metrics.sensor(fullSensorName, recordingLevel, parents); threadLevelSensors.computeIfAbsent(key, ignored -> new LinkedList<>()).push(fullSensorName); return newSensor; }); ``` Please use the correct indentation. We use 4 spaces. Same applies to the changes below.
Nit: param alignment.
This does not need to be a map, a list is good enough since we would not call `addList` with the same groupId, similar to `addError`.
Ok, I took a closer look and had a bit of a flash-back to how confusing these metrics are... Maybe https://github.com/apache/kafka/pull/7057 will help.
Good point. I think it is still worth keeping the optimization, although typically the the producer will only allocate poolable batch size, so the actual memory allocation should not happen very often.
It's internal. So should be fine.
So you want to advance `recordFactory` time too? (similar below)
For `shouldNotReturnDuplicatesInRanges` it seems best to use `processorContext.timestamp()` -- `processorContext` is passed in `init()` do you just need to add a member variable to the `Transformer` to store is so you can use it in `transform()`
nit: use `"table-source"` ? It's naming a source node, not a processor node.
This method is also deprecated. We should throw same exception as for `childIndex`.
How about `completeExpiration` or `expirationDone`? Also, do you think we should add safeguards to ensure that the batch can't be completed more than once? Maybe at least we can add an assertion that `expiryErrorMessage` is null in `RecordBatch.done`.
Although, you simplified this code, you did not apply all simplifications I proposed in PR #7914. I think you can even simplify this code further as shown here: ``` return Optional.ofNullable(metrics.getSensor(fullSensorName)).orElseGet(() -> { threadLevelSensors.computeIfAbsent(key, ignored -> new LinkedList<>()).push(fullSensorName); return metrics.sensor(fullSensorName, recordingLevel, parents); }); ``` This simplification can be applied also to the other methods below. If you have any concerns about this simplifications please share your thoughts.
Yes, I think it's worthwhile to check the result of `Connector.config()` just in case `Connector.validate()` is overridden and the default check there is no longer used.
And again - i'd say it is definitely worth having what i mentioned above
Passing through Jackson seems to be the real test we need here (though checking `toString()` itself is also useful for logging elsewhere if we want consistency).
That makes sense, let's keep it in that sense. EDIT: Actually, I'm wondering that if the `monitor` would always grep the same log4j entry in the outside verification or it always try to grep the new lines after the inner verification? If it's the first case, then the outside verification would always be redundant as we are doomed to just grep the same lines.
Is the current implementation vulnerable to the following race condition? 1. thread1 grabs `CHANNELS` lock, get the channel object from the map; and then exists the `CHANNELS` lock; 2. thread2 grabs the lock, release the lock on it, close the channel, remove from the map. 3. thread1 now calls `channel.tryLock`, which throws `ClosedChannelException`.
extra new line.
It seems to be clumsy to get a "random" `AbstactStream` to call the method. Better make `ensureCopartitionWith()` a static method and pass in the full set of `groupedStreams` -- for the join case, you would pass in both `AbstractStream` that needs to be copartitioned.
Hmm... It seems a little inconsistent to use the offset of the first record. When the batch is empty, we use the base offset of the batch. Shouldn't we do the same here? Otherwise we will end up with some batches which have base offset smaller than the segment base offset. Note that the base offset is always preserved by compaction.
nit: formatting -> should be in the line above.
I think that code got in by mistake. There is a PR by @rajinisivaram for supporting SASL/PLAIN, but it hasn't been merged yet. Support for SASL in system tests was also contributed by @rajinisivaram and maybe it assumed the presence of the yet unmerged PR.
I do not think you need to put an entry if you use mocks.
What makes this difficult to follow is that `value()` depends indirectly on the fields set in `produceFuture.set()` above. I think this is ok here, but I'm wondering if a separate refactor could make this less obscure. Something like this perhaps: 1. Pull `ProduceRequestResult` out of `FutureRecordMetadata`. 2. Pull the latch out of `ProduceRequestResult` and into `RecordBatch`. 3. Each instance of `FutureRecordMetadata` can have a reference to the latch instead of `ProduceRequestResult` 4. Make `ProduceRequestResult` immutable and only construct it when the result is ready. 5. Add a `FutureRecordMetadata.complete(ProduceRequestResult)`.
For the longer term, I feel that we either need to 1) store the topic / offset information into the upstream materialized store as well, or 2) just disable this optimization for KTable.transformValues(), or at least allow users to either opt-in or opt-out given their knowledge on the context. As for now, I think leaving the offset as -1 and topic as null seems okay -- admittedly this would break someone who's using the context for offset / topic, as they would get unexpected values or even NPE, but that's still a fix forward then getting incorrect values silently.
Isn't this a behavior change? IIRC, we had a discussion to do this change, or to maybe make it configurable if we want to interleave processing with recovery.
That makes sense. I did not think about the reconfiguration case.
Alternatively, we can change the first arg `KeyValueMapper<K, V, K1> keySelector` and the second arg `KeyValueMapper<K, V, Long> valueSelector`. If we define special value selector classes, `LongValueSelector<K, V>` whose apply method returns `long` (not `Long`), `DoubleValueSelector<K, V>` whose apply method returns `double` (not `Double`) and so on, we can overload the `sum()` method and allow summing over different data types (and avoid object overheads), I think. In this case, SumSupplier is no longer a subclass of AggregatorSupplier.
We've gotten several requests not to log the values of any records above debug level. If you think we should still log the value, we should split this into a warning log without the value, and then a debug/trace log including the value.
you don't need this. Junit gives you a new instance of the test class for every test method
nit: also add java doc for type `T, O` here
Nit: users with the high-level DSL may not be familiar with "sink", so we should reword it from the Processor API. How about "the function used to determine how records are distributed among partitions of the topic"
nit. I think there is `.` missing `since 3.0[.] Use`
Thanks for the follow-up.
nit: `addMetadata` -> `put`
I'm not sure it actually matters since users are unlikely to construct this object manually, but it seems like we should use `ConfigSource.DEFAULT_CONFIG` if `isDefault` is true and `ConfigSource.UNKNOWN` otherwise. Then `isDefault()` will continue to work with this constructor.
Very good point. For backward compatibility, we can probably just guard that by inter.broker.protocol version. If the version is >= 0.10.0, we will use the new protocol. Otherwise, use the old one.
We probably shouldn't change this default to true -- we should override it in the specific test we need by calling `self.mark_for_collect(consumer, 'verifiable_consumer_stdout')` where `consumer` is the `VerifiableConsumer` instance. stdout for verifiable consumer can result in _huge_ log files, so collecting them by default will result in very large archived data for some tests.
> I ignore 1 out of every 2 punctuations Uh. That's kinda painful... I think we need to discuss this in more details, ie, what semantics we want to provide. \cc @bbejeck @dguy @guozhangwang @miguno
Doesn't this introduce the possibility of conflict between two plugins (or I guess specifically connectors, since those are the only ones we strip suffixes from) which have different fully-qualified class names, but the same simple class name? Or where they would have the same simple class name, except that one ends with `Connector` and the other doesn't? In practice this is unlikely to come up but if we support it at the moment, probably best to take care here to avoid introducing a potential regression, especially if someone for some reason wants to run, e.g., two different `MySqlSink` connectors on their worker.
the message format => that message format
More specifically, there's no point in having this if we close the network client before we even get to the point where the request has reached the network layer.
Yes, it seems that -1 means that we are trying to read beyond the end of the channel, which probably should be treated as abnormal.
We should pass in `record.topic()` instead of `""` into `deserialize`.
I think it is a bad idea to let callers concern about calling `maybeExpandBuffer`; previously the caller is abstracted from this away.
```suggestion * windows with negative start times, which is not supported. Instead, they will fall within the [0, timeDifferenceMs] ```
@guozhangwang yes that seems correct. It would seem to be a bug if `setState` is called when were are in `NOT_RUNNING` state
Wonder if it might be simpler to initialize `partitionsToRetry` from the request key set.
the fist argument is still "expected value" so we don't need to switch the args. There are many similar occurrence.
Seems like we don't really need inheritance here. Can just have an "if" statement that checks if we have a group or not
We should also validate (in our tests) that the user cannot modify the underlying stream because, as I understand the proposed semantics, "an unchanged stream" is an invariant we want to guarantee as part of the contract.
It would be best if this test used a replication factor of 2. With a replication factor of 1 we will have no regular replication traffic occurring when the producer writes messages. It would be good to have both throttled replication and non throttled replication happening at the same time.
Let's make this protected. ```suggestion protected InternalSinkRecord(ConsumerRecord<byte[], byte[]> originalRecord, String topic, ```
I think we should probably include information about the received `kerberosName` in the error message and use `principalToLocalRules.toString` instead of `toString`.
NIT: I think we should keep the check consistent between subscribe(topic) and subscribe(TopicPartition). I am fine with either way of checking.
I see. `MaterializedInternals` must be `public` and cannot enlarge the scope if `Materialized` constructor is `protected`... What about adding a public static method `MaterializedInternals#fromMaterialized(Materialized)` that calls the copy constructor? This way, we could make it protected IMHO.
nit: how about just put these two in one line? We usually only use multi-lines if there are 3+ parameters.
Should be more specific about the type of error being caught -- catching all exceptions should be reserved for very special cases, like protecting the top stack frame of a thread to avoid uncleanly exiting the thread. I suspect that here you specifically want to capture `CalledProcessError`, which indicates an issue running the command on the remote host and/or `ValueError`.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
Currently we are not passing required security configs (using --command-config) to the tool. This change may not work for with secure broker listeners. seems like we are not using these methods in any security enabled tests.
If we are not exposing this detail, then it would be a bit weird to classify them in the first place.
I had to stare at the `SampledStat` code most of today. I actually think the original code is correct. The elapsed time should be the time elapsed in the current window plus the previous (non-obsolete) windows. It seems this is exactly what the current code is doing. Your change I think would effectively almost double the actual elapsed time. Maybe we can discuss this offline.
Or have one that takes a lambda so that the caller can do the `close`. Similar to what we have for Scala.
same as before. Would be much nicer to add a method on the abstract class rather than using instanceof
I cannot see how a unit test for the rebalance listener does not make sense. I would rather unit test the listener in isolation and then mock it in the other unit tests.
It seems better to say Producer.send() instead of send.
nit: needs a comma after the `{@link ...}`
This message is a little strange. We can certainly represent the topic id, but it is invalid. I wonder if it would make sense to raise `IllegalArgumentException` directly instead of through the result since this is likely a logical error of some kind.
Can you please explain why it's better to warn than to fail-fast in this case? Just want to make sure I understand the reasoning for the choice.
How about we get rid of the problem altogether -- define `WorkerConfig.rebalanceTimeout()` that returns null by default, and then override it in `DistributedConfig` to return `getInt(DistributedConfig.REBALANCE_TIMEOUT_MS_CONFIG)` since that will always be an integer. The latter's method is trivial, and the code in `RestServer` becomes simpler and easier to read. I think there's enough precedence in `StreamsConfig` and `ConverterConfig` to add getter methods (without `get` prefix). The fact that it cleans this up this significantly is also good justification.
I think we can move this into the block above line 70 to 72 and simplify: ``` if (!needsInitializing.isEmpty()) { initialize(); updatedEndOffsets.putAll(restoreConsumer.endOffsets(needsInitializing.keySet())); } ```
Should not have an implementation but call overloaded method.
`result` is unused in this code block. To be future proof, I'd suggest being explicit by returning an empty list here, and declare `result` right above the block that is being used at.
Nit: space before `:`.
Oh, right, I forgot that the metrics registry returns the same copy of the sensor when all the name, description, and tags are the same... Thanks.
This line would not need to be affected. ```suggestion recordActiveTopic(sinkRecord.topic()); ```
Could store `entry.getKey()` in a local variable since it is used several times
An alternative would be to also attempt to use `System.identityHashCode` to break ties in a way that would be consistent (up to the point that the hash code can be guaranteed to also be unique, which isn't perfect either).
That makes sense. I got confused by the fact that `AbortTransactionResult` takes a `Map` in its constructor. In this case, `all()` seems fine. Thanks for the clarification.
`while` seems to be missing
Should have a comma after "for example"
This doesn't read well. Assuming it needs to be as long as `inactivity-gap` plus `grace-period` then the following reads better to me: ```suggestion * @param retentionPeriod length of time to retain data in the store (cannot be negative) * Note that the retention period must be at least as long as * inactivity-gap plus grace-period. ```
ditto about the log level (also for the below uses of `debug`)
Nit: add `final`
Why do we return `Optional` here? Doesn't makes sense just by itself, unless some bigger picture requires it.
@ableegoldman is it related to the UUID randomness? If yes please ignore my other question above.
Hmm.. we already have a `metadata` object that is keeping updated by the `AdminClientRunnable`, can we just call `metadata.fetch()` to get the current cluster information? Then in line 1918 if we do not have the current leader we can still return `LEADER_NOT_AVAILABLE` to let the caller retry as it is a retryable error code.
> Was also wondering if there could ever be an exception thrown by addListener which would cause the listener to not be added or the completion handler to not be called? Hm good question ... find it hard to imagine as implemented unless we end up with multiple listeners executing on the consumer thread & a listener that precedes this one throws or something along those lines. And in that scenario right now I think we'd expect the exception to bubble out of KafkaConsumer.poll(), which would at least give us a clear signal that something went terribly wrong.
How about we get rid of the problem altogether -- define `WorkerConfig.rebalanceTimeout()` that returns null by default, and then override it in `DistributedConfig` to return `getInt(DistributedConfig.REBALANCE_TIMEOUT_MS_CONFIG)` since that will always be an integer. The latter's method is trivial, and the code in `RestServer` becomes simpler and easier to read. I think there's enough precedence in `StreamsConfig` and `ConverterConfig` to add getter methods (without `get` prefix). The fact that it cleans this up this significantly is also good justification.
nit: why double space? (similar below and further below)
`long` -> `Long` is a binary incompatible change.
Unused import - this is causing checkstyle failure in the PR build.
`result` is unused in this code block. To be future proof, I'd suggest being explicit by returning an empty list here, and declare `result` right above the block that is being used at.
If it is no more an integration test, this should be removed.
none from what I can see, but I'm not sure it's worth holding up the PR for it.
nit: Please fix code style.
+1 for consistency
Hmm, not sure if this is being inherited from other tests in this class, but this isn't the behavior we'd expect. The logic is now somewhat confusingly split between `ConnectorPluginsResource.validateConfigs()` and `AbstractHerder.validateConnectorConfig()`, but since `connector.class` is missing, we expect a `BadRequestException`. This test only works because this answer doesn't match what would actually happen in `AbstractHerder`.
We can use JUnit "expect exception" here. For example in SchemaBuilderTest.testInt64BuilderInvalidDefault.
`apiKey` is of type `ApiKeys` while `requestHeader.apiKey()` returns a `short`.
Oh yeah, duh. Nevermind this 
We could update the timer so that the min was the `requestTimeoutMs` for the second `close` too.
One thing from the ClientRequest that we don't get from the builder is the correlationId. This is occasionally useful when debugging. If you think it's useful, we might consider adding it to the log lines in `doSend` as well.
Seems like we should move this above into the top-level `process` instead of first calling `processInOrder` and then calling `processEarly`. For one thing, since we actually do need to iterate the full range for the early records, we can just call `processEarly` without having to decide between `processInOrder` and `processReverse`
Similarly here, I think we can move these checks into `TransactionManager` and just pass the batch.
Why remove the empty line? It make it harder to read the code, as logical blocks are separated by blank lines atm. (similar below)
Just curious, could we possibly call this function for the same node more than once? It seems yes as you are checking `!keyChangingOperationsToOptimizableRepartitionNodes.containsKey(node)` here, but I cannot tell from the code...
Fair enough. Let's leave it as-is.
I understand that. My question is whether there is some thinking on which configs make sense to be set by users. Ideally, we'd do that instead of being reactive.
Nit `.` at the end
No worries. All good. :)
Hmmm... Good point. Let leave it as-is. It's also covered in integration tests that the right store is returned.
I think the intended method to call would be ``` Thread.currentThread().interrupt() ``` Same with line 258 below.
Isn't MM2/Connect using at least once by default? ie, the producer in the runtime can cause duplicates.
Instead of doing: ``` if (condition) { return true; } else { return false; } ``` You can do: ``` return condition; ```
Do we really want anything related to internal topics to be client side? This could change in brokers from version to version and the clients should still work. I understand that for now we have no way to get that information, but we will soon (KAFKA-3306). I imagine removing the client side list would be part of the cleanup once thats available. So whatever exists in the mean time should be private so we don't need a deprecation cycle.
I think that the driving condition of the test is the number of samples, not the time. But I thought I'd point out that time won't advance by default, but you can make it by using the `autoTickMs` constructor.
nit: there's some redundance printing both the offset and the OffsetAndMetadata. Maybe it would be most useful to print just the offset and epoch
@ewencp I suggested not using `final` in every new loop for consistency (several loops even here don't use it such as the one in `close`), but I didn't imply that we should change unaffected lines. In general in Connect my understanding is that we are not strict in demanding use of `final` in local variables. Let me know if something changed.
Here's a nice blog re: exception costs and when they occur: https://shipilev.net/blog/2014/exceptional-performance
@bbejeck @guozhangwang Oops, looks like I missed this. Bill has a point here. I will probably log a JIRA to get this done.
newuntil => newUntil
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
nit: avoid inserting random blank lines.
How about updating `nullableSeenMetadata` only if we don't return records? ```java if (longPollShouldReturn(records)) { ... } else { if (nullableSeenMetadata == null) { nullableSeenMetadata = new HashMap<>(records.metadata()); } else { nullableSeenMetadata.putAll(records.metadata()); } } ``` The benefit from above code is that we don't need to handle duplicate metadata which exists on both `FetchedRecords` and `nullableSeenMetadata` when it succeed to get records and metadata in first loop.
We should also validate (in our tests) that the user cannot modify the underlying stream because, as I understand the proposed semantics, "an unchanged stream" is an invariant we want to guarantee as part of the contract.
@llowrey, it would also be interesting to know the environment where you can reproduce this. I tried writing a test that connects 1 million times to a Java EchoServer and `connect` always returns false.
Might be worth adding a null check here for `groupMetadata`. Another simple validation is ensuring that if `generationId > 0`, then `memberId` should be non-empty.
Should we chain the caught exception? We expect this to be the close exception, but it could also be a timeout or an authentication failure. Might be useful to know in some scenarios.
ditto on the properties and the driver.
Understand. That part can be refactored - goal is to reduce unnecessary comparison.
Hmm, not sure if this is being inherited from other tests in this class, but this isn't the behavior we'd expect. The logic is now somewhat confusingly split between `ConnectorPluginsResource.validateConfigs()` and `AbstractHerder.validateConnectorConfig()`, but since `connector.class` is missing, we expect a `BadRequestException`. This test only works because this answer doesn't match what would actually happen in `AbstractHerder`.
You need to fix these other methods also. If the exception is raised, the call to `release` will lead to invalid state.
Might be better to add a proper POJO maybe `StreamsMetadata` or something that wraps the `streamTime` Long plus `ProcessorMetadata` instead of using `KeyValue` ? We might add new fields later on what is easier to do for a new POJO.
Nit: how about "a new {@link KTable} ... as this {@link KTable}"? Ditto for all `through` calls of KTable and KStream
Can remove the first 3 null checks as they are covered in the new overloaded `aggregate` method
maybe: `inputKeySerde` and `inputValSerde`
From my understanding, neither the `ConsumerRecord` nor the `ProcessroRecordContext` are the issue, but the shared `Header` object -- it's just a "side effect" that creating a new `ConsumerRecord` creates an new `Header` object internally.
I submitted a PR that removes unused setters, makes fields final and tries to make things a bit more regular. Makes it a bit simpler, but more could be done probably.
Let's use `Map` on the left side instead of `HashMap`
I was thinking something like this: ``` java long nowMs = time.milliseconds(); long deadlineMs = nowMs + timeout; do { RequestFuture<Map<TopicPartition, OffsetAndTimestamp>> future = sendListOffsetRequests(timestampsToSearch); client.poll(future, deadlineMs - nowMs); if (!future.isDone()) break; if (future.succeeded()) return future.value(); if (!future.isRetriable()) throw future.exception(); long remaining = Math.max(0, deadlineMs - time.milliseconds()); if (future.exception() instanceof InvalidMetadataException) client.awaitMetadataUpdate(remaining); else time.sleep(Math.min(remaining, retryBackoffMs)); nowMs = time.milliseconds(); } while (deadlineMs > nowMs); throw new TimeoutException("Failed to get offsets by times in " + timeout + " ms"); ``` Not sure if it's any better though. If so, only marginally.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
nit: add one whitespace at the end after "...state"
We can implement that when handling a response, invalid cluster id are fatal unless a previous response contained a valid cluster id.
This is ugly -- we should have access to the wrapped store directly via inheritance. (also below)
recommended; ditto below.
Yeah, it seems to me like we should remove it.
Ah, yeah, you'd need to do something more like what actually happens in the actual KafkaConsumer/`getAssignorInstances` code. eg ``` @Test @SuppressWarnings("unchecked") public void shouldInstantiateAssignorClass() { Object classTypes = Collections.singletonList(StickyAssignor.class); List<ConsumerPartitionAssignor> assignors = getAssignorInstances((List<String>) classTypes, Collections.emptyMap()); assertTrue(assignors.get(0) instanceof StickyAssignor); } ```
nit: we can throw illegal-state if the state() == RESTORING since it should never happen.
```suggestion final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.emptyMap()); ```
as above. Name of the test can be more descriptive. `shouldRequireBrokerVersion0101OrHigherWhenEosDisabled`
What we are getting here is not necessarily the bootstrap nodes that the user has passed as it depends on what the caller passes (the current implementation does that, but it could easily be changed). 3 options I can think of: - Leave the current implementation, but change the name of the field to something like `initialNodes` - Add an additional constructor parameter called `bootstrapNodes` - Leave as is
I'm against the sprinkling of `final` keyword everywhere. But more than that, I'm in favor of consistency w.r.t. the surrounding code. A few lines above, you may observe that `close` has a similar loop without `final`. Every project has its idiosyncrasies and Connect is not dogmatic w.r.t to `final` for local variables.
```suggestion @Evolving public class WindowKeyQuery<K, V> implements Query<WindowStoreIterator<V>> { ```
should this be null? perhaps throw an IllegalArgException
Not really related to this line. Could you verify that the state store is closed in the unit test that tests line 148? The name of the test is `shouldThrowStreamsExceptionForOldTopicPartitions()`.
+1 for 100 tasks. Thanks.
Should be final.
Also, it's really ugly for "validate" to mutate the request. Can we have another function for this... :pray:
isFull is no longer used.
The deserialized is actually different since we need to differentiate between `timeWindowed` and `sessionWindowed`. It is partially because our signatures for time windows and session windows are not the same.
Should we clear the exception here? If not, then we'll have the exception thrown after the rebalance.
We need to make sure the `fetch` bounds don't go into the negative. We only call `processEarly` if the record's timestamp is within the timeDifferenceMs, but here we search starting at timestamp - 2*timeDifferenceMs
Maybe I'm missing something, but this doesn't appear to be used anywhere.
nit: we usually try to keep lines under 120 characters.
I think @hachikuji is thinking of the case where `ret.get(partition)` returns `null`. Not sure if we are enforcing that elsewhere though.
```suggestion capturedConsumedCallback.getValue().onCompletion(null, new ConsumerRecord<>(TOPIC, 1, 0, 0L, TimestampType.CREATE_TIME, 0L, 0, 0, TP1_KEY.array(), null)); ```
nit: final on params here and methods below.
Ah. I missed that we have only only `CogroupedKStreamImpl` object (my mental model was that we have one for each input stream). What's unclear to me atm (maybe I need to do more detailed review) is, how repartitioning works? For that case, when do we insert a "source" node that is reading from the repartition topic, and where does the source node get the `Serde` information from? We could also have multiple independent repartition steps for different input streams.
This probably doesn't work. Better just throw an unsupported exception instead of implementing the value getter.
```suggestion * ReadOnlyWindowStore<K, ValueAndTimestamp<Long>> localWindowStore = streams.store(queryableStoreName, QueryableStoreTypes.<K, ValueAndTimestamp<Long>>timestampedWindowStore()); ```
Let's make this protected. ```suggestion protected InternalSinkRecord(ConsumerRecord<byte[], byte[]> originalRecord, String topic, ```
@mumrah : equality for the generated messages should mean bytewise equality. So if two FetchResponseData instances contain the same data, they should be equal, even if one is using MemoryRecords and the other is using FileRecords. Same for hashCode, of course. If it's too much trouble to change the Records class, you can just write a static utility method in MessageUtils and invoke it from the generated classes. I expect that we won't be doing this kind of comparison except in tests, so you don't need to optimize the method too much.
The names are terrible. You don't suspendImpl something, you suspend it. You don't commitImpl, you commit.
Yeah, you can use a volatile field and synchronize on the assignment if still null. And then file a separate Jira to remove it from the class in a separate PR.
The original intent of the test was to ensure, we don't write into non-exiting topics, ie, create a topic out of nowhere -- but with the new abstraction that cannot happen anyway I guess.
This test just needs a rename: it calls `shouldNotAllowToResetWhileStreamsIsRunning()` and should have the same name. There are two separate test below: one for invalid input topic and one for invalid intermediate topic. (or did you mean something else, @bbejeck )
It looks like these are backwards. If I understand this method signature, even though iteration is reversed, the "from" key is still the lower bound, and the "to" key is the upper.
nit: Please fix code style.
I wonder if we could have a simple `IntRef` or something like that in the `common` classes to make this a little clearer. It would also help us in awkward lambda situations where we are not allowed to use a normal variable.
Nit: too many blank lines.
One idea that I had was to make this a `Map<Integer, Long>`, with the value being `System.currentTimeMillis()` at the time the fetch request is sent. That would allow the "Skipping fetch for partition" log message to include the duration that the previous request has been pending for (possibly adjusting the log level based on how long ago that previous request was sent), and also enable a fetch request time metric to be easily collected if someone wishes to add that enhancement in the future.
nit: past control records or aborted transactions when isolation.level=READ_COMMITTED
Do you want `@DefaultValue` or whatever the appropriate annotation is? Same for rest of the `forward` flags.
It does seem like we could pass the node id to `RequestSend` without much issue.
Why add this and the next ctor? They aren't used anywhere. We should add them when/if they are needed
The original motivation is to maintain the information of which thread was hitting this error, but the current implementation does not maintain that any more.. I'm not sure if it was lost somewhere in previous commit or it is never the case. But this is what I've in mind originally: ``` final String logPrefix = String.format("stream-thread [%s] ", threadClientId); final LogContext logContext = new LogContext(logPrefix); final Logger log = logContext.logger(LogAndContinueExceptionHandler.class); ```
Do we need to log here? All errors are logging in L163 already (and I think we would log it again in upper layers)
Definitely. This is one of my favorite gripes. Using more specific types whenever possible allows the compiler to do more work for us.
I think the logic here is not correct: we should still resume the main consumer and assign standby partitions if active tasks are all running; we should only alter the logic of returning flag with both active / standby all running.
nit: both lines missing . at end
Lines L#93 to L#98 can be replaced by: ``` assignment.keySet().retainAll(subscription); ``` same effect, as we want the intersection of `assignment` and `subscription`
maybe "Restoration completed for partitions:"
Could surround this call with new lines as you did for the others? Makes the calls under test more visible.
Could also do the following to be a bit more succinct: ```suggestion assertEquals(Schema.Type.INT32, transformedSchema.field("date").schema().type()); ```
This for loop is pretty similar to one in the `resolveConfigVariables(...)` method. Can we extract to a static helper method? I think it would also help make things a bit more clear, too.
Should not have an implementation but call overloaded method.
In `transform()` we have a sentence: ``` The {@link Transformer} must return a {@link KeyValue} type in {@link Transformer#transform(Object, Object) transform()} ``` Might be good to add this here too and point out it might be a an `Iterable` plus example. Compare `flatMap()`: ``` * The provided {@link KeyValueMapper} must return an {@link Iterable} (e.g., any {@link java.util.Collection} type) * and the return value must not be {@code null}. ```
To be honest, this lazy expiration seems like overkill. It should be a rare case where we actually have entries in `soonToExpireInFlightBatches` because of the other optimization to only add to it when the delivery timeout will expire prior to the request timeout. And if the producer is in a situation where batches are being expired, then the performance of removal for a particular batch is probably not a major concern. Maybe some benchmarking would show whether it is a worthwhile optimization.
Tiny nitpick: `TopicPartition.toString` does what you are doing manually here, so you could simplify it by just saying: ``` java "Batch containing " + recordCount + " record(s) expired due to timeout while requesting metadata from brokers for " + topicPartition ```
```If the thread is callback thread. Calling flush() from callback is not allowed since it makes deadlock.```
to me it seems like we can't possibly know what the constraints of all reporters would be and they don't provide an interface for validation, so it should be up to them to figure out how to substitute. but i've also asked some other folks to maybe chime in here who may have better context on how we've handled this elsewhere.
This is part of KIP-516
Shouldn't this be called once we refresh only? As far as I understand, this code will greedily refresh all possible connections (more than 1 every 10ms) if they are available. I think we should have a separate sleep call when there isn't a connection to maintain
Feel free to do a PR against https://github.com/apache/kafka-site
To get rid of the warning, you can just copy the body of `close(long, TimeUnit)`. If you don't want duplication, you can make the deprecated method call the non-deprecated one.
With the type promotion changes I think you'll need to pass in both the original value and the projected value to this method and this assertion will have to change to something like `assertEquals(expectedProjected, projected)`.
I am confused. If we change `store.range(hello, "zooom");` should `hasNext()` not return `true` (start and end are inclusive). Thus, to me it seems the test is wrong and there must be a bug in the iterator code.
If we do allow an `int` here, we should a) check for bounds and b) re-validate values after the cast. Otherwise you can end up with invalid results (which should never happen in practice given the range of sane values for replication factor, but down casts like this always warrant such checks). However, I suspect just shifting to using `short` all the way back to the configs is probably a better solution.
nit: if you use `Utils.mkSet`, then you won't need the conversion below.
An alternative would be to also attempt to use `System.identityHashCode` to break ties in a way that would be consistent (up to the point that the hash code can be guaranteed to also be unique, which isn't perfect either).
nit: could be useful to log the type of exception in the assertion message.
Ah, I see. Thanks for the explanation
nit: newline for better IDE debugging.
Could we just use `Errors` throughout? You can always get the code from `Errors` if you really need it.
But why is this needed here? I don't know what the other test is doing but I don't understand why it's used here
The number of elements is not always 1. Each created thread-level sensor is added to this queue, e.g., `processLatencySensor`, `pollRecordsSensor`, etc. Check out the callers of `threadLevelSensor()`. Each queue contains all thread-level sensors for one single stream thread.
This is unused too
You might consider using `OptionalDouble`.
This is a fairly complicated line, so I'd recommend pulling out the connector class name as a variable assignment just before line 433. And, these 3 lines are calling `configState.connectorConfig(connName)` multiple times, so that should probably be pulled out to a local variable as well.
Nit: we typically just say `partition` in these cases. Same for the other `log.debug`.
@hachikuji OK, I am fine with that. @vahidhashemian Can you remove the `needUpdate` change here? Thanks.
nit: add `final`
Actually, it seems more than one figure needs updating. Makes me wonder if we should actually remove them altogether and let people read the code (which can't go stale) instead.
nit: chain these c'tors to consolidate code. Makes it easy to do validation etc in case a need arise in future.
This should disappear with my suggestion.
It's internal. So should be fine.
This debug message seems like it would appear _before_ we actually attempt to do any checking. It's probably worth keeping the old message (or something similar) _after_ the checking has been completed.
The recursion here seems a bit wonky: if this function is called directly from the caller (i.e. not from a recursive call), then we should not return the `startSeekingNode` even it if satisfies the condition. I think we should refactor it a bit to loop over the parents and validate on the condition on each parent, if not call recursively on the parent node, and then loop to the next parent.
@mjsax What you suggested sounds right to me.
Yes, I was suggesting separate methods. Something like this: ``` private void resetGeneration() { this.generation = Generation.NO_GENERATION; this.state = MemberState.UNJOINED; this.rejoinNeeded = true; } public synchronized void resetGenerationOnLeaveGroup(String causeMessage) { log.debug("Resetting generation due to consumer pro-actively leaving the group"); resetGeneration(); } protected synchronized void resetGenerationOnResponseError(ApiKeys api, Errors error) { log.debug("Resetting generation after encountering " + error + " from " + api + response); resetGeneration(); } ```
I had to stare at the `SampledStat` code most of today. I actually think the original code is correct. The elapsed time should be the time elapsed in the current window plus the previous (non-obsolete) windows. It seems this is exactly what the current code is doing. Your change I think would effectively almost double the actual elapsed time. Maybe we can discuss this offline.
nit: new lines are generally not recommended to break object type declaration with object name. For this specific line I think we can still make them in one line.
This assertion tries to capture 3 cases: 1. All good, return `Optional.of(true)` 2. The boolean logic in the method is `false` (e.g. tasks are not ready, connector is not ready, an error response was returned etc). Please return `Optional.of(false)` 3. Exception was thrown and I can't say. Return `Optional.empty()` So based on this, how you'll interpret (3) is up to you on the `waitForCondition`. And here you want to treat it as `false`. That's why `orElse(false)` is more appropriate.
Ah, you're right. I was thinking that the `numberOfOpenFiles` variable was a field (i.e., persistent).
This should also be synchronized
Could we also move this only to the `StreamTask`? Doesn't have to be in this PR.
What's the deal with the `name` attribute instead of `id`? From what I can gather about html versions, `name` isn't actually valid in HTML, even HTML5, and `id` is the correct attribute to use.
There is no need to test this as it is calling the same method as above.
Ah, yeah, you'd need to do something more like what actually happens in the actual KafkaConsumer/`getAssignorInstances` code. eg ``` @Test @SuppressWarnings("unchecked") public void shouldInstantiateAssignorClass() { Object classTypes = Collections.singletonList(StickyAssignor.class); List<ConsumerPartitionAssignor> assignors = getAssignorInstances((List<String>) classTypes, Collections.emptyMap()); assertTrue(assignors.get(0) instanceof StickyAssignor); } ```
> Thinking about this once more, can a "global processor" have multiple children to begin with? Yeah, you could be correct about, I don't think it can.
Isn't this a behavior change? IIRC, we had a discussion to do this change, or to maybe make it configurable if we want to interleave processing with recovery.
If we're just testing broker compatibility I don't think we even need this part of the test.
This test just needs a rename: it calls `shouldNotAllowToResetWhileStreamsIsRunning()` and should have the same name. There are two separate test below: one for invalid input topic and one for invalid intermediate topic. (or did you mean something else, @bbejeck )
hm.. maybe I just did not notice `config.timeWindowMs`. All good now.
nit: avoid unnecessary `this.` prefix
Yup, that makes sense to me. I'm thinking about the world where standbys (and also restoring tasks) are executed on different threads. The concern about IQ are valid indeed that with a large set of un-compacted L0 files. In the even larger scope, where we would have checkpoints I'd believe that bulk-loading would not be very necessary since we would not have a huge number of records to catch up any more :)
Adding this constructor is quite dangerous because it's almost the same as the one that takes `partition` (the only difference is that one is a `Long` and the other is an `Integer`)
Asking because neither a `List<T>` nor a `Deserializer<T>` need a `Comparator`.
Seems like we should move this above into the top-level `process` instead of first calling `processInOrder` and then calling `processEarly`. For one thing, since we actually do need to iterate the full range for the early records, we can just call `processEarly` without having to decide between `processInOrder` and `processReverse`
Minor typo, `were` -> `where`? Also, `10 <= start time <= 20` might be slightly better notation.
We should also validate (in our tests) that the user cannot modify the underlying stream because, as I understand the proposed semantics, "an unchanged stream" is an invariant we want to guarantee as part of the contract.
One other minor note: for whatever reason, the new consumer uses the term "records" instead of "messages." We flop back and forth between these terms even in this class, but it would be nice to start to settle.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
One other minor note: for whatever reason, the new consumer uses the term "records" instead of "messages." We flop back and forth between these terms even in this class, but it would be nice to start to settle.
add `final` twice
Throwing `IllegalStateException` is served as the purpose that "this should never happen, and if it does it is a bug and hence it is ok to fail and stop the world".
If `new KafkaStreams` throws, this line will never be executed (same below). Also, `streams` will not have any object assigned. Thus, we cannot even close anything, as the object was never created -- I think we can remove this line and also remove the variable `streams`.
nit: might be better to set end to another timestamp.
I'm not sure why this needs to be a field. It looks like it is used to measure latency, but then why not just use a local variable around the code that is being timed?, i.e, ``` final long start = time.milliseconds() // do some computations computeLatency(start) ``` Also, the name doesn't seem correct as it isn't really the current time. It is more like `timerStartedMs`
Not sure about the terminology here. Reader and writer don't make sense in this context since nothing is being read or written. Maybe source and target? Also, it's possible the intent might be clearer if `writer` and `record` were next to each other in the argument list since `record` should be in the `writer` format and being converted to `reader` format.
ditto on removing before/after.
You've added a few empty lines in this file. We should remove these
I think we need to insert a `fail` here to fix this test
Then the log message should state the reason (e.g., the class was not found) and that the named provider will not be used. However, it does seem strange that this is technically an invalid configuration, so why would we not just throw a ConfigException? Note around lines 723 how any configuration property whose value is a Class name will be invalid if a `ClassNotFoundException` is caught, and this leads to a `ConfigException`. Silently ignoring seems at best inconsistent but at worst a bad idea.
Yeah, that's fair. Just thought I'd mention it since it stood out while reviewing the patch.
I'm not sure this makes sense. The offsets for each group are isolated, so `consumer2` would actually start from position 0. I think a better test case would be the following: 1. Start a single consumer with autocommit disabled. 2. Read 5 records. 3. Call unsubscribe(). 4. Verify that no offset commit request was sent. To be honest, this might be overkill, but I wouldn't complain if it was present.
nit: double space
Okay, could we have two signatures then? ``` Collection<T> XXTasks(); Collection<TaskId> XXTaskIds(); ```
The deserialized is actually different since we need to differentiate between `timeWindowed` and `sessionWindowed`. It is partially because our signatures for time windows and session windows are not the same.
Yes, it seems that -1 means that we are trying to read beyond the end of the channel, which probably should be treated as abnormal.
nit: Please fix code style.
We should verify the actual timestamp.
nit: i find it helps to space out the replayAll and verifyAll from other code as it helps visually break up the test into mocks/expectations and the method calls you are actually testing.
You might consider using `OptionalDouble`.
`HeaderConverter` and this method don't exist prior to AK 1.1.
nit: add `final` -- same next line
This is where we leave the group. Any offset commits which haven't yet been sent will definitely fail after this, so I think we need to move that loop into the try block.
Can we think of a better name for this? `pairs` doesn't really tell me anything.
@guozhangwang **Forgive me if I misunderstood this method, really**. But if the list is composed of key-value pairs, wouldn't this for loop goes up to the the middle of the array? Plus, if `tags` is `"a","1","b","2"` the final map will be `"a" -> "1", "1" -> "b"`. Is this the right intend? Besides not reaching "b" -> "2", it will make the previous value a key in the next iteration. If not, I suppose we could rewrite it as ``` for (int i = 0; i < tags.length; ) { tagMap.put(tags[i], tags[i+1]); i += 2; } ``` Again, forgive me if I understood everything wrong.
This will probably be subjective, but I'm ok with "hop" for now.
either move `this` to next line, or fix indention.
this won't work with ipv6 addresses, I think there are some helper methods for this is org.apache.kafka.common.utils.Utils
Nit: add `final`
Though now I look at the message for `UINT16` I see it would be consistent with that. Still I think because there are two types involved here, the Java type and the network type, including both is clearest.
Although we are using the same default of `retries = 5` and `retry backoff = 100ms` now, there is a subtle difference that in the old code, we throw `TimeoutException` and handles it outside the call with retries, while in the `AdminClient` timeouts are not retried but failed directly. So we are effectively less resilient to broker unavailability. I synced with @cmccabe offline and I'm thinking maybe we can have a longer default request timeout value for admin configs for now using the prefix, and in the future we may have improved Admin Client generally to provide different timeout values for client / broker.
@mumrah : equality for the generated messages should mean bytewise equality. So if two FetchResponseData instances contain the same data, they should be equal, even if one is using MemoryRecords and the other is using FileRecords. Same for hashCode, of course. If it's too much trouble to change the Records class, you can just write a static utility method in MessageUtils and invoke it from the generated classes. I expect that we won't be doing this kind of comparison except in tests, so you don't need to optimize the method too much.
Technically, this is `numDrainedRecords`.
this problem also affect replication node fetch process? our server occur a error: [2019-04-05 23:59:46,084] WARN [ReplicaFetcherThread-1-1], Error in fetch kafka.server.ReplicaFetcherThread$FetchRequest@b22a64c (kafka.server.ReplicaFetcherThread) java.io.IOException: Connection to 1 was disconnected before the response was read but return to normal after a reboot kafka server.
Please avoid raw types, even when you don't need the type bound. ```suggestion for (final RankedClient<ID> rankedClient : rankedClients) { ```
Again, a bit more information would be more useful: ```suggestion // Then if we delete the connector, it and each of its tasks should be stopped by the framework // even though the producer is blocked because there is no topic ```
I think we can simplify this test. We only want to make sure the application directory gets deleted. Thus, we can create it manually, create the driver with corresponding config (passing in a empty Topology), call `close()` and check if the directory was deleted.
I would append a couple of batches after advancing the high-watermark. At this point the HWM equals the LEO.
I think the requirement should be stronger, we should check the subject has a KerberosPrincipal to skip the kerberos login. Else we can run into a situation that there is an alternate login context that has nothing to do with Kerberos and we'll fail.
This block can be moved outside of the `try-catch-block`
using `assertThat` is nicer as it gives better failure messages. `assertThat(sourceNode.getTimestampExtractor(), instanceOf(MockTimestaampExtractor))` in other places, too
I think we may be able to get rid of some of the `bytesRead` bookkeeping. As far as I can tell, it is only used in the exception message below and it seems redundant there (i.e. sizeOfBodyInBytes - bytesRemaining = bytesRead).
In `StreamsConfig` we do populate the map from consumer / producer's default values first then use user specified values to overwrite, so it should be safe to `config.getInt` where `config` is of type `StreamsConfig`.
```suggestion synchronized (stateLock) { if (isRunningOrRebalancing()) { streamThread.start(); return Optional.of(streamThread.getName()); } else { return Optional.empty(); } } ```
You've added a few empty lines in this file. We should remove these
Why not init with `new ArrayList<>(records.size())` and avoid the check in the `for` loop? Could be `final` than, too. If required, we can also `return remainingRecords.isEmpty() ? null : remainingRecords;` -- not sure atm who calls the method and what the impact of returning and empty list vs `null` is.
Re: your concern, I don't think we can assume that a user's state store's `init` method is idempotent. AFAIK nothing should change that's relevant to the state store registration, but if something does (eg TaskCorrupted) we'd have to wipe out everything and start it all again anyways
Yes, I had misread the code originally.
We don't throw NPE anywhere in the `RocksDBStore`, so that means these are coming from `RocksDB` itself. It might be better for us to do `Objects.requireNonNull(...)` in the relevant methods
Would this be any clearer? ```java OffsetSpec offsetRequestSpec = topicPartitionOffsets.get(tp); if (offsetRequestSpec == null) { future.completeExceptionally(error.exception()); } else if (shouldRefreshMetadata(error) { retryTopicPartitionOffsets.put(tp, offsetRequestSpec); } else { ... ``` Also, in the case of that we got back an unexpected partition, I think we can raise a new `KafkaException` and provide a clear message indicating what happened.
The only place we need this duration is ``` duration.negate().addTo(now); ``` `java.time.Duration` has `negated` but its `addTo` is taking a `Temporal`, and all its extends like `LocalTime` etc do not have the right API of `getTime`. So I think we just keep it like this.
Nit: let's avoid unrelated line additions.
`hop` vs `advance` is subjective :) I am fine with `hop`, too; it's called a `HoppingWindow` after all. `advance` is just a term that is quite common in literature so I am somewhat used to it.
Since we have three threads for this test, there can be multiple rebalances before the streams instance stabilize and start processing...
> and re-using the `KGroupedStream` results in an `InvalidToplogyException` when building the topology I thought, if there is no user topic-name, old code would create multiple repartition topics? And re-using `KGroupedStream` only throughs if there is a user topic-name (and this restriction is lifted with this PR)
@cmccabe (My suggestion might not be good) If it has to check `futures`'s `size` every time, what about assign one time and use many times? Because JVM has to calculate size everytime when it is called. ```suggestion final int futuresSize = futures.size(); if (throwable == null && results.size() != futuresSize) { ```
nit: unneeded newline
Hmm.. Are we safe to remove these given that this is a public API. It's _probably_ unlikely anyone is using them, but still..
May be the Converter, Serializer and Schema can be injected through the constructor. May be doesn't make sense for the samples(). I'm not too opinionated on the approach here since we can't use Junit 5.
On a second thought, the overhead should be minimal: a few young gen objects only. So mvn.
Does this actually need to be public? It looks like the SchemaBuilder uses names anyway and expects resolution to work internally. Adding another Schema class seems like its going to get confusing.
This loop only needs to happen once, so it seems like you can move it outsize the enclosing loop.
I was thinking that this should be `Collections.unmodifiableMap(tempProducerDefaultOverrides)` to ensure that it is never mutated after it's assigned.
Also - this method gives the ability to construct different configs for different nodes - so it seems like the logic for setting `self.security_config` doesn't belong here since it is independent of the node, and would have unintuitive behavior if it did become dependent on the node? (e.g. configuration of one node affecting configuration of other nodes)
```suggestion log.warn( ```
Yeah, there's some didactic aspect to a few lines that are just a bit harder to read of course. (for instance if it was `var` instead of `2` things would be different). But I was on the edge too. Fine with leaving it.
I would prefer a second loop to guarantee a consistent reflection on the task committed state.
nit: we may as well move this check into `ConsumerGroupMetadata` since we have some other null checks there.
Sounds good. I think this is convincing :)
This was not addressed yet. the whole sentence can be removed
To be honest, this lazy expiration seems like overkill. It should be a rare case where we actually have entries in `soonToExpireInFlightBatches` because of the other optimization to only add to it when the delivery timeout will expire prior to the request timeout. And if the producer is in a situation where batches are being expired, then the performance of removal for a particular batch is probably not a major concern. Maybe some benchmarking would show whether it is a worthwhile optimization.
@fhussonnois thinking about this some more, what is the motivation for doing a validation here for processor names? When Streams starts up the `AdminClient` will attempt to create any internal topics and the full topic names are validated at that point, so we don't need this check up front. \cc @guozhangwang
Yeah, I was thinking it was fine to remove it since users should not create an instance of this apart from tests and it's been deprecated for a few release cycles. Or if we think the method is useful, then it would make sense undeprecate it.
One more thing: since this is internal, we can change it later so if we think this is the best name we can find for it at the moment, we can leave as is.
Same here, this exception message does not apply to the case this is trying to catch
Why call it `now` and not `then` (or `previous`); `time.milliseconds()` give the current timestmap, ie, "now"
I'd clarify to sth like: > 2) use general data types (here: JSON; but can also be Avro generic bindings, etc.) for serdes in Kafka Streams. To make it clear that this example does not showcase Avro usage.
Nit: can you clean up the code further and add `{ }` (we prefer to use `{}` for all blocks. Thanks.
>Maybe, if a user tries to use the constructor when classes are already defined in the configs, we simply throw an exception? Forcing the user to set only one or the other That works for me. Tbh I actually prefer this, but thought you might consider it too harsh. Someone else had that reaction to a similar scenario in the past. Let's do it 
Hmm.. why not always clear it? The behavior becomes a bit less predictable if it depends on state which is not part of the current rebalance.
nit: add `final`
@guozhangwang i'm not sure why we would want to enforce caching? Perhaps the custom store is already an in memory store? Why would we cache that? Perhaps there is some other reason why they don't want caching for a given store.
IMHO the `close` method is little easier to follow by putting `if(clean)...{ }` block in a private method, possible name `closeIfClean(clean, task, t)`
I suggest only catching `KafkaException` and only close the client then. About other exceptions, we can probably try retrying or fail the thread, I don't have a strong preference. I don't think we should catch Throwable though, as that catches errors like `OutOfMemoryError`
Same here, I think `computeIfAbsent` would simplify the logic
Should we consider including the error message of `e` in to the exception as well? also nit: capitalized `Fatal`.
Yes. But if we add some more parameters later on, it would simplify the diff. But it's also ok to keep as it.
We need to choose at least a live replica.
Should we mention this in the KIP? It was not specified there - even though this is the same behavior as the old AlterConfigs, in the context of the KIP this non-transactional functionality isn't obvious I fear
Why are we removing these cached configuration values? The `JsonConverterConfig` class does not cache them, so every time we call a getter on the `config` instance -- which is at least one per value that is (de)serialized -- we are looking up and converting the string value of the configuration. That's quite inefficient at runtime. It's probably fine to remove these here as long as we add the cached config values inside the `JsonConverterConfig` class *and* (ideally) ensure all of the getter method calls on `JsonConverterConfig` can be inlined (e.g., making `JsonConverterConfig` final or making the getter methods final) to maintain performance. However, the latter part is more restricting and would not be backward compatible for anyone already subclassing the `JsonConverterConfig` class. So one option is to simply cache the values as final fields in `JsonConverterConfig`, have the non-final getter methods return these cached values, and hope that either the JIT inlines the getter methods (as long as there's no subclass loaded, non-final methods may be inlined) or the impact is negligible. The other option is to keep these final fields here in this class where we know we're using them very heavily and continuously. This may require changing the `LogicalTypeConverter.toJson(...)` method signature to pass the converter instance rather than the config. That's a tiny bit more messy, but we know we'll get faster evaluation of the various config options. I would prefer the second option simply because we can ensure this `JsonConverter` logic -- which is used very heavily -- is as fast as possible.
same... `@link` > `@close` for this case.
make this into a different test, i.e., `shouldSupportNullInFloatSerde` or similiar
Nit: this is really primarily where the configuration properties go, plus any optional config provider properties. How about: ```suggestion * @param originals the configuration properties plus any optional config provider properties; may not be null ```
It seems like we ought to just define `log` at the AbstractTask level and avoid having two almost identical `maybeInitTaskTimeoutOrThrow` method definitions.
\cc @lindong28 -- seem's you forgot to update this when dumping the version in `1.1` branch.
I think we should probably retry on coordinator level errors. Take a look at some of the other consumer group APIs to see how we handle errors. For example, see `ConsumerGroupOperationContext.hasCoordinatorMoved`.
Are you going to update the other two to remove unnecessary operations? That's all that's left and then I can merge the PR. Thanks!
```suggestion * Furthermore, via {@link org.apache.kafka.streams.processor.Punctuator#punctuate()} the processing progress can ```
we need to shutdown the executor service even if there is a test failure (either in a finally block or the teardown).
ditto on the properties and the driver.
It seems this test is always using `Cluster.empty()`, which means it never tests state transitions from a topic that is in use to a topic that falls out of use and gets `UNKNOWN_TOPIC_OR_PARTITION` errors.
an -> a
Sensor names don't appear in JMX.
nit: I'm wondering if just using would suffice (IMHO slightly easier to immediately grok the meaning). ```java if (!cachingEnable) { context.forward(key, new Change<>(newValue, oldValue)); } ```
It may be worth handling overflow here as people could pass `Long.MAX_VALUE` for `waitTimeDuration`.
Changed it locally.
nit: `child` -> `toChild`
an -> a
I think we could reduce the change of this PR by reverting the numbering change which seems unnecessary.
You are right. Never mind.
The original approach is to avoid throwing exceptions on each of the record: for example, if you get a timeout exception on the request, all records in the batch will return the same exception in that callback, which will spill the log4j since we will get one error for each record.
What do you think of combining these two checks to one and call it `waitForTransitionFromRebalancingToRunning()`. They are always used together.
Heh, I actually just looked it up, because I was surprised all those other `<p>` elements were not closed... Apparently, even in HTML, you don't _have_ to close `<p>` elements: > Paragraphs are block-level elements, and notably will automatically close if another block-level element is parsed before the closing \</p\> tag. > https://developer.mozilla.org/en-US/docs/Web/HTML/Element/p Sometimes, you just have to stop and marvel at HTML...
IMHO the `close` method is little easier to follow by putting `if(clean)...{ }` block in a private method, possible name `closeIfClean(clean, task, t)`
I don't think you want to get rid of the `validateBasicConnectorConfig` call. The default just calls validate, but in `DistributedHerder` it also validates there won't be a conflict between the worker and consumer group for sink connectors.
When reaching this point, we have tried our best to assign standby tasks with rack awareness to all clients. I think we should have a debug log here, to log some current status, like current assignment, `pendingStandbyTaskToNumberRemainingStandbys`, `pendingStandbyTaskToClientId`, and mention we're going to distribute the remaining tasks with least loaded assignor...etc, for better troubleshooting.
nit: `this method will....`
```suggestion * @throws ConnectException if the configuration fails to be serialized or if the request could not be sent ```
I would append a couple of batches after advancing the high-watermark. At this point the HWM equals the LEO.
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
Hmm, but we're not actually calling the listener here. We do that separately.
Discussed offline with Becket - rework this patch to avoid the null checks elsewhere; i.e., make the accumulator more explicitly aware of the `sendInOrder` requirement
depending on the decision regarding naming sources for `builder.table` we'll need to update this test.
nit: I think it's better to just print the e.message in a single line.
Since we're specifying the key, we expect only to get back windows with the value for that key. The aggregation we specified is to sum all values for the key, and it comes out to `2` because we only write one value for each key; namely, the value is the same number as the key.
Not sure why it's the case? I think the previous pending txn should have aborted in step 4.
From my tests it doesn't seam to work. The CG doesn't show up in the target cluster when listing with `kafka-consumer-groups.sh`. Also, when I start a consumer it resets the offset to what is configured in the consumer (latest in my case).
style nit: if the entire body is surrounded in a conditional, it's usually more readable to just check the negation and return, then reduce indentation with the rest of the body. no real need to fix here, just a style thing to watch out for moving forward.
Do we really need to set a fatal error for every consumer, or could we just remove the problem partition from the assignment and set NEEDS_REJOIN? Or is it better to just fail fast
Not sure if I can follow. The old code calls `driver.flushState();` after each `driver.process(...)` call.
these 2 lines shouldn't be here
I think you can do the zookeeper start in the `setUp` method
Unfortunately, the consumer groups are not aggregated in the same way that topic metadata is. To get all the groups in the cluster, you have to send the ListGroups request to all nodes.
Can `LogManager.getRootLogger().getLevel()` be `null`? With other loggers you return the effective level if that's the case.
This doesn't look right..why would we need to pass in the `key` and `value` to `createRightWindow` ? The distinguishing feature of the current record's right window is that it doesn't include the current record at all. I see that `createRightWindow` ultimately calls `putAndForward` which takes a key and value, but that just seems misleading. I think we should either pass in `null` to `putAndForward` for things we don't need, or better yet (imo) don't use `putAndForward` for the right window creation and just have a clean separation between creation of the right window and everything else
nit: "Null value is encoded..." -> "A null value is encoded..."
We could get away with a single `*`
I see. Could we do something like this: first assign the partitions for all internal topics as the writing topology's number of tasks, i.e.: ``` // for all internal source topics, // first set the number of partitions to the maximum of the depending sub-topologies source topics for (Map.Entry<Integer, TopologyBuilder.TopicsInfo> entry : topicGroups.entrySet()) { Set<String> internalTopics = entry.getValue().interSourceTopics; for (String internalTopic : internalTopics) { Set<TaskId> tasks = internalSourceTopicToTaskIds.get(internalTopic); if (tasks == null) { int numPartitions = -1; for (Map.Entry<Integer, TopologyBuilder.TopicsInfo> other : topicGroups.entrySet()) { Set<String> otherSinkTopics = other.getValue().sinkTopics; if (otherSinkTopics.contains(internalTopic)) { for (String topic : other.getValue().sourceTopics) { List<PartitionInfo> infos = metadata.partitionsForTopic(topic); if (infos != null && infos.size() > numPartitions) numPartitions = infos.size(); } } } internalSourceTopicToTaskIds.put(internalTopic, Collections.singleton(new TaskId(entry.getKey(), numPartitions))); } } } ``` And then update the Cluster metadata with `Cluster.withPartitions`, then in the `ensureCopartitioning` call, if after the first for-loop, `numPartitions` is still -1, it means all topics in this co-partition group are internal topics, and then in this case read from `metadata.partitionsForTopic` and took the maximum among all of them; and then later after calling `prepareTopic`, the metadata will be updated again with `metadata.withPartitions()`.
Yeah, that works, too, and is more align with the current code.
This test seems to pass with the original logic. I'm wondering if we need to let the offset request take two partitions. One of them can succeed and the other can fail due to the provided error so that we are handling the partial failure case.
Because `ValueTransformerWithKeySupplier` is a public interface, we should try to find a solution that does not add a deprecated method to this new interface. If my proposal doesn't work, I am sure there is another solution (using sub-classing etc) to do some internal re-directs to make it work.
Can we change the naming to use `ALL_CAPS`? For example, compare with the definition of `RemotePartitionDeleteState` in this PR.
You can either make them non-static or pass `Logger` as a parameter. Makes no difference to me, but `log` won't work as a static field when you have multiple instances.
I am wondering, if we should to even more refactoring an pass in `Serialized` directly here to reduce the number of parameters. Not sure though if the win out weights the refactoring effort. Same for the other PRs btw. Any thoughts? \cc @guozhangwang @bbejeck
I was looking at the `append` code and it seems a bit brittle. It assumes that: - The collection returned from `PartitionRecords.take` is safe to mutate even though the latter returns `Collections.emptyList()` if `records == null` - That `part.take` will always return at least one element This is fine today, but it may be worth making it a bit more robust to refactorings.
Please include TopicDeletionDisabledException here.
Using `admin = null` here allows to GC the unused admin instance earlier, right? Not a big gain, but also I don't see much benefit by using a variable such as `useAdminForListOffsets`
nit: don't need the type params on the next three lines
Can you please explain why it's better to warn than to fail-fast in this case? Just want to make sure I understand the reasoning for the choice.
nit: `anf` -> `and`
Can you explain this a bit further? Why do we return null when the group is stable, I assume stable means everyone is successfully on the same generation? So why return null rather than the actual generation.
nit: line too long
It doesn't rely on the OS, it's a JVM intrinsic (this is a critical distinction). And it's used all over the place by the collection libraries. We only really care about Linux performance. If it's a small number of bytes, it may not matter, but generally I think perf driven changes have to be measured.
`keySerde` -> `valueSerde`
nit: Please fix code style.
```suggestion "The desired Unix precision for the timestamp. Used to generate the output when type=unix " + ```
This test went from checking for exactly one message, to checking at least one message. If you think that is fine (I dont have the full scope so I dont know) then LGTM! :)
We did not have this check before, why is it needed? Also checks here are only applied when running in "driver" mode.
Method should not be `final`. Additionally the `final` keyword for method arguments and local variables is not required and does not improve readability of the code here. Indeed Java does not distinguish between readonly and read-write variables. But unless an anonymous class is declared (this requirement is removed after Java 8) or the variable is used further down in the code (improved readability) marking every single readonly variable as final does not make things better IMHO.
```suggestion info.userEndPoint(), taskManager().getTaskOffsetSums()) ```
nit: we can throw illegal-state if the state() == RESTORING since it should never happen.
Sorry, my bad! It doesn't matter whether it is called or not, since the `IllegalStateException` is thrown.
add `final` (also all other methods below)
Why do you need separate `kill_consumer` method and a `stop_node` method? Or maybe just make the naming consistent with your change to `verifiable_producer.py` and call this `kill_node`
If you use this, you can also remove the `byte[] byteArray = null` variable as you can just return from within the try statement.
I think we can move this into the block above line 70 to 72 and simplify: ``` if (!needsInitializing.isEmpty()) { initialize(); updatedEndOffsets.putAll(restoreConsumer.endOffsets(needsInitializing.keySet())); } ```
One thing I was considering is whether we should be explicit about when we expect these entries to be inserted. We could raise an exception from `get` here in cases where we expect the state to exist. For example, for the transactional producer, we have `maybeAddPartitionToTransaction` where we could explicitly insert. For idempotent producer, probably the first time we try to access the sequence for a partition or something. Anyway, just a thought, but it might make the code a little easier to reason about.
Also, I just looked at `ConnectRecord.toString()`, and it does _not_ print the schemas. I wonder if it's worth changing that to include whether the key schema and value schema are null; e.g., ``` @Override public String toString() { return "ConnectRecord{" + "topic='" + topic + '\'' + ", kafkaPartition=" + kafkaPartition + ", keySchema=" + (keySchema != null ? "..." : "null") + ", key=" + key + ", valueSchema=" + (valueSchema != null ? "..." : "null") + ", value=" + value + ", timestamp=" + timestamp + ", headers=" + headers + '}'; } ```
SGTM, thanks @mjsax to bring to our attention.
Don't we need to set version 0.10.1 for those initially? Otherwise, they will have trunk version
Is the change in behavior intentional? `SecurityException`, which was previously caught and logged, is an instance of `RuntimeException`.
I would maintain the terminology of "subscribe" to topics and "assigned" partitions, and say: "manually specify the partitions that are assigned to it"
Pls use caps :) (see your `ErrorReporter` above).
Or https://github.com/google/guava/blob/master/guava/src/com/google/common/math/IntMath.java#L56-L72 It is safe to look as it is Apache License 2.0.
What do you think of combining these two checks to one and call it `waitForTransitionFromRebalancingToRunning()`. They are always used together.
`return` is not necessary
Can we at least log a warning with the exception we're swallowing? Same for the `catch (final OverlappingFileLockException | IOException e) ` above
`start` is not used.
I think it's just a computer-sciencey matter of principle. `clientsByTaskLoad` is a linear collection, so every `offer` would become `O(n)` if we did a `contains` call on it every time. Right now, it's only `O(n)` when we need to remove the prior record for the same client, and `O(log(n))` otherwise. Does it really matter? I'm not sure.
I think @becketqin was suggesting that we can add a method to `Kafka` that would cause the thread waiting on `KafkaServer.shutdownLatch` to resume and call `System.exit()` with the appropriate exit status.
Nit: why not `failIfNotReadyForSend`? One character longer, but reads a bit better. :)
Yeah if it exists elsewhere let's just leave it as is for now.
Unnecessary `new String[] {}`, can just use the string as varargs for `Arrays.asList`. Same pattern is used in multiple places in this class.
Let's use try with resources here and the other test so that the file is closed after it's used.
Ideally, we'd always use brackets on control flow operators.
We don't usually assert on exception messages as it makes tests a bit brittle. This applies to a few other tests too.
nit: add `final`
I think you want: `wait_until(lambda: self.producer.num_acked == MAX_MESSAGES, ...)` since if you specify `max_messages`, the verifiable producer will produce at most `max_messages` In the current form, I think it is guaranteed to time out
Originally we were just thinking about notifying the user, not necessarily giving them additional help to track it down (ideally you don't need this as you have a clear threading model and consumer ownership), but obviously that's not always the case. If we can get the name included too, that'd be ideal, so I'm open to changes as long as we're convinced it otherwise maintains the same semantics.
`fail` is not required. Maybe, it would be better though to have a try-catch around this (and use `fail`) and remove `expected` annoation (using `expected` should only be done for single-line tests).
I think that code got in by mistake. There is a PR by @rajinisivaram for supporting SASL/PLAIN, but it hasn't been merged yet. Support for SASL in system tests was also contributed by @rajinisivaram and maybe it assumed the presence of the yet unmerged PR.
remove this line
Can you elaborate? I don't see any point in the code where we would return between adding the topic and awaiting the update.
Let me clarify what I meant. In `TransactionManager.initializeTransactions`, we return a `TransactionalRequestResult`, which we wait on from `initTransactions()`. What I am suggesting is that we could cache the instance of `TransactionalRequestResult` inside `TransactionManager`; if `initTransactions()` times out and is invoked again, we can just continue waiting on the same result object. So it does not change the API.
We should verify the actual timestamp.
Maybe consider replacing `Stack` with `Deque` as `Stack` is synchronized and `ownedSensors` only adds in the constructor and removes values in `synchronized` block already.
I hope you don't mind if I jump in... It's probably worth doing some experiments to get the bounds just right. Here are the basic properties we need: Let's say we have a simple class hierarchy: ``` interface Animal interface Cat extends Animal interface Dog extends Animal ``` And let's say we subclass `KeyValue`: `public class KV extends KeyValue`. Given a `KStream<String, Cat>`, we want to be able to call `flatTransform` with a `TransformerSupplier<String, Animal, List<KeyValue<Animal>>>` like this one: `(String s, Animal a) -> asList(new KV(s, new Cat()), new KeyValue(s, new Dog()))`. The `? super K` and `? super V` ensure that any transformer that _can handle_ a `K` and `V` is permitted. You _can handle_ an instance if you can assign it to you parameter types (so your parameter type is a supertype of the instance type). You need to specify this as a bound because the compiler doesn't generally let me assign a supertype to a subtype (I can't write `Cat c = (Animal) a;`). I don't think you actually need the `? extends Whatever` parts to get the right outcome. If anything, you might need it on the stuff inside the iterable to make sure that you can just pass in heterogeneous members, and they'll get "rounded" to their lowest common superclass. I think this works without `extends` because you generally _can_ assign a subtype to a supertype. So maybe try an example like this without the `extends` stuff and see if the compiler chokes on it or not.
Better name as "setCurrentNodeInProcessorContext"? And then in java docs mention that it returns the processor context with current node set.
The name `restoreAvailableMemoryOnFailure` is a bit weird because we should always restore available memory on failure. Maybe we can name it `hasError` and set it to `false` right before `return buffer`.
`consumer messages` should be `consume messages`
> Mainly because I was more comfortable verifying that topics actually get created when using repartition operation. I guess that is fair. (I just try to keep test runtime short if we can -- let's keep the integration test.)
@bbejeck That is a good question! Originally I thought it is okay to always calling `hasNext` inside `next()`, as long as we make sure `hasNext` implementation is idempotent, i.e. calling it multiple times before `next()` does not have side effect is sufficient. But by making it idempotent we could have the corner case you mentioned. For example: ``` t0: call `hasNext()` -> store is still open -> call `makeNext` -> `next` field is set. t1: store is closed. t2: call `next()` -> call `hasNext()` again ``` Without this check, at `t3` we would still return the `next` field.
This can be static
I think `kafkaOffset` was incorrectly changed to `Long`. We'll always have a Kafka offset, so it should be `long`. Also, the current version breaks compatibility since the old signature constructor is no longer available.
```suggestion /** * Changelog topic partitions for the state stores the standby tasks of the Streams client replicates. * * @return set of changelog topic partitions of the standby tasks */ ```
I'm not sure of the original motivation behind setting it to `50`. But if we are going to define it as `1000` i think it might be better to remove this and `reconnect_backoff_min_ms_config` definitations from here as they are the same as what is set in the `ProducerConfig` and `ConsumerConfig`, so it seem pretty pointless overriding them
Is this `null` assignment needed? Don't see the variable used after this.
I don't think it's necessary to warn in this case. Maybe debug, but not warn. If callers are concerned, they can check the parameters before calling the method.
@ewencp Yeah, we can do that and I was debating whether I should suggest it. I wasn't sure if we wanted to make a change that could impact the common path so that the error message could include the thread name for the `currentThread`. You reviewed the original commit that introduced `acquire` and `release`, so you are in a better position to judge. :)
I would move line 328 and 329 to before this line.
That makes sense. But what I don't know is, why we only consider `partitions` in the first place...
Line too long (also some lines above and further below)
nit: it was correct before
Using generic types instead of raw types for collections is preferable (we can fix elsewhere in the file too) ```suggestion List<?> items = (List<?>) value; ```
Thanks for the explanation. A bit subtle as you had said. :)
Hmm, `DataInputStream.readFully` only throws an exception if we ask it to read past the end of the InputStream. So supposedly, if we fix the underlying InputStream, it's enough either way. The following PR does that: https://github.com/apache/kafka/pull/2025/files#diff-eaa7e4414f285da2ff8e4508456078d2L192
Should we still do `taskManager.setClusterMetadata(fullMetadata);` before returning? I'm not sure if it will give us any good but just bringing this up..
Nit: -> `messagePrefix + "It shouldn't be null.")` (remove space -- this allows to hand is an empty prefix without getting an undesired whitespace (ie, `""`, if prefix is not desired). Similar below.
Oh yeah, duh. Nevermind this 
Why don't we extract this loop into a separate method that takes an interface like: ``` scala interface WaitPredicate { boolean test(); } ``` Then we can reuse the logic from the different variants.
I've been thinking about this and I wonder if this is the best way to handle this. It feels a bit error-prone to pass a `RecordMetadata` with almost nothing set. Have we considered passing the topic and nullable partition via the `exception` parameter? It's then easy to explain: if an error occurred, the second parameter is set, otherwise the first parameter is set. This would imply having a custom exception type that would include topic, nullable partition and the original exception.
you don't use `windowedDeserializer ` or `inner` below -- can be removed IMHO
The deserialized is actually different since we need to differentiate between `timeWindowed` and `sessionWindowed`. It is partially because our signatures for time windows and session windows are not the same.
Since this is at the end of runOnce, I'm wondering if it also makes sense to log whether we committed or punctuated, and whether/how many records we polled at the beginning of the method. Basically, it seems like, if it's a good idea to log some information once per cycle, then it's probably a good idea to summarize everything you'd want to know.
(Tbh that drives me crazy, I once spent like 4 hours debugging something only to realize that I wasn't using the correct TimeoutException  )
```suggestion /** * Host where the Streams client runs. * * This method is equivalent to {@code StreamsMetadata.hostInfo().host();} * * @return the host where the Streams client runs */ ```
never mind then. I'll leave this to AI.
`innerDeserializer` could be null; we should handle to case to avoid a NPE calling `getClass()`
Not sure if we need this? If the shutdown is not clean, we logged an ERROR before in `StreamThread#run()`
Not really sure this has value if the test case expects the leader change correctly.
Not sure if I can follow. The old code calls `driver.flushState();` after each `driver.process(...)` call.
Can this be a `byte`.
Oh yeah, duh. Nevermind this 
Should we restrict the values for name and version? Maybe we can just test that they are non empty? nit: the non-capture group isn't really necessary and this regex matches stuff like `"."` and `"---"`.
nit: add `a {@link Named} config`
Since this is a general `toString()`, we probably should handle manual assignment as well.
Hmm, is this method the only place where we would sync the data to disk? I thought we would want to sync to disk periodically as well.
Not sure what has changed here.
Child-Index was deprecated recently -- should we remove it? Also, with KIP-251, we should capture output timestamps, too.
This was the checkstyle error that was failing your build.
Existing issue, space should be after the colon.
I am wondering, if we should to even more refactoring an pass in `Serialized` directly here to reduce the number of parameters. Not sure though if the win out weights the refactoring effort. Same for the other PRs btw. Any thoughts? \cc @guozhangwang @bbejeck
prop: We could do ``` committed += taskManager.commitAllStandby(); if (committed > 0) ``` for the rest of the logic so that we don't need a separate `if (committed > 0)` later
Oh, nevermind. I didn't see the following line.
you don't use `windowedDeserializer ` or `inner` below -- can be removed IMHO
none from what I can see, but I'm not sure it's worth holding up the PR for it.
`usually` -> `default` (I hope that people *usually* change the default to avoid unwanted state recreating if `temp` gets wiped out :) And: closing `)` missing at the end.
Seems the `fastTimeout` should be thread-safe since it will be accessed by both RequestSendThread and controller event thread. Perhaps `volatile` is a least requirement for memory visibility.
I think you'd want to use actual listener ports, not the JMX one. The JMX one is presumably opened very early when the process starts, but we want to make sure the Kafka service is actually up, running, and ready to serve traffic. That's why the previous version was checking for a message that happens much later in the startup process.
Would it be better to provide default value for this configuration? Otherwise this patch will break existing tests/tools that use `ProducerPerformance`.
This should never happen, right? maybe we just don't check it and get an NPE if somehow driver gets set to null after the setup.
I wonder if we want to print the actual list of partitions here, which might be long. And do it twice. I see the same pattern is applied elsewhere. I understand the value of explicit listing.
hm.. maybe I just did not notice `config.timeWindowMs`. All good now.
Oh, right, I forgot that the metrics registry returns the same copy of the sensor when all the name, description, and tags are the same... Thanks.
My minor concern is that KeyFactory and ValueFactory may be only specific to key-value stores, not not any general stores; for example for database stores you may have some functions like ``` withSchema() ``` that defines the data types for each column but not using "withKey / Value" any more. But since it is only for future improvements let's revisit this nested mechanism later.
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
Do we want a `ConnectException` here instead? Not sure.
Private and call from the constructor? We only ever call this immediately after instantiating the class.
This method is also deprecated. We should throw same exception as for `childIndex`.
We should make this test be fore `<byte[], byte[]>` as then we have covered both key and value deserialization.
nit: those lines can be rewritten (simplified?) as: `return (topic != null) ? topic: metrics.sensor(name1);`
@ewencp Actually I'd probably prefer to use separate explicitly named classes. For example: `StartConnectorCallable` and `StopConnectorCallable`. The reuse of the status enum seems a little confusing.
Maybe we should have a line for the old consumer as well. Regarding your question about the cluster id, the following line needs to be conditional on `from_kafka_version <= LATEST_0_10_0`: ``` assert self.zk.query("/cluster/id") is None ``` The code is just checking that the cluster id is generated after an upgrade from 0.10.0.x or lower to 0.10.1.x or higher.
I wonder if we could have a simple `IntRef` or something like that in the `common` classes to make this a little clearer. It would also help us in awkward lambda situations where we are not allowed to use a normal variable.
Can we change `subject` to `rockDdStore` -- it's a weird name IMHO.
This function returns true if there is a non-empty intersection between topicNames and partitionForHost. You could reverse the iteration: iterate topicNames (since it is a List) and lookup into partitionForHost (since it is a Set and likely has O(1) lookup time). The overall complexity would be reduced: O(m*n) -> O(m)
@ConcurrencyPractitioner thanks for updating the PR. My point from before was that we should restore each batch of records returned from each `poll()` call vs. keeping all returned records in memory and start the restore process when there no more records to fetch. Sorry if I did not make that point very clear.
To clarify: the PR hasn't been merged yet. Note that if this change were to cause a problem for LZ4, we would have the same problem for GZIP (due to the JDK implementation). In other words, we have to ensure that the underlying output stream has a good `close()` implementation anyway since we support GZIP as well.
This is the same code as in `KTableFilter` -- we should refactor and share code.
"empty" should be clear enough. Will update it in #10092
I don't fully understand why we check for a `processId` less than or greater than the ones defined above.
`final` is not required here.
Honestly I think it's fine to just name all three of these `build`, since they accept different parameters and it should be pretty clear from the context whether it's windowed or not. But being more descriptive is never a bad thing either. Your call 
original was better
nit: line too long
nit: we can keep the send() call without the partitioner argument which will then call this function with null.
I think this could be done with `computeIfAbsent` like in "finishSnapshot" above
I had to stare at the `SampledStat` code most of today. I actually think the original code is correct. The elapsed time should be the time elapsed in the current window plus the previous (non-obsolete) windows. It seems this is exactly what the current code is doing. Your change I think would effectively almost double the actual elapsed time. Maybe we can discuss this offline.
super nit: extra blank line
This log entry could be misleading, that even if there is an exception happened and hence no task created, it will still print as `created ...`; and in practice I have once encountered this issue before which affected the trouble shooting process, I think we should try to piggy-back fix it.
this is the same as above: we should extract to a method to avoid inconsistencies if one might get updated but the other one slips...
Note, the new version in StoreQueryUtils returns a Function, so that the iterators can just invoke the function on the value without having to know the right topic to pass in to the deserializer.
I stand by what i said, but I'll leave it up to you. It isn't a deal breaker for me!
maybe: `inputKeySerde` and `inputValSerde`
Might be good, to add a verification step for the `topologyDescription` similar to above (base on past experience, I am a little paranoid to make sure we do the correct thing when building the topology).
Should this be `error.message()` like a few lines above? Same question for other cases where we are still using `error`.
there is an issue (#8690) which RoundRobinPartitioner can cause uneven distribution when new batch is created. Maybe we should remind the known issue.
Hmm.. why not always clear it? The behavior becomes a bit less predictable if it depends on state which is not part of the current rebalance.
Nit: include brackets on all blocks, even if they are a single line. This makes it easier to read, but also reduces the number of affected lines if we have to add another line in the block in the future.
As mentioned above, we can make this constructor default access.
@showuon I just looked at the implementation of 'topLevelError' and I realized that it checks the partition errors as well. Therefore, it seems that we don't need to check them again afterwards. Sorry for this. I was not aware of this.
This is repeated in many of the methods, and I think there are a few other parts of the schema that you want to check are equal. Can we lift this up into `projectRequiredSchema`? I think you also want to check that the name, version, and parameters are equal. Then each of these `projectX` methods only needs to check any pieces that are specific to it, e.g. the key and value schemas.
Nit. use `{ }` for all code blocks
We already import the class on L26, so let's remove this import.
nit: remove empty line
Need to check if `group` is `null` in both `k1` and `k2`. Using this on, e.g., `DistributedConfig` from Kafka Connect doesn't currently work.
Yes that's correct as this PR stands now. But if we put the name check back to what it was originally, then this line is not needed.
nit: formatting -> single parameter per line (same next line)
More specifically, during `onPartitionsRevoked` the restore-consumer is assigned either: 1) with active restoring task partitions, or 2) with standby task partitions With 1), upon `onPartitionsAssigned` we would continue restoring active tasks while no standby tasks would be processed yet, hence we could update restore-consumer with revoked partitions and newly added task partitions that needs restoring; With 2), upon `onPartitionsAssigned` there are two cases: 1) if there are newly added task partitions that needs restoring, we should "revoke" all standby tasks since we need to first go to restore those active tasks; 2) no new active tasks need restoring, we should only "revoke" those standby tasks that are re-assigned.
I don't think that suppress works for any callers of `KStreamImpl#groupBy` -- from my understanding, there will be a warning for all callers independently of a suppress annotation -- callers would need to add their own annotation to suppress the warning for them. A `SuppressWarning` only suppressed warning from the body/implementation of this method (ie, if we would call any other deprecated method). I also don't think we need `@Deprecated` as this annotation is inherited anyway. However, this is an internal class anyway, and thus, not public. Thus, I don't have a strong opinion on this.
Yeah, that would be the closest for primitive types.
`seems existing already but it doesn't` -- this might be confusion. What about: ``` Could not create topic {}. Topic is properly marked for deletion (number of partitions is unknown). Will retry to create this topic in {} ms (to let broker finish async delete operation first). Error message was: {} ```
Nit: `.` full stop missing.
It seems that we haven't added the topicId yet.
Are we missing the ApiException here? I.e. error returned from servers that are not recoverable.
Should we mention the "problem" with out-of-order data for this case? Should we ever recommend to _not_ return `null` ? We had a discussion at some point to actually disallow returning `null` because a "delete" is not a valid aggregation result.
We don't need this for files, right? Just for directories (because of `file.deleteOnExit`)
Why recreating these objects? They are existed above: https://github.com/apache/kafka/pull/5390/files#diff-3cf77a4a8be4dc65221a87377c76ad33R52
I believe this is fixed in my next PR.
should we not just add 10 records in a row (offsets `0...9`) and simulate commit marker at offset 10 via setting endOffset to 11 ? This setup would indicate, that the record at offset 10 is either a non-transactional message (we could have mixed writes) or it's in pending state (neither committed not aborted) and thus endOffset could not be 11L as "last stable offset" is 9 or 10 and endoffset must be smaller than "last stable offset")
This selector is never used since we create a Selector a couple of lines below using `createSelector`. We should remove these three lines and the `logContext` created at the start of this test.
Sounds good. I just want to avoid someone trying to simplify the tests in the future without understanding that this test is verifying both features work together.
typo `direcctly` -> directly
Should we mention this in the KIP? It was not specified there - even though this is the same behavior as the old AlterConfigs, in the context of the KIP this non-transactional functionality isn't obvious I fear
nit: formatting: (we should also get the exception an verify the error message) ``` final TopologyException exception = assertThrows( TopologyException.class, () -> new StreamTask( ... ) ); assertThat(exception.getMessage(), equalTo("...")); ```
It's a bit better if you move this inside the `try` and remove the `return` from the catch.
This should probably just return a boolean
@lindong28 I tried this a bit locally, and realized the command now has two pipes to `tee` (see line 58 as well) When I drop the pipe to tee here on line 51 and keep the one below, the producer runs as expected.
Why use the delegate? Why not just call the methods on the `WorkerConnector`'s fields from within the `SourceConnectorContext` and `SinkConnectorContext` methods? E.g., @Override public void requestTaskReconfiguration() { ctx.requestTaskReconfiguration(); }
Why do you need to prepare `KafkaStreams` for testing? Only classes that are mocked and that are either `final` or have static methods need to be prepared.
Nevermind, I see that's the pattern we follow everywhere else
Since we are adding `fenced` to the RegisterBrokerRecord, do we also need to add a `fenced` field to the BrokerRegistrationRequest RPC? Or is it the case that only the controller will set the fenced state of this record
Doesn't seem to be used for anything? Why not just log a message saying that it didn't contain any plugins? In fact, even if we save this here, it seems like we'd still want that error message since the lack of any plugins probably indicates an incorrect configuration.
Can we just add https://checkstyle.sourceforge.io/config_sizes.html#LineLength so we never have to have this discussion again? :)
Seems this duplicates `L733`. Might be good to extract into a small helper method.
Should we be checking for null here? It's probably OK as this is only called from `abortIncompleteBatches`, but I thought I'd ask.
Right, so we should just reword Each connector gets their own dead letter queue topic to be more clear, so something like Each connectors dead letter queue is usually written to a different topic. Not super important, but Im just looking to eliminate potential usability issues.
Since we are adding `fenced` to the RegisterBrokerRecord, do we also need to add a `fenced` field to the BrokerRegistrationRequest RPC? Or is it the case that only the controller will set the fenced state of this record
nit: extra newline here
Typo: should be "or larger than the number of available brokers"
Also, are we fine with the config logging being bumped up to `info` (which is what `logAll` does) vs `debug` (which is what it was here).
The Achilles heel of implementing new KTable features has historically been that we forgot to test them in a context that required the ValueGetter to work properly, of which Join is a notable use case. I'd actually say it should be required for every KTable operator to have a test where it's the source of a Join. For stateless operators, we should test both with and without a Materialized argument on the operator.
Nit: Maybe `Use {@link #localThreadsMetadata()} to retrieve runtime information.`
I'd suggest to replace `5000` with `TimeUnit.SECONDS.toMillis(5)`. This is better than magic numbers.
This should be new `ValueMapperWithKey`
"or null if this was not redirected"
Yeah it makes sense. Sorry for not getting back to you sooner
The serialization package is open to everyone (it's public API and at the lowest layer). So I don't think we should worry about that. It's not like we're avoiding a dependency here, we are just hiding it via a string based config (that still requires the default constructor to be present).
@fhussonnois thinking about this some more, what is the motivation for doing a validation here for processor names? When Streams starts up the `AdminClient` will attempt to create any internal topics and the full topic names are validated at that point, so we don't need this check up front. \cc @guozhangwang
I think the name of the function is better defined as `interleaveTasksByConsumers`
By catching Throwable, aren't we silencing the error and not immediately failing the test? Also we should not be catching Throwable, if the JVM throws an Error we want it to fail the test and never want to handle it. There're a bunch of them in these files
Yes, that is the reason for the inconsistency. Obviously it was a mistake to let `OffsetAndMetadata` be serializable in the first place.
It's probably better to create two constructors, one for each version. We can then mark the v0 constructor as deprecated and can remove it in the future.
@cmccabe (My suggestion might not be good) If it has to check `futures`'s `size` every time, what about assign one time and use many times? Because JVM has to calculate size everytime when it is called. ```suggestion final int futuresSize = futures.size(); if (throwable == null && results.size() != futuresSize) { ```
Typo, should be: "an ever-updating" counting table"
nit: use `assertThat` instead
We can remove this field now that it's unused
nit: move this `if` statement below/above version check on line 62
Not sure if I can follow. The old code calls `driver.flushState();` after each `driver.process(...)` call.
This can just be referencing LEADER_AND_ISR_REQUEST_PARTITION_STATE_V0.
Maybe this copy block should be wrapped in `try/except/finally` so you can be sure to clean up temp files even if a copy phase fails. Then probably raise exception or rethrow if there was a problem copying Also, for the cleanup in the finally block, consider `shutil.rmtree(local_temp_dir, ignore_errors=True)`
Yeah with KIP-429, during the rebalance some tasks would still be processed and hence records being sent out; so the resuming tasks could be in RUNNING state as well.
This needs to be updated with the new constructor that accepts two arguments.
Not sure if I can follow. The old code calls `driver.flushState();` after each `driver.process(...)` call.
Nah, I think we should actually keep this (although `IllegalStateException` seems to make more sense, can we change it?) -- we should just make sure we don't reach it
Why "queryable-store-name"? IIRC we don't say "queryable store" anywhere else in the docs -- we use the term "interactive queries", if anything.
The test should describe what it is doing, i.e., `shouldThrowStreamsExceptionWhenBrokerCompatibilityResponseInconsisent`
Can we unify the `dataLength` computation into a single place? It's a little bit scattered at hard to follow. Also with different versions, I like a more explicit pattern using switch: ``` switch (version) { case 0: encodeV1(); break; case 1: encodeV2(); break; default: throw... } ```
Hmm.. The function is aimed to be a public API in `Topology` in KIP-120 (which I think will be renamed from the current `TopologyBuilder`?), but here it is only used as the function of the `InternalTopologyBuilder` which seems incorrect.
Hmm.. Is it actually safe to abort following a TimeoutException? I think this would cause an illegal state error in the producer. To handle this correctly, the application should retry the commit.
Same here, for verifying the thrown cause
Actually I think #2456 does not update the printed html for marking these as deprecated, so we still need to rebase + merge this PR after that one is merged.
Should be two tests instead? (Leave it up to you to decide -- don't insist on a change)
Ok, let's just keep it in our back pocket for now.
Hmm, maybe even better: ``` java long startWaitNs = time.nanoseconds(); long timeNs; boolean waitingTimeElapsed; try { waitingTimeElapsed = !moreMemory.await(remainingTimeToBlockNs, TimeUnit.NANOSECONDS); } catch (InterruptedException e) { this.waiters.remove(moreMemory); throw e; } finally { long endWaitNs = time.nanoseconds(); timeNs = Math.max(0L, endWaitNs - startWaitNs); this.waitTime.record(timeNs, time.milliseconds()); } ```
To clarify: the PR hasn't been merged yet. Note that if this change were to cause a problem for LZ4, we would have the same problem for GZIP (due to the JDK implementation). In other words, we have to ensure that the underlying output stream has a good `close()` implementation anyway since we support GZIP as well.
It's better to keep the parameters aligned (having same indentation)
We probably want all these `Long`s to be `long`s.
Upon checking out the code, actually the only purpose is for the running of the tasks, and not starting at all :-) It could definitely do with a better name... and naming for the the threads with a `ThreadFactory` (we should do that for the `bulkExecutor` too)
Nit: If we do fix up the above example of this it makes sense to fix this up too.
Should we restrict the values for name and version? Maybe we can just test that they are non empty? nit: the non-capture group isn't really necessary and this regex matches stuff like `"."` and `"---"`.
On a second thought, the overhead should be minimal: a few young gen objects only. So mvn.
'valueInZK' is poor name here - it's the name of the wildcard-suffixed pattern. 'intput' is actually a concrete resource name. `valueInZK` won't have the '*' suffix, (as discussed on the thread). - update the java doc accordingly too. Personally, I see a lot of scope for this being called in code where it shouldn't, (as it currently is). A more defensive API might be for the signature to be: ``` public static boolean matchWildcardSuffixed(Resource wildcard, Resource concrete) public static boolean matchWildcardSuffixed(ResourceFilter wildcard, Resource concrete) ``` And then to have the method throw if the wrong types of `wildcard` and `concrete` are passed in, i.e. `wildcard` should always have type `WILDCARD_SUFFIXED` and `concrete` should always to `LITERAL`
This test replaces `shouldGetThreadLevelSensor()`. Thus, you can safely remove `shouldGetThreadLevelSensor()`.
This works (note that `Properties implements Map<Object, Object>)`: ``` Properties p = new Properties(); Map<String, Object> foo = new HashMap(p); ``` So you should be able to do `getBoolean(new HashMap(props), ...)` (Need to omit the generics though...)
This should be: ```suggestion final long cacheSizePerThread = getCacheSizePerThread(threads.size() + 1); ```
nit: could be useful to log the type of exception in the assertion message.
There's a bit of a change in behavior in this PR. We would previously return an empty string for older request versions and now we return `null`. Is that intended @cmccabe? cc @hachikuji
Nice catch. And since we're here, why not make these `private`, too? They're currently not used outside of this class.
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
The iterator should return exactly one record. This, we should add an `Assert.assertFalse(it.hasNext());` after the `if`
check `source != null` not necessary. In doubt add an assertion.
I am guessing this is all part of GSS API magic but a link to doc or some explanation on what we are doing here might help with future maintenance.
For global state stores, here is the ordering of each stage: 1) Initialization: `GlobalStreamThread.initialize()` -> `GlobalStateUpdateTask.initialize()` -> `GlobalStateManagerImpl.initialize()`, where we read the checkpoint file into `checkpointableOffsets`. 2) Restoration: In the same `GlobalStateManagerImpl.initialize()`, we call `stateStore.init()`, in which `GlobalStateManagerImpl.register()` is called, and hence `restoreState()` will read from the loaded `checkpointableOffsets`: if it contains offset seekTo(), otherwise seekToBeginning(). 3) Starting: The restoration will bootstrap the global stores up to the log end offset, and after that we will write the restored offset to `checkpointableOffsets`: i.e. we will update the map, with the new values. At this stage the non-persistent stores' offsets should be written to it as well (i.e. line 288). Then we will call `GlobalStateUpdateTask.initTopology` to create the update node and go ahead the normal execution. So here the returned `stateMgr.checkpointed()` should already contain the restored offset already, therefore we can safely call `globalConsumer.seek()` in its caller now. 4) Checkpointing: When we call checkpoint(), we should make sure that non-persistent stores are not written to the checkpoint file, and actually whether we should filter on the `checkpointableOffsets` does not affect correctness anyways since we do not use it anywhere anymore, but to be consistent with its name I think it is still better to filter out those non-checkpointing offsets. Note that the whole logic is a bit awkward as it was spin off the `ProcessorStateManager` class, and as I mentioned above we can consider consolidating them in the future.
I had to stare at the `SampledStat` code most of today. I actually think the original code is correct. The elapsed time should be the time elapsed in the current window plus the previous (non-obsolete) windows. It seems this is exactly what the current code is doing. Your change I think would effectively almost double the actual elapsed time. Maybe we can discuss this offline.
There several issues with this test: - First of all the test fails. - According to the name of the test you want to verify `threadLevelSensor()`, but you call `taskLevelSensor()`. - Since the `Metrics` mock always returns the same sensor, it does not make sense to compare the sensors that are returned by the different calls to `threadLevelSensor()`. Such a verification will always be true. You should rather verify if method `sensor()` is not called on the `Metrics` mock. For example, the following two setups could replace `setupGetSensorTest()`: ``` private void setupGetNewSensorTest(final Metrics metrics, final String level, final RecordingLevel recordingLevel) { final String fullSensorName = fullSensorName(level); expect(metrics.getSensor(fullSensorName)).andStubReturn(null); final Sensor[] parents = {}; expect(metrics.sensor(fullSensorName, recordingLevel, parents)).andReturn(sensor); replay(metrics); } private void setupGetExistingSensorTest(final Metrics metrics, final String level, final RecordingLevel recordingLevel) { final String fullSensorName = fullSensorName(level); expect(metrics.getSensor(fullSensorName)).andStubReturn(sensor); replay(metrics); } ``` and the following two tests would replace `shouldGetTaskLevelSensor()`: ``` @Test public void shouldGetNewThreadLevelSensor() { final Metrics metrics = mock(Metrics.class); final RecordingLevel recordingLevel = RecordingLevel.INFO; setupGetNewSensorTest(metrics, THREAD_ID, recordingLevel); final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION); final Sensor actualSensor = streamsMetrics.threadLevelSensor(THREAD_ID, sensorName1, recordingLevel); verify(metrics); assertThat(actualSensor, is(equalToObject(sensor))); } @Test public void shouldGetExistingThreadLevelSensor() { final Metrics metrics = mock(Metrics.class); final RecordingLevel recordingLevel = RecordingLevel.INFO; setupGetExistingSensorTest(metrics, THREAD_ID, recordingLevel); final StreamsMetricsImpl streamsMetrics = new StreamsMetricsImpl(metrics, CLIENT_ID, VERSION); final Sensor actualSensor = streamsMetrics.threadLevelSensor(THREAD_ID, sensorName1, recordingLevel); verify(metrics); assertThat(actualSensor, is(equalToObject(sensor))); } ``` Similar is true for the other tests below.
It was removed from the other versions of `group` but not from here.
We really need a bug fix release for this! \cc @guozhangwang
How about the following to simplify the string construction below: ```java String clientEnabled = System.getProperty(ZK_SASL_CLIENT, "default:" + DEFAULT_ZK_SASL_CLIENT); String contextName = System.getProperty(ZK_LOGIN_CONTEXT_NAME_KEY, "default:" + DEFAULT_ZK_LOGIN_CONTEXT_NAME); ```
Below we break into `brokerResources` and `unifiedRequestResources` and send two requests; we should check them and skip if possible respectively.
```suggestion * A byte array comparator based on lexicographic ordering. ```
Maybe we should add one case where `position > 0`.
This should never happen, right? maybe we just don't check it and get an NPE if somehow driver gets set to null after the setup.
We just need to make sure the extracted generation from all three processors are the same.
Ok. Thanks for clarifying.
Shouldn't you verify if topology 1 still produces output records at this point? When I read the test name I would expect that verification here.
nit: Could just to `new ArrayList<>();`
The other constructor calls the parameter `sampledStat`. We should be consistent.
We should use `aasertThrows` and verify the error message similar to the `TransformerSupplier` test
I know we need both `File` and `Path` instance to complete the permission setting. What I meant is that: 1. We already had the `File` instances, i.e. baseDir, stateDir 2. `Paths.get(stateDir.getPath())` --> what happened behind the scene, is we created a Path instance from the path string in the file instance (i.e.`stateDir.getPath()`) ```java public final Path getPath(String var1, String... var2) { ... return new UnixPath(this, var3); } ``` 3. `path.toFile()` --> what happened behind the scene, is we created a File instance from the path string ```java public final File toFile() { return new File(this.toString()); } ``` So, currently, we will created an additional File instance via `path.toFile()`. If we pass the File instance into `configurePermissions()` directly, it'll only created a `Path` instance. ex: ```java configurePermissions(stateDir); // pass the file instance directly ``` ```java private void configurePermissions(final File file) { final Path path = Paths.get(file.getPath()); // created path instance if (path.getFileSystem().supportedFileAttributeViews().contains("posix")) { .... } else { boolean set = file.setReadable(true, true); // won't create additional File instance here .... } } ```
Yes. The user can use the config two ways: ``` // as string props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, "my.fully.qualified.package.MyInnerSerde"); // or as class props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, my.fully.qualified.package.MyInnerSerde.class); // or short (it the class is imported) props.put(DEFAULT_LIST_KEY_SERDE_TYPE_CLASS, MyInnerSerde.class); ``` Both should be supported and the code need to be able to handle both cases. Hence, we should get is as `Object` and use `instanceof` to check the type.
Perhaps we can use a better name for keysWithBytesFromSocket since selectedKeys() include keys ready for writes too.
This can be static
i think we should just stick with `joiner` for the name of this param. here and elsewhere
nit: avoid inserting random blank lines.
I'm not sure of the original motivation behind setting it to `50`. But if we are going to define it as `1000` i think it might be better to remove this and `reconnect_backoff_min_ms_config` definitations from here as they are the same as what is set in the `ProducerConfig` and `ConsumerConfig`, so it seem pretty pointless overriding them
Could we use `TestUtils.waitForCondition`? Similarly in `waitForTasksToBeUp`.
This throttle can cap our `refreshRateMs` per connection, right? e.g if we have only 2 threads and 4 tasks with a refreshRateMs of 5ms, I think only two of those tasks will ever see their connections being reset. This seems to expose a flaw in the way we find connections to maintain - by simply looping over the list we can't ensure that all tasks get an equal chance of a connection refresh. If it isn't too hard, maybe we should use some sort of heap ordered by last update time . Or maybe we can not throttle at all
I think we'd want to override `parseResponse` for `API_VERSIONS` only.
Can you please explain why it's better to warn than to fail-fast in this case? Just want to make sure I understand the reasoning for the choice.
the type of pollTimeMs is *Duration*. It seems to me that the "ms" is a bit redundant.
We can define two static variables of `NoOpStateRestoreListener` and `NoOpStateRestoreCallback` instead of creating a new instance multiple times.
This could throw a NPE. I think we should guard against this, and throw `ParseException` if NPE happens `ts.split("T")` is redundant and should be extracted into a variable.
Do we need this config? `producer.send(record).get();` ensures we get a response from the request so I don't see the value in the config
req: move this to `StreamsPartitionAssignor`, where we'll be building and passing the `Map<TaskId, SortedSet<ClientIdAndLag<ID>>> statefulTasksToRankedClients` map around
Hmm, this sounds to me that the StreamProducer's own `partitionsFor` did not return the num.partitions so we ended up calling `send` with `partition == null`, since otherwise we will get the `partition` as ``` partition = partitioner.partition(topic, key, value, partitions.size()); ``` where `partitioner` is the `StreamsPartitioner` and the producer's own partitioner should not be used.
nit: add `final
Like I said, not a big deal and I'll commit as is. But by using entrySet, I didn't mean not to use key at all, just that something like: ``` for (Map.Entry<String, String> entry : configKeys.entrySet()) { String configName = entry.getKey(); Type type = entry.getValue(); ``` would avoid doing the extra lookup and would still let you use the key directly as needed.
We also don't want to accept null addresses, right? I was thinking we could do this: ```java if (address == null || address.equals(NON_ROUTABLE_ADDRESS)) { throw new IllegalArgumentException("Invalid address " + address); } ```
Why did you remove the `return`? Without the `return`, the code will reach the `finally` block and log that the assignment took place.
If we are not exposing this detail, then it would be a bit weird to classify them in the first place.
Should be larger
Missing newline character.
Hmm, is this method the only place where we would sync the data to disk? I thought we would want to sync to disk periodically as well.
nit: 'else' can be dropped
`error` is unused
@mjsax Got it. Thanks for your response!
How about the following to simplify the string construction below: ```java String clientEnabled = System.getProperty(ZK_SASL_CLIENT, "default:" + DEFAULT_ZK_SASL_CLIENT); String contextName = System.getProperty(ZK_LOGIN_CONTEXT_NAME_KEY, "default:" + DEFAULT_ZK_LOGIN_CONTEXT_NAME); ```
line is too long
nit: `Arrays.asList` a bit more concise.
Passing in the current listener seems a little weird. I wonder if we're trying a little too hard to reuse the subscribeTopics method in SubscriptionState. If instead we had a method like SubscriptionState.subscribeMatchingTopic (or something like that), then we wouldn't need the flag and we wouldn't need to pass a listener. You could change this line to this: ``` subscription.subscribeMatchingTopics(topicsToSubscribe); metadata.setTopics(topicsToSubscribe) ```
nit: ```suggestion = new RocksDBGenericOptionsToDbOptionsColumnFamilyOptionsAdapter(new DBOptions(), new ColumnFamilyOptions()); ```
You want the loop to read even when there is no data from the network. So the condition needs to be something along the lines of `if (channel.ready() && (key.isReadable() || channel.hasBytesBuffered()) && !explicitlyMutedChannels.contains(channel) && !hasStagedReceive(channel))`
For this case, the input `KStream` key was not changed, and thus no repartition topic should be created. We should only get a single sub-topology.
That's a good point that the same taskID may change with different partitions. I think what I'm trying to explore is whether we can make the logic a bit clearer to read while being protocol agnostic. That is, we can either 1) reason about the source-of-truth for added / revoked / remained tasks for both active and standby in `assignor#onAssignment`, and then we do not need to rely on the parameters passed in the `listener#onPartitionsRevoked / Assigned` at all. 2) rely on the `listener#onPartitionsRevoked / Assigned` to get the list of revoked / remained / added tasks.
Do we need this extra variable? It seems like `defaultValueBytes` is not used
From my understanding, neither the `ConsumerRecord` nor the `ProcessroRecordContext` are the issue, but the shared `Header` object -- it's just a "side effect" that creating a new `ConsumerRecord` creates an new `Header` object internally.
That's correct. The implementation becomes a bit tricky, as we can't just use `Arrays.asList` and be done.
I'd really like to discourage passing `null`. We can have a `KeyValueMapper` instance that we pass here and also throw an exception in the method that is delegated to if the `KeyValueMapper` is `null`. Same elsewhere
Nit: can be `final`
super nit: extra blank line
Same for all such calls.
Same as above: need to check `clientResponse.hasResponse()`
Also, I just looked at `ConnectRecord.toString()`, and it does _not_ print the schemas. I wonder if it's worth changing that to include whether the key schema and value schema are null; e.g., ``` @Override public String toString() { return "ConnectRecord{" + "topic='" + topic + '\'' + ", kafkaPartition=" + kafkaPartition + ", keySchema=" + (keySchema != null ? "..." : "null") + ", key=" + key + ", valueSchema=" + (valueSchema != null ? "..." : "null") + ", value=" + value + ", timestamp=" + timestamp + ", headers=" + headers + '}'; } ```
I think we can just call `createKeyValueStore` and inline `createStore` inside `createKeyValueStore`. Also since all the calls in this class are the same, we can extract the `store` as a class variable.
Hah, I got the last word! Just kidding, fwiw I'm not trying to block this PR on the matter so it's fine by me if you merge as-is. Only wanted to make sure we're being fair to our assignor friends :P
should this be `&&`? As it is, this loop could terminate even if we always return null and never non-null
Thanks for the background @rajinisivaram. By the way, I noticed one of the checks is defined inconsistently: https://github.com/apache/kafka/blob/trunk/clients/src/main/java/org/apache/kafka/common/network/SslTransportLayer.java#L344.
ditto for the rest of the test
This should not have the `sink` suffix
Cool, if we are worried about concurrent updates then the current pattern is good. I had the sense further requests being added is not possible while in `halt()` but I don't immediately see this prevented in any way.
```java if (tagged) { buffer.printf("int _sizeBeforeArray = _size.totalSize();%n"); } ```
nit: maybe call this `fixedLengthDeserializers` -- it's not about primitive types.
In other words, I'm recommending that we specifically say something like "Producing deletes from your aggregations may cause unexpected results when processing dis-ordered data. Streams always processes data in the order it appears in the topic. If the topic is populated out of order, you may have late arriving records, which can cause records to become unexpectedly re-created after they have been deleted. Out-of-order data can be a problem for non-deleting aggregation functions as well, but it's especially surprising with aggregations that produce deletes." :/ ... you see what I mean by saying that it's a nuanced topic.
@guozhangwang Yep, sounds good to me.
@cmccabe I think you missed this change.
Since these two branches do the same thing and half of the inner conditional is the same, it seems like you could just combine it all into one condition and only have one copy of that code.
assignedTopicPartitions could be updated concurrently and we are accessing it without lock protection here.
Maybe we could use a different value here.
yes, it seems to be not what this test is checking on. I think we can drop it here.
If we run the script to do the actual release, we have this information already. It would be good to reuse this. Ie, we can keep this as-is, however add a second method that takes this information as parameters. This allow us to call the new method from here, after we collected the information, but also at the end of the regular execution of the script and pass in the information directly. Thus, if a committer does a release, it's not required to call the script again but the email template will be generated directly.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
On the broker-side this is not fatal, but typically caused by a mis-configured client. For clients, it is typically fatal, but could sometimes just be a clock-mismatch where a retry could succeed.
`UnknownTopicOrPartitionException` is the cause of the actual exception `e`, so we cannot just catch it here.
+1 to this
remove try-fail-catch and rewrite to ``` final StreamsException expected = assertThrows(StreamsException.class, () -> collector.flush()); assertTrue(expected.getCause() instanceof TimeoutException); assertTrue(expected.getMessage().endsWith(topic1TimeoutHint)); ```
Also need to change `keyValueStore` method to return `StateStoreSupplier<KeyValueStore>`
EDIT: nvm, I think I understand it now.
And same question for the other uses of `TestUtils.tempDirectory` in this PR.
Isn't this a behavior change? IIRC, we had a discussion to do this change, or to maybe make it configurable if we want to interleave processing with recovery.
nit: extra newline here
I think `nanoseconds` should be `milliseconds`. It's a little more idiomatic to do it like this: ```java time.sleep(autoCommitIntervalMs); coordinator.maybeAutoCommitOffsetsAsync(time.milliseconds()); ```
Hmm, `DataInputStream.readFully` only throws an exception if we ask it to read past the end of the InputStream. So supposedly, if we fix the underlying InputStream, it's enough either way. The following PR does that: https://github.com/apache/kafka/pull/2025/files#diff-eaa7e4414f285da2ff8e4508456078d2L192
No, I'm talking more about the `encode*` and `castTo*` methods in this class. I'm not suggesting we make them public, but instead I'm asking whether it would make sense to make these *protected* and *non-static* so that it would be easier to create subclasses. I guess the problem with that, though, is that they are implementation details and not part fo the public API. If anybody did create a subclass and we later changed the implementation, their subclass would no longer compile and they'd have problems running on different versions of Connect. Given that, I think it's fine the way it is: private non-static or private static doesn't really matter except for subclasses.
`assertX` has expected value as first parameter -- we should switch both to avoid confusing error messages. Applied to whole class.
My concern with this approach is that it isn't very flexible, i.e., i either have caching on or off, and that if i'm using any custom stores (and there might be a mix of custom/non-custom), and i don't need/want the custom store to be cached, then i need to turn it off for everything.
prop: I find `assertThat()` better readable than `assertEquals()`.
nit: add `final` -- same next line
typo: "partitions that *are* no longer assigned"
Why would `workerId` ever be `null`? And does having the `CONNECT_WORKER_ID_SEQUENCE` really help since all your workers would just have ID = 1? If this is just for tests, seems better to just require the ID to be passed in since we effectively require it for `Worker` and everything else.
Maybe a little subjective, but I think the test case would be more readable if we list these brokers directly. For example: ```java List<Integer> allBrokers = Arrays.asList(1, 2, 3, 4, 5); List<Integer> brokersToKeepUnfenced = Arrays.asList(1); ```
Do we really want anything related to internal topics to be client side? This could change in brokers from version to version and the clients should still work. I understand that for now we have no way to get that information, but we will soon (KAFKA-3306). I imagine removing the client side list would be part of the cleanup once thats available. So whatever exists in the mean time should be private so we don't need a deprecation cycle.
We shouldn't return `null`, but instead return a "unknown query" result.
Not sure what has changed here.
I don't think a reference to `protocol_api_keys.html` is required here; because that file is loaded as a server side include (SSI) inside `protocol.html`. I would prefix the anchor labels with something like `The_Messages` (which is the referred main section name) instead to make them uniform. The hyperlinks should work fine after fixing this.
Maybe we shouldn't say "error" when it's not an error. I'm just imagining the mailing list questions that will start pouring in... ```suggestion log.info("Received version probing code {}", AssignorError.VERSION_PROBING); ```
I looked at it closer. I still think it's better to split them out, but I also don't think it's a correctness issue right now, so I'd be fine with merging what you have.
nit: simplify to `throws Exception` -- in test, we don't intent to catch them anyway and just let the test fail
this could be: `assertThat(serializer.serialize(topic, null), nullValue())`
This should say `AdminClient`, not `Consumer`.
Where is this function used? I'd suggest we only keep one function, i.e. ``` public Map<TopicPartition, KafkaFuture< ConsumerGroupDescription >> DescribeConsumerGroupsResult#values() ```
Not required. Client will be automatically closes, as we use Java's "try with resource" feature.
nit: maybe worth adding `this == o` to these `equals` implementations. This applies to all of the similar classes in this PR.
This selector is never used since we create a Selector a couple of lines below using `createSelector`. We should remove these three lines and the `logContext` created at the start of this test.
Think about that a bit more, maybe we can make it simpler as: ``` if (keyFrom == null && keyTo == null) { // fetch all return true; } else if (keyFrom == null) { // start from the beginning return key.compareTo(getKey(keyTo)) <= 0; } else if (keyTo == null) { // end to the last return key.compareTo(getKey(keyFrom)) >= 0; } else { return key.compareTo(getKey(keyFrom)) >= 0 && key.compareTo(getKey(keyTo)) <= 0; } ```
Oh, I see. Well, either way works for me.
Ack, makes sense. I'm fine with either approach, although looking at the next few lines it doesn't look like there's a good, single place to reset it.
Maybe there is an easier way, but I found the following: Set the config to: ``` final StreamJoined<String, Integer, Integer> streamJoined = StreamJoined .with(Serdes.String(), Serdes.Integer(), Serdes.Integer()) .withStoreName("store") .withLoggingEnabled(Collections.singletonMap("test", "property")); ``` and then check it: ``` internalTopologyBuilder.buildSubtopology(0); assertThat(internalTopologyBuilder.stateStores().get("store-this-join-store").loggingEnabled(), equalTo(true)); assertThat(internalTopologyBuilder.stateStores().get("store-other-join-store").loggingEnabled(), equalTo(true)); assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.size(), equalTo(2)); for (final InternalTopicConfig config : internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.values()) { assertThat( config.getProperties(Collections.emptyMap(), 0).get("test"), equalTo("property") ); } ``` Without ``` assertThat(internalTopologyBuilder.topicGroups().get(0).stateChangelogTopics.size(), equalTo(2)); ``` the test would pass without checking the config if `buildSubtopology()` is not called because no changelog topics would be registered in the topology. So it basically checks that `buildSubtopology()` is called.
We did not have this check before, why is it needed? Also checks here are only applied when running in "driver" mode.
It might be nice to use different values for each record (at least within the same key). I don't think there are really any edge cases we should worry about when records have the same value so we may as well use a distinct one to make the tests a bit easier to read
IIUC, `rocksDBMetricsRecordingTriggerThread` is either going to be `null` because it didn't meet the criteria for creating the thread or it is going to be non null because we did create it. Given that, checking for `null` is a nicer way to determine if we need to shutdown because as long as we have a thread, regardless of the condition that created it (e.g. `RecordingLevel.DEBUG`), we should shut it down. This is also safer if the creation conditions ever change and we forget to update them here.
Not done as part of the PR, but... Can we pass `new PrintWriter(System.out)` here instead of `null`
The number has changed and 5 is no longer relevant.
Typo: "you can create [a] windowed ..."
`wait` should be used if the `Service` is expected to exit naturally based on previous commands: ``` Wait for the service to finish. This only makes sense for tasks with a fixed amount of work to do. For services that generate output, it is only guaranteed to be available after this call returns. ``` You generally do not need to use it in concert with `stop` as `stop` is generally implemented either to synchronously wait (on a clean shutdown via SIGTERM) or kills aggressively enough that you don't actually have to wait (i.e. SIGKILL). I suspect many of the uses of `wait`/`stop` with these `Service` classes are just redundant -- that is rare or non-existent elsewhere. Use of `wait` elsewhere is mostly limited to things like a console producer/consumer that are known to need to consume a limited amount of data.
Nit: we don't normally use exclamation marks in Kafka log messages.
nit: additional new line
Did @guozhangwang suggest to rename this DF to `2.2`? I actually think the descriptive name might be better. It seems like it'll be less work in the long run to remember what exactly is different about the different CFs.
ditto on (what I think is) the impossibility of this condition being false.
I think this can be simplified a little bit more by getting rid of this variable. How about this? ```java boolean userConfiguredTransactions = this.originalsContainsKey(TRANSACTIONAL_ID_CONFIG); boolean idempotenceEnabled = this.getBoolean(ENABLE_IDEMPOTENCE_CONFIG); if (!idempotenceEnabled && userConfiguredTransactions) { throw new ConfigException("Cannot set a " + ProducerConfig.TRANSACTIONAL_ID_CONFIG + " without also enabling idempotence."); } return idempotenceEnabled;
Fair enough, let's just leave it as is then. Thanks for the explanation.
Will this ever happen? I think `Utils.newInstance` is guaranteed to give you an instance of the passed in `class` type. Ditto below.
I know that's kind of another large change, so feel free to tell me to drop it  Or one of us can consider as followup work.
nit: rename `ivtwks`
True, will we ever want to have this ability? But the change seems fine to me.
Should we have tests for the `DistributedConfig` class? Again, much of the logic should be the same, but the tests would each be simpler if using a `ConfigDef.Validator`.
We don't need a PriorityQueue for this because the batches in the RecordAccumulator is already in order. So we just need to keep the draining order.
a tab is missing here for alignment too.
Should we wait until all brokers and Connect workers are available, via something like: ``` connect.assertions().assertExactlyNumBrokersAreUp(numBrokers, "Brokers did not start in time."); connect.assertions().assertExactlyNumWorkersAreUp(numWorkers, "Worker did not start in time."); ```
Is there a reason why this isn't simply using `Configuration.getConfiguration()` to get the default configuration since it is using the standard Java property to get the Jaas config file anyway? I think `JavaLoginConfig` is provided by the Sun provider, dont think it is available with all vendors.
I think putting a `@JsonValue` annotation here should fix the capitalization issue, seems like it uses `name()` by default for `enums`.
This doesn't need to be declared outside the loop (it can be final at the assignment).
Yes, this seems fine then.
If you pass the new one, then you can probably get rid of `changedTopicId`
This is an internal class -- no need to mark as deprecated.
